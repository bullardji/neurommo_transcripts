Kind: captions
Language: en
okay we are
live give the streams a second to warm
up we're going to do some fun stuff
okay uh let's we're going to do some fun
okay uh let's we're going to do some fun
stuff
stuff
today today is going to be a fun Dev
today today is going to be a fun Dev
day we've been doing a lot of grindy
day we've been doing a lot of grindy
infra and we're going to do some fun
infra and we're going to do some fun
stuff which is slightly different grindy
stuff which is slightly different grindy
infrastructure but still it's going to
infrastructure but still it's going to
be more
be more
fun now where did I put hold on let me
fun now where did I put hold on let me
get the gift from
yesterday we're going to take a look
yesterday we're going to take a look
let's take a look at the uh the previous
let's take a look at the uh the previous
or is it
or is it
open by
open by
location okay so this is what we did
location okay so this is what we did
yesterday we got them playing the full
yesterday we got them playing the full
game
I'm going to retweet this thing out and
I'm going to retweet this thing out and
then what we're going to do today is
then what we're going to do today is
we're actually going to pay the piper
we're actually going to pay the piper
and we're going to make this thing
and we're going to make this thing
actually be a million FPS like the
actually be a million FPS like the
stream title says and we're going to
stream title says and we're going to
start on the RL
side tweet did okay this is going to be
side tweet did okay this is going to be
a good test
though e
I want to see what happens if I tweet
I want to see what happens if I tweet
this without the link if it actually
this without the link if it actually
does
does
better also last thing before before we
better also last thing before before we
start on proper Dev Twitter is so
start on proper Dev Twitter is so
weird like this is the second time this
weird like this is the second time this
has happened where I've just made some
has happened where I've just made some
like dumb funny comment on something and
like dumb funny comment on something and
it's just completely blown up Beyond
it's just completely blown up Beyond
like any of
like any of
my any of my other things and then you
my any of my other things and then you
can't use it for anything like I can't
can't use it for anything like I can't
comment underneath it like any of my
comment underneath it like any of my
other stuff it gets no promotion
other stuff it gets no promotion
whatsoever it's so funny how that works
whatsoever it's so funny how that works
internet is weird Okay so the plan for
internet is weird Okay so the plan for
today
today
I see we've got a couple people watching
I see we've got a couple people watching
this already that's great um the plan
this already that's great um the plan
for today is we're going to pay the
for today is we're going to pay the
piper and I've been advertising that I
piper and I've been advertising that I
will make this thing 1 million FPS today
will make this thing 1 million FPS today
I'm actually going to make it 1 million
I'm actually going to make it 1 million
FPS and you're going to get to see
FPS and you're going to get to see
exactly how I do
exactly how I do
that it's going to
that it's going to
be uh some algorithmic optimization but
be uh some algorithmic optimization but
for the most part it's going to be
for the most part it's going to be
making all of the tight Loops in scon
making all of the tight Loops in scon
run natively in C without ever calling
run natively in C without ever calling
back to
back to
python uh there might be a few little
python uh there might be a few little
hitches here and there but I've done
hitches here and there but I've done
this process with a number of other
this process with a number of other
environments so that's why I was
environments so that's why I was
confident like claiming 1 million FPS
confident like claiming 1 million FPS
before I got it because it's absolutely
before I got it because it's absolutely
going to be 1 million FPS
going to be 1 million FPS
now starting on
dev first thing we are going to do we're
dev first thing we are going to do we're
going to open up this setup.py and make
going to open up this setup.py and make
sure we have annot on which is here this
sure we have annot on which is here this
tells us when we recompile stuff this
tells us when we recompile stuff this
tells us exactly where it is calling
tells us exactly where it is calling
back from scon to python so this is
back from scon to python so this is
where you're getting all your slowdowns
where you're getting all your slowdowns
from here so we're going to start with
from here so we're going to start with
this and we've got cmob pix which is our
this and we've got cmob pix which is our
file and we're also going
file and we're also going
to there's one other thing we have to do
scon has all these checks at the top
scon has all these checks at the top
these are your don't shoot yourself in
these are your don't shoot yourself in
the foot checks this is what makes it
the foot checks this is what makes it
not as painful to Devon as C for
not as painful to Devon as C for
instance and uh we're basically just
instance and uh we're basically just
going to remove all the safeties because
going to remove all the safeties because
the safeties will make it call back to
the safeties will make it call back to
python C division we leave as
python C division we leave as
true so now we're not checking in if we
true so now we're not checking in if we
like accidentally have values that are
like accidentally have values that are
none we're not checking array indexing
none we're not checking array indexing
errors that like python Toyon we're not
errors that like python Toyon we're not
doing uh things being uninitialized
doing uh things being uninitialized
we're not doing any bounce checks
we're not doing any bounce checks
okay and we're going to
recompile and hopefully it does not
recompile and hopefully it does not
crash sometimes there are like
crash sometimes there are like
optimization specific things that can
optimization specific things that can
crash
crash
you and then we're going to run uh this
you and then we're going to run uh this
test performance
test performance
here yeah let's run test per
performance right hold
performance right hold
on there's a just a slightly annoying
on there's a just a slightly annoying
thing here that I have to do in order to
thing here that I have to do in order to
make this
make this
work and I
work and I
believe I just have to
believe I just have to
do from uh
Coba let's get our initial profile
test really it doesn't
work what uh what did I mess up
work what uh what did I mess up
here just the Imports
whatever well let's take a second to
whatever well let's take a second to
figure out why this is not working as uh
figure out why this is not working as uh
as
as
intended ocean mooba seim
MOA well we can always just put this
MOA well we can always just put this
performance test somewhere else for now
performance test somewhere else for now
just to keep the
just to keep the
uh to keep this up for stream so I'm
uh to keep this up for stream so I'm
just going to copy
this uh MOA perf
from
from
puffer MOA Coba it's just from mobile we
puffer MOA Coba it's just from mobile we
import puffer MOBA and this is going to
import puffer MOBA and this is going to
be our profile test at the
start and what do we call this MOA test
start and what do we call this MOA test
or something yeah MOA
or something yeah MOA
per let's see if this works
hold
hold
on oh I did something
weird oh uh yeah it's right here it's
weird oh uh yeah it's right here it's
MOBA
MOBA
dot MOBA
dot MOBA
again that's probably all it was
again that's probably all it was
anyways uh Moa
Mo see they should
run no
module what the heck well we need to get
module what the heck well we need to get
this perf test working let's in the
this perf test working let's in the
meantime I'm going to open up something
meantime I'm going to open up something
cool uh just so we can get an initial
cool uh just so we can get an initial
look and then I'll come back to this in
look and then I'll come back to this in
a moment um and then I'll go fix this so
a moment um and then I'll go fix this so
just so that folks have something
just so that folks have something
interesting to see in the meantime uh
interesting to see in the meantime uh
just so you get like an interesting like
just so you get like an interesting like
overview and I can start thinking about
overview and I can start thinking about
this in the back of my head so uh if I
this in the back of my head so uh if I
go to the the file here hoer Leb
go to the the file here hoer Leb
environments ocean mooba
environments ocean mooba
we see that we have some HTML files in
we see that we have some HTML files in
here right and we're going to move this
here right and we're going to move this
Coba
HTML into
here and now we have cob here and look
here and now we have cob here and look
what this gives
what this gives
you so this file
you so this file
here anywhere we have this in uh yellow
here anywhere we have this in uh yellow
highlight it is calling back to Python
highlight it is calling back to Python
and anywhere that it is white it is not
and anywhere that it is white it is not
calling back to python so for instance
calling back to python so for instance
this inline function here is a pure C
this inline function here is a pure C
function no calls back to python this
function no calls back to python this
inline function here is actually calling
inline function here is actually calling
back to python uh it looks like I didn't
back to python uh it looks like I didn't
add a return type so that's probably why
add a return type so that's probably why
the function signature is bad
and then I'd assume that this is also
and then I'd assume that this is also
highlighted because I didn't add a
highlighted because I didn't add a
return type so when we go fix the types
return type so when we go fix the types
on this this will no longer call back to
on this this will no longer call back to
Python and it will be like a 100 times
Python and it will be like a 100 times
faster uh things in a knit we don't
faster uh things in a knit we don't
really care about because they only
really care about because they only
happen
happen
once things like level we may be care
once things like level we may be care
about
about
right here what what did we do
right here what what did we do
here Pi int from in Rich compare Pi
here Pi int from in Rich compare Pi
object is
object is
true uh okay we didn't type
true uh okay we didn't type
XP so missing typing
XP so missing typing
there uh cdef void compute
there uh cdef void compute
observation this doesn't look like it
observation this doesn't look like it
should have anything wrong with
should have anything wrong with
it
um let's
um let's
see add Trace back sometimes the uh The
see add Trace back sometimes the uh The
annotation thing itself will add
annotation thing itself will add
uh add like spous highlights just to
uh add like spous highlights just to
function
function
signatures but for the most part it's
signatures but for the most part it's
fine we can see here in compute
fine we can see here in compute
observation it looks like I messed this
observation it looks like I messed this
up here let's see Y into
up here let's see Y into
Dy uh I didn't type did I not type
Dy uh I didn't type did I not type
Dy Pi in from
double possibly you're not allowed to
double possibly you're not allowed to
use this cast
use this cast
syntax I thought you were allowed to do
syntax I thought you were allowed to do
this though let me see if this was done
this though let me see if this was done
up
up
top there's a different cast intax for C
top there's a different cast intax for C
Cast though I thought that they both
Cast though I thought that they both
worked but in general it's this type of
worked but in general it's this type of
a thing right where like we're going to
a thing right where like we're going to
look for places where we're calling back
look for places where we're calling back
when we don't mean to be calling back I
when we don't mean to be calling back I
actually if we're looking at this we can
actually if we're looking at this we can
see I've done a pretty good job to begin
see I've done a pretty good job to begin
with but like there's some places where
with but like there's some places where
definitely like this L2 distance it
definitely like this L2 distance it
looks like this is calling back uh this
looks like this is calling back uh this
neutral AI maybe has a call back here
neutral AI maybe has a call back here
um L2 distance is a really big one it
um L2 distance is a really big one it
looks
looks
like some of the function signatures
like some of the function signatures
apparently you're still calling
apparently you're still calling
back XP is
bad various things around here uh that
bad various things around here uh that
we can potentially optimize quite a bit
we can potentially optimize quite a bit
right though I'm
right though I'm
actually apparently I've gotten way
actually apparently I've gotten way
better at this
better at this
because for a first pass having never
because for a first pass having never
opened this before this is actually
opened this before this is actually
really
solid okay let's figure out that profile
solid okay let's figure out that profile
code and uh we will optimize from there
code and uh we will optimize from there
it looks like there's not going to be
it looks like there's not going to be
actually too much typing stuff as soon
actually too much typing stuff as soon
as we get the profile check done I think
as we get the profile check done I think
we're probably going to only have maybe
we're probably going to only have maybe
an hour's worth of uh type type based
an hour's worth of uh type type based
optimizations and then most of it's
optimizations and then most of it's
going to have to be algorithmic so it's
going to have to be algorithmic so it's
pretty important where we start off for
pretty important where we start off for
this Baseline let me just figure out why
this Baseline let me just figure out why
why this is not allowing me puffer
why this is not allowing me puffer
environments ocean MOA MOBA right
environments ocean MOA MOBA right
puffer environments ocean mooba
puffer environments ocean mooba
mooba
mooba
puffer we have puffer MOBA here
right no
right no
module puffer Li environments
oh is it not uh it's not importing the
oh is it not uh it's not importing the
sea environment that's
sea environment that's
weird from puff of environment ocean MOA
weird from puff of environment ocean MOA
sea
sea
mooba import environment as sea
environment and that looks like it's
environment and that looks like it's
fine to me
and what if I call it from here what
and what if I call it from here what
happens over
here no module cmob okay let me just pip
here no module cmob okay let me just pip
install make sure that it's actually got
install make sure that it's actually got
a upto-date copy of
everything syon is substantially less of
everything syon is substantially less of
a pain uh to get built compared to Pi
a pain uh to get built compared to Pi
bind with C++ for instance but still a
bind with C++ for instance but still a
little bit of a
pain just a little
bit let me make sure that I didn't like
bit let me make sure that I didn't like
take this pix file out for some reason I
take this pix file out for some reason I
don't think I would have that would have
don't think I would have that would have
been
been
weird this is the whole setup right here
weird this is the whole setup right here
for the scon files pretty basic just
for the scon files pretty basic just
call scon eyes on all the individual
call scon eyes on all the individual
files I can see I do have the cmob file
files I can see I do have the cmob file
here
here
correctly okay so this took a while to
correctly okay so this took a while to
run so I'm suspecting that
run so I'm suspecting that
maybe maybe there was something weird
there still cannot import
there still cannot import
this no
module ocean
module ocean
mooba I see the Coba pix right here
mooba I see the Coba pix right here
uh I don't see Theo though I don't see
uh I don't see Theo though I don't see
the linked file that's
the linked file that's
weird
weird
right there should be a a
doso so I think that this is somehow a
doso so I think that this is somehow a
build error of some
type we'll rerun this uh this form of
type we'll rerun this uh this form of
the build system there are a couple like
the build system there are a couple like
crappy tools setup tools that uh don't
crappy tools setup tools that uh don't
play nicely
play nicely
together that can cause issues
together that can cause issues
sometimes as soon as we have this fixed
sometimes as soon as we have this fixed
though like we'll be good for the
day you can see we get lots and lots of
day you can see we get lots and lots of
warnings from
warnings from
stuff with
compilation some of these are fixable
compilation some of these are fixable
and just like numpy API things I usually
and just like numpy API things I usually
do try to get this the build to be
do try to get this the build to be
pretty clear
pretty clear
for the final
version okay how is this working does
version okay how is this working does
the demo
work okay so this actually does
work okay so this actually does
work oh let's do
um import
um import
make n
crater and then we'll just
crater and then we'll just
do en Creator
do en Creator
mooba I think we can just do this
function
reset this is make en then n is going to
reset this is make en then n is going to
be making okay that should work it's
be making okay that should work it's
just some weird binding
errors it works in the demo
what this make make mobo
right and then it returns you the
environment huh
hold on there's no way that this should
hold on there's no way that this should
be running in the demo and not running
here end
module import
module import
ocean ocean
ocean ocean
dot we'll have to figure out what's
dot we'll have to figure out what's
what's weird with the pathing later
but there's there's just no way like
but there's there's just no way like
this
is puffer lib environment Ocean mooba
is puffer lib environment Ocean mooba
Sea mooba import
Sea mooba import
environment why how the heck does it
environment why how the heck does it
work here
like this runs and I can see it
render there a circular import or
render there a circular import or
something
oh there's no underscore a nit that's
weird how's there no underscore in
net that's very weird
ocean
environment from
MOBA offer lib environments ocean MOA SE
MOBA offer lib environments ocean MOA SE
[Music]
mooba this is literally Bound in setup
mooba this is literally Bound in setup
isn't
isn't
it I like I'm suspecting there's just
it I like I'm suspecting there's just
some weird [ __ ] with setup tools that's
happened environment ocean mob mobile
I'm trying to figure out why it why it
I'm trying to figure out why it why it
still works in um oh I don't have chat
still works in um oh I don't have chat
working at all do
working at all do
I something weird
happened I don't have chat working and I
happened I don't have chat working and I
haven't had the stream window up okay
haven't had the stream window up okay
that's really stupid here we
that's really stupid here we
go yay there are lots of people chatting
go yay there are lots of people chatting
and saying that there's no
and saying that there's no
code it took me 15 minutes to realize
code it took me 15 minutes to realize
that no wonder okay uh are you meaning
that no wonder okay uh are you meaning
to be sharing your screen yep it would
to be sharing your screen yep it would
be really nice if people could tell me
be really nice if people could tell me
that but the thing is the chat is also
that but the thing is the chat is also
on the
on the
screen
screen
um this is why you don't stream people
um this is why you don't stream people
it gives you brain damage and then it
it gives you brain damage and then it
makes it impossible to uh to stream
makes it impossible to uh to stream
because you're literally too dumb to
because you're literally too dumb to
stream that's how it works okay well
stream that's how it works okay well
sorry about that welcome folks um didn't
sorry about that welcome folks um didn't
miss very much I will show off some cool
miss very much I will show off some cool
stuff now
stuff now
so I'm having some stupid build error
so I'm having some stupid build error
that I'm going to have to figure out how
that I'm going to have to figure out how
to fix let me show off the cool things
to fix let me show off the cool things
now
now
so this is a HTML file that is built by
so this is a HTML file that is built by
scon uh with the annotate option and
scon uh with the annotate option and
anywhere you see yellow your code is not
anywhere you see yellow your code is not
running in pure C so what we're going to
running in pure C so what we're going to
do
do
today is uh I'm going to first get the
today is uh I'm going to first get the
code built right now I'm going to get it
code built right now I'm going to get it
built up with or without some sanity
built up with or without some sanity
options we're going to see what FPS
options we're going to see what FPS
we're getting right now and then we're
we're getting right now and then we're
going to get a million FPS via
going to get a million FPS via
optimization that's what the plan
optimization that's what the plan
is this is why I shouldn't take meetings
is this is why I shouldn't take meetings
because I forget to switch the camera
because I forget to switch the camera
back that's another MO that's another
back that's another MO that's another
uh takeaway don't have meetings just
uh takeaway don't have meetings just
write code all day it's way
better
better
okay I will tweet that the stream is
fixed oops
there we go
there we go
cool
cool
okay hey
okay hey
Roman hey hey Relic
welcome hey
welcome hey
Felix huge fan of RL as well as LOL why
Felix huge fan of RL as well as LOL why
do you think moas are interesting
do you think moas are interesting
research topic for RL have you seen open
research topic for RL have you seen open
ai5 it's probably the best RL result out
ai5 it's probably the best RL result out
there I mean mobas are just tremendously
there I mean mobas are just tremendously
complicated games um but the idea for
complicated games um but the idea for
this project was like Hey open AI did
this project was like Hey open AI did
this but they used
this but they used
128,000
128,000
CPUs
and I don't know if this is even
and I don't know if this is even
accurate this is 20 56 p100s I think it
accurate this is 20 56 p100s I think it
was up to 1,000 gpus at some
point 900 years of training data per day
point 900 years of training data per day
is what they trained on actually you
is what they trained on actually you
know what let's do a fun back of the
know what let's do a fun back of the
envelope calculation
envelope calculation
okay so 900 years per
okay so 900 years per
day uh so in 24 hours divide so this is
day uh so in 24 hours divide so this is
900 years times 365 days 364 days
900 years times 365 days 364 days
whatever it is times 364 I don't I don't
whatever it is times 364 I don't I don't
even
even
remember how many days are there in a
remember how many days are there in a
year uh
year uh
times uh uh 24 hours in a day times 3600
times uh uh 24 hours in a day times 3600
seconds in an hour okay this is the
seconds in an hour okay this is the
total
number 28
number 28
billion steps of data it looks like
billion steps of data it looks like
right uh seconds this is 28 billion
right uh seconds this is 28 billion
seconds of
seconds of
data okay and I'm going to say times
data okay and I'm going to say times
five if we're going to
five if we're going to
sample they actually give it to you
sample they actually give it to you
right here observations per second so
right here observations per second so
times
7.5 okay that's crazy
7.5 okay that's crazy
200 billion steps worth of data it's a
200 billion steps worth of data it's a
lot
right but that's
right but that's
actually how close can we get to
this that's a
this that's a
lot I don't know if I can quite match
lot I don't know if I can quite match
that I can get like in the ballpark
that I can get like in the ballpark
though so 212 billion steps worth of
though so 212 billion steps worth of
data first of
all they did this for
all they did this for
and this is per
and this is per
day so how much can we do in a day if we
day so how much can we do in a day if we
were able to get the best case scenarios
were able to get the best case scenarios
we get 1 million training steps per
we get 1 million training steps per
second that's the best case scenario so
second that's the best case scenario so
million which is
million which is
186 time 24 hours per
186 time 24 hours per
day
day
times uh 3600 seconds
is going to
be oh that's not
be oh that's not
bad we get 86 uh 86 billion per
bad we get 86 uh 86 billion per
day so we're actually only like a factor
day so we're actually only like a factor
a little more than a factor of two off
a little more than a factor of two off
and the other fun thing is wait does
and the other fun thing is wait does
this include the factor of
this include the factor of
oh and then there's another Factor where
oh and then there's another Factor where
we're going to down sample the
we're going to down sample the
observations per second so we're going
observations per second so we're going
to do
to do
times uh
times uh
1.5 I
think yeah so we're going to get times
think yeah so we're going to get times
1.5 because we're going to down sample
1.5 because we're going to down sample
the data a little bit so yeah we're only
the data a little bit so yeah we're only
a factor of two off so that's actually
a factor of two off so that's actually
cool if I managed to make this as high
cool if I managed to make this as high
perf as my other stuff this could
perf as my other stuff this could
literally be
literally be
up there with open ai5 in terms of the
up there with open ai5 in terms of the
amount of data this thing is going to
amount of data this thing is going to
chug but with one GPU instead of at
chug but with one GPU instead of at
least
least
256 and with two CPU cores instead of
256 and with two CPU cores instead of
128,000 that'd be really freaking
128,000 that'd be really freaking
sweet that'd be really
sweet okay I do have to fix this little
sweet okay I do have to fix this little
boring bug for a
boring bug for a
moment uh and then we're going to get to
moment uh and then we're going to get to
perf
test oh I guess it's fixed cool it was
test oh I guess it's fixed cool it was
literally just a stupid setup tools
literally just a stupid setup tools
annoying
thing that's perfect
thing that's perfect
timing so we get print
what are we going to do about the resets
what are we going to do about the resets
on this right now
right currently there's no way to reset
right currently there's no way to reset
the
the
environment I think we're just going to
environment I think we're just going to
ignore it for now for our initial perf
ignore it for now for our initial perf
test and then we'll we'll do fast resets
test and then we'll we'll do fast resets
later cuz that's
important okay MOA
perf there we go so it's going to run
perf there we go so it's going to run
this now for 10 seconds we're going to
this now for 10 seconds we're going to
get a rough steps per
get a rough steps per
second it's a Baseline
we're only at 880,000 steps per second
we're only at 880,000 steps per second
at the moment which is nowhere near fast
at the moment which is nowhere near fast
enough I want the environment itself to
enough I want the environment itself to
run
run
at like a
at like a
million so let's see what has happened
million so let's see what has happened
here with that um
one thing that we can do uh is we can
one thing that we can do uh is we can
enable uh profiling actually I forgot
enable uh profiling actually I forgot
there's that
option thanks for the explanation what
option thanks for the explanation what
do you get out of this
do you get out of this
research in and accept for only gaming
research in and accept for only gaming
can you transfer to other games are just
can you transfer to other games are just
a really good test bed for
a really good test bed for
things in general like what we care
things in general like what we care
about is we care that this is a complex
about is we care that this is a complex
and cognitively interesting problem and
and cognitively interesting problem and
that it's really efficient to simulate
that it's really efficient to simulate
um reinforcement learning requires a lot
um reinforcement learning requires a lot
of
of
experimentation and a lot of the things
experimentation and a lot of the things
that have been hindering RL from
that have been hindering RL from
applying to other domains is that we
applying to other domains is that we
just haven't had like hard enough
just haven't had like hard enough
problems to run it on that are also very
problems to run it on that are also very
fast so one of the things I'm doing with
fast so one of the things I'm doing with
puffer right is making it easy to run RL
puffer right is making it easy to run RL
on hard problems but another thing I'm
on hard problems but another thing I'm
doing with puffers which is what you're
doing with puffers which is what you're
seeing here is I'm making a specific set
seeing here is I'm making a specific set
of very hard problems that are
of very hard problems that are
incredibly fast so that you can iterate
incredibly fast so that you can iterate
on Research that much faster I mean just
on Research that much faster I mean just
it's a whole different game when you
it's a whole different game when you
have to be open Ai and you have to have
have to be open Ai and you have to have
a 20 person engineering team to do open
a 20 person engineering team to do open
AI five to get like you know a MOA level
AI five to get like you know a MOA level
intelligence versus if like a guy can
intelligence versus if like a guy can
just make make a admittedly very
just make make a admittedly very
stripped down but still like a basic MOA
stripped down but still like a basic MOA
and get like half of the per of their
and get like half of the per of their
entire cluster for that on a small model
entire cluster for that on a small model
with one GPU that unlocks a whole new
with one GPU that unlocks a whole new
set of progress a whole new set of stuff
set of progress a whole new set of stuff
that you can do with RL so that's what
that you can do with RL so that's what
we're doing
here like mooba MMO especially or games
here like mooba MMO especially or games
at
at
all um we use all sorts of games yeah we
all um we use all sorts of games yeah we
use all sorts of games uh mobas are
use all sorts of games uh mobas are
really complicated right they're like
really complicated right they're like
tremendous I mean you played league
tremendous I mean you played league
right it's tremendously complicated game
right it's tremendously complicated game
if you try to introduce a MOBA to
if you try to introduce a MOBA to
somebody who's never played one before
somebody who's never played one before
they're like they're going to be baffled
they're like they're going to be baffled
that people play these things as Hobbies
that people play these things as Hobbies
like this is way more complicated than
like this is way more complicated than
virtually any other type of like game
virtually any other type of like game
hobby thing that you can think of right
hobby thing that you can think of right
just like the amount of time it takes to
just like the amount of time it takes to
even learn the ropes on one of these
even learn the ropes on one of these
games people forget when they've been
games people forget when they've been
playing them for 10 years but you need
playing them for 10 years but you need
to spend like multiple hundred hours to
to spend like multiple hundred hours to
have any idea what the hell you're doing
have any idea what the hell you're doing
in one of these and MMOs are a little
in one of these and MMOs are a little
bit of a different access right there's
bit of a different access right there's
not much there's not as much like
not much there's not as much like
complexity coming from different
complexity coming from different
combinations of opponents and stuff but
combinations of opponents and stuff but
MMOs are cool because they're persistent
MMOs are cool because they're persistent
so like you can run the same environment
so like you can run the same environment
for a really long time and it can change
for a really long time and it can change
over time um and they also have a lot
over time um and they also have a lot
more players in them so it's more like
more players in them so it's more like
the real world in that sense so there
the real world in that sense so there
are two genres that I think are both
are two genres that I think are both
very useful for research uh there's
very useful for research uh there's
other stuff you can do as well they're
other stuff you can do as well they're
just two that come to
mind Platinum for hard
mind Platinum for hard
stuck man I I played league for a very
stuck man I I played league for a very
short amount of time and I got I was
short amount of time and I got I was
stuck in bronze all right
stuck in bronze all right
so I'm
so I'm
bad only thing I've ever been good at is
bad only thing I've ever been good at is
MMOs I've been you know like that top 1%
MMOs I've been you know like that top 1%
or
whatever games like Civ
whatever games like Civ
6 so problem with stuff like civ6 right
6 so problem with stuff like civ6 right
um You can do it there are a lot more
um You can do it there are a lot more
infrastructure and Engineering
infrastructure and Engineering
challenges associated with something
challenges associated with something
like that just from a game design
like that just from a game design
perspective and also it's very it's like
perspective and also it's very it's like
a very real world context dependent game
a very real world context dependent game
so if you have an agent that's learning
so if you have an agent that's learning
to play that game from scratch without
to play that game from scratch without
the context of
the context of
like without context from The Real World
like without context from The Real World
it's a much harder thing to do from
it's a much harder thing to do from
scratch like I could boot up uh League I
scratch like I could boot up uh League I
could boot up DOTA I could be boot up
could boot up DOTA I could be boot up
like RuneScape in Japanese which I don't
like RuneScape in Japanese which I don't
read right and I could figure stuff out
read right and I could figure stuff out
a little bit uh if I booted up Civ in
a little bit uh if I booted up Civ in
like Japanese I'd have no idea what the
like Japanese I'd have no idea what the
hell I was
hell I was
doing so that's like a good litmus test
doing so that's like a good litmus test
right like if you were to just boot up
right like if you were to just boot up
the game in Japanese like would you have
the game in Japanese like would you have
any idea what you were doing if not then
any idea what you were doing if not then
it's probably not great for RL
okay
python but isn't the real world context
python but isn't the real world context
the interesting area not
the interesting area not
really um that's like prior knowledge
really um that's like prior knowledge
right it's interesting in a different
right it's interesting in a different
way the real world context is what you
way the real world context is what you
would get from language models for
would get from language models for
instance but the decision making and the
instance but the decision making and the
reason behind it you don't get that's
reason behind it you don't get that's
like that that's what you can do with
like that that's what you can do with
RL and as a matter of as a practical
RL and as a matter of as a practical
matter like doing this RL stuff is
matter like doing this RL stuff is
really hard but it doesn't require that
really hard but it doesn't require that
I have a billion dollar cluster right it
I have a billion dollar cluster right it
requires that I have a $30,000
requires that I have a $30,000
cluster which is much which is still a
cluster which is much which is still a
lot but much more
lot but much more
reasonable um so yeah RL is this kind of
reasonable um so yeah RL is this kind of
this area where like there's this whole
this area where like there's this whole
other side of learning that is not being
other side of learning that is not being
actively explored and you can actually
actively explored and you can actually
do it with pretty modest
do it with pretty modest
resources but to get decisions I can
resources but to get decisions I can
apply in the real world RL is used in
apply in the real world RL is used in
the real world there are a bunch of
the real world there are a bunch of
applications of reinforcement learning
applications of reinforcement learning
where language models make absolutely no
where language models make absolutely no
sense where reinforcement learning just
sense where reinforcement learning just
works it's used in traffic control it's
works it's used in traffic control it's
used in uh like routing uh Uber drivers
used in uh like routing uh Uber drivers
or lift drivers I believe it is uh it's
or lift drivers I believe it is uh it's
used in like data center power
used in like data center power
optimization lots of things where where
optimization lots of things where where
there's like a hard decision making
there's like a hard decision making
problem that doesn't cleanly map onto
problem that doesn't cleanly map onto
Vision or text there are lots of
Vision or text there are lots of
them and mind you there are applications
them and mind you there are applications
of RL and RL has had like a tiny tiny
of RL and RL has had like a tiny tiny
drop of the amount of investment and
drop of the amount of investment and
interest that language models have had
interest that language models have had
um so there's a huge amount of Promise
um so there's a huge amount of Promise
coupled with like we can actually do
coupled with like we can actually do
stuff with this right we don't need
stuff with this right we don't need
giant clusters to do this we can just do
giant clusters to do this we can just do
it
let's rerun this thing
let's rerun this thing
um there
MOA I think I need to get the cile code
MOA I think I need to get the cile code
don't
I yeah this thing
so we do this is going to be a test
so we do this is going to be a test
performance
right
right
MOBA actions okay I think this works
test performance 10 stats.
profile I just want to get a sense of
profile I just want to get a sense of
like where all the time is going in
like where all the time is going in
these
functions hi Joseph how are you seeing
functions hi Joseph how are you seeing
you after a year or so can we get some
you after a year or so can we get some
tutorials on making your end faster like
tutorials on making your end faster like
this Mobo
this Mobo
does puffer provide built-in features to
does puffer provide built-in features to
make training fast without Jacks yes so
make training fast without Jacks yes so
this is a relatively new area the hper
this is a relatively new area the hper
engineering Sim engineering stuff is the
engineering Sim engineering stuff is the
way that I've come up with of doing this
way that I've come up with of doing this
is something new in the last few months
is something new in the last few months
I have this project one other project
I have this project one other project
that isn't uh announced yet that I'm
that isn't uh announced yet that I'm
finishing up and then like the snake
finishing up and then like the snake
project the grid project and a few other
project the grid project and a few other
smaller ones there will be a very nice
smaller ones there will be a very nice
summary blog post on this when I'm done
summary blog post on this when I'm done
and some good uh probably a good video
and some good uh probably a good video
as well so there's going to be content
as well so there's going to be content
on that um but it's a lot of work I mean
on that um but it's a lot of work I mean
this is a huge amount of work to finish
this is a huge amount of work to finish
up and I want to make sure that I can
up and I want to make sure that I can
really give you a good summary of how to
really give you a good summary of how to
do all of this before I uh I post
do all of this before I uh I post
something like that though that said if
something like that though that said if
you want to get started on stuff now
you want to get started on stuff now
like 90% of what you will need is in the
like 90% of what you will need is in the
snake environment and the snake
snake environment and the snake
environment is like a 450 line of code
environment is like a 450 line of code
standal Lo demo it's dead simple code
standal Lo demo it's dead simple code
and it runs at 14 million steps per
and it runs at 14 million steps per
second single thread it trains at over a
second single thread it trains at over a
million steps per second so that's the
million steps per second so that's the
thing to do at the
moment so we
have very weird distribution of timings
have very weird distribution of timings
here
so we've got 10 seconds worth of
so we've got 10 seconds worth of
calls but most of them
calls but most of them
are I the top time is nowhere near
10 fill observations is about
10% records get attribute
10% records get attribute
is
7% where the heck is the rest of the
7% where the heck is the rest of the
time going
if it's only
if it's only
3.8 in m.p
3.8 in m.p
Step cumulative time is 9.8 okay so MOBA
Step cumulative time is 9.8 okay so MOBA
step is actually most of the
step is actually most of the
time fill
observations okay I see so the fill
observations okay I see so the fill
observations is a cumulative of 40% of
observations is a cumulative of 40% of
that
time get attribute is another
time get attribute is another
second we've got
view okay so there are a lot of methods
view okay so there are a lot of methods
here that are like weird
here that are like weird
um yeah there are a lot of weird methods
um yeah there are a lot of weird methods
here that are being slow and uh we have
here that are being slow and uh we have
to figure out what the heck is going on
to figure out what the heck is going on
with this fine so
with this fine so
let's just start on this I'm gonna
let's just start on this I'm gonna
actually just do
this
oops
oops
okay oh I forgot to answer the other
okay oh I forgot to answer the other
part of your question uh does puffer lib
part of your question uh does puffer lib
have buil-in features to make training
have buil-in features to make training
fast uh puffer has builtin
fast uh puffer has builtin
the vectorization in puffer means that
the vectorization in puffer means that
if your environment is fast you're not
if your environment is fast you're not
going to get capped by vectorization so
going to get capped by vectorization so
like with other stuff even if your
like with other stuff even if your
environment is fast other things on the
environment is fast other things on the
stack are going to make it slow with
stack are going to make it slow with
puffer if your environment is fast then
puffer if your environment is fast then
it's just fast so that's the that's the
it's just fast so that's the that's the
thing that puffer provides for you like
thing that puffer provides for you like
a lot of the work on puffer was to make
a lot of the work on puffer was to make
it so that fast Ms are useful in the
it so that fast Ms are useful in the
first place you still have to make them
first place you still have to make them
fast that's what the stuff I'm working
fast that's what the stuff I'm working
on now is like simp ways of making
on now is like simp ways of making
really fast
Sims two people on Twitch that's cool to
Sims two people on Twitch that's cool to
see twitch usually has tough time for uh
see twitch usually has tough time for uh
promoting like new streams that's
promoting like new streams that's
awesome welcome
folks oops where are
we CD puffer lib environments ocean
okay so what is
this if we look in a
step thank you very much for pointing
step thank you very much for pointing
out the demo snake M can I please get
out the demo snake M can I please get
the repo link awaiting the blog poster
the repo link awaiting the blog poster
Series yeah I a lot of this stuff is
Series yeah I a lot of this stuff is
based on engagement frankly because like
based on engagement frankly because like
I will just I will make whatever format
I will just I will make whatever format
of content people will actually look at
of content people will actually look at
right so like I'm going to do a test
right so like I'm going to do a test
video and like cuz people really liked
video and like cuz people really liked
my thesis defense so I'm going to do a
my thesis defense so I'm going to do a
test video on puffer 10 if people like
test video on puffer 10 if people like
that I will make more if people don't
that I will make more if people don't
like go and watch that then I will spend
like go and watch that then I will spend
my time on other forms of content
right um let me get you the the link
right um let me get you the the link
it's just puffer
oops so look if you just go into Puffer
oops so look if you just go into Puffer
here it's there's the snake m is in the
here it's there's the snake m is in the
dev Branch I
dev Branch I
believe so look Dev Branch puffer
believe so look Dev Branch puffer
lib
lib
environments ocean is first party so
environments ocean is first party so
ocean has our first party environments
ocean has our first party environments
and you've got all these environments to
and you've got all these environments to
play with there's also an in config
play with there's also an in config
branch which I'm merging into this soon
branch which I'm merging into this soon
which has the mooba and a bunch of
which has the mooba and a bunch of
refactor stuff um that's really nice but
refactor stuff um that's really nice but
it's a little less stable so
it's a little less stable so
far can I put this into the chat
people must watch it
people must watch it
then yeah I hope so I mean the thesis
then yeah I hope so I mean the thesis
the thesis defense was awesome like if I
the thesis defense was awesome like if I
can get more if people are actually
can get more if people are actually
going to have this level of Engagement
going to have this level of Engagement
with the longer form stuff that I make
with the longer form stuff that I make
because this is like making something
because this is like making something
like this is very high effort right like
like this is very high effort right like
this thesis defense in addition to it
this thesis defense in addition to it
being obviously like something I've been
being obviously like something I've been
working on for years just preparing the
working on for years just preparing the
talk took a few weeks of work right
talk took a few weeks of work right
that's a lot of time investment it's
that's a lot of time investment it's
done amazing as a result but like if I'm
done amazing as a result but like if I'm
going to put like a week of work into a
going to put like a week of work into a
video and have it get like a thousand
video and have it get like a thousand
views then like I'd rather be deving
views then like I'd rather be deving
useful tools for people in that time
useful tools for people in that time
right so that's just the main thing but
right so that's just the main thing but
yeah this has been awesome this thing
yeah this has been awesome this thing
hit 120k which is that's
hit 120k which is that's
great starring the puffer repo helps a
great starring the puffer repo helps a
lot helps out a bunch promoting the
lot helps out a bunch promoting the
stuff on Twitter helps out a bunch but
stuff on Twitter helps out a bunch but
yeah that's generally where I'm
at uh oh stream's not frozen is
it I think just my preview is
it I think just my preview is
frozen I think we're
frozen I think we're
okay says zero drop frames
what is this fill
observations
observations
oh yeah okay so it looks like we have a
oh yeah okay so it looks like we have a
bunch of slow stuff in Python
land yeah like all this python stuff is
land yeah like all this python stuff is
really slow that's that's
really slow that's that's
funny
so I think for this for this mooba we're
so I think for this for this mooba we're
just going to do
just going to do
everything we're going to just do
everything we're going to just do
everything in Sealand
right so I think we're just going to do
right so I think we're just going to do
we're going to just straight up comment
we're going to just straight up comment
this
thanks for pointing out where the m is
thanks for pointing out where the m is
do my best in promoting many people I
do my best in promoting many people I
know that use Jack because there's no
know that use Jack because there's no
other way basically we were fed up with
other way basically we were fed up with
the they're fed up with yeah that's the
the they're fed up with yeah that's the
thing and I made this I don't know did
thing and I made this I don't know did
you see the post that I made on Jack I
you see the post that I made on Jack I
made a really obnoxious rambly post that
made a really obnoxious rambly post that
uh that blew
up I made this like where is
up I made this like where is
it I don't know I do a bunch of things
it I don't know I do a bunch of things
on here but here there's this really
on here but here there's this really
obnoxious
obnoxious
article where is it it's on my timeline
article where is it it's on my timeline
or on my articles so this thing got 145k
or on my articles so this thing got 145k
views right this is like one of my
views right this is like one of my
better performing posts and it's got
better performing posts and it's got
this total bait title and I talk about
this total bait title and I talk about
how like people are like oh yeah now we
how like people are like oh yeah now we
need Jacks and rust and stuff in order
need Jacks and rust and stuff in order
to make fast M and we very obviously
to make fast M and we very obviously
don't you know I can just write 200
don't you know I can just write 200
lines of scyon and it's faster than
lines of scyon and it's faster than
anything that anybody's writing with
anything that anybody's writing with
much fancier and harder to use Stacks um
much fancier and harder to use Stacks um
and it's also not limiting you to a
and it's also not limiting you to a
domain specific language like
domain specific language like
Jax
Jax
so yeah it's not even the case that this
so yeah it's not even the case that this
stuff is incredibly difficult
stuff is incredibly difficult
necessarily it's just nobody's bothered
necessarily it's just nobody's bothered
to actually take a a hard look at the
to actually take a a hard look at the
infra inrl and really put the time in
infra inrl and really put the time in
there are really no incentives in
there are really no incentives in
Academia to do the type of work I'm
Academia to do the type of work I'm
doing now
doing now
like I had a lot of freedom in my PhD
like I had a lot of freedom in my PhD
and I still probably wouldn't have been
and I still probably wouldn't have been
able to justify doing the type of work
able to justify doing the type of work
I'm doing now in my PhD so the incentive
I'm doing now in my PhD so the incentive
structures are just terrible and
structures are just terrible and
basically what's happened in the last
basically what's happened in the last
couple months with puffer is as soon as
couple months with puffer is as soon as
I actually started taking this stuff
I actually started taking this stuff
seriously and spending all of my time on
seriously and spending all of my time on
it like it's just rocketed to the moon
it like it's just rocketed to the moon
and puffer's gotten 600 some OD stars
and puffer's gotten 600 some OD stars
and like people are using it and people
and like people are using it and people
are having a good time with it and like
are having a good time with it and like
you know people are watching the streams
you know people are watching the streams
and it's just going to get better from
and it's just going to get better from
here and it's going to get better very
here and it's going to get better very
very fast what game are you doing now
very fast what game are you doing now
we're doing uh this thing I'll show
we're doing uh this thing I'll show
you where's it and then I should do a
you where's it and then I should do a
little bit of optimization
little bit of optimization
so we've got a I'm not going to say full
so we've got a I'm not going to say full
scale but a pretty you know complicated
scale but a pretty you know complicated
mooba simulator like League of Legends
mooba simulator like League of Legends
or DOTA and we're making this thing run
or DOTA and we're making this thing run
at a million frames per second that is
at a million frames per second that is
the goal for today right now it runs at
the goal for today right now it runs at
880,000 steps per second uh by the end
880,000 steps per second uh by the end
of today we're going to get it to be a
of today we're going to get it to be a
million steps per second with maybe a
million steps per second with maybe a
few small cheats and um then after that
few small cheats and um then after that
we're going to start binding it to the
we're going to start binding it to the
reinforcement learning side and start
reinforcement learning side and start
training it at a million steps per
training it at a million steps per
second that's the goal
okay so just from deleting this Phill
okay so just from deleting this Phill
observations which will be fast in in
C let's see how much better this is can
C let's see how much better this is can
people run this at home absolutely all
people run this at home absolutely all
of my stuff is open
source it's in a Dev Branch right
source it's in a Dev Branch right
now uh it's in like a a off branch of
now uh it's in like a a off branch of
Dev at the moment it's going to get
Dev at the moment it's going to get
merged to Dev soon but all of my current
merged to Dev soon but all of my current
work is in this any config Branch it'll
work is in this any config Branch it'll
get merge to Dev soon if you use it
get merge to Dev soon if you use it
please start the reap on your way in it
please start the reap on your way in it
helps me out a ton uh all of the
helps me out a ton uh all of the
simulators I've been doing a bunch of
simulators I've been doing a bunch of
different simulators on stream lately
different simulators on stream lately
and they're all inside of ocean which is
and they're all inside of ocean which is
puffer's first party environments uh so
puffer's first party environments uh so
you have MOBA grid snake all sorts of
you have MOBA grid snake all sorts of
different environments there'll be some
different environments there'll be some
more docks here soon and uh you can use
more docks here soon and uh you can use
them you can play with them you can ask
them you can play with them you can ask
about them over here
about them over here
and they're all free and open source
thank you helps me out a
ton I mean I've said this several times
ton I mean I've said this several times
on stream right my goal like puffer is
on stream right my goal like puffer is
technically a company but really my goal
technically a company but really my goal
with it is just like if this thing gets
with it is just like if this thing gets
large enough that companies start using
large enough that companies start using
it and I can get a little bit of revenue
it and I can get a little bit of revenue
from companies using puffer like support
from companies using puffer like support
contracts or whatever then my hope is I
contracts or whatever then my hope is I
can like buy a bigger cluster and
can like buy a bigger cluster and
support more open source stuff around
support more open source stuff around
puffer with it and put together some
puffer with it and put together some
like some bug bounties and stuff on that
like some bug bounties and stuff on that
that's like the short-term goal with
that's like the short-term goal with
puffer and that's why I've been
puffer and that's why I've been
promoting like the Twitter and the repo
promoting like the Twitter and the repo
so much is because that helps a lot with
so much is because that helps a lot with
other companies seeing
other companies seeing
it this needs to have a place in good
it this needs to have a place in good
conference so RL INF for track yeah
conference so RL INF for track yeah
here's the thing uh it got rejected from
here's the thing uh it got rejected from
nurs last year it got rejected from RLC
nurs last year it got rejected from RLC
this year both with [ __ ] reason
this year both with [ __ ] reason
uh this is my absolute best work I've
uh this is my absolute best work I've
gotten way worse papers in nobody cares
gotten way worse papers in nobody cares
about RL
about RL
infra and this is why it's all broken
infra and this is why it's all broken
the incentives are terrible you can do
the incentives are terrible you can do
like you can do your absolute best work
like you can do your absolute best work
as somebody who spent seven years and
as somebody who spent seven years and
you can just get multiple rejects on
you can just get multiple rejects on
conferences like there's literally no
conferences like there's literally no
incentive to do any of
incentive to do any of
this that's that's the reason that none
this that's that's the reason that none
of it's
of it's
happened and yeah like it would be nice
happened and yeah like it would be nice
to be a able to present this at a
to be a able to present this at a
conference and I did resubmit it to nurs
conference and I did resubmit it to nurs
this year but if it doesn't get in there
this year but if it doesn't get in there
I'm just not submitting more papers I'm
I'm just not submitting more papers I'm
done I'm out of the academic game I'm
done I'm out of the academic game I'm
actually building stuff right like I'm
actually building stuff right like I'm
not wasting my time on that anymore and
not wasting my time on that anymore and
there's no way around it I tried I spent
there's no way around it I tried I spent
seven years trying to fix RL uh from the
seven years trying to fix RL uh from the
inside of Academia okay like look I I'll
inside of Academia okay like look I I'll
show you something that I
show you something that I
did data sets and benchmarks track okay
did data sets and benchmarks track okay
this
this
year uh there's a very important
year uh there's a very important
language change to
this open source libraries and tools
this open source libraries and tools
that enable or accelerate ml research
that enable or accelerate ml research
and it's actually stated a second
time open source libraries and tools
time open source libraries and tools
that enable or accelerate ml so this
that enable or accelerate ml so this
exact language
exact language
I wrote an open letter on this I had to
I wrote an open letter on this I had to
promote the open letter a whole bunch I
promote the open letter a whole bunch I
circulated this I got this to last
circulated this I got this to last
year's DNB chairs I went through a big
year's DNB chairs I went through a big
chain of emails with the new DNB chairs
chain of emails with the new DNB chairs
to eventually get this integrated into
to eventually get this integrated into
this year's
this year's
call like it was a bunch of work so I
call like it was a bunch of work so I
managed to get like this one tiny
managed to get like this one tiny
thing uh for Academia but like the thing
thing uh for Academia but like the thing
is like what's the what's the return on
is like what's the what's the return on
investment for this because like the
investment for this because like the
reviewers can just completely ignore
reviewers can just completely ignore
this direction and they absolutely will
this direction and they absolutely will
right like this does not guarantee that
right like this does not guarantee that
people are not going to just reject your
people are not going to just reject your
paper because they don't like libraries
paper because they don't like libraries
and tools and they fundamentally don't
and tools and they fundamentally don't
respect your work like they're going to
respect your work like they're going to
do that anyways it helps but it's still
do that anyways it helps but it's still
[ __ ] so like I've wasted enough of
[ __ ] so like I've wasted enough of
my time on the [ __ ] academic game
my time on the [ __ ] academic game
and now like I'm building stuff for
and now like I'm building stuff for
Academia but I'm no longer doing it
Academia but I'm no longer doing it
through
through
conferences publication and the like I'm
conferences publication and the like I'm
just building tons of cool stuff really
just building tons of cool stuff really
really high performance really heavy
really high performance really heavy
engineering focus and I'm making it all
engineering focus and I'm making it all
available for free and like all I ask is
available for free and like all I ask is
that people like if you like my stuff is
that people like if you like my stuff is
that you help me promote it a little bit
that you help me promote it a little bit
so that I can like continue to build
so that I can like continue to build
this out and hopefully you know
this out and hopefully you know
hopefully make this a thing where yeah I
hopefully make this a thing where yeah I
would like to have an income of over
would like to have an income of over
zero dollars that would be nice but also
zero dollars that would be nice but also
like I would like to be able to fund a
like I would like to be able to fund a
little RL lab for people who actually
little RL lab for people who actually
care about this stuff and have like some
care about this stuff and have like some
open source bounties and stuff like that
open source bounties and stuff like that
and a bigger cluster like that's the
and a bigger cluster like that's the
type of thing that I'm trying to build
here okay so we just went up to 109,000
here okay so we just went up to 109,000
steps per second with profiling on with
steps per second with profiling on with
that garbage function deleted
we're going to have to add it back in C
we're going to have to add it back in C
but it's not going to add any overhead
but it's not going to add any overhead
in C or any noticeable
overhead
um do I need to sort this by cumulative
time this is really weird how long the
time this is really weird how long the
tail is on this because I have 9 seconds
tail is on this because I have 9 seconds
here
here
or is it total time I have 6.6 seconds
or is it total time I have 6.6 seconds
and then the next thing is 0.4
and then the next thing is 0.4
seconds so like I'm not this is not
seconds so like I'm not this is not
being timed properly if that's the case
um when did you start on puffer lib and
um when did you start on puffer lib and
what made you I started as a side
what made you I started as a side
project like a year and a half ago uh I
project like a year and a half ago uh I
was doing my PhD then so I didn't like
was doing my PhD then so I didn't like
you know I had a PhD to do so I just
you know I had a PhD to do so I just
kind of like started doing some tools
kind of like started doing some tools
and stuff on the side and and uh it sort
and stuff on the side and and uh it sort
of became obvious like last summer I
of became obvious like last summer I
didn't take MIT funding so that I could
didn't take MIT funding so that I could
work on puffer full-time and it became
work on puffer full-time and it became
obvious like RL fundamentally just was
obvious like RL fundamentally just was
not going to work without the stuff I
not going to work without the stuff I
was building for puffer so uh I didn't
was building for puffer so uh I didn't
get to spend too much time on it during
get to spend too much time on it during
the last year of my PhD properly because
the last year of my PhD properly because
I had PhD stuff but uh you know I sort
I had PhD stuff but uh you know I sort
of made the plan that okay once I
of made the plan that okay once I
graduate I'm going to do this full-time
graduate I'm going to do this full-time
I'm going to invest a year that's what
I'm going to invest a year that's what
I've said I'm going to spend a year on
I've said I'm going to spend a year on
on this I'm going to see where it goes
on this I'm going to see where it goes
and if I actually have you know if this
and if I actually have you know if this
is going somewhere after a year like
is going somewhere after a year like
clearly going somewhere after a year
clearly going somewhere after a year
then I get to keep doing
it the last two months have been great
it the last two months have been great
if we can just if we keep the growth
if we can just if we keep the growth
trend of the last two months this is set
trend of the last two months this is set
but it's hard because there's a pretty
but it's hard because there's a pretty
limited audience in RL and we're already
limited audience in RL and we're already
getting a large chunk of it what's the
getting a large chunk of it what's the
reason of naming it puffer lib it's a
reason of naming it puffer lib it's a
bunch of tools an infrastructure like
bunch of tools an infrastructure like
what the heck do you call that right
what the heck do you call that right
there's literally no there's nothing I
there's literally no there's nothing I
can call this that's a good visual
can call this that's a good visual
depiction of what this does so here have
depiction of what this does so here have
a puffer fish it's funny it's memeable
a puffer fish it's funny it's memeable
and you can feed it lots of
and you can feed it lots of
libraries understand your Fury over
libraries understand your Fury over
reviewers your effort is not going to
reviewers your effort is not going to
waste in a conference perspective
waste in a conference perspective
someone will be picking your work up a
someone will be picking your work up a
right now help the community a lot in
right now help the community a lot in
Industry it should give you an in yeah
Industry it should give you an in yeah
yeah I mean I I'm fine like I can pay
yeah I mean I I'm fine like I can pay
rent that's not an issue it's just like
rent that's not an issue it's just like
I'd like to be able to scale this stuff
I'd like to be able to scale this stuff
up um
up um
um and it's the thing with reviewers
um and it's the thing with reviewers
that made me really sad in Academia was
that made me really sad in Academia was
by the end of my PhD I figured out how
by the end of my PhD I figured out how
to consistently publish stuff even in
to consistently publish stuff even in
like this wonky area where it's really
like this wonky area where it's really
hard to publish right like I figured out
hard to publish right like I figured out
how to write papers that I could
how to write papers that I could
consistently publish but I hated them
consistently publish but I hated them
like I wrote papers that I considered
like I wrote papers that I considered
bad in order to get them
bad in order to get them
published anytime I wrote something that
published anytime I wrote something that
I was genuinely proud of and I thought
I was genuinely proud of and I thought
was a good paper a good contribution it
was a good paper a good contribution it
would get rejected
would get rejected
so I I don't want to be doing that
so I I don't want to be doing that
anymore right it's like I want to be
anymore right it's like I want to be
able to write the thing that I know is
able to write the thing that I know is
the good thing to write regardless of
the good thing to write regardless of
what the reception is going to be and
what the reception is going to be and
like outside of conferences and stuff
like outside of conferences and stuff
there's a big enough audience for this
there's a big enough audience for this
stuff that if I just do a bunch of
stuff that if I just do a bunch of
different good projects in in round RL
different good projects in in round RL
like that's going to be way way better
like that's going to be way way better
than publishing some random papers yeah
than publishing some random papers yeah
it's very sad but like the thing is
it's very sad but like the thing is
we've done this to ourselves like it's
we've done this to ourselves like it's
the RL Community doing it to ourselves
the RL Community doing it to ourselves
right like this is completely avoidable
right like this is completely avoidable
like if we in in RL because we're
like if we in in RL because we're
reviewing the papers if we just like
reviewing the papers if we just like
stopped rejecting essential things that
stopped rejecting essential things that
we need for the field to move forward on
we need for the field to move forward on
the basis of like them not matching up
the basis of like them not matching up
with science what we consider to be good
with science what we consider to be good
science
science
like there would be an incentive
like there would be an incentive
structure for pH students to do this
structure for pH students to do this
type of work and I wouldn't have to be
type of work and I wouldn't have to be
doing it outside of Academia because it
doing it outside of Academia because it
would already be done I know several
would already be done I know several
people in RL that have done like
people in RL that have done like
absolutely amazing infrastructure work
absolutely amazing infrastructure work
got absolutely zero recognition and they
got absolutely zero recognition and they
[ __ ] off and they took high-paying
[ __ ] off and they took high-paying
jobs working on language models that's
jobs working on language models that's
what they did they just they they said
what they did they just they they said
screw it I'm done with this you know
screw it I'm done with this you know
this is ridiculous there's no money in
this is ridiculous there's no money in
this there's no recognition in this I'm
this there's no recognition in this I'm
just you know deving in the dark for
just you know deving in the dark for
hours and hours on end and they went and
hours and hours on end and they went and
they took high paying jobs working on
they took high paying jobs working on
language
language
models and that's really sad because
models and that's really sad because
like you know when you're working on
like you know when you're working on
really high quality stuff like that
really high quality stuff like that
there should be a way to get your work
there should be a way to get your work
recognized but there isn't and I tried
recognized but there isn't and I tried
for many years to make a way for that to
for many years to make a way for that to
happen and there was just no way to do
happen and there was just no way to do
it from inside of Academia so the way
it from inside of Academia so the way
that I'm looking at this currently is
that I'm looking at this currently is
well if I can just make reinforcement
well if I can just make reinforcement
learning so much faster and easier to
learning so much faster and easier to
work in that you can get really awesome
work in that you can get really awesome
results way more easily right than then
results way more easily right than then
it's going to be way way way easier to
it's going to be way way way easier to
get more people doing RL that's what
get more people doing RL that's what
it's going to
be and I'm glad to be able to talk about
be and I'm glad to be able to talk about
this more publicly as well like I didn't
this more publicly as well like I didn't
have a gag order or anything during my
have a gag order or anything during my
PhD but you know I don't like to I
PhD but you know I don't like to I
didn't want to put like a bunch of
didn't want to put like a bunch of
inflammatory takes around that would
inflammatory takes around that would
reflect badly on you know MIT or my lab
reflect badly on you know MIT or my lab
or anything but now you know I'm
or anything but now you know I'm
graduated this is fully independent
graduated this is fully independent
these are my own only my own opinions
these are my own only my own opinions
not those of my lab or anything else and
not those of my lab or anything else and
yeah I'm very happy to be outspoken
yeah I'm very happy to be outspoken
about that
now what the heck is wrong with
this let's make this give us like the
this let's make this give us like the
top uh 20 five functions
top uh 20 five functions
because this is bizarre this is like a
because this is bizarre this is like a
really bizarre profiling
curve bring investor attention oh
curve bring investor attention oh
investors are not the problem if I
investors are not the problem if I
wanted to get money for this I can get
wanted to get money for this I can get
investors um the thing is it's way way
investors um the thing is it's way way
way better if I can just bootstrap this
way better if I can just bootstrap this
right revenue is is way better than
right revenue is is way better than
investment
this is very very weird this profile
this is very very weird this profile
curve here like the fact that it just
curve here like the fact that it just
goes
from okay so first of all this says that
from okay so first of all this says that
we're losing 30% of our performance
we're losing 30% of our performance
inside of the Python wrapper first step
right and then after
that clip Depp invoke with
casting
clip I don't even know where we're
clip I don't even know where we're
calling clip
let's
let's
um let's grab
this I mute the stupid sound effect on
this I mute the stupid sound effect on
Windows from
this system sounds
mute CL so
okay so what do we have here sorry I
okay so what do we have here sorry I
missed your reply to my
message uh which one the last
message uh which one the last
one I I just said that we like I'm not
one I I just said that we like I'm not
really looking I'm not even really
really looking I'm not even really
looking for investors in this if I
looking for investors in this if I
wanted to get an investment check for
wanted to get an investment check for
something around puffer I could um I've
something around puffer I could um I've
already talked to people who have been
already talked to people who have been
like you know somewhat interested um
like you know somewhat interested um
just in passing
just in passing
it's more that I want revenue for this
it's more that I want revenue for this
uh I I'd like this to be bootstrapped
uh I I'd like this to be bootstrapped
I'd like this to have no strings
I'd like this to have no strings
attached I don't want this to be tied to
attached I don't want this to be tied to
investors and uh you know shareholder
investors and uh you know shareholder
obligation I'd way prefer if I can just
obligation I'd way prefer if I can just
if I can get this thing to just
if I can get this thing to just
bootstrap itself via revenue and self
bootstrap itself via revenue and self
fund uh cool RL lab around that that's
fund uh cool RL lab around that that's
infinitely better
okay so interesting this
is is this discretized at the
is is this discretized at the
moment I thought this was discretized
moment I thought this was discretized
wasn't
wasn't
it hold
on definitely hope it
on definitely hope it
yeah and it's it's going very well at
yeah and it's it's going very well at
the
the
moment I will say like this
moment I will say like this
is this growth
Trend if we keep this up all of the
Trend if we keep this up all of the
problems outside of technical will solve
problems outside of technical will solve
themselves and I'll just be able to keep
themselves and I'll just be able to keep
working on the technical problems like
working on the technical problems like
this is this is what you need
how the heck is this thing spending so
how the heck is this thing spending so
much time in numpy clip there shouldn't
much time in numpy clip there shouldn't
even be clip shouldn't even be
even be clip shouldn't even be
called being called here and then this
called being called here and then this
is in the renderer which we're not
is in the renderer which we're not
running the renderer right yeah we're
running the renderer right yeah we're
not running the
not running the
renderer
so okay what's the report interval
so okay what's the report interval
here 32
that's probably way
too yeah that's probably way too uh too
too yeah that's probably way too uh too
quick
right Miss whoa I've missed a
right Miss whoa I've missed a
lot oh did you just check on the
lot oh did you just check on the
um on the latest environments and stuff
um on the latest environments and stuff
on
on
Twitter stuff is happening fast stuff
Twitter stuff is happening fast stuff
builds fast man
builds fast man
I'm telling you as soon as like I no
I'm telling you as soon as like I no
longer had to care about the academic
longer had to care about the academic
side of things stuff just happens so
side of things stuff just happens so
freaking quickly it's not even
funny this MOA is one week of work so
funny this MOA is one week of work so
far like I guess a week in like a week
far like I guess a week in like a week
and two days week and a half
then and I haven't even been like
then and I haven't even been like
particularly on point either I've been
particularly on point either I've been
like kind of tired kind of burnt out um
like kind of tired kind of burnt out um
been doing a whole bunch of running
been doing a whole bunch of running
that's been you know making it really
that's been you know making it really
hard to to stay focused for long work
hard to to stay focused for long work
sessions and it's still been just
cranking and we're going to get at a
cranking and we're going to get at a
million FPS today it's actually going to
million FPS today it's actually going to
be harder than I thought it was going to
be harder than I thought it was going to
be but uh we're going to get it today
be but uh we're going to get it today
that's the goal the goal for today is to
that's the goal the goal for today is to
actually make the thing in the title
actually make the thing in the title
true busy with PhD proposal only like a
true busy with PhD proposal only like a
month well in a month we've gotten best
month well in a month we've gotten best
class hyperparameter tuning working
class hyperparameter tuning working
we've made a 14 million step per second
we've made a 14 million step per second
snake environment we've made four
snake environment we've made four
different continuous control/ discreet
different continuous control/ discreet
grid environments for multi-agent
grid environments for multi-agent
Learning and we've made this MOA so a
Learning and we've made this MOA so a
lot happens in a
month I would like to know what the heck
month I would like to know what the heck
is calling clip
is calling clip
so we're up to 116,000 steps per second
so we're up to 116,000 steps per second
with profiling
with profiling
overhead um something is wonky here
overhead um something is wonky here
we're still
we're still
losing we're losing nearly 3 seconds out
losing we're losing nearly 3 seconds out
of 10 inside of the Python rapper what
of 10 inside of the Python rapper what
the heck is happening inside the python
the heck is happening inside the python
wrapper
right what the heck is happening
catch you
later welcome to the YouTube
later welcome to the YouTube
folks we're currently optimizing this
folks we're currently optimizing this
thing to a million steps per
thing to a million steps per
second
second
uh looks like there's there's a lot of
uh looks like there's there's a lot of
room for optimization I just have to
room for optimization I just have to
figure out essentially where the
figure out essentially where the
overhead is cuz the profiling tools are
overhead is cuz the profiling tools are
not not they're not doing a great job at
not not they're not doing a great job at
the
the
moment does this thing ever get reset no
moment does this thing ever get reset no
it doesn't look like it
it doesn't look like it
so that's interesting the only thing
so that's interesting the only thing
here that
is self. buff. rewards.
is self. buff. rewards.
fill
zero this could be it
zero this could be it
maybe I wonder if this this is
slow well one thing I could do
slow well one thing I could do
right let's say
um let's say I just put this cast up
um let's say I just put this cast up
here and then I just like comment out
here and then I just like comment out
all the stuff that's not strictly needed
all the stuff that's not strictly needed
right so
I just need this step
right and we'll see if this
right and we'll see if this
works and what infos is just going to be
empty does this reduce the
overhead expected float got unsigned
overhead expected float got unsigned
int uh really
int uh really
that would actually explain
that would actually explain
something though if that is the
case welcome back
do we have does this think we're
do we have does this think we're
supposed to
discretize oh for some reason we have
discretize oh for some reason we have
discretized false
here
here
so it's calling this clipping
so it's calling this clipping
function
constantly do we
constantly do we
care we might not care
we can always clip on the uh we can clip
we can always clip on the uh we can clip
and
and
see if that's really going to be if
see if that's really going to be if
that's going to be a bottleneck we can
that's going to be a bottleneck we can
clip and see so the thing that's
clip and see so the thing that's
different about this project compared to
different about this project compared to
the other ones that I have to think
the other ones that I have to think
about is this is kind of technical but a
about is this is kind of technical but a
lot of the other environments I make
lot of the other environments I make
have like a thousand plus agents in them
have like a thousand plus agents in them
so what that means is that like you're
so what that means is that like you're
making one one Loop through the python
making one one Loop through the python
for every thousand agent steps worth of
for every thousand agent steps worth of
data there only 10 agents in Dota right
data there only 10 agents in Dota right
it's a 5v5 game so what that means is
it's a 5v5 game so what that means is
that I have to be way way way more
that I have to be way way way more
careful about the python overhead and I
careful about the python overhead and I
have to put even more stuff into C than
have to put even more stuff into C than
I normally
I normally
would which isn't hard you know you can
would which isn't hard you know you can
do it it's not
do it it's not
hard but you do have to you know
hard but you do have to you know
actively uh notice and and care about
actively uh notice and and care about
this stuff
so let's see if this does any good for
so let's see if this does any good for
us we were at 116k
before H look at that from 116 straight
before H look at that from 116 straight
up to
180k very nice
180k very nice
so okay now
so okay now
now now we have uh
now now we have uh
9.5
9.5
9.7 okay at least 95% of the total time
9.7 okay at least 95% of the total time
is in in this step function
is in in this step function
here
here
[Music]
[Music]
and I can't tell if we're
and I can't tell if we're
getting I don't think we're getting
getting I don't think we're getting
scyon
scyon
functions in here we need to get the the
functions in here we need to get the the
scon function perf because all all these
scon function perf because all all these
are tiny
are tiny
right test performance there's a little
right test performance there's a little
bit of call Overhead
bit of call Overhead
yeah numpy from file
what I guess there's some weird
what I guess there's some weird
Shenanigans
happening oh this is just a startup
happening oh this is just a startup
overhead that's no big deal wait are we
overhead that's no big deal wait are we
actually timing this right then if this
actually timing this right then if this
is
the wait are we we timing this right we
the wait are we we timing this right we
might not
might not
be yeah we're not timing this perfect
be yeah we're not timing this perfect
we're actually we're losing uh we're
we're actually we're losing uh we're
losing out on some time that we
losing out on some time that we
shouldn't
shouldn't
be so what we should be doing is we put
be so what we should be doing is we put
this tick here we
this tick here we
do this goes
here action cache is going to be 1024
here action cache is going to be 1024
this is just random noise don't worry
this is just random noise don't worry
about
about
it um and
it um and
then we adjust the signature of this to
then we adjust the signature of this to
be
be
en actions
timeout and
then okay so now we have the en reset
then okay so now we have the en reset
not being tracked in this and we can do
not being tracked in this and we can do
test performance of EnV actions
10 so just by fixing our measuring
essentially that should cut out a bunch
essentially that should cut out a bunch
of garbage that we don't want to look
of garbage that we don't want to look
at yeah there you go
at yeah there you go
so now we no longer have a whole bunch
so now we no longer have a whole bunch
of trash to look at in here and uh the
of trash to look at in here and uh the
fact that there are only a few lines
fact that there are only a few lines
means that this is all that's
running all that's running that's
running all that's running that's
substantial
substantial
so we've got a small amount of call
so we've got a small amount of call
Overhead it looks like we've got uh this
Overhead it looks like we've got uh this
S type is actually this cast takes up a
S type is actually this cast takes up a
little bit of time but these are NE
little bit of time but these are NE
neither of these are significant so at
neither of these are significant so at
this point we have to actually get the
this point we have to actually get the
profiling to get into the scon code and
profiling to get into the scon code and
we need to figure out like where in the
we need to figure out like where in the
ithon code stuff is being uh where stuff
ithon code stuff is being uh where stuff
is being Jank essentially
so C
so C
profile there's there's something you
profile there's there's something you
have to do to get these
have to do to get these
things to
things to
work profile is
true slight
true slight
overhead yeah
Coba
Coba
oops ah we have a profile override to
oops ah we have a profile override to
True here this should be
true now there is going to be call
true now there is going to be call
Overhead with this oh I didn't get the
Overhead with this oh I didn't get the
the time on this did
I okay still
I okay still
180k um
180k um
so we're already more than double what
so we're already more than double what
we
started and we don't have to get 1
started and we don't have to get 1
million FPS on this machine either uh
million FPS on this machine either uh
this machine is like half the speed of
this machine is like half the speed of
the actual server so we only need to get
the actual server so we only need to get
like another factor of of maybe two or
like another factor of of maybe two or
three out of this and we'll be good okay
three out of this and we'll be good okay
perfect so now that this is compiled uh
perfect so now that this is compiled uh
we can see the one problem with doing it
we can see the one problem with doing it
this way is you can see that the SPs is
this way is you can see that the SPs is
completely crashed
completely crashed
this is because of the profiling
this is because of the profiling
overhead of running running all this
overhead of running running all this
data collection so this data is not
data collection so this data is not
always 100% accurate because when you
always 100% accurate because when you
have more overhead from profiling than
have more overhead from profiling than
the actual thing that's taking to that's
the actual thing that's taking to that's
actually taking to run
actually taking to run
it you can see how that would make it
it you can see how that would make it
hard right
hard right
but I think that the relative compute
but I think that the relative compute
time should still be more or less
time should still be more or less
correct here
so it's actually a pretty darn nice
so it's actually a pretty darn nice
curve to start with it's a pretty nice
curve to start with it's a pretty nice
profiling
curve I want to get the HTML file just
curve I want to get the HTML file just
so way make sure that I have the latest
so way make sure that I have the latest
one
and we're going to
refresh where is it we're going to
refresh where is it we're going to
refresh this
file let me make sure it refreshed yeah
file let me make sure it refreshed yeah
so now this returns an INT perfect uh
so now this returns an INT perfect uh
this still is not typed correctly but
this still is not typed correctly but
whatever so I'm going to make sure that
whatever so I'm going to make sure that
you can see this on the Stream
okay so now all we have to do is we
okay so now all we have to do is we
basically we go through all of these and
basically we go through all of these and
we see if any of this is uh caused by
we see if any of this is uh caused by
calls back to python versus algorithmic
calls back to python versus algorithmic
overhead versus me having designed stuff
overhead versus me having designed stuff
stupid so the first function I see is
stupid so the first function I see is
scan
scan
AOE that I believe is algorithmic
AOE that I believe is algorithmic
overhead I think we're going to have to
overhead I think we're going to have to
do some caching there I think that
do some caching there I think that
that's probably a very efficient
that's probably a very efficient
function that just needs to be cached so
function that just needs to be cached so
as you can see this function runs in
as you can see this function runs in
pure
C it does do a number of checks that I
C it does do a number of checks that I
could potentially improve
could potentially improve
upon
um yeah it does do a number of checks
um yeah it does do a number of checks
that I could potentially improve upon I
that I could potentially improve upon I
could save some time that way but I
could save some time that way but I
think that most likely is going to
be uh that this function can't get cold
be uh that this function can't get cold
every single frame right now it's
every single frame right now it's
getting cold every frame uh on every
getting cold every frame uh on every
creep so like everybody's constantly
creep so like everybody's constantly
rescanning for targets and I think that
rescanning for targets and I think that
if you uh you just run this thing at a
if you uh you just run this thing at a
more reasonable interval that'll
more reasonable interval that'll
probably be fine though there's going to
probably be fine though there's going to
have to be a little caching for that
have to be a little caching for that
maybe uh we have step function itself
maybe uh we have step function itself
the step function should be a very large
the step function should be a very large
function and
and we do
have we do have a call back to python
have we do have a call back to python
right
here welcome fruit punch Samurai
here welcome fruit punch Samurai
welcome welcome
exx we are optimizing the hell out of
exx we are optimizing the hell out of
this
this
code we're currently at 180,000 is the
code we're currently at 180,000 is the
best that I've seen so
best that I've seen so
far and uh the goal is 500,000 on this
far and uh the goal is 500,000 on this
machine at minimum which will be uh over
machine at minimum which will be uh over
a million on the the Box miss a few
a million on the the Box miss a few
streams yeah well I'll show since
streams yeah well I'll show since
there's some people I'll show the GIF
there's some people I'll show the GIF
while I look at uh I'll pull the GIF up
while I look at uh I'll pull the GIF up
while I continue looking at this that's
while I continue looking at this that's
the latest version
it plays full games
now so this call here is calling back to
now so this call here is calling back to
python uh this numpy actions is not
python uh this numpy actions is not
typed it probably should be
typed this is a very slow call back to
typed this is a very slow call back to
python which is weird
python which is weird
use Q is a
beant weird we will fix
beant weird we will fix
that and then these return values are
that and then these return values are
also uh because step doesn't have a
also uh because step doesn't have a
return type okay
return type okay
cool yeah this is what I did this is how
cool yeah this is what I did this is how
we ended the stream yesterday uh we have
we ended the stream yesterday uh we have
we're basically just reusing this the
we're basically just reusing this the
creep AI on the heroes and then we have
creep AI on the heroes and then we have
three Heroes assigned to Safe Lane one
three Heroes assigned to Safe Lane one
assigned to Mid and one assigned to off
assigned to Mid and one assigned to off
lane or hard Lane uh and they will play
lane or hard Lane uh and they will play
full
games so let's just fix step real quick
games so let's just fix step real quick
just to see if that does anything
so it's a little awkward because this is
so it's a little awkward because this is
a de function which is supposed to be
a de function which is supposed to be
python API but I think we'll just expose
python API but I think we'll just expose
this with
this with
cpde which allows us to add a little bit
cpde which allows us to add a little bit
of extra typing information and then we
of extra typing information and then we
can do mp. ND array or it should be cn.
can do mp. ND array or it should be cn.
ND array so we add typing information to
ND array so we add typing information to
this and I think that this will still
this and I think that this will still
potentially trigger a call back to
potentially trigger a call back to
python the only
python the only
one yeah only
one yeah only
one and then this one is the big one
one and then this one is the big one
that breaks the loop right here is this
that breaks the loop right here is this
uh in continuous whatever greater than
uh in continuous whatever greater than
zero greater than
0.5 that's kind of weird the way I
0.5 that's kind of weird the way I
structured this isn't it
I mean we're not using this at the
I mean we're not using this at the
moment whatsoever so I'm just going to
moment whatsoever so I'm just going to
comment
comment
this and then like too breaks
python we're not using this at the
python we're not using this at the
moment
anyways and I think this is the only
anyways and I think this is the only
thing that calls back to python
thing that calls back to python
so yeah
okay and then we should have a new HTML
okay and then we should have a new HTML
file we'll move it we'll
file we'll move it we'll
refresh perfect so this is now no longer
refresh perfect so this is now no longer
yellow and this is still okay as I
yellow and this is still okay as I
expected this is still yellow but this
expected this is still yellow but this
is once per frame this is not in a loop
is once per frame this is not in a loop
no big
no big
deal um
deal um
uh potentially some method call
uh potentially some method call
optimizations we can make I know how to
optimizations we can make I know how to
do that separately no big
deal a lot of these method calls I'm not
deal a lot of these method calls I'm not
positive actually I think this is the
positive actually I think this is the
profile overhead actually like the
profile overhead actually like the
reason a lot of these have this yellow
reason a lot of these have this yellow
is because I'm running profiling we can
is because I'm running profiling we can
check on that though okay so now that we
check on that though okay so now that we
have this running we can do our
have this running we can do our
profiling
profiling
again not expecting a huge difference
maybe something
though step is okay step is still at the
though step is okay step is still at the
same roughly the same Pace um it's
same roughly the same Pace um it's
saying a quarter of the time is being
saying a quarter of the time is being
spent inside the step function and not
spent inside the step function and not
inside any of the other functions that
inside any of the other functions that
are being
are being
profiled kind of weird
profiled kind of weird
I mean I guess we do have like Loops
I mean I guess we do have like Loops
like this but this is a percent this is
like this but this is a percent this is
like not called very often the percent
600 we have some method
600 we have some method
calls oh oh I know if the method calls
calls oh oh I know if the method calls
themselves are going back to python
themselves are going back to python
maybe but wait if the method calls were
maybe but wait if the method calls were
going back to python they should show up
going back to python they should show up
in yellow
here I think they should show up in
here I think they should show up in
yellow I could be wrong let me find
yellow I could be wrong let me find
something that definitely calls back to
something that definitely calls back to
python okay so nearest scan Target for
python okay so nearest scan Target for
instance calls back to Python and uh I
instance calls back to Python and uh I
know that nearest scan Target is called
know that nearest scan Target is called
from like Tower AI or creep AI or
from like Tower AI or creep AI or
something uh but it's not showing up
something uh but it's not showing up
here so probably it's just the method
here so probably it's just the method
calls are actually going back to python
calls are actually going back to python
uh and we'll have to figure that out as
uh and we'll have to figure that out as
my guess
let's focus then on uh some of the the
let's focus then on uh some of the the
lower level ones so we've got compute
lower level ones so we've got compute
observations that's a pretty performance
observations that's a pretty performance
critical
thing and uh we can see that I
thing and uh we can see that I
have some typing problems it looks
have some typing problems it looks
like R is typed as an INT and Dy is
like R is typed as an INT and Dy is
typed as an INT
typed as an INT
is this cast not
valid I thought that this cast was
valid see it's not why is this
valid see it's not why is this
valid this move to function
valid this move to function
here this is not triggering a call back
here this is not triggering a call back
to python this is parsing as a valid
cast why is the other one not parsing as
cast why is the other one not parsing as
a valid
cast R is an
cast R is an
INT int of player is player not
defined I don't see play oh wait here it
defined I don't see play oh wait here it
is player entity start
is player entity start
player Y is equal to player get y
well this doesn't need to be player doy
well this doesn't need to be player doy
right this can
right this can
be this can just be y because I computed
be this can just be y because I computed
it up here though I don't know why it
it up here though I don't know why it
would make a difference let's
see this is a very um performance
see this is a very um performance
critical function
critical function
though int y
what how the heck am I doing
what how the heck am I doing
this Dy
in okay I'm just doing this in a very
in okay I'm just doing this in a very
stupid way I
stupid way I
think
because and then we have Y and X I
because and then we have Y and X I
guess yeah I think I'm just doing this
guess yeah I think I'm just doing this
in a very stupid way
this is a perform this is absolutely a
this is a perform this is absolutely a
performance critical function by the way
performance critical function by the way
this is this is called on every hero on
this is this is called on every hero on
every frame and it does a
every frame and it does a
scan and it fills in a bunch of data it
scan and it fills in a bunch of data it
copies a bunch of data so this is very
copies a bunch of data so this is very
performance critical
so
so
here we got to go slow with this
here we got to go slow with this
um we've got float y float X do we use Y
um we've got float y float X do we use Y
and X
and X
anywhere no we do
anywhere no we do
not so we do not need
these we do want Y and X Maybe
how do I do it in scan
how do I do it in scan
AOE I think that this is a more recent
AOE I think that this is a more recent
piece of
piece of
code I did actually do Dy and DX
here it's not terrible
I think I could do this
potentially but I think that actually
potentially but I think that actually
both of these are going to be more
both of these are going to be more
efficient If instead of computing the
efficient If instead of computing the
Delta offset like this I just use Y and
Delta offset like this I just use Y and
X
X
directly so if I do if Y is in a range
directly so if I do if Y is in a range
of
um let's do yeah let's use R for this
um let's do yeah let's use R for this
maybe cuz Y is going to be an INT
maybe cuz Y is going to be an INT
now we're going to do int
now we're going to do int
y yeah int r c int
y yeah int r c int
Y and X so we're going to have x y r and
Y and X so we're going to have x y r and
c and then we're going to
do y is going to be int of player. y x
do y is going to be int of player. y x
is going to be int player.
X you have to talk about Insel lot when
X you have to talk about Insel lot when
you're talking about
mobus can't have your creeps
inting um this is going to be y minus
inting um this is going to be y minus
Vision
Vision
range y plus Vision
range y plus Vision
range right we don't need this garbage
range right we don't need this garbage
math in here
math in here
and then this is going to be C in a
and then this is going to be C in a
range of x minus Vision
range of x minus Vision
range X Plus Vision range plus one now
range X Plus Vision range plus one now
we get the target PID if it's negative 1
we get the target PID if it's negative 1
we
we
continue we get the target we have to
continue we get the target we have to
figure this out but we're not doing that
figure this out but we're not doing that
right now because it's going to be
right now because it's going to be
really boring to
really boring to
watch and
watch and
then I think that's all of our typing
then I think that's all of our typing
problems solved do we use agent idx
problems solved do we use agent idx
anywhere we don't use agent idx get rid
anywhere we don't use agent idx get rid
of this garbage we do use idx it looks
of this garbage we do use idx it looks
like do we use
like do we use
PID we do use
PID uh and we use Target PID and Target
PID uh and we use Target PID and Target
and Target up okay so let me make sure
and Target up okay so let me make sure
this makes sense the way the compute
this makes sense the way the compute
observation function works is we're
observation function works is we're
going to go
going to go
through self. num
through self. num
agents which should be 10
agents which should be 10
this is hardcoded these numbers but uh
this is hardcoded these numbers but uh
you're essentially we're setting we're
you're essentially we're setting we're
setting the observed values to negative
setting the observed values to negative
one to start with this is just clearing
one to start with this is just clearing
a
a
buffer this is a sanity check it's kind
buffer this is a sanity check it's kind
of slow but you know we'll improve that
of slow but you know we'll improve that
later I'm looking for low hanging fruit
later I'm looking for low hanging fruit
first we get the player that we're
first we get the player that we're
currently Computing the observations for
currently Computing the observations for
the main set of observations is going to
the main set of observations is going to
be a
be a
slice into the grid
slice into the grid
that is just going to tell you the uh
that is just going to tell you the uh
obstructions around you essentially this
obstructions around you essentially this
is like a map that gives you some basic
is like a map that gives you some basic
highle information about what is around
highle information about what is around
you and then the main meat of this
you and then the main meat of this
function right here is a much more
function right here is a much more
detailed
detailed
map that tells you about any agents that
map that tells you about any agents that
are nearby you so you're going to go
are nearby you so you're going to go
through all your surrounding tiles and
through all your surrounding tiles and
you're going to look for uh potential
you're going to look for uh potential
agents creeps anything like like that
agents creeps anything like like that
and then for you're going to extract a
and then for you're going to extract a
bunch of additional uh information about
bunch of additional uh information about
these up to 10 so you're going to
these up to 10 so you're going to
extract up to 10 agents worth of
extract up to 10 agents worth of
information around you and uh this
information around you and uh this
probably as a to-do we should do this
probably as a to-do we should do this
like sort by distance it should probably
like sort by distance it should probably
be the 10 nearest agents to you uh and
be the 10 nearest agents to you uh and
frankly we can probably repurpose the
frankly we can probably repurpose the
scan AOE function cuz the scan AOE
scan AOE function cuz the scan AOE
function is perfect for this it just
function is perfect for this it just
gives you the nearby Targets for now
gives you the nearby Targets for now
we're going to leave it this way though
we're going to leave it this way though
and we're going to see if we actually
and we're going to see if we actually
improved
anything doesn't look like I broke
anything if I didn't break anything then
anything if I didn't break anything then
we should have a new HTML file here
we should have a new HTML file here
which which we do
which which we do
we'll move over the HTML file we'll
we'll move over the HTML file we'll
refresh this and now our compute
refresh this and now our compute
observation function runs in pure C
observation function runs in pure C
isn't that nice so it basically looks
isn't that nice so it basically looks
like python it's almost identical to
like python it's almost identical to
python code that you would write but
python code that you would write but
this is pure native c-e for this
this is pure native c-e for this
performance critical
function I don't know if it's going to
function I don't know if it's going to
give us any benefit just
give us any benefit just
yet we'll
see ooh
see ooh
um it looks like I potentially
um it looks like I potentially
introduced a bug in the
introduced a bug in the
process differing Dimensions extend 11 Z
process differing Dimensions extend 11 Z
that's
gross runtime bugs are
gross ah because I forgot to do this R
gross ah because I forgot to do this R
and see hold on
excuse
excuse
me I just forgot to update some variable
me I just forgot to update some variable
names this is supposed to be I renamed R
names this is supposed to be I renamed R
and C so this is now y this is
and C so this is now y this is
X this is y and this is
X this is y and this is
X uh and that should be
fine okay playing mute toggle game here
refreshes we copy the Coba thing over we
refreshes we copy the Coba thing over we
make sure we've got our new source which
make sure we've got our new source which
we do we run our performance
test runs for 10
test runs for 10
seconds
roughly and there we go so
this is indeed much
this is indeed much
faster we
saved we saved I think about a third of
saved we saved I think about a third of
the compute that was just being thrown
the compute that was just being thrown
away on that function from periodically
away on that function from periodically
calling back to
calling back to
python this used to be uh a full second
python this used to be uh a full second
I
I
believe so we shaved off a little bit
believe so we shaved off a little bit
there really though I want I'm looking
there really though I want I'm looking
for bigger performance improvements than
for bigger performance improvements than
this um
this um
I
I
see it's a little hard to tell though
see it's a little hard to tell though
because this thing this profiler adds so
because this thing this profiler adds so
much overhead like C profile adds this
much overhead like C profile adds this
should run 180,000 at least steps per
should run 180,000 at least steps per
second so with 90% overhead it's
second so with 90% overhead it's
sometimes hard to tell which of these
sometimes hard to tell which of these
timings to trust and which
timings to trust and which
not
um let's see some like some things that
um let's see some like some things that
if we have some some basic free wins
if we have some some basic free wins
here uh creep AI is kind of
slow all this stuff doesn't
slow all this stuff doesn't
matter entity star get player OB get
matter entity star get player OB get
entity what the heck why is this
running I'm pretty sure that's just the
running I'm pretty sure that's just the
profile overhead I don't see how it
profile overhead I don't see how it
would be possible for this thing to be
would be possible for this thing to be
this slow because this is literally just
this slow because this is literally just
a
lookup I might want to
lookup I might want to
try I I'm going to do an experiment so
try I I'm going to do an experiment so
this is 7 Seconds right now which is not
this is 7 Seconds right now which is not
insubstantial and I have a lot of
insubstantial and I have a lot of
functions like this so
what if I inline this
right cdef inline entity
right cdef inline entity
star does this do
anything this should tell the compiler
anything this should tell the compiler
to never treat this as a separate
to never treat this as a separate
function it should always try to just
function it should always try to just
put this operation directly into the
put this operation directly into the
code um so like this is a on line
code um so like this is a on line
function
function
instead of instead of calling this
instead of instead of calling this
function everywhere and adding the
function everywhere and adding the
overhead of a call it should just run
overhead of a call it should just run
that one line of code directly
that one line of code directly
wherever it's kind of like not having a
wherever it's kind of like not having a
function and just copy pasting it
everywhere doesn't always do
anything and in this case yeah so this
anything and in this case yeah so this
didn't do anything uh I'm not going to
didn't do anything uh I'm not going to
do it if it doesn't have the clear B
do it if it doesn't have the clear B
benefit um I suspect that this is just
benefit um I suspect that this is just
function like profiling overhead because
function like profiling overhead because
this function is called very very often
this function is called very very often
you can see the number of calls and if
you can see the number of calls and if
there's just a little bit of profiling
there's just a little bit of profiling
overhead associated with this then that
overhead associated with this then that
this would be what you would get out of
it very obnoxious though that this is
like that this is happens with your
like that this is happens with your
profiling code right is there like a
profiling code right is there like a
decorator no profile
decorator is there can you use a pyx
decorator is there can you use a pyx
decorator or
decorator or
something scon that
something scon that
profile I think this is the python
profile I think this is the python
API I don't think there's a good way to
API I don't think there's a good way to
do that
oh wait here it
oh wait here it
is C import scon at python.
profile
profile
perfect Let's uh let's see what happens
perfect Let's uh let's see what happens
with this because we might be able to
with this because we might be able to
get some more reasonable results by
get some more reasonable results by
ignoring these little tiny
functions so C import scon
we're going to do at on. profile false I
we're going to do at on. profile false I
want to see if it doesn't show up in my
want to see if it doesn't show up in my
profile anymore because it would be
profile anymore because it would be
really nice if I could just ignore these
really nice if I could just ignore these
these short
these short
functions um because they make it really
functions um because they make it really
hard to profile when you have this much
hard to profile when you have this much
overhead like anytime I'm timing a
overhead like anytime I'm timing a
function that's calling this thing a
function that's calling this thing a
bunch of times I'm adding like a a
bunch of times I'm adding like a a
python call back or a profile call back
python call back or a profile call back
every time and it makes it really hard
every time and it makes it really hard
to get consistent
results does this show
up or does it respect my
override it looks like it respects my uh
override it looks like it respects my uh
my override here the steps per second
my override here the steps per second
went up by a little
went up by a little
bit
bit
and yeah okay so it omitted this
and yeah okay so it omitted this
function uh from
function uh from
profiling
and wow that actually made a huge
and wow that actually made a huge
difference didn't it like the whole
difference didn't it like the whole
profile table changed just from
profile table changed just from
that I think it's going to be worth
that I think it's going to be worth
adding this to all of the small little
adding this to all of the small little
functions um because like it doesn't not
functions um because like it doesn't not
profiling the function doesn't mean
profiling the function doesn't mean
we're not profiling that code
we're not profiling that code
it just means that we're not separately
it just means that we're not separately
profiling that code so
profiling that code so
like
here we are profiling this code
here we are profiling this code
implicitly anytime we're calling this
implicitly anytime we're calling this
function from somewhere else but the
function from somewhere else but the
thing is like if I look at the table
thing is like if I look at the table
where is it if I look at the scon op
where is it if I look at the scon op
table I see that all these functions are
table I see that all these functions are
already optimized like the returns of
already optimized like the returns of
all these functions are already pure C
all these functions are already pure C
anyways um and they're already properly
anyways um and they're already properly
typed
typed
so there's no reason to uh there's no
so there's no reason to uh there's no
reason to go further than that with
reason to go further than that with
it and actually if I move this can I see
it and actually if I move this can I see
the profile line taking effect here oh
the profile line taking effect here oh
look look how cool this
look look how cool this
is you add this decorator and now this
is you add this decorator and now this
function shows properly as being in pure
function shows properly as being in pure
C because if you look here this is just
C because if you look here this is just
a raw function call whereas this one it
a raw function call whereas this one it
has all this traceback stuff that is
has all this traceback stuff that is
being used for the profiler so this is
being used for the profiler so this is
actually perfect because it's being
actually perfect because it's being
annotated but it's not being profiled
annotated but it's not being profiled
right if I do like xals 2 here what
right if I do like xals 2 here what
happens I want to make sure that we
happens I want to make sure that we
actually have this working as intended
actually have this working as intended
because it's very very
important okay we recompile
and then we rerun I want to make
and then we rerun I want to make
absolutely sure that The annotation is
absolutely sure that The annotation is
going to pick up stuff even that's not
going to pick up stuff even that's not
in profile
blocks I'm very confident that this is
blocks I'm very confident that this is
the case but this would screw everything
the case but this would screw everything
uh everything else up otherwise okay so
uh everything else up otherwise okay so
we ran the
we ran the
profiler we move this
file ooh that's Jank
Pi
VX oh wait I think it could just be the
VX oh wait I think it could just be the
compiler optimizing it out
right h
let me let me try one other thing and
let me let me try one other thing and
then we'll uh we'll stop with this line
then we'll uh we'll stop with this line
of inquiry because the compiler is going
of inquiry because the compiler is going
to be tricky but this is
to be tricky but this is
suspicious I'm going to try to trick the
suspicious I'm going to try to trick the
compiler
here so what we're going to do is for I
here so what we're going to do is for I
in
in
range let's do like a self variable
range let's do like a self variable
something that's Dynamic and we're going
something that's Dynamic and we're going
to go like PID plus
to go like PID plus
equals uh
equals uh
I
I
so let's see if this can trick the
so let's see if this can trick the
compiler obviously we can't run this
compiler obviously we can't run this
code now because I've just broken the
code now because I've just broken the
logic um but you don't need to run the
logic um but you don't need to run the
code for annotation purposes it's
code for annotation purposes it's
compile
time okay and perfect so this is exactly
time okay and perfect so this is exactly
what I was looking for you see
what I was looking for you see
so right
so right
here this function it has profiling
here this function it has profiling
disabled but annotation is on so if I
disabled but annotation is on so if I
add something that's going to make the
add something that's going to make the
compiler call back to python even though
compiler call back to python even though
I'm not profiling it I can actually see
I'm not profiling it I can actually see
that it's calling back to python here
that it's calling back to python here
and importantly if I remove this like we
and importantly if I remove this like we
saw before uh this is going to turn
saw before uh this is going to turn
white telling us that this is a pure C
white telling us that this is a pure C
call so that's exactly what we want and
call so that's exactly what we want and
then we'll be able to do our inline
then we'll be able to do our inline
Shenanigans and we'll be able to run
Shenanigans and we'll be able to run
that experiment correctly as
well we're going to take all of these
well we're going to take all of these
shitty little functions and these are
shitty little functions and these are
all going to be profile
off don't need to profile any of these
off don't need to profile any of these
like stupid little functions
they will all be profiled
purely we're not even going to inline
purely we're not even going to inline
them for now we'll do the inline
them for now we'll do the inline
experiment 100%
separate boom okay none of these are now
separate boom okay none of these are now
profiled and I think that's yeah that
profiled and I think that's yeah that
should be all of the Annoying uh little
should be all of the Annoying uh little
functions
we build and we should actually just by
we build and we should actually just by
that we should be getting something
that we should be getting something
that's at least within a a factor of the
that's at least within a a factor of the
actual performance of our environment
actual performance of our environment
despite the profiling overhead cuz most
despite the profiling overhead cuz most
of the profiling overhead comes from
of the profiling overhead comes from
these small little functions that are
these small little functions that are
just getting like chucked in with the
just getting like chucked in with the
the rest of the
profiler over per.
this will run for 10
this will run for 10
seconds so much better so this is now
seconds so much better so this is now
three times faster than before which is
three times faster than before which is
still like a quarter of the speed of our
still like a quarter of the speed of our
actual
actual
environment but this at least now we
environment but this at least now we
have some hope of being able to tell
have some hope of being able to tell
relatively what's important and what
relatively what's important and what
isn't right
so let's
so let's
see move function update status up upate
see move function update status up upate
cool
cool
Downs lots of these little functions
Downs lots of these little functions
let's see
um are those functions
um are those functions
bad let's hold on let's run this run
bad let's hold on let's run this run
this do perfect look at
this do perfect look at
that pure
C let's look for like update
C let's look for like update
status and cooldowns
so this is an obnoxious amount of time
so this is an obnoxious amount of time
to be spending in these functions right
to be spending in these functions right
look at the number of calls
here this gets called on every entity at
here this gets called on every entity at
every
every
step so even though these functions are
step so even though these functions are
pretty highly optimized like these are
pretty highly optimized like these are
just straight up conditionals
they're taking a lot of overhead just
they're taking a lot of overhead just
because of the amount of times they're
because of the amount of times they're
getting
getting
called um that's actually kind of useful
called um that's actually kind of useful
because it tells us that any function
because it tells us that any function
that's getting called every step every
that's getting called every step every
entity is going to add like0 2.3 seconds
right so like these neutral AI functions
right so like these neutral AI functions
and stuff
three of this is just or I think 0.15 of
three of this is just or I think 0.15 of
this is just call
this is just call
Overhead that gives you a scale of like
Overhead that gives you a scale of like
how efficient we're talking
here I want to take these out of the
here I want to take these out of the
profiling though as well because these
profiling though as well because these
are like
are like
[Music]
[Music]
so so
minor and again we're trying to figure
minor and again we're trying to figure
out
where where we're losing perf on
where where we're losing perf on
step and this isn't telling us where
step and this isn't telling us where
we're losing perf on step the step is
we're losing perf on step the step is
definitely really slow and we're not
definitely really slow and we're not
able to tell why at the moment U because
able to tell why at the moment U because
of this other profiling
overhead a nice thing to note about the
overhead a nice thing to note about the
stuff that I'm doing right
stuff that I'm doing right
here um if you think about it I would be
here um if you think about it I would be
this doing this exact type of profiling
this doing this exact type of profiling
in C or C++ or any other language I'd be
in C or C++ or any other language I'd be
having to do this exact same type of
having to do this exact same type of
profiling so I'm not just doing this
profiling so I'm not just doing this
because it's syon this is like identical
because it's syon this is like identical
to the profiling work I'd be doing in
to the profiling work I'd be doing in
anything else just with additional
tools so this is
tools so this is
when you think of it that
way not too bad on the
workflow we
workflow we
rebuild I'm expecting 50,000 maybe
rebuild I'm expecting 50,000 maybe
50,000 steps per
second we'll run M perf and we will copy
second we'll run M perf and we will copy
this over to the docker
this over to the docker
again and now we we can see that these
again and now we we can see that these
are pure
are pure
C these are pure C
functions oh that was way more than I
functions oh that was way more than I
expected 67,000 steps per second uh
expected 67,000 steps per second uh
without that profile
without that profile
overhead there's still a few functions
overhead there's still a few functions
that you can tell have a lot of overhead
that you can tell have a lot of overhead
like this is these are huge call
like this is these are huge call
amounts but now we get to look at these
amounts but now we get to look at these
functions individually so
did this just
did this just
shift hold on oh that's really major
shift hold on oh that's really major
look so before step was at 3.6
look so before step was at 3.6
seconds and it was twice the amount of
seconds and it was twice the amount of
time is creep AI right and scan AOE so
time is creep AI right and scan AOE so
I'd say hey look we're losing most of
I'd say hey look we're losing most of
the perf in Step but actually when you
the perf in Step but actually when you
take out these crappy little functions
take out these crappy little functions
that are just triggering call Overhead
that are just triggering call Overhead
cuz step
cuz step
here step here is triggering profile
here step here is triggering profile
overhead every single time it calls one
overhead every single time it calls one
of these functions update status update
of these functions update status update
cool down which is every single entity
cool down which is every single entity
in the game when you take this out of
in the game when you take this out of
the
the
overhead the step function actually
overhead the step function actually
looks way better right it's only two
looks way better right it's only two
seconds and scan AOE is pretty much the
seconds and scan AOE is pretty much the
same amount of time and the neutral AI
same amount of time and the neutral AI
is also a big chunk of
is also a big chunk of
time and it's actually even now with the
time and it's actually even now with the
creep AI the creep AI is even a little
creep AI the creep AI is even a little
bit
bit
slower so I think we continue on this we
slower so I think we continue on this we
continue we're going to optimize the
continue we're going to optimize the
little functions and then we're going to
little functions and then we're going to
take them out of profile until we figure
take them out of profile until we figure
out like the relative assignment
out like the relative assignment
of how expensive the big functions are
of how expensive the big functions are
and then we're going to figure out once
and then we're going to figure out once
we no longer have anything left to
we no longer have anything left to
optimize on just like the
optimize on just like the
cide then we're going to think about
cide then we're going to think about
like caching targeting and stuff like
like caching targeting and stuff like
that and we're probably only going to
that and we're probably only going to
have to make two or three changes to
have to make two or three changes to
this whole code base in order to like
this whole code base in order to like
from the whole start until now there
from the whole start until now there
going to be like two or three High LEL
going to be like two or three High LEL
changes that we have to make to take
changes that we have to make to take
this thing from 70,000 steps per second
this thing from 70,000 steps per second
to a million steps per
to a million steps per
second it's really that
easy and the difference between 70,000
easy and the difference between 70,000
and a million let me put this into
perspective if you want to get a million
perspective if you want to get a million
steps per second train and your
steps per second train and your
environment runs at a million steps per
environment runs at a million steps per
second you just need to run two of those
second you just need to run two of those
environments and like call them back and
environments and like call them back and
forth so when one is generating data for
forth so when one is generating data for
you the other one is ready and you just
you the other one is ready and you just
go back and forth very easy if you have
go back and forth very easy if you have
a 70,000 step per second environment you
a 70,000 step per second environment you
need like 20 cores and they have to be
need like 20 cores and they have to be
very very tightly uh and accurately
very very tightly uh and accurately
relaying information across all the
relaying information across all the
process boundaries otherwise you lose
process boundaries otherwise you lose
too much of it and you won't get a
too much of it and you won't get a
million steps per second so it's so much
million steps per second so it's so much
easier when your environment is just
easier when your environment is just
fast by
default I see we've got a lot of folks
default I see we've got a lot of folks
on YouTube so uh welcome all of this
on YouTube so uh welcome all of this
stuff is open source um this is all
stuff is open source um this is all
available in puffer lib which is the
available in puffer lib which is the
main project I work on it's on
main project I work on it's on
github.com puffer ipuff currently we are
github.com puffer ipuff currently we are
on the in config Branch it's going to be
on the in config Branch it's going to be
merged into Dev soon it's in environment
merged into Dev soon it's in environment
ocean you can play around with it there
ocean you can play around with it there
uh if you like my work please start the
uh if you like my work please start the
repo helps me out a whole ton slend
add okay um function to start with next
add okay um function to start with next
I
I
think compute observation is actually
think compute observation is actually
looking pretty good
looking pretty good
now I'm pretty happy with
now I'm pretty happy with
that yeah let's go to nearest scan
that yeah let's go to nearest scan
Target I think this is the first place
Target I think this is the first place
nearest
nearest
scan Target okay so L2 distance is
scan Target okay so L2 distance is
calling back to python that's really
calling back to python that's really
bad that's like a straight up error on
bad that's like a straight up error on
my part why is it calling back
to why is L2 distance calling back to
to why is L2 distance calling back to
python it doesn't look like it
python it doesn't look like it
should it's a float that takes in a
should it's a float that takes in a
bunch of
bunch of
floats and returns a float
ER
huh wait why is this
highlighted Pi error occurred
huh it's injecting some sort of error
huh it's injecting some sort of error
check
check
here Pi error
occurred is there a division
thing compiler thinks that this function
thing compiler thinks that this function
can throw an error and it's not being
can throw an error and it's not being
caught by my current error
caught by my current error
checks I have all these flags at the top
checks I have all these flags at the top
saying we're using C division we're not
saying we're using C division we're not
doing bounds checking initialize check
doing bounds checking initialize check
we're not doing any of
that isn't squared also
that isn't squared also
slow power function is slow
right is there a better square root
right is there a better square root
function of as well that we can use and
see where
see where
is where's the C square root function
okay there is a just a built-in square
okay there is a just a built-in square
root is there a float version of
it C float square root standard
Library Square Root
F okay so we need to import this
F okay so we need to import this
and then we need to
and then we need to
implement uh we need to just change a
implement uh we need to just change a
couple small
things so this L2 and I think we should
things so this L2 and I think we should
just do
just do
cdef so
cdef so
float DX is going to be X1 -
X2 and then we're going to return square
X2 and then we're going to return square
root like
this and then we need to do
yeah and this should be square root F
yeah and this should be square root F
isn't
it cuz there
floats is there a faster there's not
floats is there a faster there's not
like a fast L2 in C standard Library no
like a fast L2 in C standard Library no
C standard library is small so I think
C standard library is small so I think
that this is what we
that this is what we
want let's try this
want let's try this
out let's see if this does anything for
us this is the type of optimization you
us this is the type of optimization you
have to do for this
though so let's go get the new
file we should have a new
function distance
okay we have a new distance function
okay we have a new distance function
right this nearest scan went
right this nearest scan went
down I can see that this went
down I can see that this went
down uh it's
down uh it's
still it is still saying that there
still it is still saying that there
is a error check on this
is a error check on this
though so now the code is
though so now the code is
different let's see so we went up from
different let's see so we went up from
67 to
67 to
69,000 steps per second this is with
69,000 steps per second this is with
profiling overhead it's like
profiling overhead it's like
200,000 uh without profiling overhead
200,000 uh without profiling overhead
and then it'll be like 4 to 500,000 on
and then it'll be like 4 to 500,000 on
the actual machine that we'll be using
the actual machine that we'll be using
for training so we're like a factor of
for training so we're like a factor of
two maybe two and a half off
two maybe two and a half off
still
um this function here is
Step
Step
oh yeah so we have very little python
oh yeah so we have very little python
overhead this is fine nearest scan
overhead this is fine nearest scan
Target is down
Target is down
to.5 with a ton of calls so this is
to.5 with a ton of calls so this is
mostly call Overhead actually which it
mostly call Overhead actually which it
should be nearest scan Target should be
should be nearest scan Target should be
very
very
fast uh and actually I think that most
fast uh and actually I think that most
of this overhead is coming from
of this overhead is coming from
this this right here well this is
this this right here well this is
bizarre though
like this is something I don't
like this is something I don't
understand and I want to learn right now
understand and I want to learn right now
um
um
um somehow this function can potentially
um somehow this function can potentially
throw throw an
error is this something with how square
error is this something with how square
root is
implemented can square root F throw an
error I don't know why it would throw a
error I don't know why it would throw a
pi error that's
bizarre let's look at this
bizarre let's look at this
code this is what it compiles
code this is what it compiles
too I don't know if anybody watching has
too I don't know if anybody watching has
any idea you can go ahead and let me
any idea you can go ahead and let me
know I have no
know I have no
idea
uh so these are just like automatically
uh so these are just like automatically
generated variable names obviously
generated variable names obviously
they're
they're
garbage this is the L2 function that we
garbage this is the L2 function that we
defined you can see it has a bunch of
defined you can see it has a bunch of
garbage but it has our uh distance
function this is right here this is the
function this is right here this is the
pointer D reference right neutral y
pointer D reference right neutral y
neutral X Target y Target
neutral X Target y Target
X and then we get if
X and then we get if
unlikely we can actually just read this
unlikely we can actually just read this
out right if
unlikely the output of this
unlikely the output of this
function pix tore
function pix tore
3 is equal to
-1 and pi High error
-1 and pi High error
occurred so if this function returns
occurred so if this function returns
-1
H that's the C error code what's this Pi
H that's the C error code what's this Pi
error occurred
though Pi error
pxl1 hey everybody's been saying chat
pxl1 hey everybody's been saying chat
gepd is going to solve everything right
gepd is going to solve everything right
chat D is going to solve everything and
chat D is going to solve everything and
take all the jobs let's let's see if it
take all the jobs let's let's see if it
solves
solves
anything I do this every so often and
anything I do this every so often and
it's got a it chat GPT currently has a
it's got a it chat GPT currently has a
success rate of like
success rate of like
zero we'll use uh
zero we'll use uh
four what's better four or 40 I think
four what's better four or 40 I think
four is better right 40 is
worse here is the uh what is it
compiled 4 is greater than 40 for
compiled 4 is greater than 40 for
programming things okay
programming things okay
well we're going to try it we're going
well we're going to try it we're going
to see I bet it's going to fail utterly
to see I bet it's going to fail utterly
and we're going to feel stupid but
and we're going to feel stupid but
whatever uh I would if it does hey look
whatever uh I would if it does hey look
if it's actually solves it then I get to
if it's actually solves it then I get to
move on with my life right because uh we
move on with my life right because uh we
don't have to stare at this error any
don't have to stare at this error any
longer
longer
um this
so I'm giving it full context for
so I'm giving it full context for
everything here
right handling a floating Point
right handling a floating Point
arithmetic okay that's what I was
arithmetic okay that's what I was
guessing right but like why
okay I guess there's an error check
against that's a kind of decent
response scon do not set pip python
response scon do not set pip python
exceptions
yeah I say it's kind of a mid
yeah I say it's kind of a mid
response this is kind of a mediocre
response this is kind of a mediocre
response
response
right
right
like I'm I'm just I was equally confused
like I'm I'm just I was equally confused
why it's raising a high error instead of
why it's raising a high error instead of
just having the error being in C given
just having the error being in C given
that I used a c function call but
like this is this is a squared number
like this is this is a squared number
like this cannot be negative
right why is it inserting the stupid
check like the compiler is not smart
check like the compiler is not smart
enough to figure out that this is always
enough to figure out that this is always
positive I guess right
do we need it to be square
rooted I mean we don't necessarily need
rooted I mean we don't necessarily need
it to be square rooted but it is mildly
it to be square rooted but it is mildly
inconvenient
inconvenient
right because then we have to work in
right because then we have to work in
like L2 squar
space we could do L1 distance
that would actually be faster
right maybe we just do L1 distance
right maybe we just do L1 distance
instead hey lots of people on the
instead hey lots of people on the
YouTube stream welcome this is all open
YouTube stream welcome this is all open
source you're free to come and uh try it
source you're free to come and uh try it
out the latest version of the demo right
out the latest version of the demo right
now that we're optimizing is right
now that we're optimizing is right
here perhaps you saw this on Twitter
so we have uh the agents playing well we
so we have uh the agents playing well we
have the scripted agents playing full
have the scripted agents playing full
games we're just reusing the creep AI
games we're just reusing the creep AI
for Heroes with fixed Lane assignments
for Heroes with fixed Lane assignments
the goal for today is to make this thing
the goal for today is to make this thing
like the title says a million FPS I'm
like the title says a million FPS I'm
confident that we'll get it today we're
confident that we'll get it today we're
only a factor of two off we started at
only a factor of two off we started at
like I guess we started at 150k and now
like I guess we started at 150k and now
we're at uh we're at like 500k
we're at uh we're at like 500k
equivalent so we only need like another
equivalent so we only need like another
factor of two and we'll be
there and then after that if we have
there and then after that if we have
time today which we should have plenty
time today which we should have plenty
of uh we're going to start on the
of uh we're going to start on the
network architectures for this stuff and
network architectures for this stuff and
that's going to be the tricky part
that's going to be the tricky part
because the network also needs to run a
because the network also needs to run a
million steps per
million steps per
second which is crazy talk for
second which is crazy talk for
reinforcement learning but we've done it
reinforcement learning but we've done it
before so
before so
maybe uh I'm going to I'm going to add a
maybe uh I'm going to I'm going to add a
comment on here for now that says
comment on here for now that says
square
square
root uh throws possible error which
root uh throws possible error which
calls back to
calls back to
python maybe some
python maybe some
way to uh
avoid negative square root check or just
avoid negative square root check or just
use
use
L1 and L1 looks like a diamond which is
L1 and L1 looks like a diamond which is
kind of a fine shape I don't think
kind of a fine shape I don't think
that'll make too much of a difference if
that'll make too much of a difference if
we use L1
we use L1
versus uh L2 and L1 is faster to compute
versus uh L2 and L1 is faster to compute
it should be right yeah absolute value
it should be right yeah absolute value
should be way faster
well this is such a stupid completion
well this is such a stupid completion
right there's no reason to cash like
right there's no reason to cash like
that all
right we're just going to replace L uh
right we're just going to replace L uh
L2 oops with L1 we only use this in a
L2 oops with L1 we only use this in a
few places I
few places I
think
two there we go
rebuild and we will
rebuild and we will
see while we're running the uh the
see while we're running the uh the
profile on this I'm going to see if the
profile on this I'm going to see if the
HTML the annotations look better if
HTML the annotations look better if
we're still calling back to python by
we're still calling back to python by
doing
this let's check this out
so we have our L1 distance
so we have our L1 distance
perfect and now if I look for L1
dist it's still calling back to
dist it's still calling back to
python
really Pi error
really Pi error
occurred
how is it just anything that returns a
how is it just anything that returns a
float it's assuming is an error
code there's actually nowhere in the
code there's actually nowhere in the
math that this can throw like a divide
math that this can throw like a divide
by zero
right so this doesn't make a a
right so this doesn't make a a
appreciable performance difference as
appreciable performance difference as
far as I can tell um and it's not
far as I can tell um and it's not
avoiding the call back to to python let
avoiding the call back to to python let
me
me
think no ABS is defined for
think no ABS is defined for
anything is this like overflow or
anything is this like overflow or
underflow or something this is Fab F ABS
underflow or something this is Fab F ABS
F go
F go
to pix l0
uh
H it's really
H it's really
weird oh wait wasn't this clip doing
weird oh wait wasn't this clip doing
this before as
well maybe there's a c uh a c flag that
well maybe there's a c uh a c flag that
I'm missing like a scyon profile flag is
I'm missing like a scyon profile flag is
there one of these that I'm not uh
there one of these that I'm not uh
thinking of here syon
Flags where is
Flags where is
it is there a list of
them
sources I don't
sources I don't
know that's a bit weird I think this is
know that's a bit weird I think this is
going to get to
going to get to
be uh rather boring rather quickly
be uh rather boring rather quickly
if I
if I
don't let me
don't let me
think inline does inline solve
this do I have it inlined already let me
this do I have it inlined already let me
think of like a quick work around for
think of like a quick work around for
now so we can get back to the other
stuff I think it's because it's in a
stuff I think it's because it's in a
function somehow right
I'm going to try one last thing and then
I'm going to try one last thing and then
we're going to move on and I will uh
we're going to move on and I will uh
sort this off stream uh we'll like just
sort this off stream uh we'll like just
do other stuff for now I want to just
do other stuff for now I want to just
see if I inline it it like this math
see if I inline it it like this math
should not be triggering an error so I
should not be triggering an error so I
think it's something about it being a
think it's something about it being a
function
function
call like I think it's somehow
call like I think it's somehow
interpreting this as an error code like
interpreting this as an error code like
because it returns a number and C uses
because it returns a number and C uses
error code like see usually if you
error code like see usually if you
return negative one it's cuz there's an
return negative one it's cuz there's an
error or something weird like I think
error or something weird like I think
that there's something like that going
on what if I just inline it
on what if I just inline it
right inline Flo
right inline Flo
L1 literally no way that this should be
L1 literally no way that this should be
erroring now
okay inline float
okay inline float
L1 and it's still throwing the stupid
L1 and it's still throwing the stupid
error okay so
I and it's compiling to call this
I and it's compiling to call this
function as well it hasn't compiled with
function as well it hasn't compiled with
the
the
inline which is even weirder okay so I
inline which is even weirder okay so I
will figure this particular one out
will figure this particular one out
later um that's on the to-do list uh
later um that's on the to-do list uh
we'll go back to L2 distance for now
we'll go back to L2 distance for now
just to keep the game playay
consistent we'll just do
consistent we'll just do
L2
L2
two oh by the way that uh that makes
two oh by the way that uh that makes
chat GPT even more wrong than we
chat GPT even more wrong than we
originally
originally
thought so uh I think that uh that's not
thought so uh I think that uh that's not
going to be replacing anything anytime
going to be replacing anything anytime
soon
okay next uh next thing from profiling
right new profile
right new profile
run probably need to rebuild
run probably need to rebuild
it and uh then we will run the profiler
it and uh then we will run the profiler
and we'll go on to the next potential
and we'll go on to the next potential
candidate
candidate
function factoring in that there is call
function factoring in that there is call
Overhead for this specific function
we're going to have to estimate the
we're going to have to estimate the
overhead since we didn't solve this
overhead since we didn't solve this
right that's kind of gross we could
right that's kind of gross we could
always just inline it ourselves time
always just inline it ourselves time
being I might just do
being I might just do
that okay so here's the latest
that okay so here's the latest
performance uh performance number here
performance uh performance number here
we
have Scan nearest Target
have Scan nearest Target
here this really is isn't that bad this
here this really is isn't that bad this
is a big number of
is a big number of
calls and it's doing L2 functions and
calls and it's doing L2 functions and
it's only 0.15 okay so compute
it's only 0.15 okay so compute
observations is a quarter of a
observations is a quarter of a
second this is a big expensive call so
second this is a big expensive call so
anything that's more than this should be
anything that's more than this should be
uh justifying its its
uh justifying its its
cost this here has I think a lot of this
cost this here has I think a lot of this
is just call
is just call
Overhead um but this move to function
Overhead um but this move to function
does do some stuff let me
see move to move to move
see move to move to move
to here's the function
defa so we do some casts
we do some checks on the
we do some checks on the
grid we do some kind of gross
grid we do some kind of gross
conditionals here but like these should
conditionals here but like these should
be fast they're gross but they're very
be fast they're gross but they're very
fast these are just comparing a few
fast these are just comparing a few
things to
things to
constants and then we move some stuff
constants and then we move some stuff
around in memory on a
around in memory on a
grid
grid
so there's no hard math here uh this
so there's no hard math here uh this
function should be very
function should be very
fast and because this function should be
fast and because this function should be
very fast we're going to take it out of
very fast we're going to take it out of
the
the
profile we're essentially when we're
profile we're essentially when we're
taking stuff out of the profile we're
taking stuff out of the profile we're
saying that like hey uh we know that
saying that like hey uh we know that
this is
this is
fast or we know that this is maybe not
fast or we know that this is maybe not
fast but we know that this is as fast as
fast but we know that this is as fast as
it can
it can
be so we don't need to get the the call
be so we don't need to get the the call
Overhead uh of this function in our
profile and actually I just thought of
profile and actually I just thought of
something that we can do for now
what we can do is we can take this L1
what we can do is we can take this L1
distance
distance
implementation and we can do
implementation and we can do
if
if
ABS we can just do it like
ABS we can just do it like
this so we
have this is L1 right if we just
have this is L1 right if we just
implement it manually it shouldn't be
implement it manually it shouldn't be
able to call
able to call
back so we'll just do like like
LF
ABS
X to distance and then we won't have the
X to distance and then we won't have the
call Overhead from this anymore
so this is a nice workaround for now is
so this is a nice workaround for now is
just hardcoding it until we can figure
just hardcoding it until we can figure
out uh you know off stream when it's not
out uh you know off stream when it's not
as
boring we can figure out the distance
functions okay
perfect so now we build this
we should actually have some substantial
we should actually have some substantial
changes to the HTML
changes to the HTML
hopefully uh if we still have errors in
hopefully uh if we still have errors in
here it means that there's some
here it means that there's some
low-level math Shenanigans going on that
low-level math Shenanigans going on that
I do not
I do not
understand that's the only explanation
understand that's the only explanation
for
it let's run the test while we look at
this okay perfect so it's something
this okay perfect so it's something
about the call the function call because
about the call the function call because
this runs pure
C oh and perfect just like that we went
C oh and perfect just like that we went
from 68,000 to 78,000 steps per second
from 68,000 to 78,000 steps per second
and this is again this is with the
and this is again this is with the
profiling overhead which is a lot so
profiling overhead which is a lot so
we're making a lot of progress
here let's see now what is saying uh
here let's see now what is saying uh
what we say has overhead still so this
what we say has overhead still so this
compute observations I see a very low
compute observations I see a very low
number of calls and a substantial
number of calls and a substantial
footprint but this makes sense the
footprint but this makes sense the
compute observation function is actually
compute observation function is actually
doing real
doing real
work so I'm actually pretty happy with
work so I'm actually pretty happy with
uh what is it quarter second or whatever
uh what is it quarter second or whatever
that's a perfectly valid thing this is
that's a perfectly valid thing this is
doing a bunch of
doing a bunch of
Loops this would be horribly
Loops this would be horribly
slow in uh python
and nearest scan Target is still .81
and nearest scan Target is still .81
that's a little weird uh let's go look
that's a little weird uh let's go look
at that
function I guess it gets does it get
function I guess it gets does it get
called a lot oh yeah this gets called a
called a lot oh yeah this gets called a
lot
lot
yeah uh so this is performance critical
yeah uh so this is performance critical
then because it gets called a lot
is there anything we can change with
is there anything we can change with
this or are we going to say that this is
this or are we going to say that this is
mostly call
mostly call
Overhead this 200 is hardcoded uh let me
Overhead this 200 is hardcoded uh let me
explain this function because this is
explain this function because this is
actually a kind of cool piece of tech
actually a kind of cool piece of tech
that I
that I
built so there's a scan
built so there's a scan
function we have a single allocated
function we have a single allocated
buffer for the whole program that gets
buffer for the whole program that gets
reused repeatedly and the pattern is
reused repeatedly and the pattern is
that you scan the nearby area in the
that you scan the nearby area in the
game for other enemies targets whatever
game for other enemies targets whatever
you want the scan function is very
you want the scan function is very
versatile and it fills up this buffer
versatile and it fills up this buffer
with targets and then you don't have to
with targets and then you don't have to
do a double Loop over your nearby
do a double Loop over your nearby
locations after that you just go through
locations after that you just go through
all the targets that the scan function
all the targets that the scan function
found and you uh you like use you get
found and you uh you like use you get
the Target or you filter It Whatever
the Target or you filter It Whatever
depending on which ones you want uh and
depending on which ones you want uh and
the logic is very clean for that so here
the logic is very clean for that so here
to get the nearest one you filtered the
to get the nearest one you filtered the
first time you went through all the
first time you went through all the
targets and now all you're going to do
targets and now all you're going to do
is you're going to compute the distance
is you're going to compute the distance
between the
between the
player uh and the target for each of
player uh and the target for each of
these
these
right uh I see one very small
right uh I see one very small
optimization that we can make
optimization that we can make
here only one that saves us two pointer
here only one that saves us two pointer
D references
let me see if there's anything else that
let me see if there's anything else that
I see I think this is going to be pretty
I see I think this is going to be pretty
negligible but we'll do it anyways just
negligible but we'll do it anyways just
to show
you you allocate the target here if it's
you you allocate the target here if it's
null we are
done if nearest Target is null
done if nearest Target is null
then nearest Target equals
then nearest Target equals
target
target
continue we can also avoid this check by
continue we can also avoid this check by
just setting nearest distance to be
just setting nearest distance to be
something
big okay there are a couple little
big okay there are a couple little
optimizations we can make
optimizations we can make
here CU I I think we're going to use
here CU I I think we're going to use
this function even more than we're using
this function even more than we're using
it now so it's worth taking a second to
it now so it's worth taking a second to
make uh a couple quick changes to this
so here for nearest scan Target we're
so here for nearest scan Target we're
going to say nearest distance equals
9999999 big
number now we no longer need to do
number now we no longer need to do
this because any distance will be better
this because any distance will be better
than this nearest distance so we save
than this nearest distance so we save
ourselves potentially 200 checks like
ourselves potentially 200 checks like
this and we also get to
this and we also get to
do uh we'll do
do uh we'll do
float uh
float uh
player Y and player X so now instead of
player Y and player X so now instead of
doing this pointer Target
doing this pointer Target
here we have these variables
here we have these variables
already right we get to reuse
already right we get to reuse
them then nearest Target is equal to
them then nearest Target is equal to
Target and nearest dist is equal to dist
Target and nearest dist is equal to dist
these are Pointers so this is
these are Pointers so this is
fast idx distance Yep this is all this
fast idx distance Yep this is all this
is all what we want
is all what we want
perfect one was it 081 before I think
perfect one was it 081 before I think
this is going to be a pretty negligible
this is going to be a pretty negligible
optimization but we did it
anyways we've got some much heavier
anyways we've got some much heavier
optimizations coming up every little bit
helps we'll run this perf
helps we'll run this perf
test grab our latest HTML
test grab our latest HTML
you can see
you can see
here that this is uh substantially
here that this is uh substantially
shorter
now actually that's not too bad we went
now actually that's not too bad we went
from 18 or whatever to
from 18 or whatever to
0.14 and given that this is actually
0.14 and given that this is actually
like close to the amount of overhead
like close to the amount of overhead
that I would expect like we probably
that I would expect like we probably
made this like twice as fast or
made this like twice as fast or
something because this is like this
something because this is like this
number here is not just the function
number here is not just the function
time it's also theun function call
time it's also theun function call
Overhead and we called it a bunch of
Overhead and we called it a bunch of
times so that's actually probably a
times so that's actually probably a
pretty decent little performance
pretty decent little performance
optimization 92,000 steps per second
um of course we have the same amount of
um of course we have the same amount of
overhead coming from the one python call
overhead coming from the one python call
which is kind of
which is kind of
obnoxious what the where the heck is
obnoxious what the where the heck is
that even coming from
actually that's like that's super
actually that's like that's super
obnoxious
obnoxious
oh it's coming from
oh it's coming from
this
this
yeah yeah that's going to happen the
yeah yeah that's going to happen the
while loop this tells you how slow
while loop this tells you how slow
python is though literally just this
python is though literally just this
like just this while loop right here
like just this while loop right here
which is optimized you can see that I
which is optimized you can see that I
pre-computed the actions and stuff this
pre-computed the actions and stuff this
is still like substantial overhead
is still like substantial overhead
Python's so
Python's so
slow so freaking slow I still love you
slow so freaking slow I still love you
python but you're slow
okay now compute observations has gone
okay now compute observations has gone
up but this is just the relative time
up but this is just the relative time
slice increasing because it's a fixed 10
slice increasing because it's a fixed 10
seconds I'm still very happy with. 3
seconds I'm still very happy with. 3
seconds for an a function that's that
seconds for an a function that's that
expensive like this does a lot under the
expensive like this does a lot under the
hood uh now we get to look at we only
hood uh now we get to look at we only
really have one two four functions plus
really have one two four functions plus
the step to look at here for
the step to look at here for
optimization this is where all the
optimization this is where all the
comput is going maybe basic attack but
comput is going maybe basic attack but
with this number of calls I don't think
with this number of calls I don't think
so
so
um in fact let me do that real quick
um in fact let me do that real quick
just because I I want to be sure that
just because I I want to be sure that
we're getting every little ounce that we
we're getting every little ounce that we
can
get
get
[Music]
attack where is it
attack where is it
bent basic yeah
yeah this is nothing this is this is
yeah this is nothing this is this is
purely call overhead
purely call overhead
right so we don't need to profile this
right so we don't need to profile this
whatsoever and then there's this attack
whatsoever and then there's this attack
function here which is this attack
function here which is this attack
function not uh more substantial so
function not uh more substantial so
attack not in here
attack not in here
anywhere where's
anywhere where's
attack oh way down here because it
attack oh way down here because it
doesn't get called as much
doesn't get called as much
right so let's
right so let's
see yeah basic attack gets called super
see yeah basic attack gets called super
often but it gets called on uh it gets
often but it gets called on uh it gets
called when it's on cool down or
called when it's on cool down or
whatever I
whatever I
guess so then attack only gets called
guess so then attack only gets called
you know much less often so the call
you know much less often so the call
Overhead is like negligible so let's uh
Overhead is like negligible so let's uh
let's add that real
quick uh oh what what
happened basic attack or bent
happened basic attack or bent
basic okay so we take the profiling off
basic okay so we take the profiling off
for this any of these like already
for this any of these like already
optimized functions
optimized functions
where we're looking it just call
where we're looking it just call
Overhead good idea
Overhead good idea
to know to to fix those
up this should bring us to about 100K I
up this should bring us to about 100K I
think maybe 100,000 steps per
think maybe 100,000 steps per
second on the profiled version by the
second on the profiled version by the
way with which is huge huge overhead so
way with which is huge huge overhead so
even though we're reducing the overhead
even though we're reducing the overhead
the overhead is still huge
the nice thing about these profile
the nice thing about these profile
decorators is when we just turn
decorators is when we just turn
profiling off globally they don't
profiling off globally they don't
interfere with anything so we won't have
interfere with anything so we won't have
to like get rid of them and uh
to like get rid of them and uh
93,000 I mean I guess there's some
93,000 I mean I guess there's some
variance in run to run did we get rid of
variance in run to run did we get rid of
basic attack overhead at least we
basic attack overhead at least we
did okay so this S Type loses .1 second
we'll look at that later I think this
we'll look at that later I think this
should already be the right type anyways
should already be the right type anyways
we'll see nearest scan
Target didn't we add a decorator to this
Target didn't we add a decorator to this
I wait I thought we said that nearest
I wait I thought we said that nearest
scan Target
was oh no we didn't exclude this
yet yeah we didn't exclude this yet
yet yeah we didn't exclude this yet
let's exclude this as
well because we already optimized it so
well because we already optimized it so
there's no point in timing it separately
there's no point in timing it separately
now this is already about as fast as it
now this is already about as fast as it
can
be that saves us
be that saves us
another another .1 seconds out of this
another another .1 seconds out of this
or another another percent on the per
or another another percent on the per
test at
test at
least just a function call
least just a function call
Overhead but like it's not that we're
Overhead but like it's not that we're
like this is kind of optimizing The
like this is kind of optimizing The
Benchmark not optimizing the program
Benchmark not optimizing the program
right now because we're removing
right now because we're removing
function call Overhead for the purpose
function call Overhead for the purpose
of profiling but the reason for this is
of profiling but the reason for this is
because it gives us more and more
because it gives us more and more
accurate profile information which then
accurate profile information which then
lets us actually optimize the things
lets us actually optimize the things
that matter so like here like this
that matter so like here like this
function we didn't even notice it in the
function we didn't even notice it in the
call time before but now we can see hey
call time before but now we can see hey
look it looks like there's actually
look it looks like there's actually
substantial overhead being incurred by
substantial overhead being incurred by
this move towards function let's see if
this move towards function let's see if
there's anything that we can actually
there's anything that we can actually
optimize there and we're going to go up
optimize there and we're going to go up
the stack this
the stack this
way so we
will move
will move
forwards this is moved
forwards this is moved
towards we can see that we have this
towards we can see that we have this
kind of gross uh condition
here we could put a table for this at
here we could put a table for this at
some point
this one's
this one's
tricky this one's actually kind of
tricky this is
tricky this is
definitely taking substantial
time and we just did we just take a move
time and we just did we just take a move
two
two
yeah so this is not including overhead
yeah so this is not including overhead
from new move
from new move
two so now we know for sure essentially
two so now we know for sure essentially
this function is slower than it should
this function is slower than it should
be
be
um these conditionals really shouldn't
um these conditionals really shouldn't
be that
slow is it this Rand right here
I was actually thinking of cashing
Jitter is that
crazy I don't think that's crazy right
crazy I don't think that's crazy right
to cash
to cash
Jitter so you don't have to do random
Jitter so you don't have to do random
number
manipulation do we even think it is the
manipulation do we even think it is the
Jitter though
it shouldn't be having to Jitter that
it shouldn't be having to Jitter that
often it could be that the Jitter is
often it could be that the Jitter is
really slow though right random number
really slow though right random number
called RNG is not
free you know you need some good
RNG we can figure that out very quickly
RNG we can figure that out very quickly
before we invest too much time
so all we have to do
is we go like this
is we go like this
right and let's see if this changes the
right and let's see if this changes the
uh the overall timing of this function
uh the overall timing of this function
it was 6 seconds before so if this time
it was 6 seconds before so if this time
plummets then we know that we're
plummets then we know that we're
basically we're using up all of the
basically we're using up all of the
compute and the infrequent Jitter
compute and the infrequent Jitter
operation so the Jitter is very slow and
operation so the Jitter is very slow and
then what I will do is I'll just
then what I will do is I'll just
pre-compute all the RNG for the whole
pre-compute all the RNG for the whole
program which is not hard to
do that's a really nice trick for folks
do that's a really nice trick for folks
by the way is to pre-compute RNG I do
by the way is to pre-compute RNG I do
this even in Python
this even in Python
sometimes interesting so it got faster
sometimes interesting so it got faster
but not by a huge
amount oh but wait the number of calls
amount oh but wait the number of calls
went
up what do you
up what do you
do to pre-compute RNG or what's the
do to pre-compute RNG or what's the
question
question
about what do you do to compute RNG or
about what do you do to compute RNG or
or is this like a new stream
question it went from
question it went from
6.4.6 seconds to
6.4.6 seconds to
to 85 at5 seconds so I'd say there's a
to 85 at5 seconds so I'd say there's a
pretty substantial time save
here I don't see a followup to that
here I don't see a followup to that
question I'm going to assume it was
question I'm going to assume it was
about the RNG so I will just show you
about the RNG so I will just show you
what I'm going to do for
what I'm going to do for
that um it's a very nice
that um it's a very nice
trick it's a very very nice trick
actually you get to replace an expensive
actually you get to replace an expensive
RNG call with a lookup
[Music]
and do I want to make it one dimensional
and do I want to make it one dimensional
or two I think 1D is probably
or two I think 1D is probably
better right yeah we'll do one
better right yeah we'll do one
D
so
so
float array
float array
RNG right
and then what we're going to do
is
is
int the
N so we're going to do self. RNG n
equals we want it to be a decent amount
equals we want it to be a decent amount
of RNG so that we have like some good
of RNG so that we have like some good
diversity in here 10K should be good
diversity in here 10K should be good
numpy
numpy
Rand RNG
Rand RNG
n
and yeah that's 0 to one RNG
and yeah that's 0 to one RNG
right was just making sure I didn't have
right was just making sure I didn't have
it confused with Rand
n so this Jitter right here
n so this Jitter right here
is-1 to 1
so RNG
n so we're going to do two
n so we're going to do two
times minus one so we're going to
times minus one so we're going to
pre-allocate this is essentially
pre-allocate this is essentially
pre-allocating
Kate yeah locate rng1 to one and now
Kate yeah locate rng1 to one and now
when we need
when we need
this it's pretty cool
oh we also forgot RNG n we need int RNG
oh we also forgot RNG n we need int RNG
idx so we need to keep track of where we
idx so we need to keep track of where we
are in the
are in the
RNG RNG idx is going to be
zero okay and now when we go to Rand
zero okay and now when we go to Rand
which is in Jitter
which is in Jitter
here uh now we get to do something
here uh now we get to do something
cool so Jitter
you see how that
you see how that
works now we do have to
works now we do have to
do uh an additional
do uh an additional
check which is
that equal 2
we have to do the modulo
here so this is a fast modulo you see
here so this is a fast modulo you see
what we
what we
did we replaced an expensive RNG
did we replaced an expensive RNG
call with a look up into a
call with a look up into a
table but the table's very
big now I have to be careful careful not
big now I have to be careful careful not
to overflow and a lot of other things
to overflow and a lot of other things
but it's not that
but it's not that
complicated and if you do it this
complicated and if you do it this
way we should get some speed out of
this we should get some
speed expected float got double whoops e
me forgetting the API of
course uh
C sayses
C sayses
type did the stream crash or something
type did the stream crash or something
why
why
is oh no my super Maven was just lagging
is oh no my super Maven was just lagging
that's
that's
fine we're good
and let's see what this gets us
to this should be a legitimate speed
to this should be a legitimate speed
optimization not just a compiler or a
optimization not just a compiler or a
profiling
optimization shouldn't be huge but it
optimization shouldn't be huge but it
should be
something huh
that didn't do very
much it is faster but only
much it is faster but only
marginally let's make sure we didn't
marginally let's make sure we didn't
screw up something with the
screw up something with the
um with the scyon
here
here
[Music]
[Music]
so Jitter X Jitter y
that's not super worth
it it's weird because it looked like
it it's weird because it looked like
before that this was where this the
before that this was where this the
slowness was coming
slowness was coming
from and I've seen this type of thing be
from and I've seen this type of thing be
a huge Boon
before well at least we know now that
before well at least we know now that
this is not where the slowness is coming
this is not where the slowness is coming
from
move two is a relatively fast
move two is a relatively fast
function we do have some additional
function we do have some additional
checks and stuff here and we have these
checks and stuff here and we have these
this series of checks and
this series of checks and
assignments we also have this
lookup
H maybe we'll figure this one out as we
H maybe we'll figure this one out as we
go through the other ones CU this is
go through the other ones CU this is
called by other
functions let's look at the bigger ones
functions let's look at the bigger ones
for now because I'm I'm drawing a blank
for now because I'm I'm drawing a blank
on
on
that so we have we have two very similar
that so we have we have two very similar
functions here and then we have a a
functions here and then we have a a
function that they both
function that they both
use so you see that this time here this
use so you see that this time here this
is cumulative
is cumulative
time so what this is saying is that scan
time so what this is saying is that scan
AOE doesn't call anything else that is
AOE doesn't call anything else that is
timed it's like all the time is spent in
timed it's like all the time is spent in
scan AOE but then creepe
scan AOE but then creepe
here there is like an additional second
here there is like an additional second
pretty much a full second in each of
pretty much a full second in each of
these a little more even um that is
these a little more even um that is
spent in other function calls and I can
spent in other function calls and I can
tell you right now that the majority of
tell you right now that the majority of
this is spent in scan AOE so basically
this is spent in scan AOE so basically
what this is telling us now is that of
what this is telling us now is that of
the N9 and a half seconds that we're
the N9 and a half seconds that we're
spending in this code we are spending
about
about
6.3 or something no I did that wrong
6.3 or something no I did that wrong
more than 6 seconds so more than I'd say
more than 6 seconds so more than I'd say
about 2third of the time of the whole
about 2third of the time of the whole
simulation is being spent on neutral and
simulation is being spent on neutral and
creep Ai and this is why having to
creep Ai and this is why having to
simulate enemy AI is evil because it's
simulate enemy AI is evil because it's
really hard to do
really hard to do
fast we spent a whole bunch of time
fast we spent a whole bunch of time
making sure that the pathf finding was
making sure that the pathf finding was
fast but there's still other stuff to to
fast but there's still other stuff to to
optimize so I think we're g to start
optimize so I think we're g to start
with they look to be about the
with they look to be about the
same speed let's start with the creep
AI so this is what creep AI looks
AI so this is what creep AI looks
like it's not calling back to uh to
like it's not calling back to uh to
python let's see if we get a rewin in
python let's see if we get a rewin in
the neutral
AI the neutral AI
AI the neutral AI
is also not calling back to python Okay
is also not calling back to python Okay
cool
cool
so what this is telling us then is
that because we're not profiling these
that because we're not profiling these
move towards functions and stuff the
move towards functions and stuff the
total time including movement and such
total time including movement and such
um outside of this scan AOE function is
um outside of this scan AOE function is
still quite substantial
and this is hard to optimize because
and this is hard to optimize because
this is just getting cold a ton of
this is just getting cold a ton of
times right this is getting
called 5 million
times so this this is running more than
times so this this is running more than
a million steps per second but it's
a million steps per second but it's
still going to hamstring us because
still going to hamstring us because
there's so many of the
Creeps and this is the thing that I was
Creeps and this is the thing that I was
most worried about having to optimize as
most worried about having to optimize as
well
um because it's reliant on some harder
um because it's reliant on some harder
to do
optimizations the easiest optimization
optimizations the easiest optimization
for this is frankly just to run the AI
for this is frankly just to run the AI
less often and to cash stuff in
here but we're going to need a better
here but we're going to need a better
breakdown of where time is being spent
breakdown of where time is being spent
I'm going to use the restroom real quick
I'm going to use the restroom real quick
I'll be back in one minute and then I if
I'll be back in one minute and then I if
we can make the AI like a few times
we can make the AI like a few times
faster we hit our million steps per
faster we hit our million steps per
second just based on that so if we just
second just based on that so if we just
cash something and Rec and compute AI
cash something and Rec and compute AI
stuff a little less often we'll hit our
stuff a little less often we'll hit our
million uh FPS just based on that so
million uh FPS just based on that so
I'll be right back and then we're going
I'll be right back and then we're going
to go do
that
e
e e
okay I should grab a drink and then
okay I should grab a drink and then
we'll be
good okay we're good for the next hour
good okay we're good for the next hour
I'll make I'll take a quick break and an
I'll make I'll take a quick break and an
hour to grab a shake and then other than
hour to grab a shake and then other than
that we are good until I don't know next
that we are good until I don't know next
four hours or
four hours or
whatever
so don't know why I even had these
so don't know why I even had these
headphones on they don't don't need them
um okay so right now the AI Rune is
um okay so right now the AI Rune is
every
every
frame it does an expensive scan
frame it does an expensive scan
operation where it looks in a nearby
operation where it looks in a nearby
area
area
and it looks
and it looks
for targets to go pathfind towards an
for targets to go pathfind towards an
agress if it finds one of these
agress if it finds one of these
targets then it checks if it's if it
targets then it checks if it's if it
finds one of these
finds one of these
targets then it looks for the nearest
targets then it looks for the nearest
one this is a good this is a relatively
one this is a good this is a relatively
fast
fast
function
function
and if it's close enough it will attack
and if it's close enough it will attack
that
that
Target
Target
otherwise it will path towards the
target if it doesn't find a
target if it doesn't find a
Target then it does this path finding
check and it then moves towards
check and it then moves towards
a specific uh position so the thing
a specific uh position so the thing
that's interesting about this to
that's interesting about this to
me is that almost none of this should
me is that almost none of this should
ever be getting
called because the neutrals the way the
called because the neutrals the way the
the AI is scripted at the moment nothing
the AI is scripted at the moment nothing
like nothing plays with the
like nothing plays with the
neutrals so let's see if that's
true according to
true according to
this the neutral AI SP spends 1.7
this the neutral AI SP spends 1.7
seconds just on itself on this function
seconds just on itself on this function
2.7 seconds
2.7 seconds
total we can assume that the additional
total we can assume that the additional
second is spent on scan
second is spent on scan
AOE which would line up very nicely with
AOE which would line up very nicely with
the other number but 1.7 seconds is
the other number but 1.7 seconds is
somehow being spent on this
function I can see that the attack
function I can see that the attack
function here
function here
it's not called very
it's not called very
often so this attack function shouldn't
often so this attack function shouldn't
be biasing it because we're calling
be biasing it because we're calling
attack in
here none of these other functions
here none of these other functions
should be
should be
interfering how the hell is it spending
interfering how the hell is it spending
1.7
1.7
seconds on these function
calls I mean that's three times the
calls I mean that's three times the
compute of the move towards oper which
compute of the move towards oper which
does everything
else am I looking at this right so
else am I looking at this right so
neutral AI
neutral AI
here right so the neutrals in this game
here right so the neutrals in this game
let me pull up the
GIF do you see these green things that
GIF do you see these green things that
are like respawning every so often but
are like respawning every so often but
they're not moving
they're not moving
otherwise those are the neutrals they
otherwise those are the neutrals they
only move for the most part if you go
only move for the most part if you go
get near them and interact with them
get near them and interact with them
which is very rarely happen like you see
which is very rarely happen like you see
every so often a green pixel will like
every so often a green pixel will like
get pulled in but it's very rare with
get pulled in but it's very rare with
the way that the scripts run right
the way that the scripts run right
now and it should be relatively
now and it should be relatively
efficient
so what should be happening is it runs f
so what should be happening is it runs f
it runs the scan AOE which is slow right
it runs the scan AOE which is slow right
we expect this to be
we expect this to be
slow we expect this to be very slow
slow we expect this to be very slow
actually found targets false
this is false so nothing happens this
this is false so nothing happens this
doesn't happen but
doesn't happen but
somehow according to this scan AOE which
somehow according to this scan AOE which
happens every single time is taking only
happens every single time is taking only
2.7 minus 1.7 is 1 second for this
2.7 minus 1.7 is 1 second for this
really expensive scan that goes through
really expensive scan that goes through
a whole bunch of
a whole bunch of
tiles
um and the rest of this code which
um and the rest of this code which
should be doing nothing is taking 1.7
seconds that's absurd that is
absurd how much of this could be
absurd how much of this could be
function call
function call
Overhead not that much
Overhead not that much
right because this move towards
right because this move towards
function which has some logic in it is
function which has some logic in it is
taking 6 seconds for almost the same
taking 6 seconds for almost the same
number of
number of
calls so basically at least a full
calls so basically at least a full
second of this total time here is uh is
second of this total time here is uh is
legitimate it's not just overhead call
Overhead what the heck would this
Overhead what the heck would this
possibly
be I wonder if it's these default args
I see Pi error occurred in
I see Pi error occurred in
here 1 Z one
one okay I'm getting a little bit
one okay I'm getting a little bit
suspicious here of these default args
suspicious here of these default args
it's possible that the parser is very
it's possible that the parser is very
slow for these it's the only thing I can
slow for these it's the only thing I can
think of that'd be a really funny
think of that'd be a really funny
low-level finding wouldn't it
only thing I can think of so B scan
only thing I can think of so B scan
AOE make sure we call it in the right
AOE make sure we call it in the right
order uh neutral
order uh neutral
AI
AI
neutral where's the stupid
thing
wait here's our signature
so we can do neutral
so we can do neutral
Vision
Vision
true
true
false friendly hostile creeps Towers
false friendly hostile creeps Towers
okay this is
okay this is
fine
fine
um I'm going to try something first
um I'm going to try something first
which is just found Target equals
which is just found Target equals
false and in principle this
should this shouldn't mean that you
should this shouldn't mean that you
spend less time in the spawn functions
spend less time in the spawn functions
right it should only mean that you spend
right it should only mean that you spend
less time in the other functions I also
less time in the other functions I also
I realized I did this in totally the
I realized I did this in totally the
wrong place I screwed that up let me put
wrong place I screwed that up let me put
it over here it should be in not inan
it over here it should be in not inan
AOE it should be in neutral
AOE it should be in neutral
AI right up
AI right up
here oh no wait
here oh no wait
what yeah this this goes away yeah I
what yeah this this goes away yeah I
have this as an an just as a hint to
have this as an an just as a hint to
myself okay perfect so yeah what happens
myself okay perfect so yeah what happens
if we do
if we do
this this will be interesting no matter
this this will be interesting no matter
what it tells
us there's a like there's a bunch of
us there's a like there's a bunch of
performance just going into the ether
performance just going into the ether
here and uh we're going to get it back
interesting
so the creep AI is now 2.6 second total
so the creep AI is now 2.6 second total
time creep AI time has gone up which
time creep AI time has gone up which
makes sense because proportionately it
makes sense because proportionately it
has a bigger time slice
has a bigger time slice
available neutral AI was 1.7 second
available neutral AI was 1.7 second
total time 2.7
cumulative and it went down all the way
cumulative and it went down all the way
to7
to7
second uh cumul uh total and obviously
second uh cumul uh total and obviously
cumulative wait did I do that right no
cumulative wait did I do that right no
right here basically same
right here basically same
thing and move towards went up a little
thing and move towards went up a little
bit so what this means is
bit so what this means is
that it's something about the found
that it's something about the found
Target true path or about the call to
Target true path or about the call to
the function itself so that's some
the function itself so that's some
really nice little archaeology to do
really nice little archaeology to do
there now what we're going to do is the
there now what we're going to do is the
more aggressive version of
more aggressive version of
this we're going to do which is uh we're
this we're going to do which is uh we're
going to call the function but we're
going to call the function but we're
going to call it without these default
going to call it without these default
args like this we're going to call it
args like this we're going to call it
with raw bulls and we're going to see
with raw bulls and we're going to see
what what happens if we do
that I did see some things on uh online
that I did see some things on uh online
about default args being and
about default args being and
wonk but it didn't show up in the HTML
wonk but it didn't show up in the HTML
which is
weird didn't show up in the HTML let's
weird didn't show up in the HTML let's
see I give this 50/50 chance that we get
see I give this 50/50 chance that we get
something interesting out of
this and if this works this one
this and if this works this one
optimization will basically be enough to
optimization will basically be enough to
save us maybe we'll a little on the scan
save us maybe we'll a little on the scan
AOE okay interestingly this went right
AOE okay interestingly this went right
back up to where this was
before went right back up to where it
before went right back up to where it
was
before okay next
before okay next
test maybe there's just like a very slow
test maybe there's just like a very slow
computational Branch
computational Branch
right maybe that branch is just really
right maybe that branch is just really
slow so um we'll
do found Target is here we scan for it
do found Target is here we scan for it
we determine that these args are
we determine that these args are
actually parsed fine and set it to false
actually parsed fine and set it to false
afterwards let's make it take the uh the
afterwards let's make it take the uh the
other branch that we know is is good
other branch that we know is is good
right
now if we make it take the other Branch
now if we make it take the other Branch
like this
then we get
okay it's about the same
so that's kind of
Bizarro let me just let me just put into
Bizarro let me just let me just put into
words what this means
words what this means
so if we set if we set this function to
so if we set if we set this function to
just be nulled out right then it not
just be nulled out right then it not
only says that you're not spending a
only says that you're not spending a
second calling the function which is
second calling the function which is
obvious but but it also says that you
obvious but but it also says that you
save a second of execution off of the
save a second of execution off of the
rest of your function excluding that so
rest of your function excluding that so
somehow I think that the call itself is
slow it shouldn't be a whole second of
slow it shouldn't be a whole second of
overhead slow that's
ridiculous what's unique about this
ridiculous what's unique about this
function BNS aren't slow are
they maybe we open up the h HTML
again right here
again right here
right
right
so entity star
so entity star
neutral this is a
constant entity star or found
constant entity star or found
Target wait
Target wait
what pi t
struct V table oh this is just a class
struct V table oh this is just a class
method this is
fine so this is essentially self this
fine so this is essentially self this
whole giant thing is
whole giant thing is
self this is self
dot scan AOE is our
dot scan AOE is our
function self
function self
neutral this is a
neutral this is a
constant and you can see it compiles
constant and you can see it compiles
here
here
to reasonable
args what the heck is
args what the heck is
this if unlikely Pi error
occurred does not everything has these
occurred does not everything has these
things right oh no wait this does still
things right oh no wait this does still
have it if unlikely Pi a error
have it if unlikely Pi a error
occurred well that's just function
call very
weird well we absolutely need to figure
weird well we absolutely need to figure
this out this is like the main blocker
this out this is like the main blocker
right now
right now
right the main blocker
oh I have an
oh I have an
idea I have a cool
idea I have a cool
idea let's just eliminate any chance
idea let's just eliminate any chance
that this is just some weird scon
that this is just some weird scon
[ __ ] because you know it's
[ __ ] because you know it's
happened let's do neutral AI instead of
happened let's do neutral AI instead of
making this thing false here let's go
making this thing false here let's go
back to the original call
back to the original call
right but then what we're going to do is
right but then what we're going to do is
we're going to make scan AO we just
we're going to make scan AO we just
return
false right here return
false and that will immediately tell us
false and that will immediately tell us
if the profiler is just screwy or
if the profiler is just screwy or
something's going weird or what because
something's going weird or what because
weirder things have happened
okay
okay
so that's interesting
so that's interesting
um the neutral AI here
is actually still
slow it's actually still
slow it's actually still
slow it's got 6 million function
calls
and 1.4
and 1.4
seconds versus since this gave us the
seconds versus since this gave us the
reasonable result I'm going
reasonable result I'm going
to I'm going to compare this
to I'm going to compare this
to not the function call
right which is right
right which is right
here and we're just going to do found
here and we're just going to do found
Target is equal to false
right so from one point uh what was it 1
right so from one point uh what was it 1
point4
to
0.4 is this actually the amount of
0.4 is this actually the amount of
overhead that's being added
overhead that's being added
by the function
by the function
call I don't want to be wasting my time
call I don't want to be wasting my time
if I'm just profiling function call
if I'm just profiling function call
Overhead but it seems like it's an
Overhead but it seems like it's an
abnormal amount of function call
Overhead let me look at you know what I
Overhead let me look at you know what I
should
should
do so this doesn't come up as having
do so this doesn't come up as having
overhead here what I want to do is I
overhead here what I want to do is I
want to go look at the scan AOE fun
function so it's got a big
signature it's got the trace back
here
okay so new hypothesis right
okay so new hypothesis right
maybe because this thing takes a bunch
maybe because this thing takes a bunch
of arguments and stuff the function call
of arguments and stuff the function call
Overhead for this is just especially
Overhead for this is just especially
bad if that's what we think is happening
here the next best thing we can
here the next best thing we can
do is uh we can eliminate the function
do is uh we can eliminate the function
call Overhead and see if there's still
call Overhead and see if there's still
something weird so scan AOE we know it
something weird so scan AOE we know it
now returns
oops where is it so we're going to call
oops where is it so we're going to call
it from here we're not going to just set
it from here we're not going to just set
it to
false where is it B scan AOE okay and
false where is it B scan AOE okay and
we're just going to we're going to add
we're just going to we're going to add
The Decorator to it now we can't keep
The Decorator to it now we can't keep
this decorator here because this
this decorator here because this
function we also need to
function we also need to
optimize uh this is probably the single
optimize uh this is probably the single
most performance critical function in
most performance critical function in
the code base I've saved the best for
the code base I've saved the best for
last which is the opposite of how you're
last which is the opposite of how you're
supposed to do profile in but you know
supposed to do profile in but you know
whatever I just want to see if
whatever I just want to see if
like the whole thing gets to be way
like the whole thing gets to be way
faster just by cutting out these
faster just by cutting out these
function
calls and we're cutting out the python
calls and we're cutting out the python
overhead to the function calls not the
overhead to the function calls not the
function calls themselves
133,000 steps per
second yeah that's substantially
faster so there's definitely something
faster so there's definitely something
about the the overhead
about the the overhead
itself so now we know okay 7
itself so now we know okay 7
Seconds right 7 seconds is what we're
Seconds right 7 seconds is what we're
taking for 9.6
taking for 9.6
million 9.6 million
million 9.6 million
calls and now what we're going to do is
calls and now what we're going to do is
we're going to look at
we're going to look at
whoops getting
there we're going to give it the full
there we're going to give it the full
function but with no signature
function but with no signature
so we're not going to be able to see the
so we're not going to be able to see the
breakdown but we're going to get
breakdown but we're going to get
accurate
accurate
profiling where we're not just profiling
profiling where we're not just profiling
expensive function call Overhead the
expensive function call Overhead the
main annoyance with profiling this
main annoyance with profiling this
stuff okay
okay so this is substantially better
actually the proportion of time has
actually the proportion of time has
decreased quite a bit there was
decreased quite a bit there was
essentially a whole second of overhead
essentially a whole second of overhead
being added
being added
to I think to both functions
to I think to both functions
maybe just from the call Signature
itself so
let's see from here so the creep AI it
let's see from here so the creep AI it
sticks out to me that the creep AI is
sticks out to me that the creep AI is
substantially slower than the neutral AI
substantially slower than the neutral AI
they're fewer creeps than neutrals
they're fewer creeps than neutrals
they're both calling a scan AOE once per
they're both calling a scan AOE once per
frame and uh the fact that the creep AI
frame and uh the fact that the creep AI
is still that much slower means that the
is still that much slower means that the
other pathing stuff is
substantial that move towards especially
substantial that move towards especially
right there needs to be optimized a
bit well
bit well
maybe
maybe
2.9 have you done much Unity much with
2.9 have you done much Unity much with
unity AI agents no I've done stuff with
unity AI agents no I've done stuff with
unity though and I've done stuff with AI
unity though and I've done stuff with AI
and unity and AI in AI but not with
and unity and AI in AI but not with
their ml agents
their ml agents
API
API
um here I'll show you the the format
um here I'll show you the the format
that I advocate for not Advocate but the
that I advocate for not Advocate but the
format I suggest
format I suggest
rather if you want to do stuff like
rather if you want to do stuff like
that the thing you want out of unity is
that the thing you want out of unity is
usually a nice front
usually a nice front
end for
end for
RL you can do that like
RL you can do that like
this here's a Unity front end for neural
this here's a Unity front end for neural
MMO I
MMO I
wrote
wrote
um the game environment is not written
um the game environment is not written
in unity the game environment is written
in unity the game environment is written
in whatever else you want you do a
in whatever else you want you do a
websocket server or whatever that will
websocket server or whatever that will
then send all of the data packets
then send all of the data packets
required to render to the to Unity and
required to render to the to Unity and
then you use Unity just for rendering
then you use Unity just for rendering
purposes so you essentially you strongly
purposes so you essentially you strongly
decouple the simulator from the uh the
decouple the simulator from the uh the
unity engine otherwise like if we want
unity engine otherwise like if we want
to talk about speed for things um well I
to talk about speed for things um well I
guess it depends on how you're
guess it depends on how you're
implementing stuff but most of the time
implementing stuff but most of the time
Unity is just going to be like the
Unity is just going to be like the
slowest possible imaginable for
slowest possible imaginable for
simulators technically it's possible to
simulators technically it's possible to
write fast simulators in unity but if
write fast simulators in unity but if
you're just like writing like writing
you're just like writing like writing
stuff like you do normal Game Dev in
stuff like you do normal Game Dev in
unity you're going to be about a
unity you're going to be about a
thousand times too slow to be useful
if you write uh efficient state
if you write uh efficient state
simulations in unity with headless so
simulations in unity with headless so
you decouple the rendering then it's
you decouple the rendering then it's
possible but you still have to go
possible but you still have to go
through their API so you have to get the
through their API so you have to get the
data into Python
data into Python
and that's hard to do efficiently if you
and that's hard to do efficiently if you
do it with I think what their default is
do it with I think what their default is
you're losing again like more than 99%
you're losing again like more than 99%
of your performance
immediately Next Step here is going to
immediately Next Step here is going to
be to uh remove move towards from the
be to uh remove move towards from the
profile just so we get an
absolute we need to know for sure that
absolute we need to know for sure that
we're not measuring function call
we're not measuring function call
Overhead and then this will give us like
Overhead and then this will give us like
the
the
final actual uh per performance overhead
final actual uh per performance overhead
of
everything yeah this should give us like
everything yeah this should give us like
everything that we need from from this
uh build X
compute
compute
observations okay this is taking up a
observations okay this is taking up a
bigger slice of time which is actually
bigger slice of time which is actually
probably good because this is means that
probably good because this is means that
the other overhead is
the other overhead is
lower we now have what's this 13 million
lower we now have what's this 13 million
in 1.7 seconds creep AI versus before we
in 1.7 seconds creep AI versus before we
had 10 million and about the same so
had 10 million and about the same so
like 30% of this was just a function
like 30% of this was just a function
call Overhead it looks
like and now we actually get like a good
like and now we actually get like a good
picture
picture
of how much what stuff is taking what
of how much what stuff is taking what
amount of
amount of
time
so optimization on movement function
so optimization on movement function
optimization on scan function and
optimization on scan function and
caching is what we get to which is I
caching is what we get to which is I
expected that we would get to
expected that we would get to
today but we've basically confirmed that
today but we've basically confirmed that
at this point there's nothing else that
at this point there's nothing else that
I've really majorly screwed up the
I've really majorly screwed up the
design of everything is pretty solid and
design of everything is pretty solid and
uh the only thing that we are really
uh the only thing that we are really
really missing
really missing
is a few optimizations maybe on movement
is a few optimizations maybe on movement
and scanning and then
and scanning and then
cashing that's about
cashing that's about
all take a quick 30 seconds to clear my
all take a quick 30 seconds to clear my
head here and then we're going to ramp
head here and then we're going to ramp
up for this last uh this last little
up for this last uh this last little
push before I take a 5 minutes to make
push before I take a 5 minutes to make
uh lunch but we're going to do this
uh lunch but we're going to do this
first we're going to get our uh our
first we're going to get our uh our
efficiency and then the hope is that
efficiency and then the hope is that
after lunch I can come back um and do
after lunch I can come back um and do
the reinforcement learning side of
the reinforcement learning side of
things we're already at by the way here
things we're already at by the way here
we're at 189,000 steps per second with
we're at 189,000 steps per second with
some profiling overhead this is what we
some profiling overhead this is what we
had before with no profiling overhead so
had before with no profiling overhead so
we're probably doing pretty well and
we're probably doing pretty well and
then the caching thing is what's really
then the caching thing is what's really
going to make this uh this thing pop uh
going to make this uh this thing pop uh
a few things for viewers at the
a few things for viewers at the
moment again it's all open source I say
moment again it's all open source I say
this once every so often it's all on
this once every so often it's all on
puffer lib right here it's in the any
puffer lib right here it's in the any
config Branch it'll be merged into Dev
config Branch it'll be merged into Dev
soon it's in puffer lib environments
soon it's in puffer lib environments
ocean you can play with it everything
ocean you can play with it everything
that you see today will be merged up by
that you see today will be merged up by
the uh the end of the stream if you like
the uh the end of the stream if you like
my work please Star Puffer lib helps me
my work please Star Puffer lib helps me
out a whole bunch
out a whole bunch
I also post all this stuff online on
I also post all this stuff online on
Twitter it's strictly for AI stuff so
Twitter it's strictly for AI stuff so
that's
that's
here and
here and
uh yeah you can see it's all like demos
uh yeah you can see it's all like demos
of code and
of code and
stuff
stuff
okay let's go back
okay let's go back
to the optimization stream now
oops
so I want to look at
so I want to look at
the the code for this
here cuz we have some functions that we
here cuz we have some functions that we
can potentially get a little bit more
can potentially get a little bit more
juice out of before we start
juice out of before we start
caching are you currently working on
caching are you currently working on
puffer lib full-time yep
puffer lib full-time yep
absolutely at least fulltime you could
absolutely at least fulltime you could
say um so definitely the uh the exposure
say um so definitely the uh the exposure
to stuff helps a ton I'm really trying
to stuff helps a ton I'm really trying
my best here to fix all the things that
my best here to fix all the things that
are cursed in reinforcement learning and
are cursed in reinforcement learning and
uh part of that is the simulation stuff
uh part of that is the simulation stuff
you see that I've been streaming lately
you see that I've been streaming lately
I've got stuff with Hyper pram tuning
I've got stuff with Hyper pram tuning
I've got stuff with like widespread
I've got stuff with like widespread
environment compatibility with puffer Li
environment compatibility with puffer Li
I've got super fast CPU vectorization
I've got super fast CPU vectorization
and it's moving crazy fast as well the
and it's moving crazy fast as well the
progress in the last two months has been
progress in the last two months has been
has been nuts
it's all free an open source as
well e
this function is
fine here's the big one right
here so what this function
does this
function goes through all of the tiles
function goes through all of the tiles
nearby in a
nearby in a
radius it looks for entities on those
radius it looks for entities on those
tiles and then it filters them
tiles and then it filters them
according to any specific criteria that
according to any specific criteria that
you
you
specify so you can specify you know all
specify so you can specify you know all
these different
criteria and based on that you can
filter let me think if I like this or
not is there a chance we see carbs
not is there a chance we see carbs
supported with WB sweeps from WB correct
supported with WB sweeps from WB correct
directly so let me tell you what
directly so let me tell you what
happened with that um I posted all the
happened with that um I posted all the
stuff i' been doing I added WB and MB a
stuff i' been doing I added WB and MB a
bunch on Twitter I got like four DMS
bunch on Twitter I got like four DMS
from WB people wanting to integrate
from WB people wanting to integrate
it uh I we sent some emails back and
it uh I we sent some emails back and
forth and then they stopped
forth and then they stopped
responding which was like weird because
responding which was like weird because
it looked like we were going to set up
it looked like we were going to set up
some meetings and then I got a DM from
some meetings and then I got a DM from
another guy at wandb saying that
another guy at wandb saying that
uh like something weird happened and
uh like something weird happened and
like our emails just never went through
like our emails just never went through
to each other or something because they
to each other or something because they
thought that I'd ghosted two meetings
thought that I'd ghosted two meetings
with them that I'd never set
with them that I'd never set
up so somehow some wires got crossed and
up so somehow some wires got crossed and
we didn't end up setting up any meetings
we didn't end up setting up any meetings
I should revisit that but I'll tell you
I should revisit that but I'll tell you
what I did
what I did
do I sent them a very nice
doc so I sent them you know Pono I sent
doc so I sent them you know Pono I sent
them this
them this
like thing for General improvements with
like thing for General improvements with
sweeps that would help as well as a
sweeps that would help as well as a
guide on carbs integration for what they
guide on carbs integration for what they
would need to add it native and I linked
would need to add it native and I linked
the uh the current integration with
the uh the current integration with
puffer which the current puffer
puffer which the current puffer
integration is not bad so that's the
integration is not bad so that's the
current state of
current state of
things carbs is
things carbs is
awesome I hope that they do
it be a really smart thing for them to
it be a really smart thing for them to
do
let me think about the design of this
let me think about the design of this
function a little bit more how many
function a little bit more how many
times do I use this scan
times do I use this scan
AOE I use it in player AOE
AOE I use it in player AOE
attack AE
push Tower AI neutral
push Tower AI neutral
AI creep okay so I see why I did this I
AI creep okay so I see why I did this I
used this five separate
used this five separate
times and other I would have had to have
times and other I would have had to have
written out like five separate uh 2D
written out like five separate uh 2D
Loops like this
right little obnoxious though because
right little obnoxious though because
like it does require you go two passes
like it does require you go two passes
over the data doesn't
it it kind of does require you to do two
it it kind of does require you to do two
passes over the data
they're actually a couple things I don't
they're actually a couple things I don't
like about
like about
this I don't like that you have this
this I don't like that you have this
giant list of filter
giant list of filter
options in
here I don't like that you have to check
here I don't like that you have to check
every single filter option even the ones
every single filter option even the ones
you're not
using these checks actually matter this
using these checks actually matter this
is like this is the most called piece of
is like this is the most called piece of
code in the entire project so like every
code in the entire project so like every
even like even every if statement
even like even every if statement
matters here
I'm I know that if I were to write out
I'm I know that if I were to write out
all the code for
all the code for
this if I were to just like time these
this if I were to just like time these
Loops like mess with the indexing a
Loops like mess with the indexing a
little bit make sure that was
little bit make sure that was
optimal and then just copy paste the
optimal and then just copy paste the
loop structure into every place I'm
loop structure into every place I'm
using scan AOE right
now it would work at the price of being
now it would work at the price of being
gross and adding like another 100 lines
gross and adding like another 100 lines
of code to the project
this function might be one of those
this function might be one of those
things that I thought was smart but
things that I thought was smart but
ended up being dumb
if you think about it it's
if you think about it it's
like it's really not acceptable to be
like it's really not acceptable to be
doing a second Passover your data
right like to be
right like to be
Computing applying all of these
Computing applying all of these
filters and doing a second Passover your
data this is a go slow to go fast moment
data this is a go slow to go fast moment
um I need to really think about this
um I need to really think about this
this is a big big thing with the project
this is a big big thing with the project
this is this is the single most
this is this is the single most
performance critical thing with the
performance critical thing with the
whole project and actually with most
whole project and actually with most
projects of this type
there's actually more to it than just
there's actually more to it than just
this as well isn't there
let me explain what's going on my head
let me explain what's going on my head
here because there's a lot that's not
here because there's a lot that's not
apparent just from this piece of code
apparent just from this piece of code
and how complicated some of this stuff
and how complicated some of this stuff
is
here
here
so
so
this this is a representation decision
this this is a representation decision
this is a decision about how we
this is a decision about how we
represent
represent
fundamentally how we represent and
fundamentally how we represent and
access data in the
access data in the
simulator the way that I have it right
simulator the way that I have it right
now everything at under the hood gets
now everything at under the hood gets
discretized onto a
discretized onto a
grid so you have a continuous position
grid so you have a continuous position
but you also have a position variant
but you also have a position variant
that's discretized to a
that's discretized to a
grid and only one thing can occupy any
grid and only one thing can occupy any
grid cell at any one time so what that
means is that you have a very uh very
means is that you have a very uh very
fast way of checking for entities nearby
fast way of checking for entities nearby
you whether you want to attack them
you whether you want to attack them
whether you want to do Collision checks
whether you want to do Collision checks
anything like that very very easy
anything like that very very easy
because you can just check nearby grid
because you can just check nearby grid
cells which is what this is doing
cells which is what this is doing
and you can go through the agents that
and you can go through the agents that
you find
you find
there the place where this scales very
there the place where this scales very
poorly is with larger distance
poorly is with larger distance
ranges so the way that I have this right
ranges so the way that I have this right
now the farthest that anything is seeing
now the farthest that anything is seeing
in the game is five squares it's like
in the game is five squares it's like
five player lengths it's very
five player lengths it's very
short and trying to make it larger than
short and trying to make it larger than
that is quadratically
that is quadratically
bad quadratically bad very very
bad quadratically bad very very
bad the problem though is that the
bad the problem though is that the
alternative is also
alternative is also
hard because the
hard because the
alternative is that you have to go
alternative is that you have to go
through all of the entities in the game
through all of the entities in the game
which I have them I have them in a nice
which I have them I have them in a nice
big data struct I could iterate through
big data struct I could iterate through
them but there are like 200 of them I
believe in mind you you always have to
believe in mind you you always have to
do distance checks as well if you do it
do distance checks as well if you do it
this way because if you do it that way
this way because if you do it that way
right you don't get the benefit of
right you don't get the benefit of
saying I know that everything that I
saying I know that everything that I
just found is within a square so you
just found is within a square so you
always have to do distance
always have to do distance
checks let me see precisely how many
checks let me see precisely how many
entities it
is actually this is in the uh the
is actually this is in the uh the
python okay so we
python okay so we
have slightly over 200 I have a buffer
have slightly over 200 I have a buffer
of 100 creeps that will probably need to
of 100 creeps that will probably need to
be
be
increased we could say it's like 256 or
increased we could say it's like 256 or
something to be cheeky will be the
something to be cheeky will be the
maximum
maximum
number
um if I did it that
way all of the targeting would be
way all of the targeting would be
directly on
agents I wouldn't have to do any index
agents I wouldn't have to do any index
calculations those are cheap anyways
calculations those are cheap anyways
though I wouldn't really have to look up
though I wouldn't really have to look up
player IDs either because I'd just be
player IDs either because I'd just be
directly iterating over the grid I mean
directly iterating over the grid I mean
over the entity
list
list
um but I don't think I could do it
um but I don't think I could do it
naively
I also think I still probably wouldn't
I also think I still probably wouldn't
use a function like this to scan
them because if I use a function like
them because if I use a function like
this to scan them you still have to go
this to scan them you still have to go
over them twice
right also um getting like the
right also um getting like the
nearest like the nearest K or whatever
nearest like the nearest K or whatever
is really hard when you do it this way
because like if I were to um I can just
because like if I were to um I can just
change the loop order essentially to
change the loop order essentially to
iterate
iterate
outwards if I wanted to do an
outwards if I wanted to do an
approximate like
approximate like
nearest nearest Elements want thing I
nearest nearest Elements want thing I
could do
that but I would lose that if I did
that but I would lose that if I did
entity based reversal
entity based reversal
now there are data structures to help
now there are data structures to help
you with this right there are like quad
you with this right there are like quad
trees and
trees and
stuff which can make this
stuff which can make this
from uh an O of n to an O of log n
from uh an O of n to an O of log n
process which is way better on paper but
process which is way better on paper but
the constant Factor matters a
the constant Factor matters a
lot and updating that data structure
lot and updating that data structure
matters a lot how fast you update it and
matters a lot how fast you update it and
such
C quad
tree 22 lines of
code yeah this is this is how you would
code yeah this is this is how you would
do it efficiently
where's all the
code where's your 22 lines of
code Lea notes contain multiple points
uhh recursive
thing I don't like this one
this is like a
this is like a
big a big difference though with the way
big a big difference though with the way
that I represent
that I represent
things well I think regardless you still
things well I think regardless you still
need to maintain a GD right regardless
need to maintain a GD right regardless
you still need to maintain a
grid this is worth spending a little bit
grid this is worth spending a little bit
more time on than I intended to today um
more time on than I intended to today um
even if it means I only get a little bit
even if it means I only get a little bit
of RL in at the end
of RL in at the end
because this is where you really make or
because this is where you really make or
break the perf of the game and this is
break the perf of the game and this is
actually something that's been holding
actually something that's been holding
back like this is the thing that holds
back like this is the thing that holds
back like entire classes of simulators
back like entire classes of simulators
at the moment is um entity parsing of
at the moment is um entity parsing of
this
this
variety
so yeah
so yeah
it's a big
deal the thing is like the algorithmic
deal the thing is like the algorithmic
complexity of this is not
complexity of this is not
trivial like conceptually a quadry is
trivial like conceptually a quadry is
not that complicated of a data structure
not that complicated of a data structure
it's just you recursively partition
it's just you recursively partition
space
space
up
up
um you just recursively partition space
um you just recursively partition space
up so that you're not Computing stuff
up so that you're not Computing stuff
over a ton of
over a ton of
entities now
entities now
I don't actually need to do that right
I don't actually need to do that right
like I don't need recursive
partitioning
partitioning
well it's not about it being recursive I
well it's not about it being recursive I
don't need infinite partitioning I
don't need infinite partitioning I
actually how many times do I need to cut
actually how many times do I need to cut
up the
up the
grid if I have 128 by 128
grid if I have 128 by 128
grid
right then if I cut it once I have 6 I
right then if I cut it once I have 6 I
have 64
have 64
eight that's probably good enough four
eight that's probably good enough four
layers and the reason I say that four
layers and the reason I say that four
layers is because
layers is because
what you would do is you would
what you would do is you would
check you would go through all of the
check you would go through all of the
entities that are in your 8 by8 and all
entities that are in your 8 by8 and all
neighboring 8 by 8s and then do distance
neighboring 8 by 8s and then do distance
checks on
checks on
them so essentially you're doing um 24x
them so essentially you're doing um 24x
24 tile
24 tile
chunks is the way that you would do this
efficiently how many entities are going
efficiently how many entities are going
to be in 24th tile
chunks no more than 50
chunks no more than 50
right on
right on
average
average
15 how many checks do you have to do for
15 how many checks do you have to do for
this
depends how it's implemented
right what's the structure for the leaf
right what's the structure for the leaf
node

Kind: captions
Language: en
okay we are
live give the streams a second to warm
up we're going to do some fun stuff
okay uh let's we're going to do some fun
okay uh let's we're going to do some fun
stuff
stuff
today today is going to be a fun Dev
today today is going to be a fun Dev
day we've been doing a lot of grindy
day we've been doing a lot of grindy
infra and we're going to do some fun
infra and we're going to do some fun
stuff which is slightly different grindy
stuff which is slightly different grindy
infrastructure but still it's going to
infrastructure but still it's going to
be more
be more
fun now where did I put hold on let me
fun now where did I put hold on let me
get the gift from
yesterday we're going to take a look
yesterday we're going to take a look
let's take a look at the uh the previous
let's take a look at the uh the previous
or is it
or is it
open by
open by
location okay so this is what we did
location okay so this is what we did
yesterday we got them playing the full
yesterday we got them playing the full
game
I'm going to retweet this thing out and
I'm going to retweet this thing out and
then what we're going to do today is
then what we're going to do today is
we're actually going to pay the piper
we're actually going to pay the piper
and we're going to make this thing
and we're going to make this thing
actually be a million FPS like the
actually be a million FPS like the
stream title says and we're going to
stream title says and we're going to
start on the RL
side tweet did okay this is going to be
side tweet did okay this is going to be
a good test
though e
I want to see what happens if I tweet
I want to see what happens if I tweet
this without the link if it actually
this without the link if it actually
does
does
better also last thing before before we
better also last thing before before we
start on proper Dev Twitter is so
start on proper Dev Twitter is so
weird like this is the second time this
weird like this is the second time this
has happened where I've just made some
has happened where I've just made some
like dumb funny comment on something and
like dumb funny comment on something and
it's just completely blown up Beyond
it's just completely blown up Beyond
like any of
like any of
my any of my other things and then you
my any of my other things and then you
can't use it for anything like I can't
can't use it for anything like I can't
comment underneath it like any of my
comment underneath it like any of my
other stuff it gets no promotion
other stuff it gets no promotion
whatsoever it's so funny how that works
whatsoever it's so funny how that works
internet is weird Okay so the plan for
internet is weird Okay so the plan for
today
today
I see we've got a couple people watching
I see we've got a couple people watching
this already that's great um the plan
this already that's great um the plan
for today is we're going to pay the
for today is we're going to pay the
piper and I've been advertising that I
piper and I've been advertising that I
will make this thing 1 million FPS today
will make this thing 1 million FPS today
I'm actually going to make it 1 million
I'm actually going to make it 1 million
FPS and you're going to get to see
FPS and you're going to get to see
exactly how I do
exactly how I do
that it's going to
that it's going to
be uh some algorithmic optimization but
be uh some algorithmic optimization but
for the most part it's going to be
for the most part it's going to be
making all of the tight Loops in scon
making all of the tight Loops in scon
run natively in C without ever calling
run natively in C without ever calling
back to
back to
python uh there might be a few little
python uh there might be a few little
hitches here and there but I've done
hitches here and there but I've done
this process with a number of other
this process with a number of other
environments so that's why I was
environments so that's why I was
confident like claiming 1 million FPS
confident like claiming 1 million FPS
before I got it because it's absolutely
before I got it because it's absolutely
going to be 1 million FPS
going to be 1 million FPS
now starting on
dev first thing we are going to do we're
dev first thing we are going to do we're
going to open up this setup.py and make
going to open up this setup.py and make
sure we have annot on which is here this
sure we have annot on which is here this
tells us when we recompile stuff this
tells us when we recompile stuff this
tells us exactly where it is calling
tells us exactly where it is calling
back from scon to python so this is
back from scon to python so this is
where you're getting all your slowdowns
where you're getting all your slowdowns
from here so we're going to start with
from here so we're going to start with
this and we've got cmob pix which is our
this and we've got cmob pix which is our
file and we're also going
file and we're also going
to there's one other thing we have to do
scon has all these checks at the top
scon has all these checks at the top
these are your don't shoot yourself in
these are your don't shoot yourself in
the foot checks this is what makes it
the foot checks this is what makes it
not as painful to Devon as C for
not as painful to Devon as C for
instance and uh we're basically just
instance and uh we're basically just
going to remove all the safeties because
going to remove all the safeties because
the safeties will make it call back to
the safeties will make it call back to
python C division we leave as
python C division we leave as
true so now we're not checking in if we
true so now we're not checking in if we
like accidentally have values that are
like accidentally have values that are
none we're not checking array indexing
none we're not checking array indexing
errors that like python Toyon we're not
errors that like python Toyon we're not
doing uh things being uninitialized
doing uh things being uninitialized
we're not doing any bounce checks
we're not doing any bounce checks
okay and we're going to
recompile and hopefully it does not
recompile and hopefully it does not
crash sometimes there are like
crash sometimes there are like
optimization specific things that can
optimization specific things that can
crash
crash
you and then we're going to run uh this
you and then we're going to run uh this
test performance
test performance
here yeah let's run test per
performance right hold
performance right hold
on there's a just a slightly annoying
on there's a just a slightly annoying
thing here that I have to do in order to
thing here that I have to do in order to
make this
make this
work and I
work and I
believe I just have to
believe I just have to
do from uh
Coba let's get our initial profile
test really it doesn't
work what uh what did I mess up
work what uh what did I mess up
here just the Imports
whatever well let's take a second to
whatever well let's take a second to
figure out why this is not working as uh
figure out why this is not working as uh
as
as
intended ocean mooba seim
MOA well we can always just put this
MOA well we can always just put this
performance test somewhere else for now
performance test somewhere else for now
just to keep the
just to keep the
uh to keep this up for stream so I'm
uh to keep this up for stream so I'm
just going to copy
this uh MOA perf
from
from
puffer MOA Coba it's just from mobile we
puffer MOA Coba it's just from mobile we
import puffer MOBA and this is going to
import puffer MOBA and this is going to
be our profile test at the
start and what do we call this MOA test
start and what do we call this MOA test
or something yeah MOA
or something yeah MOA
per let's see if this works
hold
hold
on oh I did something
weird oh uh yeah it's right here it's
weird oh uh yeah it's right here it's
MOBA
MOBA
dot MOBA
dot MOBA
again that's probably all it was
again that's probably all it was
anyways uh Moa
Mo see they should
run no
module what the heck well we need to get
module what the heck well we need to get
this perf test working let's in the
this perf test working let's in the
meantime I'm going to open up something
meantime I'm going to open up something
cool uh just so we can get an initial
cool uh just so we can get an initial
look and then I'll come back to this in
look and then I'll come back to this in
a moment um and then I'll go fix this so
a moment um and then I'll go fix this so
just so that folks have something
just so that folks have something
interesting to see in the meantime uh
interesting to see in the meantime uh
just so you get like an interesting like
just so you get like an interesting like
overview and I can start thinking about
overview and I can start thinking about
this in the back of my head so uh if I
this in the back of my head so uh if I
go to the the file here hoer Leb
go to the the file here hoer Leb
environments ocean mooba
environments ocean mooba
we see that we have some HTML files in
we see that we have some HTML files in
here right and we're going to move this
here right and we're going to move this
Coba
HTML into
here and now we have cob here and look
here and now we have cob here and look
what this gives
what this gives
you so this file
you so this file
here anywhere we have this in uh yellow
here anywhere we have this in uh yellow
highlight it is calling back to Python
highlight it is calling back to Python
and anywhere that it is white it is not
and anywhere that it is white it is not
calling back to python so for instance
calling back to python so for instance
this inline function here is a pure C
this inline function here is a pure C
function no calls back to python this
function no calls back to python this
inline function here is actually calling
inline function here is actually calling
back to python uh it looks like I didn't
back to python uh it looks like I didn't
add a return type so that's probably why
add a return type so that's probably why
the function signature is bad
and then I'd assume that this is also
and then I'd assume that this is also
highlighted because I didn't add a
highlighted because I didn't add a
return type so when we go fix the types
return type so when we go fix the types
on this this will no longer call back to
on this this will no longer call back to
Python and it will be like a 100 times
Python and it will be like a 100 times
faster uh things in a knit we don't
faster uh things in a knit we don't
really care about because they only
really care about because they only
happen
happen
once things like level we may be care
once things like level we may be care
about
about
right here what what did we do
right here what what did we do
here Pi int from in Rich compare Pi
here Pi int from in Rich compare Pi
object is
object is
true uh okay we didn't type
true uh okay we didn't type
XP so missing typing
XP so missing typing
there uh cdef void compute
there uh cdef void compute
observation this doesn't look like it
observation this doesn't look like it
should have anything wrong with
should have anything wrong with
it
um let's
um let's
see add Trace back sometimes the uh The
see add Trace back sometimes the uh The
annotation thing itself will add
annotation thing itself will add
uh add like spous highlights just to
uh add like spous highlights just to
function
function
signatures but for the most part it's
signatures but for the most part it's
fine we can see here in compute
fine we can see here in compute
observation it looks like I messed this
observation it looks like I messed this
up here let's see Y into
up here let's see Y into
Dy uh I didn't type did I not type
Dy uh I didn't type did I not type
Dy Pi in from
double possibly you're not allowed to
double possibly you're not allowed to
use this cast
use this cast
syntax I thought you were allowed to do
syntax I thought you were allowed to do
this though let me see if this was done
this though let me see if this was done
up
up
top there's a different cast intax for C
top there's a different cast intax for C
Cast though I thought that they both
Cast though I thought that they both
worked but in general it's this type of
worked but in general it's this type of
a thing right where like we're going to
a thing right where like we're going to
look for places where we're calling back
look for places where we're calling back
when we don't mean to be calling back I
when we don't mean to be calling back I
actually if we're looking at this we can
actually if we're looking at this we can
see I've done a pretty good job to begin
see I've done a pretty good job to begin
with but like there's some places where
with but like there's some places where
definitely like this L2 distance it
definitely like this L2 distance it
looks like this is calling back uh this
looks like this is calling back uh this
neutral AI maybe has a call back here
neutral AI maybe has a call back here
um L2 distance is a really big one it
um L2 distance is a really big one it
looks
looks
like some of the function signatures
like some of the function signatures
apparently you're still calling
apparently you're still calling
back XP is
bad various things around here uh that
bad various things around here uh that
we can potentially optimize quite a bit
we can potentially optimize quite a bit
right though I'm
right though I'm
actually apparently I've gotten way
actually apparently I've gotten way
better at this
better at this
because for a first pass having never
because for a first pass having never
opened this before this is actually
opened this before this is actually
really
solid okay let's figure out that profile
solid okay let's figure out that profile
code and uh we will optimize from there
code and uh we will optimize from there
it looks like there's not going to be
it looks like there's not going to be
actually too much typing stuff as soon
actually too much typing stuff as soon
as we get the profile check done I think
as we get the profile check done I think
we're probably going to only have maybe
we're probably going to only have maybe
an hour's worth of uh type type based
an hour's worth of uh type type based
optimizations and then most of it's
optimizations and then most of it's
going to have to be algorithmic so it's
going to have to be algorithmic so it's
pretty important where we start off for
pretty important where we start off for
this Baseline let me just figure out why
this Baseline let me just figure out why
why this is not allowing me puffer
why this is not allowing me puffer
environments ocean MOA MOBA right
environments ocean MOA MOBA right
puffer environments ocean mooba
puffer environments ocean mooba
mooba
mooba
puffer we have puffer MOBA here
right no
right no
module puffer Li environments
oh is it not uh it's not importing the
oh is it not uh it's not importing the
sea environment that's
sea environment that's
weird from puff of environment ocean MOA
weird from puff of environment ocean MOA
sea
sea
mooba import environment as sea
environment and that looks like it's
environment and that looks like it's
fine to me
and what if I call it from here what
and what if I call it from here what
happens over
here no module cmob okay let me just pip
here no module cmob okay let me just pip
install make sure that it's actually got
install make sure that it's actually got
a upto-date copy of
everything syon is substantially less of
everything syon is substantially less of
a pain uh to get built compared to Pi
a pain uh to get built compared to Pi
bind with C++ for instance but still a
bind with C++ for instance but still a
little bit of a
pain just a little
bit let me make sure that I didn't like
bit let me make sure that I didn't like
take this pix file out for some reason I
take this pix file out for some reason I
don't think I would have that would have
don't think I would have that would have
been
been
weird this is the whole setup right here
weird this is the whole setup right here
for the scon files pretty basic just
for the scon files pretty basic just
call scon eyes on all the individual
call scon eyes on all the individual
files I can see I do have the cmob file
files I can see I do have the cmob file
here
here
correctly okay so this took a while to
correctly okay so this took a while to
run so I'm suspecting that
run so I'm suspecting that
maybe maybe there was something weird
there still cannot import
there still cannot import
this no
module ocean
module ocean
mooba I see the Coba pix right here
mooba I see the Coba pix right here
uh I don't see Theo though I don't see
uh I don't see Theo though I don't see
the linked file that's
the linked file that's
weird
weird
right there should be a a
doso so I think that this is somehow a
doso so I think that this is somehow a
build error of some
type we'll rerun this uh this form of
type we'll rerun this uh this form of
the build system there are a couple like
the build system there are a couple like
crappy tools setup tools that uh don't
crappy tools setup tools that uh don't
play nicely
play nicely
together that can cause issues
together that can cause issues
sometimes as soon as we have this fixed
sometimes as soon as we have this fixed
though like we'll be good for the
day you can see we get lots and lots of
day you can see we get lots and lots of
warnings from
warnings from
stuff with
compilation some of these are fixable
compilation some of these are fixable
and just like numpy API things I usually
and just like numpy API things I usually
do try to get this the build to be
do try to get this the build to be
pretty clear
pretty clear
for the final
version okay how is this working does
version okay how is this working does
the demo
work okay so this actually does
work okay so this actually does
work oh let's do
um import
um import
make n
crater and then we'll just
crater and then we'll just
do en Creator
do en Creator
mooba I think we can just do this
function
reset this is make en then n is going to
reset this is make en then n is going to
be making okay that should work it's
be making okay that should work it's
just some weird binding
errors it works in the demo
what this make make mobo
right and then it returns you the
environment huh
hold on there's no way that this should
hold on there's no way that this should
be running in the demo and not running
here end
module import
module import
ocean ocean
ocean ocean
dot we'll have to figure out what's
dot we'll have to figure out what's
what's weird with the pathing later
but there's there's just no way like
but there's there's just no way like
this
is puffer lib environment Ocean mooba
is puffer lib environment Ocean mooba
Sea mooba import
Sea mooba import
environment why how the heck does it
environment why how the heck does it
work here
like this runs and I can see it
render there a circular import or
render there a circular import or
something
oh there's no underscore a nit that's
weird how's there no underscore in
net that's very weird
ocean
environment from
MOBA offer lib environments ocean MOA SE
MOBA offer lib environments ocean MOA SE
[Music]
mooba this is literally Bound in setup
mooba this is literally Bound in setup
isn't
isn't
it I like I'm suspecting there's just
it I like I'm suspecting there's just
some weird [ __ ] with setup tools that's
happened environment ocean mob mobile
I'm trying to figure out why it why it
I'm trying to figure out why it why it
still works in um oh I don't have chat
still works in um oh I don't have chat
working at all do
working at all do
I something weird
happened I don't have chat working and I
happened I don't have chat working and I
haven't had the stream window up okay
haven't had the stream window up okay
that's really stupid here we
that's really stupid here we
go yay there are lots of people chatting
go yay there are lots of people chatting
and saying that there's no
and saying that there's no
code it took me 15 minutes to realize
code it took me 15 minutes to realize
that no wonder okay uh are you meaning
that no wonder okay uh are you meaning
to be sharing your screen yep it would
to be sharing your screen yep it would
be really nice if people could tell me
be really nice if people could tell me
that but the thing is the chat is also
that but the thing is the chat is also
on the
on the
screen
screen
um this is why you don't stream people
um this is why you don't stream people
it gives you brain damage and then it
it gives you brain damage and then it
makes it impossible to uh to stream
makes it impossible to uh to stream
because you're literally too dumb to
because you're literally too dumb to
stream that's how it works okay well
stream that's how it works okay well
sorry about that welcome folks um didn't
sorry about that welcome folks um didn't
miss very much I will show off some cool
miss very much I will show off some cool
stuff now
stuff now
so I'm having some stupid build error
so I'm having some stupid build error
that I'm going to have to figure out how
that I'm going to have to figure out how
to fix let me show off the cool things
to fix let me show off the cool things
now
now
so this is a HTML file that is built by
so this is a HTML file that is built by
scon uh with the annotate option and
scon uh with the annotate option and
anywhere you see yellow your code is not
anywhere you see yellow your code is not
running in pure C so what we're going to
running in pure C so what we're going to
do
do
today is uh I'm going to first get the
today is uh I'm going to first get the
code built right now I'm going to get it
code built right now I'm going to get it
built up with or without some sanity
built up with or without some sanity
options we're going to see what FPS
options we're going to see what FPS
we're getting right now and then we're
we're getting right now and then we're
going to get a million FPS via
going to get a million FPS via
optimization that's what the plan
optimization that's what the plan
is this is why I shouldn't take meetings
is this is why I shouldn't take meetings
because I forget to switch the camera
because I forget to switch the camera
back that's another MO that's another
back that's another MO that's another
uh takeaway don't have meetings just
uh takeaway don't have meetings just
write code all day it's way
better
better
okay I will tweet that the stream is
fixed oops
there we go
there we go
cool
cool
okay hey
okay hey
Roman hey hey Relic
welcome hey
welcome hey
Felix huge fan of RL as well as LOL why
Felix huge fan of RL as well as LOL why
do you think moas are interesting
do you think moas are interesting
research topic for RL have you seen open
research topic for RL have you seen open
ai5 it's probably the best RL result out
ai5 it's probably the best RL result out
there I mean mobas are just tremendously
there I mean mobas are just tremendously
complicated games um but the idea for
complicated games um but the idea for
this project was like Hey open AI did
this project was like Hey open AI did
this but they used
this but they used
128,000
128,000
CPUs
and I don't know if this is even
and I don't know if this is even
accurate this is 20 56 p100s I think it
accurate this is 20 56 p100s I think it
was up to 1,000 gpus at some
point 900 years of training data per day
point 900 years of training data per day
is what they trained on actually you
is what they trained on actually you
know what let's do a fun back of the
know what let's do a fun back of the
envelope calculation
envelope calculation
okay so 900 years per
okay so 900 years per
day uh so in 24 hours divide so this is
day uh so in 24 hours divide so this is
900 years times 365 days 364 days
900 years times 365 days 364 days
whatever it is times 364 I don't I don't
whatever it is times 364 I don't I don't
even
even
remember how many days are there in a
remember how many days are there in a
year uh
year uh
times uh uh 24 hours in a day times 3600
times uh uh 24 hours in a day times 3600
seconds in an hour okay this is the
seconds in an hour okay this is the
total
number 28
number 28
billion steps of data it looks like
billion steps of data it looks like
right uh seconds this is 28 billion
right uh seconds this is 28 billion
seconds of
seconds of
data okay and I'm going to say times
data okay and I'm going to say times
five if we're going to
five if we're going to
sample they actually give it to you
sample they actually give it to you
right here observations per second so
right here observations per second so
times
7.5 okay that's crazy
7.5 okay that's crazy
200 billion steps worth of data it's a
200 billion steps worth of data it's a
lot
right but that's
right but that's
actually how close can we get to
this that's a
this that's a
lot I don't know if I can quite match
lot I don't know if I can quite match
that I can get like in the ballpark
that I can get like in the ballpark
though so 212 billion steps worth of
though so 212 billion steps worth of
data first of
all they did this for
all they did this for
and this is per
and this is per
day so how much can we do in a day if we
day so how much can we do in a day if we
were able to get the best case scenarios
were able to get the best case scenarios
we get 1 million training steps per
we get 1 million training steps per
second that's the best case scenario so
second that's the best case scenario so
million which is
million which is
186 time 24 hours per
186 time 24 hours per
day
day
times uh 3600 seconds
is going to
be oh that's not
be oh that's not
bad we get 86 uh 86 billion per
bad we get 86 uh 86 billion per
day so we're actually only like a factor
day so we're actually only like a factor
a little more than a factor of two off
a little more than a factor of two off
and the other fun thing is wait does
and the other fun thing is wait does
this include the factor of
this include the factor of
oh and then there's another Factor where
oh and then there's another Factor where
we're going to down sample the
we're going to down sample the
observations per second so we're going
observations per second so we're going
to do
to do
times uh
times uh
1.5 I
think yeah so we're going to get times
think yeah so we're going to get times
1.5 because we're going to down sample
1.5 because we're going to down sample
the data a little bit so yeah we're only
the data a little bit so yeah we're only
a factor of two off so that's actually
a factor of two off so that's actually
cool if I managed to make this as high
cool if I managed to make this as high
perf as my other stuff this could
perf as my other stuff this could
literally be
literally be
up there with open ai5 in terms of the
up there with open ai5 in terms of the
amount of data this thing is going to
amount of data this thing is going to
chug but with one GPU instead of at
chug but with one GPU instead of at
least
least
256 and with two CPU cores instead of
256 and with two CPU cores instead of
128,000 that'd be really freaking
128,000 that'd be really freaking
sweet that'd be really
sweet okay I do have to fix this little
sweet okay I do have to fix this little
boring bug for a
boring bug for a
moment uh and then we're going to get to
moment uh and then we're going to get to
perf
test oh I guess it's fixed cool it was
test oh I guess it's fixed cool it was
literally just a stupid setup tools
literally just a stupid setup tools
annoying
thing that's perfect
thing that's perfect
timing so we get print
what are we going to do about the resets
what are we going to do about the resets
on this right now
right currently there's no way to reset
right currently there's no way to reset
the
the
environment I think we're just going to
environment I think we're just going to
ignore it for now for our initial perf
ignore it for now for our initial perf
test and then we'll we'll do fast resets
test and then we'll we'll do fast resets
later cuz that's
important okay MOA
perf there we go so it's going to run
perf there we go so it's going to run
this now for 10 seconds we're going to
this now for 10 seconds we're going to
get a rough steps per
get a rough steps per
second it's a Baseline
we're only at 880,000 steps per second
we're only at 880,000 steps per second
at the moment which is nowhere near fast
at the moment which is nowhere near fast
enough I want the environment itself to
enough I want the environment itself to
run
run
at like a
at like a
million so let's see what has happened
million so let's see what has happened
here with that um
one thing that we can do uh is we can
one thing that we can do uh is we can
enable uh profiling actually I forgot
enable uh profiling actually I forgot
there's that
option thanks for the explanation what
option thanks for the explanation what
do you get out of this
do you get out of this
research in and accept for only gaming
research in and accept for only gaming
can you transfer to other games are just
can you transfer to other games are just
a really good test bed for
a really good test bed for
things in general like what we care
things in general like what we care
about is we care that this is a complex
about is we care that this is a complex
and cognitively interesting problem and
and cognitively interesting problem and
that it's really efficient to simulate
that it's really efficient to simulate
um reinforcement learning requires a lot
um reinforcement learning requires a lot
of
of
experimentation and a lot of the things
experimentation and a lot of the things
that have been hindering RL from
that have been hindering RL from
applying to other domains is that we
applying to other domains is that we
just haven't had like hard enough
just haven't had like hard enough
problems to run it on that are also very
problems to run it on that are also very
fast so one of the things I'm doing with
fast so one of the things I'm doing with
puffer right is making it easy to run RL
puffer right is making it easy to run RL
on hard problems but another thing I'm
on hard problems but another thing I'm
doing with puffers which is what you're
doing with puffers which is what you're
seeing here is I'm making a specific set
seeing here is I'm making a specific set
of very hard problems that are
of very hard problems that are
incredibly fast so that you can iterate
incredibly fast so that you can iterate
on Research that much faster I mean just
on Research that much faster I mean just
it's a whole different game when you
it's a whole different game when you
have to be open Ai and you have to have
have to be open Ai and you have to have
a 20 person engineering team to do open
a 20 person engineering team to do open
AI five to get like you know a MOA level
AI five to get like you know a MOA level
intelligence versus if like a guy can
intelligence versus if like a guy can
just make make a admittedly very
just make make a admittedly very
stripped down but still like a basic MOA
stripped down but still like a basic MOA
and get like half of the per of their
and get like half of the per of their
entire cluster for that on a small model
entire cluster for that on a small model
with one GPU that unlocks a whole new
with one GPU that unlocks a whole new
set of progress a whole new set of stuff
set of progress a whole new set of stuff
that you can do with RL so that's what
that you can do with RL so that's what
we're doing
here like mooba MMO especially or games
here like mooba MMO especially or games
at
at
all um we use all sorts of games yeah we
all um we use all sorts of games yeah we
use all sorts of games uh mobas are
use all sorts of games uh mobas are
really complicated right they're like
really complicated right they're like
tremendous I mean you played league
tremendous I mean you played league
right it's tremendously complicated game
right it's tremendously complicated game
if you try to introduce a MOBA to
if you try to introduce a MOBA to
somebody who's never played one before
somebody who's never played one before
they're like they're going to be baffled
they're like they're going to be baffled
that people play these things as Hobbies
that people play these things as Hobbies
like this is way more complicated than
like this is way more complicated than
virtually any other type of like game
virtually any other type of like game
hobby thing that you can think of right
hobby thing that you can think of right
just like the amount of time it takes to
just like the amount of time it takes to
even learn the ropes on one of these
even learn the ropes on one of these
games people forget when they've been
games people forget when they've been
playing them for 10 years but you need
playing them for 10 years but you need
to spend like multiple hundred hours to
to spend like multiple hundred hours to
have any idea what the hell you're doing
have any idea what the hell you're doing
in one of these and MMOs are a little
in one of these and MMOs are a little
bit of a different access right there's
bit of a different access right there's
not much there's not as much like
not much there's not as much like
complexity coming from different
complexity coming from different
combinations of opponents and stuff but
combinations of opponents and stuff but
MMOs are cool because they're persistent
MMOs are cool because they're persistent
so like you can run the same environment
so like you can run the same environment
for a really long time and it can change
for a really long time and it can change
over time um and they also have a lot
over time um and they also have a lot
more players in them so it's more like
more players in them so it's more like
the real world in that sense so there
the real world in that sense so there
are two genres that I think are both
are two genres that I think are both
very useful for research uh there's
very useful for research uh there's
other stuff you can do as well they're
other stuff you can do as well they're
just two that come to
mind Platinum for hard
mind Platinum for hard
stuck man I I played league for a very
stuck man I I played league for a very
short amount of time and I got I was
short amount of time and I got I was
stuck in bronze all right
stuck in bronze all right
so I'm
so I'm
bad only thing I've ever been good at is
bad only thing I've ever been good at is
MMOs I've been you know like that top 1%
MMOs I've been you know like that top 1%
or
whatever games like Civ
whatever games like Civ
6 so problem with stuff like civ6 right
6 so problem with stuff like civ6 right
um You can do it there are a lot more
um You can do it there are a lot more
infrastructure and Engineering
infrastructure and Engineering
challenges associated with something
challenges associated with something
like that just from a game design
like that just from a game design
perspective and also it's very it's like
perspective and also it's very it's like
a very real world context dependent game
a very real world context dependent game
so if you have an agent that's learning
so if you have an agent that's learning
to play that game from scratch without
to play that game from scratch without
the context of
the context of
like without context from The Real World
like without context from The Real World
it's a much harder thing to do from
it's a much harder thing to do from
scratch like I could boot up uh League I
scratch like I could boot up uh League I
could boot up DOTA I could be boot up
could boot up DOTA I could be boot up
like RuneScape in Japanese which I don't
like RuneScape in Japanese which I don't
read right and I could figure stuff out
read right and I could figure stuff out
a little bit uh if I booted up Civ in
a little bit uh if I booted up Civ in
like Japanese I'd have no idea what the
like Japanese I'd have no idea what the
hell I was
hell I was
doing so that's like a good litmus test
doing so that's like a good litmus test
right like if you were to just boot up
right like if you were to just boot up
the game in Japanese like would you have
the game in Japanese like would you have
any idea what you were doing if not then
any idea what you were doing if not then
it's probably not great for RL
okay
python but isn't the real world context
python but isn't the real world context
the interesting area not
the interesting area not
really um that's like prior knowledge
really um that's like prior knowledge
right it's interesting in a different
right it's interesting in a different
way the real world context is what you
way the real world context is what you
would get from language models for
would get from language models for
instance but the decision making and the
instance but the decision making and the
reason behind it you don't get that's
reason behind it you don't get that's
like that that's what you can do with
like that that's what you can do with
RL and as a matter of as a practical
RL and as a matter of as a practical
matter like doing this RL stuff is
matter like doing this RL stuff is
really hard but it doesn't require that
really hard but it doesn't require that
I have a billion dollar cluster right it
I have a billion dollar cluster right it
requires that I have a $30,000
requires that I have a $30,000
cluster which is much which is still a
cluster which is much which is still a
lot but much more
lot but much more
reasonable um so yeah RL is this kind of
reasonable um so yeah RL is this kind of
this area where like there's this whole
this area where like there's this whole
other side of learning that is not being
other side of learning that is not being
actively explored and you can actually
actively explored and you can actually
do it with pretty modest
do it with pretty modest
resources but to get decisions I can
resources but to get decisions I can
apply in the real world RL is used in
apply in the real world RL is used in
the real world there are a bunch of
the real world there are a bunch of
applications of reinforcement learning
applications of reinforcement learning
where language models make absolutely no
where language models make absolutely no
sense where reinforcement learning just
sense where reinforcement learning just
works it's used in traffic control it's
works it's used in traffic control it's
used in uh like routing uh Uber drivers
used in uh like routing uh Uber drivers
or lift drivers I believe it is uh it's
or lift drivers I believe it is uh it's
used in like data center power
used in like data center power
optimization lots of things where where
optimization lots of things where where
there's like a hard decision making
there's like a hard decision making
problem that doesn't cleanly map onto
problem that doesn't cleanly map onto
Vision or text there are lots of
Vision or text there are lots of
them and mind you there are applications
them and mind you there are applications
of RL and RL has had like a tiny tiny
of RL and RL has had like a tiny tiny
drop of the amount of investment and
drop of the amount of investment and
interest that language models have had
interest that language models have had
um so there's a huge amount of Promise
um so there's a huge amount of Promise
coupled with like we can actually do
coupled with like we can actually do
stuff with this right we don't need
stuff with this right we don't need
giant clusters to do this we can just do
giant clusters to do this we can just do
it
let's rerun this thing
let's rerun this thing
um there
MOA I think I need to get the cile code
MOA I think I need to get the cile code
don't
I yeah this thing
so we do this is going to be a test
so we do this is going to be a test
performance
right
right
MOBA actions okay I think this works
test performance 10 stats.
profile I just want to get a sense of
profile I just want to get a sense of
like where all the time is going in
like where all the time is going in
these
functions hi Joseph how are you seeing
functions hi Joseph how are you seeing
you after a year or so can we get some
you after a year or so can we get some
tutorials on making your end faster like
tutorials on making your end faster like
this Mobo
this Mobo
does puffer provide built-in features to
does puffer provide built-in features to
make training fast without Jacks yes so
make training fast without Jacks yes so
this is a relatively new area the hper
this is a relatively new area the hper
engineering Sim engineering stuff is the
engineering Sim engineering stuff is the
way that I've come up with of doing this
way that I've come up with of doing this
is something new in the last few months
is something new in the last few months
I have this project one other project
I have this project one other project
that isn't uh announced yet that I'm
that isn't uh announced yet that I'm
finishing up and then like the snake
finishing up and then like the snake
project the grid project and a few other
project the grid project and a few other
smaller ones there will be a very nice
smaller ones there will be a very nice
summary blog post on this when I'm done
summary blog post on this when I'm done
and some good uh probably a good video
and some good uh probably a good video
as well so there's going to be content
as well so there's going to be content
on that um but it's a lot of work I mean
on that um but it's a lot of work I mean
this is a huge amount of work to finish
this is a huge amount of work to finish
up and I want to make sure that I can
up and I want to make sure that I can
really give you a good summary of how to
really give you a good summary of how to
do all of this before I uh I post
do all of this before I uh I post
something like that though that said if
something like that though that said if
you want to get started on stuff now
you want to get started on stuff now
like 90% of what you will need is in the
like 90% of what you will need is in the
snake environment and the snake
snake environment and the snake
environment is like a 450 line of code
environment is like a 450 line of code
standal Lo demo it's dead simple code
standal Lo demo it's dead simple code
and it runs at 14 million steps per
and it runs at 14 million steps per
second single thread it trains at over a
second single thread it trains at over a
million steps per second so that's the
million steps per second so that's the
thing to do at the
moment so we
have very weird distribution of timings
have very weird distribution of timings
here
so we've got 10 seconds worth of
so we've got 10 seconds worth of
calls but most of them
calls but most of them
are I the top time is nowhere near
10 fill observations is about
10% records get attribute
10% records get attribute
is
7% where the heck is the rest of the
7% where the heck is the rest of the
time going
if it's only
if it's only
3.8 in m.p
3.8 in m.p
Step cumulative time is 9.8 okay so MOBA
Step cumulative time is 9.8 okay so MOBA
step is actually most of the
step is actually most of the
time fill
observations okay I see so the fill
observations okay I see so the fill
observations is a cumulative of 40% of
observations is a cumulative of 40% of
that
time get attribute is another
time get attribute is another
second we've got
view okay so there are a lot of methods
view okay so there are a lot of methods
here that are like weird
here that are like weird
um yeah there are a lot of weird methods
um yeah there are a lot of weird methods
here that are being slow and uh we have
here that are being slow and uh we have
to figure out what the heck is going on
to figure out what the heck is going on
with this fine so
with this fine so
let's just start on this I'm gonna
let's just start on this I'm gonna
actually just do
this
oops
oops
okay oh I forgot to answer the other
okay oh I forgot to answer the other
part of your question uh does puffer lib
part of your question uh does puffer lib
have buil-in features to make training
have buil-in features to make training
fast uh puffer has builtin
fast uh puffer has builtin
the vectorization in puffer means that
the vectorization in puffer means that
if your environment is fast you're not
if your environment is fast you're not
going to get capped by vectorization so
going to get capped by vectorization so
like with other stuff even if your
like with other stuff even if your
environment is fast other things on the
environment is fast other things on the
stack are going to make it slow with
stack are going to make it slow with
puffer if your environment is fast then
puffer if your environment is fast then
it's just fast so that's the that's the
it's just fast so that's the that's the
thing that puffer provides for you like
thing that puffer provides for you like
a lot of the work on puffer was to make
a lot of the work on puffer was to make
it so that fast Ms are useful in the
it so that fast Ms are useful in the
first place you still have to make them
first place you still have to make them
fast that's what the stuff I'm working
fast that's what the stuff I'm working
on now is like simp ways of making
on now is like simp ways of making
really fast
Sims two people on Twitch that's cool to
Sims two people on Twitch that's cool to
see twitch usually has tough time for uh
see twitch usually has tough time for uh
promoting like new streams that's
promoting like new streams that's
awesome welcome
folks oops where are
we CD puffer lib environments ocean
okay so what is
this if we look in a
step thank you very much for pointing
step thank you very much for pointing
out the demo snake M can I please get
out the demo snake M can I please get
the repo link awaiting the blog poster
the repo link awaiting the blog poster
Series yeah I a lot of this stuff is
Series yeah I a lot of this stuff is
based on engagement frankly because like
based on engagement frankly because like
I will just I will make whatever format
I will just I will make whatever format
of content people will actually look at
of content people will actually look at
right so like I'm going to do a test
right so like I'm going to do a test
video and like cuz people really liked
video and like cuz people really liked
my thesis defense so I'm going to do a
my thesis defense so I'm going to do a
test video on puffer 10 if people like
test video on puffer 10 if people like
that I will make more if people don't
that I will make more if people don't
like go and watch that then I will spend
like go and watch that then I will spend
my time on other forms of content
right um let me get you the the link
right um let me get you the the link
it's just puffer
oops so look if you just go into Puffer
oops so look if you just go into Puffer
here it's there's the snake m is in the
here it's there's the snake m is in the
dev Branch I
dev Branch I
believe so look Dev Branch puffer
believe so look Dev Branch puffer
lib
lib
environments ocean is first party so
environments ocean is first party so
ocean has our first party environments
ocean has our first party environments
and you've got all these environments to
and you've got all these environments to
play with there's also an in config
play with there's also an in config
branch which I'm merging into this soon
branch which I'm merging into this soon
which has the mooba and a bunch of
which has the mooba and a bunch of
refactor stuff um that's really nice but
refactor stuff um that's really nice but
it's a little less stable so
it's a little less stable so
far can I put this into the chat
people must watch it
people must watch it
then yeah I hope so I mean the thesis
then yeah I hope so I mean the thesis
the thesis defense was awesome like if I
the thesis defense was awesome like if I
can get more if people are actually
can get more if people are actually
going to have this level of Engagement
going to have this level of Engagement
with the longer form stuff that I make
with the longer form stuff that I make
because this is like making something
because this is like making something
like this is very high effort right like
like this is very high effort right like
this thesis defense in addition to it
this thesis defense in addition to it
being obviously like something I've been
being obviously like something I've been
working on for years just preparing the
working on for years just preparing the
talk took a few weeks of work right
talk took a few weeks of work right
that's a lot of time investment it's
that's a lot of time investment it's
done amazing as a result but like if I'm
done amazing as a result but like if I'm
going to put like a week of work into a
going to put like a week of work into a
video and have it get like a thousand
video and have it get like a thousand
views then like I'd rather be deving
views then like I'd rather be deving
useful tools for people in that time
useful tools for people in that time
right so that's just the main thing but
right so that's just the main thing but
yeah this has been awesome this thing
yeah this has been awesome this thing
hit 120k which is that's
hit 120k which is that's
great starring the puffer repo helps a
great starring the puffer repo helps a
lot helps out a bunch promoting the
lot helps out a bunch promoting the
stuff on Twitter helps out a bunch but
stuff on Twitter helps out a bunch but
yeah that's generally where I'm
at uh oh stream's not frozen is
it I think just my preview is
it I think just my preview is
frozen I think we're
frozen I think we're
okay says zero drop frames
what is this fill
observations
observations
oh yeah okay so it looks like we have a
oh yeah okay so it looks like we have a
bunch of slow stuff in Python
land yeah like all this python stuff is
land yeah like all this python stuff is
really slow that's that's
really slow that's that's
funny
so I think for this for this mooba we're
so I think for this for this mooba we're
just going to do
just going to do
everything we're going to just do
everything we're going to just do
everything in Sealand
right so I think we're just going to do
right so I think we're just going to do
we're going to just straight up comment
we're going to just straight up comment
this
thanks for pointing out where the m is
thanks for pointing out where the m is
do my best in promoting many people I
do my best in promoting many people I
know that use Jack because there's no
know that use Jack because there's no
other way basically we were fed up with
other way basically we were fed up with
the they're fed up with yeah that's the
the they're fed up with yeah that's the
thing and I made this I don't know did
thing and I made this I don't know did
you see the post that I made on Jack I
you see the post that I made on Jack I
made a really obnoxious rambly post that
made a really obnoxious rambly post that
uh that blew
up I made this like where is
up I made this like where is
it I don't know I do a bunch of things
it I don't know I do a bunch of things
on here but here there's this really
on here but here there's this really
obnoxious
obnoxious
article where is it it's on my timeline
article where is it it's on my timeline
or on my articles so this thing got 145k
or on my articles so this thing got 145k
views right this is like one of my
views right this is like one of my
better performing posts and it's got
better performing posts and it's got
this total bait title and I talk about
this total bait title and I talk about
how like people are like oh yeah now we
how like people are like oh yeah now we
need Jacks and rust and stuff in order
need Jacks and rust and stuff in order
to make fast M and we very obviously
to make fast M and we very obviously
don't you know I can just write 200
don't you know I can just write 200
lines of scyon and it's faster than
lines of scyon and it's faster than
anything that anybody's writing with
anything that anybody's writing with
much fancier and harder to use Stacks um
much fancier and harder to use Stacks um
and it's also not limiting you to a
and it's also not limiting you to a
domain specific language like
domain specific language like
Jax
Jax
so yeah it's not even the case that this
so yeah it's not even the case that this
stuff is incredibly difficult
stuff is incredibly difficult
necessarily it's just nobody's bothered
necessarily it's just nobody's bothered
to actually take a a hard look at the
to actually take a a hard look at the
infra inrl and really put the time in
infra inrl and really put the time in
there are really no incentives in
there are really no incentives in
Academia to do the type of work I'm
Academia to do the type of work I'm
doing now
doing now
like I had a lot of freedom in my PhD
like I had a lot of freedom in my PhD
and I still probably wouldn't have been
and I still probably wouldn't have been
able to justify doing the type of work
able to justify doing the type of work
I'm doing now in my PhD so the incentive
I'm doing now in my PhD so the incentive
structures are just terrible and
structures are just terrible and
basically what's happened in the last
basically what's happened in the last
couple months with puffer is as soon as
couple months with puffer is as soon as
I actually started taking this stuff
I actually started taking this stuff
seriously and spending all of my time on
seriously and spending all of my time on
it like it's just rocketed to the moon
it like it's just rocketed to the moon
and puffer's gotten 600 some OD stars
and puffer's gotten 600 some OD stars
and like people are using it and people
and like people are using it and people
are having a good time with it and like
are having a good time with it and like
you know people are watching the streams
you know people are watching the streams
and it's just going to get better from
and it's just going to get better from
here and it's going to get better very
here and it's going to get better very
very fast what game are you doing now
very fast what game are you doing now
we're doing uh this thing I'll show
we're doing uh this thing I'll show
you where's it and then I should do a
you where's it and then I should do a
little bit of optimization
little bit of optimization
so we've got a I'm not going to say full
so we've got a I'm not going to say full
scale but a pretty you know complicated
scale but a pretty you know complicated
mooba simulator like League of Legends
mooba simulator like League of Legends
or DOTA and we're making this thing run
or DOTA and we're making this thing run
at a million frames per second that is
at a million frames per second that is
the goal for today right now it runs at
the goal for today right now it runs at
880,000 steps per second uh by the end
880,000 steps per second uh by the end
of today we're going to get it to be a
of today we're going to get it to be a
million steps per second with maybe a
million steps per second with maybe a
few small cheats and um then after that
few small cheats and um then after that
we're going to start binding it to the
we're going to start binding it to the
reinforcement learning side and start
reinforcement learning side and start
training it at a million steps per
training it at a million steps per
second that's the goal
okay so just from deleting this Phill
okay so just from deleting this Phill
observations which will be fast in in
C let's see how much better this is can
C let's see how much better this is can
people run this at home absolutely all
people run this at home absolutely all
of my stuff is open
source it's in a Dev Branch right
source it's in a Dev Branch right
now uh it's in like a a off branch of
now uh it's in like a a off branch of
Dev at the moment it's going to get
Dev at the moment it's going to get
merged to Dev soon but all of my current
merged to Dev soon but all of my current
work is in this any config Branch it'll
work is in this any config Branch it'll
get merge to Dev soon if you use it
get merge to Dev soon if you use it
please start the reap on your way in it
please start the reap on your way in it
helps me out a ton uh all of the
helps me out a ton uh all of the
simulators I've been doing a bunch of
simulators I've been doing a bunch of
different simulators on stream lately
different simulators on stream lately
and they're all inside of ocean which is
and they're all inside of ocean which is
puffer's first party environments uh so
puffer's first party environments uh so
you have MOBA grid snake all sorts of
you have MOBA grid snake all sorts of
different environments there'll be some
different environments there'll be some
more docks here soon and uh you can use
more docks here soon and uh you can use
them you can play with them you can ask
them you can play with them you can ask
about them over here
about them over here
and they're all free and open source
thank you helps me out a
ton I mean I've said this several times
ton I mean I've said this several times
on stream right my goal like puffer is
on stream right my goal like puffer is
technically a company but really my goal
technically a company but really my goal
with it is just like if this thing gets
with it is just like if this thing gets
large enough that companies start using
large enough that companies start using
it and I can get a little bit of revenue
it and I can get a little bit of revenue
from companies using puffer like support
from companies using puffer like support
contracts or whatever then my hope is I
contracts or whatever then my hope is I
can like buy a bigger cluster and
can like buy a bigger cluster and
support more open source stuff around
support more open source stuff around
puffer with it and put together some
puffer with it and put together some
like some bug bounties and stuff on that
like some bug bounties and stuff on that
that's like the short-term goal with
that's like the short-term goal with
puffer and that's why I've been
puffer and that's why I've been
promoting like the Twitter and the repo
promoting like the Twitter and the repo
so much is because that helps a lot with
so much is because that helps a lot with
other companies seeing
other companies seeing
it this needs to have a place in good
it this needs to have a place in good
conference so RL INF for track yeah
conference so RL INF for track yeah
here's the thing uh it got rejected from
here's the thing uh it got rejected from
nurs last year it got rejected from RLC
nurs last year it got rejected from RLC
this year both with [ __ ] reason
this year both with [ __ ] reason
uh this is my absolute best work I've
uh this is my absolute best work I've
gotten way worse papers in nobody cares
gotten way worse papers in nobody cares
about RL
about RL
infra and this is why it's all broken
infra and this is why it's all broken
the incentives are terrible you can do
the incentives are terrible you can do
like you can do your absolute best work
like you can do your absolute best work
as somebody who spent seven years and
as somebody who spent seven years and
you can just get multiple rejects on
you can just get multiple rejects on
conferences like there's literally no
conferences like there's literally no
incentive to do any of
incentive to do any of
this that's that's the reason that none
this that's that's the reason that none
of it's
of it's
happened and yeah like it would be nice
happened and yeah like it would be nice
to be a able to present this at a
to be a able to present this at a
conference and I did resubmit it to nurs
conference and I did resubmit it to nurs
this year but if it doesn't get in there
this year but if it doesn't get in there
I'm just not submitting more papers I'm
I'm just not submitting more papers I'm
done I'm out of the academic game I'm
done I'm out of the academic game I'm
actually building stuff right like I'm
actually building stuff right like I'm
not wasting my time on that anymore and
not wasting my time on that anymore and
there's no way around it I tried I spent
there's no way around it I tried I spent
seven years trying to fix RL uh from the
seven years trying to fix RL uh from the
inside of Academia okay like look I I'll
inside of Academia okay like look I I'll
show you something that I
show you something that I
did data sets and benchmarks track okay
did data sets and benchmarks track okay
this
this
year uh there's a very important
year uh there's a very important
language change to
this open source libraries and tools
this open source libraries and tools
that enable or accelerate ml research
that enable or accelerate ml research
and it's actually stated a second
time open source libraries and tools
time open source libraries and tools
that enable or accelerate ml so this
that enable or accelerate ml so this
exact language
exact language
I wrote an open letter on this I had to
I wrote an open letter on this I had to
promote the open letter a whole bunch I
promote the open letter a whole bunch I
circulated this I got this to last
circulated this I got this to last
year's DNB chairs I went through a big
year's DNB chairs I went through a big
chain of emails with the new DNB chairs
chain of emails with the new DNB chairs
to eventually get this integrated into
to eventually get this integrated into
this year's
this year's
call like it was a bunch of work so I
call like it was a bunch of work so I
managed to get like this one tiny
managed to get like this one tiny
thing uh for Academia but like the thing
thing uh for Academia but like the thing
is like what's the what's the return on
is like what's the what's the return on
investment for this because like the
investment for this because like the
reviewers can just completely ignore
reviewers can just completely ignore
this direction and they absolutely will
this direction and they absolutely will
right like this does not guarantee that
right like this does not guarantee that
people are not going to just reject your
people are not going to just reject your
paper because they don't like libraries
paper because they don't like libraries
and tools and they fundamentally don't
and tools and they fundamentally don't
respect your work like they're going to
respect your work like they're going to
do that anyways it helps but it's still
do that anyways it helps but it's still
[ __ ] so like I've wasted enough of
[ __ ] so like I've wasted enough of
my time on the [ __ ] academic game
my time on the [ __ ] academic game
and now like I'm building stuff for
and now like I'm building stuff for
Academia but I'm no longer doing it
Academia but I'm no longer doing it
through
through
conferences publication and the like I'm
conferences publication and the like I'm
just building tons of cool stuff really
just building tons of cool stuff really
really high performance really heavy
really high performance really heavy
engineering focus and I'm making it all
engineering focus and I'm making it all
available for free and like all I ask is
available for free and like all I ask is
that people like if you like my stuff is
that people like if you like my stuff is
that you help me promote it a little bit
that you help me promote it a little bit
so that I can like continue to build
so that I can like continue to build
this out and hopefully you know
this out and hopefully you know
hopefully make this a thing where yeah I
hopefully make this a thing where yeah I
would like to have an income of over
would like to have an income of over
zero dollars that would be nice but also
zero dollars that would be nice but also
like I would like to be able to fund a
like I would like to be able to fund a
little RL lab for people who actually
little RL lab for people who actually
care about this stuff and have like some
care about this stuff and have like some
open source bounties and stuff like that
open source bounties and stuff like that
and a bigger cluster like that's the
and a bigger cluster like that's the
type of thing that I'm trying to build
here okay so we just went up to 109,000
here okay so we just went up to 109,000
steps per second with profiling on with
steps per second with profiling on with
that garbage function deleted
we're going to have to add it back in C
we're going to have to add it back in C
but it's not going to add any overhead
but it's not going to add any overhead
in C or any noticeable
overhead
um do I need to sort this by cumulative
time this is really weird how long the
time this is really weird how long the
tail is on this because I have 9 seconds
tail is on this because I have 9 seconds
here
here
or is it total time I have 6.6 seconds
or is it total time I have 6.6 seconds
and then the next thing is 0.4
and then the next thing is 0.4
seconds so like I'm not this is not
seconds so like I'm not this is not
being timed properly if that's the case
um when did you start on puffer lib and
um when did you start on puffer lib and
what made you I started as a side
what made you I started as a side
project like a year and a half ago uh I
project like a year and a half ago uh I
was doing my PhD then so I didn't like
was doing my PhD then so I didn't like
you know I had a PhD to do so I just
you know I had a PhD to do so I just
kind of like started doing some tools
kind of like started doing some tools
and stuff on the side and and uh it sort
and stuff on the side and and uh it sort
of became obvious like last summer I
of became obvious like last summer I
didn't take MIT funding so that I could
didn't take MIT funding so that I could
work on puffer full-time and it became
work on puffer full-time and it became
obvious like RL fundamentally just was
obvious like RL fundamentally just was
not going to work without the stuff I
not going to work without the stuff I
was building for puffer so uh I didn't
was building for puffer so uh I didn't
get to spend too much time on it during
get to spend too much time on it during
the last year of my PhD properly because
the last year of my PhD properly because
I had PhD stuff but uh you know I sort
I had PhD stuff but uh you know I sort
of made the plan that okay once I
of made the plan that okay once I
graduate I'm going to do this full-time
graduate I'm going to do this full-time
I'm going to invest a year that's what
I'm going to invest a year that's what
I've said I'm going to spend a year on
I've said I'm going to spend a year on
on this I'm going to see where it goes
on this I'm going to see where it goes
and if I actually have you know if this
and if I actually have you know if this
is going somewhere after a year like
is going somewhere after a year like
clearly going somewhere after a year
clearly going somewhere after a year
then I get to keep doing
it the last two months have been great
it the last two months have been great
if we can just if we keep the growth
if we can just if we keep the growth
trend of the last two months this is set
trend of the last two months this is set
but it's hard because there's a pretty
but it's hard because there's a pretty
limited audience in RL and we're already
limited audience in RL and we're already
getting a large chunk of it what's the
getting a large chunk of it what's the
reason of naming it puffer lib it's a
reason of naming it puffer lib it's a
bunch of tools an infrastructure like
bunch of tools an infrastructure like
what the heck do you call that right
what the heck do you call that right
there's literally no there's nothing I
there's literally no there's nothing I
can call this that's a good visual
can call this that's a good visual
depiction of what this does so here have
depiction of what this does so here have
a puffer fish it's funny it's memeable
a puffer fish it's funny it's memeable
and you can feed it lots of
and you can feed it lots of
libraries understand your Fury over
libraries understand your Fury over
reviewers your effort is not going to
reviewers your effort is not going to
waste in a conference perspective
waste in a conference perspective
someone will be picking your work up a
someone will be picking your work up a
right now help the community a lot in
right now help the community a lot in
Industry it should give you an in yeah
Industry it should give you an in yeah
yeah I mean I I'm fine like I can pay
yeah I mean I I'm fine like I can pay
rent that's not an issue it's just like
rent that's not an issue it's just like
I'd like to be able to scale this stuff
I'd like to be able to scale this stuff
up um
up um
um and it's the thing with reviewers
um and it's the thing with reviewers
that made me really sad in Academia was
that made me really sad in Academia was
by the end of my PhD I figured out how
by the end of my PhD I figured out how
to consistently publish stuff even in
to consistently publish stuff even in
like this wonky area where it's really
like this wonky area where it's really
hard to publish right like I figured out
hard to publish right like I figured out
how to write papers that I could
how to write papers that I could
consistently publish but I hated them
consistently publish but I hated them
like I wrote papers that I considered
like I wrote papers that I considered
bad in order to get them
bad in order to get them
published anytime I wrote something that
published anytime I wrote something that
I was genuinely proud of and I thought
I was genuinely proud of and I thought
was a good paper a good contribution it
was a good paper a good contribution it
would get rejected
would get rejected
so I I don't want to be doing that
so I I don't want to be doing that
anymore right it's like I want to be
anymore right it's like I want to be
able to write the thing that I know is
able to write the thing that I know is
the good thing to write regardless of
the good thing to write regardless of
what the reception is going to be and
what the reception is going to be and
like outside of conferences and stuff
like outside of conferences and stuff
there's a big enough audience for this
there's a big enough audience for this
stuff that if I just do a bunch of
stuff that if I just do a bunch of
different good projects in in round RL
different good projects in in round RL
like that's going to be way way better
like that's going to be way way better
than publishing some random papers yeah
than publishing some random papers yeah
it's very sad but like the thing is
it's very sad but like the thing is
we've done this to ourselves like it's
we've done this to ourselves like it's
the RL Community doing it to ourselves
the RL Community doing it to ourselves
right like this is completely avoidable
right like this is completely avoidable
like if we in in RL because we're
like if we in in RL because we're
reviewing the papers if we just like
reviewing the papers if we just like
stopped rejecting essential things that
stopped rejecting essential things that
we need for the field to move forward on
we need for the field to move forward on
the basis of like them not matching up
the basis of like them not matching up
with science what we consider to be good
with science what we consider to be good
science
science
like there would be an incentive
like there would be an incentive
structure for pH students to do this
structure for pH students to do this
type of work and I wouldn't have to be
type of work and I wouldn't have to be
doing it outside of Academia because it
doing it outside of Academia because it
would already be done I know several
would already be done I know several
people in RL that have done like
people in RL that have done like
absolutely amazing infrastructure work
absolutely amazing infrastructure work
got absolutely zero recognition and they
got absolutely zero recognition and they
[ __ ] off and they took high-paying
[ __ ] off and they took high-paying
jobs working on language models that's
jobs working on language models that's
what they did they just they they said
what they did they just they they said
screw it I'm done with this you know
screw it I'm done with this you know
this is ridiculous there's no money in
this is ridiculous there's no money in
this there's no recognition in this I'm
this there's no recognition in this I'm
just you know deving in the dark for
just you know deving in the dark for
hours and hours on end and they went and
hours and hours on end and they went and
they took high paying jobs working on
they took high paying jobs working on
language
language
models and that's really sad because
models and that's really sad because
like you know when you're working on
like you know when you're working on
really high quality stuff like that
really high quality stuff like that
there should be a way to get your work
there should be a way to get your work
recognized but there isn't and I tried
recognized but there isn't and I tried
for many years to make a way for that to
for many years to make a way for that to
happen and there was just no way to do
happen and there was just no way to do
it from inside of Academia so the way
it from inside of Academia so the way
that I'm looking at this currently is
that I'm looking at this currently is
well if I can just make reinforcement
well if I can just make reinforcement
learning so much faster and easier to
learning so much faster and easier to
work in that you can get really awesome
work in that you can get really awesome
results way more easily right than then
results way more easily right than then
it's going to be way way way easier to
it's going to be way way way easier to
get more people doing RL that's what
get more people doing RL that's what
it's going to
be and I'm glad to be able to talk about
be and I'm glad to be able to talk about
this more publicly as well like I didn't
this more publicly as well like I didn't
have a gag order or anything during my
have a gag order or anything during my
PhD but you know I don't like to I
PhD but you know I don't like to I
didn't want to put like a bunch of
didn't want to put like a bunch of
inflammatory takes around that would
inflammatory takes around that would
reflect badly on you know MIT or my lab
reflect badly on you know MIT or my lab
or anything but now you know I'm
or anything but now you know I'm
graduated this is fully independent
graduated this is fully independent
these are my own only my own opinions
these are my own only my own opinions
not those of my lab or anything else and
not those of my lab or anything else and
yeah I'm very happy to be outspoken
yeah I'm very happy to be outspoken
about that
now what the heck is wrong with
this let's make this give us like the
this let's make this give us like the
top uh 20 five functions
top uh 20 five functions
because this is bizarre this is like a
because this is bizarre this is like a
really bizarre profiling
curve bring investor attention oh
curve bring investor attention oh
investors are not the problem if I
investors are not the problem if I
wanted to get money for this I can get
wanted to get money for this I can get
investors um the thing is it's way way
investors um the thing is it's way way
way better if I can just bootstrap this
way better if I can just bootstrap this
right revenue is is way better than
right revenue is is way better than
investment
this is very very weird this profile
this is very very weird this profile
curve here like the fact that it just
curve here like the fact that it just
goes
from okay so first of all this says that
from okay so first of all this says that
we're losing 30% of our performance
we're losing 30% of our performance
inside of the Python wrapper first step
right and then after
that clip Depp invoke with
casting
clip I don't even know where we're
clip I don't even know where we're
calling clip
let's
let's
um let's grab
this I mute the stupid sound effect on
this I mute the stupid sound effect on
Windows from
this system sounds
mute CL so
okay so what do we have here sorry I
okay so what do we have here sorry I
missed your reply to my
message uh which one the last
message uh which one the last
one I I just said that we like I'm not
one I I just said that we like I'm not
really looking I'm not even really
really looking I'm not even really
looking for investors in this if I
looking for investors in this if I
wanted to get an investment check for
wanted to get an investment check for
something around puffer I could um I've
something around puffer I could um I've
already talked to people who have been
already talked to people who have been
like you know somewhat interested um
like you know somewhat interested um
just in passing
just in passing
it's more that I want revenue for this
it's more that I want revenue for this
uh I I'd like this to be bootstrapped
uh I I'd like this to be bootstrapped
I'd like this to have no strings
I'd like this to have no strings
attached I don't want this to be tied to
attached I don't want this to be tied to
investors and uh you know shareholder
investors and uh you know shareholder
obligation I'd way prefer if I can just
obligation I'd way prefer if I can just
if I can get this thing to just
if I can get this thing to just
bootstrap itself via revenue and self
bootstrap itself via revenue and self
fund uh cool RL lab around that that's
fund uh cool RL lab around that that's
infinitely better
okay so interesting this
is is this discretized at the
is is this discretized at the
moment I thought this was discretized
moment I thought this was discretized
wasn't
wasn't
it hold
on definitely hope it
on definitely hope it
yeah and it's it's going very well at
yeah and it's it's going very well at
the
the
moment I will say like this
moment I will say like this
is this growth
Trend if we keep this up all of the
Trend if we keep this up all of the
problems outside of technical will solve
problems outside of technical will solve
themselves and I'll just be able to keep
themselves and I'll just be able to keep
working on the technical problems like
working on the technical problems like
this is this is what you need
how the heck is this thing spending so
how the heck is this thing spending so
much time in numpy clip there shouldn't
much time in numpy clip there shouldn't
even be clip shouldn't even be
even be clip shouldn't even be
called being called here and then this
called being called here and then this
is in the renderer which we're not
is in the renderer which we're not
running the renderer right yeah we're
running the renderer right yeah we're
not running the
not running the
renderer
so okay what's the report interval
so okay what's the report interval
here 32
that's probably way
too yeah that's probably way too uh too
too yeah that's probably way too uh too
quick
right Miss whoa I've missed a
right Miss whoa I've missed a
lot oh did you just check on the
lot oh did you just check on the
um on the latest environments and stuff
um on the latest environments and stuff
on
on
Twitter stuff is happening fast stuff
Twitter stuff is happening fast stuff
builds fast man
builds fast man
I'm telling you as soon as like I no
I'm telling you as soon as like I no
longer had to care about the academic
longer had to care about the academic
side of things stuff just happens so
side of things stuff just happens so
freaking quickly it's not even
funny this MOA is one week of work so
funny this MOA is one week of work so
far like I guess a week in like a week
far like I guess a week in like a week
and two days week and a half
then and I haven't even been like
then and I haven't even been like
particularly on point either I've been
particularly on point either I've been
like kind of tired kind of burnt out um
like kind of tired kind of burnt out um
been doing a whole bunch of running
been doing a whole bunch of running
that's been you know making it really
that's been you know making it really
hard to to stay focused for long work
hard to to stay focused for long work
sessions and it's still been just
cranking and we're going to get at a
cranking and we're going to get at a
million FPS today it's actually going to
million FPS today it's actually going to
be harder than I thought it was going to
be harder than I thought it was going to
be but uh we're going to get it today
be but uh we're going to get it today
that's the goal the goal for today is to
that's the goal the goal for today is to
actually make the thing in the title
actually make the thing in the title
true busy with PhD proposal only like a
true busy with PhD proposal only like a
month well in a month we've gotten best
month well in a month we've gotten best
class hyperparameter tuning working
class hyperparameter tuning working
we've made a 14 million step per second
we've made a 14 million step per second
snake environment we've made four
snake environment we've made four
different continuous control/ discreet
different continuous control/ discreet
grid environments for multi-agent
grid environments for multi-agent
Learning and we've made this MOA so a
Learning and we've made this MOA so a
lot happens in a
month I would like to know what the heck
month I would like to know what the heck
is calling clip
is calling clip
so we're up to 116,000 steps per second
so we're up to 116,000 steps per second
with profiling
with profiling
overhead um something is wonky here
overhead um something is wonky here
we're still
we're still
losing we're losing nearly 3 seconds out
losing we're losing nearly 3 seconds out
of 10 inside of the Python rapper what
of 10 inside of the Python rapper what
the heck is happening inside the python
the heck is happening inside the python
wrapper
right what the heck is happening
catch you
later welcome to the YouTube
later welcome to the YouTube
folks we're currently optimizing this
folks we're currently optimizing this
thing to a million steps per
thing to a million steps per
second
second
uh looks like there's there's a lot of
uh looks like there's there's a lot of
room for optimization I just have to
room for optimization I just have to
figure out essentially where the
figure out essentially where the
overhead is cuz the profiling tools are
overhead is cuz the profiling tools are
not not they're not doing a great job at
not not they're not doing a great job at
the
the
moment does this thing ever get reset no
moment does this thing ever get reset no
it doesn't look like it
it doesn't look like it
so that's interesting the only thing
so that's interesting the only thing
here that
is self. buff. rewards.
is self. buff. rewards.
fill
zero this could be it
zero this could be it
maybe I wonder if this this is
slow well one thing I could do
slow well one thing I could do
right let's say
um let's say I just put this cast up
um let's say I just put this cast up
here and then I just like comment out
here and then I just like comment out
all the stuff that's not strictly needed
all the stuff that's not strictly needed
right so
I just need this step
right and we'll see if this
right and we'll see if this
works and what infos is just going to be
empty does this reduce the
overhead expected float got unsigned
overhead expected float got unsigned
int uh really
int uh really
that would actually explain
that would actually explain
something though if that is the
case welcome back
do we have does this think we're
do we have does this think we're
supposed to
discretize oh for some reason we have
discretize oh for some reason we have
discretized false
here
here
so it's calling this clipping
so it's calling this clipping
function
constantly do we
constantly do we
care we might not care
we can always clip on the uh we can clip
we can always clip on the uh we can clip
and
and
see if that's really going to be if
see if that's really going to be if
that's going to be a bottleneck we can
that's going to be a bottleneck we can
clip and see so the thing that's
clip and see so the thing that's
different about this project compared to
different about this project compared to
the other ones that I have to think
the other ones that I have to think
about is this is kind of technical but a
about is this is kind of technical but a
lot of the other environments I make
lot of the other environments I make
have like a thousand plus agents in them
have like a thousand plus agents in them
so what that means is that like you're
so what that means is that like you're
making one one Loop through the python
making one one Loop through the python
for every thousand agent steps worth of
for every thousand agent steps worth of
data there only 10 agents in Dota right
data there only 10 agents in Dota right
it's a 5v5 game so what that means is
it's a 5v5 game so what that means is
that I have to be way way way more
that I have to be way way way more
careful about the python overhead and I
careful about the python overhead and I
have to put even more stuff into C than
have to put even more stuff into C than
I normally
I normally
would which isn't hard you know you can
would which isn't hard you know you can
do it it's not
do it it's not
hard but you do have to you know
hard but you do have to you know
actively uh notice and and care about
actively uh notice and and care about
this stuff
so let's see if this does any good for
so let's see if this does any good for
us we were at 116k
before H look at that from 116 straight
before H look at that from 116 straight
up to
180k very nice
180k very nice
so okay now
so okay now
now now we have uh
now now we have uh
9.5
9.5
9.7 okay at least 95% of the total time
9.7 okay at least 95% of the total time
is in in this step function
is in in this step function
here
here
[Music]
[Music]
and I can't tell if we're
and I can't tell if we're
getting I don't think we're getting
getting I don't think we're getting
scyon
scyon
functions in here we need to get the the
functions in here we need to get the the
scon function perf because all all these
scon function perf because all all these
are tiny
are tiny
right test performance there's a little
right test performance there's a little
bit of call Overhead
bit of call Overhead
yeah numpy from file
what I guess there's some weird
what I guess there's some weird
Shenanigans
happening oh this is just a startup
happening oh this is just a startup
overhead that's no big deal wait are we
overhead that's no big deal wait are we
actually timing this right then if this
actually timing this right then if this
is
the wait are we we timing this right we
the wait are we we timing this right we
might not
might not
be yeah we're not timing this perfect
be yeah we're not timing this perfect
we're actually we're losing uh we're
we're actually we're losing uh we're
losing out on some time that we
losing out on some time that we
shouldn't
shouldn't
be so what we should be doing is we put
be so what we should be doing is we put
this tick here we
this tick here we
do this goes
here action cache is going to be 1024
here action cache is going to be 1024
this is just random noise don't worry
this is just random noise don't worry
about
about
it um and
it um and
then we adjust the signature of this to
then we adjust the signature of this to
be
be
en actions
timeout and
then okay so now we have the en reset
then okay so now we have the en reset
not being tracked in this and we can do
not being tracked in this and we can do
test performance of EnV actions
10 so just by fixing our measuring
essentially that should cut out a bunch
essentially that should cut out a bunch
of garbage that we don't want to look
of garbage that we don't want to look
at yeah there you go
at yeah there you go
so now we no longer have a whole bunch
so now we no longer have a whole bunch
of trash to look at in here and uh the
of trash to look at in here and uh the
fact that there are only a few lines
fact that there are only a few lines
means that this is all that's
running all that's running that's
running all that's running that's
substantial
substantial
so we've got a small amount of call
so we've got a small amount of call
Overhead it looks like we've got uh this
Overhead it looks like we've got uh this
S type is actually this cast takes up a
S type is actually this cast takes up a
little bit of time but these are NE
little bit of time but these are NE
neither of these are significant so at
neither of these are significant so at
this point we have to actually get the
this point we have to actually get the
profiling to get into the scon code and
profiling to get into the scon code and
we need to figure out like where in the
we need to figure out like where in the
ithon code stuff is being uh where stuff
ithon code stuff is being uh where stuff
is being Jank essentially
so C
so C
profile there's there's something you
profile there's there's something you
have to do to get these
have to do to get these
things to
things to
work profile is
true slight
true slight
overhead yeah
Coba
Coba
oops ah we have a profile override to
oops ah we have a profile override to
True here this should be
true now there is going to be call
true now there is going to be call
Overhead with this oh I didn't get the
Overhead with this oh I didn't get the
the time on this did
I okay still
I okay still
180k um
180k um
so we're already more than double what
so we're already more than double what
we
started and we don't have to get 1
started and we don't have to get 1
million FPS on this machine either uh
million FPS on this machine either uh
this machine is like half the speed of
this machine is like half the speed of
the actual server so we only need to get
the actual server so we only need to get
like another factor of of maybe two or
like another factor of of maybe two or
three out of this and we'll be good okay
three out of this and we'll be good okay
perfect so now that this is compiled uh
perfect so now that this is compiled uh
we can see the one problem with doing it
we can see the one problem with doing it
this way is you can see that the SPs is
this way is you can see that the SPs is
completely crashed
completely crashed
this is because of the profiling
this is because of the profiling
overhead of running running all this
overhead of running running all this
data collection so this data is not
data collection so this data is not
always 100% accurate because when you
always 100% accurate because when you
have more overhead from profiling than
have more overhead from profiling than
the actual thing that's taking to that's
the actual thing that's taking to that's
actually taking to run
actually taking to run
it you can see how that would make it
it you can see how that would make it
hard right
hard right
but I think that the relative compute
but I think that the relative compute
time should still be more or less
time should still be more or less
correct here
so it's actually a pretty darn nice
so it's actually a pretty darn nice
curve to start with it's a pretty nice
curve to start with it's a pretty nice
profiling
curve I want to get the HTML file just
curve I want to get the HTML file just
so way make sure that I have the latest
so way make sure that I have the latest
one
and we're going to
refresh where is it we're going to
refresh where is it we're going to
refresh this
file let me make sure it refreshed yeah
file let me make sure it refreshed yeah
so now this returns an INT perfect uh
so now this returns an INT perfect uh
this still is not typed correctly but
this still is not typed correctly but
whatever so I'm going to make sure that
whatever so I'm going to make sure that
you can see this on the Stream
okay so now all we have to do is we
okay so now all we have to do is we
basically we go through all of these and
basically we go through all of these and
we see if any of this is uh caused by
we see if any of this is uh caused by
calls back to python versus algorithmic
calls back to python versus algorithmic
overhead versus me having designed stuff
overhead versus me having designed stuff
stupid so the first function I see is
stupid so the first function I see is
scan
scan
AOE that I believe is algorithmic
AOE that I believe is algorithmic
overhead I think we're going to have to
overhead I think we're going to have to
do some caching there I think that
do some caching there I think that
that's probably a very efficient
that's probably a very efficient
function that just needs to be cached so
function that just needs to be cached so
as you can see this function runs in
as you can see this function runs in
pure
C it does do a number of checks that I
C it does do a number of checks that I
could potentially improve
could potentially improve
upon
um yeah it does do a number of checks
um yeah it does do a number of checks
that I could potentially improve upon I
that I could potentially improve upon I
could save some time that way but I
could save some time that way but I
think that most likely is going to
be uh that this function can't get cold
be uh that this function can't get cold
every single frame right now it's
every single frame right now it's
getting cold every frame uh on every
getting cold every frame uh on every
creep so like everybody's constantly
creep so like everybody's constantly
rescanning for targets and I think that
rescanning for targets and I think that
if you uh you just run this thing at a
if you uh you just run this thing at a
more reasonable interval that'll
more reasonable interval that'll
probably be fine though there's going to
probably be fine though there's going to
have to be a little caching for that
have to be a little caching for that
maybe uh we have step function itself
maybe uh we have step function itself
the step function should be a very large
the step function should be a very large
function and
and we do
have we do have a call back to python
have we do have a call back to python
right
here welcome fruit punch Samurai
here welcome fruit punch Samurai
welcome welcome
exx we are optimizing the hell out of
exx we are optimizing the hell out of
this
this
code we're currently at 180,000 is the
code we're currently at 180,000 is the
best that I've seen so
best that I've seen so
far and uh the goal is 500,000 on this
far and uh the goal is 500,000 on this
machine at minimum which will be uh over
machine at minimum which will be uh over
a million on the the Box miss a few
a million on the the Box miss a few
streams yeah well I'll show since
streams yeah well I'll show since
there's some people I'll show the GIF
there's some people I'll show the GIF
while I look at uh I'll pull the GIF up
while I look at uh I'll pull the GIF up
while I continue looking at this that's
while I continue looking at this that's
the latest version
it plays full games
now so this call here is calling back to
now so this call here is calling back to
python uh this numpy actions is not
python uh this numpy actions is not
typed it probably should be
typed this is a very slow call back to
typed this is a very slow call back to
python which is weird
python which is weird
use Q is a
beant weird we will fix
beant weird we will fix
that and then these return values are
that and then these return values are
also uh because step doesn't have a
also uh because step doesn't have a
return type okay
return type okay
cool yeah this is what I did this is how
cool yeah this is what I did this is how
we ended the stream yesterday uh we have
we ended the stream yesterday uh we have
we're basically just reusing this the
we're basically just reusing this the
creep AI on the heroes and then we have
creep AI on the heroes and then we have
three Heroes assigned to Safe Lane one
three Heroes assigned to Safe Lane one
assigned to Mid and one assigned to off
assigned to Mid and one assigned to off
lane or hard Lane uh and they will play
lane or hard Lane uh and they will play
full
games so let's just fix step real quick
games so let's just fix step real quick
just to see if that does anything
so it's a little awkward because this is
so it's a little awkward because this is
a de function which is supposed to be
a de function which is supposed to be
python API but I think we'll just expose
python API but I think we'll just expose
this with
this with
cpde which allows us to add a little bit
cpde which allows us to add a little bit
of extra typing information and then we
of extra typing information and then we
can do mp. ND array or it should be cn.
can do mp. ND array or it should be cn.
ND array so we add typing information to
ND array so we add typing information to
this and I think that this will still
this and I think that this will still
potentially trigger a call back to
potentially trigger a call back to
python the only
python the only
one yeah only
one yeah only
one and then this one is the big one
one and then this one is the big one
that breaks the loop right here is this
that breaks the loop right here is this
uh in continuous whatever greater than
uh in continuous whatever greater than
zero greater than
0.5 that's kind of weird the way I
0.5 that's kind of weird the way I
structured this isn't it
I mean we're not using this at the
I mean we're not using this at the
moment whatsoever so I'm just going to
moment whatsoever so I'm just going to
comment
comment
this and then like too breaks
python we're not using this at the
python we're not using this at the
moment
anyways and I think this is the only
anyways and I think this is the only
thing that calls back to python
thing that calls back to python
so yeah
okay and then we should have a new HTML
okay and then we should have a new HTML
file we'll move it we'll
file we'll move it we'll
refresh perfect so this is now no longer
refresh perfect so this is now no longer
yellow and this is still okay as I
yellow and this is still okay as I
expected this is still yellow but this
expected this is still yellow but this
is once per frame this is not in a loop
is once per frame this is not in a loop
no big
no big
deal um
deal um
uh potentially some method call
uh potentially some method call
optimizations we can make I know how to
optimizations we can make I know how to
do that separately no big
deal a lot of these method calls I'm not
deal a lot of these method calls I'm not
positive actually I think this is the
positive actually I think this is the
profile overhead actually like the
profile overhead actually like the
reason a lot of these have this yellow
reason a lot of these have this yellow
is because I'm running profiling we can
is because I'm running profiling we can
check on that though okay so now that we
check on that though okay so now that we
have this running we can do our
have this running we can do our
profiling
profiling
again not expecting a huge difference
maybe something
though step is okay step is still at the
though step is okay step is still at the
same roughly the same Pace um it's
same roughly the same Pace um it's
saying a quarter of the time is being
saying a quarter of the time is being
spent inside the step function and not
spent inside the step function and not
inside any of the other functions that
inside any of the other functions that
are being
are being
profiled kind of weird
profiled kind of weird
I mean I guess we do have like Loops
I mean I guess we do have like Loops
like this but this is a percent this is
like this but this is a percent this is
like not called very often the percent
600 we have some method
600 we have some method
calls oh oh I know if the method calls
calls oh oh I know if the method calls
themselves are going back to python
themselves are going back to python
maybe but wait if the method calls were
maybe but wait if the method calls were
going back to python they should show up
going back to python they should show up
in yellow
here I think they should show up in
here I think they should show up in
yellow I could be wrong let me find
yellow I could be wrong let me find
something that definitely calls back to
something that definitely calls back to
python okay so nearest scan Target for
python okay so nearest scan Target for
instance calls back to Python and uh I
instance calls back to Python and uh I
know that nearest scan Target is called
know that nearest scan Target is called
from like Tower AI or creep AI or
from like Tower AI or creep AI or
something uh but it's not showing up
something uh but it's not showing up
here so probably it's just the method
here so probably it's just the method
calls are actually going back to python
calls are actually going back to python
uh and we'll have to figure that out as
uh and we'll have to figure that out as
my guess
let's focus then on uh some of the the
let's focus then on uh some of the the
lower level ones so we've got compute
lower level ones so we've got compute
observations that's a pretty performance
observations that's a pretty performance
critical
thing and uh we can see that I
thing and uh we can see that I
have some typing problems it looks
have some typing problems it looks
like R is typed as an INT and Dy is
like R is typed as an INT and Dy is
typed as an INT
typed as an INT
is this cast not
valid I thought that this cast was
valid see it's not why is this
valid see it's not why is this
valid this move to function
valid this move to function
here this is not triggering a call back
here this is not triggering a call back
to python this is parsing as a valid
cast why is the other one not parsing as
cast why is the other one not parsing as
a valid
cast R is an
cast R is an
INT int of player is player not
defined I don't see play oh wait here it
defined I don't see play oh wait here it
is player entity start
is player entity start
player Y is equal to player get y
well this doesn't need to be player doy
well this doesn't need to be player doy
right this can
right this can
be this can just be y because I computed
be this can just be y because I computed
it up here though I don't know why it
it up here though I don't know why it
would make a difference let's
see this is a very um performance
see this is a very um performance
critical function
critical function
though int y
what how the heck am I doing
what how the heck am I doing
this Dy
in okay I'm just doing this in a very
in okay I'm just doing this in a very
stupid way I
stupid way I
think
because and then we have Y and X I
because and then we have Y and X I
guess yeah I think I'm just doing this
guess yeah I think I'm just doing this
in a very stupid way
this is a perform this is absolutely a
this is a perform this is absolutely a
performance critical function by the way
performance critical function by the way
this is this is called on every hero on
this is this is called on every hero on
every frame and it does a
every frame and it does a
scan and it fills in a bunch of data it
scan and it fills in a bunch of data it
copies a bunch of data so this is very
copies a bunch of data so this is very
performance critical
so
so
here we got to go slow with this
here we got to go slow with this
um we've got float y float X do we use Y
um we've got float y float X do we use Y
and X
and X
anywhere no we do
anywhere no we do
not so we do not need
these we do want Y and X Maybe
how do I do it in scan
how do I do it in scan
AOE I think that this is a more recent
AOE I think that this is a more recent
piece of
piece of
code I did actually do Dy and DX
here it's not terrible
I think I could do this
potentially but I think that actually
potentially but I think that actually
both of these are going to be more
both of these are going to be more
efficient If instead of computing the
efficient If instead of computing the
Delta offset like this I just use Y and
Delta offset like this I just use Y and
X
X
directly so if I do if Y is in a range
directly so if I do if Y is in a range
of
um let's do yeah let's use R for this
um let's do yeah let's use R for this
maybe cuz Y is going to be an INT
maybe cuz Y is going to be an INT
now we're going to do int
now we're going to do int
y yeah int r c int
y yeah int r c int
Y and X so we're going to have x y r and
Y and X so we're going to have x y r and
c and then we're going to
do y is going to be int of player. y x
do y is going to be int of player. y x
is going to be int player.
X you have to talk about Insel lot when
X you have to talk about Insel lot when
you're talking about
mobus can't have your creeps
inting um this is going to be y minus
inting um this is going to be y minus
Vision
Vision
range y plus Vision
range y plus Vision
range right we don't need this garbage
range right we don't need this garbage
math in here
math in here
and then this is going to be C in a
and then this is going to be C in a
range of x minus Vision
range of x minus Vision
range X Plus Vision range plus one now
range X Plus Vision range plus one now
we get the target PID if it's negative 1
we get the target PID if it's negative 1
we
we
continue we get the target we have to
continue we get the target we have to
figure this out but we're not doing that
figure this out but we're not doing that
right now because it's going to be
right now because it's going to be
really boring to
really boring to
watch and
watch and
then I think that's all of our typing
then I think that's all of our typing
problems solved do we use agent idx
problems solved do we use agent idx
anywhere we don't use agent idx get rid
anywhere we don't use agent idx get rid
of this garbage we do use idx it looks
of this garbage we do use idx it looks
like do we use
like do we use
PID we do use
PID uh and we use Target PID and Target
PID uh and we use Target PID and Target
and Target up okay so let me make sure
and Target up okay so let me make sure
this makes sense the way the compute
this makes sense the way the compute
observation function works is we're
observation function works is we're
going to go
going to go
through self. num
through self. num
agents which should be 10
agents which should be 10
this is hardcoded these numbers but uh
this is hardcoded these numbers but uh
you're essentially we're setting we're
you're essentially we're setting we're
setting the observed values to negative
setting the observed values to negative
one to start with this is just clearing
one to start with this is just clearing
a
a
buffer this is a sanity check it's kind
buffer this is a sanity check it's kind
of slow but you know we'll improve that
of slow but you know we'll improve that
later I'm looking for low hanging fruit
later I'm looking for low hanging fruit
first we get the player that we're
first we get the player that we're
currently Computing the observations for
currently Computing the observations for
the main set of observations is going to
the main set of observations is going to
be a
be a
slice into the grid
slice into the grid
that is just going to tell you the uh
that is just going to tell you the uh
obstructions around you essentially this
obstructions around you essentially this
is like a map that gives you some basic
is like a map that gives you some basic
highle information about what is around
highle information about what is around
you and then the main meat of this
you and then the main meat of this
function right here is a much more
function right here is a much more
detailed
detailed
map that tells you about any agents that
map that tells you about any agents that
are nearby you so you're going to go
are nearby you so you're going to go
through all your surrounding tiles and
through all your surrounding tiles and
you're going to look for uh potential
you're going to look for uh potential
agents creeps anything like like that
agents creeps anything like like that
and then for you're going to extract a
and then for you're going to extract a
bunch of additional uh information about
bunch of additional uh information about
these up to 10 so you're going to
these up to 10 so you're going to
extract up to 10 agents worth of
extract up to 10 agents worth of
information around you and uh this
information around you and uh this
probably as a to-do we should do this
probably as a to-do we should do this
like sort by distance it should probably
like sort by distance it should probably
be the 10 nearest agents to you uh and
be the 10 nearest agents to you uh and
frankly we can probably repurpose the
frankly we can probably repurpose the
scan AOE function cuz the scan AOE
scan AOE function cuz the scan AOE
function is perfect for this it just
function is perfect for this it just
gives you the nearby Targets for now
gives you the nearby Targets for now
we're going to leave it this way though
we're going to leave it this way though
and we're going to see if we actually
and we're going to see if we actually
improved
anything doesn't look like I broke
anything if I didn't break anything then
anything if I didn't break anything then
we should have a new HTML file here
we should have a new HTML file here
which which we do
which which we do
we'll move over the HTML file we'll
we'll move over the HTML file we'll
refresh this and now our compute
refresh this and now our compute
observation function runs in pure C
observation function runs in pure C
isn't that nice so it basically looks
isn't that nice so it basically looks
like python it's almost identical to
like python it's almost identical to
python code that you would write but
python code that you would write but
this is pure native c-e for this
this is pure native c-e for this
performance critical
function I don't know if it's going to
function I don't know if it's going to
give us any benefit just
give us any benefit just
yet we'll
see ooh
see ooh
um it looks like I potentially
um it looks like I potentially
introduced a bug in the
introduced a bug in the
process differing Dimensions extend 11 Z
process differing Dimensions extend 11 Z
that's
gross runtime bugs are
gross ah because I forgot to do this R
gross ah because I forgot to do this R
and see hold on
excuse
excuse
me I just forgot to update some variable
me I just forgot to update some variable
names this is supposed to be I renamed R
names this is supposed to be I renamed R
and C so this is now y this is
and C so this is now y this is
X this is y and this is
X this is y and this is
X uh and that should be
fine okay playing mute toggle game here
refreshes we copy the Coba thing over we
refreshes we copy the Coba thing over we
make sure we've got our new source which
make sure we've got our new source which
we do we run our performance
test runs for 10
test runs for 10
seconds
roughly and there we go so
this is indeed much
this is indeed much
faster we
saved we saved I think about a third of
saved we saved I think about a third of
the compute that was just being thrown
the compute that was just being thrown
away on that function from periodically
away on that function from periodically
calling back to
calling back to
python this used to be uh a full second
python this used to be uh a full second
I
I
believe so we shaved off a little bit
believe so we shaved off a little bit
there really though I want I'm looking
there really though I want I'm looking
for bigger performance improvements than
for bigger performance improvements than
this um
this um
I
I
see it's a little hard to tell though
see it's a little hard to tell though
because this thing this profiler adds so
because this thing this profiler adds so
much overhead like C profile adds this
much overhead like C profile adds this
should run 180,000 at least steps per
should run 180,000 at least steps per
second so with 90% overhead it's
second so with 90% overhead it's
sometimes hard to tell which of these
sometimes hard to tell which of these
timings to trust and which
timings to trust and which
not
um let's see some like some things that
um let's see some like some things that
if we have some some basic free wins
if we have some some basic free wins
here uh creep AI is kind of
slow all this stuff doesn't
slow all this stuff doesn't
matter entity star get player OB get
matter entity star get player OB get
entity what the heck why is this
running I'm pretty sure that's just the
running I'm pretty sure that's just the
profile overhead I don't see how it
profile overhead I don't see how it
would be possible for this thing to be
would be possible for this thing to be
this slow because this is literally just
this slow because this is literally just
a
lookup I might want to
lookup I might want to
try I I'm going to do an experiment so
try I I'm going to do an experiment so
this is 7 Seconds right now which is not
this is 7 Seconds right now which is not
insubstantial and I have a lot of
insubstantial and I have a lot of
functions like this so
what if I inline this
right cdef inline entity
right cdef inline entity
star does this do
anything this should tell the compiler
anything this should tell the compiler
to never treat this as a separate
to never treat this as a separate
function it should always try to just
function it should always try to just
put this operation directly into the
put this operation directly into the
code um so like this is a on line
code um so like this is a on line
function
function
instead of instead of calling this
instead of instead of calling this
function everywhere and adding the
function everywhere and adding the
overhead of a call it should just run
overhead of a call it should just run
that one line of code directly
that one line of code directly
wherever it's kind of like not having a
wherever it's kind of like not having a
function and just copy pasting it
everywhere doesn't always do
anything and in this case yeah so this
anything and in this case yeah so this
didn't do anything uh I'm not going to
didn't do anything uh I'm not going to
do it if it doesn't have the clear B
do it if it doesn't have the clear B
benefit um I suspect that this is just
benefit um I suspect that this is just
function like profiling overhead because
function like profiling overhead because
this function is called very very often
this function is called very very often
you can see the number of calls and if
you can see the number of calls and if
there's just a little bit of profiling
there's just a little bit of profiling
overhead associated with this then that
overhead associated with this then that
this would be what you would get out of
it very obnoxious though that this is
like that this is happens with your
like that this is happens with your
profiling code right is there like a
profiling code right is there like a
decorator no profile
decorator is there can you use a pyx
decorator is there can you use a pyx
decorator or
decorator or
something scon that
something scon that
profile I think this is the python
profile I think this is the python
API I don't think there's a good way to
API I don't think there's a good way to
do that
oh wait here it
oh wait here it
is C import scon at python.
profile
profile
perfect Let's uh let's see what happens
perfect Let's uh let's see what happens
with this because we might be able to
with this because we might be able to
get some more reasonable results by
get some more reasonable results by
ignoring these little tiny
functions so C import scon
we're going to do at on. profile false I
we're going to do at on. profile false I
want to see if it doesn't show up in my
want to see if it doesn't show up in my
profile anymore because it would be
profile anymore because it would be
really nice if I could just ignore these
really nice if I could just ignore these
these short
these short
functions um because they make it really
functions um because they make it really
hard to profile when you have this much
hard to profile when you have this much
overhead like anytime I'm timing a
overhead like anytime I'm timing a
function that's calling this thing a
function that's calling this thing a
bunch of times I'm adding like a a
bunch of times I'm adding like a a
python call back or a profile call back
python call back or a profile call back
every time and it makes it really hard
every time and it makes it really hard
to get consistent
results does this show
up or does it respect my
override it looks like it respects my uh
override it looks like it respects my uh
my override here the steps per second
my override here the steps per second
went up by a little
went up by a little
bit
bit
and yeah okay so it omitted this
and yeah okay so it omitted this
function uh from
function uh from
profiling
and wow that actually made a huge
and wow that actually made a huge
difference didn't it like the whole
difference didn't it like the whole
profile table changed just from
profile table changed just from
that I think it's going to be worth
that I think it's going to be worth
adding this to all of the small little
adding this to all of the small little
functions um because like it doesn't not
functions um because like it doesn't not
profiling the function doesn't mean
profiling the function doesn't mean
we're not profiling that code
we're not profiling that code
it just means that we're not separately
it just means that we're not separately
profiling that code so
profiling that code so
like
here we are profiling this code
here we are profiling this code
implicitly anytime we're calling this
implicitly anytime we're calling this
function from somewhere else but the
function from somewhere else but the
thing is like if I look at the table
thing is like if I look at the table
where is it if I look at the scon op
where is it if I look at the scon op
table I see that all these functions are
table I see that all these functions are
already optimized like the returns of
already optimized like the returns of
all these functions are already pure C
all these functions are already pure C
anyways um and they're already properly
anyways um and they're already properly
typed
typed
so there's no reason to uh there's no
so there's no reason to uh there's no
reason to go further than that with
reason to go further than that with
it and actually if I move this can I see
it and actually if I move this can I see
the profile line taking effect here oh
the profile line taking effect here oh
look look how cool this
look look how cool this
is you add this decorator and now this
is you add this decorator and now this
function shows properly as being in pure
function shows properly as being in pure
C because if you look here this is just
C because if you look here this is just
a raw function call whereas this one it
a raw function call whereas this one it
has all this traceback stuff that is
has all this traceback stuff that is
being used for the profiler so this is
being used for the profiler so this is
actually perfect because it's being
actually perfect because it's being
annotated but it's not being profiled
annotated but it's not being profiled
right if I do like xals 2 here what
right if I do like xals 2 here what
happens I want to make sure that we
happens I want to make sure that we
actually have this working as intended
actually have this working as intended
because it's very very
important okay we recompile
and then we rerun I want to make
and then we rerun I want to make
absolutely sure that The annotation is
absolutely sure that The annotation is
going to pick up stuff even that's not
going to pick up stuff even that's not
in profile
blocks I'm very confident that this is
blocks I'm very confident that this is
the case but this would screw everything
the case but this would screw everything
uh everything else up otherwise okay so
uh everything else up otherwise okay so
we ran the
we ran the
profiler we move this
file ooh that's Jank
Pi
VX oh wait I think it could just be the
VX oh wait I think it could just be the
compiler optimizing it out
right h
let me let me try one other thing and
let me let me try one other thing and
then we'll uh we'll stop with this line
then we'll uh we'll stop with this line
of inquiry because the compiler is going
of inquiry because the compiler is going
to be tricky but this is
to be tricky but this is
suspicious I'm going to try to trick the
suspicious I'm going to try to trick the
compiler
here so what we're going to do is for I
here so what we're going to do is for I
in
in
range let's do like a self variable
range let's do like a self variable
something that's Dynamic and we're going
something that's Dynamic and we're going
to go like PID plus
to go like PID plus
equals uh
equals uh
I
I
so let's see if this can trick the
so let's see if this can trick the
compiler obviously we can't run this
compiler obviously we can't run this
code now because I've just broken the
code now because I've just broken the
logic um but you don't need to run the
logic um but you don't need to run the
code for annotation purposes it's
code for annotation purposes it's
compile
time okay and perfect so this is exactly
time okay and perfect so this is exactly
what I was looking for you see
what I was looking for you see
so right
so right
here this function it has profiling
here this function it has profiling
disabled but annotation is on so if I
disabled but annotation is on so if I
add something that's going to make the
add something that's going to make the
compiler call back to python even though
compiler call back to python even though
I'm not profiling it I can actually see
I'm not profiling it I can actually see
that it's calling back to python here
that it's calling back to python here
and importantly if I remove this like we
and importantly if I remove this like we
saw before uh this is going to turn
saw before uh this is going to turn
white telling us that this is a pure C
white telling us that this is a pure C
call so that's exactly what we want and
call so that's exactly what we want and
then we'll be able to do our inline
then we'll be able to do our inline
Shenanigans and we'll be able to run
Shenanigans and we'll be able to run
that experiment correctly as
well we're going to take all of these
well we're going to take all of these
shitty little functions and these are
shitty little functions and these are
all going to be profile
off don't need to profile any of these
off don't need to profile any of these
like stupid little functions
they will all be profiled
purely we're not even going to inline
purely we're not even going to inline
them for now we'll do the inline
them for now we'll do the inline
experiment 100%
separate boom okay none of these are now
separate boom okay none of these are now
profiled and I think that's yeah that
profiled and I think that's yeah that
should be all of the Annoying uh little
should be all of the Annoying uh little
functions
we build and we should actually just by
we build and we should actually just by
that we should be getting something
that we should be getting something
that's at least within a a factor of the
that's at least within a a factor of the
actual performance of our environment
actual performance of our environment
despite the profiling overhead cuz most
despite the profiling overhead cuz most
of the profiling overhead comes from
of the profiling overhead comes from
these small little functions that are
these small little functions that are
just getting like chucked in with the
just getting like chucked in with the
the rest of the
profiler over per.
this will run for 10
this will run for 10
seconds so much better so this is now
seconds so much better so this is now
three times faster than before which is
three times faster than before which is
still like a quarter of the speed of our
still like a quarter of the speed of our
actual
actual
environment but this at least now we
environment but this at least now we
have some hope of being able to tell
have some hope of being able to tell
relatively what's important and what
relatively what's important and what
isn't right
so let's
so let's
see move function update status up upate
see move function update status up upate
cool
cool
Downs lots of these little functions
Downs lots of these little functions
let's see
um are those functions
um are those functions
bad let's hold on let's run this run
bad let's hold on let's run this run
this do perfect look at
this do perfect look at
that pure
C let's look for like update
C let's look for like update
status and cooldowns
so this is an obnoxious amount of time
so this is an obnoxious amount of time
to be spending in these functions right
to be spending in these functions right
look at the number of calls
here this gets called on every entity at
here this gets called on every entity at
every
every
step so even though these functions are
step so even though these functions are
pretty highly optimized like these are
pretty highly optimized like these are
just straight up conditionals
they're taking a lot of overhead just
they're taking a lot of overhead just
because of the amount of times they're
because of the amount of times they're
getting
getting
called um that's actually kind of useful
called um that's actually kind of useful
because it tells us that any function
because it tells us that any function
that's getting called every step every
that's getting called every step every
entity is going to add like0 2.3 seconds
right so like these neutral AI functions
right so like these neutral AI functions
and stuff
three of this is just or I think 0.15 of
three of this is just or I think 0.15 of
this is just call
this is just call
Overhead that gives you a scale of like
Overhead that gives you a scale of like
how efficient we're talking
here I want to take these out of the
here I want to take these out of the
profiling though as well because these
profiling though as well because these
are like
are like
[Music]
[Music]
so so
minor and again we're trying to figure
minor and again we're trying to figure
out
where where we're losing perf on
where where we're losing perf on
step and this isn't telling us where
step and this isn't telling us where
we're losing perf on step the step is
we're losing perf on step the step is
definitely really slow and we're not
definitely really slow and we're not
able to tell why at the moment U because
able to tell why at the moment U because
of this other profiling
overhead a nice thing to note about the
overhead a nice thing to note about the
stuff that I'm doing right
stuff that I'm doing right
here um if you think about it I would be
here um if you think about it I would be
this doing this exact type of profiling
this doing this exact type of profiling
in C or C++ or any other language I'd be
in C or C++ or any other language I'd be
having to do this exact same type of
having to do this exact same type of
profiling so I'm not just doing this
profiling so I'm not just doing this
because it's syon this is like identical
because it's syon this is like identical
to the profiling work I'd be doing in
to the profiling work I'd be doing in
anything else just with additional
tools so this is
tools so this is
when you think of it that
way not too bad on the
workflow we
workflow we
rebuild I'm expecting 50,000 maybe
rebuild I'm expecting 50,000 maybe
50,000 steps per
second we'll run M perf and we will copy
second we'll run M perf and we will copy
this over to the docker
this over to the docker
again and now we we can see that these
again and now we we can see that these
are pure
are pure
C these are pure C
functions oh that was way more than I
functions oh that was way more than I
expected 67,000 steps per second uh
expected 67,000 steps per second uh
without that profile
without that profile
overhead there's still a few functions
overhead there's still a few functions
that you can tell have a lot of overhead
that you can tell have a lot of overhead
like this is these are huge call
like this is these are huge call
amounts but now we get to look at these
amounts but now we get to look at these
functions individually so
did this just
did this just
shift hold on oh that's really major
shift hold on oh that's really major
look so before step was at 3.6
look so before step was at 3.6
seconds and it was twice the amount of
seconds and it was twice the amount of
time is creep AI right and scan AOE so
time is creep AI right and scan AOE so
I'd say hey look we're losing most of
I'd say hey look we're losing most of
the perf in Step but actually when you
the perf in Step but actually when you
take out these crappy little functions
take out these crappy little functions
that are just triggering call Overhead
that are just triggering call Overhead
cuz step
cuz step
here step here is triggering profile
here step here is triggering profile
overhead every single time it calls one
overhead every single time it calls one
of these functions update status update
of these functions update status update
cool down which is every single entity
cool down which is every single entity
in the game when you take this out of
in the game when you take this out of
the
the
overhead the step function actually
overhead the step function actually
looks way better right it's only two
looks way better right it's only two
seconds and scan AOE is pretty much the
seconds and scan AOE is pretty much the
same amount of time and the neutral AI
same amount of time and the neutral AI
is also a big chunk of
is also a big chunk of
time and it's actually even now with the
time and it's actually even now with the
creep AI the creep AI is even a little
creep AI the creep AI is even a little
bit
bit
slower so I think we continue on this we
slower so I think we continue on this we
continue we're going to optimize the
continue we're going to optimize the
little functions and then we're going to
little functions and then we're going to
take them out of profile until we figure
take them out of profile until we figure
out like the relative assignment
out like the relative assignment
of how expensive the big functions are
of how expensive the big functions are
and then we're going to figure out once
and then we're going to figure out once
we no longer have anything left to
we no longer have anything left to
optimize on just like the
optimize on just like the
cide then we're going to think about
cide then we're going to think about
like caching targeting and stuff like
like caching targeting and stuff like
that and we're probably only going to
that and we're probably only going to
have to make two or three changes to
have to make two or three changes to
this whole code base in order to like
this whole code base in order to like
from the whole start until now there
from the whole start until now there
going to be like two or three High LEL
going to be like two or three High LEL
changes that we have to make to take
changes that we have to make to take
this thing from 70,000 steps per second
this thing from 70,000 steps per second
to a million steps per
to a million steps per
second it's really that
easy and the difference between 70,000
easy and the difference between 70,000
and a million let me put this into
perspective if you want to get a million
perspective if you want to get a million
steps per second train and your
steps per second train and your
environment runs at a million steps per
environment runs at a million steps per
second you just need to run two of those
second you just need to run two of those
environments and like call them back and
environments and like call them back and
forth so when one is generating data for
forth so when one is generating data for
you the other one is ready and you just
you the other one is ready and you just
go back and forth very easy if you have
go back and forth very easy if you have
a 70,000 step per second environment you
a 70,000 step per second environment you
need like 20 cores and they have to be
need like 20 cores and they have to be
very very tightly uh and accurately
very very tightly uh and accurately
relaying information across all the
relaying information across all the
process boundaries otherwise you lose
process boundaries otherwise you lose
too much of it and you won't get a
too much of it and you won't get a
million steps per second so it's so much
million steps per second so it's so much
easier when your environment is just
easier when your environment is just
fast by
default I see we've got a lot of folks
default I see we've got a lot of folks
on YouTube so uh welcome all of this
on YouTube so uh welcome all of this
stuff is open source um this is all
stuff is open source um this is all
available in puffer lib which is the
available in puffer lib which is the
main project I work on it's on
main project I work on it's on
github.com puffer ipuff currently we are
github.com puffer ipuff currently we are
on the in config Branch it's going to be
on the in config Branch it's going to be
merged into Dev soon it's in environment
merged into Dev soon it's in environment
ocean you can play around with it there
ocean you can play around with it there
uh if you like my work please start the
uh if you like my work please start the
repo helps me out a whole ton slend
add okay um function to start with next
add okay um function to start with next
I
I
think compute observation is actually
think compute observation is actually
looking pretty good
looking pretty good
now I'm pretty happy with
now I'm pretty happy with
that yeah let's go to nearest scan
that yeah let's go to nearest scan
Target I think this is the first place
Target I think this is the first place
nearest
nearest
scan Target okay so L2 distance is
scan Target okay so L2 distance is
calling back to python that's really
calling back to python that's really
bad that's like a straight up error on
bad that's like a straight up error on
my part why is it calling back
to why is L2 distance calling back to
to why is L2 distance calling back to
python it doesn't look like it
python it doesn't look like it
should it's a float that takes in a
should it's a float that takes in a
bunch of
bunch of
floats and returns a float
ER
huh wait why is this
highlighted Pi error occurred
huh it's injecting some sort of error
huh it's injecting some sort of error
check
check
here Pi error
occurred is there a division
thing compiler thinks that this function
thing compiler thinks that this function
can throw an error and it's not being
can throw an error and it's not being
caught by my current error
caught by my current error
checks I have all these flags at the top
checks I have all these flags at the top
saying we're using C division we're not
saying we're using C division we're not
doing bounds checking initialize check
doing bounds checking initialize check
we're not doing any of
that isn't squared also
that isn't squared also
slow power function is slow
right is there a better square root
right is there a better square root
function of as well that we can use and
see where
see where
is where's the C square root function
okay there is a just a built-in square
okay there is a just a built-in square
root is there a float version of
it C float square root standard
Library Square Root
F okay so we need to import this
F okay so we need to import this
and then we need to
and then we need to
implement uh we need to just change a
implement uh we need to just change a
couple small
things so this L2 and I think we should
things so this L2 and I think we should
just do
just do
cdef so
cdef so
float DX is going to be X1 -
X2 and then we're going to return square
X2 and then we're going to return square
root like
this and then we need to do
yeah and this should be square root F
yeah and this should be square root F
isn't
it cuz there
floats is there a faster there's not
floats is there a faster there's not
like a fast L2 in C standard Library no
like a fast L2 in C standard Library no
C standard library is small so I think
C standard library is small so I think
that this is what we
that this is what we
want let's try this
want let's try this
out let's see if this does anything for
us this is the type of optimization you
us this is the type of optimization you
have to do for this
though so let's go get the new
file we should have a new
function distance
okay we have a new distance function
okay we have a new distance function
right this nearest scan went
right this nearest scan went
down I can see that this went
down I can see that this went
down uh it's
down uh it's
still it is still saying that there
still it is still saying that there
is a error check on this
is a error check on this
though so now the code is
though so now the code is
different let's see so we went up from
different let's see so we went up from
67 to
67 to
69,000 steps per second this is with
69,000 steps per second this is with
profiling overhead it's like
profiling overhead it's like
200,000 uh without profiling overhead
200,000 uh without profiling overhead
and then it'll be like 4 to 500,000 on
and then it'll be like 4 to 500,000 on
the actual machine that we'll be using
the actual machine that we'll be using
for training so we're like a factor of
for training so we're like a factor of
two maybe two and a half off
two maybe two and a half off
still
um this function here is
Step
Step
oh yeah so we have very little python
oh yeah so we have very little python
overhead this is fine nearest scan
overhead this is fine nearest scan
Target is down
Target is down
to.5 with a ton of calls so this is
to.5 with a ton of calls so this is
mostly call Overhead actually which it
mostly call Overhead actually which it
should be nearest scan Target should be
should be nearest scan Target should be
very
very
fast uh and actually I think that most
fast uh and actually I think that most
of this overhead is coming from
of this overhead is coming from
this this right here well this is
this this right here well this is
bizarre though
like this is something I don't
like this is something I don't
understand and I want to learn right now
understand and I want to learn right now
um
um
um somehow this function can potentially
um somehow this function can potentially
throw throw an
error is this something with how square
error is this something with how square
root is
implemented can square root F throw an
error I don't know why it would throw a
error I don't know why it would throw a
pi error that's
bizarre let's look at this
bizarre let's look at this
code this is what it compiles
code this is what it compiles
too I don't know if anybody watching has
too I don't know if anybody watching has
any idea you can go ahead and let me
any idea you can go ahead and let me
know I have no
know I have no
idea
uh so these are just like automatically
uh so these are just like automatically
generated variable names obviously
generated variable names obviously
they're
they're
garbage this is the L2 function that we
garbage this is the L2 function that we
defined you can see it has a bunch of
defined you can see it has a bunch of
garbage but it has our uh distance
function this is right here this is the
function this is right here this is the
pointer D reference right neutral y
pointer D reference right neutral y
neutral X Target y Target
neutral X Target y Target
X and then we get if
X and then we get if
unlikely we can actually just read this
unlikely we can actually just read this
out right if
unlikely the output of this
unlikely the output of this
function pix tore
function pix tore
3 is equal to
-1 and pi High error
-1 and pi High error
occurred so if this function returns
occurred so if this function returns
-1
H that's the C error code what's this Pi
H that's the C error code what's this Pi
error occurred
though Pi error
pxl1 hey everybody's been saying chat
pxl1 hey everybody's been saying chat
gepd is going to solve everything right
gepd is going to solve everything right
chat D is going to solve everything and
chat D is going to solve everything and
take all the jobs let's let's see if it
take all the jobs let's let's see if it
solves
solves
anything I do this every so often and
anything I do this every so often and
it's got a it chat GPT currently has a
it's got a it chat GPT currently has a
success rate of like
success rate of like
zero we'll use uh
zero we'll use uh
four what's better four or 40 I think
four what's better four or 40 I think
four is better right 40 is
worse here is the uh what is it
compiled 4 is greater than 40 for
compiled 4 is greater than 40 for
programming things okay
programming things okay
well we're going to try it we're going
well we're going to try it we're going
to see I bet it's going to fail utterly
to see I bet it's going to fail utterly
and we're going to feel stupid but
and we're going to feel stupid but
whatever uh I would if it does hey look
whatever uh I would if it does hey look
if it's actually solves it then I get to
if it's actually solves it then I get to
move on with my life right because uh we
move on with my life right because uh we
don't have to stare at this error any
don't have to stare at this error any
longer
longer
um this
so I'm giving it full context for
so I'm giving it full context for
everything here
right handling a floating Point
right handling a floating Point
arithmetic okay that's what I was
arithmetic okay that's what I was
guessing right but like why
okay I guess there's an error check
against that's a kind of decent
response scon do not set pip python
response scon do not set pip python
exceptions
yeah I say it's kind of a mid
yeah I say it's kind of a mid
response this is kind of a mediocre
response this is kind of a mediocre
response
response
right
right
like I'm I'm just I was equally confused
like I'm I'm just I was equally confused
why it's raising a high error instead of
why it's raising a high error instead of
just having the error being in C given
just having the error being in C given
that I used a c function call but
like this is this is a squared number
like this is this is a squared number
like this cannot be negative
right why is it inserting the stupid
check like the compiler is not smart
check like the compiler is not smart
enough to figure out that this is always
enough to figure out that this is always
positive I guess right
do we need it to be square
rooted I mean we don't necessarily need
rooted I mean we don't necessarily need
it to be square rooted but it is mildly
it to be square rooted but it is mildly
inconvenient
inconvenient
right because then we have to work in
right because then we have to work in
like L2 squar
space we could do L1 distance
that would actually be faster
right maybe we just do L1 distance
right maybe we just do L1 distance
instead hey lots of people on the
instead hey lots of people on the
YouTube stream welcome this is all open
YouTube stream welcome this is all open
source you're free to come and uh try it
source you're free to come and uh try it
out the latest version of the demo right
out the latest version of the demo right
now that we're optimizing is right
now that we're optimizing is right
here perhaps you saw this on Twitter
so we have uh the agents playing well we
so we have uh the agents playing well we
have the scripted agents playing full
have the scripted agents playing full
games we're just reusing the creep AI
games we're just reusing the creep AI
for Heroes with fixed Lane assignments
for Heroes with fixed Lane assignments
the goal for today is to make this thing
the goal for today is to make this thing
like the title says a million FPS I'm
like the title says a million FPS I'm
confident that we'll get it today we're
confident that we'll get it today we're
only a factor of two off we started at
only a factor of two off we started at
like I guess we started at 150k and now
like I guess we started at 150k and now
we're at uh we're at like 500k
we're at uh we're at like 500k
equivalent so we only need like another
equivalent so we only need like another
factor of two and we'll be
there and then after that if we have
there and then after that if we have
time today which we should have plenty
time today which we should have plenty
of uh we're going to start on the
of uh we're going to start on the
network architectures for this stuff and
network architectures for this stuff and
that's going to be the tricky part
that's going to be the tricky part
because the network also needs to run a
because the network also needs to run a
million steps per
million steps per
second which is crazy talk for
second which is crazy talk for
reinforcement learning but we've done it
reinforcement learning but we've done it
before so
before so
maybe uh I'm going to I'm going to add a
maybe uh I'm going to I'm going to add a
comment on here for now that says
comment on here for now that says
square
square
root uh throws possible error which
root uh throws possible error which
calls back to
calls back to
python maybe some
python maybe some
way to uh
avoid negative square root check or just
avoid negative square root check or just
use
use
L1 and L1 looks like a diamond which is
L1 and L1 looks like a diamond which is
kind of a fine shape I don't think
kind of a fine shape I don't think
that'll make too much of a difference if
that'll make too much of a difference if
we use L1
we use L1
versus uh L2 and L1 is faster to compute
versus uh L2 and L1 is faster to compute
it should be right yeah absolute value
it should be right yeah absolute value
should be way faster
well this is such a stupid completion
well this is such a stupid completion
right there's no reason to cash like
right there's no reason to cash like
that all
right we're just going to replace L uh
right we're just going to replace L uh
L2 oops with L1 we only use this in a
L2 oops with L1 we only use this in a
few places I
few places I
think
two there we go
rebuild and we will
rebuild and we will
see while we're running the uh the
see while we're running the uh the
profile on this I'm going to see if the
profile on this I'm going to see if the
HTML the annotations look better if
HTML the annotations look better if
we're still calling back to python by
we're still calling back to python by
doing
this let's check this out
so we have our L1 distance
so we have our L1 distance
perfect and now if I look for L1
dist it's still calling back to
dist it's still calling back to
python
really Pi error
really Pi error
occurred
how is it just anything that returns a
how is it just anything that returns a
float it's assuming is an error
code there's actually nowhere in the
code there's actually nowhere in the
math that this can throw like a divide
math that this can throw like a divide
by zero
right so this doesn't make a a
right so this doesn't make a a
appreciable performance difference as
appreciable performance difference as
far as I can tell um and it's not
far as I can tell um and it's not
avoiding the call back to to python let
avoiding the call back to to python let
me
me
think no ABS is defined for
think no ABS is defined for
anything is this like overflow or
anything is this like overflow or
underflow or something this is Fab F ABS
underflow or something this is Fab F ABS
F go
F go
to pix l0
uh
H it's really
H it's really
weird oh wait wasn't this clip doing
weird oh wait wasn't this clip doing
this before as
well maybe there's a c uh a c flag that
well maybe there's a c uh a c flag that
I'm missing like a scyon profile flag is
I'm missing like a scyon profile flag is
there one of these that I'm not uh
there one of these that I'm not uh
thinking of here syon
Flags where is
Flags where is
it is there a list of
them
sources I don't
sources I don't
know that's a bit weird I think this is
know that's a bit weird I think this is
going to get to
going to get to
be uh rather boring rather quickly
be uh rather boring rather quickly
if I
if I
don't let me
don't let me
think inline does inline solve
this do I have it inlined already let me
this do I have it inlined already let me
think of like a quick work around for
think of like a quick work around for
now so we can get back to the other
stuff I think it's because it's in a
stuff I think it's because it's in a
function somehow right
I'm going to try one last thing and then
I'm going to try one last thing and then
we're going to move on and I will uh
we're going to move on and I will uh
sort this off stream uh we'll like just
sort this off stream uh we'll like just
do other stuff for now I want to just
do other stuff for now I want to just
see if I inline it it like this math
see if I inline it it like this math
should not be triggering an error so I
should not be triggering an error so I
think it's something about it being a
think it's something about it being a
function
function
call like I think it's somehow
call like I think it's somehow
interpreting this as an error code like
interpreting this as an error code like
because it returns a number and C uses
because it returns a number and C uses
error code like see usually if you
error code like see usually if you
return negative one it's cuz there's an
return negative one it's cuz there's an
error or something weird like I think
error or something weird like I think
that there's something like that going
on what if I just inline it
on what if I just inline it
right inline Flo
right inline Flo
L1 literally no way that this should be
L1 literally no way that this should be
erroring now
okay inline float
okay inline float
L1 and it's still throwing the stupid
L1 and it's still throwing the stupid
error okay so
I and it's compiling to call this
I and it's compiling to call this
function as well it hasn't compiled with
function as well it hasn't compiled with
the
the
inline which is even weirder okay so I
inline which is even weirder okay so I
will figure this particular one out
will figure this particular one out
later um that's on the to-do list uh
later um that's on the to-do list uh
we'll go back to L2 distance for now
we'll go back to L2 distance for now
just to keep the game playay
consistent we'll just do
consistent we'll just do
L2
L2
two oh by the way that uh that makes
two oh by the way that uh that makes
chat GPT even more wrong than we
chat GPT even more wrong than we
originally
originally
thought so uh I think that uh that's not
thought so uh I think that uh that's not
going to be replacing anything anytime
going to be replacing anything anytime
soon
okay next uh next thing from profiling
right new profile
right new profile
run probably need to rebuild
run probably need to rebuild
it and uh then we will run the profiler
it and uh then we will run the profiler
and we'll go on to the next potential
and we'll go on to the next potential
candidate
candidate
function factoring in that there is call
function factoring in that there is call
Overhead for this specific function
we're going to have to estimate the
we're going to have to estimate the
overhead since we didn't solve this
overhead since we didn't solve this
right that's kind of gross we could
right that's kind of gross we could
always just inline it ourselves time
always just inline it ourselves time
being I might just do
being I might just do
that okay so here's the latest
that okay so here's the latest
performance uh performance number here
performance uh performance number here
we
have Scan nearest Target
have Scan nearest Target
here this really is isn't that bad this
here this really is isn't that bad this
is a big number of
is a big number of
calls and it's doing L2 functions and
calls and it's doing L2 functions and
it's only 0.15 okay so compute
it's only 0.15 okay so compute
observations is a quarter of a
observations is a quarter of a
second this is a big expensive call so
second this is a big expensive call so
anything that's more than this should be
anything that's more than this should be
uh justifying its its
uh justifying its its
cost this here has I think a lot of this
cost this here has I think a lot of this
is just call
is just call
Overhead um but this move to function
Overhead um but this move to function
does do some stuff let me
see move to move to move
see move to move to move
to here's the function
defa so we do some casts
we do some checks on the
we do some checks on the
grid we do some kind of gross
grid we do some kind of gross
conditionals here but like these should
conditionals here but like these should
be fast they're gross but they're very
be fast they're gross but they're very
fast these are just comparing a few
fast these are just comparing a few
things to
things to
constants and then we move some stuff
constants and then we move some stuff
around in memory on a
around in memory on a
grid
grid
so there's no hard math here uh this
so there's no hard math here uh this
function should be very
function should be very
fast and because this function should be
fast and because this function should be
very fast we're going to take it out of
very fast we're going to take it out of
the
the
profile we're essentially when we're
profile we're essentially when we're
taking stuff out of the profile we're
taking stuff out of the profile we're
saying that like hey uh we know that
saying that like hey uh we know that
this is
this is
fast or we know that this is maybe not
fast or we know that this is maybe not
fast but we know that this is as fast as
fast but we know that this is as fast as
it can
it can
be so we don't need to get the the call
be so we don't need to get the the call
Overhead uh of this function in our
profile and actually I just thought of
profile and actually I just thought of
something that we can do for now
what we can do is we can take this L1
what we can do is we can take this L1
distance
distance
implementation and we can do
implementation and we can do
if
if
ABS we can just do it like
ABS we can just do it like
this so we
have this is L1 right if we just
have this is L1 right if we just
implement it manually it shouldn't be
implement it manually it shouldn't be
able to call
able to call
back so we'll just do like like
LF
ABS
X to distance and then we won't have the
X to distance and then we won't have the
call Overhead from this anymore
so this is a nice workaround for now is
so this is a nice workaround for now is
just hardcoding it until we can figure
just hardcoding it until we can figure
out uh you know off stream when it's not
out uh you know off stream when it's not
as
boring we can figure out the distance
functions okay
perfect so now we build this
we should actually have some substantial
we should actually have some substantial
changes to the HTML
changes to the HTML
hopefully uh if we still have errors in
hopefully uh if we still have errors in
here it means that there's some
here it means that there's some
low-level math Shenanigans going on that
low-level math Shenanigans going on that
I do not
I do not
understand that's the only explanation
understand that's the only explanation
for
it let's run the test while we look at
this okay perfect so it's something
this okay perfect so it's something
about the call the function call because
about the call the function call because
this runs pure
C oh and perfect just like that we went
C oh and perfect just like that we went
from 68,000 to 78,000 steps per second
from 68,000 to 78,000 steps per second
and this is again this is with the
and this is again this is with the
profiling overhead which is a lot so
profiling overhead which is a lot so
we're making a lot of progress
here let's see now what is saying uh
here let's see now what is saying uh
what we say has overhead still so this
what we say has overhead still so this
compute observations I see a very low
compute observations I see a very low
number of calls and a substantial
number of calls and a substantial
footprint but this makes sense the
footprint but this makes sense the
compute observation function is actually
compute observation function is actually
doing real
doing real
work so I'm actually pretty happy with
work so I'm actually pretty happy with
uh what is it quarter second or whatever
uh what is it quarter second or whatever
that's a perfectly valid thing this is
that's a perfectly valid thing this is
doing a bunch of
doing a bunch of
Loops this would be horribly
Loops this would be horribly
slow in uh python
and nearest scan Target is still .81
and nearest scan Target is still .81
that's a little weird uh let's go look
that's a little weird uh let's go look
at that
function I guess it gets does it get
function I guess it gets does it get
called a lot oh yeah this gets called a
called a lot oh yeah this gets called a
lot
lot
yeah uh so this is performance critical
yeah uh so this is performance critical
then because it gets called a lot
is there anything we can change with
is there anything we can change with
this or are we going to say that this is
this or are we going to say that this is
mostly call
mostly call
Overhead this 200 is hardcoded uh let me
Overhead this 200 is hardcoded uh let me
explain this function because this is
explain this function because this is
actually a kind of cool piece of tech
actually a kind of cool piece of tech
that I
that I
built so there's a scan
built so there's a scan
function we have a single allocated
function we have a single allocated
buffer for the whole program that gets
buffer for the whole program that gets
reused repeatedly and the pattern is
reused repeatedly and the pattern is
that you scan the nearby area in the
that you scan the nearby area in the
game for other enemies targets whatever
game for other enemies targets whatever
you want the scan function is very
you want the scan function is very
versatile and it fills up this buffer
versatile and it fills up this buffer
with targets and then you don't have to
with targets and then you don't have to
do a double Loop over your nearby
do a double Loop over your nearby
locations after that you just go through
locations after that you just go through
all the targets that the scan function
all the targets that the scan function
found and you uh you like use you get
found and you uh you like use you get
the Target or you filter It Whatever
the Target or you filter It Whatever
depending on which ones you want uh and
depending on which ones you want uh and
the logic is very clean for that so here
the logic is very clean for that so here
to get the nearest one you filtered the
to get the nearest one you filtered the
first time you went through all the
first time you went through all the
targets and now all you're going to do
targets and now all you're going to do
is you're going to compute the distance
is you're going to compute the distance
between the
between the
player uh and the target for each of
player uh and the target for each of
these
these
right uh I see one very small
right uh I see one very small
optimization that we can make
optimization that we can make
here only one that saves us two pointer
here only one that saves us two pointer
D references
let me see if there's anything else that
let me see if there's anything else that
I see I think this is going to be pretty
I see I think this is going to be pretty
negligible but we'll do it anyways just
negligible but we'll do it anyways just
to show
you you allocate the target here if it's
you you allocate the target here if it's
null we are
done if nearest Target is null
done if nearest Target is null
then nearest Target equals
then nearest Target equals
target
target
continue we can also avoid this check by
continue we can also avoid this check by
just setting nearest distance to be
just setting nearest distance to be
something
big okay there are a couple little
big okay there are a couple little
optimizations we can make
optimizations we can make
here CU I I think we're going to use
here CU I I think we're going to use
this function even more than we're using
this function even more than we're using
it now so it's worth taking a second to
it now so it's worth taking a second to
make uh a couple quick changes to this
so here for nearest scan Target we're
so here for nearest scan Target we're
going to say nearest distance equals
9999999 big
number now we no longer need to do
number now we no longer need to do
this because any distance will be better
this because any distance will be better
than this nearest distance so we save
than this nearest distance so we save
ourselves potentially 200 checks like
ourselves potentially 200 checks like
this and we also get to
this and we also get to
do uh we'll do
do uh we'll do
float uh
float uh
player Y and player X so now instead of
player Y and player X so now instead of
doing this pointer Target
doing this pointer Target
here we have these variables
here we have these variables
already right we get to reuse
already right we get to reuse
them then nearest Target is equal to
them then nearest Target is equal to
Target and nearest dist is equal to dist
Target and nearest dist is equal to dist
these are Pointers so this is
these are Pointers so this is
fast idx distance Yep this is all this
fast idx distance Yep this is all this
is all what we want
is all what we want
perfect one was it 081 before I think
perfect one was it 081 before I think
this is going to be a pretty negligible
this is going to be a pretty negligible
optimization but we did it
anyways we've got some much heavier
anyways we've got some much heavier
optimizations coming up every little bit
helps we'll run this perf
helps we'll run this perf
test grab our latest HTML
test grab our latest HTML
you can see
you can see
here that this is uh substantially
here that this is uh substantially
shorter
now actually that's not too bad we went
now actually that's not too bad we went
from 18 or whatever to
from 18 or whatever to
0.14 and given that this is actually
0.14 and given that this is actually
like close to the amount of overhead
like close to the amount of overhead
that I would expect like we probably
that I would expect like we probably
made this like twice as fast or
made this like twice as fast or
something because this is like this
something because this is like this
number here is not just the function
number here is not just the function
time it's also theun function call
time it's also theun function call
Overhead and we called it a bunch of
Overhead and we called it a bunch of
times so that's actually probably a
times so that's actually probably a
pretty decent little performance
pretty decent little performance
optimization 92,000 steps per second
um of course we have the same amount of
um of course we have the same amount of
overhead coming from the one python call
overhead coming from the one python call
which is kind of
which is kind of
obnoxious what the where the heck is
obnoxious what the where the heck is
that even coming from
actually that's like that's super
actually that's like that's super
obnoxious
obnoxious
oh it's coming from
oh it's coming from
this
this
yeah yeah that's going to happen the
yeah yeah that's going to happen the
while loop this tells you how slow
while loop this tells you how slow
python is though literally just this
python is though literally just this
like just this while loop right here
like just this while loop right here
which is optimized you can see that I
which is optimized you can see that I
pre-computed the actions and stuff this
pre-computed the actions and stuff this
is still like substantial overhead
is still like substantial overhead
Python's so
Python's so
slow so freaking slow I still love you
slow so freaking slow I still love you
python but you're slow
okay now compute observations has gone
okay now compute observations has gone
up but this is just the relative time
up but this is just the relative time
slice increasing because it's a fixed 10
slice increasing because it's a fixed 10
seconds I'm still very happy with. 3
seconds I'm still very happy with. 3
seconds for an a function that's that
seconds for an a function that's that
expensive like this does a lot under the
expensive like this does a lot under the
hood uh now we get to look at we only
hood uh now we get to look at we only
really have one two four functions plus
really have one two four functions plus
the step to look at here for
the step to look at here for
optimization this is where all the
optimization this is where all the
comput is going maybe basic attack but
comput is going maybe basic attack but
with this number of calls I don't think
with this number of calls I don't think
so
so
um in fact let me do that real quick
um in fact let me do that real quick
just because I I want to be sure that
just because I I want to be sure that
we're getting every little ounce that we
we're getting every little ounce that we
can
get
get
[Music]
attack where is it
attack where is it
bent basic yeah
yeah this is nothing this is this is
yeah this is nothing this is this is
purely call overhead
purely call overhead
right so we don't need to profile this
right so we don't need to profile this
whatsoever and then there's this attack
whatsoever and then there's this attack
function here which is this attack
function here which is this attack
function not uh more substantial so
function not uh more substantial so
attack not in here
attack not in here
anywhere where's
anywhere where's
attack oh way down here because it
attack oh way down here because it
doesn't get called as much
doesn't get called as much
right so let's
right so let's
see yeah basic attack gets called super
see yeah basic attack gets called super
often but it gets called on uh it gets
often but it gets called on uh it gets
called when it's on cool down or
called when it's on cool down or
whatever I
whatever I
guess so then attack only gets called
guess so then attack only gets called
you know much less often so the call
you know much less often so the call
Overhead is like negligible so let's uh
Overhead is like negligible so let's uh
let's add that real
quick uh oh what what
happened basic attack or bent
happened basic attack or bent
basic okay so we take the profiling off
basic okay so we take the profiling off
for this any of these like already
for this any of these like already
optimized functions
optimized functions
where we're looking it just call
where we're looking it just call
Overhead good idea
Overhead good idea
to know to to fix those
up this should bring us to about 100K I
up this should bring us to about 100K I
think maybe 100,000 steps per
think maybe 100,000 steps per
second on the profiled version by the
second on the profiled version by the
way with which is huge huge overhead so
way with which is huge huge overhead so
even though we're reducing the overhead
even though we're reducing the overhead
the overhead is still huge
the nice thing about these profile
the nice thing about these profile
decorators is when we just turn
decorators is when we just turn
profiling off globally they don't
profiling off globally they don't
interfere with anything so we won't have
interfere with anything so we won't have
to like get rid of them and uh
to like get rid of them and uh
93,000 I mean I guess there's some
93,000 I mean I guess there's some
variance in run to run did we get rid of
variance in run to run did we get rid of
basic attack overhead at least we
basic attack overhead at least we
did okay so this S Type loses .1 second
we'll look at that later I think this
we'll look at that later I think this
should already be the right type anyways
should already be the right type anyways
we'll see nearest scan
Target didn't we add a decorator to this
Target didn't we add a decorator to this
I wait I thought we said that nearest
I wait I thought we said that nearest
scan Target
was oh no we didn't exclude this
yet yeah we didn't exclude this yet
yet yeah we didn't exclude this yet
let's exclude this as
well because we already optimized it so
well because we already optimized it so
there's no point in timing it separately
there's no point in timing it separately
now this is already about as fast as it
now this is already about as fast as it
can
be that saves us
be that saves us
another another .1 seconds out of this
another another .1 seconds out of this
or another another percent on the per
or another another percent on the per
test at
test at
least just a function call
least just a function call
Overhead but like it's not that we're
Overhead but like it's not that we're
like this is kind of optimizing The
like this is kind of optimizing The
Benchmark not optimizing the program
Benchmark not optimizing the program
right now because we're removing
right now because we're removing
function call Overhead for the purpose
function call Overhead for the purpose
of profiling but the reason for this is
of profiling but the reason for this is
because it gives us more and more
because it gives us more and more
accurate profile information which then
accurate profile information which then
lets us actually optimize the things
lets us actually optimize the things
that matter so like here like this
that matter so like here like this
function we didn't even notice it in the
function we didn't even notice it in the
call time before but now we can see hey
call time before but now we can see hey
look it looks like there's actually
look it looks like there's actually
substantial overhead being incurred by
substantial overhead being incurred by
this move towards function let's see if
this move towards function let's see if
there's anything that we can actually
there's anything that we can actually
optimize there and we're going to go up
optimize there and we're going to go up
the stack this
the stack this
way so we
will move
will move
forwards this is moved
forwards this is moved
towards we can see that we have this
towards we can see that we have this
kind of gross uh condition
here we could put a table for this at
here we could put a table for this at
some point
this one's
this one's
tricky this one's actually kind of
tricky this is
tricky this is
definitely taking substantial
time and we just did we just take a move
time and we just did we just take a move
two
two
yeah so this is not including overhead
yeah so this is not including overhead
from new move
from new move
two so now we know for sure essentially
two so now we know for sure essentially
this function is slower than it should
this function is slower than it should
be
be
um these conditionals really shouldn't
um these conditionals really shouldn't
be that
slow is it this Rand right here
I was actually thinking of cashing
Jitter is that
crazy I don't think that's crazy right
crazy I don't think that's crazy right
to cash
to cash
Jitter so you don't have to do random
Jitter so you don't have to do random
number
manipulation do we even think it is the
manipulation do we even think it is the
Jitter though
it shouldn't be having to Jitter that
it shouldn't be having to Jitter that
often it could be that the Jitter is
often it could be that the Jitter is
really slow though right random number
really slow though right random number
called RNG is not
free you know you need some good
RNG we can figure that out very quickly
RNG we can figure that out very quickly
before we invest too much time
so all we have to do
is we go like this
is we go like this
right and let's see if this changes the
right and let's see if this changes the
uh the overall timing of this function
uh the overall timing of this function
it was 6 seconds before so if this time
it was 6 seconds before so if this time
plummets then we know that we're
plummets then we know that we're
basically we're using up all of the
basically we're using up all of the
compute and the infrequent Jitter
compute and the infrequent Jitter
operation so the Jitter is very slow and
operation so the Jitter is very slow and
then what I will do is I'll just
then what I will do is I'll just
pre-compute all the RNG for the whole
pre-compute all the RNG for the whole
program which is not hard to
do that's a really nice trick for folks
do that's a really nice trick for folks
by the way is to pre-compute RNG I do
by the way is to pre-compute RNG I do
this even in Python
this even in Python
sometimes interesting so it got faster
sometimes interesting so it got faster
but not by a huge
amount oh but wait the number of calls
amount oh but wait the number of calls
went
up what do you
up what do you
do to pre-compute RNG or what's the
do to pre-compute RNG or what's the
question
question
about what do you do to compute RNG or
about what do you do to compute RNG or
or is this like a new stream
question it went from
question it went from
6.4.6 seconds to
6.4.6 seconds to
to 85 at5 seconds so I'd say there's a
to 85 at5 seconds so I'd say there's a
pretty substantial time save
here I don't see a followup to that
here I don't see a followup to that
question I'm going to assume it was
question I'm going to assume it was
about the RNG so I will just show you
about the RNG so I will just show you
what I'm going to do for
what I'm going to do for
that um it's a very nice
that um it's a very nice
trick it's a very very nice trick
actually you get to replace an expensive
actually you get to replace an expensive
RNG call with a lookup
[Music]
and do I want to make it one dimensional
and do I want to make it one dimensional
or two I think 1D is probably
or two I think 1D is probably
better right yeah we'll do one
better right yeah we'll do one
D
so
so
float array
float array
RNG right
and then what we're going to do
is
is
int the
N so we're going to do self. RNG n
equals we want it to be a decent amount
equals we want it to be a decent amount
of RNG so that we have like some good
of RNG so that we have like some good
diversity in here 10K should be good
diversity in here 10K should be good
numpy
numpy
Rand RNG
Rand RNG
n
and yeah that's 0 to one RNG
and yeah that's 0 to one RNG
right was just making sure I didn't have
right was just making sure I didn't have
it confused with Rand
n so this Jitter right here
n so this Jitter right here
is-1 to 1
so RNG
n so we're going to do two
n so we're going to do two
times minus one so we're going to
times minus one so we're going to
pre-allocate this is essentially
pre-allocate this is essentially
pre-allocating
Kate yeah locate rng1 to one and now
Kate yeah locate rng1 to one and now
when we need
when we need
this it's pretty cool
oh we also forgot RNG n we need int RNG
oh we also forgot RNG n we need int RNG
idx so we need to keep track of where we
idx so we need to keep track of where we
are in the
are in the
RNG RNG idx is going to be
zero okay and now when we go to Rand
zero okay and now when we go to Rand
which is in Jitter
which is in Jitter
here uh now we get to do something
here uh now we get to do something
cool so Jitter
you see how that
you see how that
works now we do have to
works now we do have to
do uh an additional
do uh an additional
check which is
that equal 2
we have to do the modulo
here so this is a fast modulo you see
here so this is a fast modulo you see
what we
what we
did we replaced an expensive RNG
did we replaced an expensive RNG
call with a look up into a
call with a look up into a
table but the table's very
big now I have to be careful careful not
big now I have to be careful careful not
to overflow and a lot of other things
to overflow and a lot of other things
but it's not that
but it's not that
complicated and if you do it this
complicated and if you do it this
way we should get some speed out of
this we should get some
speed expected float got double whoops e
me forgetting the API of
course uh
C sayses
C sayses
type did the stream crash or something
type did the stream crash or something
why
why
is oh no my super Maven was just lagging
is oh no my super Maven was just lagging
that's
that's
fine we're good
and let's see what this gets us
to this should be a legitimate speed
to this should be a legitimate speed
optimization not just a compiler or a
optimization not just a compiler or a
profiling
optimization shouldn't be huge but it
optimization shouldn't be huge but it
should be
something huh
that didn't do very
much it is faster but only
much it is faster but only
marginally let's make sure we didn't
marginally let's make sure we didn't
screw up something with the
screw up something with the
um with the scyon
here
here
[Music]
[Music]
so Jitter X Jitter y
that's not super worth
it it's weird because it looked like
it it's weird because it looked like
before that this was where this the
before that this was where this the
slowness was coming
slowness was coming
from and I've seen this type of thing be
from and I've seen this type of thing be
a huge Boon
before well at least we know now that
before well at least we know now that
this is not where the slowness is coming
this is not where the slowness is coming
from
move two is a relatively fast
move two is a relatively fast
function we do have some additional
function we do have some additional
checks and stuff here and we have these
checks and stuff here and we have these
this series of checks and
this series of checks and
assignments we also have this
lookup
H maybe we'll figure this one out as we
H maybe we'll figure this one out as we
go through the other ones CU this is
go through the other ones CU this is
called by other
functions let's look at the bigger ones
functions let's look at the bigger ones
for now because I'm I'm drawing a blank
for now because I'm I'm drawing a blank
on
on
that so we have we have two very similar
that so we have we have two very similar
functions here and then we have a a
functions here and then we have a a
function that they both
function that they both
use so you see that this time here this
use so you see that this time here this
is cumulative
is cumulative
time so what this is saying is that scan
time so what this is saying is that scan
AOE doesn't call anything else that is
AOE doesn't call anything else that is
timed it's like all the time is spent in
timed it's like all the time is spent in
scan AOE but then creepe
scan AOE but then creepe
here there is like an additional second
here there is like an additional second
pretty much a full second in each of
pretty much a full second in each of
these a little more even um that is
these a little more even um that is
spent in other function calls and I can
spent in other function calls and I can
tell you right now that the majority of
tell you right now that the majority of
this is spent in scan AOE so basically
this is spent in scan AOE so basically
what this is telling us now is that of
what this is telling us now is that of
the N9 and a half seconds that we're
the N9 and a half seconds that we're
spending in this code we are spending
about
about
6.3 or something no I did that wrong
6.3 or something no I did that wrong
more than 6 seconds so more than I'd say
more than 6 seconds so more than I'd say
about 2third of the time of the whole
about 2third of the time of the whole
simulation is being spent on neutral and
simulation is being spent on neutral and
creep Ai and this is why having to
creep Ai and this is why having to
simulate enemy AI is evil because it's
simulate enemy AI is evil because it's
really hard to do
really hard to do
fast we spent a whole bunch of time
fast we spent a whole bunch of time
making sure that the pathf finding was
making sure that the pathf finding was
fast but there's still other stuff to to
fast but there's still other stuff to to
optimize so I think we're g to start
optimize so I think we're g to start
with they look to be about the
with they look to be about the
same speed let's start with the creep
AI so this is what creep AI looks
AI so this is what creep AI looks
like it's not calling back to uh to
like it's not calling back to uh to
python let's see if we get a rewin in
python let's see if we get a rewin in
the neutral
AI the neutral AI
AI the neutral AI
is also not calling back to python Okay
is also not calling back to python Okay
cool
cool
so what this is telling us then is
that because we're not profiling these
that because we're not profiling these
move towards functions and stuff the
move towards functions and stuff the
total time including movement and such
total time including movement and such
um outside of this scan AOE function is
um outside of this scan AOE function is
still quite substantial
and this is hard to optimize because
and this is hard to optimize because
this is just getting cold a ton of
this is just getting cold a ton of
times right this is getting
called 5 million
times so this this is running more than
times so this this is running more than
a million steps per second but it's
a million steps per second but it's
still going to hamstring us because
still going to hamstring us because
there's so many of the
Creeps and this is the thing that I was
Creeps and this is the thing that I was
most worried about having to optimize as
most worried about having to optimize as
well
um because it's reliant on some harder
um because it's reliant on some harder
to do
optimizations the easiest optimization
optimizations the easiest optimization
for this is frankly just to run the AI
for this is frankly just to run the AI
less often and to cash stuff in
here but we're going to need a better
here but we're going to need a better
breakdown of where time is being spent
breakdown of where time is being spent
I'm going to use the restroom real quick
I'm going to use the restroom real quick
I'll be back in one minute and then I if
I'll be back in one minute and then I if
we can make the AI like a few times
we can make the AI like a few times
faster we hit our million steps per
faster we hit our million steps per
second just based on that so if we just
second just based on that so if we just
cash something and Rec and compute AI
cash something and Rec and compute AI
stuff a little less often we'll hit our
stuff a little less often we'll hit our
million uh FPS just based on that so
million uh FPS just based on that so
I'll be right back and then we're going
I'll be right back and then we're going
to go do
that
e
e e
okay I should grab a drink and then
okay I should grab a drink and then
we'll be
good okay we're good for the next hour
good okay we're good for the next hour
I'll make I'll take a quick break and an
I'll make I'll take a quick break and an
hour to grab a shake and then other than
hour to grab a shake and then other than
that we are good until I don't know next
that we are good until I don't know next
four hours or
four hours or
whatever
so don't know why I even had these
so don't know why I even had these
headphones on they don't don't need them
um okay so right now the AI Rune is
um okay so right now the AI Rune is
every
every
frame it does an expensive scan
frame it does an expensive scan
operation where it looks in a nearby
operation where it looks in a nearby
area
area
and it looks
and it looks
for targets to go pathfind towards an
for targets to go pathfind towards an
agress if it finds one of these
agress if it finds one of these
targets then it checks if it's if it
targets then it checks if it's if it
finds one of these
finds one of these
targets then it looks for the nearest
targets then it looks for the nearest
one this is a good this is a relatively
one this is a good this is a relatively
fast
fast
function
function
and if it's close enough it will attack
and if it's close enough it will attack
that
that
Target
Target
otherwise it will path towards the
target if it doesn't find a
target if it doesn't find a
Target then it does this path finding
check and it then moves towards
check and it then moves towards
a specific uh position so the thing
a specific uh position so the thing
that's interesting about this to
that's interesting about this to
me is that almost none of this should
me is that almost none of this should
ever be getting
called because the neutrals the way the
called because the neutrals the way the
the AI is scripted at the moment nothing
the AI is scripted at the moment nothing
like nothing plays with the
like nothing plays with the
neutrals so let's see if that's
true according to
true according to
this the neutral AI SP spends 1.7
this the neutral AI SP spends 1.7
seconds just on itself on this function
seconds just on itself on this function
2.7 seconds
2.7 seconds
total we can assume that the additional
total we can assume that the additional
second is spent on scan
second is spent on scan
AOE which would line up very nicely with
AOE which would line up very nicely with
the other number but 1.7 seconds is
the other number but 1.7 seconds is
somehow being spent on this
function I can see that the attack
function I can see that the attack
function here
function here
it's not called very
it's not called very
often so this attack function shouldn't
often so this attack function shouldn't
be biasing it because we're calling
be biasing it because we're calling
attack in
here none of these other functions
here none of these other functions
should be
should be
interfering how the hell is it spending
interfering how the hell is it spending
1.7
1.7
seconds on these function
calls I mean that's three times the
calls I mean that's three times the
compute of the move towards oper which
compute of the move towards oper which
does everything
else am I looking at this right so
else am I looking at this right so
neutral AI
neutral AI
here right so the neutrals in this game
here right so the neutrals in this game
let me pull up the
GIF do you see these green things that
GIF do you see these green things that
are like respawning every so often but
are like respawning every so often but
they're not moving
they're not moving
otherwise those are the neutrals they
otherwise those are the neutrals they
only move for the most part if you go
only move for the most part if you go
get near them and interact with them
get near them and interact with them
which is very rarely happen like you see
which is very rarely happen like you see
every so often a green pixel will like
every so often a green pixel will like
get pulled in but it's very rare with
get pulled in but it's very rare with
the way that the scripts run right
the way that the scripts run right
now and it should be relatively
now and it should be relatively
efficient
so what should be happening is it runs f
so what should be happening is it runs f
it runs the scan AOE which is slow right
it runs the scan AOE which is slow right
we expect this to be
we expect this to be
slow we expect this to be very slow
slow we expect this to be very slow
actually found targets false
this is false so nothing happens this
this is false so nothing happens this
doesn't happen but
doesn't happen but
somehow according to this scan AOE which
somehow according to this scan AOE which
happens every single time is taking only
happens every single time is taking only
2.7 minus 1.7 is 1 second for this
2.7 minus 1.7 is 1 second for this
really expensive scan that goes through
really expensive scan that goes through
a whole bunch of
a whole bunch of
tiles
um and the rest of this code which
um and the rest of this code which
should be doing nothing is taking 1.7
seconds that's absurd that is
absurd how much of this could be
absurd how much of this could be
function call
function call
Overhead not that much
Overhead not that much
right because this move towards
right because this move towards
function which has some logic in it is
function which has some logic in it is
taking 6 seconds for almost the same
taking 6 seconds for almost the same
number of
number of
calls so basically at least a full
calls so basically at least a full
second of this total time here is uh is
second of this total time here is uh is
legitimate it's not just overhead call
Overhead what the heck would this
Overhead what the heck would this
possibly
be I wonder if it's these default args
I see Pi error occurred in
I see Pi error occurred in
here 1 Z one
one okay I'm getting a little bit
one okay I'm getting a little bit
suspicious here of these default args
suspicious here of these default args
it's possible that the parser is very
it's possible that the parser is very
slow for these it's the only thing I can
slow for these it's the only thing I can
think of that'd be a really funny
think of that'd be a really funny
low-level finding wouldn't it
only thing I can think of so B scan
only thing I can think of so B scan
AOE make sure we call it in the right
AOE make sure we call it in the right
order uh neutral
order uh neutral
AI
AI
neutral where's the stupid
thing
wait here's our signature
so we can do neutral
so we can do neutral
Vision
Vision
true
true
false friendly hostile creeps Towers
false friendly hostile creeps Towers
okay this is
okay this is
fine
fine
um I'm going to try something first
um I'm going to try something first
which is just found Target equals
which is just found Target equals
false and in principle this
should this shouldn't mean that you
should this shouldn't mean that you
spend less time in the spawn functions
spend less time in the spawn functions
right it should only mean that you spend
right it should only mean that you spend
less time in the other functions I also
less time in the other functions I also
I realized I did this in totally the
I realized I did this in totally the
wrong place I screwed that up let me put
wrong place I screwed that up let me put
it over here it should be in not inan
it over here it should be in not inan
AOE it should be in neutral
AOE it should be in neutral
AI right up
AI right up
here oh no wait
here oh no wait
what yeah this this goes away yeah I
what yeah this this goes away yeah I
have this as an an just as a hint to
have this as an an just as a hint to
myself okay perfect so yeah what happens
myself okay perfect so yeah what happens
if we do
if we do
this this will be interesting no matter
this this will be interesting no matter
what it tells
us there's a like there's a bunch of
us there's a like there's a bunch of
performance just going into the ether
performance just going into the ether
here and uh we're going to get it back
interesting
so the creep AI is now 2.6 second total
so the creep AI is now 2.6 second total
time creep AI time has gone up which
time creep AI time has gone up which
makes sense because proportionately it
makes sense because proportionately it
has a bigger time slice
has a bigger time slice
available neutral AI was 1.7 second
available neutral AI was 1.7 second
total time 2.7
cumulative and it went down all the way
cumulative and it went down all the way
to7
to7
second uh cumul uh total and obviously
second uh cumul uh total and obviously
cumulative wait did I do that right no
cumulative wait did I do that right no
right here basically same
right here basically same
thing and move towards went up a little
thing and move towards went up a little
bit so what this means is
bit so what this means is
that it's something about the found
that it's something about the found
Target true path or about the call to
Target true path or about the call to
the function itself so that's some
the function itself so that's some
really nice little archaeology to do
really nice little archaeology to do
there now what we're going to do is the
there now what we're going to do is the
more aggressive version of
more aggressive version of
this we're going to do which is uh we're
this we're going to do which is uh we're
going to call the function but we're
going to call the function but we're
going to call it without these default
going to call it without these default
args like this we're going to call it
args like this we're going to call it
with raw bulls and we're going to see
with raw bulls and we're going to see
what what happens if we do
that I did see some things on uh online
that I did see some things on uh online
about default args being and
about default args being and
wonk but it didn't show up in the HTML
wonk but it didn't show up in the HTML
which is
weird didn't show up in the HTML let's
weird didn't show up in the HTML let's
see I give this 50/50 chance that we get
see I give this 50/50 chance that we get
something interesting out of
this and if this works this one
this and if this works this one
optimization will basically be enough to
optimization will basically be enough to
save us maybe we'll a little on the scan
save us maybe we'll a little on the scan
AOE okay interestingly this went right
AOE okay interestingly this went right
back up to where this was
before went right back up to where it
before went right back up to where it
was
before okay next
before okay next
test maybe there's just like a very slow
test maybe there's just like a very slow
computational Branch
computational Branch
right maybe that branch is just really
right maybe that branch is just really
slow so um we'll
do found Target is here we scan for it
do found Target is here we scan for it
we determine that these args are
we determine that these args are
actually parsed fine and set it to false
actually parsed fine and set it to false
afterwards let's make it take the uh the
afterwards let's make it take the uh the
other branch that we know is is good
other branch that we know is is good
right
now if we make it take the other Branch
now if we make it take the other Branch
like this
then we get
okay it's about the same
so that's kind of
Bizarro let me just let me just put into
Bizarro let me just let me just put into
words what this means
words what this means
so if we set if we set this function to
so if we set if we set this function to
just be nulled out right then it not
just be nulled out right then it not
only says that you're not spending a
only says that you're not spending a
second calling the function which is
second calling the function which is
obvious but but it also says that you
obvious but but it also says that you
save a second of execution off of the
save a second of execution off of the
rest of your function excluding that so
rest of your function excluding that so
somehow I think that the call itself is
slow it shouldn't be a whole second of
slow it shouldn't be a whole second of
overhead slow that's
ridiculous what's unique about this
ridiculous what's unique about this
function BNS aren't slow are
they maybe we open up the h HTML
again right here
again right here
right
right
so entity star
so entity star
neutral this is a
constant entity star or found
constant entity star or found
Target wait
Target wait
what pi t
struct V table oh this is just a class
struct V table oh this is just a class
method this is
fine so this is essentially self this
fine so this is essentially self this
whole giant thing is
whole giant thing is
self this is self
dot scan AOE is our
dot scan AOE is our
function self
function self
neutral this is a
neutral this is a
constant and you can see it compiles
constant and you can see it compiles
here
here
to reasonable
args what the heck is
args what the heck is
this if unlikely Pi error
occurred does not everything has these
occurred does not everything has these
things right oh no wait this does still
things right oh no wait this does still
have it if unlikely Pi a error
have it if unlikely Pi a error
occurred well that's just function
call very
weird well we absolutely need to figure
weird well we absolutely need to figure
this out this is like the main blocker
this out this is like the main blocker
right now
right now
right the main blocker
oh I have an
oh I have an
idea I have a cool
idea I have a cool
idea let's just eliminate any chance
idea let's just eliminate any chance
that this is just some weird scon
that this is just some weird scon
[ __ ] because you know it's
[ __ ] because you know it's
happened let's do neutral AI instead of
happened let's do neutral AI instead of
making this thing false here let's go
making this thing false here let's go
back to the original call
back to the original call
right but then what we're going to do is
right but then what we're going to do is
we're going to make scan AO we just
we're going to make scan AO we just
return
false right here return
false and that will immediately tell us
false and that will immediately tell us
if the profiler is just screwy or
if the profiler is just screwy or
something's going weird or what because
something's going weird or what because
weirder things have happened
okay
okay
so that's interesting
so that's interesting
um the neutral AI here
is actually still
slow it's actually still
slow it's actually still
slow it's got 6 million function
calls
and 1.4
and 1.4
seconds versus since this gave us the
seconds versus since this gave us the
reasonable result I'm going
reasonable result I'm going
to I'm going to compare this
to I'm going to compare this
to not the function call
right which is right
right which is right
here and we're just going to do found
here and we're just going to do found
Target is equal to false
right so from one point uh what was it 1
right so from one point uh what was it 1
point4
to
0.4 is this actually the amount of
0.4 is this actually the amount of
overhead that's being added
overhead that's being added
by the function
by the function
call I don't want to be wasting my time
call I don't want to be wasting my time
if I'm just profiling function call
if I'm just profiling function call
Overhead but it seems like it's an
Overhead but it seems like it's an
abnormal amount of function call
Overhead let me look at you know what I
Overhead let me look at you know what I
should
should
do so this doesn't come up as having
do so this doesn't come up as having
overhead here what I want to do is I
overhead here what I want to do is I
want to go look at the scan AOE fun
function so it's got a big
signature it's got the trace back
here
okay so new hypothesis right
okay so new hypothesis right
maybe because this thing takes a bunch
maybe because this thing takes a bunch
of arguments and stuff the function call
of arguments and stuff the function call
Overhead for this is just especially
Overhead for this is just especially
bad if that's what we think is happening
here the next best thing we can
here the next best thing we can
do is uh we can eliminate the function
do is uh we can eliminate the function
call Overhead and see if there's still
call Overhead and see if there's still
something weird so scan AOE we know it
something weird so scan AOE we know it
now returns
oops where is it so we're going to call
oops where is it so we're going to call
it from here we're not going to just set
it from here we're not going to just set
it to
false where is it B scan AOE okay and
false where is it B scan AOE okay and
we're just going to we're going to add
we're just going to we're going to add
The Decorator to it now we can't keep
The Decorator to it now we can't keep
this decorator here because this
this decorator here because this
function we also need to
function we also need to
optimize uh this is probably the single
optimize uh this is probably the single
most performance critical function in
most performance critical function in
the code base I've saved the best for
the code base I've saved the best for
last which is the opposite of how you're
last which is the opposite of how you're
supposed to do profile in but you know
supposed to do profile in but you know
whatever I just want to see if
whatever I just want to see if
like the whole thing gets to be way
like the whole thing gets to be way
faster just by cutting out these
faster just by cutting out these
function
calls and we're cutting out the python
calls and we're cutting out the python
overhead to the function calls not the
overhead to the function calls not the
function calls themselves
133,000 steps per
second yeah that's substantially
faster so there's definitely something
faster so there's definitely something
about the the overhead
about the the overhead
itself so now we know okay 7
itself so now we know okay 7
Seconds right 7 seconds is what we're
Seconds right 7 seconds is what we're
taking for 9.6
taking for 9.6
million 9.6 million
million 9.6 million
calls and now what we're going to do is
calls and now what we're going to do is
we're going to look at
we're going to look at
whoops getting
there we're going to give it the full
there we're going to give it the full
function but with no signature
function but with no signature
so we're not going to be able to see the
so we're not going to be able to see the
breakdown but we're going to get
breakdown but we're going to get
accurate
accurate
profiling where we're not just profiling
profiling where we're not just profiling
expensive function call Overhead the
expensive function call Overhead the
main annoyance with profiling this
main annoyance with profiling this
stuff okay
okay so this is substantially better
actually the proportion of time has
actually the proportion of time has
decreased quite a bit there was
decreased quite a bit there was
essentially a whole second of overhead
essentially a whole second of overhead
being added
being added
to I think to both functions
to I think to both functions
maybe just from the call Signature
itself so
let's see from here so the creep AI it
let's see from here so the creep AI it
sticks out to me that the creep AI is
sticks out to me that the creep AI is
substantially slower than the neutral AI
substantially slower than the neutral AI
they're fewer creeps than neutrals
they're fewer creeps than neutrals
they're both calling a scan AOE once per
they're both calling a scan AOE once per
frame and uh the fact that the creep AI
frame and uh the fact that the creep AI
is still that much slower means that the
is still that much slower means that the
other pathing stuff is
substantial that move towards especially
substantial that move towards especially
right there needs to be optimized a
bit well
bit well
maybe
maybe
2.9 have you done much Unity much with
2.9 have you done much Unity much with
unity AI agents no I've done stuff with
unity AI agents no I've done stuff with
unity though and I've done stuff with AI
unity though and I've done stuff with AI
and unity and AI in AI but not with
and unity and AI in AI but not with
their ml agents
their ml agents
API
API
um here I'll show you the the format
um here I'll show you the the format
that I advocate for not Advocate but the
that I advocate for not Advocate but the
format I suggest
format I suggest
rather if you want to do stuff like
rather if you want to do stuff like
that the thing you want out of unity is
that the thing you want out of unity is
usually a nice front
usually a nice front
end for
end for
RL you can do that like
RL you can do that like
this here's a Unity front end for neural
this here's a Unity front end for neural
MMO I
MMO I
wrote
wrote
um the game environment is not written
um the game environment is not written
in unity the game environment is written
in unity the game environment is written
in whatever else you want you do a
in whatever else you want you do a
websocket server or whatever that will
websocket server or whatever that will
then send all of the data packets
then send all of the data packets
required to render to the to Unity and
required to render to the to Unity and
then you use Unity just for rendering
then you use Unity just for rendering
purposes so you essentially you strongly
purposes so you essentially you strongly
decouple the simulator from the uh the
decouple the simulator from the uh the
unity engine otherwise like if we want
unity engine otherwise like if we want
to talk about speed for things um well I
to talk about speed for things um well I
guess it depends on how you're
guess it depends on how you're
implementing stuff but most of the time
implementing stuff but most of the time
Unity is just going to be like the
Unity is just going to be like the
slowest possible imaginable for
slowest possible imaginable for
simulators technically it's possible to
simulators technically it's possible to
write fast simulators in unity but if
write fast simulators in unity but if
you're just like writing like writing
you're just like writing like writing
stuff like you do normal Game Dev in
stuff like you do normal Game Dev in
unity you're going to be about a
unity you're going to be about a
thousand times too slow to be useful
if you write uh efficient state
if you write uh efficient state
simulations in unity with headless so
simulations in unity with headless so
you decouple the rendering then it's
you decouple the rendering then it's
possible but you still have to go
possible but you still have to go
through their API so you have to get the
through their API so you have to get the
data into Python
data into Python
and that's hard to do efficiently if you
and that's hard to do efficiently if you
do it with I think what their default is
do it with I think what their default is
you're losing again like more than 99%
you're losing again like more than 99%
of your performance
immediately Next Step here is going to
immediately Next Step here is going to
be to uh remove move towards from the
be to uh remove move towards from the
profile just so we get an
absolute we need to know for sure that
absolute we need to know for sure that
we're not measuring function call
we're not measuring function call
Overhead and then this will give us like
Overhead and then this will give us like
the
the
final actual uh per performance overhead
final actual uh per performance overhead
of
everything yeah this should give us like
everything yeah this should give us like
everything that we need from from this
uh build X
compute
compute
observations okay this is taking up a
observations okay this is taking up a
bigger slice of time which is actually
bigger slice of time which is actually
probably good because this is means that
probably good because this is means that
the other overhead is
the other overhead is
lower we now have what's this 13 million
lower we now have what's this 13 million
in 1.7 seconds creep AI versus before we
in 1.7 seconds creep AI versus before we
had 10 million and about the same so
had 10 million and about the same so
like 30% of this was just a function
like 30% of this was just a function
call Overhead it looks
like and now we actually get like a good
like and now we actually get like a good
picture
picture
of how much what stuff is taking what
of how much what stuff is taking what
amount of
amount of
time
so optimization on movement function
so optimization on movement function
optimization on scan function and
optimization on scan function and
caching is what we get to which is I
caching is what we get to which is I
expected that we would get to
expected that we would get to
today but we've basically confirmed that
today but we've basically confirmed that
at this point there's nothing else that
at this point there's nothing else that
I've really majorly screwed up the
I've really majorly screwed up the
design of everything is pretty solid and
design of everything is pretty solid and
uh the only thing that we are really
uh the only thing that we are really
really missing
really missing
is a few optimizations maybe on movement
is a few optimizations maybe on movement
and scanning and then
and scanning and then
cashing that's about
cashing that's about
all take a quick 30 seconds to clear my
all take a quick 30 seconds to clear my
head here and then we're going to ramp
head here and then we're going to ramp
up for this last uh this last little
up for this last uh this last little
push before I take a 5 minutes to make
push before I take a 5 minutes to make
uh lunch but we're going to do this
uh lunch but we're going to do this
first we're going to get our uh our
first we're going to get our uh our
efficiency and then the hope is that
efficiency and then the hope is that
after lunch I can come back um and do
after lunch I can come back um and do
the reinforcement learning side of
the reinforcement learning side of
things we're already at by the way here
things we're already at by the way here
we're at 189,000 steps per second with
we're at 189,000 steps per second with
some profiling overhead this is what we
some profiling overhead this is what we
had before with no profiling overhead so
had before with no profiling overhead so
we're probably doing pretty well and
we're probably doing pretty well and
then the caching thing is what's really
then the caching thing is what's really
going to make this uh this thing pop uh
going to make this uh this thing pop uh
a few things for viewers at the
a few things for viewers at the
moment again it's all open source I say
moment again it's all open source I say
this once every so often it's all on
this once every so often it's all on
puffer lib right here it's in the any
puffer lib right here it's in the any
config Branch it'll be merged into Dev
config Branch it'll be merged into Dev
soon it's in puffer lib environments
soon it's in puffer lib environments
ocean you can play with it everything
ocean you can play with it everything
that you see today will be merged up by
that you see today will be merged up by
the uh the end of the stream if you like
the uh the end of the stream if you like
my work please Star Puffer lib helps me
my work please Star Puffer lib helps me
out a whole bunch
out a whole bunch
I also post all this stuff online on
I also post all this stuff online on
Twitter it's strictly for AI stuff so
Twitter it's strictly for AI stuff so
that's
that's
here and
here and
uh yeah you can see it's all like demos
uh yeah you can see it's all like demos
of code and
of code and
stuff
stuff
okay let's go back
okay let's go back
to the optimization stream now
oops
so I want to look at
so I want to look at
the the code for this
here cuz we have some functions that we
here cuz we have some functions that we
can potentially get a little bit more
can potentially get a little bit more
juice out of before we start
juice out of before we start
caching are you currently working on
caching are you currently working on
puffer lib full-time yep
puffer lib full-time yep
absolutely at least fulltime you could
absolutely at least fulltime you could
say um so definitely the uh the exposure
say um so definitely the uh the exposure
to stuff helps a ton I'm really trying
to stuff helps a ton I'm really trying
my best here to fix all the things that
my best here to fix all the things that
are cursed in reinforcement learning and
are cursed in reinforcement learning and
uh part of that is the simulation stuff
uh part of that is the simulation stuff
you see that I've been streaming lately
you see that I've been streaming lately
I've got stuff with Hyper pram tuning
I've got stuff with Hyper pram tuning
I've got stuff with like widespread
I've got stuff with like widespread
environment compatibility with puffer Li
environment compatibility with puffer Li
I've got super fast CPU vectorization
I've got super fast CPU vectorization
and it's moving crazy fast as well the
and it's moving crazy fast as well the
progress in the last two months has been
progress in the last two months has been
has been nuts
it's all free an open source as
well e
this function is
fine here's the big one right
here so what this function
does this
function goes through all of the tiles
function goes through all of the tiles
nearby in a
nearby in a
radius it looks for entities on those
radius it looks for entities on those
tiles and then it filters them
tiles and then it filters them
according to any specific criteria that
according to any specific criteria that
you
you
specify so you can specify you know all
specify so you can specify you know all
these different
criteria and based on that you can
filter let me think if I like this or
not is there a chance we see carbs
not is there a chance we see carbs
supported with WB sweeps from WB correct
supported with WB sweeps from WB correct
directly so let me tell you what
directly so let me tell you what
happened with that um I posted all the
happened with that um I posted all the
stuff i' been doing I added WB and MB a
stuff i' been doing I added WB and MB a
bunch on Twitter I got like four DMS
bunch on Twitter I got like four DMS
from WB people wanting to integrate
from WB people wanting to integrate
it uh I we sent some emails back and
it uh I we sent some emails back and
forth and then they stopped
forth and then they stopped
responding which was like weird because
responding which was like weird because
it looked like we were going to set up
it looked like we were going to set up
some meetings and then I got a DM from
some meetings and then I got a DM from
another guy at wandb saying that
another guy at wandb saying that
uh like something weird happened and
uh like something weird happened and
like our emails just never went through
like our emails just never went through
to each other or something because they
to each other or something because they
thought that I'd ghosted two meetings
thought that I'd ghosted two meetings
with them that I'd never set
with them that I'd never set
up so somehow some wires got crossed and
up so somehow some wires got crossed and
we didn't end up setting up any meetings
we didn't end up setting up any meetings
I should revisit that but I'll tell you
I should revisit that but I'll tell you
what I did
what I did
do I sent them a very nice
doc so I sent them you know Pono I sent
doc so I sent them you know Pono I sent
them this
them this
like thing for General improvements with
like thing for General improvements with
sweeps that would help as well as a
sweeps that would help as well as a
guide on carbs integration for what they
guide on carbs integration for what they
would need to add it native and I linked
would need to add it native and I linked
the uh the current integration with
the uh the current integration with
puffer which the current puffer
puffer which the current puffer
integration is not bad so that's the
integration is not bad so that's the
current state of
current state of
things carbs is
things carbs is
awesome I hope that they do
it be a really smart thing for them to
it be a really smart thing for them to
do
let me think about the design of this
let me think about the design of this
function a little bit more how many
function a little bit more how many
times do I use this scan
times do I use this scan
AOE I use it in player AOE
AOE I use it in player AOE
attack AE
push Tower AI neutral
push Tower AI neutral
AI creep okay so I see why I did this I
AI creep okay so I see why I did this I
used this five separate
used this five separate
times and other I would have had to have
times and other I would have had to have
written out like five separate uh 2D
written out like five separate uh 2D
Loops like this
right little obnoxious though because
right little obnoxious though because
like it does require you go two passes
like it does require you go two passes
over the data doesn't
it it kind of does require you to do two
it it kind of does require you to do two
passes over the data
they're actually a couple things I don't
they're actually a couple things I don't
like about
like about
this I don't like that you have this
this I don't like that you have this
giant list of filter
giant list of filter
options in
here I don't like that you have to check
here I don't like that you have to check
every single filter option even the ones
every single filter option even the ones
you're not
using these checks actually matter this
using these checks actually matter this
is like this is the most called piece of
is like this is the most called piece of
code in the entire project so like every
code in the entire project so like every
even like even every if statement
even like even every if statement
matters here
I'm I know that if I were to write out
I'm I know that if I were to write out
all the code for
all the code for
this if I were to just like time these
this if I were to just like time these
Loops like mess with the indexing a
Loops like mess with the indexing a
little bit make sure that was
little bit make sure that was
optimal and then just copy paste the
optimal and then just copy paste the
loop structure into every place I'm
loop structure into every place I'm
using scan AOE right
now it would work at the price of being
now it would work at the price of being
gross and adding like another 100 lines
gross and adding like another 100 lines
of code to the project
this function might be one of those
this function might be one of those
things that I thought was smart but
things that I thought was smart but
ended up being dumb
if you think about it it's
if you think about it it's
like it's really not acceptable to be
like it's really not acceptable to be
doing a second Passover your data
right like to be
right like to be
Computing applying all of these
Computing applying all of these
filters and doing a second Passover your
data this is a go slow to go fast moment
data this is a go slow to go fast moment
um I need to really think about this
um I need to really think about this
this is a big big thing with the project
this is a big big thing with the project
this is this is the single most
this is this is the single most
performance critical thing with the
performance critical thing with the
whole project and actually with most
whole project and actually with most
projects of this type
there's actually more to it than just
there's actually more to it than just
this as well isn't there
let me explain what's going on my head
let me explain what's going on my head
here because there's a lot that's not
here because there's a lot that's not
apparent just from this piece of code
apparent just from this piece of code
and how complicated some of this stuff
and how complicated some of this stuff
is
here
here
so
so
this this is a representation decision
this this is a representation decision
this is a decision about how we
this is a decision about how we
represent
represent
fundamentally how we represent and
fundamentally how we represent and
access data in the
access data in the
simulator the way that I have it right
simulator the way that I have it right
now everything at under the hood gets
now everything at under the hood gets
discretized onto a
discretized onto a
grid so you have a continuous position
grid so you have a continuous position
but you also have a position variant
but you also have a position variant
that's discretized to a
that's discretized to a
grid and only one thing can occupy any
grid and only one thing can occupy any
grid cell at any one time so what that
means is that you have a very uh very
means is that you have a very uh very
fast way of checking for entities nearby
fast way of checking for entities nearby
you whether you want to attack them
you whether you want to attack them
whether you want to do Collision checks
whether you want to do Collision checks
anything like that very very easy
anything like that very very easy
because you can just check nearby grid
because you can just check nearby grid
cells which is what this is doing
cells which is what this is doing
and you can go through the agents that
and you can go through the agents that
you find
you find
there the place where this scales very
there the place where this scales very
poorly is with larger distance
poorly is with larger distance
ranges so the way that I have this right
ranges so the way that I have this right
now the farthest that anything is seeing
now the farthest that anything is seeing
in the game is five squares it's like
in the game is five squares it's like
five player lengths it's very
five player lengths it's very
short and trying to make it larger than
short and trying to make it larger than
that is quadratically
that is quadratically
bad quadratically bad very very
bad quadratically bad very very
bad the problem though is that the
bad the problem though is that the
alternative is also
alternative is also
hard because the
hard because the
alternative is that you have to go
alternative is that you have to go
through all of the entities in the game
through all of the entities in the game
which I have them I have them in a nice
which I have them I have them in a nice
big data struct I could iterate through
big data struct I could iterate through
them but there are like 200 of them I
believe in mind you you always have to
believe in mind you you always have to
do distance checks as well if you do it
do distance checks as well if you do it
this way because if you do it that way
this way because if you do it that way
right you don't get the benefit of
right you don't get the benefit of
saying I know that everything that I
saying I know that everything that I
just found is within a square so you
just found is within a square so you
always have to do distance
always have to do distance
checks let me see precisely how many
checks let me see precisely how many
entities it
is actually this is in the uh the
is actually this is in the uh the
python okay so we
python okay so we
have slightly over 200 I have a buffer
have slightly over 200 I have a buffer
of 100 creeps that will probably need to
of 100 creeps that will probably need to
be
be
increased we could say it's like 256 or
increased we could say it's like 256 or
something to be cheeky will be the
something to be cheeky will be the
maximum
maximum
number
um if I did it that
way all of the targeting would be
way all of the targeting would be
directly on
agents I wouldn't have to do any index
agents I wouldn't have to do any index
calculations those are cheap anyways
calculations those are cheap anyways
though I wouldn't really have to look up
though I wouldn't really have to look up
player IDs either because I'd just be
player IDs either because I'd just be
directly iterating over the grid I mean
directly iterating over the grid I mean
over the entity
list
list
um but I don't think I could do it
um but I don't think I could do it
naively
I also think I still probably wouldn't
I also think I still probably wouldn't
use a function like this to scan
them because if I use a function like
them because if I use a function like
this to scan them you still have to go
this to scan them you still have to go
over them twice
right also um getting like the
right also um getting like the
nearest like the nearest K or whatever
nearest like the nearest K or whatever
is really hard when you do it this way
because like if I were to um I can just
because like if I were to um I can just
change the loop order essentially to
change the loop order essentially to
iterate
iterate
outwards if I wanted to do an
outwards if I wanted to do an
approximate like
approximate like
nearest nearest Elements want thing I
nearest nearest Elements want thing I
could do
that but I would lose that if I did
that but I would lose that if I did
entity based reversal
entity based reversal
now there are data structures to help
now there are data structures to help
you with this right there are like quad
you with this right there are like quad
trees and
trees and
stuff which can make this
stuff which can make this
from uh an O of n to an O of log n
from uh an O of n to an O of log n
process which is way better on paper but
process which is way better on paper but
the constant Factor matters a
the constant Factor matters a
lot and updating that data structure
lot and updating that data structure
matters a lot how fast you update it and
matters a lot how fast you update it and
such
C quad
tree 22 lines of
code yeah this is this is how you would
code yeah this is this is how you would
do it efficiently
where's all the
code where's your 22 lines of
code Lea notes contain multiple points
uhh recursive
thing I don't like this one
this is like a
this is like a
big a big difference though with the way
big a big difference though with the way
that I represent
that I represent
things well I think regardless you still
things well I think regardless you still
need to maintain a GD right regardless
need to maintain a GD right regardless
you still need to maintain a
grid this is worth spending a little bit
grid this is worth spending a little bit
more time on than I intended to today um
more time on than I intended to today um
even if it means I only get a little bit
even if it means I only get a little bit
of RL in at the end
of RL in at the end
because this is where you really make or
because this is where you really make or
break the perf of the game and this is
break the perf of the game and this is
actually something that's been holding
actually something that's been holding
back like this is the thing that holds
back like this is the thing that holds
back like entire classes of simulators
back like entire classes of simulators
at the moment is um entity parsing of
at the moment is um entity parsing of
this
this
variety
so yeah
so yeah
it's a big
deal the thing is like the algorithmic
deal the thing is like the algorithmic
complexity of this is not
complexity of this is not
trivial like conceptually a quadry is
trivial like conceptually a quadry is
not that complicated of a data structure
not that complicated of a data structure
it's just you recursively partition
it's just you recursively partition
space
space
up
up
um you just recursively partition space
um you just recursively partition space
up so that you're not Computing stuff
up so that you're not Computing stuff
over a ton of
over a ton of
entities now
entities now
I don't actually need to do that right
I don't actually need to do that right
like I don't need recursive
partitioning
partitioning
well it's not about it being recursive I
well it's not about it being recursive I
don't need infinite partitioning I
don't need infinite partitioning I
actually how many times do I need to cut
actually how many times do I need to cut
up the
up the
grid if I have 128 by 128
grid if I have 128 by 128
grid
right then if I cut it once I have 6 I
right then if I cut it once I have 6 I
have 64
have 64
eight that's probably good enough four
eight that's probably good enough four
layers and the reason I say that four
layers and the reason I say that four
layers is because
layers is because
what you would do is you would
what you would do is you would
check you would go through all of the
check you would go through all of the
entities that are in your 8 by8 and all
entities that are in your 8 by8 and all
neighboring 8 by 8s and then do distance
neighboring 8 by 8s and then do distance
checks on
checks on
them so essentially you're doing um 24x
them so essentially you're doing um 24x
24 tile
24 tile
chunks is the way that you would do this
efficiently how many entities are going
efficiently how many entities are going
to be in 24th tile
chunks no more than 50
chunks no more than 50
right on
right on
average
average
15 how many checks do you have to do for
15 how many checks do you have to do for
this
depends how it's implemented
right what's the structure for the leaf
right what's the structure for the leaf
node
