Kind: captions
Language: en
Okay,
Okay,
this should be us live.
this should be us live.
Hello.
I am all out of sorts this morning.
I am all out of sorts this morning.
Let me at least post this real quick.
Let me at least post this real quick.
Hang on.
Hang on.
Man,
Man,
so um I've been studying quantum physics
so um I've been studying quantum physics
and it's driving me crazy.
I was like watching lectures until I
I was like watching lectures until I
don't know 10 or 11 last night and then
don't know 10 or 11 last night and then
I just couldn't sleep trying to figure
I just couldn't sleep trying to figure
out all these various different things.
out all these various different things.
I'm considering just ordering some
I'm considering just ordering some
lasers and some optical stuff and trying
lasers and some optical stuff and trying
to run some experiments.
to run some experiments.
We'll see. Welcome, Magi.
We'll see. Welcome, Magi.
Let me switch this over to stream view.
Let me switch this over to stream view.
Okay, so we have some cool stuff to go
Okay, so we have some cool stuff to go
over today. Today is not about quantum
over today. Today is not about quantum
physics. Today is about reinforcement
physics. Today is about reinforcement
learning and specifically
learning and specifically
this large scale battle simulator that
this large scale battle simulator that
I've been working on. But first, let's
I've been working on. But first, let's
take a quick look at the experiments
take a quick look at the experiments
that ran overnight. Uh because it looks
that ran overnight. Uh because it looks
like Puffer does robotics. Now, here's a
like Puffer does robotics. Now, here's a
robotics environment.
robotics environment.
Puffer solves it. Where is it? Yeah,
Puffer solves it. Where is it? Yeah,
Puffer solves it perfectly.
Puffer solves it perfectly.
No, no big news there. Puffer kind of
No, no big news there. Puffer kind of
just solves everything. It did need some
just solves everything. It did need some
sweeps. I'm gonna have to grab like the
sweeps. I'm gonna have to grab like the
best parameters out of this and all
best parameters out of this and all
that. And I have to show the guy who
that. And I have to show the guy who
built this sim to see what he thinks we
built this sim to see what he thinks we
should do next with it. But yeah, it's
should do next with it. But yeah, it's
pretty cool. All right, so let's talk
pretty cool. All right, so let's talk
about the uh the battle sim that I've
about the uh the battle sim that I've
been wanting to work on. Also, we can
been wanting to work on. Also, we can
kill this. This has all the data that we
kill this. This has all the data that we
ever need.
ever need.
All right,
I should rename this.
I should rename this.
Started out as like a schooling
Started out as like a schooling
simulator for fish or whatever and did
simulator for fish or whatever and did
crazy things with it.
crazy things with it.
Uh, for some reason it does not want to
Uh, for some reason it does not want to
render, which is weird.
Oh, I bet this is Nvidia drivers.
Yeah, this is Nvidia drivers.
Yeah, this is Nvidia drivers.
All right,
we'll show the sim and then I'll talk
we'll show the sim and then I'll talk
about my plans for what we're going to
about my plans for what we're going to
do with it today.
Actually,
where's Tyler when you need him? I know
where's Tyler when you need him? I know
a physics PhD that I can bother about
a physics PhD that I can bother about
all sorts of insane quantum mechanics
all sorts of insane quantum mechanics
things.
I've been actually trying to understand
I've been actually trying to understand
the uh the math as well.
Not that bad conceptually until you ask
Not that bad conceptually until you ask
me to actually like go solve the
me to actually like go solve the
equations manually.
All right. So, here's the sim. Anyways,
now it doesn't look like much yet. So,
now it doesn't look like much yet. So,
let me just get us a quick very quick
let me just get us a quick very quick
little baseline on this.
just so you can get an idea and then
just so you can get an idea and then
we'll talk about how uh we're going to
we'll talk about how uh we're going to
modify this simulator
modify this simulator
because it sort of works at the moment,
because it sort of works at the moment,
but like I'm not super happy with
but like I'm not super happy with
several things about the way it's
several things about the way it's
designed and I think we can get way more
designed and I think we can get way more
coherent behaviors out of it.
coffee idea.
Tried training default yesterday. Looks
Tried training default yesterday. Looks
like it's not learning quite that much.
like it's not learning quite that much.
Most of the time it's failed. How can I
Most of the time it's failed. How can I
train until it reaches in reward to
train until it reaches in reward to
certain levels?
So I instead of trying to say how can I
So I instead of trying to say how can I
train until it reaches min reward, you
train until it reaches min reward, you
should try to figure out why it's not
should try to figure out why it's not
learning in a reasonable pace because
learning in a reasonable pace because
puffer should solve basically any
puffer should solve basically any
wellposed problem quite well. Like any
wellposed problem quite well. Like any
reasonable well-posed problem should be
reasonable well-posed problem should be
solvable uh quite quickly. You just
solvable uh quite quickly. You just
adjust total time steps up to something
adjust total time steps up to something
reasonable. Uh to give you an idea, most
reasonable. Uh to give you an idea, most
of our simpler ends are solved within
of our simpler ends are solved within
like 50 to 200 million steps and at
like 50 to 200 million steps and at
several million steps per second. That
several million steps per second. That
happens very very quickly.
happens very very quickly.
And almost almost always by default, if
And almost almost always by default, if
you have a reasonable problem that you
you have a reasonable problem that you
think should be of similar complexity to
think should be of similar complexity to
one of our M's that is solved quite
one of our M's that is solved quite
quickly, it's almost always a data
quickly, it's almost always a data
problem. I tried breakout.
problem. I tried breakout.
I mean, you tried breakout.
I mean, you tried breakout.
Okay, here. So, let me show this first
Okay, here. So, let me show this first
and then I'll show you how breakout just
and then I'll show you how breakout just
works.
So, to show you that Puffer is saying
So, to show you that Puffer is saying
like this is a sim
like this is a sim
just learn to do this in the last 20 or
just learn to do this in the last 20 or
30 seconds.
30 seconds.
Okay,
clearly we have something
clearly we have something
semi-reasonable here.
Now, if I just do puffer train, puffer
Now, if I just do puffer train, puffer
breakout out of the box, no setup
breakout out of the box, no setup
changes whatsoever.
Okay. So, this is literally 24 25
Okay. So, this is literally 24 25
seconds.
seconds.
Yeah, exactly.
Yeah, exactly.
So, this is a problem that you used to
So, this is a problem that you used to
have to run this overnight with other
have to run this overnight with other
reinforcement learning libraries. All
reinforcement learning libraries. All
right. And just to show you that I'm
right. And just to show you that I'm
just not making those numbers up,
here's our model playing Breakout.
It plays kind of weird, but note that we
It plays kind of weird, but note that we
didn't tell it to play like a human. We
didn't tell it to play like a human. We
just told it to beat the game. So, it
just told it to beat the game. So, it
doesn't matter if it waves the paddle
doesn't matter if it waves the paddle
around wildly, as long as it's there
around wildly, as long as it's there
when it needs to be to actually hit the
when it needs to be to actually hit the
puffer back.
So,
So,
I don't know why it didn't why you say
I don't know why it didn't why you say
why you have it like not working, but it
why you have it like not working, but it
it kind of just works out of the box,
it kind of just works out of the box,
right?
This is just Puffer 3.0. Like I I don't
This is just Puffer 3.0. Like I I don't
have any local changes or anything to
have any local changes or anything to
this.
Now, it's possible it takes you like 10
Now, it's possible it takes you like 10
minutes or something because you're not
minutes or something because you're not
training on a GPU,
training on a GPU,
but there's like I can only work so much
but there's like I can only work so much
magic, right? It's literally training 20
magic, right? It's literally training 20
times faster on your CPU than you'd be
times faster on your CPU than you'd be
able to train it on GPU with other
able to train it on GPU with other
libraries uh with their defaults the way
libraries uh with their defaults the way
that they're set up. So, it does get to
that they're set up. So, it does get to
be like, you know, several hundred times
be like, you know, several hundred times
faster uh if you actually are training
faster uh if you actually are training
it on like a reasonable hardware setup.
it on like a reasonable hardware setup.
This is literally just my local desktop
This is literally just my local desktop
right here. Like this is not running
right here. Like this is not running
remotely or anything. It's like a nice
remotely or anything. It's like a nice
local desktop, but it is just a desktop.
Okay.
How do you understand when to stop or
How do you understand when to stop or
when it's not learning anymore? Right
when it's not learning anymore? Right
here, the game is scored from like zero
here, the game is scored from like zero
to I think it's like 850 something or
to I think it's like 850 something or
860 something. And most of our
860 something. And most of our
environments to make it even easier for
environments to make it even easier for
you, we have a zero to one normalized.
you, we have a zero to one normalized.
So this is 98% right there of the
So this is 98% right there of the
maximum score.
maximum score.
See this? And you can do d- Neptune or
See this? And you can do d- Neptune or
D-1B to get graphs of these things. So
D-1B to get graphs of these things. So
when I do this, this is all done
when I do this, this is all done
automatically for you. Just dash Neptune
automatically for you. Just dash Neptune
or whatever you get all these graphs.
Okay, back to the battle ends.
I want to rename these real quick.
on tensorboard narl, I was dealing with
on tensorboard narl, I was dealing with
a min reward for each episode.
a min reward for each episode.
Okay, it's a little bit more subtle why
Okay, it's a little bit more subtle why
that's a dumb thing to do, but please
that's a dumb thing to do, but please
take my word on it that that's kind of a
take my word on it that that's kind of a
dumb thing to do. Um, it's way better to
dumb thing to do. Um, it's way better to
just run it for a certain number of
just run it for a certain number of
steps or a certain amount of time or
steps or a certain amount of time or
whatever. um and and just observe the
whatever. um and and just observe the
results from there.
Like don't try to don't try to like make
Like don't try to don't try to like make
puffer lib work like RLIB. Like RLIB is
puffer lib work like RLIB. Like RLIB is
literally the worst RL library in
literally the worst RL library in
existence. And I'm sorry to say that
existence. And I'm sorry to say that
because I know some of the devs, they
because I know some of the devs, they
tried very hard on it. Like they
tried very hard on it. Like they
genuinely wanted to do this stuff, but
genuinely wanted to do this stuff, but
it's just it's simply not the way to
it's just it's simply not the way to
build a reinforcement learning library.
build a reinforcement learning library.
Um, the reasons for it are a little bit
Um, the reasons for it are a little bit
subtle, but like the way that big tech
subtle, but like the way that big tech
builds libraries is not the way that you
builds libraries is not the way that you
can approach reinforcement learning.
can approach reinforcement learning.
I've said this so many times and it's so
I've said this so many times and it's so
difficult to get people to understand
difficult to get people to understand
this, but it is truly truly important.
this, but it is truly truly important.
Um,
Um,
so yeah, rather than trying to make
so yeah, rather than trying to make
puffer liib look like rlib, just try to
puffer liib look like rlib, just try to
use puffer lilib and then when something
use puffer lilib and then when something
doesn't make sense on its own terms, not
doesn't make sense on its own terms, not
in comparison to another library, then
in comparison to another library, then
let me know and I'm here all day to
let me know and I'm here all day to
help.
That makes sense.
Thanks. I'm pretty impressed.
Thanks. I'm pretty impressed.
I'd hope so, man. I do this all day.
I'd hope so, man. I do this all day.
This is the only thing I do. I'd better
This is the only thing I do. I'd better
be good at it, right?
That's kind of how it goes.
I mean, I can try to give you a little
I mean, I can try to give you a little
bit of the intuition.
bit of the intuition.
3 mil SPS. We get faster than 3 million,
3 mil SPS. We get faster than 3 million,
honestly. Like, puffer lib, we can
honestly. Like, puffer lib, we can
probably make it several times faster
probably make it several times faster
even than it is now. And I have run
even than it is now. And I have run
tests up to 20 million. Uh, it's like
tests up to 20 million. Uh, it's like
silly cases, but I've gotten it up to 20
silly cases, but I've gotten it up to 20
million steps per second on one GPU. So,
million steps per second on one GPU. So,
here, let me try to just give you a
here, let me try to just give you a
little bit of the intuition because this
little bit of the intuition because this
is honestly uh local machine config.
is honestly uh local machine config.
This is a 4090 with like a 9950X. It's
This is a 4090 with like a 9950X. It's
like one of the best desktop setups you
like one of the best desktop setups you
can buy. I also have one with a 5090
can buy. I also have one with a 5090
sitting on the rack behind me. Uh, but
sitting on the rack behind me. Uh, but
yeah, it's a good desktop, but it is
yeah, it's a good desktop, but it is
just a desktop. It's not like server
just a desktop. It's not like server
grade hardware.
I don't have like H200s or something.
I don't have like H200s or something.
So, let me let me just try to convey
So, let me let me just try to convey
this because like this is honestly where
this because like this is honestly where
everybody like trips and stump like
everybody like trips and stump like
trips and falls and breaks their legs in
trips and falls and breaks their legs in
reinforcement learning. Um, the reason
reinforcement learning. Um, the reason
that you don't do stuff like you do it
that you don't do stuff like you do it
in big tech engineering, in
in big tech engineering, in
reinforcement learning specifically, is
reinforcement learning specifically, is
because the price of overabraction and
because the price of overabraction and
the price of error is incredibly higher
the price of error is incredibly higher
in reinforcement learning than in
in reinforcement learning than in
everything else. That is to say, it's
everything else. That is to say, it's
kind of always a nice thing to keep
kind of always a nice thing to keep
stuff simple, but in reinforcement
stuff simple, but in reinforcement
learning specifically, if you don't keep
learning specifically, if you don't keep
stuff simple, you will pay dearly
stuff simple, you will pay dearly
because the bugs are just going to be
because the bugs are just going to be
the agent doesn't train. Okay? And it's
the agent doesn't train. Okay? And it's
even worse than the rest of supervised
even worse than the rest of supervised
learning because your data set is part
learning because your data set is part
of the generation loop as well and you
of the generation loop as well and you
have this whole additional hard uh
have this whole additional hard uh
infrastructure stack for dealing with
infrastructure stack for dealing with
the data. So it is truly this like open
the data. So it is truly this like open
feedback loop system where you have like
feedback loop system where you have like
no sanity check on anything.
no sanity check on anything.
All right, you can do your best with
All right, you can do your best with
logging and stuff, but you will still
logging and stuff, but you will still
end up with crazy issues. And there's
end up with crazy issues. And there's
not even a fundamental science of it
not even a fundamental science of it
that tells you how stuff should actually
that tells you how stuff should actually
work that fits any of what we've
work that fits any of what we've
observed. So with all of this, you would
observed. So with all of this, you would
be insane to not build stuff as
be insane to not build stuff as
absolutely dead simple as possible. And
absolutely dead simple as possible. And
that is at odds with how big tech builds
that is at odds with how big tech builds
stuff. And the proof of this, the proof
stuff. And the proof of this, the proof
that I am right here is that every
that I am right here is that every
single modular abstracted RL library
single modular abstracted RL library
that looks like every other piece of
that looks like every other piece of
software that you would see in big tech
software that you would see in big tech
has failed horribly.
has failed horribly.
That is the proof. And it is actually
That is the proof. And it is actually
the simpler, lighter weight, more
the simpler, lighter weight, more
compact libraries that are orders of
compact libraries that are orders of
magnitude faster uh and are useful on
magnitude faster uh and are useful on
much larger projects.
If you internalize that, you will go
If you internalize that, you will go
very far.
If you do not, you will become stuck.
If you do not, you will become stuck.
That is simply how it is.
So, a lot of my job here is to try to
So, a lot of my job here is to try to
make this simpler and simpler and
make this simpler and simpler and
simpler and faster and faster and faster
simpler and faster and faster and faster
so that it's actually easier to intuitit
so that it's actually easier to intuitit
what's going on here. And this is why we
what's going on here. And this is why we
have brand new programmers getting into
have brand new programmers getting into
reinforcement learning now when before
reinforcement learning now when before
like nobody even knew what was going on
like nobody even knew what was going on
with a PhD in the exact topic. But it's
with a PhD in the exact topic. But it's
still hard and it's still going to
still hard and it's still going to
require some, you know, mental
require some, you know, mental
adjustment if that makes sense.
Okay, good. So, this still runs. Just
Okay, good. So, this still runs. Just
renamed it. No big deal.
Okay, cool.
So, all I did so far is renamed the
So, all I did so far is renamed the
environment. Now, I haven't looked at
environment. Now, I haven't looked at
this thing in like a week and a half.
this thing in like a week and a half.
Let's actually think about what we want
Let's actually think about what we want
to do with this.
There are a couple big issues at the
There are a couple big issues at the
moment.
moment.
I think that the biggest there the two
I think that the biggest there the two
biggest issues right now are figuring
biggest issues right now are figuring
out how to do the observations in a sane
out how to do the observations in a sane
way, which that takes a little bit of
way, which that takes a little bit of
code, but isn't that hard. Uh the other
code, but isn't that hard. Uh the other
thing is how how do we do evaluation
thing is how how do we do evaluation
metrics?
metrics?
I kind of want to just get some code in
I kind of want to just get some code in
while I'm fresh and then we'll think
while I'm fresh and then we'll think
about evaluation metrics after.
Uh, I forgot to change the resources.
Okay. So, you have in this simple demo,
Okay. So, you have in this simple demo,
you've got two armies. They fight yada
you've got two armies. They fight yada
yada.
yada.
They can't actually see each other right
They can't actually see each other right
now is the problem. Uh, also the physics
now is the problem. Uh, also the physics
sucks. So,
sucks. So,
let's fix them not being able to see
let's fix them not being able to see
each other first.
The only way that I know to do this
The only way that I know to do this
without complicating it a lot is
without complicating it a lot is
horribly slow, but we'll just restrict
horribly slow, but we'll just restrict
this to smaller armies just for now, and
this to smaller armies just for now, and
then I'll come up with a better way to
then I'll come up with a better way to
do it later.
Yeah. So,
Yeah. So,
actually, I don't think it's going to be
actually, I don't think it's going to be
all that much code
What's your thoughts on time series
What's your thoughts on time series
more specifically? data that has
more specifically? data that has
sequencing information.
sequencing information.
That's like literally reinforcement
That's like literally reinforcement
learning by default,
learning by default,
right? It's an interaction problem.
right? It's an interaction problem.
You're an agent. You see the world, you
You're an agent. You see the world, you
take an action, the world changes, you
take an action, the world changes, you
take another action, the world changes
take another action, the world changes
more. That is almost by definition a
more. That is almost by definition a
time series problem. And in fact, the
time series problem. And in fact, the
problems that you can solve without
problems that you can solve without
having time series information are a
having time series information are a
specific subclass and almost an
specific subclass and almost an
exception to the rule. So you don't have
exception to the rule. So you don't have
to do anything like just by default.
to do anything like just by default.
That's what reinforcement learning does.
Oh yeah, use our recurrent model by
Oh yeah, use our recurrent model by
default. So it actually has some memory,
default. So it actually has some memory,
but that's about it.
It's a non-stationary problem.
It's a non-stationary problem.
Reinforcement learning is by definition
Reinforcement learning is by definition
non-stationary because your actions
non-stationary because your actions
change the environment. Doesn't matter.
The question should be more like why the
The question should be more like why the
hell does any of this work at all? And
hell does any of this work at all? And
we don't really know, but we've gotten
we don't really know, but we've gotten
pretty good at making it to
We don't need square root f here. We'll
We don't need square root f here. We'll
save this little bit of compute. It's
save this little bit of compute. It's
negligible, but still
Question is going to be how do we sort
Question is going to be how do we sort
this
quick sword's just going to give us Ah,
quick sword's just going to give us Ah,
yeah. That's annoying.
any technique or learning algorithm with
any technique or learning algorithm with
it detects and adopt and change policy
it detects and adopt and change policy
based on long sequence.
I mean, it's literally all of them. It's
I mean, it's literally all of them. It's
just like the longer the sequence, the
just like the longer the sequence, the
worse they work. Yes, there's research
worse they work. Yes, there's research
directed to this area. I find a lot of
directed to this area. I find a lot of
the results on like specific RL for like
the results on like specific RL for like
long horizon or this and that very
long horizon or this and that very
unconvincing though.
Look, if you have a problem and your
Look, if you have a problem and your
problem does not look like it's harder
problem does not look like it's harder
than the problems that we have in
than the problems that we have in
Puffer, the default thing will just
Puffer, the default thing will just
work. If you have something that you
work. If you have something that you
think looks harder, then come discuss
think looks harder, then come discuss
it.
I really don't want to have to write my
I really don't want to have to write my
own sort.
own sort.
Not because it's difficult, but because
Not because it's difficult, but because
optimizing that is a pain.
If we assume that we just ignore ties, I
If we assume that we just ignore ties, I
can do it in a sort of a hacky way.
Um, it's Yeah, I have to do an argu
Um, it's Yeah, I have to do an argu
though.
though.
I'm going to be lazy with it for now.
Wait, what the hell is this?
Did it just come up with something
Did it just come up with something
insane or is this somehow correct?
Yeah, that's what I'm going to use
Yeah, that's what I'm going to use
wouldn't. It's just annoying because I
wouldn't. It's just annoying because I
have to do an arg sort. There's There's
have to do an arg sort. There's There's
no like trivial way to just do an
no like trivial way to just do an
argort, right?
I guess you just make like a little
I guess you just make like a little
strct or something.
Maybe we'll just do it that way. Maybe
Maybe we'll just do it that way. Maybe
that'll be easier.
graph neural net. What's that have to do
graph neural net. What's that have to do
with anything, Finn?
Welcome though.
That's lit like that's not an RL
That's lit like that's not an RL
problem. That's a that's a perception
problem. That's a that's a perception
problem. You have no control over the
problem. You have no control over the
environment. You don't use reinforcement
environment. You don't use reinforcement
learning for problems where you don't
learning for problems where you don't
have any control over the environment.
have any control over the environment.
Typically,
unless you're forced to
reinforcement learning, like if you had
reinforcement learning, like if you had
to just pick one word, right, for
to just pick one word, right, for
reinforcement learning, like the key
reinforcement learning, like the key
essence of it is interaction. There's no
essence of it is interaction. There's no
interaction.
interaction.
Sometimes people use RL for stuff, but
Sometimes people use RL for stuff, but
it's not like a clear fit.
I forgot to name this.
the high speed,
but you're not trying to
but you're not trying to
you're you're just moving yourself based
you're you're just moving yourself based
on a response to what the other things
on a response to what the other things
in the environment are doing.
in the environment are doing.
You literally don't need to change the
You literally don't need to change the
standard reinforcement formula uh
standard reinforcement formula uh
reinforcement learning formulation at
reinforcement learning formulation at
all to handle this case.
It's like very tempting to think that
It's like very tempting to think that
there's something special about a lot of
there's something special about a lot of
problems where like you need some fancy
problems where like you need some fancy
new algorithm and then you go spend
new algorithm and then you go spend
three months doing uh a whole bunch of
three months doing uh a whole bunch of
research on that and then your like
research on that and then your like
fancy new method is worse than the
fancy new method is worse than the
baseline. Like every single RLP PhD
baseline. Like every single RLP PhD
pretty much to a tea has done this at
pretty much to a tea has done this at
some point.
some point.
The thing is like it's often the case
The thing is like it's often the case
that your problem really just isn't that
that your problem really just isn't that
special
special
and there's not really anything about it
and there's not really anything about it
that makes the standard thing not work.
that makes the standard thing not work.
And if you want to make something that's
And if you want to make something that's
just better than the standard and that's
just better than the standard and that's
a lot of work, which by the way we did.
a lot of work, which by the way we did.
We have something that's better than the
We have something that's better than the
standard uh in Puffer Lib 3.0. It's this
standard uh in Puffer Lib 3.0. It's this
huge leap. It took us 30,000 experiments
huge leap. It took us 30,000 experiments
over a ton of different environments to
over a ton of different environments to
make that happen.
Okay. So now we have this thing. We have
Okay. So now we have this thing. We have
these agent obs. And now what we can do
these agent obs. And now what we can do
is we can quick sort the agent obs. We
is we can quick sort the agent obs. We
just need a comparison function.
There you go.
There you go.
I think that's right.
And now what we do is we simply iterate
And now what we do is we simply iterate
through them again.
in the LSTM give a better yes we use
in the LSTM give a better yes we use
LSTM by default for like everything
that 3 million step per second result or
that 3 million step per second result or
5 million step per second result
5 million step per second result
whatever that's including an LSTM Ready?
Do we need to filter this by theta?
Let's just do it this way for now to
Let's just do it this way for now to
see.
is there a way we can use one agent
is there a way we can use one agent
steps as an observation space for other
steps as an observation space for other
set of agents
depends what you means by steps their
depends what you means by steps their
action specifically I mean if the other
action specifically I mean if the other
you can make the other agents see the
you can make the other agents see the
other agents as they're moving around
other agents as they're moving around
right agents can see each other as
right agents can see each other as
they're moving around. If you want to
they're moving around. If you want to
specifically observe the actions that
specifically observe the actions that
they take, yes, you can do that. You
they take, yes, you can do that. You
just have to add it into the environment
just have to add it into the environment
as the uh observation space.
as the uh observation space.
It's a little odd to do though because
It's a little odd to do though because
normally you can't get that information
normally you can't get that information
in the real world. So, it kind of
in the real world. So, it kind of
depends on the problem context.
know it's own unit type, right?
One, two, three, four, five, six,
19.
19.
19 + 8
army. So yeah, this is 3 *
army. So yeah, this is 3 *
16.
And we'll basically just have to see
Oh, you're dumb.
Oh, you're dumb.
Hang on.
I don't know why I did this in two
I don't know why I did this in two
dimensions.
There we go. That's three dimensions.
This
4 * 16.
So now they should be able to see the
So now they should be able to see the
nearest 16 agents to themselves.
And we have to modify this environment
And we have to modify this environment
quite a bit because this is going to
quite a bit because this is going to
incredibly slow as written.
How about continuous space? What am I
How about continuous space? What am I
going to say? Doesn't matter. Throw it
going to say? Doesn't matter. Throw it
into the algorithm.
into the algorithm.
We literally have it right here. Doesn't
We literally have it right here. Doesn't
matter. Throw it in the algorithm.
That's the key technique to observe.
That's the key technique to observe.
What do you mean?
What do you mean?
No, not really. It's just that a lot of
No, not really. It's just that a lot of
the things that you're specifically
the things that you're specifically
asking about are just things that we
asking about are just things that we
that kind of don't matter to RL. It's
that kind of don't matter to RL. It's
like, oh, it's a continuous versus a
like, oh, it's a continuous versus a
discrete value. Whatever. Stick it in
discrete value. Whatever. Stick it in
the observations and just don't do it in
the observations and just don't do it in
a dumb way.
Yeah. So, collision right here is bad.
Yeah. So, collision right here is bad.
This thing is not training correctly.
Let me think.
some sort of data issue.
We have this training before
if we had those metrics.
Every second we have a snapshot
Every second we have a snapshot
that that is the observation. It is what
that that is the observation. It is what
the agency is at every fixed interval of
the agency is at every fixed interval of
time.
Okay. Yeah. So here the collision rate
Okay. Yeah. So here the collision rate
is good.
The fact that it's not good here
The fact that it's not good here
uh means something is wrong with the
uh means something is wrong with the
observation somehow. Let's see what I
observation somehow. Let's see what I
did.
So we have
uh distance
This is numbum armies* 3 plus
cure
cure
I had this wrong
and if this frames basically will know
and if this frames basically will know
that I've done it correctly
have to be very careful with
have to be very careful with
observations.
observations.
There you go.
There you go.
Instantly huge difference.
Instantly huge difference.
I'm specifically I'm looking at the
I'm specifically I'm looking at the
collision right here.
collision right here.
And now it very quickly learns to not
And now it very quickly learns to not
crash into the ground.
if stones replied yet.
if stones replied yet.
He's probably asleep. He's in California
He's probably asleep. He's in California
graduate student time zone.
big mistake to purchase Mac Studio.
big mistake to purchase Mac Studio.
Yeah. I mean, for RL, you kind of need
Yeah. I mean, for RL, you kind of need
Nvidia GPUs. It's just how it works.
Does this thing spin this thing? This is
Does this thing spin this thing? This is
probably a dumb idea, but here
like No, doesn't spin all the way sadly.
like No, doesn't spin all the way sadly.
I was going to see if I could spin it to
I was going to see if I could spin it to
get to the PC, but it doesn't. I'd have
get to the PC, but it doesn't. I'd have
to like fully shift it.
to like fully shift it.
Ah, now I messed up my camera. Hang on.
Who is king?
I'm on a farm.
I'm literally in This is a warehouse on
I'm literally in This is a warehouse on
a farm.
That's literally corn.
Unfortunately, I haven't really been
Unfortunately, I haven't really been
able to enjoy the outdoors at all in the
able to enjoy the outdoors at all in the
last couple weeks. It's freaking hot and
last couple weeks. It's freaking hot and
they're like biting insects everywhere.
they're like biting insects everywhere.
Now, this is this is tech stream. We do
Now, this is this is tech stream. We do
tech here.
lab tour. The lab is right I mean it's
lab tour. The lab is right I mean it's
literally just like a bunch of PCs on a
literally just like a bunch of PCs on a
rack. You can see them right behind me.
I don't know. I was I was looking on uh
I don't know. I was I was looking on uh
I was looking for like lasers and
I was looking for like lasers and
optical stuff earlier today for a side
optical stuff earlier today for a side
project. Maybe I'll show that if I get
project. Maybe I'll show that if I get
any of that stuff.
I'm learning um I'm studying quantum
I'm learning um I'm studying quantum
physics and I'm kind of wanting to do
physics and I'm kind of wanting to do
some experiments.
Some of that equipment is ridiculously
Some of that equipment is ridiculously
expensive, but some of it's pretty
expensive, but some of it's pretty
cheap.
I think we can just add a small
I think we can just add a small
observation to fix OB
because it basically doesn't know when
because it basically doesn't know when
it's going out of bounds.
Let's see if that does anything.
Obs
We'll see if that does anything to OB.
We'll see if that does anything to OB.
Okay.
Yeah. So, out of bounds is not being
Yeah. So, out of bounds is not being
fixed, it seems, by this obs.
fixed, it seems, by this obs.
Oh, no. Yes, it is.
Oh, no. Yes, it is.
Yeah, it just took it a little bit.
Horse flies this week.
Horse flies this week.
Horse flies are the worst.
Horse flies are the worst.
Like I I don't think I'm going to out to
Like I I don't think I'm going to out to
run outside tomorrow cuz like literally
run outside tomorrow cuz like literally
last week I ran I was out for an hour
last week I ran I was out for an hour
maybe an hour 10. Uh brutally hot. But
maybe an hour 10. Uh brutally hot. But
then I came back and I had golf ball
then I came back and I had golf ball
sized welts all over my back from uh
sized welts all over my back from uh
just all the freaking horse flies and
just all the freaking horse flies and
whatever other biting stinging insects
whatever other biting stinging insects
there are.
there are.
literally would just be running and like
literally would just be running and like
rip them off of my back and stuff as I'm
rip them off of my back and stuff as I'm
going.
Yeah.
Huh?
Hey, Spencer.
There's some sort of maneuvering going
There's some sort of maneuvering going
on here. It's interesting.
Oh, I think it's the um
these ones here. These flat planes are
these ones here. These flat planes are
bombers.
bombers.
Uh they should be trying to be very high
Uh they should be trying to be very high
up in the air because they fired like
up in the air because they fired like
directly down.
directly down.
So, they want to be like pretty high up
So, they want to be like pretty high up
in the air.
in the air.
But I think that they're hitting the
But I think that they're hitting the
skybox is their problem.
How can I do ray train from last
How can I do ray train from last
training snapshot? We don't usually do
training snapshot? We don't usually do
that. You can try to just like d-load
that. You can try to just like d-load
model path. See if that works.
model path. See if that works.
I like it's as funny as it is. We
I like it's as funny as it is. We
literally don't bother with that most of
literally don't bother with that most of
the time because of how fast our
the time because of how fast our
experiments are.
We teach agent to do new skill
either you can load policies up like
either you can load policies up like
that's a thing you can do. So it's we
that's a thing you can do. So it's we
just usually with Puffer we usually
just usually with Puffer we usually
don't bother because most of our
don't bother because most of our
experiments are so fast
and also like a lot of the stuff we're
and also like a lot of the stuff we're
doing is science side stuff. So it's
doing is science side stuff. So it's
like we want things to re be
like we want things to re be
reproducible and if you chain together a
reproducible and if you chain together a
whole bunch of experiments it's harder
whole bunch of experiments it's harder
to reproduce the results if you just
to reproduce the results if you just
have one that runs from the start.
Let me think about the second problem
Let me think about the second problem
that we're going to have here.
Second problem that we're going to have
Second problem that we're going to have
here is how we actually know which of
here is how we actually know which of
these is any good when um
these is any good when um
yeah, how do we know which of these is
yeah, how do we know which of these is
any good? They're it's like pure
any good? They're it's like pure
selfplay.
We'd have to make a scripted opponent,
We'd have to make a scripted opponent,
right?
But we can cheat with the scripted
But we can cheat with the scripted
opponent a little bit, I think.
Yeah, I know what we're going to do.
Yeah, I know what we're going to do.
We're basically just going to make a uh
We're basically just going to make a uh
an opponent that runs at you in a
an opponent that runs at you in a
straight line. I'm going to see if we
straight line. I'm going to see if we
can beat that.
We'll go from there.
Let me go grab some more coffee restroom
Let me go grab some more coffee restroom
one second and then we'll uh we'll do
Okay.
Scripted opponent time.
What we're going to do is we're going to
What we're going to do is we're going to
add scripted
add scripted
ground.
ground.
It does not take actions.
It does not take actions.
And then this is going to be
eats physics
eats physics
and moves
and moves
directly
directly
to the nearest MMA.
We need to get nearest
nearest
nearest
int.
So, we're going to do entity star
So, we're going to do entity star
nearest enemy.
See if this autofill is actually
See if this autofill is actually
reasonable.
reasonable.
Go through the agents. Get other. Yeah.
Go through the agents. Get other. Yeah.
So, it literally just copy pasted this
So, it literally just copy pasted this
from elsewhere in like my ops code,
from elsewhere in like my ops code,
which is fine.
which is fine.
Uh, this didn't include Y though.
We'll do that.
messing around with linking bullet 3 to
messing around with linking bullet 3 to
puffer. Do you think that might be a
puffer. Do you think that might be a
reasonable thing to do or do you have
reasonable thing to do or do you have
any ideas? Does bullet 3 have um
any ideas? Does bullet 3 have um
is it uh does it have GPU excel or no?
I think warp is the thing if you want
I think warp is the thing if you want
like to actually do like low-level
like to actually do like low-level
physics I think warp is the thing
physics I think warp is the thing
that you do these days.
But we uh we are doing some robotic
But we uh we are doing some robotic
stuff now. I think I showed this this
stuff now. I think I showed this this
morning. So this is uh picking of a
morning. So this is uh picking of a
cube. This is like pick up a cube, bring
cube. This is like pick up a cube, bring
it to a target or whatever. We have this
it to a target or whatever. We have this
working super easily in Puffer. Um, and
working super easily in Puffer. Um, and
we're starting to do more robotics
we're starting to do more robotics
stuff. So, if you want like an out of
stuff. So, if you want like an out of
the box robotics thing to play with and
the box robotics thing to play with and
you want to like take our existing
you want to like take our existing
stuff,
stuff,
uh, you can ask me on like the new manny
uh, you can ask me on like the new manny
skill stuff.
skill stuff.
If you want to do your own low-level
If you want to do your own low-level
things, I would look at something like
things, I would look at something like
warp,
warp,
Nvidia Warp.
Oh, wait. This is Python.
Oh, never mind.
Wait, this is dumb.
Maybe it's physics.
Yeah, this is not the highle thing. This
Yeah, this is not the highle thing. This
is I This is not the low-level thing.
is I This is not the low-level thing.
This is like some highle thing.
Might be physics. You'd have to look
Might be physics. You'd have to look
into like what the actual like what all
into like what the actual like what all
the Sims are implemented using, right?
You kind of like the most useful thing
You kind of like the most useful thing
in robotics at the moment. If you want
in robotics at the moment. If you want
something that's like truly difficult is
something that's like truly difficult is
just getting like absolute maximum
just getting like absolute maximum
performance sim.
performance sim.
I'd be very impressed if you could train
I'd be very impressed if you could train
difficult robotic tasks like insertion.
difficult robotic tasks like insertion.
I'd be very impressed if we couldn't.
I'd be very impressed if we couldn't.
Um, it's like we're gonna have to I'm
Um, it's like we're gonna have to I'm
gonna have to spend a little bit more
gonna have to spend a little bit more
time on stuff, but like this stuff
time on stuff, but like this stuff
should not be hard.
Bullet 3 was go-to for lowle. Is it? I
Bullet 3 was go-to for lowle. Is it? I
think it's CPU.
Doesn't it not support if it doesn't
Doesn't it not support if it doesn't
support GPU? Like physics is one of the
support GPU? Like physics is one of the
few things where it's like, yeah, you
few things where it's like, yeah, you
need GPUs by default. Oh, wait.
need GPUs by default. Oh, wait.
Experimental Open CLG GPGPU support.
Experimental Open CLG GPGPU support.
Apparently, that's like experimental
Apparently, that's like experimental
support.
support.
Uh, and also this project
Uh, and also this project
doesn't seem like it's really being
doesn't seem like it's really being
maintained much.
I would definitely do some looking
I would definitely do some looking
around to see that like what what is
around to see that like what what is
actually good these days rather than
actually good these days rather than
just jumping into something like this.
Will it is slow as Yeah, that's
Will it is slow as Yeah, that's
what I kind of expected.
Manny skills goat. So, here's the funny
Manny skills goat. So, here's the funny
thing with Manny skill, right? Um
thing with Manny skill, right? Um
I So,
I So,
and I think that I don't think this is
and I think that I don't think this is
maniskll specific. I think this is just
maniskll specific. I think this is just
a general thing in robotics. All the
a general thing in robotics. All the
reward functions are wrong. All of them.
reward functions are wrong. All of them.
So, uh, in order to get this to work,
So, uh, in order to get this to work,
I had to make a small change, a small
I had to make a small change, a small
but very significant change. And this
but very significant change. And this
persists across all the robotics
persists across all the robotics
environments. And in order to make this
environments. And in order to make this
thing train despite the reward being
thing train despite the reward being
wrong, essentially roboticists have come
wrong, essentially roboticists have come
up with this like alternate wrong
up with this like alternate wrong
formulation of a different part of the
formulation of a different part of the
learning algorithm that counteracts the
learning algorithm that counteracts the
first error.
So yeah, it's real weird. Um, and I will
So yeah, it's real weird. Um, and I will
be surprised if we can't just kind of
be surprised if we can't just kind of
make a lot of stuff just work.
What is it that's wrong? I'm listening.
What is it that's wrong? I'm listening.
So, they do everything in robotics, you
So, they do everything in robotics, you
all do state based state based reward.
all do state based state based reward.
So, like as I get closer to the goal,
So, like as I get closer to the goal,
for instance,
for instance,
you get more and more reward. Uh but
you get more and more reward. Uh but
that's not how rewards work
that's not how rewards work
because
because
in order to fix this, right, the issue
in order to fix this, right, the issue
with this is that you can farm reward at
with this is that you can farm reward at
the end. First of all, the reward
the end. First of all, the reward
between one state and the next state is
between one state and the next state is
a very small difference. You actually
a very small difference. You actually
have to like implicitly learn this very
have to like implicitly learn this very
small delta, which is very difficult.
small delta, which is very difficult.
But then even worse is that you can farm
But then even worse is that you can farm
reward just by like staying really near
reward just by like staying really near
the target. And then they fix this by
the target. And then they fix this by
bootstrapping the reward across the
bootstrapping the reward across the
terminals in generalized advantage
terminals in generalized advantage
estimation, which is wrong. You're not
estimation, which is wrong. You're not
supposed to do that because that's a
supposed to do that because that's a
hard assumption that the uh terminal
hard assumption that the uh terminal
state is the target state. Um the
state is the target state. Um the
correct thing to do is to use delta
correct thing to do is to use delta
based rewards where you do delta from
based rewards where you do delta from
your previous state reward to the
your previous state reward to the
current state reward and that's the
current state reward and that's the
actual reward you give to the agent. So
actual reward you give to the agent. So
I did that and immediately it started
I did that and immediately it started
working perfectly.
Shouldn't
say they
max no because of a detail of how they
max no because of a detail of how they
know because of um the way generalized
know because of um the way generalized
advantage estimation works.
Like I saw this and I was like, "Oh
Like I saw this and I was like, "Oh
yeah, that's very clearly wrong."
yeah, that's very clearly wrong."
And then the experimental data, the
And then the experimental data, the
experiment perfectly tracked
experiment perfectly tracked
uh it perfect like the experimental
uh it perfect like the experimental
results perfectly tracked.
And now basically the only question is
And now basically the only question is
um whether we can make puffer
um whether we can make puffer
substantially faster wall clock time for
substantially faster wall clock time for
the environment or not because uh we're
the environment or not because uh we're
really like a lot of our demos are
really like a lot of our demos are
optimized for way faster environments
optimized for way faster environments
than robotics. The question will be
than robotics. The question will be
whether you know there's actually
whether you know there's actually
substantial uh improvement over this
substantial uh improvement over this
versus the other libraries. But we would
versus the other libraries. But we would
expect that there should be if we tune
expect that there should be if we tune
it.
Preach that to the whole man skill crew.
Preach that to the whole man skill crew.
Uh yeah, I know Stone personally and
Uh yeah, I know Stone personally and
I'll be chatting with him about this
I'll be chatting with him about this
briefly because the cool thing about
briefly because the cool thing about
this is it's like a 10line fix for their
this is it's like a 10line fix for their
entire library.
entire library.
It's a 10-line fix.
It's a 10-line fix.
And I don't think it's specifically
And I don't think it's specifically
them. Like to be clear, uh Stone's
them. Like to be clear, uh Stone's
probably the most competent person I
probably the most competent person I
know in robotics. And uh I had to deal
know in robotics. And uh I had to deal
with Isaac Jim and like that they don't
with Isaac Jim and like that they don't
know what the hell they're doing over
know what the hell they're doing over
there. All right, that all the Isaac
there. All right, that all the Isaac
code just sucks. But like my expectation
code just sucks. But like my expectation
is if this is happening here, it's
is if this is happening here, it's
probably happening everywhere. There.
feel like it will bring more attention.
feel like it will bring more attention.
Yeah, we're doing a little bit of
Yeah, we're doing a little bit of
robotics just to see if robotics people
robotics just to see if robotics people
are interested in Popper. It's not my
are interested in Popper. It's not my
main application area of interest, but
main application area of interest, but
you know, if there's if there's some
you know, if there's if there's some
industry robotics stuff that we can do,
industry robotics stuff that we can do,
uh we'll be happy to support that.
You talk already about multi-stage
You talk already about multi-stage
training. What do you mean multi-stage
training. What do you mean multi-stage
training?
multiple times.
You can do it. We don't usually do it.
You can do it. We don't usually do it.
Like,
Like,
yes, you can do that. We don't normally
yes, you can do that. We don't normally
have to, right?
If we actually get this environment into
If we actually get this environment into
a decent spot. Um,
if we get this environment into a decent
if we get this environment into a decent
spot, maybe we'll do some robotics after
spot, maybe we'll do some robotics after
this later in the day. We'll see.
this later in the day. We'll see.
But I want to I want to actually have
But I want to I want to actually have
like some cool tactical thing with this.
Kind of my fault. I'm supposed to be
Kind of my fault. I'm supposed to be
super well rested on Saturday so I can
super well rested on Saturday so I can
like really hammer out a lot of work.
like really hammer out a lot of work.
But
But
I don't know. I kind of uh I kept myself
I don't know. I kind of uh I kept myself
up half the night thinking about and it
up half the night thinking about and it
was specifically thinking about quantum
was specifically thinking about quantum
recording which I don't know
quantum's really weird
what if the problem is so big it needs
what if the problem is so big it needs
multi-stage training then you do
multi-stage training then you do
multi-stage training
multi-stage training
like you can load in policies into
like you can load in policies into
puffer and keep training technically it
puffer and keep training technically it
would be like a fiveline edition to make
would be like a fiveline edition to make
sure you also load the optimizer state.
sure you also load the optimizer state.
Uh full self-driving car. Oh,
Uh full self-driving car. Oh,
uh you mean like this?
Like these this type of a thing?
Like these this type of a thing?
Oops. Where is it?
actual real world self-driving car, not
actual real world self-driving car, not
an end to end RL problem,
an end to end RL problem,
mostly imitation learning.
But yeah, it's a fiveline change to
But yeah, it's a fiveline change to
resume training.
Oh yeah, that's the other thing that we
Oh yeah, that's the other thing that we
try to do in Puffer Lib, right? We don't
try to do in Puffer Lib, right? We don't
have like we don't necessarily have
have like we don't necessarily have
flags for every feature that you could
flags for every feature that you could
possibly imagine, but the code is
possibly imagine, but the code is
structured such that like way more often
structured such that like way more often
than any other library, the thing that
than any other library, the thing that
you want will be like a five or 10 line
you want will be like a five or 10 line
code change. It's just like in the main
code change. It's just like in the main
trainer file or whatever. It won't be
trainer file or whatever. It won't be
like some horrible thing where you have
like some horrible thing where you have
to like go rearchitect this like
to like go rearchitect this like
gigantic amalgam of nonsense. just like
gigantic amalgam of nonsense. just like
very quick.
I think that might even work. Magic.
I think that might even work. Magic.
It's like I think that probably just
It's like I think that probably just
works like load last checkpoint. I don't
works like load last checkpoint. I don't
know if it I it probably doesn't load
know if it I it probably doesn't load
the optimizer state. I It would be like
the optimizer state. I It would be like
a fiveline change. I don't know. I could
a fiveline change. I don't know. I could
add it.
add it.
Literally nobody's needed it because of
Literally nobody's needed it because of
how fast um the training is, but I could
how fast um the training is, but I could
figure that out.
Like the only reason you're thinking
Like the only reason you're thinking
that you might need that stuff at the
that you might need that stuff at the
moment is just because you're training
moment is just because you're training
on CPU, right?
Like here
Oh, this is where we've damn it. I love
Oh, this is where we've damn it. I love
how you actually like Google the thing
how you actually like Google the thing
and they just
Oh, they changed their whole thing, huh?
Oh, they changed their whole thing, huh?
And they increased the price as well.
And they increased the price as well.
Well, I know this still works
Well, I know this still works
here.
You can go get yourself a 4090 for as
You can go get yourself a 4090 for as
low as 35 cents an hour.
low as 35 cents an hour.
You say
if you don't have hardware,
if you don't have hardware,
good thing to do. Hey, Hyper.
Tyler, just who I was looking for.
Tyler, just who I was looking for.
Where's a physics PhD when you need him?
Where's a physics PhD when you need him?
I've been studying quantum mechanics
I've been studying quantum mechanics
and I am very confused.
I don't know. Is this a thing? Like, do
I don't know. Is this a thing? Like, do
all physics students like study quantum
all physics students like study quantum
at some point or is this like a or do I
at some point or is this like a or do I
need to find somebody who is like a
need to find somebody who is like a
specialist in quantum?
specialist in quantum?
I don't know how it works.
I think Tyler's got like million years
I think Tyler's got like million years
worth of stream delay on X at the
worth of stream delay on X at the
moment.
What was the answer? You were right
What was the answer? You were right
about the delay.
What was what was what answer?
Oh, the answer is that because driving
Oh, the answer is that because driving
is open-ended.
is open-ended.
Uh, the reason that you don't end to end
Uh, the reason that you don't end to end
RL driving is because you want something
RL driving is because you want something
that actually drives like a human and
that actually drives like a human and
it's a problem for which you have a huge
it's a problem for which you have a huge
amount of human data. It's mostly
amount of human data. It's mostly
imitation learning.
You know any quantum mechanics, Tyler,
You know any quantum mechanics, Tyler,
or is that outside of
or is that outside of
outside of your area?
I know a bit.
I know a bit.
So, the thing that's driving me insane
So, the thing that's driving me insane
at the moment is
at the moment is
the definition of a record seems like
the definition of a record seems like
really circular as an experimentalist.
really circular as an experimentalist.
Well, yeah. I I'm actually I'm mostly
Well, yeah. I I'm actually I'm mostly
trying to figure this out from an
trying to figure this out from an
experimental perspective. So, the thing
experimental perspective. So, the thing
that's driving me absolutely crazy is
that's driving me absolutely crazy is
that the experiment goes Oh, okay. So
that the experiment goes Oh, okay. So
yeah, you get this interference effect
yeah, you get this interference effect
that goes away uh when you record it.
that goes away uh when you record it.
Like, well, is that an artifact of
Like, well, is that an artifact of
measurement? No, it just goes away no
measurement? No, it just goes away no
matter how you measure it, even if you
matter how you measure it, even if you
do it in a way that doesn't disturb the
do it in a way that doesn't disturb the
experiment at all. Oh, okay. So, it's
experiment at all. Oh, okay. So, it's
somehow the measurement the process of
somehow the measurement the process of
measurement
measurement
uh messes with that. Well, how does that
uh messes with that. Well, how does that
work? Oh, well, you entangle the Let me
work? Oh, well, you entangle the Let me
get this right. The particle becomes
get this right. The particle becomes
entangled with the macroscopic detector
entangled with the macroscopic detector
state. Well, what the heck does that
state. Well, what the heck does that
mean? Like, well, it's because you
mean? Like, well, it's because you
create a record of it and it becomes
create a record of it and it becomes
entangled with the record. Like, so if
entangled with the record. Like, so if
you do this exact same thing, but you
you do this exact same thing, but you
don't create a record, then there's no
don't create a record, then there's no
entanglement.
entanglement.
Well, yeah.
Well, yeah.
Okay. Okay. So, like if I just do this
Okay. Okay. So, like if I just do this
experiment and I record the data in the
experiment and I record the data in the
exact same way and I throw it away, then
exact same way and I throw it away, then
there's no record. Well, yeah, it it
there's no record. Well, yeah, it it
it's kind of like this really circular
it's kind of like this really circular
thing where it's like they're defining
thing where it's like they're defining
this very highle concept of making a
this very highle concept of making a
record and then there's basically no
record and then there's basically no
explan like there's no mechanistic
explan like there's no mechanistic
explanation that I can see that fits
explanation that I can see that fits
this data better than literally saying
this data better than literally saying
that particles are omnisient.
That's the thing that's driving me
That's the thing that's driving me
insane.
is inverse reinforcement learning.
Let me see.
is this?
You're learning the reward function.
Honestly, I haven't seen anything in
Honestly, I haven't seen anything in
that in a while.
Learning reward. Yeah, I haven't seen
Learning reward. Yeah, I haven't seen
anything in that in a while.
I don't know if that whole line of work
I don't know if that whole line of work
went anywhere.
Uh, we need to orient this thing.
Shoot. How do we do this?
Shoot. How do we do this?
Long live behavioral cloning.
Long live behavioral cloning.
Yeah, that doesn't solve your problem
Yeah, that doesn't solve your problem
either, though.
Like online RL is kind of goated. It's
Like online RL is kind of goated. It's
kind of hard to just beat online RL with
kind of hard to just beat online RL with
infinite data.
Is there like a quat rotate too or like
Is there like a quat rotate too or like
a quat look at
Are you making a Starcraft 2 end? Uh,
Are you making a Starcraft 2 end? Uh,
not. Here, I'll show you it. It's not
not. Here, I'll show you it. It's not
quite that.
You can run it way bigger with way more
You can run it way bigger with way more
agents, but um it's like a tactical
agents, but um it's like a tactical
battle sim. So there drones, they're
battle sim. So there drones, they're
fighters, they're bombers,
fighters, they're bombers,
drone ship, there tanks, there's
drone ship, there tanks, there's
infantry.
It's pretty much just a big battle sim.
think what to do with this. We need like
think what to do with this. We need like
a quat look at or something.
Have you heard of action
Have you heard of action
derived rewards? Is that a thing?
derived rewards? Is that a thing?
Action? I don't know what that refers
Action? I don't know what that refers
to, Spencer.
to, Spencer.
Is it possible to explain this battle? M
Is it possible to explain this battle? M
specifically, observation space. Sure.
specifically, observation space. Sure.
So, I have I think there like six or
So, I have I think there like six or
seven different types of units. There's
seven different types of units. There's
infantry, there tanks, um there's
infantry, there tanks, um there's
anti-air like trucks that are like
anti-air like trucks that are like
anti-air specifically. There are drones,
anti-air specifically. There are drones,
there are fighters, there are bombers,
there are fighters, there are bombers,
and then there's this mother ship that
and then there's this mother ship that
like launches drones. They all have
like launches drones. They all have
different effective speeds, turning
different effective speeds, turning
radiuses, and uh weapon ranges. So, they
radiuses, and uh weapon ranges. So, they
all like behave a little bit
all like behave a little bit
differently,
differently,
and you just have multiple armies, and
and you just have multiple armies, and
they fight. Um, and then reinforcement
they fight. Um, and then reinforcement
learning will just control, same policy,
learning will just control, same policy,
can control whatever ship because they
can control whatever ship because they
all have the same observation space. the
all have the same observation space. the
action spaces are interpreted
action spaces are interpreted
differently, but it still works. Um,
differently, but it still works. Um,
observation space, they see like their
observation space, they see like their
own state. So, they see like their own
own state. So, they see like their own
orientation, their own speed, heading,
orientation, their own speed, heading,
uh, position, all that stuff.
uh, position, all that stuff.
And then they see, you know, the
And then they see, you know, the
distance to ground so that they don't
distance to ground so that they don't
crash. And then they just observe like
crash. And then they just observe like
the nearest 16 agents at the moment.
the nearest 16 agents at the moment.
They observe like the position of the
They observe like the position of the
nearest 16 agents and whether they're
nearest 16 agents and whether they're
friendly or hostile. That's all.
Is there like a look
Is there like a look
matrix look at?
matrix look at?
Yeah, this is not what we need because
Yeah, this is not what we need because
we need quat version.
we need quat version.
the data structure.
the data structure.
It's a bunch of floats.
It's literally just a like a bunch of
It's literally just a like a bunch of
floats.
So, like
So, like
here's some data and we just like here
here's some data and we just like here
are the observations to the nearest
are the observations to the nearest
agent. You just add them in. And here
agent. You just add them in. And here
are the observations of all the agent
are the observations of all the agent
properties. They just get added in. It
properties. They just get added in. It
knows what type of unit it is. They're
knows what type of unit it is. They're
just written down like that. Goes into a
just written down like that. Goes into a
very simple neural net.
I think we lost Tyler.
I think we lost Tyler.
Dang.
He's like the only one I know who's in
He's like the only one I know who's in
physics. I was hoping he'd bail me bail
physics. I was hoping he'd bail me bail
me out of this mess.
So I
So I
I like technically I guess we can just
I like technically I guess we can just
run it like this for now and then we'll
run it like this for now and then we'll
have to figure out the look at
just do this
just do this
and then
how do we distinguish between scripted
how do we distinguish between scripted
versus not?
versus not?
I believe you're asking a question
I believe you're asking a question
nobody has an answer to. Lovely.
nobody has an answer to. Lovely.
Um,
so I I guess Tyler, and this is like
so I I guess Tyler, and this is like
this is driving me crazy to the point
this is driving me crazy to the point
that like literally look at this. I
that like literally look at this. I
literally have Where's the shopping
literally have Where's the shopping
cart?
Oh, yeah. I'm literally looking at
Oh, yeah. I'm literally looking at
ordering lasers
ordering lasers
to see if I can answer some of these
to see if I can answer some of these
questions to set up some experiments.
questions to set up some experiments.
Um,
Um,
great.
Yeah, I I'm trying to set up some
Yeah, I I'm trying to set up some
experiments that decouple measurement
experiments that decouple measurement
from observability.
I took quantum. It was like X happens.
I took quantum. It was like X happens.
Don't question why. No one knows. Just
Don't question why. No one knows. Just
accept. Yeah, but that's not how my
accept. Yeah, but that's not how my
brain works, Spencer.
Like if you tell me that like a normal
Like if you tell me that like a normal
person would be like, "Yeah, okay,
person would be like, "Yeah, okay,
cool." Me, it'll be like, "No,
cool." Me, it'll be like, "No,
that. I'm ordering lasers to figure this
that. I'm ordering lasers to figure this
out.
Any worlds decoherence quantum?"
Any worlds decoherence quantum?"
I don't think any of that explains
I don't think any of that explains
observability itself, right? Like the
observability itself, right? Like the
fact
fact
I mean, you can get these things to be,
I mean, you can get these things to be,
it seems like you can get these things
it seems like you can get these things
to be pretty dang decoupled. Like the
to be pretty dang decoupled. Like the
process of recording can be pretty dang
process of recording can be pretty dang
decoupled from the process of
decoupled from the process of
measurement
measurement
and somehow
and somehow
it still affects the interference,
it still affects the interference,
right?
Does free will exist? I actually don't
Does free will exist? I actually don't
care about that question at all.
You're observing all values in the list
You're observing all values in the list
using a fixed index. Yes. And uh imagine
using a fixed index. Yes. And uh imagine
to make that work, we sort the uh
to make that work, we sort the uh
because that's not a super smart thing
because that's not a super smart thing
to do. It's just a fast thing to do. We
to do. It's just a fast thing to do. We
sort uh a we sort the nearby agents by
sort uh a we sort the nearby agents by
their distance to us. You always get
their distance to us. You always get
like the nearest one, the second nearest
like the nearest one, the second nearest
one, so on and so forth.
one, so on and so forth.
Not a philosopher, huh?
Not a philosopher, huh?
Uh, I don't mind philosophy. I only mind
Uh, I don't mind philosophy. I only mind
stupid philosophy.
I don't know. I find a lot of philosophy
I don't know. I find a lot of philosophy
just kind of dumb.
Then you track their coordinates or
Then you track their coordinates or
position. We do deltas.
position. We do deltas.
Maybe we can RL the hell out of
Maybe we can RL the hell out of
philosophy.
I think the RL would be like what what
I think the RL would be like what what
the hell are you guys doing? go back to
the hell are you guys doing? go back to
running actual experiments on things.
running actual experiments on things.
Delta delta is just distance. So we just
Delta delta is just distance. So we just
do like you know your so it's we do like
do like you know your so it's we do like
the x distance from you to the target or
the x distance from you to the target or
you could do angle and distance right.
you could do angle and distance right.
I think we just do use uh we just use
I think we just do use uh we just use
standard uh xyz chords not spherical or
standard uh xyz chords not spherical or
anything. There you go.
anything. There you go.
If you believe the universe itself can
If you believe the universe itself can
be an observer. So yeah. So Tyler, this
be an observer. So yeah. So Tyler, this
is basically the thing that just bothers
is basically the thing that just bothers
me about all of this is like, and this
me about all of this is like, and this
is something that scientists do, right?
is something that scientists do, right?
You come up with all these like
You come up with all these like
absolutely insane deranged theories uh
absolutely insane deranged theories uh
that really don't make any bloody sense
that really don't make any bloody sense
if you think about them. It's like you
if you think about them. It's like you
kind of just wrote down some math and
kind of just wrote down some math and
like ah yes, there's math. It makes
like ah yes, there's math. It makes
sense. But if you think about it, it
sense. But if you think about it, it
doesn't really make any bloody sense.
doesn't really make any bloody sense.
And literally like all these theories
And literally like all these theories
fit the data exactly as well as just
fit the data exactly as well as just
saying that the particles are omnisient.
That's what drives me insane.
So if we like flip the typical, you
So if we like flip the typical, you
know, if we flip the typical view of
know, if we flip the typical view of
quantum like well look, we have these
quantum like well look, we have these
models and they're very good at
models and they're very good at
predicting the real world, but we don't
predicting the real world, but we don't
really care if they're true or not.
really care if they're true or not.
they're very good at predicting the the
they're very good at predicting the the
data and they let us run experiments
data and they let us run experiments
that I could say, okay, well, I can
that I could say, okay, well, I can
equally well predict the real world by
equally well predict the real world by
just saying that the particles are
just saying that the particles are
omnisient and they know when they're
omnisient and they know when they're
being recorded.
And you do not have any more of a
And you do not have any more of a
satisfying mathematical explanation than
satisfying mathematical explanation than
the one that I just gave.
If the universe is the observer then
If the universe is the observer then
that could be true
that could be true
but like
but like
I mean that's not saying the universe is
I mean that's not saying the universe is
like that's like the same thing man
like that's like the same thing man
right
the thing is this is not speculation
the thing is this is not speculation
right we literally have experiments
right we literally have experiments
that match this as well as any other
that match this as well as any other
theory. I don't know how to go deeper
theory. I don't know how to go deeper
from there. Yeah. So, the problem here
from there. Yeah. So, the problem here
is if I try to like go back and forth
is if I try to like go back and forth
with a language model, they eventually
with a language model, they eventually
go off the rails and start telling me
go off the rails and start telling me
insane things. But quantum is also
insane things. But quantum is also
already kind of insane. So, I literally
already kind of insane. So, I literally
don't know what we know versus what is
don't know what we know versus what is
being made up. It seems like there is a
being made up. It seems like there is a
formal process to recording where it's
formal process to recording where it's
kind of hard to set up an experiment
kind of hard to set up an experiment
that decouples measurement from
that decouples measurement from
recording, but that seems like it should
recording, but that seems like it should
be possible.
be possible.
So anyways, the result of this
So anyways, the result of this
conversation is that I am probably going
conversation is that I am probably going
to have to just buy some lasers.
Maybe I can at least tell find somebody
Maybe I can at least tell find somebody
to tell me what to buy.
to tell me what to buy.
I don't end up buying the wrong
I don't end up buying the wrong
One agent calculating distance for 100
One agent calculating distance for 100
opponents.
opponents.
100 agent calculating delta for 100
100 agent calculating delta for 100
opponents.
opponents.
100 by 100 for deltas only. Yep.
100 by 100 for deltas only. Yep.
But you probably don't need to know the
But you probably don't need to know the
nearest 100.
You probably need like the nearest It's
You probably need like the nearest It's
probably like you need like the nearest
probably like you need like the nearest
20 or something.
20 or something.
And then right now we're doing it
And then right now we're doing it
naively. So it's quadratic, but we could
naively. So it's quadratic, but we could
make it n login if we were a little
make it n login if we were a little
smarter.
So there you go. All right, let me
So there you go. All right, let me
actually figure out how to do this
actually figure out how to do this
before I drive myself crazy. I mean, I
before I drive myself crazy. I mean, I
literally I was
literally I was
to give you an idea of my evening
to give you an idea of my evening
yesterday. Uh, and this has been for the
yesterday. Uh, and this has been for the
past two days. I finished my stream
past two days. I finished my stream
right before 6, had dinner, gone back to
right before 6, had dinner, gone back to
do a bunch of exercise behind me while
do a bunch of exercise behind me while
watching quantum quantum physics
watching quantum quantum physics
lectures,
lectures,
and then spent the like several hours
and then spent the like several hours
after that just like looking stuff up
after that just like looking stuff up
and thinking about stuff and trying to
and thinking about stuff and trying to
make sense of all this. So, let's
make sense of all this. So, let's
actually get some RL done.
actually get some RL done.
At least here we can get concrete
At least here we can get concrete
answers to things quite quickly.
like a decent evening. Yeah, except for
like a decent evening. Yeah, except for
the part where I keep myself up half the
the part where I keep myself up half the
night trying to like, you know, keep
night trying to like, you know, keep
myself up half the night thinking about
myself up half the night thinking about
what the is going on in quantum
model is just pattern matching.
model is just pattern matching.
But the thing is it's
But the thing is it's
there's a difference between a model and
there's a difference between a model and
an underlying phenomenon, right?
an underlying phenomenon, right?
Like a correct model is is necessary but
Like a correct model is is necessary but
not sufficient.
I don't know. This is what I get for
I don't know. This is what I get for
branching out and trying to study other
branching out and trying to study other
areas. Like originally this started as
areas. Like originally this started as
let me study a bunch of other areas of
let me study a bunch of other areas of
science to like look for cool
science to like look for cool
reinforcement learning problems. And now
reinforcement learning problems. And now
this has become okay these other areas
this has become okay these other areas
of science are pretty cool and I do want
of science are pretty cool and I do want
and I actually want to understand them a
and I actually want to understand them a
bit deeper.
All models are wrong but some are
All models are wrong but some are
useful.
useful.
Okay. So that's that's fair, right? And
Okay. So that's that's fair, right? And
I can understand the math. Um
I can understand the math. Um
at least I probably you I could if you
at least I probably you I could if you
as long as you don't ask me to solve the
as long as you don't ask me to solve the
equations. I actually at least I
equations. I actually at least I
understand the math as it's being
understand the math as it's being
explained, right? like yes I understand
explained, right? like yes I understand
the I understand the wave function as a
the I understand the wave function as a
model. I understand why it implies that
model. I understand why it implies that
by knowing position the forier transform
by knowing position the forier transform
collapses. Therefore you cannot
collapses. Therefore you cannot
understand uh you have no information
understand uh you have no information
about momentum. uh when one becomes a
about momentum. uh when one becomes a
direct delta the other becomes a uh a s
direct delta the other becomes a uh a s
or cosine like I understand that
or cosine like I understand that
right
but that doesn't tell us the that's like
but that doesn't tell us the that's like
a model that doesn't actually tell us
a model that doesn't actually tell us
the underlying thing or like why it
the underlying thing or like why it
happens or anything like That
I don't know. Maybe um maybe by the time
I don't know. Maybe um maybe by the time
I get to quantum field theory that will
I get to quantum field theory that will
have some answers.
have some answers.
From like the very little that I know,
From like the very little that I know,
it seems like maybe there's at least
it seems like maybe there's at least
something in there that gives us
something in there that gives us
something sort of plausible, but I don't
something sort of plausible, but I don't
think it gives you a full a full
think it gives you a full a full
solution to any of this.
Physics is cool. I don't know why I
Physics is cool. I don't know why I
never did more physics. Probably because
never did more physics. Probably because
I really didn't like having to like I
I really didn't like having to like I
liked learning about physics. I didn't
liked learning about physics. I didn't
like problem sets where it's basically
like problem sets where it's basically
solve puzzles using all these equations.
be a quantum physicist that has the most
be a quantum physicist that has the most
RL background in the field. That is
RL background in the field. That is
true. Well, I mean the thing is I could
true. Well, I mean the thing is I could
kind of do that with any of the fields,
kind of do that with any of the fields,
right? Which is kind of the point. Like
right? Which is kind of the point. Like
if I start learning a little bit about
if I start learning a little bit about
all these fields that maybe I can
all these fields that maybe I can
actually find cool problems where I
actually find cool problems where I
could apply RL to things.
could apply RL to things.
Of course, quantum has to stop driving
Of course, quantum has to stop driving
me crazy for me to do that first.
I don't know. Mad Scientist arc.
I forgot we don't need this anymore.
for me to hack the world. So, yeah,
for me to hack the world. So, yeah,
that's fine, right?
that's fine, right?
I understand it from that perspective,
I understand it from that perspective,
Tyler. I'm trying to understand it from
Tyler. I'm trying to understand it from
another perspective.
another perspective.
Well, let's be real. I don't fully
Well, let's be real. I don't fully
understand it from that perspective.
understand it from that perspective.
It's going to take me like going back
It's going to take me like going back
through a bunch more math and a bunch
through a bunch more math and a bunch
more lectures and things.
more lectures and things.
um to be like competent,
but I'm trying to understand it from
but I'm trying to understand it from
another perspective.
another perspective.
Yes. Industry is where you'll find most
Yes. Industry is where you'll find most
worthwhile RL problems. Yeah, exactly.
I mean, basically the way that I view
I mean, basically the way that I view
the way I view this stuff with RL is
the way I view this stuff with RL is
like all I got to do is find at least
like all I got to do is find at least
one of these problems, right, that
one of these problems, right, that
nobody's thought about from an RL
nobody's thought about from an RL
perspective before or at least from a
perspective before or at least from a
competent RL perspective before that's
competent RL perspective before that's
worth a billion dollars and then yay, we
worth a billion dollars and then yay, we
have unlimited funding to do science
have unlimited funding to do science
forever.
That's how I think of it.
If you want to find the secrets
If you want to find the secrets
universe, think in terms of energy,
universe, think in terms of energy,
frequency, and vibration.
Isn't that just flipping
That just flips you from particles by
That just flips you from particles by
default to waves by default, doesn't it?
default to waves by default, doesn't it?
But it's a dual interpretation. You need
But it's a dual interpretation. You need
both to explain the like to explain the
both to explain the like to explain the
data, don't you?
To explain all the experiments that have
To explain all the experiments that have
been done
been done
more of an aether effective
more of an aether effective
is it fields aren't aether. I guess
is it fields aren't aether. I guess
they're I guess you can kind of think of
they're I guess you can kind of think of
him as such. Maybe we should just Maybe
him as such. Maybe we should just Maybe
we should just like word swap the like
we should just like word swap the like
field with aether or was it ether?
field with aether or was it ether?
Aether. I think it's ether usually,
Aether. I think it's ether usually,
right? It's spelled that way. It's
right? It's spelled that way. It's
pronounced ether. Let's just like swap
pronounced ether. Let's just like swap
field with ether and everybody will
field with ether and everybody will
suddenly be more interested in stuff.
Physicist
Physicists think they're wizards. They
Physicists think they're wizards. They
can accomplish a lot.
can accomplish a lot.
I mean, it's kind of true of everything,
I mean, it's kind of true of everything,
right?
When stuff gets boring, nobody wants to
When stuff gets boring, nobody wants to
work on it.
work on it.
been one of the best things with RL is
been one of the best things with RL is
like, you know what speeding up RL a
like, you know what speeding up RL a
thousandx means? It means your
thousandx means? It means your
day-to-day work goes a lot faster
day-to-day work goes a lot faster
because it's less boring.
Okay, let me I think we are ready to run
Okay, let me I think we are ready to run
this little experiment that I've kind of
this little experiment that I've kind of
I kind of just been chatting but in the
I kind of just been chatting but in the
background I've sort of been thinking
background I've sort of been thinking
about how to do this
cuz I think I can literally just do
cuz I think I can literally just do
times two.
physics where things is called a
physics where things is called a
constant.
constant.
Yeah, those are just that's just curve
Yeah, those are just that's just curve
fitting, right?
fitting, right?
That doesn't bother me as much.
I would like it if I could find somebody
I would like it if I could find somebody
to actually tell me what I need for like
to actually tell me what I need for like
a decent experimental setup for uh
a decent experimental setup for uh
some of the stuff that you'd want to get
some of the stuff that you'd want to get
is like ludicrously expensive.
is like ludicrously expensive.
Like they technically
Like they technically
it's a hyperparameter.
it's a hyperparameter.
Uh I mean like every everything is
Uh I mean like every everything is
always going to have a constant in front
always going to have a constant in front
of it, right? Sometimes it's just one
of it, right? Sometimes it's just one
and like it's almost weird with there is
and like it's almost weird with there is
something special about the number one
this.
this.
So yeah, like it turns out you can
So yeah, like it turns out you can
actually just buy single photon sources
actually just buy single photon sources
and detectors, but uh yeah, they're like
and detectors, but uh yeah, they're like
25 grand.
So, I was trying to do a um
So, I was trying to do a um
I was trying to get like a laser
I was trying to get like a laser
instead.
You're going to get to the point where
You're going to get to the point where
you need an Earthsized particle
you need an Earthsized particle
accelerator.
accelerator.
Better get building it then.
Better get building it then.
Must be at least one hyper pram.
Must be at least one hyper pram.
H.
H.
I don't know. Constants have never
I don't know. Constants have never
really
really
hasn't bothered me too much.
[Music]
[Music]
Does this work?
I have a feeling this is seg faulting.
Yes. Fault. Okay.
Oh, and I know why.
That's That's more philosophy than
That's That's more philosophy than
anything.
When it becomes philosophy, I get bored.
Like actual experiments things.
It's actually kind of amusing. And so
It's actually kind of amusing. And so
the thing that set me off on this whole
the thing that set me off on this whole
quantum shenanigans was I was watching
quantum shenanigans was I was watching
solid state chemistry and the professor
solid state chemistry and the professor
said that actually the Heisenberg
said that actually the Heisenberg
uncertainty principle should be called
uncertainty principle should be called
the Heisenberg non-determinate
the Heisenberg non-determinate
non-determination principle because it's
non-determination principle because it's
a problem of measurement. Oh, okay. That
a problem of measurement. Oh, okay. That
actually makes way more sense. And then
actually makes way more sense. And then
you go over to quantum and they say
you go over to quantum and they say
actually no. It seems that this kind of
actually no. It seems that this kind of
just happens like regardless.
I mean that's
I just have to compile this with um
I just have to compile this with um
I think I'm uh I'm too tired to just
I think I'm uh I'm too tired to just
guess. I'm going to have to just compile
guess. I'm going to have to just compile
this with uh
this with uh
have to compile this with debug on and
have to compile this with debug on and
just figure it out.
Gotta love when uh random ass
Gotta love when uh random ass
environment screws you over.
What I get for merging this
Of
course, it's in a case statement where
course, it's in a case statement where
it's like, "Please don't do that."
it's like, "Please don't do that."
Did you see Tesla's full self-driving?
Did you see Tesla's full self-driving?
What do you mean? Did I see it?
video plus operation.
I like my family has a Tesla. Like
I like my family has a Tesla. Like
I've ridden in it. Yeah, it's good. Like
I've ridden in it. Yeah, it's good. Like
yes, they're going to self-driving.
Why is this me set wrong?
Why is this me set wrong?
Oh.
Yes, vision data is plenty.
Yes, vision data is plenty.
This is obvious.
What if there's a snowstorm? Same thing
What if there's a snowstorm? Same thing
that happens when people drive in
that happens when people drive in
snowstorms, except, you know, better
snowstorms, except, you know, better
because it has instantaneous reaction
because it has instantaneous reaction
time basically
and precise control.
any argument of the form that like the
any argument of the form that like the
camera shouldn't be able to drive in
camera shouldn't be able to drive in
snowstorm or whatever um leads to the
snowstorm or whatever um leads to the
natural argument that people should be
natural argument that people should be
banned from driving in snowstorms.
It's like a one to one. There's like no
It's like a one to one. There's like no
difference. Like basically any case you
difference. Like basically any case you
say well the camera can't handle this
say well the camera can't handle this
situation. You're basically saying a
situation. You're basically saying a
person can't handle this situation.
do think you can trust a system more if
do think you can trust a system more if
it has extra feedback.
it has extra feedback.
You can make it way safer than humans
You can make it way safer than humans
without extra sensors. You probably
without extra sensors. You probably
can't make it as safe as if you as if
can't make it as safe as if you as if
you had all the sensors, but I would
you had all the sensors, but I would
imagine you can like reduce the number
imagine you can like reduce the number
of accidents uh by a factor of 10 over
of accidents uh by a factor of 10 over
humans
humans
just with the existing ones.
And basically at the at the point that
And basically at the at the point that
so I mean
so I mean
the thing that's really obnoxious about
the thing that's really obnoxious about
self-driving and why I just don't like
self-driving and why I just don't like
it as a problem uh is because there's a
it as a problem uh is because there's a
very large gap between the like
very large gap between the like
logically very clear thing that should
logically very clear thing that should
happen and what people will actually
happen and what people will actually
accept. Right? Right. So, a lot like the
accept. Right? Right. So, a lot like the
very clear thing that should happen here
very clear thing that should happen here
is that once you reduce the number of
is that once you reduce the number of
accidents per mile below the uh let's
accidents per mile below the uh let's
say below the median human driver,
say below the median human driver,
uh you're actively killing people by
uh you're actively killing people by
keeping these things off of the road.
keeping these things off of the road.
Like just straight up like number of
Like just straight up like number of
deaths with these on road is strictly
deaths with these on road is strictly
going to be greater than number of
going to be greater than number of
deaths without these things on road. So
deaths without these things on road. So
clearly these things should be legalized
clearly these things should be legalized
as soon as you beat that benchmark
as soon as you beat that benchmark
convincingly. Uh, but what's going to
convincingly. Uh, but what's going to
happen in practice is it's going to have
happen in practice is it's going to have
to be like 10x lower at least because
to be like 10x lower at least because
every time there is an accident, the
every time there is an accident, the
media is going to blow it up and like
media is going to blow it up and like
Congress is going to blow it up and like
Congress is going to blow it up and like
there's going to be all sorts of
there's going to be all sorts of
legislation. Uh, where like for
legislation. Uh, where like for
absolutely no reason. Uh, so like it's
absolutely no reason. Uh, so like it's
kind of just a problem that just makes
kind of just a problem that just makes
you hate people more than anything else
you hate people more than anything else
because like you can solve the tech
because like you can solve the tech
problem sufficiently and then like okay
problem sufficiently and then like okay
we can make it 10x better from here
we can make it 10x better from here
but that's not actually how it's going
but that's not actually how it's going
to turn out.
Number they aim for is one accident per
Number they aim for is one accident per
400k. I I don't think it gets deployed
400k. I I don't think it gets deployed
on that is the thing. I don't think you
on that is the thing. I don't think you
get full deployment on that number
get full deployment on that number
because of the reason that I just said.
What if human vision is a decoder that's
What if human vision is a decoder that's
impossible to replicate? that would take
impossible to replicate? that would take
it. That seems like exceedingly unlikely
rainbows and Teslas approach that number
rainbows and Teslas approach that number
in better. Yeah, that's the problem,
in better. Yeah, that's the problem,
right?
right?
Like I hate it when you end up with like
Like I hate it when you end up with like
it's not even a tech problem, right? The
it's not even a tech problem, right? The
answer is incredibly obvious and then
answer is incredibly obvious and then
you just have this existing class of
you just have this existing class of
like I don't know useless bureaucrats in
like I don't know useless bureaucrats in
the way
Yeah, it's a political problem.
Yeah, it's a political problem.
It's like literally like, "Oh yeah, my
It's like literally like, "Oh yeah, my
job is to show up to the office, look
job is to show up to the office, look
important, stole technological progress,
important, stole technological progress,
and kill people."
and kill people."
That's literally what it it boils down
That's literally what it it boils down
to. Of course, they're not going to say
to. Of course, they're not going to say
it that way. They're going to say
it that way. They're going to say
something super lofty sounding, but
something super lofty sounding, but
that's what it boils down to.
The heck is wrong with this?
Surely it can't be sealing here, right?
Surely it can't be sealing here, right?
Oh, you know what it is? No, it is
Oh, you know what it is? No, it is
seging there. I'm dumb.
I know what it is. Ipotent
AI.
Yeah. And the funny thing about this is
Yeah. And the funny thing about this is
right like this discussion
right like this discussion
is like yeah I agree I don't I don't
is like yeah I agree I don't I don't
want humans to be like relegated to this
want humans to be like relegated to this
like useless position but like the
like useless position but like the
current alternative
current alternative
the current alternative is the leaders
the current alternative is the leaders
that we have now which
that we have now which
You can look at that and that's not a
You can look at that and that's not a
comment on current political anything.
comment on current political anything.
That's a comment on politics in general.
But then the other like the other side
But then the other like the other side
of that, right, is that the AIS are
of that, right, is that the AIS are
currently they're made by people and
currently they're made by people and
they suck. Like the language models are
they suck. Like the language models are
kind of crap right now.
Like at the moment I trust a competent
Like at the moment I trust a competent
person way more than I trust a language
person way more than I trust a language
model. That will eventually change.
model. That will eventually change.
Maybe, maybe not. I don't know.
Maybe, maybe not. I don't know.
Architecturally, like AI will get
Architecturally, like AI will get
better. I don't know if language models
better. I don't know if language models
alone get to that point.
Neural MMO, can you please, my name is
Neural MMO, can you please, my name is
Joseph. Neural MMO is my main project
Joseph. Neural MMO is my main project
from my PhD. Can you please guide me on
from my PhD. Can you please guide me on
how to start reinforcement learning? I
how to start reinforcement learning? I
need it and I can't find any proper
need it and I can't find any proper
path. I got you covered. hover.ai
path. I got you covered. hover.ai
docs or not docs, my bad. You can go to
docs or not docs, my bad. You can go to
there after reinforcement learning quick
there after reinforcement learning quick
start guide. Read this. Read the
start guide. Read this. Read the
articles in here that it tells you to
articles in here that it tells you to
read. It's like a handful of blog post
read. It's like a handful of blog post
and a few academic papers. So, do that
and a few academic papers. So, do that
in chunks. You don't have to do it all
in chunks. You don't have to do it all
at once. Do like this plus maybe one or
at once. Do like this plus maybe one or
two blog posts. All right? and then go
two blog posts. All right? and then go
over to the docs
over to the docs
and implement a basic reinforcement
and implement a basic reinforcement
learning environment from scratch
learning environment from scratch
following these docs.
following these docs.
And if you have trouble with that, come
And if you have trouble with that, come
ask for help over here. This is how you
ask for help over here. This is how you
get into reinforcement learning. This is
get into reinforcement learning. This is
how almost all of our contributors have
how almost all of our contributors have
gotten into reinforcement learning. It
gotten into reinforcement learning. It
works even if you do not have like
works even if you do not have like
remotely any background. It'll just take
remotely any background. It'll just take
a little bit longer. You just have to do
a little bit longer. You just have to do
it.
it.
I've made it as easy as I possibly can
I've made it as easy as I possibly can
with reward engineered by a human.
with reward engineered by a human.
Sometimes
Sometimes
uh sometimes it depends on the problem
uh sometimes it depends on the problem
in the reward
to robot. I honestly I don't Yeah, I
to robot. I honestly I don't Yeah, I
don't I don't really care about the
don't I don't really care about the
whole political side of of all this
whole political side of of all this
stuff.
stuff.
It's kind of just like we're probably
It's kind of just like we're probably
going to come up with the dumbest pro
going to come up with the dumbest pro
the dumbest possible way to handle all
the dumbest possible way to handle all
of it. And like there's very little that
of it. And like there's very little that
you can do about that. The only thing
you can do about that. The only thing
that we can do is build good tech.
Go.
Average
Average
Oh, that's going to have to improve
Oh, that's going to have to improve
eventually, man. That's going to have to
eventually, man. That's going to have to
improve eventually.
My hope is that we develop tech that
My hope is that we develop tech that
actually allows us to be smarter
actually allows us to be smarter
because I can tell you with all the
because I can tell you with all the
stuff that I've built, like most of the
stuff that I've built, like most of the
time, I feel like barely smart enough to
time, I feel like barely smart enough to
make progress in all the stuff that I'm
make progress in all the stuff that I'm
doing, right? Like barely.
doing, right? Like barely.
There are like clear clear areas and
There are like clear clear areas and
like gaps in my own abilities where it's
like gaps in my own abilities where it's
like it's just straight up I don't know
like it's just straight up I don't know
why my brain doesn't let me do this
Like certain types of symbolic
Like certain types of symbolic
manipulation and stuff. It just doesn't
manipulation and stuff. It just doesn't
work for me.
I don't know.
Let's see if this works.
worst performing student.
I might
I might
PhD graduate. That's still not good
PhD graduate. That's still not good
enough, man.
enough, man.
That's still not good enough.
That's still not good enough.
Welcome, SPY.
Today's discussion topics include
Today's discussion topics include
multi-agent swarms, tactical battle
multi-agent swarms, tactical battle
sims, quantum physics,
sims, quantum physics,
and uh long-term AI progress. Welcome to
and uh long-term AI progress. Welcome to
Saturday stream.
This thing hasn't seeded yet.
This thing hasn't seeded yet.
Let me have more coffee.
I don't happen to have anybody watching
I don't happen to have anybody watching
that knows quantum physics and can tell
that knows quantum physics and can tell
me what lasers to order, right? That
me what lasers to order, right? That
would just be too lucky.
Single-handedly comes up with diffusion
Single-handedly comes up with diffusion
model.
It depends. Math is one axis, man. Like
It depends. Math is one axis, man. Like
there are a lot of really really good
there are a lot of really really good
math people at MIT and like far far
math people at MIT and like far far
fewer people at MIT that have like some
fewer people at MIT that have like some
sort of broad perspective on what to do
sort of broad perspective on what to do
with the math that they know.
Garbage. Garbage. Garbage.
Okay, this runs
Let's see if we can get the scripted
Let's see if we can get the scripted
thing to like do something.
thing to like do something.
How prioritized replay improve overall
How prioritized replay improve overall
agent action selection? Are you asking
agent action selection? Are you asking
about the original prioritized
about the original prioritized
experience replay or the version that we
experience replay or the version that we
have in puffer lip? Because they're two
have in puffer lip? Because they're two
very different things.
very different things.
Please clarify.
Please clarify.
Yes. What? Original or the puffer one?
Okay. So, puffer replay it's only done
Okay. So, puffer replay it's only done
over the experience that's collected in
over the experience that's collected in
a single epoch. Okay. So, it's it's a is
a single epoch. Okay. So, it's it's a is
it's as on policy as on policy data can
it's as on policy as on policy data can
be. So, we're not taking data from
be. So, we're not taking data from
previous epochs. Okay. And specifically
previous epochs. Okay. And specifically
what we're doing is we're using the
what we're doing is we're using the
prioritize replay sampling criterion
prioritize replay sampling criterion
because prioritize replay is just that.
because prioritize replay is just that.
It's a sampling criterion. It tells you
It's a sampling criterion. It tells you
what data to sample in what frequency
what data to sample in what frequency
based on in this case the advantage
based on in this case the advantage
function. We're using this to guide uh
function. We're using this to guide uh
how we sample from the experience
how we sample from the experience
collected just during this one last
collected just during this one last
epoch uh into many batches. So instead
epoch uh into many batches. So instead
of going over the data in chunks, we're
of going over the data in chunks, we're
sampling it according to the prioritized
sampling it according to the prioritized
replay uh math for sampling. That's all
replay uh math for sampling. That's all
we're doing. And this allows you to uh
we're doing. And this allows you to uh
bias the algorithm towards higher
bias the algorithm towards higher
information trajectory segments if you
information trajectory segments if you
want to think of it that way.
want to think of it that way.
That is what we do.
Double check my email real quick.
If I have a stream of data, I don't need
If I have a stream of data, I don't need
to think of LSTM manually. Just use the
to think of LSTM manually. Just use the
damn LSTM, man.
There's like no reason not to.
There's like no reason not to.
Our
Our
L we have LSTM support for everything
L we have LSTM support for everything
out of the box and the LSTM is literally
out of the box and the LSTM is literally
the far the fastest part of the network.
the far the fastest part of the network.
Like I can train a million parameter
Like I can train a million parameter
LSTM at a million steps per No, I'm
LSTM at a million steps per No, I'm
sorry. I can train a 4 million parameter
sorry. I can train a 4 million parameter
LSTM at a million steps per second. All
LSTM at a million steps per second. All
right, the LSTM is not a bottleneck.
right, the LSTM is not a bottleneck.
It's slow in other libraries because
It's slow in other libraries because
they're bad.
they're bad.
That's it.
Uh yeah, this is super freaking fast.
The hell
The hell
fault.
do this.
It's not that we think that LSTM is like
It's not that we think that LSTM is like
the holy grail of architectures or
the holy grail of architectures or
something like in 2019. It's just it's
something like in 2019. It's just it's
really fast.
really fast.
And it's like it's the most stable fast
And it's like it's the most stable fast
thing. Does that make sense? Like
thing. Does that make sense? Like
transformers are just not fast. At least
transformers are just not fast. At least
any variant that we've found is just not
any variant that we've found is just not
fast. And also they're a pain in the ass
fast. And also they're a pain in the ass
because like you get all these like off
because like you get all these like off
these like misalign trajectory segments
these like misalign trajectory segments
in RL. And uh you have to run a
in RL. And uh you have to run a
transformer on that context, which like
transformer on that context, which like
admittedly I could figure out how to do.
admittedly I could figure out how to do.
It wouldn't be terrible, but even then I
It wouldn't be terrible, but even then I
just don't think it would be fast. Like
just don't think it would be fast. Like
fundamentally
fundamentally
they aren't linear in time. So unless
they aren't linear in time. So unless
you actually had a good
you actually had a good
even linear in time wouldn't be good
even linear in time wouldn't be good
enough, frankly, because right now it's
enough, frankly, because right now it's
constant in time. Yeah, literally it's
constant in time. Yeah, literally it's
constant in time right now. And then
constant in time right now. And then
they go to quadratic in time. The best
they go to quadratic in time. The best
ones are linear in time and those don't
ones are linear in time and those don't
even work.
Things slow, man. Super slow.
Okay. Why are
Okay. Why are
are bots this fast?
Got these guys that are going at a
Got these guys that are going at a
normal speed and then these guys that
normal speed and then these guys that
are just like zoom.
Okay.
Oh,
Oh,
forgot this
dummy.
Yeah, there we go.
Huh?
There they are.
What is your goal with the lasers? Are
What is your goal with the lasers? Are
you trying to make an interferometer?
you trying to make an interferometer?
Uh
Uh
I basically want to run a double slit
I basically want to run a double slit
experiment that
experiment that
uh in which there are no moving parts
uh in which there are no moving parts
that change between the on and the off
that change between the on and the off
state. So the recording of data is
state. So the recording of data is
maximally isolated
maximally isolated
or the the recording of data is
or the the recording of data is
maximally isolated from the measurement
maximally isolated from the measurement
of data such that the recording off
of data such that the recording off
state produces interference.
Side project. Side project. Quantum
Side project. Side project. Quantum
physics research.
I do here.
This should now make these things fly
This should now make these things fly
much more reasonably maybe.
some weird thing happening when they get
some weird thing happening when they get
close to each other.
Take full
I was like looking to see if I uh if I
I was like looking to see if I uh if I
had responses on the other environment
had responses on the other environment
that I work on and they go, "Oh yeah,
that I work on and they go, "Oh yeah,
Saturday. Most people don't work
Saturday. Most people don't work
Saturday." Duh.
What have I done that's silly here that
What have I done that's silly here that
causes this behavior?
causes this behavior?
We should also just figure out what the
We should also just figure out what the
seg fault is, right?
But like look at this behavior. Ready?
But like look at this behavior. Ready?
So, they're going to get close and
So, they're going to get close and
they're going to accelerate.
Yeah, it's like they just get super
Yeah, it's like they just get super
fast.
fast.
Uh, how did
Uh, how did
I have something getting divide by zero,
I have something getting divide by zero,
right?
Yeah.
They start accelerating when they get
They start accelerating when they get
like relatively close.
Anybody
see it?
It have to be this somehow, but I don't
It have to be this somehow, but I don't
see it.
I mean, I could just clip it, but I
I mean, I could just clip it, but I
don't want to just like that. No, this
don't want to just like that. No, this
this should be the correct
weird distance.
Is it because I have to divide by square
Is it because I have to divide by square
root?
root?
I think it's got to be.
I think it's got to be.
It's got to be this.
I was trying to save compute, but I
I was trying to save compute, but I
think it might have been nonlinear.
think it might have been nonlinear.
See if this is it.
Yep, that was it.
Yep, that was it.
Okay. So, they don't know how to turn
Okay. So, they don't know how to turn
towards each other.
towards each other.
So, uh they don't actually fight.
So, uh they don't actually fight.
But yeah, that's the that's the issue.
But yeah, that's the that's the issue.
Me dumb. Square root not linear
Me dumb. Square root not linear
function. Duh.
I'm going to leave this up for a couple
I'm going to leave this up for a couple
minutes. We'll see if it's stable. I'll
minutes. We'll see if it's stable. I'll
leave this. So you can watch it. If
leave this. So you can watch it. If
anybody has any ideas how to do the math
anybody has any ideas how to do the math
to like turn these towards the target,
to like turn these towards the target,
it's probably just some sort of vector
it's probably just some sort of vector
multiply, some clot multiply. I will be
multiply, some clot multiply. I will be
right back. a couple quick things and we
right back. a couple quick things and we
will continue on this and we will uh
will continue on this and we will uh
once we get the ships to turn towards
once we get the ships to turn towards
each other basically we'll have like a a
each other basically we'll have like a a
simple scripted opponent to play against
simple scripted opponent to play against
and then the idea is that we'll be able
and then the idea is that we'll be able
to actually get a reasonable evaluation
to actually get a reasonable evaluation
metric which is win rate versus the
metric which is win rate versus the
opponent or whatever. Uh unlike the
opponent or whatever. Uh unlike the
current thing where it's all selfplay so
current thing where it's all selfplay so
you can't really get like a consistent
you can't really get like a consistent
metric and then we can optimize versus
metric and then we can optimize versus
that and then hopefully that'll give us
that and then hopefully that'll give us
some reasonable tactical behavior. We
some reasonable tactical behavior. We
take the same hyper prams, we throw it
take the same hyper prams, we throw it
on selfplay, and we get some like cool
on selfplay, and we get some like cool
thing to happen. Be right back. Oops. Be
thing to happen. Be right back. Oops. Be
right back.
Okay.
Okay.
What's the procedure
What's the procedure
to connect Neptune AI?
So,
you literally just make an account and
you literally just make an account and
then you paste your API key in. It's all
then you paste your API key in. It's all
it is.
it is.
And you just do d- Neptune
And you just do d- Neptune
and it'll pick it up.
All right.
Yep,
Yep,
that'll work.
You got to pip install Neptune.
You got to pip install Neptune.
Obviously,
what is tag? Tag just assigns it like a
what is tag? Tag just assigns it like a
little group in the dashboard so you can
little group in the dashboard so you can
sort your experiments. You don't have to
sort your experiments. You don't have to
tag it. It'll just go under the default
tag it. It'll just go under the default
tag if you don't tag it. We use it for
tag if you don't tag it. We use it for
mostly sweeps and like specific games
mostly sweeps and like specific games
and stuff.
Neptune's authenticating. So yeah. So
Neptune's authenticating. So yeah. So
technically I believe there's a default
technically I believe there's a default
project like Ablation somewhere.
project like Ablation somewhere.
Yeah. So right here there's also this
Yeah. So right here there's also this
project name. You should probably set
project name. You should probably set
these
token product. Yeah. So, there's a
token product. Yeah. So, there's a
default config. You can set these from
default config. You can set these from
command line train.name like or you can
command line train.name like or you can
just edit them in the default config.
just edit them in the default config.
Either way,
Either way,
you'll be good.
Okay. So, We unfortunately have some
Okay. So, We unfortunately have some
vector math to deal with,
vector math to deal with,
which should be easy, but for whatever
which should be easy, but for whatever
reason, never is.
Isn't it literally Okay, all I need to
Isn't it literally Okay, all I need to
do is I need a quaternian to rotate
do is I need a quaternian to rotate
towards the target, right?
Wait, rotate by quitterium.
using UV. That's fine. So I think then
using UV. That's fine. So I think then
you can do here. Look, if you just do
you can do here. Look, if you just do
puffer train uh puffer
puffer train uh puffer
help, it'll just tell you
- Neptune-
- Neptune-
Neptune name and Neptune project
Neptune name and Neptune project
apparently should do it
and let me know if that doesn't work.
Token isn't uh you don't pass token like
Token isn't uh you don't pass token like
that. So token you pass as an end
that. So token you pass as an end
variable or as an export. That's part of
variable or as an export. That's part of
Neptune. So if when you do like get my
Neptune. So if when you do like get my
API token or whatever, it'll tell you
API token or whatever, it'll tell you
how to export it,
how to export it,
it gives you the thing to just paste in
it gives you the thing to just paste in
or to put in your bash RC or whatever.
End. Yes, you put it in the end or
End. Yes, you put it in the end or
whatever. Make sure you source the file.
There you go.
How do you do this, man? So weird.
How do you do this, man? So weird.
I'm going to plug this into Grock
I'm going to plug this into Grock
against my better judgment.
I don't know what it is.
Whenever I get to geometry stuff with
Whenever I get to geometry stuff with
like
like
vector map for geometry, it's like I my
vector map for geometry, it's like I my
brain just stops working.
brain just stops working.
I don't know why.
I have no idea why this is unintuitive.
environment.
Yeah, it has all the information.
That's just Neptune. That's like Neptune
That's just Neptune. That's like Neptune
standard doc. So not puffer.
quturnian from vector 3 to ve did it
quturnian from vector 3 to ve did it
just make up a function that doesn't
just make up a function that doesn't
exist?
I think it did. modify
I think it did. modify
this.
Huh?
Some reason they didn't shoot each
Some reason they didn't shoot each
other.
Okay, so now they shouldn't actually get
Okay, so now they shouldn't actually get
to be on top of each other. We'll just
to be on top of each other. We'll just
have to figure out why they don't
have to figure out why they don't
actually fire.
is puffer lilib and by default a
is puffer lilib and by default a
parallel or sequential?
parallel or sequential?
Uh
Uh
kind of both. So our most of our ocean
kind of both. So our most of our ocean
environments the way they work is uh on
environments the way they work is uh on
each core you can simulate many
each core you can simulate many
environments in series that is the n of
environments in series that is the n of
num ms param and then vecnum ms will
num ms param and then vecnum ms will
allow you to multi-core those you have
allow you to multi-core those you have
multiple cores within multiple ends in
multiple cores within multiple ends in
serial on each core but then across
serial on each core but then across
cores is parallel
I don't know what happened there.
I don't know what happened there.
Roll through it.
Here we go.
Uh yeah, that's not supposed to happen.
Yeah, I was looking up that thing. So,
Yeah, I was looking up that thing. So,
the thing is that experiment is usually
the thing is that experiment is usually
done with um polarizing filters, isn't
done with um polarizing filters, isn't
it, Tyler?
which are a physical obstruction
which are a physical obstruction
and also like clearly have the like the
and also like clearly have the like the
effect of basically doing a change of
effect of basically doing a change of
basis where you project the polarized
basis where you project the polarized
like so all light is gone on one axis
like so all light is gone on one axis
but then you project it on a different
but then you project it on a different
coordinates so then you end up with half
coordinates so then you end up with half
of that back I didn't find that
of that back I didn't find that
experiment like or at least that version
experiment like or at least that version
of it particularly useful
I've also literally only been studying
I've also literally only been studying
quantum for like three days. I knew
quantum for like three days. I knew
nothing about quantum mechanics at all
nothing about quantum mechanics at all
three days ago. I've kind of just been
three days ago. I've kind of just been
binging lectures and like reading a
binging lectures and like reading a
bunch of stuff in my off hours.
Okay. So somehow these things they just
Okay. So somehow these things they just
get like
get like
got quantum entangled reinforcement
got quantum entangled reinforcement
learning agents.
learning agents.
You can see here
You can see here
see how that we figure this out.
Okay. So D.
This does. They should stop
This does. They should stop
like close to each other now.
And they should be fighting here.
It's actually a good question why
It's actually a good question why
they're not firing at each other here.
I think the angle's probably computed
I think the angle's probably computed
wrong.
Yeah, there we go.
Yeah, there we go.
Whether the damage values are reasonable
Whether the damage values are reasonable
or not, who knows? But it is the angle
or not, who knows? But it is the angle
somehow.
This branch of physics makes my head
This branch of physics makes my head
hurt.
hurt.
I don't know. It's it's been very cool.
The thing is like
the experiment that I'm trying to
the experiment that I'm trying to
conduct and I'll I'll tell you more once
conduct and I'll I'll tell you more once
I think about it a little bit but like
I think about it a little bit but like
if the experiment
if the experiment
if the experiment that I have in my head
if the experiment that I have in my head
works the way that
works the way that
um I think it should work according to
um I think it should work according to
the predictions of quantum mechanics
the predictions of quantum mechanics
then it would be like
then it would be like
it would essentially be like a thing
it would essentially be like a thing
that would just completely completely
that would just completely completely
break your understanding of reality
break your understanding of reality
without you having to know anything
without you having to know anything
about physics, if that makes sense.
And it would also have a bunch of like
And it would also have a bunch of like
actual useful applications of the tech
actual useful applications of the tech
as well. So,
as well. So,
physics cool.
I need to buy some lasers. Apparently,
I also have to look up safety
I also have to look up safety
precautions for working with lasers.
I've been trying to figure out like
I've been trying to figure out like
because I'm looking into all these
because I'm looking into all these
different branches of science now, many
different branches of science now, many
of which have like are actually they do
of which have like are actually they do
actual lab work. Um
actual lab work. Um
I kind of need to like go get myself lab
I kind of need to like go get myself lab
trained for a bunch of different areas
trained for a bunch of different areas
somehow.
somehow.
definitely buy some GL. Yeah, I probably
definitely buy some GL. Yeah, I probably
should like figure out how I can go get
should like figure out how I can go get
myself trained for like a bunch of
myself trained for like a bunch of
different types of lab work because I
different types of lab work because I
really have never done that type of
really have never done that type of
stuff. You know,
stuff. You know,
it's the one very unfortunate things
it's the one very unfortunate things
about working uh in AI is like you don't
about working uh in AI is like you don't
really need any equipment to do all this
really need any equipment to do all this
cool stuff that we do, but that also
cool stuff that we do, but that also
means you don't have any experience
means you don't have any experience
working with actual equipment of any
working with actual equipment of any
type. You kind of just sit here and type
type. You kind of just sit here and type
and then you make crazy happen. But
and then you make crazy happen. But
then as soon as you want to do something
then as soon as you want to do something
that doesn't just involve typing, you're
that doesn't just involve typing, you're
like, "Hey, I don't know what to do."
like, "Hey, I don't know what to do."
walk. I'm a mia
less than five
less than five
mango watts.
mango watts.
I think it was seven.
But it's the thing is it goes through an
But it's the thing is it goes through an
attenuator as well.
Yeah, it's seven.
It's this thing.
But then I think that you you basic I
But then I think that you you basic I
think that you try to like take the
think that you try to like take the
power down or like block most of it so
power down or like block most of it so
that you get a a relatively
that you get a a relatively
fewer number of photons out of it.
But I think like technically it's
But I think like technically it's
dangerous if you set it up wrong or
dangerous if you set it up wrong or
whatever cuz obviously the source is
whatever cuz obviously the source is
still seven mega uh seven mills or
still seven mega uh seven mills or
whatever.
I don't know. The lasers are actually
I don't know. The lasers are actually
super cheap. I would love to know why
super cheap. I would love to know why
some of this other stuff is so bloody
some of this other stuff is so bloody
expensive.
No.
Also, why it's nuked my shopping cart?
Manufactured in USA. Oh, I don't know.
Manufactured in USA. Oh, I don't know.
Maybe that's why lasers like that 20
Maybe that's why lasers like that 20
years ago were bloody expensive.
years ago were bloody expensive.
Yeah. I co-founder house drama slop
Yeah. I co-founder house drama slop
show. What?
show. What?
Yeah. I don't I I really don't care
Yeah. I don't I I really don't care
about the dumb things that SF people do.
about the dumb things that SF people do.
Like I I really don't care.
I'm really kind of just sick of the
I'm really kind of just sick of the
whole
whole
the whole like all of AI being B2B SAS
the whole like all of AI being B2B SAS
idiot wear is like that needs to go.
idiot wear is like that needs to go.
Come on, we're making cool tech. Let's
Come on, we're making cool tech. Let's
actually throw it on things that matter.
in light has potential
clout chasing. Yeah. Which is just lame
clout chasing. Yeah. Which is just lame
as
Like Tyler, do you know do you know what
Like Tyler, do you know do you know what
the easiest way would be for me to like
the easiest way would be for me to like
figure out uh what I need and where to
figure out uh what I need and where to
like what I should get for this type of
like what I should get for this type of
basic optic setup. But I you need like
basic optic setup. But I you need like
an optics breadboard and like you put it
an optics breadboard and like you put it
on I think it's like a meter or one by
on I think it's like a meter or one by
one or 2x two meter surface or whatever.
one or 2x two meter surface or whatever.
And like I think that there's some stuff
And like I think that there's some stuff
with like the lighting and all that like
with like the lighting and all that like
I need to figure that stuff out.
I don't know. I could technically stream
I don't know. I could technically stream
all this stuff, too. I have a spot right
all this stuff, too. I have a spot right
behind me. Just put this freaking table
behind me. Just put this freaking table
down behind me and we do we do quantum
down behind me and we do we do quantum
physics experiments on stream. That
physics experiments on stream. That
sounds fun.
I mean, it looks like the basic setup
I mean, it looks like the basic setup
can be obtained for a few grand, which
can be obtained for a few grand, which
is like I'm willing to spend that or uh
is like I'm willing to spend that or uh
do cool science.
particularly when there's a possibility
particularly when there's a possibility
that I discover something new.
Okay, I think I see how I did this
Okay, I think I see how I did this
wrong.
distance three angle.
Let me know what you're thinking about
Let me know what you're thinking about
buying. Oh yeah, I can send you the
buying. Oh yeah, I can send you the
list. I got to finish putting it
list. I got to finish putting it
together. Um, which I'll probably do
together. Um, which I'll probably do
like tomorrow in my spare time.
like tomorrow in my spare time.
Nanc pyometers for electron beam.
Nanc pyometers for electron beam.
Version interferometer for nancond.
Version interferometer for nancond.
Okay, that's actually that's a different
Okay, that's actually that's a different
application but pretty similar
application but pretty similar
equipment.
Yeah, that's pretty similar equipment
Yeah, that's pretty similar equipment
because it is kind of just optics
because it is kind of just optics
equipment for a lot of the quantum
if this does anything. So, this should
if this does anything. So, this should
give us the result that the drones fire
give us the result that the drones fire
at each other consistently.
Yep. So, they fire.
Yep. So, they fire.
That looks consistent to me.
That looks consistent to me.
That does it. We just have to do this
That does it. We just have to do this
for the rest of our uh
for the rest of our uh
Oh, wait. Hang on.
Oh, wait. Hang on.
Yes, that does it. So, we just have to
Yes, that does it. So, we just have to
do this for the rest of our um
do this for the rest of our um
attack functions.
by
word vector
word vector
target.
This looks good.
Uh, this one's easy.
Uh, this one's easy.
And this one
anti-air.
This one does have a range.
Wait. Attack any air.
Wait. Attack any air.
Bomber
Bomber
ground air.
ground air.
That's it.
That makes sense why the ships were
That makes sense why the ships were
flying in this weird fashion.
flying in this weird fashion.
Find it pretty weird that he skills with
Find it pretty weird that he skills with
the power and the beam.
the power and the beam.
I have not even gotten there, Tyler.
I have not even gotten there, Tyler.
I gotta figure a lot of stuff out still,
I gotta figure a lot of stuff out still,
man.
So basically I so first of all the
So basically I so first of all the
quantum stuff is just awesome and like
quantum stuff is just awesome and like
it's messing with me. So I think there's
it's messing with me. So I think there's
a possibility I actually might with the
a possibility I actually might with the
experiments I'm thinking about if they
experiments I'm thinking about if they
work in remotely the way that I think
work in remotely the way that I think
that they might then I could actually
that they might then I could actually
discover something really cool or at
discover something really cool or at
least let's say I could present
least let's say I could present
something that is known in a way that's
something that is known in a way that's
like
like
very
very
striking and actually would like it
striking and actually would like it
would change the way that a lot of
would change the way that a lot of
people look at stuff potentially. But
people look at stuff potentially. But
then separately, I'm kind of just trying
then separately, I'm kind of just trying
to understand a lot of like low-level
to understand a lot of like low-level
physics. Uh because it applies to
physics. Uh because it applies to
everything, right? It applies to
everything, right? It applies to
chemistry, it applies to physics itself,
chemistry, it applies to physics itself,
it applies to material science. And I'm
it applies to material science. And I'm
sort of starting to think about like
sort of starting to think about like
low-level real world simulation
low-level real world simulation
uh for, you know, aiding scientific
uh for, you know, aiding scientific
discovery and for advancing science and
discovery and for advancing science and
how we think about doing that.
Okay, so this looks way better. This
Okay, so this looks way better. This
looks like way more reasonable,
looks like way more reasonable,
right? Army's doing things.
right? Army's doing things.
Why are you guys going over there? That
Why are you guys going over there? That
doesn't make any sense to me.
doesn't make any sense to me.
Oh, it's cuz these ones are not
Oh, it's cuz these ones are not
controlled by our scripted AI.
controlled by our scripted AI.
That's fine then.
That's fine then.
That's actually a good indicator maybe.
That's actually a good indicator maybe.
Yeah, because like this army is hunting
Yeah, because like this army is hunting
that army and it's kind of doing an okay
that army and it's kind of doing an okay
job of it.
Cool.
Cool.
So, we can actually train versus this
So, we can actually train versus this
now
and maybe get like a actual real result.
I was baffled about what's tried.
I was baffled about what's tried.
I don't think we have though.
I don't think we have though.
When I look around, I see like so many
When I look around, I see like so many
things that have not been done, man.
things that have not been done, man.
But perhaps it's because I'm coming in
But perhaps it's because I'm coming in
from an outside perspective, right? Like
from an outside perspective, right? Like
the things I would think of are very
the things I would think of are very
very they're going to be very very
very they're going to be very very
different from the things that you'd
different from the things that you'd
think of based on being trained in the
think of based on being trained in the
field. And half of them aren't going to
field. And half of them aren't going to
make any sense, but who knows? Maybe
make any sense, but who knows? Maybe
some end up being novel.
some end up being novel.
I got a pretty good track record of
I got a pretty good track record of
doing that within reinforcement learning
doing that within reinforcement learning
as well to be fair.
Okay. Yeah. So fixing those dynamics
Okay. Yeah. So fixing those dynamics
immediately fixed a whole bunch of the
immediately fixed a whole bunch of the
problems we had
about score
hardly find the sol problem.
Outlook.
I don't know. We'll see.
I don't know. We'll see.
That tends to be the thing that I'm
That tends to be the thing that I'm
usually pretty good at,
usually pretty good at,
to be fair, is like coming up with weird
to be fair, is like coming up with weird
that nobody's thought of.
I'm not beating anyone in the I'm not
I'm not beating anyone in the I'm not
out like I'm not solving equations
out like I'm not solving equations
better than the next guy. I'll tell you
better than the next guy. I'll tell you
that
a lot of the stuff I've done in RL was
a lot of the stuff I've done in RL was
just like a dramatic perspective shift
just like a dramatic perspective shift
on how the field was done before.
Where exponentials
of error?
kind of thinking needed for progress. I
kind of thinking needed for progress. I
don't know. It's been somewhat It's been
don't know. It's been somewhat It's been
pretty effective at least in the domains
pretty effective at least in the domains
where I've worked.
Like I kind of think of it this way,
Like I kind of think of it this way,
right? Like when I'm at MIT and there
right? Like when I'm at MIT and there
are like a ton of people who are really
are like a ton of people who are really
good at the math, right? And there are
good at the math, right? And there are
like hundreds of RL papers on the math
like hundreds of RL papers on the math
and we're kind of stuck. Well, I'm sure
and we're kind of stuck. Well, I'm sure
as hell not making any progress just by
as hell not making any progress just by
thinking about the math more, right?
thinking about the math more, right?
Like the core algorithm more. That's how
Like the core algorithm more. That's how
I came up to the approach that I came
I came up to the approach that I came
with Puffer, right? I was like looking
with Puffer, right? I was like looking
at the type of stuff that fundamentally
at the type of stuff that fundamentally
people were not looking at.
1 megawatt 1 matt laser with a 1 millm
1 megawatt 1 matt laser with a 1 millm
squared beam
volts per meter for high intensity laser
changes with density.
Uh yeah, I would just have to look at
Uh yeah, I would just have to look at
the
the
I would need to go look at the the
I would need to go look at the the
freaking uh I'd need to go look at like
freaking uh I'd need to go look at like
the reference equation for that.
the reference equation for that.
The grow with like square or something.
The grow with like square or something.
I don't know.
For what it's worth, I am actually at
For what it's worth, I am actually at
least now trying to learn enough of the
least now trying to learn enough of the
math quantum. I kind of have to
Accelerate
more particles more compact with high
more particles more compact with high
intensity light source.
I I think the only thing I need for my
I I think the only thing I need for my
specific experiment is I need to filter
specific experiment is I need to filter
it down to a reasonable number of
it down to a reasonable number of
particles,
particles,
which I think I think that's just a
which I think I think that's just a
filter. There
OD filters we say every second there's
OD filters we say every second there's
high probability
high probability
I don't need second level re I literally
I don't need second level re I literally
all I need to know is like that there is
all I need to know is like that there is
still some interference
still some interference
um and it's not like because I have too
um and it's not like because I have too
many go like too many going through
many go like too many going through
simultaneously
simultaneously
like I can have like ideally I would
like I can have like ideally I would
like to have on the order of a thousand
like to have on the order of a thousand
photons going through per second and be
photons going through per second and be
able to tune it up to a million for
able to tune it up to a million for
instance
which I think I should be able to do
which I think I should be able to do
with uh setup I have or the setup I'm
with uh setup I have or the setup I'm
thinking of getting
What are our current rewards?
What are our current rewards?
Negative one for crashing
0.25. 25. We're hitting uh an enemy
curse a bunch. Yeah,
we're going to have to at least crack
we're going to have to at least crack
one code of the universe with all the
one code of the universe with all the
research I'm doing, right?
research I'm doing, right?
Something
Something
kind of made RL work. Pretty cool.
We in a position to make it happen.
A lot of this it just takes a lot of
A lot of this it just takes a lot of
work. A lot of this stuff does. Can do
work. A lot of this stuff does. Can do
it though.
Why wouldn't the learning here be
Why wouldn't the learning here be
stable, right?
With the score specifically,
this could literally be hyper prim sweep
this could literally be hyper prim sweep
though at this point.
though at this point.
We should kind of just run one like go
We should kind of just run one like go
set up a quick hyper pram sweep.
Oh yeah, hang on.
Oh yeah, hang on.
That's kind of doing something.
That's kind of doing something.
It's just unstable. I think
It's just unstable. I think
it starts learning and you get these
it starts learning and you get these
crashes.
crashes.
Let's figure this out how we're going to
Let's figure this out how we're going to
set this up.
Even need to sweep this stupid thing, do
Even need to sweep this stupid thing, do
we?
Yeah, let's just let's set up a sweep
Yeah, let's just let's set up a sweep
and then we can go do robotics in the
and then we can go do robotics in the
meantime. It'll be a smart thing to do.
Go grab the 5090 box.
I don't know why I just tried to SSH to
I don't know why I just tried to SSH to
my website.
Oh, cool. Stone says he'll drop by after
Oh, cool. Stone says he'll drop by after
uh after brunch. So, we'll actually have
uh after brunch. So, we'll actually have
a robotics pro to uh help us out with
a robotics pro to uh help us out with
what we're doing.
Okay, so they're battle trains pretty
Okay, so they're battle trains pretty
Back.
Cool. So this should what this should do
Cool. So this should what this should do
is in the background this will run a
is in the background this will run a
bunch of experiments and it'll basically
bunch of experiments and it'll basically
just tell us whether there are better
just tell us whether there are better
hyperparameters we can use to get
hyperparameters we can use to get
something to learn and if they're not
something to learn and if they're not
then there's still something wrong with
then there's still something wrong with
the end. If it does then yay we have
the end. If it does then yay we have
cool uh cool results.
What?
Okay.
Okay.
Make sure that this is actually running.
See, then um if this actually is good,
See, then um if this actually is good,
then we'll start on the robotics with be
then we'll start on the robotics with be
able to do uh let's actually just start
able to do uh let's actually just start
pulling the the hyper prams from this
pulling the the hyper prams from this
sweep.
Oh.
So, here are all the experiments we ran.
Here are all the good experiments that
Here are all the good experiments that
we ran.
And here are all the grade experiments
And here are all the grade experiments
that we ran.
So what we'll do is we'll just take
So what we'll do is we'll just take
this.
We'll pick whichever of these did uh the
We'll pick whichever of these did uh the
fastest.
fastest.
Looks to be I like the look of this um
Looks to be I like the look of this um
purple curve right here.
Grab this purple curve.
Yeah. Yeah. Yeah. Yeah.
back.
But really, this is like only a partial
But really, this is like only a partial
sweep. I don't know if we did um max
sweep. I don't know if we did um max
not
do like this. Yeah.
64 BPT horizon from the sweep. Okay.
64 BPT horizon from the sweep. Okay.
Very very high clip co.
Apparently I had lambda wrong.
and gamma of 088
and gamma of 088
with our tuning.
with our tuning.
Actually, I'd like to figure out for
Actually, I'd like to figure out for
stone real quick the uh the spread of
stone real quick the uh the spread of
gamas.
gamas.
Do that super high learning rate.
prior replay co-ops.
And uh this is is this 15 mil steps?
And uh this is is this 15 mil steps?
15 mil steps.
15 mil steps.
Kind of weird because it doesn't need 15
Kind of weird because it doesn't need 15
mil steps, right?
mil steps, right?
Come back to that one.
Come back to that one.
Then we have our coats here.
Then we have our coats here.
Our mostly sane kind of low value
Our mostly sane kind of low value
function clip. Really care about these
function clip. Really care about these
trace clips.
trace clips.
Uh update epox one. So I don't think I
Uh update epox one. So I don't think I
swept that.
swept that.
and total time steps.
It's kind of good by uh before that, but
It's kind of good by uh before that, but
we'll do 15
we'll do 15
15 mil
to match
We'll see.
We'll see.
Let's just run this.
And in the meantime,
And in the meantime,
just do a little analysis.
I should have added a score variable so
I should have added a score variable so
I don't have to read my uh my charts,
I don't have to read my uh my charts,
but
but
okay.
Did you see the post with the RF filter
Did you see the post with the RF filter
made by AI that looked like a QR code?
made by AI that looked like a QR code?
That was hilarious.
I didn't see that.
Could be good for micro strip
Could be good for micro strip
mic. What? What do you mean micro strip
mic. What? What do you mean micro strip
problems?
table runs from 0.8 gamma to 0.9 gamma.
table runs from 0.8 gamma to 0.9 gamma.
What this says
a lot of RF is on a PCB. Microchip is
a lot of RF is on a PCB. Microchip is
essentially having some conductive
essentially having some conductive
material on the bottom and top and a
material on the bottom and top and a
substrate between
substrate between
geometries of the structure. Oh, okay.
geometries of the structure. Oh, okay.
Yeah. So, this is like the type of stuff
Yeah. So, this is like the type of stuff
where I'd need to learn more about the
where I'd need to learn more about the
actual problem and like what it would
actual problem and like what it would
take to simulate stuff, right? And this
take to simulate stuff, right? And this
is actually one of the things I'm trying
is actually one of the things I'm trying
to do with quantum is to like go as low
to do with quantum is to like go as low
level as possible and then build back up
level as possible and then build back up
because like if you have to simulate
because like if you have to simulate
stuff on the level of what is described
stuff on the level of what is described
by quantum mechanics, you're screwed,
by quantum mechanics, you're screwed,
right? Like it's just the most
right? Like it's just the most
ridiculously expensive sim ever. And
ridiculously expensive sim ever. And
then if you go up and you have to
then if you go up and you have to
simulate stuff on an atomic level, okay,
simulate stuff on an atomic level, okay,
that's very slow. Like get away with
that's very slow. Like get away with
just simulating molecules and like vague
just simulating molecules and like vague
estimates of forces. They can go up with
estimates of forces. They can go up with
simulating just like material behaviors
simulating just like material behaviors
and it goes up from there.
and it goes up from there.
Me find that post.
Huh.
Yeah, that's a really really dumb
Yeah, that's a really really dumb
application of generative AI. RL would
application of generative AI. RL would
crush that
crush that
if you had a fast sim.
you basically it comes down to how fast
you basically it comes down to how fast
you can make a good enough like a good
you can make a good enough like a good
enough sim of the RF board. Man,
as you know, I talk about the amount of
as you know, I talk about the amount of
data we train on all the
Yeah, stone things better.
How's comment? Yeah, I don't know what
How's comment? Yeah, I don't know what
that is.
I do suspect that a lot of these Sims
I do suspect that a lot of these Sims
are just slow.
Ah, here we are. Our perfect
Ah, here we are. Our perfect
are perfect solve.
That's the battle sim.
Nice.
Nice.
Uh, and this thing ran
Uh, and this thing ran
less than 5 minutes.
So maybe we go find a harder tasks.
Someone told me some of them.
Someone told me some of them.
See what he sent me originally.
I got to scroll way up. I apparently I
I got to scroll way up. I apparently I
bothered him a whole bunch about a lot
bothered him a whole bunch about a lot
of things.
of things.
Going to have some nice results.
Peg insertion is unsolved.
Peg insertion side V1
push T.
Okay.
Egg insertion
Egg insertion
side one.
See what this does.
Trains able
enough rate, I guess.
So, let's see what they
So, let's see what they
their docks.
This is peg insert insertion.
Oh, we can do that.
Oh, we can do that.
Yeah, we can freaking do that.
A peg.
A peg.
Oh, do they not have it? No, they do.
Oh, do they not have it? No, they do.
It's right here.
Okay. So, it's not that bad in the sense
Okay. So, it's not that bad in the sense
that it's supposed to start learning
that it's supposed to start learning
uh after
some number of mills.
Our returns are not going to match at
Our returns are not going to match at
all is the annoying bit. But
the turn goes up immediately and then it
the turn goes up immediately and then it
takes a while.
takes a while.
Okay.
Word goes up.
Word goes up.
annoying
how long this type of stuff takes.
how long this type of stuff takes.
Um, you know what?
This is GPU bound, right?
Why don't we like 6x this speed?
Why don't we like 6x this speed?
Get this running DD. Uh, get this
Get this running DD. Uh, get this
running DDP.
running DDP.
They probably don't even have the
They probably don't even have the
ability to do that.
We'll probably We'll just do that.
We'll probably We'll just do that.
Um
Huffarell is programmatic interface. Uh
Huffarell is programmatic interface. Uh
yeah, you can just import stuff from
yeah, you can just import stuff from
there if you want to use it as an API.
Time to fix broken power supply. Very
Time to fix broken power supply. Very
fun.
We are doing more physics stuff. So do
We are doing more physics stuff. So do
drop by from time to time.
use command line interface or API. So
use command line interface or API. So
because I'm developing the project, I
because I'm developing the project, I
have a local install of it from source
have a local install of it from source
and I do a mix of editing command line
and I do a mix of editing command line
args for experiments and editing code
args for experiments and editing code
directly.
That's mostly because I'm the developer
That's mostly because I'm the developer
of it, though.
Yep, you can do that.
There's an example as well like in the
There's an example as well like in the
docs there all these examples. One of
docs there all these examples. One of
them shows you like basic usage of the
them shows you like basic usage of the
programmatic interface
config back end.
Yeah. So if I'll show you if you go here
examples
examples
puffer importable.
There you go.
Let me know if you run into any issues
Let me know if you run into any issues
with that.
with that.
Not we will
impressed with puffer liib. Thank you.
impressed with puffer liib. Thank you.
Very easy to learn. That's the goal.
Very easy to learn. That's the goal.
It's very lightweight, so now they're
It's very lightweight, so now they're
not going to be like options for
not going to be like options for
literally everything you want to do.
literally everything you want to do.
Sometimes you'll have to edit code, but
Sometimes you'll have to edit code, but
it's meant to be very lightweight.
it's meant to be very lightweight.
You know, RLI is a nightmare.
Dang heavy.
domain to upload tutorial.
Always just make GitHub pages.
Always just make GitHub pages.
RL mind.
RL mind.
That's funny. You were able to get that.
I got lucky that I got a puffer. Nobody
I got lucky that I got a puffer. Nobody
had it
like my puffer domain.
Going like puffer. The puffer is so
Going like puffer. The puffer is so
friendly.
Look. Very friendly.
Very friendly fish.
They're very curious, too. If you've
They're very curious, too. If you've
ever been like snorkeling, they will uh
ever been like snorkeling, they will uh
they'll just come up to you and be like,
they'll just come up to you and be like,
"Hey, yo, what's up?
cuz that works lovely.
Let's uh add this
There we are.
Now we also have to
How do you convert the those render for
How do you convert the those render for
website.
website.
Um, so in our C environments,
Um, so in our C environments,
yes. Well, it doesn't natively run
yes. Well, it doesn't natively run
Python. No, but we have environments
Python. No, but we have environments
that are in C, right? We uh we have a
that are in C, right? We uh we have a
build ocean script. It scripts build
build ocean script. It scripts build
ocean or whatever. And there's a web GPU
ocean or whatever. And there's a web GPU
option. If you just build for web with
option. If you just build for web with
mcript inton,
mcript inton,
copy that directly into a website.
I built it.
It's one of several environments. That's
It's one of several environments. That's
like maybe a few days worth of work,
like maybe a few days worth of work,
something like that.
like of the environments that we have on
like of the environments that we have on
the website.
the website.
Um, I built neural MMO 3, Moa, Snake,
Um, I built neural MMO 3, Moa, Snake,
Convert,
Convert,
uh, the sample environments down here.
uh, the sample environments down here.
Yeah, I've built like a few of them,
Yeah, I've built like a few of them,
right?
right?
By far the most complex of any of them
By far the most complex of any of them
uh to build was neural MMO.
This was something like truly
This was something like truly
complicated
by a mile.
How do you manipulate 3DN? What do you
How do you manipulate 3DN? What do you
mean?
How do I draw it? We use Ray Lib for
How do I draw it? We use Ray Lib for
drawing about it. It's like a very
drawing about it. It's like a very
lightweight like just header library
and see.
Yep.
Yep.
Very nice. I like that library a lot.
Okay, so we have this going here.
Okay, so we have this going here.
We're going to start on
We're going to start on
distributed stuff in a second.
Is that faster than JavaScript? Yes.
And you would also literally have to
And you would also literally have to
rewrite all of the code in JavaScript,
which I know an RL team that has done
which I know an RL team that has done
that and it's horrible.
that and it's horrible.
Not fun JavaScript. Be right back.
Uh-huh. This is now This is doing
Uh-huh. This is now This is doing
something.
something.
This is still not doing anything.
Possibly his hypers just aren't good.
Possibly his hypers just aren't good.
The return is very very low.
That's interesting.
Oh man, Kyle's got this massive thread.
horrifying. This is I have no idea what
horrifying. This is I have no idea what
the heck what I don't know what's going
the heck what I don't know what's going
on in robotics land, but uh yeah,
on in robotics land, but uh yeah,
sketchy.
Okay. So, this did not replicate the
Okay. So, this did not replicate the
result.
Something must be different here. Yeah.
Something must be different here. Yeah.
Oh, it's probably the config isn't
Oh, it's probably the config isn't
pulled, right?
Yeah. I'm dumb. Okay. Try that again.
Yeah. I'm dumb. Okay. Try that again.
Config this time.
will this fly in the meantime.
man scale render is not written in C.
man scale render is not written in C.
I don't think so. We do not have that on
I don't think so. We do not have that on
the website.
Oh, I see what I did.
How do you publish that then? We don't
How do you publish that then? We don't
have Manny skill on the website.
Like I on like almost nobody has live
Like I on like almost nobody has live
demos of RL on the website. That's not
demos of RL on the website. That's not
standard. That's pretty much just us and
standard. That's pretty much just us and
like maybe a couple other people.
So, in the meantime,
So, in the meantime,
this ain't working.
That works.
Does Puffer CLI work on globally? What
Does Puffer CLI work on globally? What
do you mean on globally?
Uh it should work everywhere provided
Uh it should work everywhere provided
that um
uh I bu I think that the caveat is like
uh I bu I think that the caveat is like
if you're loading custom configs need to
if you're loading custom configs need to
run it from the directory of those
run it from the directory of those
configs because there isn't a variable
configs because there isn't a variable
that tells you where custom configs go.
Okay, this works. Lovely.
Okay, this works. Lovely.
Now, what we get to do is something very
Now, what we get to do is something very
fun. Get to see how fast it goes.
fun. Get to see how fast it goes.
Um,
how to pass that device.
The args of train is a dictionary.
The args of train is a dictionary.
You look at it, you'll see that it has
You look at it, you'll see that it has
all the attributes from the help menu.
all the attributes from the help menu.
It's not like a special fancy class or
It's not like a special fancy class or
anything. You can just add it to the
anything. You can just add it to the
dictionary.
You can use our CLI parser if you want.
You can use our CLI parser if you want.
Our CLI parser is also in PRL. Um or you
Our CLI parser is also in PRL. Um or you
can just add it to the dictionary
can just add it to the dictionary
however you'd like.
We'll see if this gets us distributed
We'll see if this gets us distributed
any skill.
Hopefully it does.
Well, I think it's up to us to get Manny
Well, I think it's up to us to get Manny
skill to work on um multiGPU.
If I use device equal MPS, what happens?
If I use device equal MPS, what happens?
No idea.
No idea.
What's MPS? Mac stuff.
Try it. What happens?
5 minutes later.
5 minutes later.
No, it should be fine.
works. There you go. I'm not doing
works. There you go. I'm not doing
anything that should make it not work,
anything that should make it not work,
though,
though,
you know.
Doubled PF. There you go.
Fortunately, double of a small number is
Fortunately, double of a small number is
still a small number, but it's better
still a small number, but it's better
than nothing.
than nothing.
Second fly for me to kill. I can't.
We're officially fly free in this
We're officially fly free in this
building for the time being.
set up when they advertise how fast
set up when they advertise how fast
their chips are
their chips are
and then give you one less than onetenth
and then give you one less than onetenth
of one GPU perf
update doc Hey,
silicon.
Uh, I guess I could do that. Yeah,
it's still going to be like the things
it's still going to be like the things
are all still going to be slow. Is that
are all still going to be slow. Is that
Is that actually using the full
Is that actually using the full
Oh, that I could do. Is is it actually
Oh, that I could do. Is is it actually
um
um
is that using the entire chip? Like the
is that using the entire chip? Like the
entire chip still only gets you 260k.
Only six of them are working.
Well, you can figure out then why the
Well, you can figure out then why the
hell that doesn't work. But
hell that doesn't work. But
total
um
well, apparently they don't work like
well, apparently they don't work like
CUDA corores then because
CUDA corores then because
uh the back end should call should use
uh the back end should call should use
all of them basically.
annoying.
I'm increasing 10%. I don't know
your memory, your system memory.
VRAM is GP is GPU memory.
0%.
I I don't know how that works with MPS.
I I don't know how that works with MPS.
Like you don't have It's probably the
Like you don't have It's probably the
monitoring tool is expecting CUDA and
monitoring tool is expecting CUDA and
like it's not going to work for MPS to
like it's not going to work for MPS to
tell you, but like it Yeah, it's going
tell you, but like it Yeah, it's going
to be like that runs pvml or whatever.
do with This
is what
make. Well, no, because that'll put your
make. Well, no, because that'll put your
device on
device on
that'll put your device on CPU
that'll put your device on CPU
if uh you're not on a Mac.
think we could add max support natively.
Uh I
Uh I
I'd have to think about a good way to do
I'd have to think about a good way to do
it with the config,
it with the config,
but yeah, possibly could do
but yeah, possibly could do
it. You have to be a little careful
it. You have to be a little careful
because if you hardcode devices like
because if you hardcode devices like
that, there are other things you can
that, there are other things you can
Take
The stone just confirmed.
have a name machine.
Try this.
30k.
I'll show you the crazy part about that
I'll show you the crazy part about that
in just a second.
Okay, so this apparently runs. Cool.
Okay, so this apparently runs. Cool.
Okay, watch this.
Uh, done. This is not going to work, I
Uh, done. This is not going to work, I
guess. Okay. Puffer train. Puffer.
250K on CPU.
250K on CPU.
That hardware just sucks.
It is unfortunately that simple.
I used to use Macs growing up as well.
I used to use Macs growing up as well.
like I used Max for like six years or
like I used Max for like six years or
whatever.
whatever.
Um, and it's just like
Um, and it's just like
it boggles my mind that people use them
it boggles my mind that people use them
as much as they do in tech for like
as much as they do in tech for like
anything.
Yeah. As was I. And it's just like,
Yeah. As was I. And it's just like,
yeah, these things are awful.
They're just I I don't understand like
They're just I I don't understand like
why people use them. They're just they
why people use them. They're just they
suck for any actual computing. And then
suck for any actual computing. And then
like okay, you can use them to SSH to
like okay, you can use them to SSH to
your other hardware, but then you just
your other hardware, but then you just
have like an overpriced like thing that
have like an overpriced like thing that
doesn't even have the same development
doesn't even have the same development
environment as you're going to use for
environment as you're going to use for
your actual jobs. So now you have to
your actual jobs. So now you have to
debug your stupid Mac errors in addition
debug your stupid Mac errors in addition
to your stupid normal errors. It's just
to your stupid normal errors. It's just
like terrible.
I can't even tell you the amount of
I can't even tell you the amount of
errors where it's like but like it like
errors where it's like but like it like
doesn't work on my Mac and it's just
doesn't work on my Mac and it's just
like god damn
Yeah. So, this actually does go to um
Yeah. So, this actually does go to um
device
Last.
Go
idx. Practice.
this you and me on live.
this you and me on live.
Uh let me see. I think that according to
Uh let me see. I think that according to
the live stream,
the live stream,
no there are five people watching
no there are five people watching
according to this plus maybe some on X.
according to this plus maybe some on X.
It doesn't actually tell you X. Just
It doesn't actually tell you X. Just
tells you uh YouTube and Twitch.
Not everyone chats. People just leave
Not everyone chats. People just leave
stream on in the background while
stream on in the background while
they're doing work or other stuff. often
they're doing work or other stuff. often
times.
Yeah, shoot.
How much does compress increase
the length of the observation space? It
the length of the observation space? It
depends what you do in the process. It
depends what you do in the process. It
the answer could be not at all. Like if
the answer could be not at all. Like if
I just add a bunch of extra zeros to the
I just add a bunch of extra zeros to the
observation space, it's not going to
observation space, it's not going to
change Anything?
time in memory.
time in memory.
Um,
Um,
that depends a little bit more.
that depends a little bit more.
So, typically it'll increase the
So, typically it'll increase the
bandwidth,
bandwidth,
the CPU to GPU transfer bandwidth, which
the CPU to GPU transfer bandwidth, which
can add a little bit of overhead.
can add a little bit of overhead.
It's not going to make the network very
It's not going to make the network very
much slower though. It just makes the
much slower though. It just makes the
encoding layer slower. That's it.
When you make the the observation size
When you make the the observation size
really big, you like the biggest thing
really big, you like the biggest thing
is the CPU GPU bandwidth transfer being
is the CPU GPU bandwidth transfer being
annoying.
annoying.
And actually, we have ways to mitigate
And actually, we have ways to mitigate
that. Um, I just haven't gotten around
that. Um, I just haven't gotten around
to doing that yet.
Something is screwy here.
Make tank n.
Make tank n.
Oh, those obs are tiny. Those are like
Oh, those obs are tiny. Those are like
um
um
121 bytes.
121 bytes.
11 by 11 with uh Uint 8.
11 by 11 with uh Uint 8.
The bigger M's have like maybe 2 to 4
The bigger M's have like maybe 2 to 4
kilobyte observations.
kilobyte observations.
Neural MMO 3 is 1700 bytes.
OBS are on the wrong device. Interesting
OBS are on the wrong device. Interesting
enough.
enough.
OBS be on the wrong device.
Big CSV as a data set from a continuous
Big CSV as a data set from a continuous
envis log.
envis log.
Well, you certainly aren't going to put
Well, you certainly aren't going to put
CSV in. You're going to put the contents
CSV in. You're going to put the contents
of CSV. I don't know how you have a CS.
of CSV. I don't know how you have a CS.
How do you have a big CSV
as an RLN beenput?
know what the end is.
and pass cuda n to thim back end.
and pass cuda n to thim back end.
Okay,
20 columns on it.
20 columns on it.
I I don't understand how you have 20 col
I I don't understand how you have 20 col
like
like
Your observation is what the agency is
Your observation is what the agency is
at one specific time step, right?
So if your column is data and then rows
So if your column is data and then rows
are the time, you know, you get like one
are the time, you know, you get like one
entry, then it's probably only one row
entry, then it's probably only one row
of the table.
Well, then if it's one row, it's 20
Well, then if it's one row, it's 20
floats, which is nothing. So, you're
floats, which is nothing. So, you're
fine,
fine,
right?
fixed length each time full row. Yeah,
fixed length each time full row. Yeah,
something like that
something like that
should Okay.
need to do anything. If I want to show
need to do anything. If I want to show
agent previously observed data, just use
agent previously observed data, just use
the LSTM.
You're trying to do non-standard stuff
You're trying to do non-standard stuff
without knowing like without even like
without knowing like without even like
knowing the basic thing first, which
knowing the basic thing first, which
will almost certainly solve your
So the LSTM by definition, right, you
So the LSTM by definition, right, you
show it one observation, it makes a
show it one observation, it makes a
decision. It has memory. It can choose
decision. It has memory. It can choose
to remember stuff. It can learn to
to remember stuff. It can learn to
remember stuff rather from previous data
remember stuff rather from previous data
points.
Looks like uh I'm jumping on a call with
Looks like uh I'm jumping on a call with
Stone.
We get to do a robotics arc.
Whoops. Can you How do I plug that in
Whoops. Can you How do I plug that in
with pop? It's literally the default.
Don't have to do anything.
Don't have to do anything.
Like as long as your config has the
Like as long as your config has the
recurrent policy in it, it's it's
recurrent policy in it, it's it's
literally the default
any size.
any size.
Uh you can look at some of the configs
Uh you can look at some of the configs
for examples. We default to 128 hidden.
for examples. We default to 128 hidden.
There are other M's that we do like 256
There are other M's that we do like 256
or 512.
or 512.
Hey. Oh, hey Stone. Hey.
Hey. Oh, hey Stone. Hey.
Cool. Ready to solve robotics?
Cool. Ready to solve robotics?
Yes, I would love to get this multiGPU
Yes, I would love to get this multiGPU
thing working. I know it's been an issue
thing working. I know it's been an issue
a little bit recently. Let me Hang on.
a little bit recently. Let me Hang on.
Let me share my screen on this so that
Let me share my screen on this so that
you don't get
you don't get
delayed.
delayed.
You're getting I don't I don't want you
You're getting I don't I don't want you
to have the delay from this.
to have the delay from this.
Sure.
Sure.
Okay. On second monitor here. So,
actually, let's I can even do like this.
actually, let's I can even do like this.
So by wait by the way are you think
So by wait by the way are you think
course distributed? How are you doing
course distributed? How are you doing
the distributed training? Hang on. Let
the distributed training? Hang on. Let
me
me
if I just do it this way here. See if
if I just do it this way here. See if
this does if legible.
this does if legible.
Yeah I can I see you and yeah. So uh
Yeah I can I see you and yeah. So uh
this is what we're doing. We just use
this is what we're doing. We just use
run for this and we have this set up in
run for this and we have this set up in
puffer lib. So this thing here, this is
puffer lib. So this thing here, this is
the exact way that I ran uh one pabyte
the exact way that I ran uh one pabyte
of observations on neural MMO 3. Okay.
of observations on neural MMO 3. Okay.
So what are these commands doing? What's
So what are these commands doing? What's
nodes and what's n proc per node mean?
nodes and what's n proc per node mean?
So it's one machine and then six GPU. So
So it's one machine and then six GPU. So
each proc is a GPU. Okay. Yes. Not CPU.
each proc is a GPU. Okay. Yes. Not CPU.
Yes. And then does it not set
Yes. And then does it not set
environment variables? Uh no, but I just
environment variables? Uh no, but I just
did that and that doesn't help.
did that and that doesn't help.
Can I see the issue you got when you did
Can I see the issue you got when you did
that? Yes. So, uh, well, to be fair, it
that? Yes. So, uh, well, to be fair, it
is actually erroring in one of the
is actually erroring in one of the
things that I added, which is this last
things that I added, which is this last
reward thing. I'll run it again for you
reward thing. I'll run it again for you
fresh.
I have not gotten the side uh pegert
I have not gotten the side uh pegert
task to do anything yet, but we So, this
task to do anything yet, but we So, this
is me trying to set the device
is me trying to set the device
here.
here.
They're two sort of separate things,
They're two sort of separate things,
right? So, you can see that this is not
right? So, you can see that this is not
available. And then if I go into the you
available. And then if I go into the you
can see that it's not defined in here.
can see that it's not defined in here.
It's just CPU GPU. The reason that
It's just CPU GPU. The reason that
should that shouldn't be the bug
should that shouldn't be the bug
actually. Wait. Oh, it says s back end
actually. Wait. Oh, it says s back end
is CUDA zero. That shouldn't happen.
is CUDA zero. That shouldn't happen.
Well, I I set that. I set that. You
Well, I I set that. I set that. You
definitely should Are you exposing?
definitely should Are you exposing?
It says to set this. That's outdated.
It says to set this. That's outdated.
Outdated, man. I need to change that.
Outdated, man. I need to change that.
Okay. Okay. Um that might not work as as
Okay. Okay. Um that might not work as as
expected. Um you want to leave it as
expected. Um you want to leave it as
physx cuda. Okay. So I can do that but
physx cuda. Okay. So I can do that but
then then we get to the other error
then then we get to the other error
because that was the first thing I
because that was the first thing I
tried.
tried.
Okay. I'll show you the binding.
Okay. I'll show you the binding.
Um I can also try to see if I can just
Um I can also try to see if I can just
get CUDA end working. I remember we had
get CUDA end working. I remember we had
it working at one point but maybe
it working at one point but maybe
something broke like maybe something's
something broke like maybe something's
not using the right device. And also I
not using the right device. And also I
can literally give you SSH to this box
can literally give you SSH to this box
if you want.
if you want.
Sure. Let's go through this system first
Sure. Let's go through this system first
and then I'll try debug myself as well
and then I'll try debug myself as well
later. So then get rid of this device
later. So then get rid of this device
arc. Don't need that apparently.
arc. Don't need that apparently.
Yeah. The the whole idea is if you just
Yeah. The the whole idea is if you just
expose CUDA devices, it isolates the
expose CUDA devices, it isolates the
whole thing and CUDA zero looks like
whole thing and CUDA zero looks like
whatever GPU you're giving it access to.
whatever GPU you're giving it access to.
Okay.
Okay.
Let's see what's the exact bug here.
How many guys you have on Twitch
How many guys you have on Twitch
watching right now? I swear like on
watching right now? I swear like on
Twitter you have like 500 plus. Well,
Twitter you have like 500 plus. Well,
that's not concurrent. That's not
that's not concurrent. That's not
concurrent.
concurrent.
Oh, those numbers are not concurrent.
Oh, those numbers are not concurrent.
No. So, all the Twitch all the the
No. So, all the Twitch all the the
Twitter streams you see the X streams,
Twitter streams you see the X streams,
those all lie. So, when you see people
those all lie. So, when you see people
have like a bajillion viewers, that's
have like a bajillion viewers, that's
total. I usually have like I usually
total. I usually have like I usually
have like, you know, between five and 10
have like, you know, between five and 10
people watching.
people watching.
Okay, this is something that we can fix,
Okay, this is something that we can fix,
I believe. But you think that there are
I believe. But you think that there are
hundreds of people watching like RLDev?
hundreds of people watching like RLDev?
No. I I thought for a second like
No. I I thought for a second like
Twitter is just a better platform like
Twitter is just a better platform like
has so many people on it. No. Okay. I
has so many people on it. No. Okay. I
think so. What's the error here? The
think so. What's the error here? The
runtime error indic CPU or on the same
runtime error indic CPU or on the same
device as index tensor. Can you go back
device as index tensor. Can you go back
to that line? So this is the thing that
to that line? So this is the thing that
I added, but I added it the exact same
I added, but I added it the exact same
way that all your other stuff is added.
way that all your other stuff is added.
So unless it gets like uh the device
So unless it gets like uh the device
gets switched later here, let me show
gets switched later here, let me show
you this. Can I go to that? Can we get
you this. Can I go to that? Can we get
go to the line of error? Yes, I will. I
go to the line of error? Yes, I will. I
just want to show you I added a print
just want to show you I added a print
for this. We'll go we'll show you that
for this. We'll go we'll show you that
line.
line.
Okay. So
Okay. So
you can see this is how I define this. I
you can see this is how I define this. I
use your device.
use your device.
This isn't the init. This is just the
This isn't the init. This is just the
init. Ah okay. And then
and then this is right here. Uh
and then this is right here. Uh
so what is the print saying?
so what is the print saying?
Okay,
Okay,
this is saying that the observation is
this is saying that the observation is
on the wrong device. Show you is it
on the wrong device. Show you is it
saying CUDA zero each time? Saying that
saying CUDA zero each time? Saying that
the observation is on CUDA zero. So the
the observation is on CUDA zero. So the
other devices match what we would
other devices match what we would
expect. I did export the like I did add
expect. I did export the like I did add
a thing to export the device. Wait, I
a thing to export the device. Wait, I
thought CUDA zero is what it should say.
thought CUDA zero is what it should say.
If you're doing exposed CUD to visible
If you're doing exposed CUD to visible
devices like three, it will think it's
devices like three, it will think it's
CUD to zero. Isn't that not how that
CUD to zero. Isn't that not how that
works? Shouldn't be.
works? Shouldn't be.
That's what I remember. Maybe I'm
That's what I remember. Maybe I'm
remember last time I tried a multiGP
remember last time I tried a multiGP
setup.
setup.
Okay. What does it say? The other ones
Okay. What does it say? The other ones
have the correct device.
have the correct device.
The hell is where my prints go? Oh,
The hell is where my prints go? Oh,
yeah. Here. Look. M is on CUDA 4. Last
yeah. Here. Look. M is on CUDA 4. Last
reward is on CUDA 4. is here.
reward is on CUDA 4. is here.
Uh can I see the print line command
Uh can I see the print line command
again? Let me see where it is. What is
again? Let me see where it is. What is
it printing? So that is actually on the
it printing? So that is actually on the
right device. It's just OBS device is
right device. It's just OBS device is
wrong. Yeah. So it seems device wrong.
wrong. Yeah. So it seems device wrong.
Yeah, which I don't mess with your OBS,
Yeah, which I don't mess with your OBS,
right? It seems like it's running the
right? It seems like it's running the
SIM on the wrong device.
That could be possible. Uh
can we check the memory allocation? like
can we check the memory allocation? like
stop it before it goes to get ops and
stop it before it goes to get ops and
just to see where the me which GPU is
just to see where the me which GPU is
being used. We should expect every
being used. We should expect every
single one to have some GPU memory
single one to have some GPU memory
allocated for the simulation. Uh okay, I
allocated for the simulation. Uh okay, I
can do that but not in the way that you
can do that but not in the way that you
expect cuz I can't put break point. So
expect cuz I can't put break point. So
hang on. Oh, I can't put Yeah. In the
hang on. Oh, I can't put Yeah. In the
meantime, I'm going to check the get ops
meantime, I'm going to check the get ops
function to see if we're doing some
function to see if we're doing some
funky stupid thing like we're doing two
funky stupid thing like we're doing two
CUDA zero or something. Uh I hope we're
CUDA zero or something. Uh I hope we're
not doing that though.
not doing that though.
Let's see. Let me try to get off
Let's see. Let me try to get off
function. Are you doing state based?
function. Are you doing state based?
Yes. Okay. I will see the function for
Yes. Okay. I will see the function for
that. Get off state dick. Okay. So, this
that. Get off state dick. Okay. So, this
is now the video.
is now the video.
Yes.
Okay. That 300 megabytes is probably
Okay. That 300 megabytes is probably
just imported pietorch.
just imported pietorch.
Oh, I think they're all being it on the
Oh, I think they're all being it on the
first GPU. How many parallel
first GPU. How many parallel
environments is this? 4096 each per GPU.
environments is this? 4096 each per GPU.
Yep.
Yep.
Oh yeah, that's definitely using way
Oh yeah, that's definitely using way
more memory than it should be. So they
more memory than it should be. So they
must be being initialized on the first
must be being initialized on the first
one. Yep. Okay. Yeah. Um 4096 on a state
one. Yep. Okay. Yeah. Um 4096 on a state
based P cube should not be using even
based P cube should not be using even
more than like 5 gigs I think. So
more than like 5 gigs I think. So
let's see. Let me see where we're
let's see. Let me see where we're
initializing the simulation engine. That
initializing the simulation engine. That
could be what it is.
could be what it is.
Perhaps I'm not doing that right.
Perhaps I'm not doing that right.
But we train p cube at I think it's a
But we train p cube at I think it's a
bit above 60k steps per second on the
bit above 60k steps per second on the
current tuned config. It does take too
current tuned config. It does take too
many samples at the moment. Uh one more
many samples at the moment. Uh one more
sanity to check. Is it possible for you
sanity to check. Is it possible for you
to run it on one GPU but it's not GPU
to run it on one GPU but it's not GPU
zero and look at the memory usage. Uh I
zero and look at the memory usage. Uh I
have not tried that. Let's see. Uh I'm
have not tried that. Let's see. Uh I'm
curious like if this is a multiGPU setup
curious like if this is a multiGPU setup
problem or if it's like I'm not setting
problem or if it's like I'm not setting
ID or I don't know. Yeah.
ID or I don't know. Yeah.
Yeah. So, we should ideally see the
Yeah. So, we should ideally see the
second GPU being used obviously.
Okay, it's importing torch or stuff.
Okay, it's importing torch or stuff.
That's definitely the simulator being
That's definitely the simulator being
imported.
imported.
So, this works. Well, we'll see. This is
So, this works. Well, we'll see. This is
taking forever to start up.
taking forever to start up.
Is there any kind of warm cold machine
Is there any kind of warm cold machine
kind of thing going on? Maybe.
kind of thing going on? Maybe.
Okay, let's see if it does anything.
Okay, let's see if it does anything.
Can you see the prints? They're all
Can you see the prints? They're all
saying CUD to zero.
saying CUD to zero.
Okay, this is what I mean whenever I was
Okay, this is what I mean whenever I was
mentioning like if the CUDA devices is
mentioning like if the CUDA devices is
some other random number, okay, to the
some other random number, okay, to the
machine to the Python process itself, it
machine to the Python process itself, it
thinks it's CUDA zero. Okay, so in that
thinks it's CUDA zero. Okay, so in that
case then probably the export uh is not
case then probably the export uh is not
working the way that I expect it is and
working the way that I expect it is and
some of it it's like some of these are
some of it it's like some of these are
using the N variable and some of them
using the N variable and some of them
are using something that's been cached
are using something that's been cached
or whatever.
or whatever.
H because you like you realize like with
H because you like you realize like with
this when you run it with torch run
this when you run it with torch run
um it's going to start the processes for
um it's going to start the processes for
you. So you don't really have an option
you. So you don't really have an option
to start I don't think you have the
to start I don't think you have the
option to set that variable
option to set that variable
uh before the process launches. You can
uh before the process launches. You can
set it after you start the process.
set it after you start the process.
Huh. Uh that's not Wait. I I swear I saw
Huh. Uh that's not Wait. I I swear I saw
a line in the code in the error trace
a line in the code in the error trace
where it showed the export variable
where it showed the export variable
thing or like os.vironment
thing or like os.vironment
replvices. Yes, you did. So, was that
replvices. Yes, you did. So, was that
your code? Yes, I will show you.
your code? Yes, I will show you.
Uh if you if you set it after running
Uh if you if you set it after running
the Python script, I don't think that
the Python script, I don't think that
will work.
will work.
Well, I was attempting to patch it
Well, I was attempting to patch it
because I mean it definitely doesn't
because I mean it definitely doesn't
work without it either.
work without it either.
Uh,
Uh,
also wait, is Torch run a open source
also wait, is Torch run a open source
project? Can I find it? I'm curious what
project? Can I find it? I'm curious what
it looks like. Yeah.
it looks like. Yeah.
Uh, do you have the link to it? I can't
Uh, do you have the link to it? I can't
find it on Google.
Is it from PyTorch? Yeah. Oh, it's from
Is it from PyTorch? Yeah. Oh, it's from
PyTorch. Okay. It's distributed.
PyTorch. Okay. It's distributed.
It's the same as just Yeah. This same
It's the same as just Yeah. This same
thing.
thing.
Oh, okay.
Oh, okay.
Let me take a look at this thing.
Let me take a look at this thing.
So, they don't set visible devices
So, they don't set visible devices
apparently. I guess they set local rank.
apparently. I guess they set local rank.
They set local rank. No, I I see the
They set local rank. No, I I see the
visible devices thing. Well, this is
visible devices thing. Well, this is
what I set. Yeah, I just I just did this
what I set. Yeah, I just I just did this
to try to make Manny skill work.
to try to make Manny skill work.
And we also have this torch cuda set
And we also have this torch cuda set
device.
device.
I have never seen that one. Let me see.
I have never seen that one. Let me see.
Let me see what that does.
Let me see what that does.
That's supposed to set the default. So
That's supposed to set the default. So
like if I just make a tensor, it should
like if I just make a tensor, it should
make it on that device.
I see. So set a default to whatever.
I see. So set a default to whatever.
Huh.
Huh.
Okay. Let me just check the physics side
Okay. Let me just check the physics side
of things.
Yeah. Um I mean I would hope it's not
Yeah. Um I mean I would hope it's not
physics issue because Isaac Lab can do
physics issue because Isaac Lab can do
multiGPU stuff apparently. So, it's
multiGPU stuff apparently. So, it's
probably something on our side then.
probably something on our side then.
Well, I don't even know if it's on your
Well, I don't even know if it's on your
side as much as it's like there are many
side as much as it's like there are many
ways that you can set these devices and
ways that you can set these devices and
it depends on how you have it
it depends on how you have it
implemented, which ones work and which
implemented, which ones work and which
ones don't. Yeah, I'm guessing torch
ones don't. Yeah, I'm guessing torch
doesn't do the ones that we expected.
doesn't do the ones that we expected.
Um, even then it shouldn't be as hard to
Um, even then it shouldn't be as hard to
do.
do.
I'm hoping we can get this working and
I'm hoping we can get this working and
then I can like attempt to find some set
then I can like attempt to find some set
of parameters that will do uh the like
of parameters that will do uh the like
the peg insertion task or one of the
the peg insertion task or one of the
harder ones in puffer lip.
harder ones in puffer lip.
Yeah, that one takes like 30 minutes to
Yeah, that one takes like 30 minutes to
an hour on statebased training right now
an hour on statebased training right now
on 1490. If you can get it faster,
on 1490. If you can get it faster,
that'd be pretty cool. We don't have
that'd be pretty cool. We don't have
faster than you yet because like like
faster than you yet because like like
our just our defaults are not set up for
our just our defaults are not set up for
slow environments. Um, so I just have to
slow environments. Um, so I just have to
tune some stuff. But we do have it very
tune some stuff. But we do have it very
very stable uh with I think it's like
very stable uh with I think it's like
10. It's like 15 million steps, but it
10. It's like 15 million steps, but it
takes like a little bit, but it's per
takes like a little bit, but it's per
second.
second.
Okay. Uh, I'm going to try to create a
Okay. Uh, I'm going to try to create a
new branch for Manasco. Can you just Are
new branch for Manasco. Can you just Are
you Did you get clone it or did you pip
you Did you get clone it or did you pip
install it? I pip installed. I can clone
install it? I pip installed. I can clone
it. All I would have to do is copy the
it. All I would have to do is copy the
Sapion file over.
Sapion file over.
What sapion file? Well, I have the end
What sapion file? Well, I have the end
modified for the local reward stuff. The
modified for the local reward stuff. The
new stuff. I see. I'm just I'm just make
new stuff. I see. I'm just I'm just make
a new branch. Maybe you can add the
a new branch. Maybe you can add the
change to that and then Yeah, make make
change to that and then Yeah, make make
the branch and like I will I'll fork off
the branch and like I will I'll fork off
of it. Okay, great. Let me figure that.
We're going to get you. I've been
We're going to get you. I've been
promising uh I've been promising robotic
promising uh I've been promising robotic
stuff in Puffer for quite a while. So,
stuff in Puffer for quite a while. So,
now you can finally get it. I do
now you can finally get it. I do
eventually get around to it. It just
eventually get around to it. It just
takes a while. Yeah, you got to solve
takes a while. Yeah, you got to solve
all the other issues first, right? There
all the other issues first, right? There
is so much RL, man. I like gh the amount
is so much RL, man. I like gh the amount
of different things I've fixed
of different things I've fixed
build.
build.
Okay, let me send you the branch name
Okay, let me send you the branch name
for add to that branch. It's just a
for add to that branch. It's just a
sapion repo, right? Nope, that's not the
sapion repo, right? Nope, that's not the
repo. It's a man skill repo.
repo. It's a man skill repo.
Uh, I'm just going to set to your
Uh, I'm just going to set to your
development chat. Oh, sorry. I sent the
development chat. Oh, sorry. I sent the
change, but it's called puffer lib, the
change, but it's called puffer lib, the
branch name, the public one. Okay, let
branch name, the public one. Okay, let
me work.
me work.
Yeah. And then in the meantime, I'm
Yeah. And then in the meantime, I'm
going to see if I can edit the code to
going to see if I can edit the code to
let you set CUDA and see if that works.
let you set CUDA and see if that works.
Uh, I've never really truly tested that,
Uh, I've never really truly tested that,
but maybe it will.
Is this um reasonable to set up from
Is this um reasonable to set up from
source or is it potentially pain in the
source or is it potentially pain in the
ass? No, it's the same thing you do with
ass? No, it's the same thing you do with
pip installs. You're just get cloning
pip installs. You're just get cloning
it.
it.
Yeah, there's only a few extra files for
Yeah, there's only a few extra files for
like RL that's not included with the
like RL that's not included with the
package.
Yeah, you just do pip install- e dot and
Yeah, you just do pip install- e dot and
you're good.
And then you have like Vulcan whatever
And then you have like Vulcan whatever
set already, right? So Mhm.
set already, right? So Mhm.
good.
Yep. That should be good.
Uh, copy. Hang on.
You still use Vens. You don't use UV or
You still use Vens. You don't use UV or
micro. This is UV.
micro. This is UV.
Oh, they also call it V. Okay. And I
Oh, they also call it V. Okay. And I
only recently started using UV out after
only recently started using UV out after
great protest. I typically would use no
great protest. I typically would use no
virtual end and just Docker. Um,
virtual end and just Docker. Um,
but unfortunately there have been
but unfortunately there have been
changes to Python which kind of force
changes to Python which kind of force
you to use virtual ends even inside of
you to use virtual ends even inside of
Docker which Python's just a bad
Docker which Python's just a bad
language. All right. Nobody knows what
language. All right. Nobody knows what
they're building.
they're building.
Literally nobody knows what they're I'm
Literally nobody knows what they're I'm
very mad about this.
Uh, this removed Manny skill. So, I have
Uh, this removed Manny skill. So, I have
to copy this from my local, I guess. And
to copy this from my local, I guess. And
luckily, I still have this on my local.
Okay.
So I have a strange kind of backend name
So I have a strange kind of backend name
thing where physicuda physics GPU or
thing where physicuda physics GPU or
physics CPU. Yeah, that's need to add
physics CPU. Yeah, that's need to add
another option just to say specify CUDA
another option just to say specify CUDA
device. That's what it it says in the
device. That's what it it says in the
docs that you do but doesn't actually
docs that you do but doesn't actually
work. Yeah, I removed that feature a
work. Yeah, I removed that feature a
while back I think by accident without
while back I think by accident without
realizing. I don't I don't have
realizing. I don't I don't have
automated tests for multi GPU stuff. I
automated tests for multi GPU stuff. I
don't have automated tests for almost
don't have automated tests for almost
anything.
anything.
Yeah, I literally whenever I do big
Yeah, I literally whenever I do big
release, I run the test once. If it
release, I run the test once. If it
pass, it's fine. But I don't actually
pass, it's fine. But I don't actually
have a cheat. That is what I do as well.
have a cheat. That is what I do as well.
That is fine.
That is fine.
Yeah,
Yeah,
I guess I could just parse their sim
I guess I could just parse their sim
back in from physics CUDA to be like
back in from physics CUDA to be like
physics cuda colon check the reax and
physics cuda colon check the reax and
then if you pass in number, we'd only
then if you pass in number, we'd only
use that. I mean, we could also just
use that. I mean, we could also just
figure out like what is the difference
figure out like what is the difference
between sending CUDA or actually wait
between sending CUDA or actually wait
this doesn't make sense. If you pass in
this doesn't make sense. If you pass in
physics CUDA, we create a device called
physics CUDA, we create a device called
torch.de device and pass in a string
torch.de device and pass in a string
CUDA.
CUDA.
That should be looking for whatever the
That should be looking for whatever the
default device is.
default device is.
Unless it's not. Yeah, I don't know.
Unless it's not. Yeah, I don't know.
Wait,
Wait,
wait. Maybe this is a safe pin issue cuz
wait. Maybe this is a safe pin issue cuz
the torch device we're passing Oh, I
the torch device we're passing Oh, I
think it's a maybe sap is not tracking
think it's a maybe sap is not tracking
it correctly. Um cuz I noticed how the
it correctly. Um cuz I noticed how the
ward and everything else is on the right
ward and everything else is on the right
device, right? It's like 765, right?
device, right? It's like 765, right?
Yeah. Hang on. Let me get you this.
Yeah. Hang on. Let me get you this.
Yeah, we we keep track of two devices.
Yeah, we we keep track of two devices.
We have the device for a simulation and
We have the device for a simulation and
renderer and then we have a device for
renderer and then we have a device for
the APIs, tasks, and reward function.
the APIs, tasks, and reward function.
Whatever. Those are two different
Whatever. Those are two different
devices because they have to be managed
devices because they have to be managed
a little differently. That could be the
a little differently. That could be the
issue.
issue.
Uh,
Uh,
I guess you can print ID or
Okay. So, here I have the single um
Okay. So, here I have the single um
single GPU peg insertion task running.
single GPU peg insertion task running.
Okay.
Okay.
And this should be running with the
And this should be running with the
latest man like the from source manny.
latest man like the from source manny.
Okay.
Okay.
Um, on one GPU.
Um, on one GPU.
Okay. Um, I have a quick fix you can try
Okay. Um, I have a quick fix you can try
checking for the multiGP setup. Can you
checking for the multiGP setup. Can you
go to the backendpay file again
back end?
back end?
It's going to pass.
It's going to pass.
Uh so what we're going to do is let's
Uh so what we're going to do is let's
just use environment variable to or what
just use environment variable to or what
what's the function you use to get the
what's the function you use to get the
rank. Hang on let me where's is it in uh
rank. Hang on let me where's is it in uh
a man skill m utils systems back end.py
Okay. So, here it is.
Okay. So, here it is.
Yes. Go to the line under physics sim
Yes. Go to the line under physics sim
back end equals physics kudo. Go to that
back end equals physics kudo. Go to that
line.
line.
Uh like elimin back end equals physics
Uh like elimin back end equals physics
kudo.
kudo.
This Oh, no. The one with the if
This Oh, no. The one with the if
statement that sets a SIM device and and
statement that sets a SIM device and and
a torch device. Torch. Yeah. Okay. So it
a torch device. Torch. Yeah. Okay. So it
seems like core device is selecting the
seems like core device is selecting the
one that you thought you're selecting
one that you thought you're selecting
right saf device is not I don't know why
right saf device is not I don't know why
we can trick check can you check the
we can trick check can you check the
envir can you how do you get the local
envir can you how do you get the local
rank like the number one to eight
rank like the number one to eight
whatever can you get that number and
whatever can you get that number and
append it to the string cuda
append it to the string cuda
so device equals safe device instead of
so device equals safe device instead of
writing cuda we're going to write cuda
writing cuda we're going to write cuda
colon the number
colon the number
uh I see So,
I guess what we can I can do something
I guess what we can I can do something
as a quick hack. Um, because this is not
as a quick hack. Um, because this is not
going to be exported.
going to be exported.
Let's see if we get it to work like
Let's see if we get it to work like
this. Yeah, this is just like a quick
this. Yeah, this is just like a quick
check and if this works, I'll add a
check and if this works, I'll add a
feature to add the exact number that
feature to add the exact number that
people want. Okay, so we'll do is it
people want. Okay, so we'll do is it
sapient CUDA like this? Does this
sapient CUDA like this? Does this
render? No, not that line. Go above. Go
render? No, not that line. Go above. Go
above. Oh, yes. I don't line numbers.
above. Oh, yes. I don't line numbers.
How do I tell you which line? Sim device
How do I tell you which line? Sim device
equals saving device under e- lift sim
equals saving device under e- lift sim
back end equals physics cuda.
Right below that one. Okay, this thing.
Right below that one. Okay, this thing.
Yeah, that one. And then we're doing
Yeah, that one. And then we're doing
cuda colon whatever the local rank is.
cuda colon whatever the local rank is.
Let's see if that works and maybe print
Let's see if that works and maybe print
it and see how it works.
Okay. And then format the strength for
Okay. And then format the strength for
CUDA and saf device. Oh, I don't know if
CUDA and saf device. Oh, I don't know if
I did this on the right machine. Uh,
I did this on the right machine. Uh,
what what are you is this a file not the
what what are you is this a file not the
right one? Yeah, I accidentally I
right one? Yeah, I accidentally I
accidentally set all this stuff up on my
accidentally set all this stuff up on my
local. My bad. Oh, no worries. Uh, hang
local. My bad. Oh, no worries. Uh, hang
on. I because it's I have all these
on. I because it's I have all these
terms and like
terms and like
supposed to be here.
My bad.
Let's see. I'm trying to think, okay, if
Let's see. I'm trying to think, okay, if
I'm going to add a feature where people
I'm going to add a feature where people
can specify the exact CUDA device.
can specify the exact CUDA device.
Do I have to specify a number or do I
Do I have to specify a number or do I
let them pass a CUDA colon? CUDA colon
let them pass a CUDA colon? CUDA colon
is kind of stupid because other things
is kind of stupid because other things
we might have other GP backends. Yeah,
we might have other GP backends. Yeah,
we're probably going to Yeah. So, other
we're probably going to Yeah. So, other
backends would be uh like MPS or
Yeah, we might add MJX Warp in the
Yeah, we might add MJX Warp in the
future. They're still working on it.
future. They're still working on it.
Nvidia and Majoko's teams, but it's
Nvidia and Majoko's teams, but it's
supposedly going to be much better than
supposedly going to be much better than
Physics or the current MJX. Yeah, I saw
Physics or the current MJX. Yeah, I saw
have fun at uh Nvidia over the summer.
have fun at uh Nvidia over the summer.
Yes. Um playing around with simulators,
Yes. Um playing around with simulators,
I guess. Isaac and R.
I guess. Isaac and R.
What's the Sims?
Uh okay.
Our sapient file
that was
what the heck was Oh yeah, utils back
what the heck was Oh yeah, utils back
And yep.
The second e- lift.
The second e- lift.
Okay. In this function here. Not that
Okay. In this function here. Not that
one. No. Nope. That's for That's for
one. No. Nope. That's for That's for
something else. You got to go to the
something else. You got to go to the
fix. Oh, this is render. Yeah. Yeah.
fix. Oh, this is render. Yeah. Yeah.
Yeah. This is render. Rendering. We We
Yeah. This is render. Rendering. We We
might need to fix that, too. But let's
might need to fix that, too. But let's
fix this one first. X. This looks good.
fix this one first. X. This looks good.
Device.
Device.
Why don't I just set Couldn't I just set
Why don't I just set Couldn't I just set
this to Oh, it's because it's
this to Oh, it's because it's
sapient.device is separate from torch
sapient.device is separate from torch
device. I think we're not using the same
device. I think we're not using the same
API torch is using to detect what torch
API torch is using to detect what torch
run is setting. We are only using CUDA
run is setting. We are only using CUDA
visible devices which I think is
visible devices which I think is
actually the standard approach but for
actually the standard approach but for
whatever reason torch does not do it and
whatever reason torch does not do it and
they don't need care torch them. Okay,
they don't need care torch them. Okay,
let me I have to do
Anakin
Anakin
waited.
Me time. Let me see what the hell torch
Me time. Let me see what the hell torch
run is doing. Okay, so now we have this.
run is doing. Okay, so now we have this.
So
local rank. Okay. Because it doesn't
local rank. Okay. Because it doesn't
it's not going to get set if I don't if
it's not going to get set if I don't if
I don't run it with distributed. We'll
I don't run it with distributed. We'll
just do distributed. Yeah. Let's just
just do distributed. Yeah. Let's just
give it a shot. Can can we see the GPU
give it a shot. Can can we see the GPU
memory usage as well to see which one
memory usage as well to see which one
it's using?
it's using?
Great.
Great.
So,
So,
let's hope if this doesn't work, I'll
let's hope if this doesn't work, I'll
ask the Sapion lead to fix something.
ask the Sapion lead to fix something.
It should work. Oh, that's not a good
It should work. Oh, that's not a good
sign. It's going to 9,000 GB.
Uh, yeah, that kind of looks like it's
Uh, yeah, that kind of looks like it's
just initializing them all one after
just initializing them all one after
another.
another.
Yeah, same issue again. Uh, didn't we
Yeah, same issue again. Uh, didn't we
print the device or didn't work?
print the device or didn't work?
Maybe I did.
I guess we're also not sure if the local
I guess we're also not sure if the local
rank variable is correct either. Find
rank variable is correct either. Find
it. Uh utils back end. Yeah. Yeah.
Yeah. And then one more print to do. Um
Yeah. And then one more print to do. Um
after we find a send device, can you
after we find a send device, can you
print send device uh
print send device uh
CUDA id?
This is the one that s thinks it's using
This is the one that s thinks it's using
is it cuda like this? Yep, that's
is it cuda like this? Yep, that's
correct. That's the right property name.
correct. That's the right property name.
Okay, we will attempt to get something
Okay, we will attempt to get something
out of this.
Uh
Uh
why is syn device still zero?
So we're passing cuda colon a number
So we're passing cuda colon a number
right the right number right. So that
right the right number right. So that
seems strange. Um no we didn't change
seems strange. Um no we didn't change
it. We didn't change it. Cuda you had to
it. We didn't change it. Cuda you had to
do colon local rank. Yeah bad man. No
do colon local rank. Yeah bad man. No
worries.
All right, nice. Let's try it again.
Kind of just been doing a ton of RL and
Kind of just been doing a ton of RL and
driving myself nuts.
driving myself nuts.
You know, I I feel bad I've kind of
You know, I I feel bad I've kind of
moved away from RL recently. Like I'm
moved away from RL recently. Like I'm
just using default PPO. I'm not
just using default PPO. I'm not
modifying anymore. I'm just doing sim
modifying anymore. I'm just doing sim
stuff instead. You know what? You're not
stuff instead. You know what? You're not
going to be using default PO very soon
going to be using default PO very soon
because Puffer LE is gonna solve all
because Puffer LE is gonna solve all
your stuff. It's working. It's working
your stuff. It's working. It's working
now.
now.
Correct. Let's see if this does
Correct. Let's see if this does
anything. Yeah. So, if I if if I get
anything. Yeah. So, if I if if I get
this to work, I don't think you're going
this to work, I don't think you're going
to be using default PO.
Cool. I'm going to on that branch add
Cool. I'm going to on that branch add
the feature to specify the device
the feature to specify the device
directly. At least add it back. Hey, uh,
directly. At least add it back. Hey, uh,
have you seen uh, man skill run this
have you seen uh, man skill run this
fast?
fast?
No, it's state based, right? Uh,
No, it's state based, right? Uh,
it's still 300k
it's still 300k
for Q picking. I want to see the
for Q picking. I want to see the
rendering forms later, too. Oh, we have
rendering forms later, too. Oh, we have
to change the code renderer as well, but
to change the code renderer as well, but
yeah, we'll have to change some stuff.
yeah, we'll have to change some stuff.
Nice. Okay. Um, I'm going to add a
Nice. Okay. Um, I'm going to add a
official feature to make this work so
official feature to make this work so
you don't have to do the hack. So, I'm
you don't have to do the hack. So, I'm
gonna have to PR you once I figure out
gonna have to PR you once I figure out
the the reward stuff anyways cuz like it
the the reward stuff anyways cuz like it
um
um
you literally can't use any of the manny
you literally can't use any of the manny
skill rewards with a standard J.
skill rewards with a standard J.
Yes, we have a different one I guess
Yes, we have a different one I guess
that we've modified and it seems like
that we've modified and it seems like
other people I saw your comment with
other people I saw your comment with
Kyle. I guess it's the same situation
Kyle. I guess it's the same situation
with them. Yeah. So, it's I basically I
with them. Yeah. So, it's I basically I
like I kind of figure that if you're
like I kind of figure that if you're
doing something everyone's probably
doing something everyone's probably
doing it that way. Um Yep. like because
doing it that way. Um Yep. like because
it's generally you guys are doing the
it's generally you guys are doing the
most reasonable stuff I see in robotics.
most reasonable stuff I see in robotics.
So I kind of assume if everybody's just
So I kind of assume if everybody's just
doing these state based rewards then
doing these state based rewards then
everybody's probably made the same
everybody's probably made the same
chains to J which is like it's kind of
chains to J which is like it's kind of
two errors that cancel each other out.
two errors that cancel each other out.
Wait, what is a statebased reward? Is
Wait, what is a statebased reward? Is
this like we're not doing potential or
this like we're not doing potential or
we're just doing like the current value
we're just doing like the current value
of your state. Right. So, you're
of your state. Right. So, you're
basically you're giving it a reward
basically you're giving it a reward
based on how close you are to a target
based on how close you are to a target
when the way to do this that doesn't
when the way to do this that doesn't
require you to have J like one way or
require you to have J like one way or
the other fixed is to do deltas, right?
the other fixed is to do deltas, right?
Because then if you do deltas, it's
Because then if you do deltas, it's
unfarmmable.
unfarmmable.
Do you do deltas for all your
Do you do deltas for all your
environments now? Well, we mostly don't
environments now? Well, we mostly don't
have these types of continuous rewards
have these types of continuous rewards
in the first place for a lot of our
in the first place for a lot of our
stuff. Our stuff is way sparer.
stuff. Our stuff is way sparer.
Ah, right. You don't even need a density
Ah, right. You don't even need a density
ward sometimes, right? Some of them. No,
ward sometimes, right? Some of them. No,
not like not at all. Ours are pretty
not like not at all. Ours are pretty
much sparse by default. Actually, you
much sparse by default. Actually, you
could try sparse on a pick cube. I doubt
could try sparse on a pick cube. I doubt
it will work, but maybe you get a
it will work, but maybe you get a
billion samples, maybe figure out by
billion samples, maybe figure out by
accident. Who knows? It's kind of tough
accident. Who knows? It's kind of tough
because I I tried it briefly. Um, your
because I I tried it briefly. Um, your
sparse reward is super sparse in the
sparse reward is super sparse in the
sense that like you're just never going
sense that like you're just never going
to accidentally do that, right? Yes. In
to accidentally do that, right? Yes. In
general, that's usually the case. Yeah.
general, that's usually the case. Yeah.
Okay. Okay. So this thing is um you can
Okay. Okay. So this thing is um you can
see that this is solving already, right?
see that this is solving already, right?
Nice.
Nice.
Yeah. But pick cube is too easy to like
Yeah. But pick cube is too easy to like
compare performance like we already
compare performance like we already
solve it with under a minute. So if you
solve it with under a minute. So if you
check the harder test then we should
check the harder test then we should
hopefully see some improvements. Yeah.
hopefully see some improvements. Yeah.
So and the thing is this is also
So and the thing is this is also
remember this is not tuned well enough
remember this is not tuned well enough
yet. So I tuned it to um I actually
yet. So I tuned it to um I actually
didn't even do up like multiple update
didn't even do up like multiple update
epochs in this. So, this is literally
epochs in this. So, this is literally
looking at your data once and throwing
looking at your data once and throwing
it away.
Nice. You'll see the uh here. Okay, we
Nice. You'll see the uh here. Okay, we
can get rid of this. So, we can show you
can get rid of this. So, we can show you
here. These are the params from the
here. These are the params from the
sweep that I got. You can see that this
sweep that I got. You can see that this
is a slightly different scale from uh we
is a slightly different scale from uh we
have a 64 horizon. This gives us an
have a 64 horizon. This gives us an
effective batch size of I believe this
effective batch size of I believe this
is 280K or something like that. And then
is 280K or something like that. And then
a mini batch size
a mini batch size
Yeah, we do recurrent by default. Oh,
Yeah, we do recurrent by default. Oh,
your ind bash size is far larger than
your ind bash size is far larger than
mine. Yes. Much much bigger. Yes. So,
mine. Yes. Much much bigger. Yes. So,
this is this is a thing in puffer that
this is this is a thing in puffer that
we usually have standard. So, if you
we usually have standard. So, if you
actually look the at this, you can see
actually look the at this, you can see
that 94% of the time is spent on the
that 94% of the time is spent on the
environment. Like puffer takes almost no
environment. Like puffer takes almost no
time.
Uh wait, what are these two numbers? 34
Uh wait, what are these two numbers? 34
seconds and 94%. What does that mean? So
seconds and 94%. What does that mean? So
ignore this because this is relative.
ignore this because this is relative.
But this is 94%
But this is 94%
of the total time of this experiment is
of the total time of this experiment is
being spent simulating the in
being spent simulating the in
Oh, you're spending no time training.
Oh, you're spending no time training.
Yeah. So in this setting then if you're
Yeah. So in this setting then if you're
simulator is faster whatever how you
simulator is faster whatever how you
have better scaling, right? Uh yes,
have better scaling, right? Uh yes,
exactly. So this is why if I do this
exactly. So this is why if I do this
exact same thing. So if I literally just
exact same thing. So if I literally just
do this and I just change this to
buffer neural MMO 3. Yeah.
You'll see you get a very different
You'll see you get a very different
spread.
So, first of all, you're immediately
So, first of all, you're immediately
training over two million steps per
training over two million steps per
second. Yeah. And
second. Yeah. And
uh you can see that we have almost no
uh you can see that we have almost no
time is spent on the environment even
time is spent on the environment even
though we need to simulate two million
though we need to simulate two million
steps per second.
steps per second.
Right. I mean, isn't that because you're
Right. I mean, isn't that because you're
collecting the same amount of data but
collecting the same amount of data but
faster. So most of the time is red
faster. So most of the time is red
training time. Yes, exactly. Because the
training time. Yes, exactly. Because the
end just runs super fast and now there's
end just runs super fast and now there's
actually a little bit of copy overhead
actually a little bit of copy overhead
because the amount of data this it's
because the amount of data this it's
actually quite a large amount of data.
actually quite a large amount of data.
It'll do this will be about a pabyte in
It'll do this will be about a pabyte in
three or four days of data. Is the copy
three or four days of data. Is the copy
overhead from just transferring CPU data
overhead from just transferring CPU data
to GPU? Yes, we have a bit of but for us
to GPU? Yes, we have a bit of but for us
for us the copy should pretty much it's
for us the copy should pretty much it's
zero because there's no copy. Yeah. So
zero because there's no copy. Yeah. So
for us we have but like the total
for us we have but like the total
bandwidth still it's still 15%. Compared
bandwidth still it's still 15%. Compared
to 94% right it's kind of crazy and this
to 94% right it's kind of crazy and this
is and this is with a much bigger this
is and this is with a much bigger this
is also with a we have a bigger policy
is also with a we have a bigger policy
in here as well. This is a 3.4 million
in here as well. This is a 3.4 million
parameter policy with an LSTM in it
parameter policy with an LSTM in it
training at 2.2 mil.
training at 2.2 mil.
Yeah, I'm guessing you need to have
Yeah, I'm guessing you need to have
settings tuned based on this
settings tuned based on this
distribution, right? Like for high
distribution, right? Like for high
throughput environments like or CR
throughput environments like or CR
environments, you can do something else.
environments, you can do something else.
For slower environments, you definitely
For slower environments, you definitely
do something else, right? Yes. But we
do something else, right? Yes. But we
also have we also have the best
also have we also have the best
hyperparameter tuning algorithm. So
hyperparameter tuning algorithm. So
we'll be able to do that, right? Yeah.
we'll be able to do that, right? Yeah.
Now, the only thing is it's not set up
Now, the only thing is it's not set up
by default to even bother looking at
by default to even bother looking at
like multiple update epochs or really
like multiple update epochs or really
small like mini batch or anything. Just
small like mini batch or anything. Just
don't do it. I see. Nice.
don't do it. I see. Nice.
Cuz even our slow even our slowm are
Cuz even our slow even our slowm are
typically like hundreds of hundreds of
typically like hundreds of hundreds of
thousands per uh per GPU.
thousands per uh per GPU.
Mhm. Like neural MMO is considered one
Mhm. Like neural MMO is considered one
of our slowm. If I do like here,
this is single GPU speed.
this is single GPU speed.
So, literally one GPU on Breakout. Oh,
So, literally one GPU on Breakout. Oh,
that's actually sad. That's sad. Slow.
that's actually sad. That's sad. Slow.
My local settings.
My local settings.
Where is this?
Go.
Go.
Uh, I don't I'll grab it from.
So there you go. This is here's puffer
So there you go. This is here's puffer
breakout at 3 million steps per second
breakout at 3 million steps per second
on one GP.
on one GP.
Yeah, it's very different regime.
Yeah, it's very different regime.
Um I also point out another thing with
Um I also point out another thing with
physics environments. We often do
physics environments. We often do
multiple physics steps before you take
multiple physics steps before you take
an action. So the default for PC cube is
an action. So the default for PC cube is
five physics steps for every action. You
five physics steps for every action. You
can technically have five times the S
can technically have five times the S
fps, but your training performance will
fps, but your training performance will
be more sample efficient. The reason is
be more sample efficient. The reason is
because for every physics step you take,
because for every physics step you take,
the robot moves further sometimes. So we
the robot moves further sometimes. So we
actually have a way to automatically
actually have a way to automatically
sweep that. Um oh, the physics steps
sweep that. Um oh, the physics steps
amount if if you can bind it. So here,
amount if if you can bind it. So here,
let me just I'll show you how we do this
let me just I'll show you how we do this
big. Um,
so literally all we do is what's the
so literally all we do is what's the
parameter called?
parameter called?
Uh, we have some it's in the MK works.
Uh, we have some it's in the MK works.
This is something called sim config.
This is something called sim config.
Yeah, but what's the is it like physics
Yeah, but what's the is it like physics
steps? Physics steps or something? No,
steps? Physics steps or something? No,
it's in the sim config. There's like
it's in the sim config. There's like
it's nested. The sim config is a
it's nested. The sim config is a
dictionary. Yeah, but like what's what's
dictionary. Yeah, but like what's what's
the what's the innermost name?
the what's the innermost name?
The innermost name is sim. Sorry, I need
The innermost name is sim. Sorry, I need
to check. We don't call steps. We have a
to check. We don't call steps. We have a
sim frequency and control frequency. If
sim frequency and control frequency. If
you increase the control frequency, you
you increase the control frequency, you
take more you take less physics per
take more you take less physics per
action. Um, so let me find. So basically
action. Um, so let me find. So basically
what I want to do
is I want to add I want to add it to the
is I want to add I want to add it to the
make function.
make function.
Yeah. And then it's going to be like
Yeah. I just want to add it to the make
Yeah. I just want to add it to the make
function and then I can auto add it to
function and then I can auto add it to
our
our
Yeah. So you said do you see the sim
Yeah. So you said do you see the sim
conflict class I just sent you in
conflict class I just sent you in
discord? There's two numbers you change
discord? There's two numbers you change
the simulation frequency only really
the simulation frequency only really
change it changes like the granularity
change it changes like the granularity
of each physics step. So if the sim
of each physics step. So if the sim
frequency is 100 that means each physics
frequency is 100 that means each physics
step is about 1/100th of a second in the
step is about 1/100th of a second in the
real world.
real world.
Um okay and then the number of physics
Um okay and then the number of physics
steps we take is sim frequency divided
steps we take is sim frequency divided
by control frequency.
by control frequency.
So should I be tuning? Should I play
So should I be tuning? Should I play
with both of these numbers or just one
with both of these numbers or just one
of them? So I actually have not bothered
of them? So I actually have not bothered
sweeping Simfreak. It is very poss. So
sweeping Simfreak. It is very poss. So
the problem with Simre Freak is that if
the problem with Simre Freak is that if
it's too small, the simulation is
it's too small, the simulation is
inaccurate and it'll break. Like you
inaccurate and it'll break. Like you
know the cube will bounce everywhere. If
know the cube will bounce everywhere. If
it's too big, you're simulating too much
it's too big, you're simulating too much
and your simulator is very slow. So how
and your simulator is very slow. So how
do I add these? Is there a way that I
do I add these? Is there a way that I
can pass this into a sim config for
can pass this into a sim config for
this? So in the original yeah you got to
this? So in the original yeah you got to
do after render mode do comma sim config
do after render mode do comma sim config
sim_config
sim_config
equals dict
equals dict
and then pass in sim_refak and control
and then pass in sim_refak and control
freak and we will just override the
freak and we will just override the
defaults with whatever only sort of
defaults with whatever only sort of
things you provide. Everything else will
things you provide. Everything else will
be kept the same.
Yep, that works. Uh, I would recommend
Yep, that works. Uh, I would recommend
not changing sim freak for most part
not changing sim freak for most part
because we tuned them a little bit to be
because we tuned them a little bit to be
stable, but you can try sweeping it if
stable, but you can try sweeping it if
you want. Uh, usually defaults are
you want. Uh, usually defaults are
pretty good. Um, control freak is
pretty good. Um, control freak is
definitely something you can try.
definitely something you can try.
The other thing I would note is that if
The other thing I would note is that if
the control freak is higher, like let's
the control freak is higher, like let's
say you use 40 or sorry, let's say you
say you use 40 or sorry, let's say you
use 50, it has to be divisible. The
use 50, it has to be divisible. The
problem with that is that the robot will
problem with that is that the robot will
move slower per action and so the
move slower per action and so the
effective length of a task grows longer
effective length of a task grows longer
and so the max steps value that we tune
and so the max steps value that we tune
for each environment are wrong. Now
for each environment are wrong. Now
the only fix against that is to possibly
the only fix against that is to possibly
increase the maximum delta of each robot
increase the maximum delta of each robot
action which currently is maybe not so
action which currently is maybe not so
easy to change from the command line. So
easy to change from the command line. So
hang on. So simulation freak decreases
hang on. So simulation freak decreases
fidelity. If I just in order to make
fidelity. If I just in order to make
this thing faster, do I have to divide
this thing faster, do I have to divide
both of these by the same constant or
both of these by the same constant or
just like one of them or what? No, no,
just like one of them or what? No, no,
no. So, the fastest simulation you can
no. So, the fastest simulation you can
get is if you do sim freak like 10,
get is if you do sim freak like 10,
control freak 10, you're basically
control freak 10, you're basically
simulating very very coarsely. I see.
simulating very very coarsely. I see.
Um, and every physics step we return an
Um, and every physics step we return an
observation. So, your SPS is technically
observation. So, your SPS is technically
higher. Um, but you probably won't be
higher. Um, but you probably won't be
able to solve anything because one with
able to solve anything because one with
control freak of 10, it's you're not
control freak of 10, it's you're not
moving a lot in environment and sim
moving a lot in environment and sim
freak of 10, the simulation is very
freak of 10, the simulation is very
inaccurate.
inaccurate.
Um, yeah, so it's a strange balance and
Um, yeah, so it's a strange balance and
that's why I've never bothered sweeping
that's why I've never bothered sweeping
it before. Um, because the higher the
it before. Um, because the higher the
control freak, the less distance your
control freak, the less distance your
robot moves. Um, now there's one
robot moves. Um, now there's one
potential fix you can explore later,
potential fix you can explore later,
which is you can try increasing the
which is you can try increasing the
speed of the robot, like the maximum
speed of the robot, like the maximum
action it could take. Right now, we cap
action it could take. Right now, we cap
it at certain number of radians per
it at certain number of radians per
joint, but you can you can bump that up
joint, but you can you can bump that up
and see what happens. We would like The
and see what happens. We would like The
reason why the reason why we keep this
reason why the reason why we keep this
smaller is only just for like
smaller is only just for like
reasonability.
reasonability.
Like we want to do some tore. If you
Like we want to do some tore. If you
make it too large, it's probably not
make it too large, it's probably not
going to transfer to real world. Um, oh,
going to transfer to real world. Um, oh,
you can't lurp it. Like if you get like
you can't lurp it. Like if you get like
a lowfi thing, can't you like upscale?
a lowfi thing, can't you like upscale?
Yeah, that's true. But we want to keep
Yeah, that's true. But we want to keep
our defaults reasonable for most users
our defaults reasonable for most users
because otherwise it won't be they'll be
because otherwise it won't be they'll be
confused if they do. Well, I mean, what
confused if they do. Well, I mean, what
happens if we set it really coarse and
happens if we set it really coarse and
then set everything to be super domain
then set everything to be super domain
randomized and then we have manny scale
randomized and then we have manny scale
at 2 million steps per second and we
at 2 million steps per second and we
solve robotics. How about that? I know.
solve robotics. How about that? I know.
Give it a try. Um, I can tell you the
Give it a try. Um, I can tell you the
function or thing you could try to
function or thing you could try to
change to increase the maximum
change to increase the maximum
actions later. I need to figure it out
actions later. I need to figure it out
because we don't have it as a typical
because we don't have it as a typical
API. If you have a thing we can do with
API. If you have a thing we can do with
that because I mean it really is the
that because I mean it really is the
case that with puffer like we see some
case that with puffer like we see some
crazy stuff as soon as we get things to
crazy stuff as soon as we get things to
run at a reasonable speed. Right.
run at a reasonable speed. Right.
Like you I think you saw the neural MMO
Like you I think you saw the neural MMO
3 curve, right? Yeah. Much better than
3 curve, right? Yeah. Much better than
before, right? Yeah. It's like almost 3x
before, right? Yeah. It's like almost 3x
better than our 20 baseline. Yeah. And
better than our 20 baseline. Yeah. And
it's better than the game. It's better
it's better than the game. It's better
at the game than I am.
at the game than I am.
Wow.
Wow.
Have you tried a net hack yet? I guess
Have you tried a net hack yet? I guess
net. We are We are waiting for Ryan to
net. We are We are waiting for Ryan to
uh be ready to do that stuff and I'm
uh be ready to do that stuff and I'm
going to hack on that with him for a
going to hack on that with him for a
bit. Oh, that's cool.
Okay.
If we actually get something that seems
If we actually get something that seems
like it'll work, I'm just going to order
like it'll work, I'm just going to order
I'll just order like a little robot arm
I'll just order like a little robot arm
or something to see if it if it works or
or something to see if it if it works or
not. Our center real experiments. We do
not. Our center real experiments. We do
zero shot center real. You have to set
zero shot center real. You have to set
up the camera a little bit after you
up the camera a little bit after you
follow tutorial. It should be pretty
follow tutorial. It should be pretty
straightforward and hopefully you can
straightforward and hopefully you can
get it solving random tasks you define
get it solving random tasks you define
really accurately. Like the main thing
really accurately. Like the main thing
about reinforcement learning compared to
about reinforcement learning compared to
like imitation learning, you have high
like imitation learning, you have high
generalizability. You have high spatial
generalizability. You have high spatial
generalizability. I can place a cube in
generalizability. I can place a cube in
like 30 by 30 cmters large area for a
like 30 by 30 cmters large area for a
tiny robot arm and it's fast, right? The
tiny robot arm and it's fast, right? The
policy deploys decently fast.
policy deploys decently fast.
Um, obviously it's not going to be like
Um, obviously it's not going to be like
a general purpose robot. That's kind of
a general purpose robot. That's kind of
harder, but um, you know, some people
harder, but um, you know, some people
want high performance robots for one
want high performance robots for one
task. This is the way it can do quite a
task. This is the way it can do quite a
lot. Frankly, if like the main
lot. Frankly, if like the main
limitation on why we don't do robotics,
limitation on why we don't do robotics,
it's not that the problems are hard,
it's not that the problems are hard,
it's that they're slow. Like I mean, we
it's that they're slow. Like I mean, we
already one of the faster ones. I mean,
already one of the faster ones. I mean,
there are faster tasks you can try, but
there are faster tasks you can try, but
Oh, no. Absolutely. I'm not faulting
Oh, no. Absolutely. I'm not faulting
you. I'm just the field as a whole.
you. I'm just the field as a whole.
Like, this stuff is like at least I I
Like, this stuff is like at least I I
mean, being very generous in order of
mean, being very generous in order of
magnitude too slow.
magnitude too slow.
Yeah. You got you got to get more GPS to
Yeah. You got you got to get more GPS to
scale up at this point. Yeah. I mean, if
scale up at this point. Yeah. I mean, if
if there are these fidelity settings
if there are these fidelity settings
like, you know, break like breakout or
like, you know, break like breakout or
pong are basically unplayable for humans
pong are basically unplayable for humans
at like eight frame skip, but the RL
at like eight frame skip, but the RL
agent is freaking just it just does it.
agent is freaking just it just does it.
Wait, what is eight frame skip? So, do
Wait, what is eight frame skip? So, do
you take like eight physics tests before
you take like eight physics tests before
you take an action or something? Yeah,
you take an action or something? Yeah,
it'll just do that. I see.
it'll just do that. I see.
But the thing is so frame skip for
But the thing is so frame skip for
something like that like you say you can
something like that like you say you can
upscale the speed of the actions and
upscale the speed of the actions and
it's the same thing. You just lose a bit
it's the same thing. You just lose a bit
of granularity and it'll work. It'll
of granularity and it'll work. It'll
work model
work model
any range of actions. It can take the
any range of actions. It can take the
largest one or take a smaller one in
largest one or take a smaller one in
case it can't solve the problem. Right.
case it can't solve the problem. Right.
Yeah. We'll just have to like observe
Yeah. We'll just have to like observe
for the real training we've done with
for the real training we've done with
the little robot hugging face arm. It
the little robot hugging face arm. It
will take larger actions initially, but
will take larger actions initially, but
once it gets to a cube, it generally
once it gets to a cube, it generally
takes smaller actions because it knows
takes smaller actions because it knows
if it takes too large of an action,
if it takes too large of an action,
it'll break.
it'll break.
Um, so I think I think this is
Um, so I think I think this is
definitely possible for sure.
definitely possible for sure.
Yeah. Yeah. I might have to just stick
Yeah. Yeah. I might have to just stick
on the uh the push cube task for a
on the uh the push cube task for a
little bit and just like speedrun it
little bit and just like speedrun it
first because my guess is that the peg
first because my guess is that the peg
insertion we can probably solve it, but
insertion we can probably solve it, but
the way Puffer works, it's pretty data
the way Puffer works, it's pretty data
hungry, at least with the defaults. But
hungry, at least with the defaults. But
I'd like to try to first like tune tune
I'd like to try to first like tune tune
for sample efficiency, tune for speed to
for sample efficiency, tune for speed to
get a feel for what I can solve this
get a feel for what I can solve this
with. Um, yeah. Oh, not push cube. Push
with. Um, yeah. Oh, not push cube. Push
cube is too easy. Pick cube. We can do
cube is too easy. Pick cube. We can do
both of those. Um, yeah. The next
both of those. Um, yeah. The next
difficulty task is probably stack cube
difficulty task is probably stack cube
and push t. Those are next two. Yeah, I
and push t. Those are next two. Yeah, I
can do either. Push t1. Push tv1 is uh
can do either. Push t1. Push tv1 is uh
is a very famous task because of a
is a very famous task because of a
famous paper from a while back. But
famous paper from a while back. But
there's a we have the only GPU sim
there's a we have the only GPU sim
version of it.
version of it.
Um yeah, literally some undergrad at my
Um yeah, literally some undergrad at my
at UCSD did it for a course project.
at UCSD did it for a course project.
Like he saw this paper that did push t
Like he saw this paper that did push t
in real world was like you know let me
in real world was like you know let me
try to simulate it. Cracked guy wrote
try to simulate it. Cracked guy wrote
the code wrote the reward function wrote
the code wrote the reward function wrote
a function to check the area overlap
a function to check the area overlap
like batched uh 2D area overlap
like batched uh 2D area overlap
function. That was kind of cool. Cool.
function. That was kind of cool. Cool.
Submitted a PR. I accepted it. He joined
Submitted a PR. I accepted it. He joined
my lab. He did the center real project
my lab. He did the center real project
actually. I mentored him on that. Now
actually. I mentored him on that. Now
he's joining Nvidia as well.
he's joining Nvidia as well.
That's cool. I don't know about keeping
That's cool. I don't know about keeping
for PhD but um yeah
for PhD but um yeah
very cracked underground there. Three
very cracked underground there. Three
stack cube. Now we have our chat asking
stack cube. Now we have our chat asking
for three stack cube. All right. What's
for three stack cube. All right. What's
it called? I don't have a three stack
it called? I don't have a three stack
cube. Two stack cube. Okay. What's it
cube. Two stack cube. Okay. What's it
called? Stack stack cube. So we do Manny
called? Stack stack cube. So we do Manny
stack.
Uh we I can add a three stack cube task.
Uh we I can add a three stack cube task.
Uh might be hard to solve. I don't know
Uh might be hard to solve. I don't know
the time it would take to solve, but we
the time it would take to solve, but we
can try running it. Very easy to define.
can try running it. Very easy to define.
I can define it like this stack cube v1.
I can define it like this stack cube v1.
Yep, that's right. Well, let's see if we
Yep, that's right. Well, let's see if we
can solve these first. I at least have
can solve these first. I at least have
some stuff to play with. Uh what are we
some stuff to play with. Uh what are we
going to do about this reward thing? So,
going to do about this reward thing? So,
I can show you what I what I made. Um
I can show you what I what I made. Um
just make can you make the change in PR
just make can you make the change in PR
or something or Yeah, I can totally I
or something or Yeah, I can totally I
will PR it for you. I just want to make
will PR it for you. I just want to make
sure this is like reasonable for you.
sure this is like reasonable for you.
Yeah, I I'll just edit as needed. Um,
Yeah, I I'll just edit as needed. Um,
let me see. Let me just make sure that
let me see. Let me just make sure that
you like you think that this is a
you like you think that this is a
reasonable uh thing to do because I
reasonable uh thing to do because I
don't like it's possible I missed
don't like it's possible I missed
something. The one thing is that you
something. The one thing is that you
probably need to add a scale param
probably need to add a scale param
because it changes the reward scale
because it changes the reward scale
differently per task. Uh, so I haven't
differently per task. Uh, so I haven't
done that yet, but where is it? Many
done that yet, but where is it? Many
skill. Why are we changing why are we
skill. Why are we changing why are we
changing reward scale? Uh, you'll see.
changing reward scale? Uh, you'll see.
Hang on. Manny skill and
Okay, so you start with these zeros for
Okay, so you start with these zeros for
last reward, right? And then last to
last reward, right? And then last to
zeros
and then the delta reward function.
and then the delta reward function.
It gives Oh, you have 10.
It gives Oh, you have 10.
Well, because the difference is going to
Well, because the difference is going to
be very small.
be very small.
I see. I guess that should be another
I see. I guess that should be another
parameter to him now. Yes, this would be
parameter to him now. Yes, this would be
a per this would be a hyper which is the
a per this would be a hyper which is the
reward scale. Um because this is a very
reward scale. Um because this is a very
small scale and but here's the crazy
small scale and but here's the crazy
thing about this though, right? So
thing about this though, right? So
this doesn't actually do anything if you
this doesn't actually do anything if you
think about it because if your rewards
think about it because if your rewards
were like 0.9 or 0.91
were like 0.9 or 0.91
before you still had to like it had to
before you still had to like it had to
learn that difference which is very
learn that difference which is very
small. So I've seen separately in my own
small. So I've seen separately in my own
work that state-based rewards are very
work that state-based rewards are very
bad because of this reason because let's
bad because of this reason because let's
say that you want your reward to be
say that you want your reward to be
roughly zero to one scaled that covers
roughly zero to one scaled that covers
the entire state space like one is the
the entire state space like one is the
best zero is bad. So like between very
best zero is bad. So like between very
good and like a little bit worse.
good and like a little bit worse.
There's only this tiny little band. You
There's only this tiny little band. You
kind of have to learn to upnormalize it.
kind of have to learn to upnormalize it.
Versus with these deltas, deltas can
Versus with these deltas, deltas can
have a much more reasonable magnitude
have a much more reasonable magnitude
for them because they're always
for them because they're always
relative. So that's like another big
relative. So that's like another big
reason for this. I thought that's what
reason for this. I thought that's what
advantage calculation was meant for. It
advantage calculation was meant for. It
was meant to compute the scenes. It
was meant to compute the scenes. It
doesn't quite work.
doesn't quite work.
I guess this just makes it easier for
I guess this just makes it easier for
advantage too, right? Yes. Yes, this
advantage too, right? Yes. Yes, this
does. And it will keep everything on
does. And it will keep everything on
roughly the same scale as well. Another
roughly the same scale as well. Another
question is I don't I mean I think
question is I don't I mean I think
personally this 10 times div thing the
personally this 10 times div thing the
10 should go into the algo code the fun
10 should go into the algo code the fun
the training code not the environment.
the training code not the environment.
So
So
you'd ideally want to have your well I
you'd ideally want to have your well I
guess it depends. You can technically
guess it depends. You can technically
put a reward scale constant into your
put a reward scale constant into your
algorithm. Uh generally what I do in
algorithm. Uh generally what I do in
puffers we kind of just assume that the
puffers we kind of just assume that the
M should have reasonably normalized
M should have reasonably normalized
rewards and if they don't then we like
rewards and if they don't then we like
make a wrapper for the N so that like
make a wrapper for the N so that like
the N is responsible for giving us a
the N is responsible for giving us a
reasonable reward. The only thing that
reasonable reward. The only thing that
we do is we will clip the reward from
we do is we will clip the reward from
negative one to one just because like
negative one to one just because like
there are a lot of M's with just insane
there are a lot of M's with just insane
reward functions that will instantly
reward functions that will instantly
break learning otherwise.
break learning otherwise.
Yeah, but all our rewards are probably
Yeah, but all our rewards are probably
in a scale of like 0.01 or 0.1 because
in a scale of like 0.01 or 0.1 because
you already normalize it. You're using
you already normalize it. You're using
normalized one, right? Yeah, you are. Uh
normalized one, right? Yeah, you are. Uh
so I could get rid of this 10x and just
so I could get rid of this 10x and just
have diff and then I' I'd have to add
have diff and then I' I'd have to add
like a reward scale param. I guess it's
like a reward scale param. I guess it's
a little weird, but I we could do it.
a little weird, but I we could do it.
It's okay. I my person like at least in
It's okay. I my person like at least in
my own ppl code I often add your scale
my own ppl code I often add your scale
as just a config parameter because it's
as just a config parameter because it's
dependent on environment. Yeah. Well, I
dependent on environment. Yeah. Well, I
guess because it's dependent on
guess because it's dependent on
environment maybe you should just put it
environment maybe you should just put it
in the environment. But the thing is
in the environment. But the thing is
the other reason why I put it there is
the other reason why I put it there is
because it's also dependent on algorithm
because it's also dependent on algorithm
sometimes. Yeah, some algorithms might
sometimes. Yeah, some algorithms might
handle it better than others. Right. We
handle it better than others. Right. We
kind of just the thing in puffer is we
kind of just the thing in puffer is we
just have the one best algorithm.
just have the one best algorithm.
I see right. Uh I mean technically we
I see right. Uh I mean technically we
already have a mistake in here where we
already have a mistake in here where we
have a normalized density reward and a
have a normalized density reward and a
non-normalized one. Yeah. The reason why
non-normalized one. Yeah. The reason why
we call it a non-normalized one is
we call it a non-normalized one is
because people still use that from
because people still use that from
manuscript 2 and just left it there. But
manuscript 2 and just left it there. But
I
I
uh Okay. The problem is I I don't like
uh Okay. The problem is I I don't like
the idea of having to tune the delta
the idea of having to tune the delta
reward skill for every environment.
reward skill for every environment.
Unless we want to do it now, we could.
Unless we want to do it now, we could.
Um I guess but the problem is like well
Um I guess but the problem is like well
I don't that's the only you don't really
I don't that's the only you don't really
have to as long as it's in a reasonable
have to as long as it's in a reasonable
enough range. Um that's it then like
enough range. Um that's it then like
because the thing is you you're tuning
because the thing is you you're tuning
your learning rate in other things right
your learning rate in other things right
and that kind of gets it but it like you
and that kind of gets it but it like you
still want to have your reward on like a
still want to have your reward on like a
reasonable enough scale that your
reasonable enough scale that your
default like your defaults actually
default like your defaults actually
learn something so you have a starting
learn something so you have a starting
point. So like it just generally if we
point. So like it just generally if we
can get the reward into a roughly 0ero
can get the reward into a roughly 0ero
to one or negative one to one scale like
to one or negative one to one scale like
somethingish around there we'll be fine
somethingish around there we'll be fine
but I don't know is there some general
but I don't know is there some general
thing we can do because it's like so
thing we can do because it's like so
technically the maximum diff the maximum
technically the maximum diff the maximum
delta is one right because your
delta is one right because your
normalized reward goes from zero to one
normalized reward goes from zero to one
so if you were to jump if you were to
so if you were to jump if you were to
teleport to the target in one step it
teleport to the target in one step it
would be one
would be one
yes but that's almost impossible. Yes,
yes but that's almost impossible. Yes,
exactly. So, but then the thing is like
exactly. So, but then the thing is like
what do we set it to to be reasonable?
what do we set it to to be reasonable?
I mean, if you do times 10, you're going
I mean, if you do times 10, you're going
to clip it to one anyway. Yeah. Um, but
to clip it to one anyway. Yeah. Um, but
most of the time the reward function
most of the time the reward function
you're going to be dealing with is just
you're going to be dealing with is just
a tage function or exponential, right?
a tage function or exponential, right?
Yeah. Because most of the time you're
Yeah. Because most of the time you're
not switching stages in reward function.
not switching stages in reward function.
Like we do reward functions by stages
Like we do reward functions by stages
usually. Um, and so between stages is a
usually. Um, and so between stages is a
small jump, but otherwise in a stage is
small jump, but otherwise in a stage is
always just whatever the gradient of the
always just whatever the gradient of the
tanh function is and that's what you're
tanh function is and that's what you're
following. Well, I mean, I can show you
following. Well, I mean, I can show you
what we get from this in where is it?
what we get from this in where is it?
So, success once. These are some of our
So, success once. These are some of our
experiments here. Actually, I'll show
experiments here. Actually, I'll show
you the best ones because I have this
you the best ones because I have this
nice full sweep for you.
nice full sweep for you.
Okay, this is what it looks like um for
Okay, this is what it looks like um for
thisund and 138 experiments.
And you can see that we have like a
And you can see that we have like a
variety of these different results.
variety of these different results.
get return and such. And uh we also have
get return and such. And uh we also have
reward. So reward it looks like for the
reward. So reward it looks like for the
best it gets up to about point four with
best it gets up to about point four with
the times 10 that I find. Yeah, is like
the times 10 that I find. Yeah, is like
a reason I would call that a reasonable
a reason I would call that a reasonable
enough scale. Um which task is this
enough scale. Um which task is this
again? This is pick.
again? This is pick.
Okay. I I feel like time st is okay.
Okay. I I feel like time st is okay.
This is reflecting what the result of
This is reflecting what the result of
tanh is usually like the difference of
tanh is usually like the difference of
two tanh operations at two points. Yeah,
two tanh operations at two points. Yeah,
that seems about and then I can show you
that seems about and then I can show you
if I just I can show you the best runs.
if I just I can show you the best runs.
But also this is probably overfitit on
But also this is probably overfitit on
the robot you're using right now. Some
the robot you're using right now. Some
other robots have smaller scales of
other robots have smaller scales of
movement which might be different which
movement which might be different which
might be annoying. I mean I would be
might be annoying. I mean I would be
curious try without multip by 10 and
curious try without multip by 10 and
just see if your algorithm can be robust
just see if your algorithm can be robust
to it. Uh I can try. My guess would be
to it. Uh I can try. My guess would be
that the p the optimal hypers are going
that the p the optimal hypers are going
to shift dramatically.
Maybe not. a way to make this I feel
Maybe not. a way to make this I feel
like you need a way to make this
like you need a way to make this
slightly more robust because I I can try
slightly more robust because I I can try
it. I can just try it. Yeah, I would
it. I can just try it. Yeah, I would
think you should try it. But I feel like
think you should try it. But I feel like
it's a bit hard to guarantee that every
it's a bit hard to guarantee that every
environment has a reasonable reward
environment has a reasonable reward
function. I mean, you're already
function. I mean, you're already
clipping to try to avoid that. Well,
clipping to try to avoid that. Well,
we're clipping is just like if you give
we're clipping is just like if you give
it's that's basically the intent of that
it's that's basically the intent of that
is don't give me something insane. Like
is don't give me something insane. Like
there are people people will literally
there are people people will literally
PR me environments that have like 300
PR me environments that have like 300
reward scale and I tell them to fix but
reward scale and I tell them to fix but
like all the third party environments
like all the third party environments
literally people have no idea what
literally people have no idea what
they're doing in this field man I
they're doing in this field man I
remember the days in the first opening
remember the days in the first opening
were like going to thousands or tens of
were like going to thousands or tens of
thousands. Yeah
thousands. Yeah
that's kind of crazy. Yeah people just
that's kind of crazy. Yeah people just
don't know what they're doing honest
don't know what they're doing honest
the fix for that some people try to do
the fix for that some people try to do
is try and use sim log wait clipping
is try and use sim log wait clipping
also yeah that doesn't work. We uh we
also yeah that doesn't work. We uh we
have we have extensive we have extensive
have we have extensive we have extensive
experimental evidence that sim log is a
experimental evidence that sim log is a
method. I think you tested only
method. I think you tested only
on dreamer though. Wasn't on a dreamer
on dreamer though. Wasn't on a dreamer
one. We tested it on PO.
one. We tested it on PO.
Oh, maybe that's a PO thing. We we we
Oh, maybe that's a PO thing. We we we
tried sim log on TDMPC our model base.
tried sim log on TDMPC our model base.
That seems to work quite well. Did you
That seems to work quite well. Did you
try it versus just clipping?
try it versus just clipping?
Uh we have not tried it versus clipping
Uh we have not tried it versus clipping
but it was definitely better than not
but it was definitely better than not
doing anything. Yes. So you need to So
doing anything. Yes. So you need to So
it's basically you just need to do
it's basically you just need to do
something and just clipping is just as
something and just clipping is just as
good as sim log if not better.
good as sim log if not better.
Huh. Yeah, I see. Okay. Yeah. Uh yeah.
Huh. Yeah, I see. Okay. Yeah. Uh yeah.
So that was a bust one for paper.
Interesting. Yeah. I mean like you said
Interesting. Yeah. I mean like you said
we don't like our algorithm it's based
we don't like our algorithm it's based
on PO but our trainer is not PO at this
on PO but our trainer is not PO at this
point. It's like it's changed enough to
point. It's like it's changed enough to
not call it the same algorithm.
not call it the same algorithm.
Huh. Okay.
Huh. Okay.
And it's been dramatically better on
And it's been dramatically better on
everything else we've tested. So, my
everything else we've tested. So, my
expectation is after we speak, you
expectation is after we speak, you
should see some improvements on this.
should see some improvements on this.
Um, it's got it has a new advantage
Um, it's got it has a new advantage
function. It's got a different
function. It's got a different
optimizer. It's got like prioritized
optimizer. It's got like prioritized
replay on online prioritized replay. Uh,
replay on online prioritized replay. Uh,
advantage filtering like trajectory
advantage filtering like trajectory
segment level filtering. Got a bunch of
segment level filtering. Got a bunch of
stuff.
stuff.
Nice.
Nice.
And it's fast.
Yeah, you're adding a lot of It's like a
Yeah, you're adding a lot of It's like a
rainbow PO now. H I mean I would think
rainbow PO now. H I mean I would think
that the stuff that we've added has been
that the stuff that we've added has been
much better validated. And also like
much better validated. And also like
it's harder to bolt stuff onto PO that
it's harder to bolt stuff onto PO that
matters than it is to bolt stuff onto
matters than it is to bolt stuff onto
DQN because DQN's just a bad base
DQN because DQN's just a bad base
algorithm whereas PO is a pretty dang
algorithm whereas PO is a pretty dang
good base algorithm. Still using PQN. I
good base algorithm. Still using PQN. I
I swear there shouldn't be anyone using
I swear there shouldn't be anyone using
DQ. Yeah, but like Rainbow is like
DQ. Yeah, but like Rainbow is like
Rainbow is like a bolt-on to DQN
Rainbow is like a bolt-on to DQN
basically, right? Yeah, but like DK is
basically, right? Yeah, but like DK is
too bad of a base algorithm. I don't
too bad of a base algorithm. I don't
know why you would do that. Yeah. Well,
know why you would do that. Yeah. Well,
the point here is that like if you try
the point here is that like if you try
to like make like a rainbow PO for
to like make like a rainbow PO for
instance, it's a lot harder than it is
instance, it's a lot harder than it is
to make like rainbow DQN because your
to make like rainbow DQN because your
starting point is a much stronger
starting point is a much stronger
baseline.
baseline.
Ah, yes, I agree. That makes sense.
Ah, yes, I agree. That makes sense.
Yeah. Yeah. Cuz like so most of the
Yeah. Yeah. Cuz like so most of the
papers that say we made P like we made a
papers that say we made P like we made a
better PO if you actually go try them
better PO if you actually go try them
they're just wrong.
they're just wrong.
Yeah. I mean people are still using PO
Yeah. I mean people are still using PO
now right. There's a good reason for
now right. There's a good reason for
that. Yeah I'm still it. I think there
that. Yeah I'm still it. I think there
is some possibility SACE might make a
is some possibility SACE might make a
comeback but it could be within the
comeback but it could be within the
regime that we are testing out which is
regime that we are testing out which is
100ks. It's just low. I will say um well
100ks. It's just low. I will say um well
we'll see once I run these sweeps for
we'll see once I run these sweeps for
you if you're convinced by this. Uh the
you if you're convinced by this. Uh the
very least though, like the absolute
very least though, like the absolute
very least you do, even if you don't
very least you do, even if you don't
want to do like our more complicated
want to do like our more complicated
stuff is to switch your optimizer from
stuff is to switch your optimizer from
Atom to Muon and retune all your hyper
Atom to Muon and retune all your hyper
prams. Oh yeah, I heard you were using
prams. Oh yeah, I heard you were using
Muon. It seems to actually work pretty
Muon. It seems to actually work pretty
well, right? But you also need to tune
well, right? But you also need to tune
your other parameters according to
your other parameters according to
learning rate and whatever. You need to
learning rate and whatever. You need to
retune all your parameters.
retune all your parameters.
I see. Are you using muon right now?
I see. Are you using muon right now?
Yes. In these sweeps? Yes. Everything is
Yes. In these sweeps? Yes. Everything is
muon by default.
muon by default.
Nice.
Nice.
Okay. I mean, at this point in manual
Okay. I mean, at this point in manual
repo, we have a baselines folder. I'll
repo, we have a baselines folder. I'll
probably just add a separate folder
probably just add a separate folder
called puffer dbo and just point to your
called puffer dbo and just point to your
website. That works much better. Yeah. I
website. That works much better. Yeah. I
I mean, it's like the cool thing is our
I mean, it's like the cool thing is our
stuff is it's vaguely clean RL. It's
stuff is it's vaguely clean RL. It's
obviously it's gotten a little bit
obviously it's gotten a little bit
longer with all the stuff we've had to
longer with all the stuff we've had to
do, but like our trainer is still Have
do, but like our trainer is still Have
you seen it late? Have you seen it
you seen it late? Have you seen it
recently? Which one? The Puff Rel file.
recently? Which one? The Puff Rel file.
No. What is it? This is your training
No. What is it? This is your training
file. 1,000 total lines. And this
file. 1,000 total lines. And this
includes this includes pretty much
includes this includes pretty much
everything. Uh it includes as well the
everything. Uh it includes as well the
local dashboard, the nice local
local dashboard, the nice local
monitoring dashboard, integrations for
monitoring dashboard, integrations for
Neptune and wann. Uh it includes like
Neptune and wann. Uh it includes like
the runner. Yes. For current training.
the runner. Yes. For current training.
It includes all the config stuff to load
It includes all the config stuff to load
all the different puffer ends as well.
all the different puffer ends as well.
Um
Um
yeah, and eval. It includes a lot of
yeah, and eval. It includes a lot of
stuff. A big chunk of it is just
stuff. A big chunk of it is just
printing. Yes. A lot of it is like this
printing. Yes. A lot of it is like this
is the dashboard. When you see that like
is the dashboard. When you see that like
in your terminal dashboard, it's just
in your terminal dashboard, it's just
right there. And then this is move this
right there. And then this is move this
function out outside the dashboard part.
function out outside the dashboard part.
No, we just keep everything in a file as
No, we just keep everything in a file as
much as possible. That's funny. I feel
much as possible. That's funny. I feel
like I minimum logging stuff should be a
like I minimum logging stuff should be a
separate file, but okay. We try to just
separate file, but okay. We try to just
keep everything there. I think we have
keep everything there. I think we have
separate models because of separate
separate models because of separate
models file because it's like you're not
models file because it's like you're not
going to use every model with this but
going to use every model with this but
you're always going to this dashboard
you're always going to this dashboard
with this. Um so we try to just keep
with this. Um so we try to just keep
this together and then the one other
this together and then the one other
thing here that literally cannot be in
thing here that literally cannot be in
the same file is the CUDA extension
the same file is the CUDA extension
because we have the advantage function
because we have the advantage function
here. Oh, you're on a CUDA colonel for
here. Oh, you're on a CUDA colonel for
advantage. It's required. Uh, puffer is
advantage. It's required. Uh, puffer is
literally so fast that with the way that
literally so fast that with the way that
prioritized experience replay works, if
prioritized experience replay works, if
you do not have this, you can bottleneck
you do not have this, you can bottleneck
on the advantage computation.
on the advantage computation.
Huh? Yeah, I remember advantage comput
Huh? Yeah, I remember advantage comput
is like a big for loop, right? You got
is like a big for loop, right? You got
to paralyze that. This is also this is
to paralyze that. This is also this is
also something that you can steal. This
also something that you can steal. This
is not generalized advantage estimation.
is not generalized advantage estimation.
This is our own algorithm. This is a
This is our own algorithm. This is a
strict generalization of both vrace and
strict generalization of both vrace and
generalized advantage estimation.
generalized advantage estimation.
Wait, what is this different from the
Wait, what is this different from the
standard advantage computation? Yes.
standard advantage computation? Yes.
What's the difference? It is a strict
What's the difference? It is a strict
generalization of vrace and generalized
generalization of vrace and generalized
advantage estimation both. Oh, wait. You
advantage estimation both. Oh, wait. You
have an importance vector and then
have an importance vector and then
you're you have a row clip. What row
you're you have a row clip. What row
clip doing here? So, this is vrace. You
clip doing here? So, this is vrace. You
know vtrace from Impala? I have heard of
know vtrace from Impala? I have heard of
it. I don't know how it works. It's an
it. I don't know how it works. It's an
off it's an off policy correction
off it's an off policy correction
mechanism. You know how uh PO has like
mechanism. You know how uh PO has like
this it has this term that tries to like
this it has this term that tries to like
keep close to the original policy like
keep close to the original policy like
this importance term. So what vrace does
this importance term. So what vrace does
is it does that inside of the advantage
is it does that inside of the advantage
function. So it pushes it a layer
function. So it pushes it a layer
deeper. You have it at actually every
deeper. You have it at actually every
step of the advantage computation. You
step of the advantage computation. You
have that importance term.
have that importance term.
I see. Huh. So what this does is this
I see. Huh. So what this does is this
gives you that and it gives you
gives you that and it gives you
generalized advantage estimation at the
generalized advantage estimation at the
same time as a generalization of both.
same time as a generalization of both.
What's the fmn in function where oh
What's the fmn in function where oh
fmin? It's just a min float min float.
fmin? It's just a min float min float.
Oh, that's the clipping thing. Okay.
Oh, that's the clipping thing. Okay.
Float. So, you're taking them in and you
Float. So, you're taking them in and you
have the CT part and then Huh. And then
have the CT part and then Huh. And then
the only thing you have to be a little
the only thing you have to be a little
careful of is whether your next your
careful of is whether your next your
current versus next step indexing is the
current versus next step indexing is the
same as ours. This is correct for our
same as ours. This is correct for our
implementation.
implementation.
Yeah. But yeah, this is this is the main
Yeah. But yeah, this is this is the main
thing. This was the thing that made it
thing. This was the thing that made it
really annoying to ship Puffer 3.0
really annoying to ship Puffer 3.0
because shipping CUDA kernels just
because shipping CUDA kernels just
sucks. It's just a pain in the ass to
sucks. It's just a pain in the ass to
set up with uh with your setup.py. high.
set up with uh with your setup.py. high.
Uh, and there's also like there's an
Uh, and there's also like there's an
automatic C++ fallback for this as well.
automatic C++ fallback for this as well.
Without embedded GPUs at least. Yeah.
Without embedded GPUs at least. Yeah.
So, this just like works. Yeah. And then
So, this just like works. Yeah. And then
that's that was one of the other big
that's that was one of the other big
things. So, like at this point,
things. So, like at this point,
basically nobody has actually started
basically nobody has actually started
using any of our stuff outside of Puffer
using any of our stuff outside of Puffer
yet, but it is technically just all
yet, but it is technically just all
there and you can just like
there and you can just like
state of the art stuff.
state of the art stuff.
I mean, I have my own PO code. I'll
I mean, I have my own PO code. I'll
probably just switch if it's faster than
probably just switch if it's faster than
lean RL version of it. It will be
lean RL version of it. It will be
dramatically faster. I guess I will
dramatically faster. I guess I will
still need to kind of tune for single
still need to kind of tune for single
GPU still. Well, let me just do that
GPU still. Well, let me just do that
first, right? Let me let me just run
first, right? Let me let me just run
that stuff and we'll see how good I can
that stuff and we'll see how good I can
get it. But yeah, like yeah, this this
get it. But yeah, like yeah, this this
single implementation we use this on the
single implementation we use this on the
cool thing about this is we just use
cool thing about this is we just use
this one implementation on everything.
this one implementation on everything.
So it's like tuned for it like has to be
So it's like tuned for it like has to be
good for everything basically. Um,
good for everything basically. Um,
right. So this thing with really big
right. So this thing with really big
batch sizes I have hit I've trained uh
batch sizes I have hit I've trained uh
20 million step per second pong that
20 million step per second pong that
actually solves the M like at that like
actually solves the M like at that like
with crazy batch sizes. And the other
with crazy batch sizes. And the other
thing about this is if you run this
thing about this is if you run this
distributed, this thing will give you
distributed, this thing will give you
linear speed ups even for Ms that are
linear speed ups even for Ms that are
like running at like uh like several
like running at like uh like several
hundred thousand steps per second
hundred thousand steps per second
because like the overhead is tiny.
because like the overhead is tiny.
That's crazy.
Yeah, this is basically core of puffer
Yeah, this is basically core of puffer
3. I I hope that this is going to be
3. I I hope that this is going to be
useful for robotics because basically
useful for robotics because basically
what I'm trying to do with Manny here is
what I'm trying to do with Manny here is
like just see whether we can just throw
like just see whether we can just throw
this on robotics and build something
this on robotics and build something
that's useful to robotics researchers as
that's useful to robotics researchers as
a result. We haven't had that much
a result. We haven't had that much
usage. A lot of our people use our PO
usage. A lot of our people use our PO
baseline if they can use this when it's
baseline if they can use this when it's
faster, that's easy to install, but I'm
faster, that's easy to install, but I'm
sure they'll switch over. Uh, I would
sure they'll switch over. Uh, I would
also recommend I mean if you want more
also recommend I mean if you want more
you should target locomotion but I know
you should target locomotion but I know
you haven't done Isaac but you probably
you haven't done Isaac but you probably
should. The reason we did Isaac Gym and
should. The reason we did Isaac Gym and
it was we had a contract where we did
it was we had a contract where we did
Isaac gym and it was it was hell like
Isaac gym and it was it was hell like
did the contract work out eventually?
did the contract work out eventually?
Like yeah we did it but like we did it.
Like yeah we did it but like we did it.
It was just like way way more work than
It was just like way way more work than
it should have been. And like honestly
it should have been. And like honestly
it was just like some of the dumbest
it was just like some of the dumbest
most deranged code we've ever seen uh
most deranged code we've ever seen uh
was the Isaac Jim code bases. Like they
was the Isaac Jim code bases. Like they
literally have like they have
literally have like they have
generational trauma of like it's like
generational trauma of like it's like
one PhD student wrapping another PhD
one PhD student wrapping another PhD
student shitty code and then like roll
student shitty code and then like roll
that forward five generations of
that forward five generations of
miserable PhD students.
miserable PhD students.
I see. Um well anyway regardless the
I see. Um well anyway regardless the
most frequent uses of PO and robotics
most frequent uses of PO and robotics
will be people training dogs and robot
will be people training dogs and robot
humanoids.
humanoids.
Um you have the you have um you have
Um you have the you have um you have
humanoid tasks in Manny, don't you?
humanoid tasks in Manny, don't you?
Yeah, we have manipulation tasks, not
Yeah, we have manipulation tasks, not
locomotion. Our locomotion ones suck
locomotion. Our locomotion ones suck
because I don't have the right reward
because I don't have the right reward
functions. Isaac Lab and Isaac Jim have
functions. Isaac Lab and Isaac Jim have
tuned the reward functions already and
tuned the reward functions already and
I've never figured out how to do it
I've never figured out how to do it
myself. Oh, the other thing is we I've
myself. Oh, the other thing is we I've
never been able to replicate Isaac Jim's
never been able to replicate Isaac Jim's
locomotion simulation speed. I don't
locomotion simulation speed. I don't
know what they did, but we have not been
know what they did, but we have not been
able to replicate it. So, I just did.
able to replicate it. So, I just did.
Okay. So, I mean, let's just see how far
Okay. So, I mean, let's just see how far
we get out of tuning. If like if I am
we get out of tuning. If like if I am
actually able to get something fast and
actually able to get something fast and
like if I'm able to get stable training
like if I'm able to get stable training
at quick speeds with this, then I think
at quick speeds with this, then I think
that could potentially unlock a lot of
that could potentially unlock a lot of
new stuff for you on the sim. Yeah, for
new stuff for you on the sim. Yeah, for
sure. I mean, it'll be tasks that we
sure. I mean, it'll be tasks that we
didn't expect we can solve, right? That
didn't expect we can solve, right? That
we can also solve. That's literally what
we can also solve. That's literally what
has happened with a lot of the things in
has happened with a lot of the things in
Puffer is like just from 2 to 3 0 we had
Puffer is like just from 2 to 3 0 we had
a lot of hard problems that we really we
a lot of hard problems that we really we
were putting a lot of effort into and we
were putting a lot of effort into and we
couldn't quite get before and now they
couldn't quite get before and now they
just work out of the box. Um nice like
just work out of the box. Um nice like
in various different domains things are
in various different domains things are
just like getting soda.
just like getting soda.
Another thing I want you to consider
Another thing I want you to consider
have you considered learning from
have you considered learning from
demonstrations like online learning
demonstrations like online learning
demonstrations?
demonstrations?
Um we did that for that one contract.
Um we did that for that one contract.
It's like is that even a hard problem
It's like is that even a hard problem
like at all? Yes. And also it's a very
like at all? Yes. And also it's a very
popular problem in robotics because
popular problem in robotics because
right now most of robotics is heavily
right now most of robotics is heavily
focused on using demonstration data from
focused on using demonstration data from
the real world or simulation.
the real world or simulation.
The problem is I mean real world data
The problem is I mean real world data
they do imitation learning on it but in
they do imitation learning on it but in
simulation you can do RL and imitation
simulation you can do RL and imitation
learning together. Yeah that's a setup
learning together. Yeah that's a setup
we is the point is you want to get rid
we is the point is you want to get rid
of density functions. There's too many
of density functions. There's too many
possible robotics task. There's not
possible robotics task. There's not
enough people to write reward functions
enough people to write reward functions
for and language models are not good
for and language models are not good
enough at writing reward functions
enough at writing reward functions
apparently. So it's hard to scale in
apparently. So it's hard to scale in
that sense. So people have opted
that sense. So people have opted
including me people have opted to try
including me people have opted to try
get a few demonstrations train or SACE
get a few demonstrations train or SACE
or whatever to learn from that in a
or whatever to learn from that in a
sparse reward environment. So I think
sparse reward environment. So I think
that basically if you just get if you
that basically if you just get if you
just get a policy that can take actions
just get a policy that can take actions
that make sense. So instead of like
that make sense. So instead of like
flailing and like jittering, if it can
flailing and like jittering, if it can
just like make actions that are like
just like make actions that are like
move arm here, move arm here, whatever,
move arm here, move arm here, whatever,
the exploration problem kind of becomes
the exploration problem kind of becomes
trivial enough that you should just be
trivial enough that you should just be
able to use the sparse reward setting
able to use the sparse reward setting
online. No, no, that's what I hope too.
online. No, no, that's what I hope too.
And in fact, actually, one of the things
And in fact, actually, one of the things
I worked on before was trying to use
I worked on before was trying to use
simulation state to reset the agent to
simulation state to reset the agent to
anywhere I want. Like you know the go
anywhere I want. Like you know the go
explore paper. Oh yeah. I I made a
explore paper. Oh yeah. I I made a
version probably like I mean code. They
version probably like I mean code. They
didn't have code for that one, but like
didn't have code for that one, but like
a much better version of it. It's called
a much better version of it. It's called
reverse for curriculum learning. Yeah,
reverse for curriculum learning. Yeah,
that would work for robotics. That
that would work for robotics. That
should just work. Yes, I am I have one
should just work. Yes, I am I have one
student trying to make that work with
student trying to make that work with
PTO now because we originally used SACE
PTO now because we originally used SACE
back when GPU summation wasn't a thing.
back when GPU summation wasn't a thing.
But yeah, that would be the way I would
But yeah, that would be the way I would
approach for simulation based learning
approach for simulation based learning
demonstrations, which is use state to
demonstrations, which is use state to
mitigate all the exploration problems.
mitigate all the exploration problems.
Um, yeah, I don't have to do any fancy
Um, yeah, I don't have to do any fancy
loss function actually. I don't I don't
loss function actually. I don't I don't
actually I just do curriculum learning
actually I just do curriculum learning
and state setting. Um I know there's
and state setting. Um I know there's
some fancier methods that try to do like
some fancier methods that try to do like
I don't know if you heard of method
I don't know if you heard of method
called DAPG demonstration augmented
called DAPG demonstration augmented
policy gradient. No they changed the pol
policy gradient. No they changed the pol
policy gradient a little bit by use with
policy gradient a little bit by use with
demonstration data and it's okay. I
demonstration data and it's okay. I
don't think it's very stable. Um it's
don't think it's very stable. Um it's
like very old papers from like 2018. U
like very old papers from like 2018. U
but that's still one of the more popular
but that's still one of the more popular
baselines for on policy learning from
baselines for on policy learning from
demonstrations if you don't use
demonstrations if you don't use
simulation state at least.
simulation state at least.
Um, let's just see. Let's see how much
Um, let's just see. Let's see how much
of a let's see if if this just makes a
of a let's see if if this just makes a
difference or not because it like it
difference or not because it like it
it's possible that it doesn't like
it's possible that it doesn't like
because it's a pretty different domain.
because it's a pretty different domain.
But my hope is that between messing with
But my hope is that between messing with
the simulation fidelity and everything,
the simulation fidelity and everything,
we should be able to get something. And
we should be able to get something. And
then uh if that starts kind of working
then uh if that starts kind of working
then I'm gonna have to ask you about
then I'm gonna have to ask you about
like control speed and domain
like control speed and domain
randomization and stuff because like my
randomization and stuff because like my
kind of my impression on a lot of these
kind of my impression on a lot of these
things is just like a really fast and
things is just like a really fast and
loose and well randomized sim should get
loose and well randomized sim should get
you very very far. um including like
you very very far. um including like
let's say that you wanted to mix in some
let's say that you wanted to mix in some
slower sim, right? Then I'd have to
slower sim, right? Then I'd have to
figure out how you do that from an
figure out how you do that from an
instructor perspective with the way that
instructor perspective with the way that
your GP sims are set up, but you should
your GP sims are set up, but you should
be able to do something like that. Wait,
be able to do something like that. Wait,
what do you mean mix in slower sims like
what do you mean mix in slower sims like
our rendering ones? Well, you wouldn't
our rendering ones? Well, you wouldn't
be able to go state to rendering, but
be able to go state to rendering, but
let's say that you had like a setting of
let's say that you had like a setting of
the sim that's domain randomized to be
the sim that's domain randomized to be
super low fidelity and then a setting
super low fidelity and then a setting
that's randomized to be like that's
that's randomized to be like that's
super high fidelity. Ah, yes. That's a
super high fidelity. Ah, yes. That's a
very interesting thing. Um I actually
very interesting thing. Um I actually
have one research project where we're
have one research project where we're
trying to explore how much curriculum
trying to explore how much curriculum
learning we can do on the physics and
learning we can do on the physics and
the renderer. We have we will have
the renderer. We have we will have
options in the future to modify the
options in the future to modify the
fidelity in many ways. Um obviously the
fidelity in many ways. Um obviously the
physics ones are
physics ones are
I have a way that you could this with
I have a way that you could this with
puffer. I you'd have to make separate
puffer. I you'd have to make separate
batches of the sim. I don't know how
batches of the sim. I don't know how
well it would work, but like essentially
well it would work, but like essentially
you could make like say you could make
you could make like say you could make
like four batches of Sims, three of
like four batches of Sims, three of
which are low fidelity and one of which
which are low fidelity and one of which
is high fidelity and then you cycle
is high fidelity and then you cycle
through them, you only get the highest
through them, you only get the highest
fidelity sim like a quarter of the time,
fidelity sim like a quarter of the time,
for instance. You can over time you
for instance. You can over time you
start to use more of the high fidelity
start to use more of the high fidelity
data, right? You can do that as well.
data, right? You can do that as well.
The only thing I don't know about how it
The only thing I don't know about how it
works in your case is like this the
works in your case is like this the
highfidelity sims are slower. You have
highfidelity sims are slower. You have
to set it up in a way that you don't get
to set it up in a way that you don't get
time bottlenecked by the slowest sim,
time bottlenecked by the slowest sim,
right?
right?
I see. Um I'm not exactly sure how
I see. Um I'm not exactly sure how
you're Well, if you're running these
you're Well, if you're running these
processes isolated, right, one of them
processes isolated, right, one of them
is not going to affect the other one
is not going to affect the other one
anyway, right? I think because you do
anyway, right? I think because you do
batch sim the way we do we're not but
batch sim the way we do we're not but
you you have batch sim, don't you? like
you you have batch sim, don't you? like
each each enemy is using separate CUDA
each each enemy is using separate CUDA
cores. Yeah. Yes. Yes. That's that'll be
cores. Yeah. Yes. Yes. That's that'll be
a problem.
a problem.
This will get pretty deep into sim. I
This will get pretty deep into sim. I
see. So in Puffer, we can just do domain
see. So in Puffer, we can just do domain
randomization for free pretty much
randomization for free pretty much
because our M's are serial on each core,
because our M's are serial on each core,
but like the fast ones and the slow
but like the fast ones and the slow
ones, they all average out.
ones, they all average out.
Okay. So yeah, there's some sim design
Okay. So yeah, there's some sim design
things to consider here. But basically,
things to consider here. But basically,
I think that if if this actually does
I think that if if this actually does
give us enough lift to like be worth
give us enough lift to like be worth
looking into further, um there's a lot
looking into further, um there's a lot
that you can do in the hyper space based
that you can do in the hyper space based
on what we have here.
on what we have here.
Nice. Like that lel implementation for
Nice. Like that lel implementation for
instance, my guess will be that even if
instance, my guess will be that even if
you make the sim dramatically faster,
you make the sim dramatically faster,
you're going to get bottlenecked by
you're going to get bottlenecked by
other sources overhead quite quickly.
other sources overhead quite quickly.
But we don't. Yeah. Like my lean roar
But we don't. Yeah. Like my lean roar
version for SAC and PO like you know
version for SAC and PO like you know
like 20 to 50% of the time spent on
like 20 to 50% of the time spent on
updates. Yeah. Uh right. So I mean like
updates. Yeah. Uh right. So I mean like
you see our default out of the box it's
you see our default out of the box it's
like 5% on updates. Now it'll go up if
like 5% on updates. Now it'll go up if
we increase update epochs obviously but
we increase update epochs obviously but
like there other design like there's
like there other design like there's
several sources of slowness right
several sources of slowness right
there's overhead in the trainer itself.
there's overhead in the trainer itself.
There's optimization for specific batch
There's optimization for specific batch
sizes and mini batch sizes. Like some of
sizes and mini batch sizes. Like some of
it is the implementation of itself. Some
it is the implementation of itself. Some
of it's just the settings. We have all
of it's just the settings. We have all
that figured out basically the high perf
that figured out basically the high perf
case already.
case already.
Nice.
Nice.
Okay, I also just pushed to that branch
Okay, I also just pushed to that branch
my fix for the back end thing. So you
my fix for the back end thing. So you
can just put physics cuda col
can just put physics cuda col
number and it should work. I hope. Well,
number and it should work. I hope. Well,
okay. So, I'm going to I'm going to go
okay. So, I'm going to I'm going to go
work on this for a little bit. I'm going
work on this for a little bit. I'm going
to see if I can find like anything cool.
to see if I can find like anything cool.
I'm going to try to like basically
I'm going to try to like basically
speedrun the PC cube task and then see
speedrun the PC cube task and then see
if I can use that to like solve some
if I can use that to like solve some
harder stuff. Awesome. Cool. Yeah. Um,
harder stuff. Awesome. Cool. Yeah. Um,
we'll do RGB eventually. We'll do RGB
we'll do RGB eventually. We'll do RGB
eventually. Um, I I know that's probably
eventually. Um, I I know that's probably
going to be a little tougher because
going to be a little tougher because
that just gets way slower, but we'll
that just gets way slower, but we'll
we'll cross that bridge when we get
we'll cross that bridge when we get
there. Mhm. Okay, nice.
there. Mhm. Okay, nice.
Yeah, look forward to it. I'm going to
Yeah, look forward to it. I'm going to
hop for now, but yeah, thanks for
hop for now, but yeah, thanks for
dropping by and thanks for the the
dropping by and thanks for the the
assistance. Yes, see you. Yeah,
assistance. Yes, see you. Yeah,
that was fun.
that was fun.
Cool. YouTube folks, I will be right
Cool. YouTube folks, I will be right
back. Use the restroom real quick and
back. Use the restroom real quick and
then we will uh using all that
then we will uh using all that
information we just got, we will
information we just got, we will
robotics.
robotics.
Be right back.
respond to this thing.
All All right.
All
right.
right.
Do the uh let's do the robotics thing.
Do the uh let's do the robotics thing.
Time for science.
Time for science.
So,
So,
a few quick tests. Uh, first
six times.
six times.
Let's do 3 million.
Annie pick cube
Annie pick cube
tag.
First we're going to see if this thing
First we're going to see if this thing
can actually solve indecent wall clock
can actually solve indecent wall clock
these settings. Uh we haven't run this
these settings. Uh we haven't run this
before because this is going to do
before because this is going to do
Whoops.
Whoops.
Unexpected keyword sim freak.
Okay, we'll just not do this yet.
Roll freak. Sim freak.
What is going on here?
Ah,
okay.
This ought to work. And uh the question
This ought to work. And uh the question
here
here
is if we can learn this in a reasonable
is if we can learn this in a reasonable
amount of time and then after this we
amount of time and then after this we
will we'll basically tune this for uh
will we'll basically tune this for uh
even faster potentially.
I just want to try messing with the uh
I just want to try messing with the uh
update epochs real quick
update epochs real quick
and then we'll try messing with the
and then we'll try messing with the
simulation resolution.
Yeah, I think I need to increase it a
Yeah, I think I need to increase it a
little bit because
little bit because
it is learning but not fast enough.
the heck.
I don't think you should be trapping
I don't think you should be trapping
terminals.
Okay. So this thing is
Okay. So this thing is
it's training,
but it's not training anywhere near as
but it's not training anywhere near as
well.
well.
I guess it's just there's a limitation
I guess it's just there's a limitation
to how much you can get by just scaling
to how much you can get by just scaling
the batch size in these
which is what you would expect. That's
which is what you would expect. That's
fine.
So in that case then there's no point in
So in that case then there's no point in
us running this distributed at all for
us running this distributed at all for
this specific task which again fine.
We will rerun the single GPU task just
We will rerun the single GPU task just
to make sure that it still works.
this should give us a clean solve curve.
this should give us a clean solve curve.
And of course,
Okay. So this is now giving us
the expected curve.
Another.
Oh yeah, right here.
Just make sure that we get the
bars.
So, and we're going to try to do like
So, and we're going to try to do like
sim frequency
like 20 or something
like 20 or something
and see if it still solves.
and see if it still solves.
I think that should be I don't know.
Yeah. Because if you can increase if you
Yeah. Because if you can increase if you
can't increase the throughput easily by
can't increase the throughput easily by
increasing the number of ends
increasing the number of ends
at least we can increase the throughput
at least we can increase the throughput
by increasing the M speed
by increasing the M speed
and then the question will just be how
and then the question will just be how
much does the uh the simulation fidelity
much does the uh the simulation fidelity
hurt you?
Some robotics people tell me it matters
Some robotics people tell me it matters
a lot. Um,
a lot. Um,
let's just say I don't believe them.
We will see. But for now, I don't
We will see. But for now, I don't
believe them.
believe them.
We'll see if Puffer can do it.
All
right. So, 11.5ish mil and 4 minutes. 4
right. So, 11.5ish mil and 4 minutes. 4
minutes to train a policy. I don't know
minutes to train a policy. I don't know
about you, but four minutes, that's way
about you, but four minutes, that's way
too long.
What happens if I cut this to uh to 20?
What happens if I cut this to uh to 20?
What happens
according to stone? It should just get
according to stone? It should just get
five times faster.
They're
Hello. This might start to sound dumb,
Hello. This might start to sound dumb,
but I saw
but I saw
you started your PhD in 2019 and saw
you started your PhD in 2019 and saw
some words from your GitHub. People used
some words from your GitHub. People used
the word agents like they do now, or is
the word agents like they do now, or is
that a buzz word? Yeah. So, here's the
that a buzz word? Yeah. So, here's the
thing. Uh, agent was always an RL term
thing. Uh, agent was always an RL term
and then some dumb LLM people came along
and then some dumb LLM people came along
and decided that was their word now. So
and decided that was their word now. So
we still talk about agents as our models
we still talk about agents as our models
that interact with the environment. We
that interact with the environment. We
train them uh through interaction. They
train them uh through interaction. They
are interaction models. They're agents,
are interaction models. They're agents,
right? Apparently now LM's run in a for
right? Apparently now LM's run in a for
loop or agents or whatever, but we still
loop or agents or whatever, but we still
use the word the way that we always did.
Got that error when I try to switch.
Got that error when I try to switch.
Sim freak too low. Simulator becomes
Sim freak too low. Simulator becomes
inaccurate. It might have ns.
inaccurate. It might have ns.
Dang.
control freak for higher fake FPS.
control freak for higher fake FPS.
Really want higher fake FPS though.
Yeah.
Yeah.
So, yeah. No, agent is a real RL word.
So, yeah. No, agent is a real RL word.
It just doesn't mean the thing that the
It just doesn't mean the thing that the
LLM people think it means.
Okay, this is 80K. Let's see if this is
Okay, this is 80K. Let's see if this is
stable.
uses it. Yeah, just ignore the SF tech
uses it. Yeah, just ignore the SF tech
bros. All I can say there are people
bros. All I can say there are people
actually building legitimate stuff. You
actually building legitimate stuff. You
just have to find them.
Like go ahead and download Puffer Lib
Like go ahead and download Puffer Lib
and see for So,
Okay. So, so far,
Okay. So, so far,
uh, this seems fine.
uh, this seems fine.
We're going to see how much like how
We're going to see how much like how
ridiculously low we can crank the
ridiculously low we can crank the
fidelity.
Okay.
So if this converges then it seems like
So if this converges then it seems like
we can just get
we can just get
whatever that is plus 50% for free.
Not fast enough for my liking yet
Not fast enough for my liking yet
though.
Okay. 12 mil solve. Pretty much
Okay. 12 mil solve. Pretty much
identical curves. Yeah. Test or little
identical curves. Yeah. Test or little
lower. It doesn't matter. Same same
lower. It doesn't matter. Same same
solve curve. Yeah.
solve curve. Yeah.
Hey BDF, we're in the middle of solving
Hey BDF, we're in the middle of solving
robotics.
What happens if I bump control freak up?
What happens if I bump control freak up?
Stone says this is higher fake FPS.
Stone says this is higher fake FPS.
So, we'll see if this actually helps
So, we'll see if this actually helps
learning or not.
Okay,
higher fake FPS. I'm down with this.
higher fake FPS. I'm down with this.
Let's see what it does to the learn
Let's see what it does to the learn
curve,
curve,
whether the data is actually fake or
whether the data is actually fake or
not.
This will probably change the learning
This will probably change the learning
dynamics quite a bit. So, I will not be
dynamics quite a bit. So, I will not be
surprised if this does not help us. We
surprised if this does not help us. We
will see. What are you trying now? I'm
will see. What are you trying now? I'm
trying to make robotics really, really
trying to make robotics really, really
fast while still being stable. I'm
fast while still being stable. I'm
messing with their simulation parameters
messing with their simulation parameters
and seeing if we can still solve
Definitely a gap here.
If it actually does anything.
This is kind of the same as the frame
This is kind of the same as the frame
skip idea.
Yeah, fake FPS confirmed. Basically just
Yeah, fake FPS confirmed. Basically just
chips the curve where it like stretches
chips the curve where it like stretches
the curve.
Okay. So, if that doesn't work, let's
Okay. So, if that doesn't work, let's
let's try to go back to
let's try to go back to
We want this at 20, man.
We want this at 20, man.
saying this isn't stable.
Okay. So
observations probably have ns
Hey, Joseph. What have you been up to
Hey, Joseph. What have you been up to
lately? How's it going? Uh, we are
lately? How's it going? Uh, we are
currently attempting to fix robotics.
currently attempting to fix robotics.
I've got Manny skills set up. We have
I've got Manny skills set up. We have
training. It's decent. Uh, we're trying
training. It's decent. Uh, we're trying
to optimize it to go very, very fast, as
to optimize it to go very, very fast, as
is the tendency with Puffer.
is the tendency with Puffer.
So, I'm currently doing a combination of
So, I'm currently doing a combination of
tuning hyperparams,
tuning hyperparams,
uh, messing with the simulator
uh, messing with the simulator
configuration to see if we can get away
configuration to see if we can get away
with lower fidelity, generally seeing
with lower fidelity, generally seeing
how much speed we can get out of this
how much speed we can get out of this
thing.
Excuse
me.
I'm here for about another hour today.
Previous topics of this stream have
Previous topics of this stream have
included earlier in the day large scale
included earlier in the day large scale
battle sim and quantum mechanics.
battle sim and quantum mechanics.
Which simulator is this? This is this is
Which simulator is this? This is this is
Manny scale specifically. We're just
Manny scale specifically. We're just
using P cube for now as a a simple task
using P cube for now as a a simple task
to test with quickly, but our goal is
to test with quickly, but our goal is
going to be to solve their hardest task
going to be to solve their hardest task
with Puffer.
with Puffer.
And if we do a good job, who knows?
And if we do a good job, who knows?
Maybe all the roboticists will come over
Maybe all the roboticists will come over
and start using puffer lib.
Okay. So, we got nams and hidden
how you convert their sim to puffer
how you convert their sim to puffer
ends.
ends.
A little tiny wrapper.
A little tiny wrapper.
I mean, they already have a vector
I mean, they already have a vector
format. Puffer M's a vector format. It's
format. Puffer M's a vector format. It's
like kind of trivial.
So, they're just using our trainer, not
So, they're just using our trainer, not
really our sim stack, but that's fine.
really our sim stack, but that's fine.
Our trainer is pretty good on its own,
Our trainer is pretty good on its own,
right?
Don't wear ns are getting into
N to numb.
See what that does.
Wait, why is the hidden float 16?
I just noticed that.
Are they doing float 16 by default for
Are they doing float 16 by default for
some reason?
How the heck are we getting float 16?
I did not enable AM or anything.
There might be a bug with the I could
There might be a bug with the I could
see there being a weird bug.
Okay. So, this is the end.
That's super weird.
This is uh lipstick.
Decode actions is in slow 16 somehow.
Decode actions is in slow 16 somehow.
That's bizarre.
Is it specified as float 16?
Nope. Float 32.
Nope. Float 32.
This a me problem.
This a me problem.
I messed this up somehow.
Second, I had multiple continuous
Second, I had multiple continuous
actions. I had this bug.
actions. I had this bug.
Interesting.
Interesting.
So, Spencer, I'm seeing stuff in float
So, Spencer, I'm seeing stuff in float
16,
16,
which should not be happening.
which should not be happening.
Loss of precision can definitely cause
Loss of precision can definitely cause
that. If you're if there's like backward
that. If you're if there's like backward
pass ops happening and float 16, things
pass ops happening and float 16, things
can definitely get screwed up.
can definitely get screwed up.
It's a very weird issue.
Yeah, somehow hidden got puted into
Yeah, somehow hidden got puted into
float 16.
Yeah. So they got into the mean tensor
Yeah. So they got into the mean tensor
or the hidden tensor.
code observations is somehow
it a dictionary
maybe opposite a dictionary
maybe opposite a dictionary
I think it
even going to catch it? Not going to
even going to catch it? Not going to
catch it.
I did this backwards. Is this supposed
I did this backwards. Is this supposed
to be float
Uh, this is weird.
We need to catch this earlier.
Yeah, I'm somehow doing this crap.
Yeah, I'm somehow doing this crap.
How that makes any sense.
LSTM changing
LSTM changing
my uh DT type.
What?
Why the hell is that just doing this?
You think it's the torch zeros thing we
You think it's the torch zeros thing we
set where
the precision is set to float 32 here as
the precision is set to float 32 here as
well.
Eval,
Eval,
this is in training.
this is in training.
You mean um
You mean um
Yeah, this happens in training, man.
Yeah, this happens in training, man.
This literally gets none for the LSTM
This literally gets none for the LSTM
state as input.
See what happens.
How should I design my ends? As I said,
How should I design my ends? As I said,
real life this is continuous
and nothing in the real world is like
and nothing in the real world is like
actually modeled as a continuous process
actually modeled as a continuous process
almost.
almost.
I have fat right
on production.
Yeah, you would just Well, I don't know
Yeah, you would just Well, I don't know
what the actions are because if you're
what the actions are because if you're
like there has to be something you're
like there has to be something you're
interacting with here, right?
interacting with here, right?
A CSV is not a simulation. A CSV is a
A CSV is not a simulation. A CSV is a
data set.
Eight and six different actions.
If it's a day, then presumably if the
If it's a day, then presumably if the
actions influence the results of the
actions influence the results of the
next day, then yeah, each row is a day.
next day, then yeah, each row is a day.
But I don't know how you if you have
But I don't know how you if you have
fixed data for the next step, right? I
fixed data for the next step, right? I
don't know how you have an interactive
don't know how you have an interactive
process. This
every day. Multi second.
Are you like trying to tra build a
Are you like trying to tra build a
trading agent or something?
Yeah, the issue that you're going to run
Yeah, the issue that you're going to run
into there, right?
into there, right?
You'd have to predict deltas or
You'd have to predict deltas or
something. HFT,
something. HFT,
a good way to lose a lot of money is not
a good way to lose a lot of money is not
understanding reinforcement learning and
understanding reinforcement learning and
trying to throw it on HFT. I'm just
trying to throw it on HFT. I'm just
going to warn you. Um,
the problem you're also going to run
the problem you're also going to run
into there is that your data set is not
into there is that your data set is not
an environment. It's a fixed static
an environment. It's a fixed static
archive. Whereas reinforcement learning
archive. Whereas reinforcement learning
is meant to be trained in an interactive
is meant to be trained in an interactive
context.
context.
Um,
you have to reformulate some things a
you have to reformulate some things a
little bit.
You'd basically be trying to like the
You'd basically be trying to like the
actions would be like predict delta to
actions would be like predict delta to
next step or something. But then again,
next step or something. But then again,
you're not benefiting from interaction
you're not benefiting from interaction
at all. Then you have to ask why you're
at all. Then you have to ask why you're
not just training a sequence model.
this a non-stationary
this a non-stationary
it's not an environment at all the real
it's not an environment at all the real
markets an environment static archive a
markets an environment static archive a
CSV as a data That
Right. But like
You'd have to have the sim would have to
You'd have to have the sim would have to
actually be
actually be
the actions would be trades or
the actions would be trades or
something. You'd have to actually sim
something. You'd have to actually sim
trades.
Yeah, you're able to see it, but you
Yeah, you're able to see it, but you
don't have a sim of it. So, unless
don't have a sim of it. So, unless
you're training it on the real
you're training it on the real
environment, which you're not, right?
environment, which you're not, right?
There's an issue
the sim.
Okay. So these observations are like
Okay. So these observations are like
obscene.
The question is whether you're trying to
The question is whether you're trying to
model the influence of your own actions
model the influence of your own actions
or not.
If you're not, then you're way better
If you're not, then you're way better
off just with a sequence model. It's not
off just with a sequence model. It's not
an RL problem.
an RL problem.
If you are, then you need to know what
If you are, then you need to know what
you're doing
you're doing
because it's a lot harder.
Oh yeah, these OBS are not normalized
Oh yeah, these OBS are not normalized
for are they?
Okay. So, we need to do something here.
How hard is it?
Well, essentially you would have to try
Well, essentially you would have to try
to actually build a sim of the market in
to actually build a sim of the market in
order to train it. Then that gets you
order to train it. Then that gets you
unlimited training data, but your SIM
unlimited training data, but your SIM
has to be accurate. You didn't both know
has to be accurate. You didn't both know
how to build a SIM reasonably, and you'd
how to build a SIM reasonably, and you'd
need good knowledge of the market
need good knowledge of the market
dynamics. And you'd have to hope that
dynamics. And you'd have to hope that
this thing even makes any sense. I've
this thing even makes any sense. I've
done a little bit of work in this space.
done a little bit of work in this space.
There are some details.
I you just initially you just build a
I you just initially you just build a
sim that would like try to map and to be
sim that would like try to map and to be
fair there's there's something in that
fair there's there's something in that
space that's kind of similar that we
space that's kind of similar that we
might be able to open source. Um
but yeah, you just I think you just try
but yeah, you just I think you just try
to like predict deltas initially
where you basically you try to what you
where you basically you try to what you
do is you'd assume that the you assume
do is you'd assume that the you assume
you don't move the market and then your
you don't move the market and then your
actions are what to buy, what to sell.
actions are what to buy, what to sell.
I'm telling you though, you're going to
I'm telling you though, you're going to
lose a ton of money if you actually just
lose a ton of money if you actually just
like try to throw this on the real
like try to throw this on the real
market. Hodge podge.
Okay, let's see if this thing still
Okay, let's see if this thing still
trains. I didn't realize that the ops
trains. I didn't realize that the ops
were so poorly normalized.
were so poorly normalized.
Demo.
Demo.
Well, ideally, yes.
How does this not make a huge
How does this not make a huge
difference? Like immediately.
Delta.
This is where things stop making sense,
This is where things stop making sense,
right?
right?
Cuz it's like, you know what the price
Cuz it's like, you know what the price
is now. So you know what the price is on
is now. So you know what the price is on
the next step from the data. So you like
the next step from the data. So you like
technically the best action is to just
technically the best action is to just
buy as much as possible of the thing
buy as much as possible of the thing
that you think is going to go up the
that you think is going to go up the
most.
That's the delta.
Is this thing seriously not trained? Now
I normalize the observations.
I might have to reweep it. Honestly,
Plasma, how's it going?
did lose any money?
No, I didn't throw it on the real
No, I didn't throw it on the real
market. I just made a sim.
I literally don't even bother looking at
I literally don't even bother looking at
my stocks.
my stocks.
I just have like I just have some tech
I just have like I just have some tech
stocks and I don't look at them.
Okay. So, um,
Okay. So, um,
we didn't solve this end, but we figured
we didn't solve this end, but we figured
out something very important here
out something very important here
that their obs magnitudes are crazy.
Index funds. I don't just do index
Index funds. I don't just do index
funds. I have tech stocks.
funds. I have tech stocks.
Yeah.
Uh I also know some people I think I
Uh I also know some people I think I
probably am not allowed to do anything
probably am not allowed to do anything
else adjacent under under that
else adjacent under under that
agreement. So,
like the vast majority of the people
like the vast majority of the people
trying to throw RL on stuff just aren't
trying to throw RL on stuff just aren't
going to know what they're doing enough
going to know what they're doing enough
or things like
You do about this man?
Do I just have to like guess
Do I just have to like guess
a different learning rate or something?
a different learning rate or something?
That seems really silly.
Why don't I just reweep this thing?
Hang on.
Hang on.
Maybe maybe there's like a clipping
Maybe maybe there's like a clipping
thing
thing
going on here
and know how they are doing. I don't
and know how they are doing. I don't
have right technology.
Yeah, like I said, I have some adjacent
Yeah, like I said, I have some adjacent
stuff in this space. I probably can't do
stuff in this space. I probably can't do
like another thing in this space.
like another thing in this space.
Um,
Um,
you're more than welcome though to try
you're more than welcome though to try
to set this up as a pop if you want.
to set this up as a pop if you want.
Just be careful.
Good way to lose money.
I'd have to double check. I think
I'd have to double check. I think
generally though the way most of the
generally though the way most of the
things do is I don't I don't do like
things do is I don't I don't do like
simultaneous things. I don't do like
simultaneous things. I don't do like
things in um
like if I have like a if I have like a
like if I have like a if I have like a
puffer thing formally with a business in
puffer thing formally with a business in
one like very specific area, I'm not
one like very specific area, I'm not
going to do something that's like very
going to do something that's like very
very close to it elsewhere, right?
I'd have to double check specifics, but
I'd have to double check specifics, but
that's generally what we do just by
that's generally what we do just by
policy.
I will solve.
I mean, I think ultimately it comes down
I mean, I think ultimately it comes down
to
to
it comes down to you just need to make a
it comes down to you just need to make a
really good sim of the market, which is
really good sim of the market, which is
very difficult, right?
Probably difficult regardless of what
Probably difficult regardless of what
data you have.
But this does
not have most of does lose money though.
Okay, so Stone says the solvers in the
Okay, so Stone says the solvers in the
physics sim are trying to optimally
physics sim are trying to optimally
figure out how the robot moves and
figure out how the robot moves and
objects collide at a very high DT low
objects collide at a very high DT low
sim frequency
sim frequency
only so many solver iterations. is
only so many solver iterations. is
likely not converging.
This looks substantially more stable
This looks substantially more stable
than before.
than before.
Like learning
Maybe this will just be enough. We'll
Maybe this will just be enough. We'll
see.
Yeah. So, this is a stable solve.
Why you laughing?
cuz I'm trying to figure out what the
cuz I'm trying to figure out what the
hell this is. Like the fact that they
hell this is. Like the fact that they
return you giant observations. I'm
return you giant observations. I'm
asking Stone if like you can just do
asking Stone if like you can just do
forward oiler on this thing.
I have a DM with Stone where I'm asking
I have a DM with Stone where I'm asking
him stupid
him stupid
I'm like, "Hey, what happens if you just
I'm like, "Hey, what happens if you just
use forward oiler on this thing? What if
use forward oiler on this thing? What if
your robotic sim is just x= x + bx * dt?
you use gridl like matrix on observ you
you use gridl like matrix on observ you
can do that
I'm going to see if this solves anything
real fast
I'm messing with the uh I'm messing with
I'm messing with the uh I'm messing with
the simulation fidelity. And apparently,
the simulation fidelity. And apparently,
according to Stone, I'm doing like dumb
according to Stone, I'm doing like dumb
that nobody does in robotics, which
that nobody does in robotics, which
is precisely the way I like things.
suggestion
for market
like matrix.
You can do that technically. Yeah,
You can do that technically. Yeah,
I don't know. People do like comms over
I don't know. People do like comms over
old temporal data if you really have to
old temporal data if you really have to
batch a bunch of it into one
And I got to run for dinner in a few
And I got to run for dinner in a few
minutes as well.
High frequency trading. Yes, I know.
High frequency trading. Yes, I know.
I know what that is.
I do this fast.
The reason I think that's hard, I'll
The reason I think that's hard, I'll
give you this. It's because typically
give you this. It's because typically
you want to have a decent simulator for
you want to have a decent simulator for
the thing that you're trying to mess
the thing that you're trying to mess
with. And uh it's very difficult to
with. And uh it's very difficult to
build a good one of those for the
build a good one of those for the
market. Why?
I'm on Discord.
This isn't you. I don't Oh, one minute
This isn't you. I don't Oh, one minute
ago.
Not it.
Not it.
Hello.
Passing physics step.
Number of physics steps that run
Number of physics steps that run
after each action.
Okay. So, it's just it's hard for it to
Okay. So, it's just it's hard for it to
converge.
converge.
Okay.
Like this was faster, wasn't it?
Yeah, I'm not going to be able to tell
Yeah, I'm not going to be able to tell
you. Like, I'm not going to be able to
you. Like, I'm not going to be able to
answer that, man.
Like, obviously.
Physics
is known to take lesser steps. The DT is
is known to take lesser steps. The DT is
smaller. Okay.
So
like Yes.
Uh I did fix the nans thing Spencer just
Uh I did fix the nans thing Spencer just
by uh clamping the observations and nans
by uh clamping the observations and nans
and numbing them but that doesn't make
and numbing them but that doesn't make
it it trained to like 50% in the same
it it trained to like 50% in the same
number of steps.
So, I think Stone told me this should be
So, I think Stone told me this should be
this should be like theoretically the
this should be like theoretically the
fastest it could possibly go, right?
And I have to run for dinner in a
And I have to run for dinner in a
second. So, for the folks on YouTube,
second. So, for the folks on YouTube,
um, all open source work, we'll be back
um, all open source work, we'll be back
on Monday. Buffer.ai for all the things.
on Monday. Buffer.ai for all the things.
the repo to help me out for free. You
the repo to help me out for free. You
can join the discord to get involved
can join the discord to get involved
with this as well.
Uh help me.
Uh help me.
I obviously can't answer questions like
I obviously can't answer questions like
that, man. Answer general questions. I
that, man. Answer general questions. I
can't tell you like data source things.
can't tell you like data source things.
Um,
Um,
do you know why nans were being
do you know why nans were being
inserted? Yeah, Spencer. So, it's just
inserted? Yeah, Spencer. So, it's just
it's the physics and fidelity.

Kind: captions
Language: en
Okay,
Okay,
this should be us live.
this should be us live.
Hello.
I am all out of sorts this morning.
I am all out of sorts this morning.
Let me at least post this real quick.
Let me at least post this real quick.
Hang on.
Hang on.
Man,
Man,
so um I've been studying quantum physics
so um I've been studying quantum physics
and it's driving me crazy.
I was like watching lectures until I
I was like watching lectures until I
don't know 10 or 11 last night and then
don't know 10 or 11 last night and then
I just couldn't sleep trying to figure
I just couldn't sleep trying to figure
out all these various different things.
out all these various different things.
I'm considering just ordering some
I'm considering just ordering some
lasers and some optical stuff and trying
lasers and some optical stuff and trying
to run some experiments.
to run some experiments.
We'll see. Welcome, Magi.
We'll see. Welcome, Magi.
Let me switch this over to stream view.
Let me switch this over to stream view.
Okay, so we have some cool stuff to go
Okay, so we have some cool stuff to go
over today. Today is not about quantum
over today. Today is not about quantum
physics. Today is about reinforcement
physics. Today is about reinforcement
learning and specifically
learning and specifically
this large scale battle simulator that
this large scale battle simulator that
I've been working on. But first, let's
I've been working on. But first, let's
take a quick look at the experiments
take a quick look at the experiments
that ran overnight. Uh because it looks
that ran overnight. Uh because it looks
like Puffer does robotics. Now, here's a
like Puffer does robotics. Now, here's a
robotics environment.
robotics environment.
Puffer solves it. Where is it? Yeah,
Puffer solves it. Where is it? Yeah,
Puffer solves it perfectly.
Puffer solves it perfectly.
No, no big news there. Puffer kind of
No, no big news there. Puffer kind of
just solves everything. It did need some
just solves everything. It did need some
sweeps. I'm gonna have to grab like the
sweeps. I'm gonna have to grab like the
best parameters out of this and all
best parameters out of this and all
that. And I have to show the guy who
that. And I have to show the guy who
built this sim to see what he thinks we
built this sim to see what he thinks we
should do next with it. But yeah, it's
should do next with it. But yeah, it's
pretty cool. All right, so let's talk
pretty cool. All right, so let's talk
about the uh the battle sim that I've
about the uh the battle sim that I've
been wanting to work on. Also, we can
been wanting to work on. Also, we can
kill this. This has all the data that we
kill this. This has all the data that we
ever need.
ever need.
All right,
I should rename this.
I should rename this.
Started out as like a schooling
Started out as like a schooling
simulator for fish or whatever and did
simulator for fish or whatever and did
crazy things with it.
crazy things with it.
Uh, for some reason it does not want to
Uh, for some reason it does not want to
render, which is weird.
Oh, I bet this is Nvidia drivers.
Yeah, this is Nvidia drivers.
Yeah, this is Nvidia drivers.
All right,
we'll show the sim and then I'll talk
we'll show the sim and then I'll talk
about my plans for what we're going to
about my plans for what we're going to
do with it today.
Actually,
where's Tyler when you need him? I know
where's Tyler when you need him? I know
a physics PhD that I can bother about
a physics PhD that I can bother about
all sorts of insane quantum mechanics
all sorts of insane quantum mechanics
things.
I've been actually trying to understand
I've been actually trying to understand
the uh the math as well.
Not that bad conceptually until you ask
Not that bad conceptually until you ask
me to actually like go solve the
me to actually like go solve the
equations manually.
All right. So, here's the sim. Anyways,
now it doesn't look like much yet. So,
now it doesn't look like much yet. So,
let me just get us a quick very quick
let me just get us a quick very quick
little baseline on this.
just so you can get an idea and then
just so you can get an idea and then
we'll talk about how uh we're going to
we'll talk about how uh we're going to
modify this simulator
modify this simulator
because it sort of works at the moment,
because it sort of works at the moment,
but like I'm not super happy with
but like I'm not super happy with
several things about the way it's
several things about the way it's
designed and I think we can get way more
designed and I think we can get way more
coherent behaviors out of it.
coffee idea.
Tried training default yesterday. Looks
Tried training default yesterday. Looks
like it's not learning quite that much.
like it's not learning quite that much.
Most of the time it's failed. How can I
Most of the time it's failed. How can I
train until it reaches in reward to
train until it reaches in reward to
certain levels?
So I instead of trying to say how can I
So I instead of trying to say how can I
train until it reaches min reward, you
train until it reaches min reward, you
should try to figure out why it's not
should try to figure out why it's not
learning in a reasonable pace because
learning in a reasonable pace because
puffer should solve basically any
puffer should solve basically any
wellposed problem quite well. Like any
wellposed problem quite well. Like any
reasonable well-posed problem should be
reasonable well-posed problem should be
solvable uh quite quickly. You just
solvable uh quite quickly. You just
adjust total time steps up to something
adjust total time steps up to something
reasonable. Uh to give you an idea, most
reasonable. Uh to give you an idea, most
of our simpler ends are solved within
of our simpler ends are solved within
like 50 to 200 million steps and at
like 50 to 200 million steps and at
several million steps per second. That
several million steps per second. That
happens very very quickly.
happens very very quickly.
And almost almost always by default, if
And almost almost always by default, if
you have a reasonable problem that you
you have a reasonable problem that you
think should be of similar complexity to
think should be of similar complexity to
one of our M's that is solved quite
one of our M's that is solved quite
quickly, it's almost always a data
quickly, it's almost always a data
problem. I tried breakout.
problem. I tried breakout.
I mean, you tried breakout.
I mean, you tried breakout.
Okay, here. So, let me show this first
Okay, here. So, let me show this first
and then I'll show you how breakout just
and then I'll show you how breakout just
works.
So, to show you that Puffer is saying
So, to show you that Puffer is saying
like this is a sim
like this is a sim
just learn to do this in the last 20 or
just learn to do this in the last 20 or
30 seconds.
30 seconds.
Okay,
clearly we have something
clearly we have something
semi-reasonable here.
Now, if I just do puffer train, puffer
Now, if I just do puffer train, puffer
breakout out of the box, no setup
breakout out of the box, no setup
changes whatsoever.
Okay. So, this is literally 24 25
Okay. So, this is literally 24 25
seconds.
seconds.
Yeah, exactly.
Yeah, exactly.
So, this is a problem that you used to
So, this is a problem that you used to
have to run this overnight with other
have to run this overnight with other
reinforcement learning libraries. All
reinforcement learning libraries. All
right. And just to show you that I'm
right. And just to show you that I'm
just not making those numbers up,
here's our model playing Breakout.
It plays kind of weird, but note that we
It plays kind of weird, but note that we
didn't tell it to play like a human. We
didn't tell it to play like a human. We
just told it to beat the game. So, it
just told it to beat the game. So, it
doesn't matter if it waves the paddle
doesn't matter if it waves the paddle
around wildly, as long as it's there
around wildly, as long as it's there
when it needs to be to actually hit the
when it needs to be to actually hit the
puffer back.
So,
So,
I don't know why it didn't why you say
I don't know why it didn't why you say
why you have it like not working, but it
why you have it like not working, but it
it kind of just works out of the box,
it kind of just works out of the box,
right?
This is just Puffer 3.0. Like I I don't
This is just Puffer 3.0. Like I I don't
have any local changes or anything to
have any local changes or anything to
this.
Now, it's possible it takes you like 10
Now, it's possible it takes you like 10
minutes or something because you're not
minutes or something because you're not
training on a GPU,
training on a GPU,
but there's like I can only work so much
but there's like I can only work so much
magic, right? It's literally training 20
magic, right? It's literally training 20
times faster on your CPU than you'd be
times faster on your CPU than you'd be
able to train it on GPU with other
able to train it on GPU with other
libraries uh with their defaults the way
libraries uh with their defaults the way
that they're set up. So, it does get to
that they're set up. So, it does get to
be like, you know, several hundred times
be like, you know, several hundred times
faster uh if you actually are training
faster uh if you actually are training
it on like a reasonable hardware setup.
it on like a reasonable hardware setup.
This is literally just my local desktop
This is literally just my local desktop
right here. Like this is not running
right here. Like this is not running
remotely or anything. It's like a nice
remotely or anything. It's like a nice
local desktop, but it is just a desktop.
Okay.
How do you understand when to stop or
How do you understand when to stop or
when it's not learning anymore? Right
when it's not learning anymore? Right
here, the game is scored from like zero
here, the game is scored from like zero
to I think it's like 850 something or
to I think it's like 850 something or
860 something. And most of our
860 something. And most of our
environments to make it even easier for
environments to make it even easier for
you, we have a zero to one normalized.
you, we have a zero to one normalized.
So this is 98% right there of the
So this is 98% right there of the
maximum score.
maximum score.
See this? And you can do d- Neptune or
See this? And you can do d- Neptune or
D-1B to get graphs of these things. So
D-1B to get graphs of these things. So
when I do this, this is all done
when I do this, this is all done
automatically for you. Just dash Neptune
automatically for you. Just dash Neptune
or whatever you get all these graphs.
Okay, back to the battle ends.
I want to rename these real quick.
on tensorboard narl, I was dealing with
on tensorboard narl, I was dealing with
a min reward for each episode.
a min reward for each episode.
Okay, it's a little bit more subtle why
Okay, it's a little bit more subtle why
that's a dumb thing to do, but please
that's a dumb thing to do, but please
take my word on it that that's kind of a
take my word on it that that's kind of a
dumb thing to do. Um, it's way better to
dumb thing to do. Um, it's way better to
just run it for a certain number of
just run it for a certain number of
steps or a certain amount of time or
steps or a certain amount of time or
whatever. um and and just observe the
whatever. um and and just observe the
results from there.
Like don't try to don't try to like make
Like don't try to don't try to like make
puffer lib work like RLIB. Like RLIB is
puffer lib work like RLIB. Like RLIB is
literally the worst RL library in
literally the worst RL library in
existence. And I'm sorry to say that
existence. And I'm sorry to say that
because I know some of the devs, they
because I know some of the devs, they
tried very hard on it. Like they
tried very hard on it. Like they
genuinely wanted to do this stuff, but
genuinely wanted to do this stuff, but
it's just it's simply not the way to
it's just it's simply not the way to
build a reinforcement learning library.
build a reinforcement learning library.
Um, the reasons for it are a little bit
Um, the reasons for it are a little bit
subtle, but like the way that big tech
subtle, but like the way that big tech
builds libraries is not the way that you
builds libraries is not the way that you
can approach reinforcement learning.
can approach reinforcement learning.
I've said this so many times and it's so
I've said this so many times and it's so
difficult to get people to understand
difficult to get people to understand
this, but it is truly truly important.
this, but it is truly truly important.
Um,
Um,
so yeah, rather than trying to make
so yeah, rather than trying to make
puffer liib look like rlib, just try to
puffer liib look like rlib, just try to
use puffer lilib and then when something
use puffer lilib and then when something
doesn't make sense on its own terms, not
doesn't make sense on its own terms, not
in comparison to another library, then
in comparison to another library, then
let me know and I'm here all day to
let me know and I'm here all day to
help.
That makes sense.
Thanks. I'm pretty impressed.
Thanks. I'm pretty impressed.
I'd hope so, man. I do this all day.
I'd hope so, man. I do this all day.
This is the only thing I do. I'd better
This is the only thing I do. I'd better
be good at it, right?
That's kind of how it goes.
I mean, I can try to give you a little
I mean, I can try to give you a little
bit of the intuition.
bit of the intuition.
3 mil SPS. We get faster than 3 million,
3 mil SPS. We get faster than 3 million,
honestly. Like, puffer lib, we can
honestly. Like, puffer lib, we can
probably make it several times faster
probably make it several times faster
even than it is now. And I have run
even than it is now. And I have run
tests up to 20 million. Uh, it's like
tests up to 20 million. Uh, it's like
silly cases, but I've gotten it up to 20
silly cases, but I've gotten it up to 20
million steps per second on one GPU. So,
million steps per second on one GPU. So,
here, let me try to just give you a
here, let me try to just give you a
little bit of the intuition because this
little bit of the intuition because this
is honestly uh local machine config.
is honestly uh local machine config.
This is a 4090 with like a 9950X. It's
This is a 4090 with like a 9950X. It's
like one of the best desktop setups you
like one of the best desktop setups you
can buy. I also have one with a 5090
can buy. I also have one with a 5090
sitting on the rack behind me. Uh, but
sitting on the rack behind me. Uh, but
yeah, it's a good desktop, but it is
yeah, it's a good desktop, but it is
just a desktop. It's not like server
just a desktop. It's not like server
grade hardware.
I don't have like H200s or something.
I don't have like H200s or something.
So, let me let me just try to convey
So, let me let me just try to convey
this because like this is honestly where
this because like this is honestly where
everybody like trips and stump like
everybody like trips and stump like
trips and falls and breaks their legs in
trips and falls and breaks their legs in
reinforcement learning. Um, the reason
reinforcement learning. Um, the reason
that you don't do stuff like you do it
that you don't do stuff like you do it
in big tech engineering, in
in big tech engineering, in
reinforcement learning specifically, is
reinforcement learning specifically, is
because the price of overabraction and
because the price of overabraction and
the price of error is incredibly higher
the price of error is incredibly higher
in reinforcement learning than in
in reinforcement learning than in
everything else. That is to say, it's
everything else. That is to say, it's
kind of always a nice thing to keep
kind of always a nice thing to keep
stuff simple, but in reinforcement
stuff simple, but in reinforcement
learning specifically, if you don't keep
learning specifically, if you don't keep
stuff simple, you will pay dearly
stuff simple, you will pay dearly
because the bugs are just going to be
because the bugs are just going to be
the agent doesn't train. Okay? And it's
the agent doesn't train. Okay? And it's
even worse than the rest of supervised
even worse than the rest of supervised
learning because your data set is part
learning because your data set is part
of the generation loop as well and you
of the generation loop as well and you
have this whole additional hard uh
have this whole additional hard uh
infrastructure stack for dealing with
infrastructure stack for dealing with
the data. So it is truly this like open
the data. So it is truly this like open
feedback loop system where you have like
feedback loop system where you have like
no sanity check on anything.
no sanity check on anything.
All right, you can do your best with
All right, you can do your best with
logging and stuff, but you will still
logging and stuff, but you will still
end up with crazy issues. And there's
end up with crazy issues. And there's
not even a fundamental science of it
not even a fundamental science of it
that tells you how stuff should actually
that tells you how stuff should actually
work that fits any of what we've
work that fits any of what we've
observed. So with all of this, you would
observed. So with all of this, you would
be insane to not build stuff as
be insane to not build stuff as
absolutely dead simple as possible. And
absolutely dead simple as possible. And
that is at odds with how big tech builds
that is at odds with how big tech builds
stuff. And the proof of this, the proof
stuff. And the proof of this, the proof
that I am right here is that every
that I am right here is that every
single modular abstracted RL library
single modular abstracted RL library
that looks like every other piece of
that looks like every other piece of
software that you would see in big tech
software that you would see in big tech
has failed horribly.
has failed horribly.
That is the proof. And it is actually
That is the proof. And it is actually
the simpler, lighter weight, more
the simpler, lighter weight, more
compact libraries that are orders of
compact libraries that are orders of
magnitude faster uh and are useful on
magnitude faster uh and are useful on
much larger projects.
If you internalize that, you will go
If you internalize that, you will go
very far.
If you do not, you will become stuck.
If you do not, you will become stuck.
That is simply how it is.
So, a lot of my job here is to try to
So, a lot of my job here is to try to
make this simpler and simpler and
make this simpler and simpler and
simpler and faster and faster and faster
simpler and faster and faster and faster
so that it's actually easier to intuitit
so that it's actually easier to intuitit
what's going on here. And this is why we
what's going on here. And this is why we
have brand new programmers getting into
have brand new programmers getting into
reinforcement learning now when before
reinforcement learning now when before
like nobody even knew what was going on
like nobody even knew what was going on
with a PhD in the exact topic. But it's
with a PhD in the exact topic. But it's
still hard and it's still going to
still hard and it's still going to
require some, you know, mental
require some, you know, mental
adjustment if that makes sense.
Okay, good. So, this still runs. Just
Okay, good. So, this still runs. Just
renamed it. No big deal.
Okay, cool.
So, all I did so far is renamed the
So, all I did so far is renamed the
environment. Now, I haven't looked at
environment. Now, I haven't looked at
this thing in like a week and a half.
this thing in like a week and a half.
Let's actually think about what we want
Let's actually think about what we want
to do with this.
There are a couple big issues at the
There are a couple big issues at the
moment.
moment.
I think that the biggest there the two
I think that the biggest there the two
biggest issues right now are figuring
biggest issues right now are figuring
out how to do the observations in a sane
out how to do the observations in a sane
way, which that takes a little bit of
way, which that takes a little bit of
code, but isn't that hard. Uh the other
code, but isn't that hard. Uh the other
thing is how how do we do evaluation
thing is how how do we do evaluation
metrics?
metrics?
I kind of want to just get some code in
I kind of want to just get some code in
while I'm fresh and then we'll think
while I'm fresh and then we'll think
about evaluation metrics after.
Uh, I forgot to change the resources.
Okay. So, you have in this simple demo,
Okay. So, you have in this simple demo,
you've got two armies. They fight yada
you've got two armies. They fight yada
yada.
yada.
They can't actually see each other right
They can't actually see each other right
now is the problem. Uh, also the physics
now is the problem. Uh, also the physics
sucks. So,
sucks. So,
let's fix them not being able to see
let's fix them not being able to see
each other first.
The only way that I know to do this
The only way that I know to do this
without complicating it a lot is
without complicating it a lot is
horribly slow, but we'll just restrict
horribly slow, but we'll just restrict
this to smaller armies just for now, and
this to smaller armies just for now, and
then I'll come up with a better way to
then I'll come up with a better way to
do it later.
Yeah. So,
Yeah. So,
actually, I don't think it's going to be
actually, I don't think it's going to be
all that much code
What's your thoughts on time series
What's your thoughts on time series
more specifically? data that has
more specifically? data that has
sequencing information.
sequencing information.
That's like literally reinforcement
That's like literally reinforcement
learning by default,
learning by default,
right? It's an interaction problem.
right? It's an interaction problem.
You're an agent. You see the world, you
You're an agent. You see the world, you
take an action, the world changes, you
take an action, the world changes, you
take another action, the world changes
take another action, the world changes
more. That is almost by definition a
more. That is almost by definition a
time series problem. And in fact, the
time series problem. And in fact, the
problems that you can solve without
problems that you can solve without
having time series information are a
having time series information are a
specific subclass and almost an
specific subclass and almost an
exception to the rule. So you don't have
exception to the rule. So you don't have
to do anything like just by default.
to do anything like just by default.
That's what reinforcement learning does.
Oh yeah, use our recurrent model by
Oh yeah, use our recurrent model by
default. So it actually has some memory,
default. So it actually has some memory,
but that's about it.
It's a non-stationary problem.
It's a non-stationary problem.
Reinforcement learning is by definition
Reinforcement learning is by definition
non-stationary because your actions
non-stationary because your actions
change the environment. Doesn't matter.
The question should be more like why the
The question should be more like why the
hell does any of this work at all? And
hell does any of this work at all? And
we don't really know, but we've gotten
we don't really know, but we've gotten
pretty good at making it to
We don't need square root f here. We'll
We don't need square root f here. We'll
save this little bit of compute. It's
save this little bit of compute. It's
negligible, but still
Question is going to be how do we sort
Question is going to be how do we sort
this
quick sword's just going to give us Ah,
quick sword's just going to give us Ah,
yeah. That's annoying.
any technique or learning algorithm with
any technique or learning algorithm with
it detects and adopt and change policy
it detects and adopt and change policy
based on long sequence.
I mean, it's literally all of them. It's
I mean, it's literally all of them. It's
just like the longer the sequence, the
just like the longer the sequence, the
worse they work. Yes, there's research
worse they work. Yes, there's research
directed to this area. I find a lot of
directed to this area. I find a lot of
the results on like specific RL for like
the results on like specific RL for like
long horizon or this and that very
long horizon or this and that very
unconvincing though.
Look, if you have a problem and your
Look, if you have a problem and your
problem does not look like it's harder
problem does not look like it's harder
than the problems that we have in
than the problems that we have in
Puffer, the default thing will just
Puffer, the default thing will just
work. If you have something that you
work. If you have something that you
think looks harder, then come discuss
think looks harder, then come discuss
it.
I really don't want to have to write my
I really don't want to have to write my
own sort.
own sort.
Not because it's difficult, but because
Not because it's difficult, but because
optimizing that is a pain.
If we assume that we just ignore ties, I
If we assume that we just ignore ties, I
can do it in a sort of a hacky way.
Um, it's Yeah, I have to do an argu
Um, it's Yeah, I have to do an argu
though.
though.
I'm going to be lazy with it for now.
Wait, what the hell is this?
Did it just come up with something
Did it just come up with something
insane or is this somehow correct?
Yeah, that's what I'm going to use
Yeah, that's what I'm going to use
wouldn't. It's just annoying because I
wouldn't. It's just annoying because I
have to do an arg sort. There's There's
have to do an arg sort. There's There's
no like trivial way to just do an
no like trivial way to just do an
argort, right?
I guess you just make like a little
I guess you just make like a little
strct or something.
Maybe we'll just do it that way. Maybe
Maybe we'll just do it that way. Maybe
that'll be easier.
graph neural net. What's that have to do
graph neural net. What's that have to do
with anything, Finn?
Welcome though.
That's lit like that's not an RL
That's lit like that's not an RL
problem. That's a that's a perception
problem. That's a that's a perception
problem. You have no control over the
problem. You have no control over the
environment. You don't use reinforcement
environment. You don't use reinforcement
learning for problems where you don't
learning for problems where you don't
have any control over the environment.
have any control over the environment.
Typically,
unless you're forced to
reinforcement learning, like if you had
reinforcement learning, like if you had
to just pick one word, right, for
to just pick one word, right, for
reinforcement learning, like the key
reinforcement learning, like the key
essence of it is interaction. There's no
essence of it is interaction. There's no
interaction.
interaction.
Sometimes people use RL for stuff, but
Sometimes people use RL for stuff, but
it's not like a clear fit.
I forgot to name this.
the high speed,
but you're not trying to
but you're not trying to
you're you're just moving yourself based
you're you're just moving yourself based
on a response to what the other things
on a response to what the other things
in the environment are doing.
in the environment are doing.
You literally don't need to change the
You literally don't need to change the
standard reinforcement formula uh
standard reinforcement formula uh
reinforcement learning formulation at
reinforcement learning formulation at
all to handle this case.
It's like very tempting to think that
It's like very tempting to think that
there's something special about a lot of
there's something special about a lot of
problems where like you need some fancy
problems where like you need some fancy
new algorithm and then you go spend
new algorithm and then you go spend
three months doing uh a whole bunch of
three months doing uh a whole bunch of
research on that and then your like
research on that and then your like
fancy new method is worse than the
fancy new method is worse than the
baseline. Like every single RLP PhD
baseline. Like every single RLP PhD
pretty much to a tea has done this at
pretty much to a tea has done this at
some point.
some point.
The thing is like it's often the case
The thing is like it's often the case
that your problem really just isn't that
that your problem really just isn't that
special
special
and there's not really anything about it
and there's not really anything about it
that makes the standard thing not work.
that makes the standard thing not work.
And if you want to make something that's
And if you want to make something that's
just better than the standard and that's
just better than the standard and that's
a lot of work, which by the way we did.
a lot of work, which by the way we did.
We have something that's better than the
We have something that's better than the
standard uh in Puffer Lib 3.0. It's this
standard uh in Puffer Lib 3.0. It's this
huge leap. It took us 30,000 experiments
huge leap. It took us 30,000 experiments
over a ton of different environments to
over a ton of different environments to
make that happen.
Okay. So now we have this thing. We have
Okay. So now we have this thing. We have
these agent obs. And now what we can do
these agent obs. And now what we can do
is we can quick sort the agent obs. We
is we can quick sort the agent obs. We
just need a comparison function.
There you go.
There you go.
I think that's right.
And now what we do is we simply iterate
And now what we do is we simply iterate
through them again.
in the LSTM give a better yes we use
in the LSTM give a better yes we use
LSTM by default for like everything
that 3 million step per second result or
that 3 million step per second result or
5 million step per second result
5 million step per second result
whatever that's including an LSTM Ready?
Do we need to filter this by theta?
Let's just do it this way for now to
Let's just do it this way for now to
see.
is there a way we can use one agent
is there a way we can use one agent
steps as an observation space for other
steps as an observation space for other
set of agents
depends what you means by steps their
depends what you means by steps their
action specifically I mean if the other
action specifically I mean if the other
you can make the other agents see the
you can make the other agents see the
other agents as they're moving around
other agents as they're moving around
right agents can see each other as
right agents can see each other as
they're moving around. If you want to
they're moving around. If you want to
specifically observe the actions that
specifically observe the actions that
they take, yes, you can do that. You
they take, yes, you can do that. You
just have to add it into the environment
just have to add it into the environment
as the uh observation space.
as the uh observation space.
It's a little odd to do though because
It's a little odd to do though because
normally you can't get that information
normally you can't get that information
in the real world. So, it kind of
in the real world. So, it kind of
depends on the problem context.
know it's own unit type, right?
One, two, three, four, five, six,
19.
19.
19 + 8
army. So yeah, this is 3 *
army. So yeah, this is 3 *
16.
And we'll basically just have to see
Oh, you're dumb.
Oh, you're dumb.
Hang on.
I don't know why I did this in two
I don't know why I did this in two
dimensions.
There we go. That's three dimensions.
This
4 * 16.
So now they should be able to see the
So now they should be able to see the
nearest 16 agents to themselves.
And we have to modify this environment
And we have to modify this environment
quite a bit because this is going to
quite a bit because this is going to
incredibly slow as written.
How about continuous space? What am I
How about continuous space? What am I
going to say? Doesn't matter. Throw it
going to say? Doesn't matter. Throw it
into the algorithm.
into the algorithm.
We literally have it right here. Doesn't
We literally have it right here. Doesn't
matter. Throw it in the algorithm.
That's the key technique to observe.
That's the key technique to observe.
What do you mean?
What do you mean?
No, not really. It's just that a lot of
No, not really. It's just that a lot of
the things that you're specifically
the things that you're specifically
asking about are just things that we
asking about are just things that we
that kind of don't matter to RL. It's
that kind of don't matter to RL. It's
like, oh, it's a continuous versus a
like, oh, it's a continuous versus a
discrete value. Whatever. Stick it in
discrete value. Whatever. Stick it in
the observations and just don't do it in
the observations and just don't do it in
a dumb way.
Yeah. So, collision right here is bad.
Yeah. So, collision right here is bad.
This thing is not training correctly.
Let me think.
some sort of data issue.
We have this training before
if we had those metrics.
Every second we have a snapshot
Every second we have a snapshot
that that is the observation. It is what
that that is the observation. It is what
the agency is at every fixed interval of
the agency is at every fixed interval of
time.
Okay. Yeah. So here the collision rate
Okay. Yeah. So here the collision rate
is good.
The fact that it's not good here
The fact that it's not good here
uh means something is wrong with the
uh means something is wrong with the
observation somehow. Let's see what I
observation somehow. Let's see what I
did.
So we have
uh distance
This is numbum armies* 3 plus
cure
cure
I had this wrong
and if this frames basically will know
and if this frames basically will know
that I've done it correctly
have to be very careful with
have to be very careful with
observations.
observations.
There you go.
There you go.
Instantly huge difference.
Instantly huge difference.
I'm specifically I'm looking at the
I'm specifically I'm looking at the
collision right here.
collision right here.
And now it very quickly learns to not
And now it very quickly learns to not
crash into the ground.
if stones replied yet.
if stones replied yet.
He's probably asleep. He's in California
He's probably asleep. He's in California
graduate student time zone.
big mistake to purchase Mac Studio.
big mistake to purchase Mac Studio.
Yeah. I mean, for RL, you kind of need
Yeah. I mean, for RL, you kind of need
Nvidia GPUs. It's just how it works.
Does this thing spin this thing? This is
Does this thing spin this thing? This is
probably a dumb idea, but here
like No, doesn't spin all the way sadly.
like No, doesn't spin all the way sadly.
I was going to see if I could spin it to
I was going to see if I could spin it to
get to the PC, but it doesn't. I'd have
get to the PC, but it doesn't. I'd have
to like fully shift it.
to like fully shift it.
Ah, now I messed up my camera. Hang on.
Who is king?
I'm on a farm.
I'm literally in This is a warehouse on
I'm literally in This is a warehouse on
a farm.
That's literally corn.
Unfortunately, I haven't really been
Unfortunately, I haven't really been
able to enjoy the outdoors at all in the
able to enjoy the outdoors at all in the
last couple weeks. It's freaking hot and
last couple weeks. It's freaking hot and
they're like biting insects everywhere.
they're like biting insects everywhere.
Now, this is this is tech stream. We do
Now, this is this is tech stream. We do
tech here.
lab tour. The lab is right I mean it's
lab tour. The lab is right I mean it's
literally just like a bunch of PCs on a
literally just like a bunch of PCs on a
rack. You can see them right behind me.
I don't know. I was I was looking on uh
I don't know. I was I was looking on uh
I was looking for like lasers and
I was looking for like lasers and
optical stuff earlier today for a side
optical stuff earlier today for a side
project. Maybe I'll show that if I get
project. Maybe I'll show that if I get
any of that stuff.
I'm learning um I'm studying quantum
I'm learning um I'm studying quantum
physics and I'm kind of wanting to do
physics and I'm kind of wanting to do
some experiments.
Some of that equipment is ridiculously
Some of that equipment is ridiculously
expensive, but some of it's pretty
expensive, but some of it's pretty
cheap.
I think we can just add a small
I think we can just add a small
observation to fix OB
because it basically doesn't know when
because it basically doesn't know when
it's going out of bounds.
Let's see if that does anything.
Obs
We'll see if that does anything to OB.
We'll see if that does anything to OB.
Okay.
Yeah. So, out of bounds is not being
Yeah. So, out of bounds is not being
fixed, it seems, by this obs.
fixed, it seems, by this obs.
Oh, no. Yes, it is.
Oh, no. Yes, it is.
Yeah, it just took it a little bit.
Horse flies this week.
Horse flies this week.
Horse flies are the worst.
Horse flies are the worst.
Like I I don't think I'm going to out to
Like I I don't think I'm going to out to
run outside tomorrow cuz like literally
run outside tomorrow cuz like literally
last week I ran I was out for an hour
last week I ran I was out for an hour
maybe an hour 10. Uh brutally hot. But
maybe an hour 10. Uh brutally hot. But
then I came back and I had golf ball
then I came back and I had golf ball
sized welts all over my back from uh
sized welts all over my back from uh
just all the freaking horse flies and
just all the freaking horse flies and
whatever other biting stinging insects
whatever other biting stinging insects
there are.
there are.
literally would just be running and like
literally would just be running and like
rip them off of my back and stuff as I'm
rip them off of my back and stuff as I'm
going.
Yeah.
Huh?
Hey, Spencer.
There's some sort of maneuvering going
There's some sort of maneuvering going
on here. It's interesting.
Oh, I think it's the um
these ones here. These flat planes are
these ones here. These flat planes are
bombers.
bombers.
Uh they should be trying to be very high
Uh they should be trying to be very high
up in the air because they fired like
up in the air because they fired like
directly down.
directly down.
So, they want to be like pretty high up
So, they want to be like pretty high up
in the air.
in the air.
But I think that they're hitting the
But I think that they're hitting the
skybox is their problem.
How can I do ray train from last
How can I do ray train from last
training snapshot? We don't usually do
training snapshot? We don't usually do
that. You can try to just like d-load
that. You can try to just like d-load
model path. See if that works.
model path. See if that works.
I like it's as funny as it is. We
I like it's as funny as it is. We
literally don't bother with that most of
literally don't bother with that most of
the time because of how fast our
the time because of how fast our
experiments are.
We teach agent to do new skill
either you can load policies up like
either you can load policies up like
that's a thing you can do. So it's we
that's a thing you can do. So it's we
just usually with Puffer we usually
just usually with Puffer we usually
don't bother because most of our
don't bother because most of our
experiments are so fast
and also like a lot of the stuff we're
and also like a lot of the stuff we're
doing is science side stuff. So it's
doing is science side stuff. So it's
like we want things to re be
like we want things to re be
reproducible and if you chain together a
reproducible and if you chain together a
whole bunch of experiments it's harder
whole bunch of experiments it's harder
to reproduce the results if you just
to reproduce the results if you just
have one that runs from the start.
Let me think about the second problem
Let me think about the second problem
that we're going to have here.
Second problem that we're going to have
Second problem that we're going to have
here is how we actually know which of
here is how we actually know which of
these is any good when um
these is any good when um
yeah, how do we know which of these is
yeah, how do we know which of these is
any good? They're it's like pure
any good? They're it's like pure
selfplay.
We'd have to make a scripted opponent,
We'd have to make a scripted opponent,
right?
But we can cheat with the scripted
But we can cheat with the scripted
opponent a little bit, I think.
Yeah, I know what we're going to do.
Yeah, I know what we're going to do.
We're basically just going to make a uh
We're basically just going to make a uh
an opponent that runs at you in a
an opponent that runs at you in a
straight line. I'm going to see if we
straight line. I'm going to see if we
can beat that.
We'll go from there.
Let me go grab some more coffee restroom
Let me go grab some more coffee restroom
one second and then we'll uh we'll do
Okay.
Scripted opponent time.
What we're going to do is we're going to
What we're going to do is we're going to
add scripted
add scripted
ground.
ground.
It does not take actions.
It does not take actions.
And then this is going to be
eats physics
eats physics
and moves
and moves
directly
directly
to the nearest MMA.
We need to get nearest
nearest
nearest
int.
So, we're going to do entity star
So, we're going to do entity star
nearest enemy.
See if this autofill is actually
See if this autofill is actually
reasonable.
reasonable.
Go through the agents. Get other. Yeah.
Go through the agents. Get other. Yeah.
So, it literally just copy pasted this
So, it literally just copy pasted this
from elsewhere in like my ops code,
from elsewhere in like my ops code,
which is fine.
which is fine.
Uh, this didn't include Y though.
We'll do that.
messing around with linking bullet 3 to
messing around with linking bullet 3 to
puffer. Do you think that might be a
puffer. Do you think that might be a
reasonable thing to do or do you have
reasonable thing to do or do you have
any ideas? Does bullet 3 have um
any ideas? Does bullet 3 have um
is it uh does it have GPU excel or no?
I think warp is the thing if you want
I think warp is the thing if you want
like to actually do like low-level
like to actually do like low-level
physics I think warp is the thing
physics I think warp is the thing
that you do these days.
But we uh we are doing some robotic
But we uh we are doing some robotic
stuff now. I think I showed this this
stuff now. I think I showed this this
morning. So this is uh picking of a
morning. So this is uh picking of a
cube. This is like pick up a cube, bring
cube. This is like pick up a cube, bring
it to a target or whatever. We have this
it to a target or whatever. We have this
working super easily in Puffer. Um, and
working super easily in Puffer. Um, and
we're starting to do more robotics
we're starting to do more robotics
stuff. So, if you want like an out of
stuff. So, if you want like an out of
the box robotics thing to play with and
the box robotics thing to play with and
you want to like take our existing
you want to like take our existing
stuff,
stuff,
uh, you can ask me on like the new manny
uh, you can ask me on like the new manny
skill stuff.
skill stuff.
If you want to do your own low-level
If you want to do your own low-level
things, I would look at something like
things, I would look at something like
warp,
warp,
Nvidia Warp.
Oh, wait. This is Python.
Oh, never mind.
Wait, this is dumb.
Maybe it's physics.
Yeah, this is not the highle thing. This
Yeah, this is not the highle thing. This
is I This is not the low-level thing.
is I This is not the low-level thing.
This is like some highle thing.
Might be physics. You'd have to look
Might be physics. You'd have to look
into like what the actual like what all
into like what the actual like what all
the Sims are implemented using, right?
You kind of like the most useful thing
You kind of like the most useful thing
in robotics at the moment. If you want
in robotics at the moment. If you want
something that's like truly difficult is
something that's like truly difficult is
just getting like absolute maximum
just getting like absolute maximum
performance sim.
performance sim.
I'd be very impressed if you could train
I'd be very impressed if you could train
difficult robotic tasks like insertion.
difficult robotic tasks like insertion.
I'd be very impressed if we couldn't.
I'd be very impressed if we couldn't.
Um, it's like we're gonna have to I'm
Um, it's like we're gonna have to I'm
gonna have to spend a little bit more
gonna have to spend a little bit more
time on stuff, but like this stuff
time on stuff, but like this stuff
should not be hard.
Bullet 3 was go-to for lowle. Is it? I
Bullet 3 was go-to for lowle. Is it? I
think it's CPU.
Doesn't it not support if it doesn't
Doesn't it not support if it doesn't
support GPU? Like physics is one of the
support GPU? Like physics is one of the
few things where it's like, yeah, you
few things where it's like, yeah, you
need GPUs by default. Oh, wait.
need GPUs by default. Oh, wait.
Experimental Open CLG GPGPU support.
Experimental Open CLG GPGPU support.
Apparently, that's like experimental
Apparently, that's like experimental
support.
support.
Uh, and also this project
Uh, and also this project
doesn't seem like it's really being
doesn't seem like it's really being
maintained much.
I would definitely do some looking
I would definitely do some looking
around to see that like what what is
around to see that like what what is
actually good these days rather than
actually good these days rather than
just jumping into something like this.
Will it is slow as Yeah, that's
Will it is slow as Yeah, that's
what I kind of expected.
Manny skills goat. So, here's the funny
Manny skills goat. So, here's the funny
thing with Manny skill, right? Um
thing with Manny skill, right? Um
I So,
I So,
and I think that I don't think this is
and I think that I don't think this is
maniskll specific. I think this is just
maniskll specific. I think this is just
a general thing in robotics. All the
a general thing in robotics. All the
reward functions are wrong. All of them.
reward functions are wrong. All of them.
So, uh, in order to get this to work,
So, uh, in order to get this to work,
I had to make a small change, a small
I had to make a small change, a small
but very significant change. And this
but very significant change. And this
persists across all the robotics
persists across all the robotics
environments. And in order to make this
environments. And in order to make this
thing train despite the reward being
thing train despite the reward being
wrong, essentially roboticists have come
wrong, essentially roboticists have come
up with this like alternate wrong
up with this like alternate wrong
formulation of a different part of the
formulation of a different part of the
learning algorithm that counteracts the
learning algorithm that counteracts the
first error.
So yeah, it's real weird. Um, and I will
So yeah, it's real weird. Um, and I will
be surprised if we can't just kind of
be surprised if we can't just kind of
make a lot of stuff just work.
What is it that's wrong? I'm listening.
What is it that's wrong? I'm listening.
So, they do everything in robotics, you
So, they do everything in robotics, you
all do state based state based reward.
all do state based state based reward.
So, like as I get closer to the goal,
So, like as I get closer to the goal,
for instance,
for instance,
you get more and more reward. Uh but
you get more and more reward. Uh but
that's not how rewards work
that's not how rewards work
because
because
in order to fix this, right, the issue
in order to fix this, right, the issue
with this is that you can farm reward at
with this is that you can farm reward at
the end. First of all, the reward
the end. First of all, the reward
between one state and the next state is
between one state and the next state is
a very small difference. You actually
a very small difference. You actually
have to like implicitly learn this very
have to like implicitly learn this very
small delta, which is very difficult.
small delta, which is very difficult.
But then even worse is that you can farm
But then even worse is that you can farm
reward just by like staying really near
reward just by like staying really near
the target. And then they fix this by
the target. And then they fix this by
bootstrapping the reward across the
bootstrapping the reward across the
terminals in generalized advantage
terminals in generalized advantage
estimation, which is wrong. You're not
estimation, which is wrong. You're not
supposed to do that because that's a
supposed to do that because that's a
hard assumption that the uh terminal
hard assumption that the uh terminal
state is the target state. Um the
state is the target state. Um the
correct thing to do is to use delta
correct thing to do is to use delta
based rewards where you do delta from
based rewards where you do delta from
your previous state reward to the
your previous state reward to the
current state reward and that's the
current state reward and that's the
actual reward you give to the agent. So
actual reward you give to the agent. So
I did that and immediately it started
I did that and immediately it started
working perfectly.
Shouldn't
say they
max no because of a detail of how they
max no because of a detail of how they
know because of um the way generalized
know because of um the way generalized
advantage estimation works.
Like I saw this and I was like, "Oh
Like I saw this and I was like, "Oh
yeah, that's very clearly wrong."
yeah, that's very clearly wrong."
And then the experimental data, the
And then the experimental data, the
experiment perfectly tracked
experiment perfectly tracked
uh it perfect like the experimental
uh it perfect like the experimental
results perfectly tracked.
And now basically the only question is
And now basically the only question is
um whether we can make puffer
um whether we can make puffer
substantially faster wall clock time for
substantially faster wall clock time for
the environment or not because uh we're
the environment or not because uh we're
really like a lot of our demos are
really like a lot of our demos are
optimized for way faster environments
optimized for way faster environments
than robotics. The question will be
than robotics. The question will be
whether you know there's actually
whether you know there's actually
substantial uh improvement over this
substantial uh improvement over this
versus the other libraries. But we would
versus the other libraries. But we would
expect that there should be if we tune
expect that there should be if we tune
it.
Preach that to the whole man skill crew.
Preach that to the whole man skill crew.
Uh yeah, I know Stone personally and
Uh yeah, I know Stone personally and
I'll be chatting with him about this
I'll be chatting with him about this
briefly because the cool thing about
briefly because the cool thing about
this is it's like a 10line fix for their
this is it's like a 10line fix for their
entire library.
entire library.
It's a 10-line fix.
It's a 10-line fix.
And I don't think it's specifically
And I don't think it's specifically
them. Like to be clear, uh Stone's
them. Like to be clear, uh Stone's
probably the most competent person I
probably the most competent person I
know in robotics. And uh I had to deal
know in robotics. And uh I had to deal
with Isaac Jim and like that they don't
with Isaac Jim and like that they don't
know what the hell they're doing over
know what the hell they're doing over
there. All right, that all the Isaac
there. All right, that all the Isaac
code just sucks. But like my expectation
code just sucks. But like my expectation
is if this is happening here, it's
is if this is happening here, it's
probably happening everywhere. There.
feel like it will bring more attention.
feel like it will bring more attention.
Yeah, we're doing a little bit of
Yeah, we're doing a little bit of
robotics just to see if robotics people
robotics just to see if robotics people
are interested in Popper. It's not my
are interested in Popper. It's not my
main application area of interest, but
main application area of interest, but
you know, if there's if there's some
you know, if there's if there's some
industry robotics stuff that we can do,
industry robotics stuff that we can do,
uh we'll be happy to support that.
You talk already about multi-stage
You talk already about multi-stage
training. What do you mean multi-stage
training. What do you mean multi-stage
training?
multiple times.
You can do it. We don't usually do it.
You can do it. We don't usually do it.
Like,
Like,
yes, you can do that. We don't normally
yes, you can do that. We don't normally
have to, right?
If we actually get this environment into
If we actually get this environment into
a decent spot. Um,
if we get this environment into a decent
if we get this environment into a decent
spot, maybe we'll do some robotics after
spot, maybe we'll do some robotics after
this later in the day. We'll see.
this later in the day. We'll see.
But I want to I want to actually have
But I want to I want to actually have
like some cool tactical thing with this.
Kind of my fault. I'm supposed to be
Kind of my fault. I'm supposed to be
super well rested on Saturday so I can
super well rested on Saturday so I can
like really hammer out a lot of work.
like really hammer out a lot of work.
But
But
I don't know. I kind of uh I kept myself
I don't know. I kind of uh I kept myself
up half the night thinking about and it
up half the night thinking about and it
was specifically thinking about quantum
was specifically thinking about quantum
recording which I don't know
quantum's really weird
what if the problem is so big it needs
what if the problem is so big it needs
multi-stage training then you do
multi-stage training then you do
multi-stage training
multi-stage training
like you can load in policies into
like you can load in policies into
puffer and keep training technically it
puffer and keep training technically it
would be like a fiveline edition to make
would be like a fiveline edition to make
sure you also load the optimizer state.
sure you also load the optimizer state.
Uh full self-driving car. Oh,
Uh full self-driving car. Oh,
uh you mean like this?
Like these this type of a thing?
Like these this type of a thing?
Oops. Where is it?
actual real world self-driving car, not
actual real world self-driving car, not
an end to end RL problem,
an end to end RL problem,
mostly imitation learning.
But yeah, it's a fiveline change to
But yeah, it's a fiveline change to
resume training.
Oh yeah, that's the other thing that we
Oh yeah, that's the other thing that we
try to do in Puffer Lib, right? We don't
try to do in Puffer Lib, right? We don't
have like we don't necessarily have
have like we don't necessarily have
flags for every feature that you could
flags for every feature that you could
possibly imagine, but the code is
possibly imagine, but the code is
structured such that like way more often
structured such that like way more often
than any other library, the thing that
than any other library, the thing that
you want will be like a five or 10 line
you want will be like a five or 10 line
code change. It's just like in the main
code change. It's just like in the main
trainer file or whatever. It won't be
trainer file or whatever. It won't be
like some horrible thing where you have
like some horrible thing where you have
to like go rearchitect this like
to like go rearchitect this like
gigantic amalgam of nonsense. just like
gigantic amalgam of nonsense. just like
very quick.
I think that might even work. Magic.
I think that might even work. Magic.
It's like I think that probably just
It's like I think that probably just
works like load last checkpoint. I don't
works like load last checkpoint. I don't
know if it I it probably doesn't load
know if it I it probably doesn't load
the optimizer state. I It would be like
the optimizer state. I It would be like
a fiveline change. I don't know. I could
a fiveline change. I don't know. I could
add it.
add it.
Literally nobody's needed it because of
Literally nobody's needed it because of
how fast um the training is, but I could
how fast um the training is, but I could
figure that out.
Like the only reason you're thinking
Like the only reason you're thinking
that you might need that stuff at the
that you might need that stuff at the
moment is just because you're training
moment is just because you're training
on CPU, right?
Like here
Oh, this is where we've damn it. I love
Oh, this is where we've damn it. I love
how you actually like Google the thing
how you actually like Google the thing
and they just
Oh, they changed their whole thing, huh?
Oh, they changed their whole thing, huh?
And they increased the price as well.
And they increased the price as well.
Well, I know this still works
Well, I know this still works
here.
You can go get yourself a 4090 for as
You can go get yourself a 4090 for as
low as 35 cents an hour.
low as 35 cents an hour.
You say
if you don't have hardware,
if you don't have hardware,
good thing to do. Hey, Hyper.
Tyler, just who I was looking for.
Tyler, just who I was looking for.
Where's a physics PhD when you need him?
Where's a physics PhD when you need him?
I've been studying quantum mechanics
I've been studying quantum mechanics
and I am very confused.
I don't know. Is this a thing? Like, do
I don't know. Is this a thing? Like, do
all physics students like study quantum
all physics students like study quantum
at some point or is this like a or do I
at some point or is this like a or do I
need to find somebody who is like a
need to find somebody who is like a
specialist in quantum?
specialist in quantum?
I don't know how it works.
I think Tyler's got like million years
I think Tyler's got like million years
worth of stream delay on X at the
worth of stream delay on X at the
moment.
What was the answer? You were right
What was the answer? You were right
about the delay.
What was what was what answer?
Oh, the answer is that because driving
Oh, the answer is that because driving
is open-ended.
is open-ended.
Uh, the reason that you don't end to end
Uh, the reason that you don't end to end
RL driving is because you want something
RL driving is because you want something
that actually drives like a human and
that actually drives like a human and
it's a problem for which you have a huge
it's a problem for which you have a huge
amount of human data. It's mostly
amount of human data. It's mostly
imitation learning.
You know any quantum mechanics, Tyler,
You know any quantum mechanics, Tyler,
or is that outside of
or is that outside of
outside of your area?
I know a bit.
I know a bit.
So, the thing that's driving me insane
So, the thing that's driving me insane
at the moment is
at the moment is
the definition of a record seems like
the definition of a record seems like
really circular as an experimentalist.
really circular as an experimentalist.
Well, yeah. I I'm actually I'm mostly
Well, yeah. I I'm actually I'm mostly
trying to figure this out from an
trying to figure this out from an
experimental perspective. So, the thing
experimental perspective. So, the thing
that's driving me absolutely crazy is
that's driving me absolutely crazy is
that the experiment goes Oh, okay. So
that the experiment goes Oh, okay. So
yeah, you get this interference effect
yeah, you get this interference effect
that goes away uh when you record it.
that goes away uh when you record it.
Like, well, is that an artifact of
Like, well, is that an artifact of
measurement? No, it just goes away no
measurement? No, it just goes away no
matter how you measure it, even if you
matter how you measure it, even if you
do it in a way that doesn't disturb the
do it in a way that doesn't disturb the
experiment at all. Oh, okay. So, it's
experiment at all. Oh, okay. So, it's
somehow the measurement the process of
somehow the measurement the process of
measurement
measurement
uh messes with that. Well, how does that
uh messes with that. Well, how does that
work? Oh, well, you entangle the Let me
work? Oh, well, you entangle the Let me
get this right. The particle becomes
get this right. The particle becomes
entangled with the macroscopic detector
entangled with the macroscopic detector
state. Well, what the heck does that
state. Well, what the heck does that
mean? Like, well, it's because you
mean? Like, well, it's because you
create a record of it and it becomes
create a record of it and it becomes
entangled with the record. Like, so if
entangled with the record. Like, so if
you do this exact same thing, but you
you do this exact same thing, but you
don't create a record, then there's no
don't create a record, then there's no
entanglement.
entanglement.
Well, yeah.
Well, yeah.
Okay. Okay. So, like if I just do this
Okay. Okay. So, like if I just do this
experiment and I record the data in the
experiment and I record the data in the
exact same way and I throw it away, then
exact same way and I throw it away, then
there's no record. Well, yeah, it it
there's no record. Well, yeah, it it
it's kind of like this really circular
it's kind of like this really circular
thing where it's like they're defining
thing where it's like they're defining
this very highle concept of making a
this very highle concept of making a
record and then there's basically no
record and then there's basically no
explan like there's no mechanistic
explan like there's no mechanistic
explanation that I can see that fits
explanation that I can see that fits
this data better than literally saying
this data better than literally saying
that particles are omnisient.
That's the thing that's driving me
That's the thing that's driving me
insane.
is inverse reinforcement learning.
Let me see.
is this?
You're learning the reward function.
Honestly, I haven't seen anything in
Honestly, I haven't seen anything in
that in a while.
Learning reward. Yeah, I haven't seen
Learning reward. Yeah, I haven't seen
anything in that in a while.
I don't know if that whole line of work
I don't know if that whole line of work
went anywhere.
Uh, we need to orient this thing.
Shoot. How do we do this?
Shoot. How do we do this?
Long live behavioral cloning.
Long live behavioral cloning.
Yeah, that doesn't solve your problem
Yeah, that doesn't solve your problem
either, though.
Like online RL is kind of goated. It's
Like online RL is kind of goated. It's
kind of hard to just beat online RL with
kind of hard to just beat online RL with
infinite data.
Is there like a quat rotate too or like
Is there like a quat rotate too or like
a quat look at
Are you making a Starcraft 2 end? Uh,
Are you making a Starcraft 2 end? Uh,
not. Here, I'll show you it. It's not
not. Here, I'll show you it. It's not
quite that.
You can run it way bigger with way more
You can run it way bigger with way more
agents, but um it's like a tactical
agents, but um it's like a tactical
battle sim. So there drones, they're
battle sim. So there drones, they're
fighters, they're bombers,
fighters, they're bombers,
drone ship, there tanks, there's
drone ship, there tanks, there's
infantry.
It's pretty much just a big battle sim.
think what to do with this. We need like
think what to do with this. We need like
a quat look at or something.
Have you heard of action
Have you heard of action
derived rewards? Is that a thing?
derived rewards? Is that a thing?
Action? I don't know what that refers
Action? I don't know what that refers
to, Spencer.
to, Spencer.
Is it possible to explain this battle? M
Is it possible to explain this battle? M
specifically, observation space. Sure.
specifically, observation space. Sure.
So, I have I think there like six or
So, I have I think there like six or
seven different types of units. There's
seven different types of units. There's
infantry, there tanks, um there's
infantry, there tanks, um there's
anti-air like trucks that are like
anti-air like trucks that are like
anti-air specifically. There are drones,
anti-air specifically. There are drones,
there are fighters, there are bombers,
there are fighters, there are bombers,
and then there's this mother ship that
and then there's this mother ship that
like launches drones. They all have
like launches drones. They all have
different effective speeds, turning
different effective speeds, turning
radiuses, and uh weapon ranges. So, they
radiuses, and uh weapon ranges. So, they
all like behave a little bit
all like behave a little bit
differently,
differently,
and you just have multiple armies, and
and you just have multiple armies, and
they fight. Um, and then reinforcement
they fight. Um, and then reinforcement
learning will just control, same policy,
learning will just control, same policy,
can control whatever ship because they
can control whatever ship because they
all have the same observation space. the
all have the same observation space. the
action spaces are interpreted
action spaces are interpreted
differently, but it still works. Um,
differently, but it still works. Um,
observation space, they see like their
observation space, they see like their
own state. So, they see like their own
own state. So, they see like their own
orientation, their own speed, heading,
orientation, their own speed, heading,
uh, position, all that stuff.
uh, position, all that stuff.
And then they see, you know, the
And then they see, you know, the
distance to ground so that they don't
distance to ground so that they don't
crash. And then they just observe like
crash. And then they just observe like
the nearest 16 agents at the moment.
the nearest 16 agents at the moment.
They observe like the position of the
They observe like the position of the
nearest 16 agents and whether they're
nearest 16 agents and whether they're
friendly or hostile. That's all.
Is there like a look
Is there like a look
matrix look at?
matrix look at?
Yeah, this is not what we need because
Yeah, this is not what we need because
we need quat version.
we need quat version.
the data structure.
the data structure.
It's a bunch of floats.
It's literally just a like a bunch of
It's literally just a like a bunch of
floats.
So, like
So, like
here's some data and we just like here
here's some data and we just like here
are the observations to the nearest
are the observations to the nearest
agent. You just add them in. And here
agent. You just add them in. And here
are the observations of all the agent
are the observations of all the agent
properties. They just get added in. It
properties. They just get added in. It
knows what type of unit it is. They're
knows what type of unit it is. They're
just written down like that. Goes into a
just written down like that. Goes into a
very simple neural net.
I think we lost Tyler.
I think we lost Tyler.
Dang.
He's like the only one I know who's in
He's like the only one I know who's in
physics. I was hoping he'd bail me bail
physics. I was hoping he'd bail me bail
me out of this mess.
So I
So I
I like technically I guess we can just
I like technically I guess we can just
run it like this for now and then we'll
run it like this for now and then we'll
have to figure out the look at
just do this
just do this
and then
how do we distinguish between scripted
how do we distinguish between scripted
versus not?
versus not?
I believe you're asking a question
I believe you're asking a question
nobody has an answer to. Lovely.
nobody has an answer to. Lovely.
Um,
so I I guess Tyler, and this is like
so I I guess Tyler, and this is like
this is driving me crazy to the point
this is driving me crazy to the point
that like literally look at this. I
that like literally look at this. I
literally have Where's the shopping
literally have Where's the shopping
cart?
Oh, yeah. I'm literally looking at
Oh, yeah. I'm literally looking at
ordering lasers
ordering lasers
to see if I can answer some of these
to see if I can answer some of these
questions to set up some experiments.
questions to set up some experiments.
Um,
Um,
great.
Yeah, I I'm trying to set up some
Yeah, I I'm trying to set up some
experiments that decouple measurement
experiments that decouple measurement
from observability.
I took quantum. It was like X happens.
I took quantum. It was like X happens.
Don't question why. No one knows. Just
Don't question why. No one knows. Just
accept. Yeah, but that's not how my
accept. Yeah, but that's not how my
brain works, Spencer.
Like if you tell me that like a normal
Like if you tell me that like a normal
person would be like, "Yeah, okay,
person would be like, "Yeah, okay,
cool." Me, it'll be like, "No,
cool." Me, it'll be like, "No,
that. I'm ordering lasers to figure this
that. I'm ordering lasers to figure this
out.
Any worlds decoherence quantum?"
Any worlds decoherence quantum?"
I don't think any of that explains
I don't think any of that explains
observability itself, right? Like the
observability itself, right? Like the
fact
fact
I mean, you can get these things to be,
I mean, you can get these things to be,
it seems like you can get these things
it seems like you can get these things
to be pretty dang decoupled. Like the
to be pretty dang decoupled. Like the
process of recording can be pretty dang
process of recording can be pretty dang
decoupled from the process of
decoupled from the process of
measurement
measurement
and somehow
and somehow
it still affects the interference,
it still affects the interference,
right?
Does free will exist? I actually don't
Does free will exist? I actually don't
care about that question at all.
You're observing all values in the list
You're observing all values in the list
using a fixed index. Yes. And uh imagine
using a fixed index. Yes. And uh imagine
to make that work, we sort the uh
to make that work, we sort the uh
because that's not a super smart thing
because that's not a super smart thing
to do. It's just a fast thing to do. We
to do. It's just a fast thing to do. We
sort uh a we sort the nearby agents by
sort uh a we sort the nearby agents by
their distance to us. You always get
their distance to us. You always get
like the nearest one, the second nearest
like the nearest one, the second nearest
one, so on and so forth.
one, so on and so forth.
Not a philosopher, huh?
Not a philosopher, huh?
Uh, I don't mind philosophy. I only mind
Uh, I don't mind philosophy. I only mind
stupid philosophy.
I don't know. I find a lot of philosophy
I don't know. I find a lot of philosophy
just kind of dumb.
Then you track their coordinates or
Then you track their coordinates or
position. We do deltas.
position. We do deltas.
Maybe we can RL the hell out of
Maybe we can RL the hell out of
philosophy.
I think the RL would be like what what
I think the RL would be like what what
the hell are you guys doing? go back to
the hell are you guys doing? go back to
running actual experiments on things.
running actual experiments on things.
Delta delta is just distance. So we just
Delta delta is just distance. So we just
do like you know your so it's we do like
do like you know your so it's we do like
the x distance from you to the target or
the x distance from you to the target or
you could do angle and distance right.
you could do angle and distance right.
I think we just do use uh we just use
I think we just do use uh we just use
standard uh xyz chords not spherical or
standard uh xyz chords not spherical or
anything. There you go.
anything. There you go.
If you believe the universe itself can
If you believe the universe itself can
be an observer. So yeah. So Tyler, this
be an observer. So yeah. So Tyler, this
is basically the thing that just bothers
is basically the thing that just bothers
me about all of this is like, and this
me about all of this is like, and this
is something that scientists do, right?
is something that scientists do, right?
You come up with all these like
You come up with all these like
absolutely insane deranged theories uh
absolutely insane deranged theories uh
that really don't make any bloody sense
that really don't make any bloody sense
if you think about them. It's like you
if you think about them. It's like you
kind of just wrote down some math and
kind of just wrote down some math and
like ah yes, there's math. It makes
like ah yes, there's math. It makes
sense. But if you think about it, it
sense. But if you think about it, it
doesn't really make any bloody sense.
doesn't really make any bloody sense.
And literally like all these theories
And literally like all these theories
fit the data exactly as well as just
fit the data exactly as well as just
saying that the particles are omnisient.
That's what drives me insane.
So if we like flip the typical, you
So if we like flip the typical, you
know, if we flip the typical view of
know, if we flip the typical view of
quantum like well look, we have these
quantum like well look, we have these
models and they're very good at
models and they're very good at
predicting the real world, but we don't
predicting the real world, but we don't
really care if they're true or not.
really care if they're true or not.
they're very good at predicting the the
they're very good at predicting the the
data and they let us run experiments
data and they let us run experiments
that I could say, okay, well, I can
that I could say, okay, well, I can
equally well predict the real world by
equally well predict the real world by
just saying that the particles are
just saying that the particles are
omnisient and they know when they're
omnisient and they know when they're
being recorded.
And you do not have any more of a
And you do not have any more of a
satisfying mathematical explanation than
satisfying mathematical explanation than
the one that I just gave.
If the universe is the observer then
If the universe is the observer then
that could be true
that could be true
but like
but like
I mean that's not saying the universe is
I mean that's not saying the universe is
like that's like the same thing man
like that's like the same thing man
right
the thing is this is not speculation
the thing is this is not speculation
right we literally have experiments
right we literally have experiments
that match this as well as any other
that match this as well as any other
theory. I don't know how to go deeper
theory. I don't know how to go deeper
from there. Yeah. So, the problem here
from there. Yeah. So, the problem here
is if I try to like go back and forth
is if I try to like go back and forth
with a language model, they eventually
with a language model, they eventually
go off the rails and start telling me
go off the rails and start telling me
insane things. But quantum is also
insane things. But quantum is also
already kind of insane. So, I literally
already kind of insane. So, I literally
don't know what we know versus what is
don't know what we know versus what is
being made up. It seems like there is a
being made up. It seems like there is a
formal process to recording where it's
formal process to recording where it's
kind of hard to set up an experiment
kind of hard to set up an experiment
that decouples measurement from
that decouples measurement from
recording, but that seems like it should
recording, but that seems like it should
be possible.
be possible.
So anyways, the result of this
So anyways, the result of this
conversation is that I am probably going
conversation is that I am probably going
to have to just buy some lasers.
Maybe I can at least tell find somebody
Maybe I can at least tell find somebody
to tell me what to buy.
to tell me what to buy.
I don't end up buying the wrong
I don't end up buying the wrong
One agent calculating distance for 100
One agent calculating distance for 100
opponents.
opponents.
100 agent calculating delta for 100
100 agent calculating delta for 100
opponents.
opponents.
100 by 100 for deltas only. Yep.
100 by 100 for deltas only. Yep.
But you probably don't need to know the
But you probably don't need to know the
nearest 100.
You probably need like the nearest It's
You probably need like the nearest It's
probably like you need like the nearest
probably like you need like the nearest
20 or something.
20 or something.
And then right now we're doing it
And then right now we're doing it
naively. So it's quadratic, but we could
naively. So it's quadratic, but we could
make it n login if we were a little
make it n login if we were a little
smarter.
So there you go. All right, let me
So there you go. All right, let me
actually figure out how to do this
actually figure out how to do this
before I drive myself crazy. I mean, I
before I drive myself crazy. I mean, I
literally I was
literally I was
to give you an idea of my evening
to give you an idea of my evening
yesterday. Uh, and this has been for the
yesterday. Uh, and this has been for the
past two days. I finished my stream
past two days. I finished my stream
right before 6, had dinner, gone back to
right before 6, had dinner, gone back to
do a bunch of exercise behind me while
do a bunch of exercise behind me while
watching quantum quantum physics
watching quantum quantum physics
lectures,
lectures,
and then spent the like several hours
and then spent the like several hours
after that just like looking stuff up
after that just like looking stuff up
and thinking about stuff and trying to
and thinking about stuff and trying to
make sense of all this. So, let's
make sense of all this. So, let's
actually get some RL done.
actually get some RL done.
At least here we can get concrete
At least here we can get concrete
answers to things quite quickly.
like a decent evening. Yeah, except for
like a decent evening. Yeah, except for
the part where I keep myself up half the
the part where I keep myself up half the
night trying to like, you know, keep
night trying to like, you know, keep
myself up half the night thinking about
myself up half the night thinking about
what the is going on in quantum
model is just pattern matching.
model is just pattern matching.
But the thing is it's
But the thing is it's
there's a difference between a model and
there's a difference between a model and
an underlying phenomenon, right?
an underlying phenomenon, right?
Like a correct model is is necessary but
Like a correct model is is necessary but
not sufficient.
I don't know. This is what I get for
I don't know. This is what I get for
branching out and trying to study other
branching out and trying to study other
areas. Like originally this started as
areas. Like originally this started as
let me study a bunch of other areas of
let me study a bunch of other areas of
science to like look for cool
science to like look for cool
reinforcement learning problems. And now
reinforcement learning problems. And now
this has become okay these other areas
this has become okay these other areas
of science are pretty cool and I do want
of science are pretty cool and I do want
and I actually want to understand them a
and I actually want to understand them a
bit deeper.
All models are wrong but some are
All models are wrong but some are
useful.
useful.
Okay. So that's that's fair, right? And
Okay. So that's that's fair, right? And
I can understand the math. Um
I can understand the math. Um
at least I probably you I could if you
at least I probably you I could if you
as long as you don't ask me to solve the
as long as you don't ask me to solve the
equations. I actually at least I
equations. I actually at least I
understand the math as it's being
understand the math as it's being
explained, right? like yes I understand
explained, right? like yes I understand
the I understand the wave function as a
the I understand the wave function as a
model. I understand why it implies that
model. I understand why it implies that
by knowing position the forier transform
by knowing position the forier transform
collapses. Therefore you cannot
collapses. Therefore you cannot
understand uh you have no information
understand uh you have no information
about momentum. uh when one becomes a
about momentum. uh when one becomes a
direct delta the other becomes a uh a s
direct delta the other becomes a uh a s
or cosine like I understand that
or cosine like I understand that
right
but that doesn't tell us the that's like
but that doesn't tell us the that's like
a model that doesn't actually tell us
a model that doesn't actually tell us
the underlying thing or like why it
the underlying thing or like why it
happens or anything like That
I don't know. Maybe um maybe by the time
I don't know. Maybe um maybe by the time
I get to quantum field theory that will
I get to quantum field theory that will
have some answers.
have some answers.
From like the very little that I know,
From like the very little that I know,
it seems like maybe there's at least
it seems like maybe there's at least
something in there that gives us
something in there that gives us
something sort of plausible, but I don't
something sort of plausible, but I don't
think it gives you a full a full
think it gives you a full a full
solution to any of this.
Physics is cool. I don't know why I
Physics is cool. I don't know why I
never did more physics. Probably because
never did more physics. Probably because
I really didn't like having to like I
I really didn't like having to like I
liked learning about physics. I didn't
liked learning about physics. I didn't
like problem sets where it's basically
like problem sets where it's basically
solve puzzles using all these equations.
be a quantum physicist that has the most
be a quantum physicist that has the most
RL background in the field. That is
RL background in the field. That is
true. Well, I mean the thing is I could
true. Well, I mean the thing is I could
kind of do that with any of the fields,
kind of do that with any of the fields,
right? Which is kind of the point. Like
right? Which is kind of the point. Like
if I start learning a little bit about
if I start learning a little bit about
all these fields that maybe I can
all these fields that maybe I can
actually find cool problems where I
actually find cool problems where I
could apply RL to things.
could apply RL to things.
Of course, quantum has to stop driving
Of course, quantum has to stop driving
me crazy for me to do that first.
I don't know. Mad Scientist arc.
I forgot we don't need this anymore.
for me to hack the world. So, yeah,
for me to hack the world. So, yeah,
that's fine, right?
that's fine, right?
I understand it from that perspective,
I understand it from that perspective,
Tyler. I'm trying to understand it from
Tyler. I'm trying to understand it from
another perspective.
another perspective.
Well, let's be real. I don't fully
Well, let's be real. I don't fully
understand it from that perspective.
understand it from that perspective.
It's going to take me like going back
It's going to take me like going back
through a bunch more math and a bunch
through a bunch more math and a bunch
more lectures and things.
more lectures and things.
um to be like competent,
but I'm trying to understand it from
but I'm trying to understand it from
another perspective.
another perspective.
Yes. Industry is where you'll find most
Yes. Industry is where you'll find most
worthwhile RL problems. Yeah, exactly.
I mean, basically the way that I view
I mean, basically the way that I view
the way I view this stuff with RL is
the way I view this stuff with RL is
like all I got to do is find at least
like all I got to do is find at least
one of these problems, right, that
one of these problems, right, that
nobody's thought about from an RL
nobody's thought about from an RL
perspective before or at least from a
perspective before or at least from a
competent RL perspective before that's
competent RL perspective before that's
worth a billion dollars and then yay, we
worth a billion dollars and then yay, we
have unlimited funding to do science
have unlimited funding to do science
forever.
That's how I think of it.
If you want to find the secrets
If you want to find the secrets
universe, think in terms of energy,
universe, think in terms of energy,
frequency, and vibration.
Isn't that just flipping
That just flips you from particles by
That just flips you from particles by
default to waves by default, doesn't it?
default to waves by default, doesn't it?
But it's a dual interpretation. You need
But it's a dual interpretation. You need
both to explain the like to explain the
both to explain the like to explain the
data, don't you?
To explain all the experiments that have
To explain all the experiments that have
been done
been done
more of an aether effective
more of an aether effective
is it fields aren't aether. I guess
is it fields aren't aether. I guess
they're I guess you can kind of think of
they're I guess you can kind of think of
him as such. Maybe we should just Maybe
him as such. Maybe we should just Maybe
we should just like word swap the like
we should just like word swap the like
field with aether or was it ether?
field with aether or was it ether?
Aether. I think it's ether usually,
Aether. I think it's ether usually,
right? It's spelled that way. It's
right? It's spelled that way. It's
pronounced ether. Let's just like swap
pronounced ether. Let's just like swap
field with ether and everybody will
field with ether and everybody will
suddenly be more interested in stuff.
Physicist
Physicists think they're wizards. They
Physicists think they're wizards. They
can accomplish a lot.
can accomplish a lot.
I mean, it's kind of true of everything,
I mean, it's kind of true of everything,
right?
When stuff gets boring, nobody wants to
When stuff gets boring, nobody wants to
work on it.
work on it.
been one of the best things with RL is
been one of the best things with RL is
like, you know what speeding up RL a
like, you know what speeding up RL a
thousandx means? It means your
thousandx means? It means your
day-to-day work goes a lot faster
day-to-day work goes a lot faster
because it's less boring.
Okay, let me I think we are ready to run
Okay, let me I think we are ready to run
this little experiment that I've kind of
this little experiment that I've kind of
I kind of just been chatting but in the
I kind of just been chatting but in the
background I've sort of been thinking
background I've sort of been thinking
about how to do this
cuz I think I can literally just do
cuz I think I can literally just do
times two.
physics where things is called a
physics where things is called a
constant.
constant.
Yeah, those are just that's just curve
Yeah, those are just that's just curve
fitting, right?
fitting, right?
That doesn't bother me as much.
I would like it if I could find somebody
I would like it if I could find somebody
to actually tell me what I need for like
to actually tell me what I need for like
a decent experimental setup for uh
a decent experimental setup for uh
some of the stuff that you'd want to get
some of the stuff that you'd want to get
is like ludicrously expensive.
is like ludicrously expensive.
Like they technically
Like they technically
it's a hyperparameter.
it's a hyperparameter.
Uh I mean like every everything is
Uh I mean like every everything is
always going to have a constant in front
always going to have a constant in front
of it, right? Sometimes it's just one
of it, right? Sometimes it's just one
and like it's almost weird with there is
and like it's almost weird with there is
something special about the number one
this.
this.
So yeah, like it turns out you can
So yeah, like it turns out you can
actually just buy single photon sources
actually just buy single photon sources
and detectors, but uh yeah, they're like
and detectors, but uh yeah, they're like
25 grand.
So, I was trying to do a um
So, I was trying to do a um
I was trying to get like a laser
I was trying to get like a laser
instead.
You're going to get to the point where
You're going to get to the point where
you need an Earthsized particle
you need an Earthsized particle
accelerator.
accelerator.
Better get building it then.
Better get building it then.
Must be at least one hyper pram.
Must be at least one hyper pram.
H.
H.
I don't know. Constants have never
I don't know. Constants have never
really
really
hasn't bothered me too much.
[Music]
[Music]
Does this work?
I have a feeling this is seg faulting.
Yes. Fault. Okay.
Oh, and I know why.
That's That's more philosophy than
That's That's more philosophy than
anything.
When it becomes philosophy, I get bored.
Like actual experiments things.
It's actually kind of amusing. And so
It's actually kind of amusing. And so
the thing that set me off on this whole
the thing that set me off on this whole
quantum shenanigans was I was watching
quantum shenanigans was I was watching
solid state chemistry and the professor
solid state chemistry and the professor
said that actually the Heisenberg
said that actually the Heisenberg
uncertainty principle should be called
uncertainty principle should be called
the Heisenberg non-determinate
the Heisenberg non-determinate
non-determination principle because it's
non-determination principle because it's
a problem of measurement. Oh, okay. That
a problem of measurement. Oh, okay. That
actually makes way more sense. And then
actually makes way more sense. And then
you go over to quantum and they say
you go over to quantum and they say
actually no. It seems that this kind of
actually no. It seems that this kind of
just happens like regardless.
I mean that's
I just have to compile this with um
I just have to compile this with um
I think I'm uh I'm too tired to just
I think I'm uh I'm too tired to just
guess. I'm going to have to just compile
guess. I'm going to have to just compile
this with uh
this with uh
have to compile this with debug on and
have to compile this with debug on and
just figure it out.
Gotta love when uh random ass
Gotta love when uh random ass
environment screws you over.
What I get for merging this
Of
course, it's in a case statement where
course, it's in a case statement where
it's like, "Please don't do that."
it's like, "Please don't do that."
Did you see Tesla's full self-driving?
Did you see Tesla's full self-driving?
What do you mean? Did I see it?
video plus operation.
I like my family has a Tesla. Like
I like my family has a Tesla. Like
I've ridden in it. Yeah, it's good. Like
I've ridden in it. Yeah, it's good. Like
yes, they're going to self-driving.
Why is this me set wrong?
Why is this me set wrong?
Oh.
Yes, vision data is plenty.
Yes, vision data is plenty.
This is obvious.
What if there's a snowstorm? Same thing
What if there's a snowstorm? Same thing
that happens when people drive in
that happens when people drive in
snowstorms, except, you know, better
snowstorms, except, you know, better
because it has instantaneous reaction
because it has instantaneous reaction
time basically
and precise control.
any argument of the form that like the
any argument of the form that like the
camera shouldn't be able to drive in
camera shouldn't be able to drive in
snowstorm or whatever um leads to the
snowstorm or whatever um leads to the
natural argument that people should be
natural argument that people should be
banned from driving in snowstorms.
It's like a one to one. There's like no
It's like a one to one. There's like no
difference. Like basically any case you
difference. Like basically any case you
say well the camera can't handle this
say well the camera can't handle this
situation. You're basically saying a
situation. You're basically saying a
person can't handle this situation.
do think you can trust a system more if
do think you can trust a system more if
it has extra feedback.
it has extra feedback.
You can make it way safer than humans
You can make it way safer than humans
without extra sensors. You probably
without extra sensors. You probably
can't make it as safe as if you as if
can't make it as safe as if you as if
you had all the sensors, but I would
you had all the sensors, but I would
imagine you can like reduce the number
imagine you can like reduce the number
of accidents uh by a factor of 10 over
of accidents uh by a factor of 10 over
humans
humans
just with the existing ones.
And basically at the at the point that
And basically at the at the point that
so I mean
so I mean
the thing that's really obnoxious about
the thing that's really obnoxious about
self-driving and why I just don't like
self-driving and why I just don't like
it as a problem uh is because there's a
it as a problem uh is because there's a
very large gap between the like
very large gap between the like
logically very clear thing that should
logically very clear thing that should
happen and what people will actually
happen and what people will actually
accept. Right? Right. So, a lot like the
accept. Right? Right. So, a lot like the
very clear thing that should happen here
very clear thing that should happen here
is that once you reduce the number of
is that once you reduce the number of
accidents per mile below the uh let's
accidents per mile below the uh let's
say below the median human driver,
say below the median human driver,
uh you're actively killing people by
uh you're actively killing people by
keeping these things off of the road.
keeping these things off of the road.
Like just straight up like number of
Like just straight up like number of
deaths with these on road is strictly
deaths with these on road is strictly
going to be greater than number of
going to be greater than number of
deaths without these things on road. So
deaths without these things on road. So
clearly these things should be legalized
clearly these things should be legalized
as soon as you beat that benchmark
as soon as you beat that benchmark
convincingly. Uh, but what's going to
convincingly. Uh, but what's going to
happen in practice is it's going to have
happen in practice is it's going to have
to be like 10x lower at least because
to be like 10x lower at least because
every time there is an accident, the
every time there is an accident, the
media is going to blow it up and like
media is going to blow it up and like
Congress is going to blow it up and like
Congress is going to blow it up and like
there's going to be all sorts of
there's going to be all sorts of
legislation. Uh, where like for
legislation. Uh, where like for
absolutely no reason. Uh, so like it's
absolutely no reason. Uh, so like it's
kind of just a problem that just makes
kind of just a problem that just makes
you hate people more than anything else
you hate people more than anything else
because like you can solve the tech
because like you can solve the tech
problem sufficiently and then like okay
problem sufficiently and then like okay
we can make it 10x better from here
we can make it 10x better from here
but that's not actually how it's going
but that's not actually how it's going
to turn out.
Number they aim for is one accident per
Number they aim for is one accident per
400k. I I don't think it gets deployed
400k. I I don't think it gets deployed
on that is the thing. I don't think you
on that is the thing. I don't think you
get full deployment on that number
get full deployment on that number
because of the reason that I just said.
What if human vision is a decoder that's
What if human vision is a decoder that's
impossible to replicate? that would take
impossible to replicate? that would take
it. That seems like exceedingly unlikely
rainbows and Teslas approach that number
rainbows and Teslas approach that number
in better. Yeah, that's the problem,
in better. Yeah, that's the problem,
right?
right?
Like I hate it when you end up with like
Like I hate it when you end up with like
it's not even a tech problem, right? The
it's not even a tech problem, right? The
answer is incredibly obvious and then
answer is incredibly obvious and then
you just have this existing class of
you just have this existing class of
like I don't know useless bureaucrats in
like I don't know useless bureaucrats in
the way
Yeah, it's a political problem.
Yeah, it's a political problem.
It's like literally like, "Oh yeah, my
It's like literally like, "Oh yeah, my
job is to show up to the office, look
job is to show up to the office, look
important, stole technological progress,
important, stole technological progress,
and kill people."
and kill people."
That's literally what it it boils down
That's literally what it it boils down
to. Of course, they're not going to say
to. Of course, they're not going to say
it that way. They're going to say
it that way. They're going to say
something super lofty sounding, but
something super lofty sounding, but
that's what it boils down to.
The heck is wrong with this?
Surely it can't be sealing here, right?
Surely it can't be sealing here, right?
Oh, you know what it is? No, it is
Oh, you know what it is? No, it is
seging there. I'm dumb.
I know what it is. Ipotent
AI.
Yeah. And the funny thing about this is
Yeah. And the funny thing about this is
right like this discussion
right like this discussion
is like yeah I agree I don't I don't
is like yeah I agree I don't I don't
want humans to be like relegated to this
want humans to be like relegated to this
like useless position but like the
like useless position but like the
current alternative
current alternative
the current alternative is the leaders
the current alternative is the leaders
that we have now which
that we have now which
You can look at that and that's not a
You can look at that and that's not a
comment on current political anything.
comment on current political anything.
That's a comment on politics in general.
But then the other like the other side
But then the other like the other side
of that, right, is that the AIS are
of that, right, is that the AIS are
currently they're made by people and
currently they're made by people and
they suck. Like the language models are
they suck. Like the language models are
kind of crap right now.
Like at the moment I trust a competent
Like at the moment I trust a competent
person way more than I trust a language
person way more than I trust a language
model. That will eventually change.
model. That will eventually change.
Maybe, maybe not. I don't know.
Maybe, maybe not. I don't know.
Architecturally, like AI will get
Architecturally, like AI will get
better. I don't know if language models
better. I don't know if language models
alone get to that point.
Neural MMO, can you please, my name is
Neural MMO, can you please, my name is
Joseph. Neural MMO is my main project
Joseph. Neural MMO is my main project
from my PhD. Can you please guide me on
from my PhD. Can you please guide me on
how to start reinforcement learning? I
how to start reinforcement learning? I
need it and I can't find any proper
need it and I can't find any proper
path. I got you covered. hover.ai
path. I got you covered. hover.ai
docs or not docs, my bad. You can go to
docs or not docs, my bad. You can go to
there after reinforcement learning quick
there after reinforcement learning quick
start guide. Read this. Read the
start guide. Read this. Read the
articles in here that it tells you to
articles in here that it tells you to
read. It's like a handful of blog post
read. It's like a handful of blog post
and a few academic papers. So, do that
and a few academic papers. So, do that
in chunks. You don't have to do it all
in chunks. You don't have to do it all
at once. Do like this plus maybe one or
at once. Do like this plus maybe one or
two blog posts. All right? and then go
two blog posts. All right? and then go
over to the docs
over to the docs
and implement a basic reinforcement
and implement a basic reinforcement
learning environment from scratch
learning environment from scratch
following these docs.
following these docs.
And if you have trouble with that, come
And if you have trouble with that, come
ask for help over here. This is how you
ask for help over here. This is how you
get into reinforcement learning. This is
get into reinforcement learning. This is
how almost all of our contributors have
how almost all of our contributors have
gotten into reinforcement learning. It
gotten into reinforcement learning. It
works even if you do not have like
works even if you do not have like
remotely any background. It'll just take
remotely any background. It'll just take
a little bit longer. You just have to do
a little bit longer. You just have to do
it.
it.
I've made it as easy as I possibly can
I've made it as easy as I possibly can
with reward engineered by a human.
with reward engineered by a human.
Sometimes
Sometimes
uh sometimes it depends on the problem
uh sometimes it depends on the problem
in the reward
to robot. I honestly I don't Yeah, I
to robot. I honestly I don't Yeah, I
don't I don't really care about the
don't I don't really care about the
whole political side of of all this
whole political side of of all this
stuff.
stuff.
It's kind of just like we're probably
It's kind of just like we're probably
going to come up with the dumbest pro
going to come up with the dumbest pro
the dumbest possible way to handle all
the dumbest possible way to handle all
of it. And like there's very little that
of it. And like there's very little that
you can do about that. The only thing
you can do about that. The only thing
that we can do is build good tech.
Go.
Average
Average
Oh, that's going to have to improve
Oh, that's going to have to improve
eventually, man. That's going to have to
eventually, man. That's going to have to
improve eventually.
My hope is that we develop tech that
My hope is that we develop tech that
actually allows us to be smarter
actually allows us to be smarter
because I can tell you with all the
because I can tell you with all the
stuff that I've built, like most of the
stuff that I've built, like most of the
time, I feel like barely smart enough to
time, I feel like barely smart enough to
make progress in all the stuff that I'm
make progress in all the stuff that I'm
doing, right? Like barely.
doing, right? Like barely.
There are like clear clear areas and
There are like clear clear areas and
like gaps in my own abilities where it's
like gaps in my own abilities where it's
like it's just straight up I don't know
like it's just straight up I don't know
why my brain doesn't let me do this
Like certain types of symbolic
Like certain types of symbolic
manipulation and stuff. It just doesn't
manipulation and stuff. It just doesn't
work for me.
I don't know.
Let's see if this works.
worst performing student.
I might
I might
PhD graduate. That's still not good
PhD graduate. That's still not good
enough, man.
enough, man.
That's still not good enough.
That's still not good enough.
Welcome, SPY.
Today's discussion topics include
Today's discussion topics include
multi-agent swarms, tactical battle
multi-agent swarms, tactical battle
sims, quantum physics,
sims, quantum physics,
and uh long-term AI progress. Welcome to
and uh long-term AI progress. Welcome to
Saturday stream.
This thing hasn't seeded yet.
This thing hasn't seeded yet.
Let me have more coffee.
I don't happen to have anybody watching
I don't happen to have anybody watching
that knows quantum physics and can tell
that knows quantum physics and can tell
me what lasers to order, right? That
me what lasers to order, right? That
would just be too lucky.
Single-handedly comes up with diffusion
Single-handedly comes up with diffusion
model.
It depends. Math is one axis, man. Like
It depends. Math is one axis, man. Like
there are a lot of really really good
there are a lot of really really good
math people at MIT and like far far
math people at MIT and like far far
fewer people at MIT that have like some
fewer people at MIT that have like some
sort of broad perspective on what to do
sort of broad perspective on what to do
with the math that they know.
Garbage. Garbage. Garbage.
Okay, this runs
Let's see if we can get the scripted
Let's see if we can get the scripted
thing to like do something.
thing to like do something.
How prioritized replay improve overall
How prioritized replay improve overall
agent action selection? Are you asking
agent action selection? Are you asking
about the original prioritized
about the original prioritized
experience replay or the version that we
experience replay or the version that we
have in puffer lip? Because they're two
have in puffer lip? Because they're two
very different things.
very different things.
Please clarify.
Please clarify.
Yes. What? Original or the puffer one?
Okay. So, puffer replay it's only done
Okay. So, puffer replay it's only done
over the experience that's collected in
over the experience that's collected in
a single epoch. Okay. So, it's it's a is
a single epoch. Okay. So, it's it's a is
it's as on policy as on policy data can
it's as on policy as on policy data can
be. So, we're not taking data from
be. So, we're not taking data from
previous epochs. Okay. And specifically
previous epochs. Okay. And specifically
what we're doing is we're using the
what we're doing is we're using the
prioritize replay sampling criterion
prioritize replay sampling criterion
because prioritize replay is just that.
because prioritize replay is just that.
It's a sampling criterion. It tells you
It's a sampling criterion. It tells you
what data to sample in what frequency
what data to sample in what frequency
based on in this case the advantage
based on in this case the advantage
function. We're using this to guide uh
function. We're using this to guide uh
how we sample from the experience
how we sample from the experience
collected just during this one last
collected just during this one last
epoch uh into many batches. So instead
epoch uh into many batches. So instead
of going over the data in chunks, we're
of going over the data in chunks, we're
sampling it according to the prioritized
sampling it according to the prioritized
replay uh math for sampling. That's all
replay uh math for sampling. That's all
we're doing. And this allows you to uh
we're doing. And this allows you to uh
bias the algorithm towards higher
bias the algorithm towards higher
information trajectory segments if you
information trajectory segments if you
want to think of it that way.
want to think of it that way.
That is what we do.
Double check my email real quick.
If I have a stream of data, I don't need
If I have a stream of data, I don't need
to think of LSTM manually. Just use the
to think of LSTM manually. Just use the
damn LSTM, man.
There's like no reason not to.
There's like no reason not to.
Our
Our
L we have LSTM support for everything
L we have LSTM support for everything
out of the box and the LSTM is literally
out of the box and the LSTM is literally
the far the fastest part of the network.
the far the fastest part of the network.
Like I can train a million parameter
Like I can train a million parameter
LSTM at a million steps per No, I'm
LSTM at a million steps per No, I'm
sorry. I can train a 4 million parameter
sorry. I can train a 4 million parameter
LSTM at a million steps per second. All
LSTM at a million steps per second. All
right, the LSTM is not a bottleneck.
right, the LSTM is not a bottleneck.
It's slow in other libraries because
It's slow in other libraries because
they're bad.
they're bad.
That's it.
Uh yeah, this is super freaking fast.
The hell
The hell
fault.
do this.
It's not that we think that LSTM is like
It's not that we think that LSTM is like
the holy grail of architectures or
the holy grail of architectures or
something like in 2019. It's just it's
something like in 2019. It's just it's
really fast.
really fast.
And it's like it's the most stable fast
And it's like it's the most stable fast
thing. Does that make sense? Like
thing. Does that make sense? Like
transformers are just not fast. At least
transformers are just not fast. At least
any variant that we've found is just not
any variant that we've found is just not
fast. And also they're a pain in the ass
fast. And also they're a pain in the ass
because like you get all these like off
because like you get all these like off
these like misalign trajectory segments
these like misalign trajectory segments
in RL. And uh you have to run a
in RL. And uh you have to run a
transformer on that context, which like
transformer on that context, which like
admittedly I could figure out how to do.
admittedly I could figure out how to do.
It wouldn't be terrible, but even then I
It wouldn't be terrible, but even then I
just don't think it would be fast. Like
just don't think it would be fast. Like
fundamentally
fundamentally
they aren't linear in time. So unless
they aren't linear in time. So unless
you actually had a good
you actually had a good
even linear in time wouldn't be good
even linear in time wouldn't be good
enough, frankly, because right now it's
enough, frankly, because right now it's
constant in time. Yeah, literally it's
constant in time. Yeah, literally it's
constant in time right now. And then
constant in time right now. And then
they go to quadratic in time. The best
they go to quadratic in time. The best
ones are linear in time and those don't
ones are linear in time and those don't
even work.
Things slow, man. Super slow.
Okay. Why are
Okay. Why are
are bots this fast?
Got these guys that are going at a
Got these guys that are going at a
normal speed and then these guys that
normal speed and then these guys that
are just like zoom.
Okay.
Oh,
Oh,
forgot this
dummy.
Yeah, there we go.
Huh?
There they are.
What is your goal with the lasers? Are
What is your goal with the lasers? Are
you trying to make an interferometer?
you trying to make an interferometer?
Uh
Uh
I basically want to run a double slit
I basically want to run a double slit
experiment that
experiment that
uh in which there are no moving parts
uh in which there are no moving parts
that change between the on and the off
that change between the on and the off
state. So the recording of data is
state. So the recording of data is
maximally isolated
maximally isolated
or the the recording of data is
or the the recording of data is
maximally isolated from the measurement
maximally isolated from the measurement
of data such that the recording off
of data such that the recording off
state produces interference.
Side project. Side project. Quantum
Side project. Side project. Quantum
physics research.
I do here.
This should now make these things fly
This should now make these things fly
much more reasonably maybe.
some weird thing happening when they get
some weird thing happening when they get
close to each other.
Take full
I was like looking to see if I uh if I
I was like looking to see if I uh if I
had responses on the other environment
had responses on the other environment
that I work on and they go, "Oh yeah,
that I work on and they go, "Oh yeah,
Saturday. Most people don't work
Saturday. Most people don't work
Saturday." Duh.
What have I done that's silly here that
What have I done that's silly here that
causes this behavior?
causes this behavior?
We should also just figure out what the
We should also just figure out what the
seg fault is, right?
But like look at this behavior. Ready?
But like look at this behavior. Ready?
So, they're going to get close and
So, they're going to get close and
they're going to accelerate.
Yeah, it's like they just get super
Yeah, it's like they just get super
fast.
fast.
Uh, how did
Uh, how did
I have something getting divide by zero,
I have something getting divide by zero,
right?
Yeah.
They start accelerating when they get
They start accelerating when they get
like relatively close.
Anybody
see it?
It have to be this somehow, but I don't
It have to be this somehow, but I don't
see it.
I mean, I could just clip it, but I
I mean, I could just clip it, but I
don't want to just like that. No, this
don't want to just like that. No, this
this should be the correct
weird distance.
Is it because I have to divide by square
Is it because I have to divide by square
root?
root?
I think it's got to be.
I think it's got to be.
It's got to be this.
I was trying to save compute, but I
I was trying to save compute, but I
think it might have been nonlinear.
think it might have been nonlinear.
See if this is it.
Yep, that was it.
Yep, that was it.
Okay. So, they don't know how to turn
Okay. So, they don't know how to turn
towards each other.
towards each other.
So, uh they don't actually fight.
So, uh they don't actually fight.
But yeah, that's the that's the issue.
But yeah, that's the that's the issue.
Me dumb. Square root not linear
Me dumb. Square root not linear
function. Duh.
I'm going to leave this up for a couple
I'm going to leave this up for a couple
minutes. We'll see if it's stable. I'll
minutes. We'll see if it's stable. I'll
leave this. So you can watch it. If
leave this. So you can watch it. If
anybody has any ideas how to do the math
anybody has any ideas how to do the math
to like turn these towards the target,
to like turn these towards the target,
it's probably just some sort of vector
it's probably just some sort of vector
multiply, some clot multiply. I will be
multiply, some clot multiply. I will be
right back. a couple quick things and we
right back. a couple quick things and we
will continue on this and we will uh
will continue on this and we will uh
once we get the ships to turn towards
once we get the ships to turn towards
each other basically we'll have like a a
each other basically we'll have like a a
simple scripted opponent to play against
simple scripted opponent to play against
and then the idea is that we'll be able
and then the idea is that we'll be able
to actually get a reasonable evaluation
to actually get a reasonable evaluation
metric which is win rate versus the
metric which is win rate versus the
opponent or whatever. Uh unlike the
opponent or whatever. Uh unlike the
current thing where it's all selfplay so
current thing where it's all selfplay so
you can't really get like a consistent
you can't really get like a consistent
metric and then we can optimize versus
metric and then we can optimize versus
that and then hopefully that'll give us
that and then hopefully that'll give us
some reasonable tactical behavior. We
some reasonable tactical behavior. We
take the same hyper prams, we throw it
take the same hyper prams, we throw it
on selfplay, and we get some like cool
on selfplay, and we get some like cool
thing to happen. Be right back. Oops. Be
thing to happen. Be right back. Oops. Be
right back.
Okay.
Okay.
What's the procedure
What's the procedure
to connect Neptune AI?
So,
you literally just make an account and
you literally just make an account and
then you paste your API key in. It's all
then you paste your API key in. It's all
it is.
it is.
And you just do d- Neptune
And you just do d- Neptune
and it'll pick it up.
All right.
Yep,
Yep,
that'll work.
You got to pip install Neptune.
You got to pip install Neptune.
Obviously,
what is tag? Tag just assigns it like a
what is tag? Tag just assigns it like a
little group in the dashboard so you can
little group in the dashboard so you can
sort your experiments. You don't have to
sort your experiments. You don't have to
tag it. It'll just go under the default
tag it. It'll just go under the default
tag if you don't tag it. We use it for
tag if you don't tag it. We use it for
mostly sweeps and like specific games
mostly sweeps and like specific games
and stuff.
Neptune's authenticating. So yeah. So
Neptune's authenticating. So yeah. So
technically I believe there's a default
technically I believe there's a default
project like Ablation somewhere.
project like Ablation somewhere.
Yeah. So right here there's also this
Yeah. So right here there's also this
project name. You should probably set
project name. You should probably set
these
token product. Yeah. So, there's a
token product. Yeah. So, there's a
default config. You can set these from
default config. You can set these from
command line train.name like or you can
command line train.name like or you can
just edit them in the default config.
just edit them in the default config.
Either way,
Either way,
you'll be good.
Okay. So, We unfortunately have some
Okay. So, We unfortunately have some
vector math to deal with,
vector math to deal with,
which should be easy, but for whatever
which should be easy, but for whatever
reason, never is.
Isn't it literally Okay, all I need to
Isn't it literally Okay, all I need to
do is I need a quaternian to rotate
do is I need a quaternian to rotate
towards the target, right?
Wait, rotate by quitterium.
using UV. That's fine. So I think then
using UV. That's fine. So I think then
you can do here. Look, if you just do
you can do here. Look, if you just do
puffer train uh puffer
puffer train uh puffer
help, it'll just tell you
- Neptune-
- Neptune-
Neptune name and Neptune project
Neptune name and Neptune project
apparently should do it
and let me know if that doesn't work.
Token isn't uh you don't pass token like
Token isn't uh you don't pass token like
that. So token you pass as an end
that. So token you pass as an end
variable or as an export. That's part of
variable or as an export. That's part of
Neptune. So if when you do like get my
Neptune. So if when you do like get my
API token or whatever, it'll tell you
API token or whatever, it'll tell you
how to export it,
how to export it,
it gives you the thing to just paste in
it gives you the thing to just paste in
or to put in your bash RC or whatever.
End. Yes, you put it in the end or
End. Yes, you put it in the end or
whatever. Make sure you source the file.
There you go.
How do you do this, man? So weird.
How do you do this, man? So weird.
I'm going to plug this into Grock
I'm going to plug this into Grock
against my better judgment.
I don't know what it is.
Whenever I get to geometry stuff with
Whenever I get to geometry stuff with
like
like
vector map for geometry, it's like I my
vector map for geometry, it's like I my
brain just stops working.
brain just stops working.
I don't know why.
I have no idea why this is unintuitive.
environment.
Yeah, it has all the information.
That's just Neptune. That's like Neptune
That's just Neptune. That's like Neptune
standard doc. So not puffer.
quturnian from vector 3 to ve did it
quturnian from vector 3 to ve did it
just make up a function that doesn't
just make up a function that doesn't
exist?
I think it did. modify
I think it did. modify
this.
Huh?
Some reason they didn't shoot each
Some reason they didn't shoot each
other.
Okay, so now they shouldn't actually get
Okay, so now they shouldn't actually get
to be on top of each other. We'll just
to be on top of each other. We'll just
have to figure out why they don't
have to figure out why they don't
actually fire.
is puffer lilib and by default a
is puffer lilib and by default a
parallel or sequential?
parallel or sequential?
Uh
Uh
kind of both. So our most of our ocean
kind of both. So our most of our ocean
environments the way they work is uh on
environments the way they work is uh on
each core you can simulate many
each core you can simulate many
environments in series that is the n of
environments in series that is the n of
num ms param and then vecnum ms will
num ms param and then vecnum ms will
allow you to multi-core those you have
allow you to multi-core those you have
multiple cores within multiple ends in
multiple cores within multiple ends in
serial on each core but then across
serial on each core but then across
cores is parallel
I don't know what happened there.
I don't know what happened there.
Roll through it.
Here we go.
Uh yeah, that's not supposed to happen.
Yeah, I was looking up that thing. So,
Yeah, I was looking up that thing. So,
the thing is that experiment is usually
the thing is that experiment is usually
done with um polarizing filters, isn't
done with um polarizing filters, isn't
it, Tyler?
which are a physical obstruction
which are a physical obstruction
and also like clearly have the like the
and also like clearly have the like the
effect of basically doing a change of
effect of basically doing a change of
basis where you project the polarized
basis where you project the polarized
like so all light is gone on one axis
like so all light is gone on one axis
but then you project it on a different
but then you project it on a different
coordinates so then you end up with half
coordinates so then you end up with half
of that back I didn't find that
of that back I didn't find that
experiment like or at least that version
experiment like or at least that version
of it particularly useful
I've also literally only been studying
I've also literally only been studying
quantum for like three days. I knew
quantum for like three days. I knew
nothing about quantum mechanics at all
nothing about quantum mechanics at all
three days ago. I've kind of just been
three days ago. I've kind of just been
binging lectures and like reading a
binging lectures and like reading a
bunch of stuff in my off hours.
Okay. So somehow these things they just
Okay. So somehow these things they just
get like
get like
got quantum entangled reinforcement
got quantum entangled reinforcement
learning agents.
learning agents.
You can see here
You can see here
see how that we figure this out.
Okay. So D.
This does. They should stop
This does. They should stop
like close to each other now.
And they should be fighting here.
It's actually a good question why
It's actually a good question why
they're not firing at each other here.
I think the angle's probably computed
I think the angle's probably computed
wrong.
Yeah, there we go.
Yeah, there we go.
Whether the damage values are reasonable
Whether the damage values are reasonable
or not, who knows? But it is the angle
or not, who knows? But it is the angle
somehow.
This branch of physics makes my head
This branch of physics makes my head
hurt.
hurt.
I don't know. It's it's been very cool.
The thing is like
the experiment that I'm trying to
the experiment that I'm trying to
conduct and I'll I'll tell you more once
conduct and I'll I'll tell you more once
I think about it a little bit but like
I think about it a little bit but like
if the experiment
if the experiment
if the experiment that I have in my head
if the experiment that I have in my head
works the way that
works the way that
um I think it should work according to
um I think it should work according to
the predictions of quantum mechanics
the predictions of quantum mechanics
then it would be like
then it would be like
it would essentially be like a thing
it would essentially be like a thing
that would just completely completely
that would just completely completely
break your understanding of reality
break your understanding of reality
without you having to know anything
without you having to know anything
about physics, if that makes sense.
And it would also have a bunch of like
And it would also have a bunch of like
actual useful applications of the tech
actual useful applications of the tech
as well. So,
as well. So,
physics cool.
I need to buy some lasers. Apparently,
I also have to look up safety
I also have to look up safety
precautions for working with lasers.
I've been trying to figure out like
I've been trying to figure out like
because I'm looking into all these
because I'm looking into all these
different branches of science now, many
different branches of science now, many
of which have like are actually they do
of which have like are actually they do
actual lab work. Um
actual lab work. Um
I kind of need to like go get myself lab
I kind of need to like go get myself lab
trained for a bunch of different areas
trained for a bunch of different areas
somehow.
somehow.
definitely buy some GL. Yeah, I probably
definitely buy some GL. Yeah, I probably
should like figure out how I can go get
should like figure out how I can go get
myself trained for like a bunch of
myself trained for like a bunch of
different types of lab work because I
different types of lab work because I
really have never done that type of
really have never done that type of
stuff. You know,
stuff. You know,
it's the one very unfortunate things
it's the one very unfortunate things
about working uh in AI is like you don't
about working uh in AI is like you don't
really need any equipment to do all this
really need any equipment to do all this
cool stuff that we do, but that also
cool stuff that we do, but that also
means you don't have any experience
means you don't have any experience
working with actual equipment of any
working with actual equipment of any
type. You kind of just sit here and type
type. You kind of just sit here and type
and then you make crazy happen. But
and then you make crazy happen. But
then as soon as you want to do something
then as soon as you want to do something
that doesn't just involve typing, you're
that doesn't just involve typing, you're
like, "Hey, I don't know what to do."
like, "Hey, I don't know what to do."
walk. I'm a mia
less than five
less than five
mango watts.
mango watts.
I think it was seven.
But it's the thing is it goes through an
But it's the thing is it goes through an
attenuator as well.
Yeah, it's seven.
It's this thing.
But then I think that you you basic I
But then I think that you you basic I
think that you try to like take the
think that you try to like take the
power down or like block most of it so
power down or like block most of it so
that you get a a relatively
that you get a a relatively
fewer number of photons out of it.
But I think like technically it's
But I think like technically it's
dangerous if you set it up wrong or
dangerous if you set it up wrong or
whatever cuz obviously the source is
whatever cuz obviously the source is
still seven mega uh seven mills or
still seven mega uh seven mills or
whatever.
I don't know. The lasers are actually
I don't know. The lasers are actually
super cheap. I would love to know why
super cheap. I would love to know why
some of this other stuff is so bloody
some of this other stuff is so bloody
expensive.
No.
Also, why it's nuked my shopping cart?
Manufactured in USA. Oh, I don't know.
Manufactured in USA. Oh, I don't know.
Maybe that's why lasers like that 20
Maybe that's why lasers like that 20
years ago were bloody expensive.
years ago were bloody expensive.
Yeah. I co-founder house drama slop
Yeah. I co-founder house drama slop
show. What?
show. What?
Yeah. I don't I I really don't care
Yeah. I don't I I really don't care
about the dumb things that SF people do.
about the dumb things that SF people do.
Like I I really don't care.
I'm really kind of just sick of the
I'm really kind of just sick of the
whole
whole
the whole like all of AI being B2B SAS
the whole like all of AI being B2B SAS
idiot wear is like that needs to go.
idiot wear is like that needs to go.
Come on, we're making cool tech. Let's
Come on, we're making cool tech. Let's
actually throw it on things that matter.
in light has potential
clout chasing. Yeah. Which is just lame
clout chasing. Yeah. Which is just lame
as
Like Tyler, do you know do you know what
Like Tyler, do you know do you know what
the easiest way would be for me to like
the easiest way would be for me to like
figure out uh what I need and where to
figure out uh what I need and where to
like what I should get for this type of
like what I should get for this type of
basic optic setup. But I you need like
basic optic setup. But I you need like
an optics breadboard and like you put it
an optics breadboard and like you put it
on I think it's like a meter or one by
on I think it's like a meter or one by
one or 2x two meter surface or whatever.
one or 2x two meter surface or whatever.
And like I think that there's some stuff
And like I think that there's some stuff
with like the lighting and all that like
with like the lighting and all that like
I need to figure that stuff out.
I don't know. I could technically stream
I don't know. I could technically stream
all this stuff, too. I have a spot right
all this stuff, too. I have a spot right
behind me. Just put this freaking table
behind me. Just put this freaking table
down behind me and we do we do quantum
down behind me and we do we do quantum
physics experiments on stream. That
physics experiments on stream. That
sounds fun.
I mean, it looks like the basic setup
I mean, it looks like the basic setup
can be obtained for a few grand, which
can be obtained for a few grand, which
is like I'm willing to spend that or uh
is like I'm willing to spend that or uh
do cool science.
particularly when there's a possibility
particularly when there's a possibility
that I discover something new.
Okay, I think I see how I did this
Okay, I think I see how I did this
wrong.
distance three angle.
Let me know what you're thinking about
Let me know what you're thinking about
buying. Oh yeah, I can send you the
buying. Oh yeah, I can send you the
list. I got to finish putting it
list. I got to finish putting it
together. Um, which I'll probably do
together. Um, which I'll probably do
like tomorrow in my spare time.
like tomorrow in my spare time.
Nanc pyometers for electron beam.
Nanc pyometers for electron beam.
Version interferometer for nancond.
Version interferometer for nancond.
Okay, that's actually that's a different
Okay, that's actually that's a different
application but pretty similar
application but pretty similar
equipment.
Yeah, that's pretty similar equipment
Yeah, that's pretty similar equipment
because it is kind of just optics
because it is kind of just optics
equipment for a lot of the quantum
if this does anything. So, this should
if this does anything. So, this should
give us the result that the drones fire
give us the result that the drones fire
at each other consistently.
Yep. So, they fire.
Yep. So, they fire.
That looks consistent to me.
That looks consistent to me.
That does it. We just have to do this
That does it. We just have to do this
for the rest of our uh
for the rest of our uh
Oh, wait. Hang on.
Oh, wait. Hang on.
Yes, that does it. So, we just have to
Yes, that does it. So, we just have to
do this for the rest of our um
do this for the rest of our um
attack functions.
by
word vector
word vector
target.
This looks good.
Uh, this one's easy.
Uh, this one's easy.
And this one
anti-air.
This one does have a range.
Wait. Attack any air.
Wait. Attack any air.
Bomber
Bomber
ground air.
ground air.
That's it.
That makes sense why the ships were
That makes sense why the ships were
flying in this weird fashion.
flying in this weird fashion.
Find it pretty weird that he skills with
Find it pretty weird that he skills with
the power and the beam.
the power and the beam.
I have not even gotten there, Tyler.
I have not even gotten there, Tyler.
I gotta figure a lot of stuff out still,
I gotta figure a lot of stuff out still,
man.
So basically I so first of all the
So basically I so first of all the
quantum stuff is just awesome and like
quantum stuff is just awesome and like
it's messing with me. So I think there's
it's messing with me. So I think there's
a possibility I actually might with the
a possibility I actually might with the
experiments I'm thinking about if they
experiments I'm thinking about if they
work in remotely the way that I think
work in remotely the way that I think
that they might then I could actually
that they might then I could actually
discover something really cool or at
discover something really cool or at
least let's say I could present
least let's say I could present
something that is known in a way that's
something that is known in a way that's
like
like
very
very
striking and actually would like it
striking and actually would like it
would change the way that a lot of
would change the way that a lot of
people look at stuff potentially. But
people look at stuff potentially. But
then separately, I'm kind of just trying
then separately, I'm kind of just trying
to understand a lot of like low-level
to understand a lot of like low-level
physics. Uh because it applies to
physics. Uh because it applies to
everything, right? It applies to
everything, right? It applies to
chemistry, it applies to physics itself,
chemistry, it applies to physics itself,
it applies to material science. And I'm
it applies to material science. And I'm
sort of starting to think about like
sort of starting to think about like
low-level real world simulation
low-level real world simulation
uh for, you know, aiding scientific
uh for, you know, aiding scientific
discovery and for advancing science and
discovery and for advancing science and
how we think about doing that.
Okay, so this looks way better. This
Okay, so this looks way better. This
looks like way more reasonable,
looks like way more reasonable,
right? Army's doing things.
right? Army's doing things.
Why are you guys going over there? That
Why are you guys going over there? That
doesn't make any sense to me.
doesn't make any sense to me.
Oh, it's cuz these ones are not
Oh, it's cuz these ones are not
controlled by our scripted AI.
controlled by our scripted AI.
That's fine then.
That's fine then.
That's actually a good indicator maybe.
That's actually a good indicator maybe.
Yeah, because like this army is hunting
Yeah, because like this army is hunting
that army and it's kind of doing an okay
that army and it's kind of doing an okay
job of it.
Cool.
Cool.
So, we can actually train versus this
So, we can actually train versus this
now
and maybe get like a actual real result.
I was baffled about what's tried.
I was baffled about what's tried.
I don't think we have though.
I don't think we have though.
When I look around, I see like so many
When I look around, I see like so many
things that have not been done, man.
things that have not been done, man.
But perhaps it's because I'm coming in
But perhaps it's because I'm coming in
from an outside perspective, right? Like
from an outside perspective, right? Like
the things I would think of are very
the things I would think of are very
very they're going to be very very
very they're going to be very very
different from the things that you'd
different from the things that you'd
think of based on being trained in the
think of based on being trained in the
field. And half of them aren't going to
field. And half of them aren't going to
make any sense, but who knows? Maybe
make any sense, but who knows? Maybe
some end up being novel.
some end up being novel.
I got a pretty good track record of
I got a pretty good track record of
doing that within reinforcement learning
doing that within reinforcement learning
as well to be fair.
Okay. Yeah. So fixing those dynamics
Okay. Yeah. So fixing those dynamics
immediately fixed a whole bunch of the
immediately fixed a whole bunch of the
problems we had
about score
hardly find the sol problem.
Outlook.
I don't know. We'll see.
I don't know. We'll see.
That tends to be the thing that I'm
That tends to be the thing that I'm
usually pretty good at,
usually pretty good at,
to be fair, is like coming up with weird
to be fair, is like coming up with weird
that nobody's thought of.
I'm not beating anyone in the I'm not
I'm not beating anyone in the I'm not
out like I'm not solving equations
out like I'm not solving equations
better than the next guy. I'll tell you
better than the next guy. I'll tell you
that
a lot of the stuff I've done in RL was
a lot of the stuff I've done in RL was
just like a dramatic perspective shift
just like a dramatic perspective shift
on how the field was done before.
Where exponentials
of error?
kind of thinking needed for progress. I
kind of thinking needed for progress. I
don't know. It's been somewhat It's been
don't know. It's been somewhat It's been
pretty effective at least in the domains
pretty effective at least in the domains
where I've worked.
Like I kind of think of it this way,
Like I kind of think of it this way,
right? Like when I'm at MIT and there
right? Like when I'm at MIT and there
are like a ton of people who are really
are like a ton of people who are really
good at the math, right? And there are
good at the math, right? And there are
like hundreds of RL papers on the math
like hundreds of RL papers on the math
and we're kind of stuck. Well, I'm sure
and we're kind of stuck. Well, I'm sure
as hell not making any progress just by
as hell not making any progress just by
thinking about the math more, right?
thinking about the math more, right?
Like the core algorithm more. That's how
Like the core algorithm more. That's how
I came up to the approach that I came
I came up to the approach that I came
with Puffer, right? I was like looking
with Puffer, right? I was like looking
at the type of stuff that fundamentally
at the type of stuff that fundamentally
people were not looking at.
1 megawatt 1 matt laser with a 1 millm
1 megawatt 1 matt laser with a 1 millm
squared beam
volts per meter for high intensity laser
changes with density.
Uh yeah, I would just have to look at
Uh yeah, I would just have to look at
the
the
I would need to go look at the the
I would need to go look at the the
freaking uh I'd need to go look at like
freaking uh I'd need to go look at like
the reference equation for that.
the reference equation for that.
The grow with like square or something.
The grow with like square or something.
I don't know.
For what it's worth, I am actually at
For what it's worth, I am actually at
least now trying to learn enough of the
least now trying to learn enough of the
math quantum. I kind of have to
Accelerate
more particles more compact with high
more particles more compact with high
intensity light source.
I I think the only thing I need for my
I I think the only thing I need for my
specific experiment is I need to filter
specific experiment is I need to filter
it down to a reasonable number of
it down to a reasonable number of
particles,
particles,
which I think I think that's just a
which I think I think that's just a
filter. There
OD filters we say every second there's
OD filters we say every second there's
high probability
high probability
I don't need second level re I literally
I don't need second level re I literally
all I need to know is like that there is
all I need to know is like that there is
still some interference
still some interference
um and it's not like because I have too
um and it's not like because I have too
many go like too many going through
many go like too many going through
simultaneously
simultaneously
like I can have like ideally I would
like I can have like ideally I would
like to have on the order of a thousand
like to have on the order of a thousand
photons going through per second and be
photons going through per second and be
able to tune it up to a million for
able to tune it up to a million for
instance
which I think I should be able to do
which I think I should be able to do
with uh setup I have or the setup I'm
with uh setup I have or the setup I'm
thinking of getting
What are our current rewards?
What are our current rewards?
Negative one for crashing
0.25. 25. We're hitting uh an enemy
curse a bunch. Yeah,
we're going to have to at least crack
we're going to have to at least crack
one code of the universe with all the
one code of the universe with all the
research I'm doing, right?
research I'm doing, right?
Something
Something
kind of made RL work. Pretty cool.
We in a position to make it happen.
A lot of this it just takes a lot of
A lot of this it just takes a lot of
work. A lot of this stuff does. Can do
work. A lot of this stuff does. Can do
it though.
Why wouldn't the learning here be
Why wouldn't the learning here be
stable, right?
With the score specifically,
this could literally be hyper prim sweep
this could literally be hyper prim sweep
though at this point.
though at this point.
We should kind of just run one like go
We should kind of just run one like go
set up a quick hyper pram sweep.
Oh yeah, hang on.
Oh yeah, hang on.
That's kind of doing something.
That's kind of doing something.
It's just unstable. I think
It's just unstable. I think
it starts learning and you get these
it starts learning and you get these
crashes.
crashes.
Let's figure this out how we're going to
Let's figure this out how we're going to
set this up.
Even need to sweep this stupid thing, do
Even need to sweep this stupid thing, do
we?
Yeah, let's just let's set up a sweep
Yeah, let's just let's set up a sweep
and then we can go do robotics in the
and then we can go do robotics in the
meantime. It'll be a smart thing to do.
Go grab the 5090 box.
I don't know why I just tried to SSH to
I don't know why I just tried to SSH to
my website.
Oh, cool. Stone says he'll drop by after
Oh, cool. Stone says he'll drop by after
uh after brunch. So, we'll actually have
uh after brunch. So, we'll actually have
a robotics pro to uh help us out with
a robotics pro to uh help us out with
what we're doing.
Okay, so they're battle trains pretty
Okay, so they're battle trains pretty
Back.
Cool. So this should what this should do
Cool. So this should what this should do
is in the background this will run a
is in the background this will run a
bunch of experiments and it'll basically
bunch of experiments and it'll basically
just tell us whether there are better
just tell us whether there are better
hyperparameters we can use to get
hyperparameters we can use to get
something to learn and if they're not
something to learn and if they're not
then there's still something wrong with
then there's still something wrong with
the end. If it does then yay we have
the end. If it does then yay we have
cool uh cool results.
What?
Okay.
Okay.
Make sure that this is actually running.
See, then um if this actually is good,
See, then um if this actually is good,
then we'll start on the robotics with be
then we'll start on the robotics with be
able to do uh let's actually just start
able to do uh let's actually just start
pulling the the hyper prams from this
pulling the the hyper prams from this
sweep.
Oh.
So, here are all the experiments we ran.
Here are all the good experiments that
Here are all the good experiments that
we ran.
And here are all the grade experiments
And here are all the grade experiments
that we ran.
So what we'll do is we'll just take
So what we'll do is we'll just take
this.
We'll pick whichever of these did uh the
We'll pick whichever of these did uh the
fastest.
fastest.
Looks to be I like the look of this um
Looks to be I like the look of this um
purple curve right here.
Grab this purple curve.
Yeah. Yeah. Yeah. Yeah.
back.
But really, this is like only a partial
But really, this is like only a partial
sweep. I don't know if we did um max
sweep. I don't know if we did um max
not
do like this. Yeah.
64 BPT horizon from the sweep. Okay.
64 BPT horizon from the sweep. Okay.
Very very high clip co.
Apparently I had lambda wrong.
and gamma of 088
and gamma of 088
with our tuning.
with our tuning.
Actually, I'd like to figure out for
Actually, I'd like to figure out for
stone real quick the uh the spread of
stone real quick the uh the spread of
gamas.
gamas.
Do that super high learning rate.
prior replay co-ops.
And uh this is is this 15 mil steps?
And uh this is is this 15 mil steps?
15 mil steps.
15 mil steps.
Kind of weird because it doesn't need 15
Kind of weird because it doesn't need 15
mil steps, right?
mil steps, right?
Come back to that one.
Come back to that one.
Then we have our coats here.
Then we have our coats here.
Our mostly sane kind of low value
Our mostly sane kind of low value
function clip. Really care about these
function clip. Really care about these
trace clips.
trace clips.
Uh update epox one. So I don't think I
Uh update epox one. So I don't think I
swept that.
swept that.
and total time steps.
It's kind of good by uh before that, but
It's kind of good by uh before that, but
we'll do 15
we'll do 15
15 mil
to match
We'll see.
We'll see.
Let's just run this.
And in the meantime,
And in the meantime,
just do a little analysis.
I should have added a score variable so
I should have added a score variable so
I don't have to read my uh my charts,
I don't have to read my uh my charts,
but
but
okay.
Did you see the post with the RF filter
Did you see the post with the RF filter
made by AI that looked like a QR code?
made by AI that looked like a QR code?
That was hilarious.
I didn't see that.
Could be good for micro strip
Could be good for micro strip
mic. What? What do you mean micro strip
mic. What? What do you mean micro strip
problems?
table runs from 0.8 gamma to 0.9 gamma.
table runs from 0.8 gamma to 0.9 gamma.
What this says
a lot of RF is on a PCB. Microchip is
a lot of RF is on a PCB. Microchip is
essentially having some conductive
essentially having some conductive
material on the bottom and top and a
material on the bottom and top and a
substrate between
substrate between
geometries of the structure. Oh, okay.
geometries of the structure. Oh, okay.
Yeah. So, this is like the type of stuff
Yeah. So, this is like the type of stuff
where I'd need to learn more about the
where I'd need to learn more about the
actual problem and like what it would
actual problem and like what it would
take to simulate stuff, right? And this
take to simulate stuff, right? And this
is actually one of the things I'm trying
is actually one of the things I'm trying
to do with quantum is to like go as low
to do with quantum is to like go as low
level as possible and then build back up
level as possible and then build back up
because like if you have to simulate
because like if you have to simulate
stuff on the level of what is described
stuff on the level of what is described
by quantum mechanics, you're screwed,
by quantum mechanics, you're screwed,
right? Like it's just the most
right? Like it's just the most
ridiculously expensive sim ever. And
ridiculously expensive sim ever. And
then if you go up and you have to
then if you go up and you have to
simulate stuff on an atomic level, okay,
simulate stuff on an atomic level, okay,
that's very slow. Like get away with
that's very slow. Like get away with
just simulating molecules and like vague
just simulating molecules and like vague
estimates of forces. They can go up with
estimates of forces. They can go up with
simulating just like material behaviors
simulating just like material behaviors
and it goes up from there.
and it goes up from there.
Me find that post.
Huh.
Yeah, that's a really really dumb
Yeah, that's a really really dumb
application of generative AI. RL would
application of generative AI. RL would
crush that
crush that
if you had a fast sim.
you basically it comes down to how fast
you basically it comes down to how fast
you can make a good enough like a good
you can make a good enough like a good
enough sim of the RF board. Man,
as you know, I talk about the amount of
as you know, I talk about the amount of
data we train on all the
Yeah, stone things better.
How's comment? Yeah, I don't know what
How's comment? Yeah, I don't know what
that is.
I do suspect that a lot of these Sims
I do suspect that a lot of these Sims
are just slow.
Ah, here we are. Our perfect
Ah, here we are. Our perfect
are perfect solve.
That's the battle sim.
Nice.
Nice.
Uh, and this thing ran
Uh, and this thing ran
less than 5 minutes.
So maybe we go find a harder tasks.
Someone told me some of them.
Someone told me some of them.
See what he sent me originally.
I got to scroll way up. I apparently I
I got to scroll way up. I apparently I
bothered him a whole bunch about a lot
bothered him a whole bunch about a lot
of things.
of things.
Going to have some nice results.
Peg insertion is unsolved.
Peg insertion side V1
push T.
Okay.
Egg insertion
Egg insertion
side one.
See what this does.
Trains able
enough rate, I guess.
So, let's see what they
So, let's see what they
their docks.
This is peg insert insertion.
Oh, we can do that.
Oh, we can do that.
Yeah, we can freaking do that.
A peg.
A peg.
Oh, do they not have it? No, they do.
Oh, do they not have it? No, they do.
It's right here.
Okay. So, it's not that bad in the sense
Okay. So, it's not that bad in the sense
that it's supposed to start learning
that it's supposed to start learning
uh after
some number of mills.
Our returns are not going to match at
Our returns are not going to match at
all is the annoying bit. But
the turn goes up immediately and then it
the turn goes up immediately and then it
takes a while.
takes a while.
Okay.
Word goes up.
Word goes up.
annoying
how long this type of stuff takes.
how long this type of stuff takes.
Um, you know what?
This is GPU bound, right?
Why don't we like 6x this speed?
Why don't we like 6x this speed?
Get this running DD. Uh, get this
Get this running DD. Uh, get this
running DDP.
running DDP.
They probably don't even have the
They probably don't even have the
ability to do that.
We'll probably We'll just do that.
We'll probably We'll just do that.
Um
Huffarell is programmatic interface. Uh
Huffarell is programmatic interface. Uh
yeah, you can just import stuff from
yeah, you can just import stuff from
there if you want to use it as an API.
Time to fix broken power supply. Very
Time to fix broken power supply. Very
fun.
We are doing more physics stuff. So do
We are doing more physics stuff. So do
drop by from time to time.
use command line interface or API. So
use command line interface or API. So
because I'm developing the project, I
because I'm developing the project, I
have a local install of it from source
have a local install of it from source
and I do a mix of editing command line
and I do a mix of editing command line
args for experiments and editing code
args for experiments and editing code
directly.
That's mostly because I'm the developer
That's mostly because I'm the developer
of it, though.
Yep, you can do that.
There's an example as well like in the
There's an example as well like in the
docs there all these examples. One of
docs there all these examples. One of
them shows you like basic usage of the
them shows you like basic usage of the
programmatic interface
config back end.
Yeah. So if I'll show you if you go here
examples
examples
puffer importable.
There you go.
Let me know if you run into any issues
Let me know if you run into any issues
with that.
with that.
Not we will
impressed with puffer liib. Thank you.
impressed with puffer liib. Thank you.
Very easy to learn. That's the goal.
Very easy to learn. That's the goal.
It's very lightweight, so now they're
It's very lightweight, so now they're
not going to be like options for
not going to be like options for
literally everything you want to do.
literally everything you want to do.
Sometimes you'll have to edit code, but
Sometimes you'll have to edit code, but
it's meant to be very lightweight.
it's meant to be very lightweight.
You know, RLI is a nightmare.
Dang heavy.
domain to upload tutorial.
Always just make GitHub pages.
Always just make GitHub pages.
RL mind.
RL mind.
That's funny. You were able to get that.
I got lucky that I got a puffer. Nobody
I got lucky that I got a puffer. Nobody
had it
like my puffer domain.
Going like puffer. The puffer is so
Going like puffer. The puffer is so
friendly.
Look. Very friendly.
Very friendly fish.
They're very curious, too. If you've
They're very curious, too. If you've
ever been like snorkeling, they will uh
ever been like snorkeling, they will uh
they'll just come up to you and be like,
they'll just come up to you and be like,
"Hey, yo, what's up?
cuz that works lovely.
Let's uh add this
There we are.
Now we also have to
How do you convert the those render for
How do you convert the those render for
website.
website.
Um, so in our C environments,
Um, so in our C environments,
yes. Well, it doesn't natively run
yes. Well, it doesn't natively run
Python. No, but we have environments
Python. No, but we have environments
that are in C, right? We uh we have a
that are in C, right? We uh we have a
build ocean script. It scripts build
build ocean script. It scripts build
ocean or whatever. And there's a web GPU
ocean or whatever. And there's a web GPU
option. If you just build for web with
option. If you just build for web with
mcript inton,
mcript inton,
copy that directly into a website.
I built it.
It's one of several environments. That's
It's one of several environments. That's
like maybe a few days worth of work,
like maybe a few days worth of work,
something like that.
like of the environments that we have on
like of the environments that we have on
the website.
the website.
Um, I built neural MMO 3, Moa, Snake,
Um, I built neural MMO 3, Moa, Snake,
Convert,
Convert,
uh, the sample environments down here.
uh, the sample environments down here.
Yeah, I've built like a few of them,
Yeah, I've built like a few of them,
right?
right?
By far the most complex of any of them
By far the most complex of any of them
uh to build was neural MMO.
This was something like truly
This was something like truly
complicated
by a mile.
How do you manipulate 3DN? What do you
How do you manipulate 3DN? What do you
mean?
How do I draw it? We use Ray Lib for
How do I draw it? We use Ray Lib for
drawing about it. It's like a very
drawing about it. It's like a very
lightweight like just header library
and see.
Yep.
Yep.
Very nice. I like that library a lot.
Okay, so we have this going here.
Okay, so we have this going here.
We're going to start on
We're going to start on
distributed stuff in a second.
Is that faster than JavaScript? Yes.
And you would also literally have to
And you would also literally have to
rewrite all of the code in JavaScript,
which I know an RL team that has done
which I know an RL team that has done
that and it's horrible.
that and it's horrible.
Not fun JavaScript. Be right back.
Uh-huh. This is now This is doing
Uh-huh. This is now This is doing
something.
something.
This is still not doing anything.
Possibly his hypers just aren't good.
Possibly his hypers just aren't good.
The return is very very low.
That's interesting.
Oh man, Kyle's got this massive thread.
horrifying. This is I have no idea what
horrifying. This is I have no idea what
the heck what I don't know what's going
the heck what I don't know what's going
on in robotics land, but uh yeah,
on in robotics land, but uh yeah,
sketchy.
Okay. So, this did not replicate the
Okay. So, this did not replicate the
result.
Something must be different here. Yeah.
Something must be different here. Yeah.
Oh, it's probably the config isn't
Oh, it's probably the config isn't
pulled, right?
Yeah. I'm dumb. Okay. Try that again.
Yeah. I'm dumb. Okay. Try that again.
Config this time.
will this fly in the meantime.
man scale render is not written in C.
man scale render is not written in C.
I don't think so. We do not have that on
I don't think so. We do not have that on
the website.
Oh, I see what I did.
How do you publish that then? We don't
How do you publish that then? We don't
have Manny skill on the website.
Like I on like almost nobody has live
Like I on like almost nobody has live
demos of RL on the website. That's not
demos of RL on the website. That's not
standard. That's pretty much just us and
standard. That's pretty much just us and
like maybe a couple other people.
So, in the meantime,
So, in the meantime,
this ain't working.
That works.
Does Puffer CLI work on globally? What
Does Puffer CLI work on globally? What
do you mean on globally?
Uh it should work everywhere provided
Uh it should work everywhere provided
that um
uh I bu I think that the caveat is like
uh I bu I think that the caveat is like
if you're loading custom configs need to
if you're loading custom configs need to
run it from the directory of those
run it from the directory of those
configs because there isn't a variable
configs because there isn't a variable
that tells you where custom configs go.
Okay, this works. Lovely.
Okay, this works. Lovely.
Now, what we get to do is something very
Now, what we get to do is something very
fun. Get to see how fast it goes.
fun. Get to see how fast it goes.
Um,
how to pass that device.
The args of train is a dictionary.
The args of train is a dictionary.
You look at it, you'll see that it has
You look at it, you'll see that it has
all the attributes from the help menu.
all the attributes from the help menu.
It's not like a special fancy class or
It's not like a special fancy class or
anything. You can just add it to the
anything. You can just add it to the
dictionary.
You can use our CLI parser if you want.
You can use our CLI parser if you want.
Our CLI parser is also in PRL. Um or you
Our CLI parser is also in PRL. Um or you
can just add it to the dictionary
can just add it to the dictionary
however you'd like.
We'll see if this gets us distributed
We'll see if this gets us distributed
any skill.
Hopefully it does.
Well, I think it's up to us to get Manny
Well, I think it's up to us to get Manny
skill to work on um multiGPU.
If I use device equal MPS, what happens?
If I use device equal MPS, what happens?
No idea.
No idea.
What's MPS? Mac stuff.
Try it. What happens?
5 minutes later.
5 minutes later.
No, it should be fine.
works. There you go. I'm not doing
works. There you go. I'm not doing
anything that should make it not work,
anything that should make it not work,
though,
though,
you know.
Doubled PF. There you go.
Fortunately, double of a small number is
Fortunately, double of a small number is
still a small number, but it's better
still a small number, but it's better
than nothing.
than nothing.
Second fly for me to kill. I can't.
We're officially fly free in this
We're officially fly free in this
building for the time being.
set up when they advertise how fast
set up when they advertise how fast
their chips are
their chips are
and then give you one less than onetenth
and then give you one less than onetenth
of one GPU perf
update doc Hey,
silicon.
Uh, I guess I could do that. Yeah,
it's still going to be like the things
it's still going to be like the things
are all still going to be slow. Is that
are all still going to be slow. Is that
Is that actually using the full
Is that actually using the full
Oh, that I could do. Is is it actually
Oh, that I could do. Is is it actually
um
um
is that using the entire chip? Like the
is that using the entire chip? Like the
entire chip still only gets you 260k.
Only six of them are working.
Well, you can figure out then why the
Well, you can figure out then why the
hell that doesn't work. But
hell that doesn't work. But
total
um
well, apparently they don't work like
well, apparently they don't work like
CUDA corores then because
CUDA corores then because
uh the back end should call should use
uh the back end should call should use
all of them basically.
annoying.
I'm increasing 10%. I don't know
your memory, your system memory.
VRAM is GP is GPU memory.
0%.
I I don't know how that works with MPS.
I I don't know how that works with MPS.
Like you don't have It's probably the
Like you don't have It's probably the
monitoring tool is expecting CUDA and
monitoring tool is expecting CUDA and
like it's not going to work for MPS to
like it's not going to work for MPS to
tell you, but like it Yeah, it's going
tell you, but like it Yeah, it's going
to be like that runs pvml or whatever.
do with This
is what
make. Well, no, because that'll put your
make. Well, no, because that'll put your
device on
device on
that'll put your device on CPU
that'll put your device on CPU
if uh you're not on a Mac.
think we could add max support natively.
Uh I
Uh I
I'd have to think about a good way to do
I'd have to think about a good way to do
it with the config,
it with the config,
but yeah, possibly could do
but yeah, possibly could do
it. You have to be a little careful
it. You have to be a little careful
because if you hardcode devices like
because if you hardcode devices like
that, there are other things you can
that, there are other things you can
Take
The stone just confirmed.
have a name machine.
Try this.
30k.
I'll show you the crazy part about that
I'll show you the crazy part about that
in just a second.
Okay, so this apparently runs. Cool.
Okay, so this apparently runs. Cool.
Okay, watch this.
Uh, done. This is not going to work, I
Uh, done. This is not going to work, I
guess. Okay. Puffer train. Puffer.
250K on CPU.
250K on CPU.
That hardware just sucks.
It is unfortunately that simple.
I used to use Macs growing up as well.
I used to use Macs growing up as well.
like I used Max for like six years or
like I used Max for like six years or
whatever.
whatever.
Um, and it's just like
Um, and it's just like
it boggles my mind that people use them
it boggles my mind that people use them
as much as they do in tech for like
as much as they do in tech for like
anything.
Yeah. As was I. And it's just like,
Yeah. As was I. And it's just like,
yeah, these things are awful.
They're just I I don't understand like
They're just I I don't understand like
why people use them. They're just they
why people use them. They're just they
suck for any actual computing. And then
suck for any actual computing. And then
like okay, you can use them to SSH to
like okay, you can use them to SSH to
your other hardware, but then you just
your other hardware, but then you just
have like an overpriced like thing that
have like an overpriced like thing that
doesn't even have the same development
doesn't even have the same development
environment as you're going to use for
environment as you're going to use for
your actual jobs. So now you have to
your actual jobs. So now you have to
debug your stupid Mac errors in addition
debug your stupid Mac errors in addition
to your stupid normal errors. It's just
to your stupid normal errors. It's just
like terrible.
I can't even tell you the amount of
I can't even tell you the amount of
errors where it's like but like it like
errors where it's like but like it like
doesn't work on my Mac and it's just
doesn't work on my Mac and it's just
like god damn
Yeah. So, this actually does go to um
Yeah. So, this actually does go to um
device
Last.
Go
idx. Practice.
this you and me on live.
this you and me on live.
Uh let me see. I think that according to
Uh let me see. I think that according to
the live stream,
the live stream,
no there are five people watching
no there are five people watching
according to this plus maybe some on X.
according to this plus maybe some on X.
It doesn't actually tell you X. Just
It doesn't actually tell you X. Just
tells you uh YouTube and Twitch.
Not everyone chats. People just leave
Not everyone chats. People just leave
stream on in the background while
stream on in the background while
they're doing work or other stuff. often
they're doing work or other stuff. often
times.
Yeah, shoot.
How much does compress increase
the length of the observation space? It
the length of the observation space? It
depends what you do in the process. It
depends what you do in the process. It
the answer could be not at all. Like if
the answer could be not at all. Like if
I just add a bunch of extra zeros to the
I just add a bunch of extra zeros to the
observation space, it's not going to
observation space, it's not going to
change Anything?
time in memory.
time in memory.
Um,
Um,
that depends a little bit more.
that depends a little bit more.
So, typically it'll increase the
So, typically it'll increase the
bandwidth,
bandwidth,
the CPU to GPU transfer bandwidth, which
the CPU to GPU transfer bandwidth, which
can add a little bit of overhead.
can add a little bit of overhead.
It's not going to make the network very
It's not going to make the network very
much slower though. It just makes the
much slower though. It just makes the
encoding layer slower. That's it.
When you make the the observation size
When you make the the observation size
really big, you like the biggest thing
really big, you like the biggest thing
is the CPU GPU bandwidth transfer being
is the CPU GPU bandwidth transfer being
annoying.
annoying.
And actually, we have ways to mitigate
And actually, we have ways to mitigate
that. Um, I just haven't gotten around
that. Um, I just haven't gotten around
to doing that yet.
Something is screwy here.
Make tank n.
Make tank n.
Oh, those obs are tiny. Those are like
Oh, those obs are tiny. Those are like
um
um
121 bytes.
121 bytes.
11 by 11 with uh Uint 8.
11 by 11 with uh Uint 8.
The bigger M's have like maybe 2 to 4
The bigger M's have like maybe 2 to 4
kilobyte observations.
kilobyte observations.
Neural MMO 3 is 1700 bytes.
OBS are on the wrong device. Interesting
OBS are on the wrong device. Interesting
enough.
enough.
OBS be on the wrong device.
Big CSV as a data set from a continuous
Big CSV as a data set from a continuous
envis log.
envis log.
Well, you certainly aren't going to put
Well, you certainly aren't going to put
CSV in. You're going to put the contents
CSV in. You're going to put the contents
of CSV. I don't know how you have a CS.
of CSV. I don't know how you have a CS.
How do you have a big CSV
as an RLN beenput?
know what the end is.
and pass cuda n to thim back end.
and pass cuda n to thim back end.
Okay,
20 columns on it.
20 columns on it.
I I don't understand how you have 20 col
I I don't understand how you have 20 col
like
like
Your observation is what the agency is
Your observation is what the agency is
at one specific time step, right?
So if your column is data and then rows
So if your column is data and then rows
are the time, you know, you get like one
are the time, you know, you get like one
entry, then it's probably only one row
entry, then it's probably only one row
of the table.
Well, then if it's one row, it's 20
Well, then if it's one row, it's 20
floats, which is nothing. So, you're
floats, which is nothing. So, you're
fine,
fine,
right?
fixed length each time full row. Yeah,
fixed length each time full row. Yeah,
something like that
something like that
should Okay.
need to do anything. If I want to show
need to do anything. If I want to show
agent previously observed data, just use
agent previously observed data, just use
the LSTM.
You're trying to do non-standard stuff
You're trying to do non-standard stuff
without knowing like without even like
without knowing like without even like
knowing the basic thing first, which
knowing the basic thing first, which
will almost certainly solve your
So the LSTM by definition, right, you
So the LSTM by definition, right, you
show it one observation, it makes a
show it one observation, it makes a
decision. It has memory. It can choose
decision. It has memory. It can choose
to remember stuff. It can learn to
to remember stuff. It can learn to
remember stuff rather from previous data
remember stuff rather from previous data
points.
Looks like uh I'm jumping on a call with
Looks like uh I'm jumping on a call with
Stone.
We get to do a robotics arc.
Whoops. Can you How do I plug that in
Whoops. Can you How do I plug that in
with pop? It's literally the default.
Don't have to do anything.
Don't have to do anything.
Like as long as your config has the
Like as long as your config has the
recurrent policy in it, it's it's
recurrent policy in it, it's it's
literally the default
any size.
any size.
Uh you can look at some of the configs
Uh you can look at some of the configs
for examples. We default to 128 hidden.
for examples. We default to 128 hidden.
There are other M's that we do like 256
There are other M's that we do like 256
or 512.
or 512.
Hey. Oh, hey Stone. Hey.
Hey. Oh, hey Stone. Hey.
Cool. Ready to solve robotics?
Cool. Ready to solve robotics?
Yes, I would love to get this multiGPU
Yes, I would love to get this multiGPU
thing working. I know it's been an issue
thing working. I know it's been an issue
a little bit recently. Let me Hang on.
a little bit recently. Let me Hang on.
Let me share my screen on this so that
Let me share my screen on this so that
you don't get
you don't get
delayed.
delayed.
You're getting I don't I don't want you
You're getting I don't I don't want you
to have the delay from this.
to have the delay from this.
Sure.
Sure.
Okay. On second monitor here. So,
actually, let's I can even do like this.
actually, let's I can even do like this.
So by wait by the way are you think
So by wait by the way are you think
course distributed? How are you doing
course distributed? How are you doing
the distributed training? Hang on. Let
the distributed training? Hang on. Let
me
me
if I just do it this way here. See if
if I just do it this way here. See if
this does if legible.
this does if legible.
Yeah I can I see you and yeah. So uh
Yeah I can I see you and yeah. So uh
this is what we're doing. We just use
this is what we're doing. We just use
run for this and we have this set up in
run for this and we have this set up in
puffer lib. So this thing here, this is
puffer lib. So this thing here, this is
the exact way that I ran uh one pabyte
the exact way that I ran uh one pabyte
of observations on neural MMO 3. Okay.
of observations on neural MMO 3. Okay.
So what are these commands doing? What's
So what are these commands doing? What's
nodes and what's n proc per node mean?
nodes and what's n proc per node mean?
So it's one machine and then six GPU. So
So it's one machine and then six GPU. So
each proc is a GPU. Okay. Yes. Not CPU.
each proc is a GPU. Okay. Yes. Not CPU.
Yes. And then does it not set
Yes. And then does it not set
environment variables? Uh no, but I just
environment variables? Uh no, but I just
did that and that doesn't help.
did that and that doesn't help.
Can I see the issue you got when you did
Can I see the issue you got when you did
that? Yes. So, uh, well, to be fair, it
that? Yes. So, uh, well, to be fair, it
is actually erroring in one of the
is actually erroring in one of the
things that I added, which is this last
things that I added, which is this last
reward thing. I'll run it again for you
reward thing. I'll run it again for you
fresh.
I have not gotten the side uh pegert
I have not gotten the side uh pegert
task to do anything yet, but we So, this
task to do anything yet, but we So, this
is me trying to set the device
is me trying to set the device
here.
here.
They're two sort of separate things,
They're two sort of separate things,
right? So, you can see that this is not
right? So, you can see that this is not
available. And then if I go into the you
available. And then if I go into the you
can see that it's not defined in here.
can see that it's not defined in here.
It's just CPU GPU. The reason that
It's just CPU GPU. The reason that
should that shouldn't be the bug
should that shouldn't be the bug
actually. Wait. Oh, it says s back end
actually. Wait. Oh, it says s back end
is CUDA zero. That shouldn't happen.
is CUDA zero. That shouldn't happen.
Well, I I set that. I set that. You
Well, I I set that. I set that. You
definitely should Are you exposing?
definitely should Are you exposing?
It says to set this. That's outdated.
It says to set this. That's outdated.
Outdated, man. I need to change that.
Outdated, man. I need to change that.
Okay. Okay. Um that might not work as as
Okay. Okay. Um that might not work as as
expected. Um you want to leave it as
expected. Um you want to leave it as
physx cuda. Okay. So I can do that but
physx cuda. Okay. So I can do that but
then then we get to the other error
then then we get to the other error
because that was the first thing I
because that was the first thing I
tried.
tried.
Okay. I'll show you the binding.
Okay. I'll show you the binding.
Um I can also try to see if I can just
Um I can also try to see if I can just
get CUDA end working. I remember we had
get CUDA end working. I remember we had
it working at one point but maybe
it working at one point but maybe
something broke like maybe something's
something broke like maybe something's
not using the right device. And also I
not using the right device. And also I
can literally give you SSH to this box
can literally give you SSH to this box
if you want.
if you want.
Sure. Let's go through this system first
Sure. Let's go through this system first
and then I'll try debug myself as well
and then I'll try debug myself as well
later. So then get rid of this device
later. So then get rid of this device
arc. Don't need that apparently.
arc. Don't need that apparently.
Yeah. The the whole idea is if you just
Yeah. The the whole idea is if you just
expose CUDA devices, it isolates the
expose CUDA devices, it isolates the
whole thing and CUDA zero looks like
whole thing and CUDA zero looks like
whatever GPU you're giving it access to.
whatever GPU you're giving it access to.
Okay.
Okay.
Let's see what's the exact bug here.
How many guys you have on Twitch
How many guys you have on Twitch
watching right now? I swear like on
watching right now? I swear like on
Twitter you have like 500 plus. Well,
Twitter you have like 500 plus. Well,
that's not concurrent. That's not
that's not concurrent. That's not
concurrent.
concurrent.
Oh, those numbers are not concurrent.
Oh, those numbers are not concurrent.
No. So, all the Twitch all the the
No. So, all the Twitch all the the
Twitter streams you see the X streams,
Twitter streams you see the X streams,
those all lie. So, when you see people
those all lie. So, when you see people
have like a bajillion viewers, that's
have like a bajillion viewers, that's
total. I usually have like I usually
total. I usually have like I usually
have like, you know, between five and 10
have like, you know, between five and 10
people watching.
people watching.
Okay, this is something that we can fix,
Okay, this is something that we can fix,
I believe. But you think that there are
I believe. But you think that there are
hundreds of people watching like RLDev?
hundreds of people watching like RLDev?
No. I I thought for a second like
No. I I thought for a second like
Twitter is just a better platform like
Twitter is just a better platform like
has so many people on it. No. Okay. I
has so many people on it. No. Okay. I
think so. What's the error here? The
think so. What's the error here? The
runtime error indic CPU or on the same
runtime error indic CPU or on the same
device as index tensor. Can you go back
device as index tensor. Can you go back
to that line? So this is the thing that
to that line? So this is the thing that
I added, but I added it the exact same
I added, but I added it the exact same
way that all your other stuff is added.
way that all your other stuff is added.
So unless it gets like uh the device
So unless it gets like uh the device
gets switched later here, let me show
gets switched later here, let me show
you this. Can I go to that? Can we get
you this. Can I go to that? Can we get
go to the line of error? Yes, I will. I
go to the line of error? Yes, I will. I
just want to show you I added a print
just want to show you I added a print
for this. We'll go we'll show you that
for this. We'll go we'll show you that
line.
line.
Okay. So
Okay. So
you can see this is how I define this. I
you can see this is how I define this. I
use your device.
use your device.
This isn't the init. This is just the
This isn't the init. This is just the
init. Ah okay. And then
and then this is right here. Uh
and then this is right here. Uh
so what is the print saying?
so what is the print saying?
Okay,
Okay,
this is saying that the observation is
this is saying that the observation is
on the wrong device. Show you is it
on the wrong device. Show you is it
saying CUDA zero each time? Saying that
saying CUDA zero each time? Saying that
the observation is on CUDA zero. So the
the observation is on CUDA zero. So the
other devices match what we would
other devices match what we would
expect. I did export the like I did add
expect. I did export the like I did add
a thing to export the device. Wait, I
a thing to export the device. Wait, I
thought CUDA zero is what it should say.
thought CUDA zero is what it should say.
If you're doing exposed CUD to visible
If you're doing exposed CUD to visible
devices like three, it will think it's
devices like three, it will think it's
CUD to zero. Isn't that not how that
CUD to zero. Isn't that not how that
works? Shouldn't be.
works? Shouldn't be.
That's what I remember. Maybe I'm
That's what I remember. Maybe I'm
remember last time I tried a multiGP
remember last time I tried a multiGP
setup.
setup.
Okay. What does it say? The other ones
Okay. What does it say? The other ones
have the correct device.
have the correct device.
The hell is where my prints go? Oh,
The hell is where my prints go? Oh,
yeah. Here. Look. M is on CUDA 4. Last
yeah. Here. Look. M is on CUDA 4. Last
reward is on CUDA 4. is here.
reward is on CUDA 4. is here.
Uh can I see the print line command
Uh can I see the print line command
again? Let me see where it is. What is
again? Let me see where it is. What is
it printing? So that is actually on the
it printing? So that is actually on the
right device. It's just OBS device is
right device. It's just OBS device is
wrong. Yeah. So it seems device wrong.
wrong. Yeah. So it seems device wrong.
Yeah, which I don't mess with your OBS,
Yeah, which I don't mess with your OBS,
right? It seems like it's running the
right? It seems like it's running the
SIM on the wrong device.
That could be possible. Uh
can we check the memory allocation? like
can we check the memory allocation? like
stop it before it goes to get ops and
stop it before it goes to get ops and
just to see where the me which GPU is
just to see where the me which GPU is
being used. We should expect every
being used. We should expect every
single one to have some GPU memory
single one to have some GPU memory
allocated for the simulation. Uh okay, I
allocated for the simulation. Uh okay, I
can do that but not in the way that you
can do that but not in the way that you
expect cuz I can't put break point. So
expect cuz I can't put break point. So
hang on. Oh, I can't put Yeah. In the
hang on. Oh, I can't put Yeah. In the
meantime, I'm going to check the get ops
meantime, I'm going to check the get ops
function to see if we're doing some
function to see if we're doing some
funky stupid thing like we're doing two
funky stupid thing like we're doing two
CUDA zero or something. Uh I hope we're
CUDA zero or something. Uh I hope we're
not doing that though.
not doing that though.
Let's see. Let me try to get off
Let's see. Let me try to get off
function. Are you doing state based?
function. Are you doing state based?
Yes. Okay. I will see the function for
Yes. Okay. I will see the function for
that. Get off state dick. Okay. So, this
that. Get off state dick. Okay. So, this
is now the video.
is now the video.
Yes.
Okay. That 300 megabytes is probably
Okay. That 300 megabytes is probably
just imported pietorch.
just imported pietorch.
Oh, I think they're all being it on the
Oh, I think they're all being it on the
first GPU. How many parallel
first GPU. How many parallel
environments is this? 4096 each per GPU.
environments is this? 4096 each per GPU.
Yep.
Yep.
Oh yeah, that's definitely using way
Oh yeah, that's definitely using way
more memory than it should be. So they
more memory than it should be. So they
must be being initialized on the first
must be being initialized on the first
one. Yep. Okay. Yeah. Um 4096 on a state
one. Yep. Okay. Yeah. Um 4096 on a state
based P cube should not be using even
based P cube should not be using even
more than like 5 gigs I think. So
more than like 5 gigs I think. So
let's see. Let me see where we're
let's see. Let me see where we're
initializing the simulation engine. That
initializing the simulation engine. That
could be what it is.
could be what it is.
Perhaps I'm not doing that right.
Perhaps I'm not doing that right.
But we train p cube at I think it's a
But we train p cube at I think it's a
bit above 60k steps per second on the
bit above 60k steps per second on the
current tuned config. It does take too
current tuned config. It does take too
many samples at the moment. Uh one more
many samples at the moment. Uh one more
sanity to check. Is it possible for you
sanity to check. Is it possible for you
to run it on one GPU but it's not GPU
to run it on one GPU but it's not GPU
zero and look at the memory usage. Uh I
zero and look at the memory usage. Uh I
have not tried that. Let's see. Uh I'm
have not tried that. Let's see. Uh I'm
curious like if this is a multiGPU setup
curious like if this is a multiGPU setup
problem or if it's like I'm not setting
problem or if it's like I'm not setting
ID or I don't know. Yeah.
ID or I don't know. Yeah.
Yeah. So, we should ideally see the
Yeah. So, we should ideally see the
second GPU being used obviously.
Okay, it's importing torch or stuff.
Okay, it's importing torch or stuff.
That's definitely the simulator being
That's definitely the simulator being
imported.
imported.
So, this works. Well, we'll see. This is
So, this works. Well, we'll see. This is
taking forever to start up.
taking forever to start up.
Is there any kind of warm cold machine
Is there any kind of warm cold machine
kind of thing going on? Maybe.
kind of thing going on? Maybe.
Okay, let's see if it does anything.
Okay, let's see if it does anything.
Can you see the prints? They're all
Can you see the prints? They're all
saying CUD to zero.
saying CUD to zero.
Okay, this is what I mean whenever I was
Okay, this is what I mean whenever I was
mentioning like if the CUDA devices is
mentioning like if the CUDA devices is
some other random number, okay, to the
some other random number, okay, to the
machine to the Python process itself, it
machine to the Python process itself, it
thinks it's CUDA zero. Okay, so in that
thinks it's CUDA zero. Okay, so in that
case then probably the export uh is not
case then probably the export uh is not
working the way that I expect it is and
working the way that I expect it is and
some of it it's like some of these are
some of it it's like some of these are
using the N variable and some of them
using the N variable and some of them
are using something that's been cached
are using something that's been cached
or whatever.
or whatever.
H because you like you realize like with
H because you like you realize like with
this when you run it with torch run
this when you run it with torch run
um it's going to start the processes for
um it's going to start the processes for
you. So you don't really have an option
you. So you don't really have an option
to start I don't think you have the
to start I don't think you have the
option to set that variable
option to set that variable
uh before the process launches. You can
uh before the process launches. You can
set it after you start the process.
set it after you start the process.
Huh. Uh that's not Wait. I I swear I saw
Huh. Uh that's not Wait. I I swear I saw
a line in the code in the error trace
a line in the code in the error trace
where it showed the export variable
where it showed the export variable
thing or like os.vironment
thing or like os.vironment
replvices. Yes, you did. So, was that
replvices. Yes, you did. So, was that
your code? Yes, I will show you.
your code? Yes, I will show you.
Uh if you if you set it after running
Uh if you if you set it after running
the Python script, I don't think that
the Python script, I don't think that
will work.
will work.
Well, I was attempting to patch it
Well, I was attempting to patch it
because I mean it definitely doesn't
because I mean it definitely doesn't
work without it either.
work without it either.
Uh,
Uh,
also wait, is Torch run a open source
also wait, is Torch run a open source
project? Can I find it? I'm curious what
project? Can I find it? I'm curious what
it looks like. Yeah.
it looks like. Yeah.
Uh, do you have the link to it? I can't
Uh, do you have the link to it? I can't
find it on Google.
Is it from PyTorch? Yeah. Oh, it's from
Is it from PyTorch? Yeah. Oh, it's from
PyTorch. Okay. It's distributed.
PyTorch. Okay. It's distributed.
It's the same as just Yeah. This same
It's the same as just Yeah. This same
thing.
thing.
Oh, okay.
Oh, okay.
Let me take a look at this thing.
Let me take a look at this thing.
So, they don't set visible devices
So, they don't set visible devices
apparently. I guess they set local rank.
apparently. I guess they set local rank.
They set local rank. No, I I see the
They set local rank. No, I I see the
visible devices thing. Well, this is
visible devices thing. Well, this is
what I set. Yeah, I just I just did this
what I set. Yeah, I just I just did this
to try to make Manny skill work.
to try to make Manny skill work.
And we also have this torch cuda set
And we also have this torch cuda set
device.
device.
I have never seen that one. Let me see.
I have never seen that one. Let me see.
Let me see what that does.
Let me see what that does.
That's supposed to set the default. So
That's supposed to set the default. So
like if I just make a tensor, it should
like if I just make a tensor, it should
make it on that device.
I see. So set a default to whatever.
I see. So set a default to whatever.
Huh.
Huh.
Okay. Let me just check the physics side
Okay. Let me just check the physics side
of things.
Yeah. Um I mean I would hope it's not
Yeah. Um I mean I would hope it's not
physics issue because Isaac Lab can do
physics issue because Isaac Lab can do
multiGPU stuff apparently. So, it's
multiGPU stuff apparently. So, it's
probably something on our side then.
probably something on our side then.
Well, I don't even know if it's on your
Well, I don't even know if it's on your
side as much as it's like there are many
side as much as it's like there are many
ways that you can set these devices and
ways that you can set these devices and
it depends on how you have it
it depends on how you have it
implemented, which ones work and which
implemented, which ones work and which
ones don't. Yeah, I'm guessing torch
ones don't. Yeah, I'm guessing torch
doesn't do the ones that we expected.
doesn't do the ones that we expected.
Um, even then it shouldn't be as hard to
Um, even then it shouldn't be as hard to
do.
do.
I'm hoping we can get this working and
I'm hoping we can get this working and
then I can like attempt to find some set
then I can like attempt to find some set
of parameters that will do uh the like
of parameters that will do uh the like
the peg insertion task or one of the
the peg insertion task or one of the
harder ones in puffer lip.
harder ones in puffer lip.
Yeah, that one takes like 30 minutes to
Yeah, that one takes like 30 minutes to
an hour on statebased training right now
an hour on statebased training right now
on 1490. If you can get it faster,
on 1490. If you can get it faster,
that'd be pretty cool. We don't have
that'd be pretty cool. We don't have
faster than you yet because like like
faster than you yet because like like
our just our defaults are not set up for
our just our defaults are not set up for
slow environments. Um, so I just have to
slow environments. Um, so I just have to
tune some stuff. But we do have it very
tune some stuff. But we do have it very
very stable uh with I think it's like
very stable uh with I think it's like
10. It's like 15 million steps, but it
10. It's like 15 million steps, but it
takes like a little bit, but it's per
takes like a little bit, but it's per
second.
second.
Okay. Uh, I'm going to try to create a
Okay. Uh, I'm going to try to create a
new branch for Manasco. Can you just Are
new branch for Manasco. Can you just Are
you Did you get clone it or did you pip
you Did you get clone it or did you pip
install it? I pip installed. I can clone
install it? I pip installed. I can clone
it. All I would have to do is copy the
it. All I would have to do is copy the
Sapion file over.
Sapion file over.
What sapion file? Well, I have the end
What sapion file? Well, I have the end
modified for the local reward stuff. The
modified for the local reward stuff. The
new stuff. I see. I'm just I'm just make
new stuff. I see. I'm just I'm just make
a new branch. Maybe you can add the
a new branch. Maybe you can add the
change to that and then Yeah, make make
change to that and then Yeah, make make
the branch and like I will I'll fork off
the branch and like I will I'll fork off
of it. Okay, great. Let me figure that.
We're going to get you. I've been
We're going to get you. I've been
promising uh I've been promising robotic
promising uh I've been promising robotic
stuff in Puffer for quite a while. So,
stuff in Puffer for quite a while. So,
now you can finally get it. I do
now you can finally get it. I do
eventually get around to it. It just
eventually get around to it. It just
takes a while. Yeah, you got to solve
takes a while. Yeah, you got to solve
all the other issues first, right? There
all the other issues first, right? There
is so much RL, man. I like gh the amount
is so much RL, man. I like gh the amount
of different things I've fixed
of different things I've fixed
build.
build.
Okay, let me send you the branch name
Okay, let me send you the branch name
for add to that branch. It's just a
for add to that branch. It's just a
sapion repo, right? Nope, that's not the
sapion repo, right? Nope, that's not the
repo. It's a man skill repo.
repo. It's a man skill repo.
Uh, I'm just going to set to your
Uh, I'm just going to set to your
development chat. Oh, sorry. I sent the
development chat. Oh, sorry. I sent the
change, but it's called puffer lib, the
change, but it's called puffer lib, the
branch name, the public one. Okay, let
branch name, the public one. Okay, let
me work.
me work.
Yeah. And then in the meantime, I'm
Yeah. And then in the meantime, I'm
going to see if I can edit the code to
going to see if I can edit the code to
let you set CUDA and see if that works.
let you set CUDA and see if that works.
Uh, I've never really truly tested that,
Uh, I've never really truly tested that,
but maybe it will.
Is this um reasonable to set up from
Is this um reasonable to set up from
source or is it potentially pain in the
source or is it potentially pain in the
ass? No, it's the same thing you do with
ass? No, it's the same thing you do with
pip installs. You're just get cloning
pip installs. You're just get cloning
it.
it.
Yeah, there's only a few extra files for
Yeah, there's only a few extra files for
like RL that's not included with the
like RL that's not included with the
package.
Yeah, you just do pip install- e dot and
Yeah, you just do pip install- e dot and
you're good.
And then you have like Vulcan whatever
And then you have like Vulcan whatever
set already, right? So Mhm.
set already, right? So Mhm.
good.
Yep. That should be good.
Uh, copy. Hang on.
You still use Vens. You don't use UV or
You still use Vens. You don't use UV or
micro. This is UV.
micro. This is UV.
Oh, they also call it V. Okay. And I
Oh, they also call it V. Okay. And I
only recently started using UV out after
only recently started using UV out after
great protest. I typically would use no
great protest. I typically would use no
virtual end and just Docker. Um,
virtual end and just Docker. Um,
but unfortunately there have been
but unfortunately there have been
changes to Python which kind of force
changes to Python which kind of force
you to use virtual ends even inside of
you to use virtual ends even inside of
Docker which Python's just a bad
Docker which Python's just a bad
language. All right. Nobody knows what
language. All right. Nobody knows what
they're building.
they're building.
Literally nobody knows what they're I'm
Literally nobody knows what they're I'm
very mad about this.
Uh, this removed Manny skill. So, I have
Uh, this removed Manny skill. So, I have
to copy this from my local, I guess. And
to copy this from my local, I guess. And
luckily, I still have this on my local.
Okay.
So I have a strange kind of backend name
So I have a strange kind of backend name
thing where physicuda physics GPU or
thing where physicuda physics GPU or
physics CPU. Yeah, that's need to add
physics CPU. Yeah, that's need to add
another option just to say specify CUDA
another option just to say specify CUDA
device. That's what it it says in the
device. That's what it it says in the
docs that you do but doesn't actually
docs that you do but doesn't actually
work. Yeah, I removed that feature a
work. Yeah, I removed that feature a
while back I think by accident without
while back I think by accident without
realizing. I don't I don't have
realizing. I don't I don't have
automated tests for multi GPU stuff. I
automated tests for multi GPU stuff. I
don't have automated tests for almost
don't have automated tests for almost
anything.
anything.
Yeah, I literally whenever I do big
Yeah, I literally whenever I do big
release, I run the test once. If it
release, I run the test once. If it
pass, it's fine. But I don't actually
pass, it's fine. But I don't actually
have a cheat. That is what I do as well.
have a cheat. That is what I do as well.
That is fine.
That is fine.
Yeah,
Yeah,
I guess I could just parse their sim
I guess I could just parse their sim
back in from physics CUDA to be like
back in from physics CUDA to be like
physics cuda colon check the reax and
physics cuda colon check the reax and
then if you pass in number, we'd only
then if you pass in number, we'd only
use that. I mean, we could also just
use that. I mean, we could also just
figure out like what is the difference
figure out like what is the difference
between sending CUDA or actually wait
between sending CUDA or actually wait
this doesn't make sense. If you pass in
this doesn't make sense. If you pass in
physics CUDA, we create a device called
physics CUDA, we create a device called
torch.de device and pass in a string
torch.de device and pass in a string
CUDA.
CUDA.
That should be looking for whatever the
That should be looking for whatever the
default device is.
default device is.
Unless it's not. Yeah, I don't know.
Unless it's not. Yeah, I don't know.
Wait,
Wait,
wait. Maybe this is a safe pin issue cuz
wait. Maybe this is a safe pin issue cuz
the torch device we're passing Oh, I
the torch device we're passing Oh, I
think it's a maybe sap is not tracking
think it's a maybe sap is not tracking
it correctly. Um cuz I noticed how the
it correctly. Um cuz I noticed how the
ward and everything else is on the right
ward and everything else is on the right
device, right? It's like 765, right?
device, right? It's like 765, right?
Yeah. Hang on. Let me get you this.
Yeah. Hang on. Let me get you this.
Yeah, we we keep track of two devices.
Yeah, we we keep track of two devices.
We have the device for a simulation and
We have the device for a simulation and
renderer and then we have a device for
renderer and then we have a device for
the APIs, tasks, and reward function.
the APIs, tasks, and reward function.
Whatever. Those are two different
Whatever. Those are two different
devices because they have to be managed
devices because they have to be managed
a little differently. That could be the
a little differently. That could be the
issue.
issue.
Uh,
Uh,
I guess you can print ID or
Okay. So, here I have the single um
Okay. So, here I have the single um
single GPU peg insertion task running.
single GPU peg insertion task running.
Okay.
Okay.
And this should be running with the
And this should be running with the
latest man like the from source manny.
latest man like the from source manny.
Okay.
Okay.
Um, on one GPU.
Um, on one GPU.
Okay. Um, I have a quick fix you can try
Okay. Um, I have a quick fix you can try
checking for the multiGP setup. Can you
checking for the multiGP setup. Can you
go to the backendpay file again
back end?
back end?
It's going to pass.
It's going to pass.
Uh so what we're going to do is let's
Uh so what we're going to do is let's
just use environment variable to or what
just use environment variable to or what
what's the function you use to get the
what's the function you use to get the
rank. Hang on let me where's is it in uh
rank. Hang on let me where's is it in uh
a man skill m utils systems back end.py
Okay. So, here it is.
Okay. So, here it is.
Yes. Go to the line under physics sim
Yes. Go to the line under physics sim
back end equals physics kudo. Go to that
back end equals physics kudo. Go to that
line.
line.
Uh like elimin back end equals physics
Uh like elimin back end equals physics
kudo.
kudo.
This Oh, no. The one with the if
This Oh, no. The one with the if
statement that sets a SIM device and and
statement that sets a SIM device and and
a torch device. Torch. Yeah. Okay. So it
a torch device. Torch. Yeah. Okay. So it
seems like core device is selecting the
seems like core device is selecting the
one that you thought you're selecting
one that you thought you're selecting
right saf device is not I don't know why
right saf device is not I don't know why
we can trick check can you check the
we can trick check can you check the
envir can you how do you get the local
envir can you how do you get the local
rank like the number one to eight
rank like the number one to eight
whatever can you get that number and
whatever can you get that number and
append it to the string cuda
append it to the string cuda
so device equals safe device instead of
so device equals safe device instead of
writing cuda we're going to write cuda
writing cuda we're going to write cuda
colon the number
colon the number
uh I see So,
I guess what we can I can do something
I guess what we can I can do something
as a quick hack. Um, because this is not
as a quick hack. Um, because this is not
going to be exported.
going to be exported.
Let's see if we get it to work like
Let's see if we get it to work like
this. Yeah, this is just like a quick
this. Yeah, this is just like a quick
check and if this works, I'll add a
check and if this works, I'll add a
feature to add the exact number that
feature to add the exact number that
people want. Okay, so we'll do is it
people want. Okay, so we'll do is it
sapient CUDA like this? Does this
sapient CUDA like this? Does this
render? No, not that line. Go above. Go
render? No, not that line. Go above. Go
above. Oh, yes. I don't line numbers.
above. Oh, yes. I don't line numbers.
How do I tell you which line? Sim device
How do I tell you which line? Sim device
equals saving device under e- lift sim
equals saving device under e- lift sim
back end equals physics cuda.
Right below that one. Okay, this thing.
Right below that one. Okay, this thing.
Yeah, that one. And then we're doing
Yeah, that one. And then we're doing
cuda colon whatever the local rank is.
cuda colon whatever the local rank is.
Let's see if that works and maybe print
Let's see if that works and maybe print
it and see how it works.
Okay. And then format the strength for
Okay. And then format the strength for
CUDA and saf device. Oh, I don't know if
CUDA and saf device. Oh, I don't know if
I did this on the right machine. Uh,
I did this on the right machine. Uh,
what what are you is this a file not the
what what are you is this a file not the
right one? Yeah, I accidentally I
right one? Yeah, I accidentally I
accidentally set all this stuff up on my
accidentally set all this stuff up on my
local. My bad. Oh, no worries. Uh, hang
local. My bad. Oh, no worries. Uh, hang
on. I because it's I have all these
on. I because it's I have all these
terms and like
terms and like
supposed to be here.
My bad.
Let's see. I'm trying to think, okay, if
Let's see. I'm trying to think, okay, if
I'm going to add a feature where people
I'm going to add a feature where people
can specify the exact CUDA device.
can specify the exact CUDA device.
Do I have to specify a number or do I
Do I have to specify a number or do I
let them pass a CUDA colon? CUDA colon
let them pass a CUDA colon? CUDA colon
is kind of stupid because other things
is kind of stupid because other things
we might have other GP backends. Yeah,
we might have other GP backends. Yeah,
we're probably going to Yeah. So, other
we're probably going to Yeah. So, other
backends would be uh like MPS or
Yeah, we might add MJX Warp in the
Yeah, we might add MJX Warp in the
future. They're still working on it.
future. They're still working on it.
Nvidia and Majoko's teams, but it's
Nvidia and Majoko's teams, but it's
supposedly going to be much better than
supposedly going to be much better than
Physics or the current MJX. Yeah, I saw
Physics or the current MJX. Yeah, I saw
have fun at uh Nvidia over the summer.
have fun at uh Nvidia over the summer.
Yes. Um playing around with simulators,
Yes. Um playing around with simulators,
I guess. Isaac and R.
I guess. Isaac and R.
What's the Sims?
Uh okay.
Our sapient file
that was
what the heck was Oh yeah, utils back
what the heck was Oh yeah, utils back
And yep.
The second e- lift.
The second e- lift.
Okay. In this function here. Not that
Okay. In this function here. Not that
one. No. Nope. That's for That's for
one. No. Nope. That's for That's for
something else. You got to go to the
something else. You got to go to the
fix. Oh, this is render. Yeah. Yeah.
fix. Oh, this is render. Yeah. Yeah.
Yeah. This is render. Rendering. We We
Yeah. This is render. Rendering. We We
might need to fix that, too. But let's
might need to fix that, too. But let's
fix this one first. X. This looks good.
fix this one first. X. This looks good.
Device.
Device.
Why don't I just set Couldn't I just set
Why don't I just set Couldn't I just set
this to Oh, it's because it's
this to Oh, it's because it's
sapient.device is separate from torch
sapient.device is separate from torch
device. I think we're not using the same
device. I think we're not using the same
API torch is using to detect what torch
API torch is using to detect what torch
run is setting. We are only using CUDA
run is setting. We are only using CUDA
visible devices which I think is
visible devices which I think is
actually the standard approach but for
actually the standard approach but for
whatever reason torch does not do it and
whatever reason torch does not do it and
they don't need care torch them. Okay,
they don't need care torch them. Okay,
let me I have to do
Anakin
Anakin
waited.
Me time. Let me see what the hell torch
Me time. Let me see what the hell torch
run is doing. Okay, so now we have this.
run is doing. Okay, so now we have this.
So
local rank. Okay. Because it doesn't
local rank. Okay. Because it doesn't
it's not going to get set if I don't if
it's not going to get set if I don't if
I don't run it with distributed. We'll
I don't run it with distributed. We'll
just do distributed. Yeah. Let's just
just do distributed. Yeah. Let's just
give it a shot. Can can we see the GPU
give it a shot. Can can we see the GPU
memory usage as well to see which one
memory usage as well to see which one
it's using?
it's using?
Great.
Great.
So,
So,
let's hope if this doesn't work, I'll
let's hope if this doesn't work, I'll
ask the Sapion lead to fix something.
ask the Sapion lead to fix something.
It should work. Oh, that's not a good
It should work. Oh, that's not a good
sign. It's going to 9,000 GB.
Uh, yeah, that kind of looks like it's
Uh, yeah, that kind of looks like it's
just initializing them all one after
just initializing them all one after
another.
another.
Yeah, same issue again. Uh, didn't we
Yeah, same issue again. Uh, didn't we
print the device or didn't work?
print the device or didn't work?
Maybe I did.
I guess we're also not sure if the local
I guess we're also not sure if the local
rank variable is correct either. Find
rank variable is correct either. Find
it. Uh utils back end. Yeah. Yeah.
Yeah. And then one more print to do. Um
Yeah. And then one more print to do. Um
after we find a send device, can you
after we find a send device, can you
print send device uh
print send device uh
CUDA id?
This is the one that s thinks it's using
This is the one that s thinks it's using
is it cuda like this? Yep, that's
is it cuda like this? Yep, that's
correct. That's the right property name.
correct. That's the right property name.
Okay, we will attempt to get something
Okay, we will attempt to get something
out of this.
Uh
Uh
why is syn device still zero?
So we're passing cuda colon a number
So we're passing cuda colon a number
right the right number right. So that
right the right number right. So that
seems strange. Um no we didn't change
seems strange. Um no we didn't change
it. We didn't change it. Cuda you had to
it. We didn't change it. Cuda you had to
do colon local rank. Yeah bad man. No
do colon local rank. Yeah bad man. No
worries.
All right, nice. Let's try it again.
Kind of just been doing a ton of RL and
Kind of just been doing a ton of RL and
driving myself nuts.
driving myself nuts.
You know, I I feel bad I've kind of
You know, I I feel bad I've kind of
moved away from RL recently. Like I'm
moved away from RL recently. Like I'm
just using default PPO. I'm not
just using default PPO. I'm not
modifying anymore. I'm just doing sim
modifying anymore. I'm just doing sim
stuff instead. You know what? You're not
stuff instead. You know what? You're not
going to be using default PO very soon
going to be using default PO very soon
because Puffer LE is gonna solve all
because Puffer LE is gonna solve all
your stuff. It's working. It's working
your stuff. It's working. It's working
now.
now.
Correct. Let's see if this does
Correct. Let's see if this does
anything. Yeah. So, if I if if I get
anything. Yeah. So, if I if if I get
this to work, I don't think you're going
this to work, I don't think you're going
to be using default PO.
Cool. I'm going to on that branch add
Cool. I'm going to on that branch add
the feature to specify the device
the feature to specify the device
directly. At least add it back. Hey, uh,
directly. At least add it back. Hey, uh,
have you seen uh, man skill run this
have you seen uh, man skill run this
fast?
fast?
No, it's state based, right? Uh,
No, it's state based, right? Uh,
it's still 300k
it's still 300k
for Q picking. I want to see the
for Q picking. I want to see the
rendering forms later, too. Oh, we have
rendering forms later, too. Oh, we have
to change the code renderer as well, but
to change the code renderer as well, but
yeah, we'll have to change some stuff.
yeah, we'll have to change some stuff.
Nice. Okay. Um, I'm going to add a
Nice. Okay. Um, I'm going to add a
official feature to make this work so
official feature to make this work so
you don't have to do the hack. So, I'm
you don't have to do the hack. So, I'm
gonna have to PR you once I figure out
gonna have to PR you once I figure out
the the reward stuff anyways cuz like it
the the reward stuff anyways cuz like it
um
um
you literally can't use any of the manny
you literally can't use any of the manny
skill rewards with a standard J.
skill rewards with a standard J.
Yes, we have a different one I guess
Yes, we have a different one I guess
that we've modified and it seems like
that we've modified and it seems like
other people I saw your comment with
other people I saw your comment with
Kyle. I guess it's the same situation
Kyle. I guess it's the same situation
with them. Yeah. So, it's I basically I
with them. Yeah. So, it's I basically I
like I kind of figure that if you're
like I kind of figure that if you're
doing something everyone's probably
doing something everyone's probably
doing it that way. Um Yep. like because
doing it that way. Um Yep. like because
it's generally you guys are doing the
it's generally you guys are doing the
most reasonable stuff I see in robotics.
most reasonable stuff I see in robotics.
So I kind of assume if everybody's just
So I kind of assume if everybody's just
doing these state based rewards then
doing these state based rewards then
everybody's probably made the same
everybody's probably made the same
chains to J which is like it's kind of
chains to J which is like it's kind of
two errors that cancel each other out.
two errors that cancel each other out.
Wait, what is a statebased reward? Is
Wait, what is a statebased reward? Is
this like we're not doing potential or
this like we're not doing potential or
we're just doing like the current value
we're just doing like the current value
of your state. Right. So, you're
of your state. Right. So, you're
basically you're giving it a reward
basically you're giving it a reward
based on how close you are to a target
based on how close you are to a target
when the way to do this that doesn't
when the way to do this that doesn't
require you to have J like one way or
require you to have J like one way or
the other fixed is to do deltas, right?
the other fixed is to do deltas, right?
Because then if you do deltas, it's
Because then if you do deltas, it's
unfarmmable.
unfarmmable.
Do you do deltas for all your
Do you do deltas for all your
environments now? Well, we mostly don't
environments now? Well, we mostly don't
have these types of continuous rewards
have these types of continuous rewards
in the first place for a lot of our
in the first place for a lot of our
stuff. Our stuff is way sparer.
stuff. Our stuff is way sparer.
Ah, right. You don't even need a density
Ah, right. You don't even need a density
ward sometimes, right? Some of them. No,
ward sometimes, right? Some of them. No,
not like not at all. Ours are pretty
not like not at all. Ours are pretty
much sparse by default. Actually, you
much sparse by default. Actually, you
could try sparse on a pick cube. I doubt
could try sparse on a pick cube. I doubt
it will work, but maybe you get a
it will work, but maybe you get a
billion samples, maybe figure out by
billion samples, maybe figure out by
accident. Who knows? It's kind of tough
accident. Who knows? It's kind of tough
because I I tried it briefly. Um, your
because I I tried it briefly. Um, your
sparse reward is super sparse in the
sparse reward is super sparse in the
sense that like you're just never going
sense that like you're just never going
to accidentally do that, right? Yes. In
to accidentally do that, right? Yes. In
general, that's usually the case. Yeah.
general, that's usually the case. Yeah.
Okay. Okay. So this thing is um you can
Okay. Okay. So this thing is um you can
see that this is solving already, right?
see that this is solving already, right?
Nice.
Nice.
Yeah. But pick cube is too easy to like
Yeah. But pick cube is too easy to like
compare performance like we already
compare performance like we already
solve it with under a minute. So if you
solve it with under a minute. So if you
check the harder test then we should
check the harder test then we should
hopefully see some improvements. Yeah.
hopefully see some improvements. Yeah.
So and the thing is this is also
So and the thing is this is also
remember this is not tuned well enough
remember this is not tuned well enough
yet. So I tuned it to um I actually
yet. So I tuned it to um I actually
didn't even do up like multiple update
didn't even do up like multiple update
epochs in this. So, this is literally
epochs in this. So, this is literally
looking at your data once and throwing
looking at your data once and throwing
it away.
Nice. You'll see the uh here. Okay, we
Nice. You'll see the uh here. Okay, we
can get rid of this. So, we can show you
can get rid of this. So, we can show you
here. These are the params from the
here. These are the params from the
sweep that I got. You can see that this
sweep that I got. You can see that this
is a slightly different scale from uh we
is a slightly different scale from uh we
have a 64 horizon. This gives us an
have a 64 horizon. This gives us an
effective batch size of I believe this
effective batch size of I believe this
is 280K or something like that. And then
is 280K or something like that. And then
a mini batch size
a mini batch size
Yeah, we do recurrent by default. Oh,
Yeah, we do recurrent by default. Oh,
your ind bash size is far larger than
your ind bash size is far larger than
mine. Yes. Much much bigger. Yes. So,
mine. Yes. Much much bigger. Yes. So,
this is this is a thing in puffer that
this is this is a thing in puffer that
we usually have standard. So, if you
we usually have standard. So, if you
actually look the at this, you can see
actually look the at this, you can see
that 94% of the time is spent on the
that 94% of the time is spent on the
environment. Like puffer takes almost no
environment. Like puffer takes almost no
time.
Uh wait, what are these two numbers? 34
Uh wait, what are these two numbers? 34
seconds and 94%. What does that mean? So
seconds and 94%. What does that mean? So
ignore this because this is relative.
ignore this because this is relative.
But this is 94%
But this is 94%
of the total time of this experiment is
of the total time of this experiment is
being spent simulating the in
being spent simulating the in
Oh, you're spending no time training.
Oh, you're spending no time training.
Yeah. So in this setting then if you're
Yeah. So in this setting then if you're
simulator is faster whatever how you
simulator is faster whatever how you
have better scaling, right? Uh yes,
have better scaling, right? Uh yes,
exactly. So this is why if I do this
exactly. So this is why if I do this
exact same thing. So if I literally just
exact same thing. So if I literally just
do this and I just change this to
buffer neural MMO 3. Yeah.
You'll see you get a very different
You'll see you get a very different
spread.
So, first of all, you're immediately
So, first of all, you're immediately
training over two million steps per
training over two million steps per
second. Yeah. And
second. Yeah. And
uh you can see that we have almost no
uh you can see that we have almost no
time is spent on the environment even
time is spent on the environment even
though we need to simulate two million
though we need to simulate two million
steps per second.
steps per second.
Right. I mean, isn't that because you're
Right. I mean, isn't that because you're
collecting the same amount of data but
collecting the same amount of data but
faster. So most of the time is red
faster. So most of the time is red
training time. Yes, exactly. Because the
training time. Yes, exactly. Because the
end just runs super fast and now there's
end just runs super fast and now there's
actually a little bit of copy overhead
actually a little bit of copy overhead
because the amount of data this it's
because the amount of data this it's
actually quite a large amount of data.
actually quite a large amount of data.
It'll do this will be about a pabyte in
It'll do this will be about a pabyte in
three or four days of data. Is the copy
three or four days of data. Is the copy
overhead from just transferring CPU data
overhead from just transferring CPU data
to GPU? Yes, we have a bit of but for us
to GPU? Yes, we have a bit of but for us
for us the copy should pretty much it's
for us the copy should pretty much it's
zero because there's no copy. Yeah. So
zero because there's no copy. Yeah. So
for us we have but like the total
for us we have but like the total
bandwidth still it's still 15%. Compared
bandwidth still it's still 15%. Compared
to 94% right it's kind of crazy and this
to 94% right it's kind of crazy and this
is and this is with a much bigger this
is and this is with a much bigger this
is also with a we have a bigger policy
is also with a we have a bigger policy
in here as well. This is a 3.4 million
in here as well. This is a 3.4 million
parameter policy with an LSTM in it
parameter policy with an LSTM in it
training at 2.2 mil.
training at 2.2 mil.
Yeah, I'm guessing you need to have
Yeah, I'm guessing you need to have
settings tuned based on this
settings tuned based on this
distribution, right? Like for high
distribution, right? Like for high
throughput environments like or CR
throughput environments like or CR
environments, you can do something else.
environments, you can do something else.
For slower environments, you definitely
For slower environments, you definitely
do something else, right? Yes. But we
do something else, right? Yes. But we
also have we also have the best
also have we also have the best
hyperparameter tuning algorithm. So
hyperparameter tuning algorithm. So
we'll be able to do that, right? Yeah.
we'll be able to do that, right? Yeah.
Now, the only thing is it's not set up
Now, the only thing is it's not set up
by default to even bother looking at
by default to even bother looking at
like multiple update epochs or really
like multiple update epochs or really
small like mini batch or anything. Just
small like mini batch or anything. Just
don't do it. I see. Nice.
don't do it. I see. Nice.
Cuz even our slow even our slowm are
Cuz even our slow even our slowm are
typically like hundreds of hundreds of
typically like hundreds of hundreds of
thousands per uh per GPU.
thousands per uh per GPU.
Mhm. Like neural MMO is considered one
Mhm. Like neural MMO is considered one
of our slowm. If I do like here,
this is single GPU speed.
this is single GPU speed.
So, literally one GPU on Breakout. Oh,
So, literally one GPU on Breakout. Oh,
that's actually sad. That's sad. Slow.
that's actually sad. That's sad. Slow.
My local settings.
My local settings.
Where is this?
Go.
Go.
Uh, I don't I'll grab it from.
So there you go. This is here's puffer
So there you go. This is here's puffer
breakout at 3 million steps per second
breakout at 3 million steps per second
on one GP.
on one GP.
Yeah, it's very different regime.
Yeah, it's very different regime.
Um I also point out another thing with
Um I also point out another thing with
physics environments. We often do
physics environments. We often do
multiple physics steps before you take
multiple physics steps before you take
an action. So the default for PC cube is
an action. So the default for PC cube is
five physics steps for every action. You
five physics steps for every action. You
can technically have five times the S
can technically have five times the S
fps, but your training performance will
fps, but your training performance will
be more sample efficient. The reason is
be more sample efficient. The reason is
because for every physics step you take,
because for every physics step you take,
the robot moves further sometimes. So we
the robot moves further sometimes. So we
actually have a way to automatically
actually have a way to automatically
sweep that. Um oh, the physics steps
sweep that. Um oh, the physics steps
amount if if you can bind it. So here,
amount if if you can bind it. So here,
let me just I'll show you how we do this
let me just I'll show you how we do this
big. Um,
so literally all we do is what's the
so literally all we do is what's the
parameter called?
parameter called?
Uh, we have some it's in the MK works.
Uh, we have some it's in the MK works.
This is something called sim config.
This is something called sim config.
Yeah, but what's the is it like physics
Yeah, but what's the is it like physics
steps? Physics steps or something? No,
steps? Physics steps or something? No,
it's in the sim config. There's like
it's in the sim config. There's like
it's nested. The sim config is a
it's nested. The sim config is a
dictionary. Yeah, but like what's what's
dictionary. Yeah, but like what's what's
the what's the innermost name?
the what's the innermost name?
The innermost name is sim. Sorry, I need
The innermost name is sim. Sorry, I need
to check. We don't call steps. We have a
to check. We don't call steps. We have a
sim frequency and control frequency. If
sim frequency and control frequency. If
you increase the control frequency, you
you increase the control frequency, you
take more you take less physics per
take more you take less physics per
action. Um, so let me find. So basically
action. Um, so let me find. So basically
what I want to do
is I want to add I want to add it to the
is I want to add I want to add it to the
make function.
make function.
Yeah. And then it's going to be like
Yeah. I just want to add it to the make
Yeah. I just want to add it to the make
function and then I can auto add it to
function and then I can auto add it to
our
our
Yeah. So you said do you see the sim
Yeah. So you said do you see the sim
conflict class I just sent you in
conflict class I just sent you in
discord? There's two numbers you change
discord? There's two numbers you change
the simulation frequency only really
the simulation frequency only really
change it changes like the granularity
change it changes like the granularity
of each physics step. So if the sim
of each physics step. So if the sim
frequency is 100 that means each physics
frequency is 100 that means each physics
step is about 1/100th of a second in the
step is about 1/100th of a second in the
real world.
real world.
Um okay and then the number of physics
Um okay and then the number of physics
steps we take is sim frequency divided
steps we take is sim frequency divided
by control frequency.
by control frequency.
So should I be tuning? Should I play
So should I be tuning? Should I play
with both of these numbers or just one
with both of these numbers or just one
of them? So I actually have not bothered
of them? So I actually have not bothered
sweeping Simfreak. It is very poss. So
sweeping Simfreak. It is very poss. So
the problem with Simre Freak is that if
the problem with Simre Freak is that if
it's too small, the simulation is
it's too small, the simulation is
inaccurate and it'll break. Like you
inaccurate and it'll break. Like you
know the cube will bounce everywhere. If
know the cube will bounce everywhere. If
it's too big, you're simulating too much
it's too big, you're simulating too much
and your simulator is very slow. So how
and your simulator is very slow. So how
do I add these? Is there a way that I
do I add these? Is there a way that I
can pass this into a sim config for
can pass this into a sim config for
this? So in the original yeah you got to
this? So in the original yeah you got to
do after render mode do comma sim config
do after render mode do comma sim config
sim_config
sim_config
equals dict
equals dict
and then pass in sim_refak and control
and then pass in sim_refak and control
freak and we will just override the
freak and we will just override the
defaults with whatever only sort of
defaults with whatever only sort of
things you provide. Everything else will
things you provide. Everything else will
be kept the same.
Yep, that works. Uh, I would recommend
Yep, that works. Uh, I would recommend
not changing sim freak for most part
not changing sim freak for most part
because we tuned them a little bit to be
because we tuned them a little bit to be
stable, but you can try sweeping it if
stable, but you can try sweeping it if
you want. Uh, usually defaults are
you want. Uh, usually defaults are
pretty good. Um, control freak is
pretty good. Um, control freak is
definitely something you can try.
definitely something you can try.
The other thing I would note is that if
The other thing I would note is that if
the control freak is higher, like let's
the control freak is higher, like let's
say you use 40 or sorry, let's say you
say you use 40 or sorry, let's say you
use 50, it has to be divisible. The
use 50, it has to be divisible. The
problem with that is that the robot will
problem with that is that the robot will
move slower per action and so the
move slower per action and so the
effective length of a task grows longer
effective length of a task grows longer
and so the max steps value that we tune
and so the max steps value that we tune
for each environment are wrong. Now
for each environment are wrong. Now
the only fix against that is to possibly
the only fix against that is to possibly
increase the maximum delta of each robot
increase the maximum delta of each robot
action which currently is maybe not so
action which currently is maybe not so
easy to change from the command line. So
easy to change from the command line. So
hang on. So simulation freak decreases
hang on. So simulation freak decreases
fidelity. If I just in order to make
fidelity. If I just in order to make
this thing faster, do I have to divide
this thing faster, do I have to divide
both of these by the same constant or
both of these by the same constant or
just like one of them or what? No, no,
just like one of them or what? No, no,
no. So, the fastest simulation you can
no. So, the fastest simulation you can
get is if you do sim freak like 10,
get is if you do sim freak like 10,
control freak 10, you're basically
control freak 10, you're basically
simulating very very coarsely. I see.
simulating very very coarsely. I see.
Um, and every physics step we return an
Um, and every physics step we return an
observation. So, your SPS is technically
observation. So, your SPS is technically
higher. Um, but you probably won't be
higher. Um, but you probably won't be
able to solve anything because one with
able to solve anything because one with
control freak of 10, it's you're not
control freak of 10, it's you're not
moving a lot in environment and sim
moving a lot in environment and sim
freak of 10, the simulation is very
freak of 10, the simulation is very
inaccurate.
inaccurate.
Um, yeah, so it's a strange balance and
Um, yeah, so it's a strange balance and
that's why I've never bothered sweeping
that's why I've never bothered sweeping
it before. Um, because the higher the
it before. Um, because the higher the
control freak, the less distance your
control freak, the less distance your
robot moves. Um, now there's one
robot moves. Um, now there's one
potential fix you can explore later,
potential fix you can explore later,
which is you can try increasing the
which is you can try increasing the
speed of the robot, like the maximum
speed of the robot, like the maximum
action it could take. Right now, we cap
action it could take. Right now, we cap
it at certain number of radians per
it at certain number of radians per
joint, but you can you can bump that up
joint, but you can you can bump that up
and see what happens. We would like The
and see what happens. We would like The
reason why the reason why we keep this
reason why the reason why we keep this
smaller is only just for like
smaller is only just for like
reasonability.
reasonability.
Like we want to do some tore. If you
Like we want to do some tore. If you
make it too large, it's probably not
make it too large, it's probably not
going to transfer to real world. Um, oh,
going to transfer to real world. Um, oh,
you can't lurp it. Like if you get like
you can't lurp it. Like if you get like
a lowfi thing, can't you like upscale?
a lowfi thing, can't you like upscale?
Yeah, that's true. But we want to keep
Yeah, that's true. But we want to keep
our defaults reasonable for most users
our defaults reasonable for most users
because otherwise it won't be they'll be
because otherwise it won't be they'll be
confused if they do. Well, I mean, what
confused if they do. Well, I mean, what
happens if we set it really coarse and
happens if we set it really coarse and
then set everything to be super domain
then set everything to be super domain
randomized and then we have manny scale
randomized and then we have manny scale
at 2 million steps per second and we
at 2 million steps per second and we
solve robotics. How about that? I know.
solve robotics. How about that? I know.
Give it a try. Um, I can tell you the
Give it a try. Um, I can tell you the
function or thing you could try to
function or thing you could try to
change to increase the maximum
change to increase the maximum
actions later. I need to figure it out
actions later. I need to figure it out
because we don't have it as a typical
because we don't have it as a typical
API. If you have a thing we can do with
API. If you have a thing we can do with
that because I mean it really is the
that because I mean it really is the
case that with puffer like we see some
case that with puffer like we see some
crazy stuff as soon as we get things to
crazy stuff as soon as we get things to
run at a reasonable speed. Right.
run at a reasonable speed. Right.
Like you I think you saw the neural MMO
Like you I think you saw the neural MMO
3 curve, right? Yeah. Much better than
3 curve, right? Yeah. Much better than
before, right? Yeah. It's like almost 3x
before, right? Yeah. It's like almost 3x
better than our 20 baseline. Yeah. And
better than our 20 baseline. Yeah. And
it's better than the game. It's better
it's better than the game. It's better
at the game than I am.
at the game than I am.
Wow.
Wow.
Have you tried a net hack yet? I guess
Have you tried a net hack yet? I guess
net. We are We are waiting for Ryan to
net. We are We are waiting for Ryan to
uh be ready to do that stuff and I'm
uh be ready to do that stuff and I'm
going to hack on that with him for a
going to hack on that with him for a
bit. Oh, that's cool.
Okay.
If we actually get something that seems
If we actually get something that seems
like it'll work, I'm just going to order
like it'll work, I'm just going to order
I'll just order like a little robot arm
I'll just order like a little robot arm
or something to see if it if it works or
or something to see if it if it works or
not. Our center real experiments. We do
not. Our center real experiments. We do
zero shot center real. You have to set
zero shot center real. You have to set
up the camera a little bit after you
up the camera a little bit after you
follow tutorial. It should be pretty
follow tutorial. It should be pretty
straightforward and hopefully you can
straightforward and hopefully you can
get it solving random tasks you define
get it solving random tasks you define
really accurately. Like the main thing
really accurately. Like the main thing
about reinforcement learning compared to
about reinforcement learning compared to
like imitation learning, you have high
like imitation learning, you have high
generalizability. You have high spatial
generalizability. You have high spatial
generalizability. I can place a cube in
generalizability. I can place a cube in
like 30 by 30 cmters large area for a
like 30 by 30 cmters large area for a
tiny robot arm and it's fast, right? The
tiny robot arm and it's fast, right? The
policy deploys decently fast.
policy deploys decently fast.
Um, obviously it's not going to be like
Um, obviously it's not going to be like
a general purpose robot. That's kind of
a general purpose robot. That's kind of
harder, but um, you know, some people
harder, but um, you know, some people
want high performance robots for one
want high performance robots for one
task. This is the way it can do quite a
task. This is the way it can do quite a
lot. Frankly, if like the main
lot. Frankly, if like the main
limitation on why we don't do robotics,
limitation on why we don't do robotics,
it's not that the problems are hard,
it's not that the problems are hard,
it's that they're slow. Like I mean, we
it's that they're slow. Like I mean, we
already one of the faster ones. I mean,
already one of the faster ones. I mean,
there are faster tasks you can try, but
there are faster tasks you can try, but
Oh, no. Absolutely. I'm not faulting
Oh, no. Absolutely. I'm not faulting
you. I'm just the field as a whole.
you. I'm just the field as a whole.
Like, this stuff is like at least I I
Like, this stuff is like at least I I
mean, being very generous in order of
mean, being very generous in order of
magnitude too slow.
magnitude too slow.
Yeah. You got you got to get more GPS to
Yeah. You got you got to get more GPS to
scale up at this point. Yeah. I mean, if
scale up at this point. Yeah. I mean, if
if there are these fidelity settings
if there are these fidelity settings
like, you know, break like breakout or
like, you know, break like breakout or
pong are basically unplayable for humans
pong are basically unplayable for humans
at like eight frame skip, but the RL
at like eight frame skip, but the RL
agent is freaking just it just does it.
agent is freaking just it just does it.
Wait, what is eight frame skip? So, do
Wait, what is eight frame skip? So, do
you take like eight physics tests before
you take like eight physics tests before
you take an action or something? Yeah,
you take an action or something? Yeah,
it'll just do that. I see.
it'll just do that. I see.
But the thing is so frame skip for
But the thing is so frame skip for
something like that like you say you can
something like that like you say you can
upscale the speed of the actions and
upscale the speed of the actions and
it's the same thing. You just lose a bit
it's the same thing. You just lose a bit
of granularity and it'll work. It'll
of granularity and it'll work. It'll
work model
work model
any range of actions. It can take the
any range of actions. It can take the
largest one or take a smaller one in
largest one or take a smaller one in
case it can't solve the problem. Right.
case it can't solve the problem. Right.
Yeah. We'll just have to like observe
Yeah. We'll just have to like observe
for the real training we've done with
for the real training we've done with
the little robot hugging face arm. It
the little robot hugging face arm. It
will take larger actions initially, but
will take larger actions initially, but
once it gets to a cube, it generally
once it gets to a cube, it generally
takes smaller actions because it knows
takes smaller actions because it knows
if it takes too large of an action,
if it takes too large of an action,
it'll break.
it'll break.
Um, so I think I think this is
Um, so I think I think this is
definitely possible for sure.
definitely possible for sure.
Yeah. Yeah. I might have to just stick
Yeah. Yeah. I might have to just stick
on the uh the push cube task for a
on the uh the push cube task for a
little bit and just like speedrun it
little bit and just like speedrun it
first because my guess is that the peg
first because my guess is that the peg
insertion we can probably solve it, but
insertion we can probably solve it, but
the way Puffer works, it's pretty data
the way Puffer works, it's pretty data
hungry, at least with the defaults. But
hungry, at least with the defaults. But
I'd like to try to first like tune tune
I'd like to try to first like tune tune
for sample efficiency, tune for speed to
for sample efficiency, tune for speed to
get a feel for what I can solve this
get a feel for what I can solve this
with. Um, yeah. Oh, not push cube. Push
with. Um, yeah. Oh, not push cube. Push
cube is too easy. Pick cube. We can do
cube is too easy. Pick cube. We can do
both of those. Um, yeah. The next
both of those. Um, yeah. The next
difficulty task is probably stack cube
difficulty task is probably stack cube
and push t. Those are next two. Yeah, I
and push t. Those are next two. Yeah, I
can do either. Push t1. Push tv1 is uh
can do either. Push t1. Push tv1 is uh
is a very famous task because of a
is a very famous task because of a
famous paper from a while back. But
famous paper from a while back. But
there's a we have the only GPU sim
there's a we have the only GPU sim
version of it.
version of it.
Um yeah, literally some undergrad at my
Um yeah, literally some undergrad at my
at UCSD did it for a course project.
at UCSD did it for a course project.
Like he saw this paper that did push t
Like he saw this paper that did push t
in real world was like you know let me
in real world was like you know let me
try to simulate it. Cracked guy wrote
try to simulate it. Cracked guy wrote
the code wrote the reward function wrote
the code wrote the reward function wrote
a function to check the area overlap
a function to check the area overlap
like batched uh 2D area overlap
like batched uh 2D area overlap
function. That was kind of cool. Cool.
function. That was kind of cool. Cool.
Submitted a PR. I accepted it. He joined
Submitted a PR. I accepted it. He joined
my lab. He did the center real project
my lab. He did the center real project
actually. I mentored him on that. Now
actually. I mentored him on that. Now
he's joining Nvidia as well.
he's joining Nvidia as well.
That's cool. I don't know about keeping
That's cool. I don't know about keeping
for PhD but um yeah
for PhD but um yeah
very cracked underground there. Three
very cracked underground there. Three
stack cube. Now we have our chat asking
stack cube. Now we have our chat asking
for three stack cube. All right. What's
for three stack cube. All right. What's
it called? I don't have a three stack
it called? I don't have a three stack
cube. Two stack cube. Okay. What's it
cube. Two stack cube. Okay. What's it
called? Stack stack cube. So we do Manny
called? Stack stack cube. So we do Manny
stack.
Uh we I can add a three stack cube task.
Uh we I can add a three stack cube task.
Uh might be hard to solve. I don't know
Uh might be hard to solve. I don't know
the time it would take to solve, but we
the time it would take to solve, but we
can try running it. Very easy to define.
can try running it. Very easy to define.
I can define it like this stack cube v1.
I can define it like this stack cube v1.
Yep, that's right. Well, let's see if we
Yep, that's right. Well, let's see if we
can solve these first. I at least have
can solve these first. I at least have
some stuff to play with. Uh what are we
some stuff to play with. Uh what are we
going to do about this reward thing? So,
going to do about this reward thing? So,
I can show you what I what I made. Um
I can show you what I what I made. Um
just make can you make the change in PR
just make can you make the change in PR
or something or Yeah, I can totally I
or something or Yeah, I can totally I
will PR it for you. I just want to make
will PR it for you. I just want to make
sure this is like reasonable for you.
sure this is like reasonable for you.
Yeah, I I'll just edit as needed. Um,
Yeah, I I'll just edit as needed. Um,
let me see. Let me just make sure that
let me see. Let me just make sure that
you like you think that this is a
you like you think that this is a
reasonable uh thing to do because I
reasonable uh thing to do because I
don't like it's possible I missed
don't like it's possible I missed
something. The one thing is that you
something. The one thing is that you
probably need to add a scale param
probably need to add a scale param
because it changes the reward scale
because it changes the reward scale
differently per task. Uh, so I haven't
differently per task. Uh, so I haven't
done that yet, but where is it? Many
done that yet, but where is it? Many
skill. Why are we changing why are we
skill. Why are we changing why are we
changing reward scale? Uh, you'll see.
changing reward scale? Uh, you'll see.
Hang on. Manny skill and
Okay, so you start with these zeros for
Okay, so you start with these zeros for
last reward, right? And then last to
last reward, right? And then last to
zeros
and then the delta reward function.
and then the delta reward function.
It gives Oh, you have 10.
It gives Oh, you have 10.
Well, because the difference is going to
Well, because the difference is going to
be very small.
be very small.
I see. I guess that should be another
I see. I guess that should be another
parameter to him now. Yes, this would be
parameter to him now. Yes, this would be
a per this would be a hyper which is the
a per this would be a hyper which is the
reward scale. Um because this is a very
reward scale. Um because this is a very
small scale and but here's the crazy
small scale and but here's the crazy
thing about this though, right? So
thing about this though, right? So
this doesn't actually do anything if you
this doesn't actually do anything if you
think about it because if your rewards
think about it because if your rewards
were like 0.9 or 0.91
were like 0.9 or 0.91
before you still had to like it had to
before you still had to like it had to
learn that difference which is very
learn that difference which is very
small. So I've seen separately in my own
small. So I've seen separately in my own
work that state-based rewards are very
work that state-based rewards are very
bad because of this reason because let's
bad because of this reason because let's
say that you want your reward to be
say that you want your reward to be
roughly zero to one scaled that covers
roughly zero to one scaled that covers
the entire state space like one is the
the entire state space like one is the
best zero is bad. So like between very
best zero is bad. So like between very
good and like a little bit worse.
good and like a little bit worse.
There's only this tiny little band. You
There's only this tiny little band. You
kind of have to learn to upnormalize it.
kind of have to learn to upnormalize it.
Versus with these deltas, deltas can
Versus with these deltas, deltas can
have a much more reasonable magnitude
have a much more reasonable magnitude
for them because they're always
for them because they're always
relative. So that's like another big
relative. So that's like another big
reason for this. I thought that's what
reason for this. I thought that's what
advantage calculation was meant for. It
advantage calculation was meant for. It
was meant to compute the scenes. It
was meant to compute the scenes. It
doesn't quite work.
doesn't quite work.
I guess this just makes it easier for
I guess this just makes it easier for
advantage too, right? Yes. Yes, this
advantage too, right? Yes. Yes, this
does. And it will keep everything on
does. And it will keep everything on
roughly the same scale as well. Another
roughly the same scale as well. Another
question is I don't I mean I think
question is I don't I mean I think
personally this 10 times div thing the
personally this 10 times div thing the
10 should go into the algo code the fun
10 should go into the algo code the fun
the training code not the environment.
the training code not the environment.
So
So
you'd ideally want to have your well I
you'd ideally want to have your well I
guess it depends. You can technically
guess it depends. You can technically
put a reward scale constant into your
put a reward scale constant into your
algorithm. Uh generally what I do in
algorithm. Uh generally what I do in
puffers we kind of just assume that the
puffers we kind of just assume that the
M should have reasonably normalized
M should have reasonably normalized
rewards and if they don't then we like
rewards and if they don't then we like
make a wrapper for the N so that like
make a wrapper for the N so that like
the N is responsible for giving us a
the N is responsible for giving us a
reasonable reward. The only thing that
reasonable reward. The only thing that
we do is we will clip the reward from
we do is we will clip the reward from
negative one to one just because like
negative one to one just because like
there are a lot of M's with just insane
there are a lot of M's with just insane
reward functions that will instantly
reward functions that will instantly
break learning otherwise.
break learning otherwise.
Yeah, but all our rewards are probably
Yeah, but all our rewards are probably
in a scale of like 0.01 or 0.1 because
in a scale of like 0.01 or 0.1 because
you already normalize it. You're using
you already normalize it. You're using
normalized one, right? Yeah, you are. Uh
normalized one, right? Yeah, you are. Uh
so I could get rid of this 10x and just
so I could get rid of this 10x and just
have diff and then I' I'd have to add
have diff and then I' I'd have to add
like a reward scale param. I guess it's
like a reward scale param. I guess it's
a little weird, but I we could do it.
a little weird, but I we could do it.
It's okay. I my person like at least in
It's okay. I my person like at least in
my own ppl code I often add your scale
my own ppl code I often add your scale
as just a config parameter because it's
as just a config parameter because it's
dependent on environment. Yeah. Well, I
dependent on environment. Yeah. Well, I
guess because it's dependent on
guess because it's dependent on
environment maybe you should just put it
environment maybe you should just put it
in the environment. But the thing is
in the environment. But the thing is
the other reason why I put it there is
the other reason why I put it there is
because it's also dependent on algorithm
because it's also dependent on algorithm
sometimes. Yeah, some algorithms might
sometimes. Yeah, some algorithms might
handle it better than others. Right. We
handle it better than others. Right. We
kind of just the thing in puffer is we
kind of just the thing in puffer is we
just have the one best algorithm.
just have the one best algorithm.
I see right. Uh I mean technically we
I see right. Uh I mean technically we
already have a mistake in here where we
already have a mistake in here where we
have a normalized density reward and a
have a normalized density reward and a
non-normalized one. Yeah. The reason why
non-normalized one. Yeah. The reason why
we call it a non-normalized one is
we call it a non-normalized one is
because people still use that from
because people still use that from
manuscript 2 and just left it there. But
manuscript 2 and just left it there. But
I
I
uh Okay. The problem is I I don't like
uh Okay. The problem is I I don't like
the idea of having to tune the delta
the idea of having to tune the delta
reward skill for every environment.
reward skill for every environment.
Unless we want to do it now, we could.
Unless we want to do it now, we could.
Um I guess but the problem is like well
Um I guess but the problem is like well
I don't that's the only you don't really
I don't that's the only you don't really
have to as long as it's in a reasonable
have to as long as it's in a reasonable
enough range. Um that's it then like
enough range. Um that's it then like
because the thing is you you're tuning
because the thing is you you're tuning
your learning rate in other things right
your learning rate in other things right
and that kind of gets it but it like you
and that kind of gets it but it like you
still want to have your reward on like a
still want to have your reward on like a
reasonable enough scale that your
reasonable enough scale that your
default like your defaults actually
default like your defaults actually
learn something so you have a starting
learn something so you have a starting
point. So like it just generally if we
point. So like it just generally if we
can get the reward into a roughly 0ero
can get the reward into a roughly 0ero
to one or negative one to one scale like
to one or negative one to one scale like
somethingish around there we'll be fine
somethingish around there we'll be fine
but I don't know is there some general
but I don't know is there some general
thing we can do because it's like so
thing we can do because it's like so
technically the maximum diff the maximum
technically the maximum diff the maximum
delta is one right because your
delta is one right because your
normalized reward goes from zero to one
normalized reward goes from zero to one
so if you were to jump if you were to
so if you were to jump if you were to
teleport to the target in one step it
teleport to the target in one step it
would be one
would be one
yes but that's almost impossible. Yes,
yes but that's almost impossible. Yes,
exactly. So, but then the thing is like
exactly. So, but then the thing is like
what do we set it to to be reasonable?
what do we set it to to be reasonable?
I mean, if you do times 10, you're going
I mean, if you do times 10, you're going
to clip it to one anyway. Yeah. Um, but
to clip it to one anyway. Yeah. Um, but
most of the time the reward function
most of the time the reward function
you're going to be dealing with is just
you're going to be dealing with is just
a tage function or exponential, right?
a tage function or exponential, right?
Yeah. Because most of the time you're
Yeah. Because most of the time you're
not switching stages in reward function.
not switching stages in reward function.
Like we do reward functions by stages
Like we do reward functions by stages
usually. Um, and so between stages is a
usually. Um, and so between stages is a
small jump, but otherwise in a stage is
small jump, but otherwise in a stage is
always just whatever the gradient of the
always just whatever the gradient of the
tanh function is and that's what you're
tanh function is and that's what you're
following. Well, I mean, I can show you
following. Well, I mean, I can show you
what we get from this in where is it?
what we get from this in where is it?
So, success once. These are some of our
So, success once. These are some of our
experiments here. Actually, I'll show
experiments here. Actually, I'll show
you the best ones because I have this
you the best ones because I have this
nice full sweep for you.
nice full sweep for you.
Okay, this is what it looks like um for
Okay, this is what it looks like um for
thisund and 138 experiments.
And you can see that we have like a
And you can see that we have like a
variety of these different results.
variety of these different results.
get return and such. And uh we also have
get return and such. And uh we also have
reward. So reward it looks like for the
reward. So reward it looks like for the
best it gets up to about point four with
best it gets up to about point four with
the times 10 that I find. Yeah, is like
the times 10 that I find. Yeah, is like
a reason I would call that a reasonable
a reason I would call that a reasonable
enough scale. Um which task is this
enough scale. Um which task is this
again? This is pick.
again? This is pick.
Okay. I I feel like time st is okay.
Okay. I I feel like time st is okay.
This is reflecting what the result of
This is reflecting what the result of
tanh is usually like the difference of
tanh is usually like the difference of
two tanh operations at two points. Yeah,
two tanh operations at two points. Yeah,
that seems about and then I can show you
that seems about and then I can show you
if I just I can show you the best runs.
if I just I can show you the best runs.
But also this is probably overfitit on
But also this is probably overfitit on
the robot you're using right now. Some
the robot you're using right now. Some
other robots have smaller scales of
other robots have smaller scales of
movement which might be different which
movement which might be different which
might be annoying. I mean I would be
might be annoying. I mean I would be
curious try without multip by 10 and
curious try without multip by 10 and
just see if your algorithm can be robust
just see if your algorithm can be robust
to it. Uh I can try. My guess would be
to it. Uh I can try. My guess would be
that the p the optimal hypers are going
that the p the optimal hypers are going
to shift dramatically.
Maybe not. a way to make this I feel
Maybe not. a way to make this I feel
like you need a way to make this
like you need a way to make this
slightly more robust because I I can try
slightly more robust because I I can try
it. I can just try it. Yeah, I would
it. I can just try it. Yeah, I would
think you should try it. But I feel like
think you should try it. But I feel like
it's a bit hard to guarantee that every
it's a bit hard to guarantee that every
environment has a reasonable reward
environment has a reasonable reward
function. I mean, you're already
function. I mean, you're already
clipping to try to avoid that. Well,
clipping to try to avoid that. Well,
we're clipping is just like if you give
we're clipping is just like if you give
it's that's basically the intent of that
it's that's basically the intent of that
is don't give me something insane. Like
is don't give me something insane. Like
there are people people will literally
there are people people will literally
PR me environments that have like 300
PR me environments that have like 300
reward scale and I tell them to fix but
reward scale and I tell them to fix but
like all the third party environments
like all the third party environments
literally people have no idea what
literally people have no idea what
they're doing in this field man I
they're doing in this field man I
remember the days in the first opening
remember the days in the first opening
were like going to thousands or tens of
were like going to thousands or tens of
thousands. Yeah
thousands. Yeah
that's kind of crazy. Yeah people just
that's kind of crazy. Yeah people just
don't know what they're doing honest
don't know what they're doing honest
the fix for that some people try to do
the fix for that some people try to do
is try and use sim log wait clipping
is try and use sim log wait clipping
also yeah that doesn't work. We uh we
also yeah that doesn't work. We uh we
have we have extensive we have extensive
have we have extensive we have extensive
experimental evidence that sim log is a
experimental evidence that sim log is a
method. I think you tested only
method. I think you tested only
on dreamer though. Wasn't on a dreamer
on dreamer though. Wasn't on a dreamer
one. We tested it on PO.
one. We tested it on PO.
Oh, maybe that's a PO thing. We we we
Oh, maybe that's a PO thing. We we we
tried sim log on TDMPC our model base.
tried sim log on TDMPC our model base.
That seems to work quite well. Did you
That seems to work quite well. Did you
try it versus just clipping?
try it versus just clipping?
Uh we have not tried it versus clipping
Uh we have not tried it versus clipping
but it was definitely better than not
but it was definitely better than not
doing anything. Yes. So you need to So
doing anything. Yes. So you need to So
it's basically you just need to do
it's basically you just need to do
something and just clipping is just as
something and just clipping is just as
good as sim log if not better.
good as sim log if not better.
Huh. Yeah, I see. Okay. Yeah. Uh yeah.
Huh. Yeah, I see. Okay. Yeah. Uh yeah.
So that was a bust one for paper.
Interesting. Yeah. I mean like you said
Interesting. Yeah. I mean like you said
we don't like our algorithm it's based
we don't like our algorithm it's based
on PO but our trainer is not PO at this
on PO but our trainer is not PO at this
point. It's like it's changed enough to
point. It's like it's changed enough to
not call it the same algorithm.
not call it the same algorithm.
Huh. Okay.
Huh. Okay.
And it's been dramatically better on
And it's been dramatically better on
everything else we've tested. So, my
everything else we've tested. So, my
expectation is after we speak, you
expectation is after we speak, you
should see some improvements on this.
should see some improvements on this.
Um, it's got it has a new advantage
Um, it's got it has a new advantage
function. It's got a different
function. It's got a different
optimizer. It's got like prioritized
optimizer. It's got like prioritized
replay on online prioritized replay. Uh,
replay on online prioritized replay. Uh,
advantage filtering like trajectory
advantage filtering like trajectory
segment level filtering. Got a bunch of
segment level filtering. Got a bunch of
stuff.
stuff.
Nice.
Nice.
And it's fast.
Yeah, you're adding a lot of It's like a
Yeah, you're adding a lot of It's like a
rainbow PO now. H I mean I would think
rainbow PO now. H I mean I would think
that the stuff that we've added has been
that the stuff that we've added has been
much better validated. And also like
much better validated. And also like
it's harder to bolt stuff onto PO that
it's harder to bolt stuff onto PO that
matters than it is to bolt stuff onto
matters than it is to bolt stuff onto
DQN because DQN's just a bad base
DQN because DQN's just a bad base
algorithm whereas PO is a pretty dang
algorithm whereas PO is a pretty dang
good base algorithm. Still using PQN. I
good base algorithm. Still using PQN. I
I swear there shouldn't be anyone using
I swear there shouldn't be anyone using
DQ. Yeah, but like Rainbow is like
DQ. Yeah, but like Rainbow is like
Rainbow is like a bolt-on to DQN
Rainbow is like a bolt-on to DQN
basically, right? Yeah, but like DK is
basically, right? Yeah, but like DK is
too bad of a base algorithm. I don't
too bad of a base algorithm. I don't
know why you would do that. Yeah. Well,
know why you would do that. Yeah. Well,
the point here is that like if you try
the point here is that like if you try
to like make like a rainbow PO for
to like make like a rainbow PO for
instance, it's a lot harder than it is
instance, it's a lot harder than it is
to make like rainbow DQN because your
to make like rainbow DQN because your
starting point is a much stronger
starting point is a much stronger
baseline.
baseline.
Ah, yes, I agree. That makes sense.
Ah, yes, I agree. That makes sense.
Yeah. Yeah. Cuz like so most of the
Yeah. Yeah. Cuz like so most of the
papers that say we made P like we made a
papers that say we made P like we made a
better PO if you actually go try them
better PO if you actually go try them
they're just wrong.
they're just wrong.
Yeah. I mean people are still using PO
Yeah. I mean people are still using PO
now right. There's a good reason for
now right. There's a good reason for
that. Yeah I'm still it. I think there
that. Yeah I'm still it. I think there
is some possibility SACE might make a
is some possibility SACE might make a
comeback but it could be within the
comeback but it could be within the
regime that we are testing out which is
regime that we are testing out which is
100ks. It's just low. I will say um well
100ks. It's just low. I will say um well
we'll see once I run these sweeps for
we'll see once I run these sweeps for
you if you're convinced by this. Uh the
you if you're convinced by this. Uh the
very least though, like the absolute
very least though, like the absolute
very least you do, even if you don't
very least you do, even if you don't
want to do like our more complicated
want to do like our more complicated
stuff is to switch your optimizer from
stuff is to switch your optimizer from
Atom to Muon and retune all your hyper
Atom to Muon and retune all your hyper
prams. Oh yeah, I heard you were using
prams. Oh yeah, I heard you were using
Muon. It seems to actually work pretty
Muon. It seems to actually work pretty
well, right? But you also need to tune
well, right? But you also need to tune
your other parameters according to
your other parameters according to
learning rate and whatever. You need to
learning rate and whatever. You need to
retune all your parameters.
retune all your parameters.
I see. Are you using muon right now?
I see. Are you using muon right now?
Yes. In these sweeps? Yes. Everything is
Yes. In these sweeps? Yes. Everything is
muon by default.
muon by default.
Nice.
Nice.
Okay. I mean, at this point in manual
Okay. I mean, at this point in manual
repo, we have a baselines folder. I'll
repo, we have a baselines folder. I'll
probably just add a separate folder
probably just add a separate folder
called puffer dbo and just point to your
called puffer dbo and just point to your
website. That works much better. Yeah. I
website. That works much better. Yeah. I
I mean, it's like the cool thing is our
I mean, it's like the cool thing is our
stuff is it's vaguely clean RL. It's
stuff is it's vaguely clean RL. It's
obviously it's gotten a little bit
obviously it's gotten a little bit
longer with all the stuff we've had to
longer with all the stuff we've had to
do, but like our trainer is still Have
do, but like our trainer is still Have
you seen it late? Have you seen it
you seen it late? Have you seen it
recently? Which one? The Puff Rel file.
recently? Which one? The Puff Rel file.
No. What is it? This is your training
No. What is it? This is your training
file. 1,000 total lines. And this
file. 1,000 total lines. And this
includes this includes pretty much
includes this includes pretty much
everything. Uh it includes as well the
everything. Uh it includes as well the
local dashboard, the nice local
local dashboard, the nice local
monitoring dashboard, integrations for
monitoring dashboard, integrations for
Neptune and wann. Uh it includes like
Neptune and wann. Uh it includes like
the runner. Yes. For current training.
the runner. Yes. For current training.
It includes all the config stuff to load
It includes all the config stuff to load
all the different puffer ends as well.
all the different puffer ends as well.
Um
Um
yeah, and eval. It includes a lot of
yeah, and eval. It includes a lot of
stuff. A big chunk of it is just
stuff. A big chunk of it is just
printing. Yes. A lot of it is like this
printing. Yes. A lot of it is like this
is the dashboard. When you see that like
is the dashboard. When you see that like
in your terminal dashboard, it's just
in your terminal dashboard, it's just
right there. And then this is move this
right there. And then this is move this
function out outside the dashboard part.
function out outside the dashboard part.
No, we just keep everything in a file as
No, we just keep everything in a file as
much as possible. That's funny. I feel
much as possible. That's funny. I feel
like I minimum logging stuff should be a
like I minimum logging stuff should be a
separate file, but okay. We try to just
separate file, but okay. We try to just
keep everything there. I think we have
keep everything there. I think we have
separate models because of separate
separate models because of separate
models file because it's like you're not
models file because it's like you're not
going to use every model with this but
going to use every model with this but
you're always going to this dashboard
you're always going to this dashboard
with this. Um so we try to just keep
with this. Um so we try to just keep
this together and then the one other
this together and then the one other
thing here that literally cannot be in
thing here that literally cannot be in
the same file is the CUDA extension
the same file is the CUDA extension
because we have the advantage function
because we have the advantage function
here. Oh, you're on a CUDA colonel for
here. Oh, you're on a CUDA colonel for
advantage. It's required. Uh, puffer is
advantage. It's required. Uh, puffer is
literally so fast that with the way that
literally so fast that with the way that
prioritized experience replay works, if
prioritized experience replay works, if
you do not have this, you can bottleneck
you do not have this, you can bottleneck
on the advantage computation.
on the advantage computation.
Huh? Yeah, I remember advantage comput
Huh? Yeah, I remember advantage comput
is like a big for loop, right? You got
is like a big for loop, right? You got
to paralyze that. This is also this is
to paralyze that. This is also this is
also something that you can steal. This
also something that you can steal. This
is not generalized advantage estimation.
is not generalized advantage estimation.
This is our own algorithm. This is a
This is our own algorithm. This is a
strict generalization of both vrace and
strict generalization of both vrace and
generalized advantage estimation.
generalized advantage estimation.
Wait, what is this different from the
Wait, what is this different from the
standard advantage computation? Yes.
standard advantage computation? Yes.
What's the difference? It is a strict
What's the difference? It is a strict
generalization of vrace and generalized
generalization of vrace and generalized
advantage estimation both. Oh, wait. You
advantage estimation both. Oh, wait. You
have an importance vector and then
have an importance vector and then
you're you have a row clip. What row
you're you have a row clip. What row
clip doing here? So, this is vrace. You
clip doing here? So, this is vrace. You
know vtrace from Impala? I have heard of
know vtrace from Impala? I have heard of
it. I don't know how it works. It's an
it. I don't know how it works. It's an
off it's an off policy correction
off it's an off policy correction
mechanism. You know how uh PO has like
mechanism. You know how uh PO has like
this it has this term that tries to like
this it has this term that tries to like
keep close to the original policy like
keep close to the original policy like
this importance term. So what vrace does
this importance term. So what vrace does
is it does that inside of the advantage
is it does that inside of the advantage
function. So it pushes it a layer
function. So it pushes it a layer
deeper. You have it at actually every
deeper. You have it at actually every
step of the advantage computation. You
step of the advantage computation. You
have that importance term.
have that importance term.
I see. Huh. So what this does is this
I see. Huh. So what this does is this
gives you that and it gives you
gives you that and it gives you
generalized advantage estimation at the
generalized advantage estimation at the
same time as a generalization of both.
same time as a generalization of both.
What's the fmn in function where oh
What's the fmn in function where oh
fmin? It's just a min float min float.
fmin? It's just a min float min float.
Oh, that's the clipping thing. Okay.
Oh, that's the clipping thing. Okay.
Float. So, you're taking them in and you
Float. So, you're taking them in and you
have the CT part and then Huh. And then
have the CT part and then Huh. And then
the only thing you have to be a little
the only thing you have to be a little
careful of is whether your next your
careful of is whether your next your
current versus next step indexing is the
current versus next step indexing is the
same as ours. This is correct for our
same as ours. This is correct for our
implementation.
implementation.
Yeah. But yeah, this is this is the main
Yeah. But yeah, this is this is the main
thing. This was the thing that made it
thing. This was the thing that made it
really annoying to ship Puffer 3.0
really annoying to ship Puffer 3.0
because shipping CUDA kernels just
because shipping CUDA kernels just
sucks. It's just a pain in the ass to
sucks. It's just a pain in the ass to
set up with uh with your setup.py. high.
set up with uh with your setup.py. high.
Uh, and there's also like there's an
Uh, and there's also like there's an
automatic C++ fallback for this as well.
automatic C++ fallback for this as well.
Without embedded GPUs at least. Yeah.
Without embedded GPUs at least. Yeah.
So, this just like works. Yeah. And then
So, this just like works. Yeah. And then
that's that was one of the other big
that's that was one of the other big
things. So, like at this point,
things. So, like at this point,
basically nobody has actually started
basically nobody has actually started
using any of our stuff outside of Puffer
using any of our stuff outside of Puffer
yet, but it is technically just all
yet, but it is technically just all
there and you can just like
there and you can just like
state of the art stuff.
state of the art stuff.
I mean, I have my own PO code. I'll
I mean, I have my own PO code. I'll
probably just switch if it's faster than
probably just switch if it's faster than
lean RL version of it. It will be
lean RL version of it. It will be
dramatically faster. I guess I will
dramatically faster. I guess I will
still need to kind of tune for single
still need to kind of tune for single
GPU still. Well, let me just do that
GPU still. Well, let me just do that
first, right? Let me let me just run
first, right? Let me let me just run
that stuff and we'll see how good I can
that stuff and we'll see how good I can
get it. But yeah, like yeah, this this
get it. But yeah, like yeah, this this
single implementation we use this on the
single implementation we use this on the
cool thing about this is we just use
cool thing about this is we just use
this one implementation on everything.
this one implementation on everything.
So it's like tuned for it like has to be
So it's like tuned for it like has to be
good for everything basically. Um,
good for everything basically. Um,
right. So this thing with really big
right. So this thing with really big
batch sizes I have hit I've trained uh
batch sizes I have hit I've trained uh
20 million step per second pong that
20 million step per second pong that
actually solves the M like at that like
actually solves the M like at that like
with crazy batch sizes. And the other
with crazy batch sizes. And the other
thing about this is if you run this
thing about this is if you run this
distributed, this thing will give you
distributed, this thing will give you
linear speed ups even for Ms that are
linear speed ups even for Ms that are
like running at like uh like several
like running at like uh like several
hundred thousand steps per second
hundred thousand steps per second
because like the overhead is tiny.
because like the overhead is tiny.
That's crazy.
Yeah, this is basically core of puffer
Yeah, this is basically core of puffer
3. I I hope that this is going to be
3. I I hope that this is going to be
useful for robotics because basically
useful for robotics because basically
what I'm trying to do with Manny here is
what I'm trying to do with Manny here is
like just see whether we can just throw
like just see whether we can just throw
this on robotics and build something
this on robotics and build something
that's useful to robotics researchers as
that's useful to robotics researchers as
a result. We haven't had that much
a result. We haven't had that much
usage. A lot of our people use our PO
usage. A lot of our people use our PO
baseline if they can use this when it's
baseline if they can use this when it's
faster, that's easy to install, but I'm
faster, that's easy to install, but I'm
sure they'll switch over. Uh, I would
sure they'll switch over. Uh, I would
also recommend I mean if you want more
also recommend I mean if you want more
you should target locomotion but I know
you should target locomotion but I know
you haven't done Isaac but you probably
you haven't done Isaac but you probably
should. The reason we did Isaac Gym and
should. The reason we did Isaac Gym and
it was we had a contract where we did
it was we had a contract where we did
Isaac gym and it was it was hell like
Isaac gym and it was it was hell like
did the contract work out eventually?
did the contract work out eventually?
Like yeah we did it but like we did it.
Like yeah we did it but like we did it.
It was just like way way more work than
It was just like way way more work than
it should have been. And like honestly
it should have been. And like honestly
it was just like some of the dumbest
it was just like some of the dumbest
most deranged code we've ever seen uh
most deranged code we've ever seen uh
was the Isaac Jim code bases. Like they
was the Isaac Jim code bases. Like they
literally have like they have
literally have like they have
generational trauma of like it's like
generational trauma of like it's like
one PhD student wrapping another PhD
one PhD student wrapping another PhD
student shitty code and then like roll
student shitty code and then like roll
that forward five generations of
that forward five generations of
miserable PhD students.
miserable PhD students.
I see. Um well anyway regardless the
I see. Um well anyway regardless the
most frequent uses of PO and robotics
most frequent uses of PO and robotics
will be people training dogs and robot
will be people training dogs and robot
humanoids.
humanoids.
Um you have the you have um you have
Um you have the you have um you have
humanoid tasks in Manny, don't you?
humanoid tasks in Manny, don't you?
Yeah, we have manipulation tasks, not
Yeah, we have manipulation tasks, not
locomotion. Our locomotion ones suck
locomotion. Our locomotion ones suck
because I don't have the right reward
because I don't have the right reward
functions. Isaac Lab and Isaac Jim have
functions. Isaac Lab and Isaac Jim have
tuned the reward functions already and
tuned the reward functions already and
I've never figured out how to do it
I've never figured out how to do it
myself. Oh, the other thing is we I've
myself. Oh, the other thing is we I've
never been able to replicate Isaac Jim's
never been able to replicate Isaac Jim's
locomotion simulation speed. I don't
locomotion simulation speed. I don't
know what they did, but we have not been
know what they did, but we have not been
able to replicate it. So, I just did.
able to replicate it. So, I just did.
Okay. So, I mean, let's just see how far
Okay. So, I mean, let's just see how far
we get out of tuning. If like if I am
we get out of tuning. If like if I am
actually able to get something fast and
actually able to get something fast and
like if I'm able to get stable training
like if I'm able to get stable training
at quick speeds with this, then I think
at quick speeds with this, then I think
that could potentially unlock a lot of
that could potentially unlock a lot of
new stuff for you on the sim. Yeah, for
new stuff for you on the sim. Yeah, for
sure. I mean, it'll be tasks that we
sure. I mean, it'll be tasks that we
didn't expect we can solve, right? That
didn't expect we can solve, right? That
we can also solve. That's literally what
we can also solve. That's literally what
has happened with a lot of the things in
has happened with a lot of the things in
Puffer is like just from 2 to 3 0 we had
Puffer is like just from 2 to 3 0 we had
a lot of hard problems that we really we
a lot of hard problems that we really we
were putting a lot of effort into and we
were putting a lot of effort into and we
couldn't quite get before and now they
couldn't quite get before and now they
just work out of the box. Um nice like
just work out of the box. Um nice like
in various different domains things are
in various different domains things are
just like getting soda.
just like getting soda.
Another thing I want you to consider
Another thing I want you to consider
have you considered learning from
have you considered learning from
demonstrations like online learning
demonstrations like online learning
demonstrations?
demonstrations?
Um we did that for that one contract.
Um we did that for that one contract.
It's like is that even a hard problem
It's like is that even a hard problem
like at all? Yes. And also it's a very
like at all? Yes. And also it's a very
popular problem in robotics because
popular problem in robotics because
right now most of robotics is heavily
right now most of robotics is heavily
focused on using demonstration data from
focused on using demonstration data from
the real world or simulation.
the real world or simulation.
The problem is I mean real world data
The problem is I mean real world data
they do imitation learning on it but in
they do imitation learning on it but in
simulation you can do RL and imitation
simulation you can do RL and imitation
learning together. Yeah that's a setup
learning together. Yeah that's a setup
we is the point is you want to get rid
we is the point is you want to get rid
of density functions. There's too many
of density functions. There's too many
possible robotics task. There's not
possible robotics task. There's not
enough people to write reward functions
enough people to write reward functions
for and language models are not good
for and language models are not good
enough at writing reward functions
enough at writing reward functions
apparently. So it's hard to scale in
apparently. So it's hard to scale in
that sense. So people have opted
that sense. So people have opted
including me people have opted to try
including me people have opted to try
get a few demonstrations train or SACE
get a few demonstrations train or SACE
or whatever to learn from that in a
or whatever to learn from that in a
sparse reward environment. So I think
sparse reward environment. So I think
that basically if you just get if you
that basically if you just get if you
just get a policy that can take actions
just get a policy that can take actions
that make sense. So instead of like
that make sense. So instead of like
flailing and like jittering, if it can
flailing and like jittering, if it can
just like make actions that are like
just like make actions that are like
move arm here, move arm here, whatever,
move arm here, move arm here, whatever,
the exploration problem kind of becomes
the exploration problem kind of becomes
trivial enough that you should just be
trivial enough that you should just be
able to use the sparse reward setting
able to use the sparse reward setting
online. No, no, that's what I hope too.
online. No, no, that's what I hope too.
And in fact, actually, one of the things
And in fact, actually, one of the things
I worked on before was trying to use
I worked on before was trying to use
simulation state to reset the agent to
simulation state to reset the agent to
anywhere I want. Like you know the go
anywhere I want. Like you know the go
explore paper. Oh yeah. I I made a
explore paper. Oh yeah. I I made a
version probably like I mean code. They
version probably like I mean code. They
didn't have code for that one, but like
didn't have code for that one, but like
a much better version of it. It's called
a much better version of it. It's called
reverse for curriculum learning. Yeah,
reverse for curriculum learning. Yeah,
that would work for robotics. That
that would work for robotics. That
should just work. Yes, I am I have one
should just work. Yes, I am I have one
student trying to make that work with
student trying to make that work with
PTO now because we originally used SACE
PTO now because we originally used SACE
back when GPU summation wasn't a thing.
back when GPU summation wasn't a thing.
But yeah, that would be the way I would
But yeah, that would be the way I would
approach for simulation based learning
approach for simulation based learning
demonstrations, which is use state to
demonstrations, which is use state to
mitigate all the exploration problems.
mitigate all the exploration problems.
Um, yeah, I don't have to do any fancy
Um, yeah, I don't have to do any fancy
loss function actually. I don't I don't
loss function actually. I don't I don't
actually I just do curriculum learning
actually I just do curriculum learning
and state setting. Um I know there's
and state setting. Um I know there's
some fancier methods that try to do like
some fancier methods that try to do like
I don't know if you heard of method
I don't know if you heard of method
called DAPG demonstration augmented
called DAPG demonstration augmented
policy gradient. No they changed the pol
policy gradient. No they changed the pol
policy gradient a little bit by use with
policy gradient a little bit by use with
demonstration data and it's okay. I
demonstration data and it's okay. I
don't think it's very stable. Um it's
don't think it's very stable. Um it's
like very old papers from like 2018. U
like very old papers from like 2018. U
but that's still one of the more popular
but that's still one of the more popular
baselines for on policy learning from
baselines for on policy learning from
demonstrations if you don't use
demonstrations if you don't use
simulation state at least.
simulation state at least.
Um, let's just see. Let's see how much
Um, let's just see. Let's see how much
of a let's see if if this just makes a
of a let's see if if this just makes a
difference or not because it like it
difference or not because it like it
it's possible that it doesn't like
it's possible that it doesn't like
because it's a pretty different domain.
because it's a pretty different domain.
But my hope is that between messing with
But my hope is that between messing with
the simulation fidelity and everything,
the simulation fidelity and everything,
we should be able to get something. And
we should be able to get something. And
then uh if that starts kind of working
then uh if that starts kind of working
then I'm gonna have to ask you about
then I'm gonna have to ask you about
like control speed and domain
like control speed and domain
randomization and stuff because like my
randomization and stuff because like my
kind of my impression on a lot of these
kind of my impression on a lot of these
things is just like a really fast and
things is just like a really fast and
loose and well randomized sim should get
loose and well randomized sim should get
you very very far. um including like
you very very far. um including like
let's say that you wanted to mix in some
let's say that you wanted to mix in some
slower sim, right? Then I'd have to
slower sim, right? Then I'd have to
figure out how you do that from an
figure out how you do that from an
instructor perspective with the way that
instructor perspective with the way that
your GP sims are set up, but you should
your GP sims are set up, but you should
be able to do something like that. Wait,
be able to do something like that. Wait,
what do you mean mix in slower sims like
what do you mean mix in slower sims like
our rendering ones? Well, you wouldn't
our rendering ones? Well, you wouldn't
be able to go state to rendering, but
be able to go state to rendering, but
let's say that you had like a setting of
let's say that you had like a setting of
the sim that's domain randomized to be
the sim that's domain randomized to be
super low fidelity and then a setting
super low fidelity and then a setting
that's randomized to be like that's
that's randomized to be like that's
super high fidelity. Ah, yes. That's a
super high fidelity. Ah, yes. That's a
very interesting thing. Um I actually
very interesting thing. Um I actually
have one research project where we're
have one research project where we're
trying to explore how much curriculum
trying to explore how much curriculum
learning we can do on the physics and
learning we can do on the physics and
the renderer. We have we will have
the renderer. We have we will have
options in the future to modify the
options in the future to modify the
fidelity in many ways. Um obviously the
fidelity in many ways. Um obviously the
physics ones are
physics ones are
I have a way that you could this with
I have a way that you could this with
puffer. I you'd have to make separate
puffer. I you'd have to make separate
batches of the sim. I don't know how
batches of the sim. I don't know how
well it would work, but like essentially
well it would work, but like essentially
you could make like say you could make
you could make like say you could make
like four batches of Sims, three of
like four batches of Sims, three of
which are low fidelity and one of which
which are low fidelity and one of which
is high fidelity and then you cycle
is high fidelity and then you cycle
through them, you only get the highest
through them, you only get the highest
fidelity sim like a quarter of the time,
fidelity sim like a quarter of the time,
for instance. You can over time you
for instance. You can over time you
start to use more of the high fidelity
start to use more of the high fidelity
data, right? You can do that as well.
data, right? You can do that as well.
The only thing I don't know about how it
The only thing I don't know about how it
works in your case is like this the
works in your case is like this the
highfidelity sims are slower. You have
highfidelity sims are slower. You have
to set it up in a way that you don't get
to set it up in a way that you don't get
time bottlenecked by the slowest sim,
time bottlenecked by the slowest sim,
right?
right?
I see. Um I'm not exactly sure how
I see. Um I'm not exactly sure how
you're Well, if you're running these
you're Well, if you're running these
processes isolated, right, one of them
processes isolated, right, one of them
is not going to affect the other one
is not going to affect the other one
anyway, right? I think because you do
anyway, right? I think because you do
batch sim the way we do we're not but
batch sim the way we do we're not but
you you have batch sim, don't you? like
you you have batch sim, don't you? like
each each enemy is using separate CUDA
each each enemy is using separate CUDA
cores. Yeah. Yes. Yes. That's that'll be
cores. Yeah. Yes. Yes. That's that'll be
a problem.
a problem.
This will get pretty deep into sim. I
This will get pretty deep into sim. I
see. So in Puffer, we can just do domain
see. So in Puffer, we can just do domain
randomization for free pretty much
randomization for free pretty much
because our M's are serial on each core,
because our M's are serial on each core,
but like the fast ones and the slow
but like the fast ones and the slow
ones, they all average out.
ones, they all average out.
Okay. So yeah, there's some sim design
Okay. So yeah, there's some sim design
things to consider here. But basically,
things to consider here. But basically,
I think that if if this actually does
I think that if if this actually does
give us enough lift to like be worth
give us enough lift to like be worth
looking into further, um there's a lot
looking into further, um there's a lot
that you can do in the hyper space based
that you can do in the hyper space based
on what we have here.
on what we have here.
Nice. Like that lel implementation for
Nice. Like that lel implementation for
instance, my guess will be that even if
instance, my guess will be that even if
you make the sim dramatically faster,
you make the sim dramatically faster,
you're going to get bottlenecked by
you're going to get bottlenecked by
other sources overhead quite quickly.
other sources overhead quite quickly.
But we don't. Yeah. Like my lean roar
But we don't. Yeah. Like my lean roar
version for SAC and PO like you know
version for SAC and PO like you know
like 20 to 50% of the time spent on
like 20 to 50% of the time spent on
updates. Yeah. Uh right. So I mean like
updates. Yeah. Uh right. So I mean like
you see our default out of the box it's
you see our default out of the box it's
like 5% on updates. Now it'll go up if
like 5% on updates. Now it'll go up if
we increase update epochs obviously but
we increase update epochs obviously but
like there other design like there's
like there other design like there's
several sources of slowness right
several sources of slowness right
there's overhead in the trainer itself.
there's overhead in the trainer itself.
There's optimization for specific batch
There's optimization for specific batch
sizes and mini batch sizes. Like some of
sizes and mini batch sizes. Like some of
it is the implementation of itself. Some
it is the implementation of itself. Some
of it's just the settings. We have all
of it's just the settings. We have all
that figured out basically the high perf
that figured out basically the high perf
case already.
case already.
Nice.
Nice.
Okay, I also just pushed to that branch
Okay, I also just pushed to that branch
my fix for the back end thing. So you
my fix for the back end thing. So you
can just put physics cuda col
can just put physics cuda col
number and it should work. I hope. Well,
number and it should work. I hope. Well,
okay. So, I'm going to I'm going to go
okay. So, I'm going to I'm going to go
work on this for a little bit. I'm going
work on this for a little bit. I'm going
to see if I can find like anything cool.
to see if I can find like anything cool.
I'm going to try to like basically
I'm going to try to like basically
speedrun the PC cube task and then see
speedrun the PC cube task and then see
if I can use that to like solve some
if I can use that to like solve some
harder stuff. Awesome. Cool. Yeah. Um,
harder stuff. Awesome. Cool. Yeah. Um,
we'll do RGB eventually. We'll do RGB
we'll do RGB eventually. We'll do RGB
eventually. Um, I I know that's probably
eventually. Um, I I know that's probably
going to be a little tougher because
going to be a little tougher because
that just gets way slower, but we'll
that just gets way slower, but we'll
we'll cross that bridge when we get
we'll cross that bridge when we get
there. Mhm. Okay, nice.
there. Mhm. Okay, nice.
Yeah, look forward to it. I'm going to
Yeah, look forward to it. I'm going to
hop for now, but yeah, thanks for
hop for now, but yeah, thanks for
dropping by and thanks for the the
dropping by and thanks for the the
assistance. Yes, see you. Yeah,
assistance. Yes, see you. Yeah,
that was fun.
that was fun.
Cool. YouTube folks, I will be right
Cool. YouTube folks, I will be right
back. Use the restroom real quick and
back. Use the restroom real quick and
then we will uh using all that
then we will uh using all that
information we just got, we will
information we just got, we will
robotics.
robotics.
Be right back.
respond to this thing.
All All right.
All
right.
right.
Do the uh let's do the robotics thing.
Do the uh let's do the robotics thing.
Time for science.
Time for science.
So,
So,
a few quick tests. Uh, first
six times.
six times.
Let's do 3 million.
Annie pick cube
Annie pick cube
tag.
First we're going to see if this thing
First we're going to see if this thing
can actually solve indecent wall clock
can actually solve indecent wall clock
these settings. Uh we haven't run this
these settings. Uh we haven't run this
before because this is going to do
before because this is going to do
Whoops.
Whoops.
Unexpected keyword sim freak.
Okay, we'll just not do this yet.
Roll freak. Sim freak.
What is going on here?
Ah,
okay.
This ought to work. And uh the question
This ought to work. And uh the question
here
here
is if we can learn this in a reasonable
is if we can learn this in a reasonable
amount of time and then after this we
amount of time and then after this we
will we'll basically tune this for uh
will we'll basically tune this for uh
even faster potentially.
I just want to try messing with the uh
I just want to try messing with the uh
update epochs real quick
update epochs real quick
and then we'll try messing with the
and then we'll try messing with the
simulation resolution.
Yeah, I think I need to increase it a
Yeah, I think I need to increase it a
little bit because
little bit because
it is learning but not fast enough.
the heck.
I don't think you should be trapping
I don't think you should be trapping
terminals.
Okay. So this thing is
Okay. So this thing is
it's training,
but it's not training anywhere near as
but it's not training anywhere near as
well.
well.
I guess it's just there's a limitation
I guess it's just there's a limitation
to how much you can get by just scaling
to how much you can get by just scaling
the batch size in these
which is what you would expect. That's
which is what you would expect. That's
fine.
So in that case then there's no point in
So in that case then there's no point in
us running this distributed at all for
us running this distributed at all for
this specific task which again fine.
We will rerun the single GPU task just
We will rerun the single GPU task just
to make sure that it still works.
this should give us a clean solve curve.
this should give us a clean solve curve.
And of course,
Okay. So this is now giving us
the expected curve.
Another.
Oh yeah, right here.
Just make sure that we get the
bars.
So, and we're going to try to do like
So, and we're going to try to do like
sim frequency
like 20 or something
like 20 or something
and see if it still solves.
and see if it still solves.
I think that should be I don't know.
Yeah. Because if you can increase if you
Yeah. Because if you can increase if you
can't increase the throughput easily by
can't increase the throughput easily by
increasing the number of ends
increasing the number of ends
at least we can increase the throughput
at least we can increase the throughput
by increasing the M speed
by increasing the M speed
and then the question will just be how
and then the question will just be how
much does the uh the simulation fidelity
much does the uh the simulation fidelity
hurt you?
Some robotics people tell me it matters
Some robotics people tell me it matters
a lot. Um,
a lot. Um,
let's just say I don't believe them.
We will see. But for now, I don't
We will see. But for now, I don't
believe them.
believe them.
We'll see if Puffer can do it.
All
right. So, 11.5ish mil and 4 minutes. 4
right. So, 11.5ish mil and 4 minutes. 4
minutes to train a policy. I don't know
minutes to train a policy. I don't know
about you, but four minutes, that's way
about you, but four minutes, that's way
too long.
What happens if I cut this to uh to 20?
What happens if I cut this to uh to 20?
What happens
according to stone? It should just get
according to stone? It should just get
five times faster.
They're
Hello. This might start to sound dumb,
Hello. This might start to sound dumb,
but I saw
but I saw
you started your PhD in 2019 and saw
you started your PhD in 2019 and saw
some words from your GitHub. People used
some words from your GitHub. People used
the word agents like they do now, or is
the word agents like they do now, or is
that a buzz word? Yeah. So, here's the
that a buzz word? Yeah. So, here's the
thing. Uh, agent was always an RL term
thing. Uh, agent was always an RL term
and then some dumb LLM people came along
and then some dumb LLM people came along
and decided that was their word now. So
and decided that was their word now. So
we still talk about agents as our models
we still talk about agents as our models
that interact with the environment. We
that interact with the environment. We
train them uh through interaction. They
train them uh through interaction. They
are interaction models. They're agents,
are interaction models. They're agents,
right? Apparently now LM's run in a for
right? Apparently now LM's run in a for
loop or agents or whatever, but we still
loop or agents or whatever, but we still
use the word the way that we always did.
Got that error when I try to switch.
Got that error when I try to switch.
Sim freak too low. Simulator becomes
Sim freak too low. Simulator becomes
inaccurate. It might have ns.
inaccurate. It might have ns.
Dang.
control freak for higher fake FPS.
control freak for higher fake FPS.
Really want higher fake FPS though.
Yeah.
Yeah.
So, yeah. No, agent is a real RL word.
So, yeah. No, agent is a real RL word.
It just doesn't mean the thing that the
It just doesn't mean the thing that the
LLM people think it means.
Okay, this is 80K. Let's see if this is
Okay, this is 80K. Let's see if this is
stable.
uses it. Yeah, just ignore the SF tech
uses it. Yeah, just ignore the SF tech
bros. All I can say there are people
bros. All I can say there are people
actually building legitimate stuff. You
actually building legitimate stuff. You
just have to find them.
Like go ahead and download Puffer Lib
Like go ahead and download Puffer Lib
and see for So,
Okay. So, so far,
Okay. So, so far,
uh, this seems fine.
uh, this seems fine.
We're going to see how much like how
We're going to see how much like how
ridiculously low we can crank the
ridiculously low we can crank the
fidelity.
Okay.
So if this converges then it seems like
So if this converges then it seems like
we can just get
we can just get
whatever that is plus 50% for free.
Not fast enough for my liking yet
Not fast enough for my liking yet
though.
Okay. 12 mil solve. Pretty much
Okay. 12 mil solve. Pretty much
identical curves. Yeah. Test or little
identical curves. Yeah. Test or little
lower. It doesn't matter. Same same
lower. It doesn't matter. Same same
solve curve. Yeah.
solve curve. Yeah.
Hey BDF, we're in the middle of solving
Hey BDF, we're in the middle of solving
robotics.
What happens if I bump control freak up?
What happens if I bump control freak up?
Stone says this is higher fake FPS.
Stone says this is higher fake FPS.
So, we'll see if this actually helps
So, we'll see if this actually helps
learning or not.
Okay,
higher fake FPS. I'm down with this.
higher fake FPS. I'm down with this.
Let's see what it does to the learn
Let's see what it does to the learn
curve,
curve,
whether the data is actually fake or
whether the data is actually fake or
not.
This will probably change the learning
This will probably change the learning
dynamics quite a bit. So, I will not be
dynamics quite a bit. So, I will not be
surprised if this does not help us. We
surprised if this does not help us. We
will see. What are you trying now? I'm
will see. What are you trying now? I'm
trying to make robotics really, really
trying to make robotics really, really
fast while still being stable. I'm
fast while still being stable. I'm
messing with their simulation parameters
messing with their simulation parameters
and seeing if we can still solve
Definitely a gap here.
If it actually does anything.
This is kind of the same as the frame
This is kind of the same as the frame
skip idea.
Yeah, fake FPS confirmed. Basically just
Yeah, fake FPS confirmed. Basically just
chips the curve where it like stretches
chips the curve where it like stretches
the curve.
Okay. So, if that doesn't work, let's
Okay. So, if that doesn't work, let's
let's try to go back to
let's try to go back to
We want this at 20, man.
We want this at 20, man.
saying this isn't stable.
Okay. So
observations probably have ns
Hey, Joseph. What have you been up to
Hey, Joseph. What have you been up to
lately? How's it going? Uh, we are
lately? How's it going? Uh, we are
currently attempting to fix robotics.
currently attempting to fix robotics.
I've got Manny skills set up. We have
I've got Manny skills set up. We have
training. It's decent. Uh, we're trying
training. It's decent. Uh, we're trying
to optimize it to go very, very fast, as
to optimize it to go very, very fast, as
is the tendency with Puffer.
is the tendency with Puffer.
So, I'm currently doing a combination of
So, I'm currently doing a combination of
tuning hyperparams,
tuning hyperparams,
uh, messing with the simulator
uh, messing with the simulator
configuration to see if we can get away
configuration to see if we can get away
with lower fidelity, generally seeing
with lower fidelity, generally seeing
how much speed we can get out of this
how much speed we can get out of this
thing.
Excuse
me.
I'm here for about another hour today.
Previous topics of this stream have
Previous topics of this stream have
included earlier in the day large scale
included earlier in the day large scale
battle sim and quantum mechanics.
battle sim and quantum mechanics.
Which simulator is this? This is this is
Which simulator is this? This is this is
Manny scale specifically. We're just
Manny scale specifically. We're just
using P cube for now as a a simple task
using P cube for now as a a simple task
to test with quickly, but our goal is
to test with quickly, but our goal is
going to be to solve their hardest task
going to be to solve their hardest task
with Puffer.
with Puffer.
And if we do a good job, who knows?
And if we do a good job, who knows?
Maybe all the roboticists will come over
Maybe all the roboticists will come over
and start using puffer lib.
Okay. So, we got nams and hidden
how you convert their sim to puffer
how you convert their sim to puffer
ends.
ends.
A little tiny wrapper.
A little tiny wrapper.
I mean, they already have a vector
I mean, they already have a vector
format. Puffer M's a vector format. It's
format. Puffer M's a vector format. It's
like kind of trivial.
So, they're just using our trainer, not
So, they're just using our trainer, not
really our sim stack, but that's fine.
really our sim stack, but that's fine.
Our trainer is pretty good on its own,
Our trainer is pretty good on its own,
right?
Don't wear ns are getting into
N to numb.
See what that does.
Wait, why is the hidden float 16?
I just noticed that.
Are they doing float 16 by default for
Are they doing float 16 by default for
some reason?
How the heck are we getting float 16?
I did not enable AM or anything.
There might be a bug with the I could
There might be a bug with the I could
see there being a weird bug.
Okay. So, this is the end.
That's super weird.
This is uh lipstick.
Decode actions is in slow 16 somehow.
Decode actions is in slow 16 somehow.
That's bizarre.
Is it specified as float 16?
Nope. Float 32.
Nope. Float 32.
This a me problem.
This a me problem.
I messed this up somehow.
Second, I had multiple continuous
Second, I had multiple continuous
actions. I had this bug.
actions. I had this bug.
Interesting.
Interesting.
So, Spencer, I'm seeing stuff in float
So, Spencer, I'm seeing stuff in float
16,
16,
which should not be happening.
which should not be happening.
Loss of precision can definitely cause
Loss of precision can definitely cause
that. If you're if there's like backward
that. If you're if there's like backward
pass ops happening and float 16, things
pass ops happening and float 16, things
can definitely get screwed up.
can definitely get screwed up.
It's a very weird issue.
Yeah, somehow hidden got puted into
Yeah, somehow hidden got puted into
float 16.
Yeah. So they got into the mean tensor
Yeah. So they got into the mean tensor
or the hidden tensor.
code observations is somehow
it a dictionary
maybe opposite a dictionary
maybe opposite a dictionary
I think it
even going to catch it? Not going to
even going to catch it? Not going to
catch it.
I did this backwards. Is this supposed
I did this backwards. Is this supposed
to be float
Uh, this is weird.
We need to catch this earlier.
Yeah, I'm somehow doing this crap.
Yeah, I'm somehow doing this crap.
How that makes any sense.
LSTM changing
LSTM changing
my uh DT type.
What?
Why the hell is that just doing this?
You think it's the torch zeros thing we
You think it's the torch zeros thing we
set where
the precision is set to float 32 here as
the precision is set to float 32 here as
well.
Eval,
Eval,
this is in training.
this is in training.
You mean um
You mean um
Yeah, this happens in training, man.
Yeah, this happens in training, man.
This literally gets none for the LSTM
This literally gets none for the LSTM
state as input.
See what happens.
How should I design my ends? As I said,
How should I design my ends? As I said,
real life this is continuous
and nothing in the real world is like
and nothing in the real world is like
actually modeled as a continuous process
actually modeled as a continuous process
almost.
almost.
I have fat right
on production.
Yeah, you would just Well, I don't know
Yeah, you would just Well, I don't know
what the actions are because if you're
what the actions are because if you're
like there has to be something you're
like there has to be something you're
interacting with here, right?
interacting with here, right?
A CSV is not a simulation. A CSV is a
A CSV is not a simulation. A CSV is a
data set.
Eight and six different actions.
If it's a day, then presumably if the
If it's a day, then presumably if the
actions influence the results of the
actions influence the results of the
next day, then yeah, each row is a day.
next day, then yeah, each row is a day.
But I don't know how you if you have
But I don't know how you if you have
fixed data for the next step, right? I
fixed data for the next step, right? I
don't know how you have an interactive
don't know how you have an interactive
process. This
every day. Multi second.
Are you like trying to tra build a
Are you like trying to tra build a
trading agent or something?
Yeah, the issue that you're going to run
Yeah, the issue that you're going to run
into there, right?
into there, right?
You'd have to predict deltas or
You'd have to predict deltas or
something. HFT,
something. HFT,
a good way to lose a lot of money is not
a good way to lose a lot of money is not
understanding reinforcement learning and
understanding reinforcement learning and
trying to throw it on HFT. I'm just
trying to throw it on HFT. I'm just
going to warn you. Um,
the problem you're also going to run
the problem you're also going to run
into there is that your data set is not
into there is that your data set is not
an environment. It's a fixed static
an environment. It's a fixed static
archive. Whereas reinforcement learning
archive. Whereas reinforcement learning
is meant to be trained in an interactive
is meant to be trained in an interactive
context.
context.
Um,
you have to reformulate some things a
you have to reformulate some things a
little bit.
You'd basically be trying to like the
You'd basically be trying to like the
actions would be like predict delta to
actions would be like predict delta to
next step or something. But then again,
next step or something. But then again,
you're not benefiting from interaction
you're not benefiting from interaction
at all. Then you have to ask why you're
at all. Then you have to ask why you're
not just training a sequence model.
this a non-stationary
this a non-stationary
it's not an environment at all the real
it's not an environment at all the real
markets an environment static archive a
markets an environment static archive a
CSV as a data That
Right. But like
You'd have to have the sim would have to
You'd have to have the sim would have to
actually be
actually be
the actions would be trades or
the actions would be trades or
something. You'd have to actually sim
something. You'd have to actually sim
trades.
Yeah, you're able to see it, but you
Yeah, you're able to see it, but you
don't have a sim of it. So, unless
don't have a sim of it. So, unless
you're training it on the real
you're training it on the real
environment, which you're not, right?
environment, which you're not, right?
There's an issue
the sim.
Okay. So these observations are like
Okay. So these observations are like
obscene.
The question is whether you're trying to
The question is whether you're trying to
model the influence of your own actions
model the influence of your own actions
or not.
If you're not, then you're way better
If you're not, then you're way better
off just with a sequence model. It's not
off just with a sequence model. It's not
an RL problem.
an RL problem.
If you are, then you need to know what
If you are, then you need to know what
you're doing
you're doing
because it's a lot harder.
Oh yeah, these OBS are not normalized
Oh yeah, these OBS are not normalized
for are they?
Okay. So, we need to do something here.
How hard is it?
Well, essentially you would have to try
Well, essentially you would have to try
to actually build a sim of the market in
to actually build a sim of the market in
order to train it. Then that gets you
order to train it. Then that gets you
unlimited training data, but your SIM
unlimited training data, but your SIM
has to be accurate. You didn't both know
has to be accurate. You didn't both know
how to build a SIM reasonably, and you'd
how to build a SIM reasonably, and you'd
need good knowledge of the market
need good knowledge of the market
dynamics. And you'd have to hope that
dynamics. And you'd have to hope that
this thing even makes any sense. I've
this thing even makes any sense. I've
done a little bit of work in this space.
done a little bit of work in this space.
There are some details.
I you just initially you just build a
I you just initially you just build a
sim that would like try to map and to be
sim that would like try to map and to be
fair there's there's something in that
fair there's there's something in that
space that's kind of similar that we
space that's kind of similar that we
might be able to open source. Um
but yeah, you just I think you just try
but yeah, you just I think you just try
to like predict deltas initially
where you basically you try to what you
where you basically you try to what you
do is you'd assume that the you assume
do is you'd assume that the you assume
you don't move the market and then your
you don't move the market and then your
actions are what to buy, what to sell.
actions are what to buy, what to sell.
I'm telling you though, you're going to
I'm telling you though, you're going to
lose a ton of money if you actually just
lose a ton of money if you actually just
like try to throw this on the real
like try to throw this on the real
market. Hodge podge.
Okay, let's see if this thing still
Okay, let's see if this thing still
trains. I didn't realize that the ops
trains. I didn't realize that the ops
were so poorly normalized.
were so poorly normalized.
Demo.
Demo.
Well, ideally, yes.
How does this not make a huge
How does this not make a huge
difference? Like immediately.
Delta.
This is where things stop making sense,
This is where things stop making sense,
right?
right?
Cuz it's like, you know what the price
Cuz it's like, you know what the price
is now. So you know what the price is on
is now. So you know what the price is on
the next step from the data. So you like
the next step from the data. So you like
technically the best action is to just
technically the best action is to just
buy as much as possible of the thing
buy as much as possible of the thing
that you think is going to go up the
that you think is going to go up the
most.
That's the delta.
Is this thing seriously not trained? Now
I normalize the observations.
I might have to reweep it. Honestly,
Plasma, how's it going?
did lose any money?
No, I didn't throw it on the real
No, I didn't throw it on the real
market. I just made a sim.
I literally don't even bother looking at
I literally don't even bother looking at
my stocks.
my stocks.
I just have like I just have some tech
I just have like I just have some tech
stocks and I don't look at them.
Okay. So, um,
Okay. So, um,
we didn't solve this end, but we figured
we didn't solve this end, but we figured
out something very important here
out something very important here
that their obs magnitudes are crazy.
Index funds. I don't just do index
Index funds. I don't just do index
funds. I have tech stocks.
funds. I have tech stocks.
Yeah.
Uh I also know some people I think I
Uh I also know some people I think I
probably am not allowed to do anything
probably am not allowed to do anything
else adjacent under under that
else adjacent under under that
agreement. So,
like the vast majority of the people
like the vast majority of the people
trying to throw RL on stuff just aren't
trying to throw RL on stuff just aren't
going to know what they're doing enough
going to know what they're doing enough
or things like
You do about this man?
Do I just have to like guess
Do I just have to like guess
a different learning rate or something?
a different learning rate or something?
That seems really silly.
Why don't I just reweep this thing?
Hang on.
Hang on.
Maybe maybe there's like a clipping
Maybe maybe there's like a clipping
thing
thing
going on here
and know how they are doing. I don't
and know how they are doing. I don't
have right technology.
Yeah, like I said, I have some adjacent
Yeah, like I said, I have some adjacent
stuff in this space. I probably can't do
stuff in this space. I probably can't do
like another thing in this space.
like another thing in this space.
Um,
Um,
you're more than welcome though to try
you're more than welcome though to try
to set this up as a pop if you want.
to set this up as a pop if you want.
Just be careful.
Good way to lose money.
I'd have to double check. I think
I'd have to double check. I think
generally though the way most of the
generally though the way most of the
things do is I don't I don't do like
things do is I don't I don't do like
simultaneous things. I don't do like
simultaneous things. I don't do like
things in um
like if I have like a if I have like a
like if I have like a if I have like a
puffer thing formally with a business in
puffer thing formally with a business in
one like very specific area, I'm not
one like very specific area, I'm not
going to do something that's like very
going to do something that's like very
very close to it elsewhere, right?
I'd have to double check specifics, but
I'd have to double check specifics, but
that's generally what we do just by
that's generally what we do just by
policy.
I will solve.
I mean, I think ultimately it comes down
I mean, I think ultimately it comes down
to
to
it comes down to you just need to make a
it comes down to you just need to make a
really good sim of the market, which is
really good sim of the market, which is
very difficult, right?
Probably difficult regardless of what
Probably difficult regardless of what
data you have.
But this does
not have most of does lose money though.
Okay, so Stone says the solvers in the
Okay, so Stone says the solvers in the
physics sim are trying to optimally
physics sim are trying to optimally
figure out how the robot moves and
figure out how the robot moves and
objects collide at a very high DT low
objects collide at a very high DT low
sim frequency
sim frequency
only so many solver iterations. is
only so many solver iterations. is
likely not converging.
This looks substantially more stable
This looks substantially more stable
than before.
than before.
Like learning
Maybe this will just be enough. We'll
Maybe this will just be enough. We'll
see.
Yeah. So, this is a stable solve.
Why you laughing?
cuz I'm trying to figure out what the
cuz I'm trying to figure out what the
hell this is. Like the fact that they
hell this is. Like the fact that they
return you giant observations. I'm
return you giant observations. I'm
asking Stone if like you can just do
asking Stone if like you can just do
forward oiler on this thing.
I have a DM with Stone where I'm asking
I have a DM with Stone where I'm asking
him stupid
him stupid
I'm like, "Hey, what happens if you just
I'm like, "Hey, what happens if you just
use forward oiler on this thing? What if
use forward oiler on this thing? What if
your robotic sim is just x= x + bx * dt?
you use gridl like matrix on observ you
you use gridl like matrix on observ you
can do that
I'm going to see if this solves anything
real fast
I'm messing with the uh I'm messing with
I'm messing with the uh I'm messing with
the simulation fidelity. And apparently,
the simulation fidelity. And apparently,
according to Stone, I'm doing like dumb
according to Stone, I'm doing like dumb
that nobody does in robotics, which
that nobody does in robotics, which
is precisely the way I like things.
suggestion
for market
like matrix.
You can do that technically. Yeah,
You can do that technically. Yeah,
I don't know. People do like comms over
I don't know. People do like comms over
old temporal data if you really have to
old temporal data if you really have to
batch a bunch of it into one
And I got to run for dinner in a few
And I got to run for dinner in a few
minutes as well.
High frequency trading. Yes, I know.
High frequency trading. Yes, I know.
I know what that is.
I do this fast.
The reason I think that's hard, I'll
The reason I think that's hard, I'll
give you this. It's because typically
give you this. It's because typically
you want to have a decent simulator for
you want to have a decent simulator for
the thing that you're trying to mess
the thing that you're trying to mess
with. And uh it's very difficult to
with. And uh it's very difficult to
build a good one of those for the
build a good one of those for the
market. Why?
I'm on Discord.
This isn't you. I don't Oh, one minute
This isn't you. I don't Oh, one minute
ago.
Not it.
Not it.
Hello.
Passing physics step.
Number of physics steps that run
Number of physics steps that run
after each action.
Okay. So, it's just it's hard for it to
Okay. So, it's just it's hard for it to
converge.
converge.
Okay.
Like this was faster, wasn't it?
Yeah, I'm not going to be able to tell
Yeah, I'm not going to be able to tell
you. Like, I'm not going to be able to
you. Like, I'm not going to be able to
answer that, man.
Like, obviously.
Physics
is known to take lesser steps. The DT is
is known to take lesser steps. The DT is
smaller. Okay.
So
like Yes.
Uh I did fix the nans thing Spencer just
Uh I did fix the nans thing Spencer just
by uh clamping the observations and nans
by uh clamping the observations and nans
and numbing them but that doesn't make
and numbing them but that doesn't make
it it trained to like 50% in the same
it it trained to like 50% in the same
number of steps.
So, I think Stone told me this should be
So, I think Stone told me this should be
this should be like theoretically the
this should be like theoretically the
fastest it could possibly go, right?
And I have to run for dinner in a
And I have to run for dinner in a
second. So, for the folks on YouTube,
second. So, for the folks on YouTube,
um, all open source work, we'll be back
um, all open source work, we'll be back
on Monday. Buffer.ai for all the things.
on Monday. Buffer.ai for all the things.
the repo to help me out for free. You
the repo to help me out for free. You
can join the discord to get involved
can join the discord to get involved
with this as well.
Uh help me.
Uh help me.
I obviously can't answer questions like
I obviously can't answer questions like
that, man. Answer general questions. I
that, man. Answer general questions. I
can't tell you like data source things.
can't tell you like data source things.
Um,
Um,
do you know why nans were being
do you know why nans were being
inserted? Yeah, Spencer. So, it's just
inserted? Yeah, Spencer. So, it's just
it's the physics and fidelity.
