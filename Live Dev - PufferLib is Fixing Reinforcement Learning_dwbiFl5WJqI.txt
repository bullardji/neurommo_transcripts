Kind: captions
Language: en
for a little bit here.
for a little bit here.
Um, got a meeting that should have
Um, got a meeting that should have
happened,
happened,
but I guess I'll uh it's gotten
but I guess I'll uh it's gotten
postponed a bit. So, I don't know how
postponed a bit. So, I don't know how
long I'm going to be live for right now,
long I'm going to be live for right now,
but I figured we'd at least see if we
but I figured we'd at least see if we
can get a short stream in for a bit of
can get a short stream in for a bit of
work. Hang on. Let me make sure this
work. Hang on. Let me make sure this
thing's working and then I'll talk about
thing's working and then I'll talk about
what I want to do. Yeah, this works.
what I want to do. Yeah, this works.
Cool. So uh I want to do
Cool. So uh I want to do
something kind of similar to phasic
something kind of similar to phasic
policy
policy
gradients. I have
maybe 50% confidence at best that this
maybe 50% confidence at best that this
is going to actually be useful, but um
is going to actually be useful, but um
we're kind of at a spot where it would
we're kind of at a spot where it would
be relatively easy to add.
be relatively easy to add.
So, I I sort of just want to do it and
see. That better not be Yeah. Okay,
see. That better not be Yeah. Okay,
we're
good. Something like this.
Oops.
little scattered
little scattered
today. Yesterday was like just cranking
today. Yesterday was like just cranking
cranking on work and I'm a little
cranking on work and I'm a little
scattered today. I had to catch up on
scattered today. I had to catch up on
meetings and stuff. Um, all right. So we
meetings and stuff. Um, all right. So we
get ppg epox
get ppg epox
here and then the only thing that we
here and then the only thing that we
have to really add to this
have to really add to this
uh to make this
uh to make this
work is this like extra
work is this like extra
phase after
phase after
training. You know, technically I think
training. You know, technically I think
that I can just
that I can just
do I just want to test something quick,
do I just want to test something quick,
right? Probably just copy paste a lot of
this. It's a little awkward.
It is a little awkward.
I guess we do just literally paste for
I guess we do just literally paste for
now. We just repaste
this and we'll just like delete
stuff. So all the freaking code
We'll like remove all the sections we
We'll like remove all the sections we
don't need at least and then we'll come
don't need at least and then we'll come
up with a cleaner way to do it if
um well we'll come up with a cleaner way
um well we'll come up with a cleaner way
to do it if it
works.
This
Let's do a little minimal version of
it. Does need
it. Does need
this. Doesn't really need
this. And we don't really have kale
this. And we don't really have kale
target.
This is the third person I've had asking
This is the third person I've had asking
me about hierarchical RL this
me about hierarchical RL this
week. I guess we will have to do
week. I guess we will have to do
something in that
area. I think we're just going to do the
area. I think we're just going to do the
simple thing though like fast slow LSTM.
simple thing though like fast slow LSTM.
That I actually think will work. That
That I actually think will work. That
should just be like free win.
implementation's a little tricky. I have
implementation's a little tricky. I have
to think about it.
So the only thing that's really
So the only thing that's really
different with
different with
the iterations here,
right, as you do this like K loss
And of course I now I get the right as
And of course I now I get the right as
soon as I start streaming I get meeting
soon as I start streaming I get meeting
call. Okay. Um let me see. I think I'm
call. Okay. Um let me see. I think I'm
going to have to just go take this and
going to have to just go take this and
this will be just like a quick 10-minute
this will be just like a quick 10-minute
thing and then I'll come back and get to
this. Let me make sure.
Okay. No, they're going to they're at
Okay. No, they're going to they're at
lunch now. So, we we will keep
lunch now. So, we we will keep
streaming.
streaming.
Cool.
Cool.
Perfect. So, we will get uh to finish
Perfect. So, we will get uh to finish
this
This is kind of it, isn't
it? Oh, yeah. The one thing that we
it? Oh, yeah. The one thing that we
forgot here, the annoying bit,
forgot here, the annoying bit,
right? So, you have to do
You actually like need to do this thing
again. Maybe just this block.
You have to like recmp compute logits on
You have to like recmp compute logits on
everything in the data
set. I think how we would do that.
Oh, actually this is kind of easy, isn't
it? Yeah, this is kind of
easy. At least to do this as a hack is
easy. At least to do this as a hack is
kind of
easy. We just need to go through the
easy. We just need to go through the
full data set here. Uh, I wrote it in a
full data set here. Uh, I wrote it in a
way where it's a little awkward to do
way where it's a little awkward to do
that, but I can just
do something like this.
something like
something like
this. And then what we do
this. And then what we do
is experience
dot log props of
dot log props of
index. It's set to new log
index. It's set to new log
props. I think that's the only thing we
props. I think that's the only thing we
need, right?
the
the
heck. Hang
on. I assume that's just a battery
on. I assume that's just a battery
test. That's weird.
Somebody's trying to get my
attention. No, just a battery test, I
guess. All right. So, um,
I think this is just
it. Forgot state. I'm sorry.
state.
Hang on. I think I screwed something up
Hang on. I think I screwed something up
here.
Yeah, I totally screwed this up.
Um, this can be and samples and this
Um, this can be and samples and this
is data experience.
We don't even need this.
deal with one message.
This is still totally screwed, right?
Pretty much all I'm trying to do here is
Pretty much all I'm trying to do here is
I'm just trying to hack this super quick
I'm just trying to hack this super quick
so that we can do regular PO EPO eval
so that we can do regular PO EPO eval
the entire data set or the entire batch
the entire data set or the entire batch
so that we can update the log props and
so that we can update the log props and
then run additional value function
then run additional value function
training. That's all I'm trying to
do. Yeah. Okay. So, this seems like this
do. Yeah. Okay. So, this seems like this
is
is
fine. Why is log props like
fine. Why is log props like
that? Wait, why is
Oh
Oh
shoot. You need log. It's not log prop,
right? So what you need is
It's something like this experience
It's something like this experience
rows and
then like
that. See if that runs.
It doesn't matter if this is a hack. I
It doesn't matter if this is a hack. I
just need to like have something that I
just need to like have something that I
can test this with for now. And then I
can test this with for now. And then I
like if this is actually good, then I
like if this is actually good, then I
will think about how I can do this
will think about how I can do this
without reading a ton of code.
Okay, so that actually
Okay, so that actually
runs. Um, we need to
now so this needs to get
now so this needs to get
normed. Where's the KL
normed. Where's the KL
here? Yeah. Okay. So, this is this can't
here? Yeah. Okay. So, this is this can't
be bash.log props. So, ppg log props
be bash.log props. So, ppg log props
equals all
equals all
logs
logs
idx. Then this has got to be this is not
idx. Then this has got to be this is not
new log
new log
prop. This is
logs logs.
Something like this, I
Something like this, I
think. We'll see how this does.
It's probably better to
have first of
all
all
patch and then
I actually don't know how this is going
I actually don't know how this is going
to work back. We'll
see. Okay. Is this obviously wrong or
not? Seems pretty wrong, right?
Okay. So, that doesn't work, right?
Okay. So, this doesn't make sense
Okay. So, this doesn't make sense
because like
somehow we've somehow like broken
this. We didn't mess up the
this. We didn't mess up the
scheduleuler.
We just comment
We just comment
this whole block. It should work
right. Yeah. So if you just comment this
right. Yeah. So if you just comment this
lock out. It works. So, we're clearly
lock out. It works. So, we're clearly
just breaking something
just breaking something
because this shouldn't even be
because this shouldn't even be
optimizing anything with the loss of
optimizing anything with the loss of
zero. So, like some variables getting
zero. So, like some variables getting
updated that shouldn't
be. Where's this lined up?
That's lined up
correctly. Welcome YouTube folks. So
correctly. Welcome YouTube folks. So
what this is
what this is
here uh I am currently attempting to
do some weird hodge podgeic policy
do some weird hodge podgeic policy
gradients.
This thing separates policy learning
This thing separates policy learning
from value learning. It's kind of slow
from value learning. It's kind of slow
though. So I was coming up with a
though. So I was coming up with a
version of this that lets you just do PO
version of this that lets you just do PO
for one epoch because they say that you
for one epoch because they say that you
don't really benefit beyond one epoch
don't really benefit beyond one epoch
except for training the value function
except for training the value function
and that let you do more epochs on the
and that let you do more epochs on the
value function using the ppg style
value function using the ppg style
loss. So that's what I'm currently
loss. So that's what I'm currently
trying. I have no idea if this works. I
trying. I have no idea if this works. I
do know that the current version uh it
do know that the current version uh it
should work better than this. So I'm
should work better than this. So I'm
somehow breaking it here. So goal here
somehow breaking it here. So goal here
is just to see if we get anything out of
is just to see if we get anything out of
this. This is kind of like a invest a
this. This is kind of like a invest a
few hours, see if anything works kind of
few hours, see if anything works kind of
a
gig. If it did work, best case result
gig. If it did work, best case result
would be that uh this lets us get more
would be that uh this lets us get more
sample efficient learning when we want
sample efficient learning when we want
it and then have exactly the same
it and then have exactly the same
behavior and per as po uh when we don't
behavior and per as po uh when we don't
want to crank up compute.
Let me see what variables would be
Let me see what variables would be
getting overwritten in
place. Maybe that's
place. Maybe that's
This should get zeroed anyways
though. It should be getting zeroed
though. It should be getting zeroed
anyways. Yeah.
I don't know why we do
this. It should be up
this. It should be up
top. What language do you use? Just
Abuntu. We tried running Debian on the
Abuntu. We tried running Debian on the
servers was more of a pain in the ass
servers was more of a pain in the ass
than
abundu. I ran like a crazy custom arch
abundu. I ran like a crazy custom arch
setup during my cringe undergrad
setup during my cringe undergrad
years. Uh now we just just a bunt
years. Uh now we just just a bunt
two. It honestly really doesn't matter
two. It honestly really doesn't matter
that much cuz like all the dev is
that much cuz like all the dev is
containerized
containerized
anyways. like this. I'm editing this
anyways. like this. I'm editing this
locally on this machine, but inside of a
locally on this machine, but inside of a
container that's identical to the
container that's identical to the
container that'll run on our servers.
So like host OS doesn't really matter
So like host OS doesn't really matter
that much except for it being a pain in
that much except for it being a pain in
the ass to get drivers correct on some
the ass to get drivers correct on some
of them.
Okay, let me just sanity a thing because
like Yeah, let me just sanity a thing.
Okay, this does work,
right? So, what the heck
right? So, what the heck
is there? Shouldn't even be a loss
is there? Shouldn't even be a loss
here. It's zero, right?
Oh
man. That'll do
it. Wise lost man.
Does KL explode if um the distributions
Does KL explode if um the distributions
are
identical? Shouldn't, right?
identical? Shouldn't, right?
Hang
on. What app or program are you doing?
on. What app or program are you doing?
I'm here. New
I'm here. New
here. So, this is I work on
here. So, this is I work on
reinforcement learning dev full-time.
reinforcement learning dev full-time.
It's all at puffer.ai.
It's all at puffer.ai.
We do like a really high performance
We do like a really high performance
games and other types of simulators and
games and other types of simulators and
we train uh agents from scratch on them
we train uh agents from scratch on them
and we work on all the tech behind that.
and we work on all the tech behind that.
So this is like superhuman agent running
So this is like superhuman agent running
playing
playing
enduro. We have like simple games like
enduro. We have like simple games like
this and like uh breakout and stuff. And
this and like uh breakout and stuff. And
then we have more complicated stuff like
then we have more complicated stuff like
uh this miniature
uh this miniature
MMO is really big.
So stream is a mix
So stream is a mix
of doing math on the various different
of doing math on the various different
algorithms that go into this uh
algorithms that go into this uh
low-level engineering. All the M's are
low-level engineering. All the M's are
in C. We have some CUDA extensions,
in C. We have some CUDA extensions,
stuff like that. And yeah, just
stuff like that. And yeah, just
generally all the stuff that goes into
generally all the stuff that goes into
making RL work.
Oh, hang on. Can you not do this? I
Oh, hang on. Can you not do this? I
might just be using this loss
might just be using this loss
incorrectly, right? Does this
incorrectly, right? Does this
expect the output of a
expect the output of a
model? What are you supposed to call
model? What are you supposed to call
this thing
this thing
with log softmax? I see. So you're
with log softmax? I see. So you're
supposed to call log softmax followed by
k. Why do they Why is the input log
k. Why do they Why is the input log
softmax and the target is
softmax? Log target.
softmax? Log target.
Okay.
Okay.
So yeah, I just messed up the usage of
So yeah, I just messed up the usage of
this. So the whole thing is cracking
this. So the whole thing is cracking
because I get nan losses.
It isn't it? It's input, target. Yeah,
It isn't it? It's input, target. Yeah,
that's
correct. It's
true. Let's see what this does.
cannot
access. Okay, so now we actually get
access. Okay, so now we actually get
something.
They shouldn't these be the
same? Hang on. Something's wrong here
same? Hang on. Something's wrong here
because I'm pretty sure these should be
because I'm pretty sure these should be
the same.
Wait, this is
bash.index zero.
bash.index zero.
Perfect. Now, this should no longer
Perfect. Now, this should no longer
break everything. If I just run
break everything. If I just run
this and what are we getting spammed on
this and what are we getting spammed on
here?
Nothing. Okay. So, this is still somehow
exploding. Maybe we're just screwing
exploding. Maybe we're just screwing
over the optimizer
somehow. It is technically shared. What
somehow. It is technically shared. What
happens if we actually run with
this? Okay, now it actually runs
this? Okay, now it actually runs
reasonably. So, we were just screwing
reasonably. So, we were just screwing
over the optimizer somehow.
get the graphs for this going. I'm going
get the graphs for this going. I'm going
to use a restroom. I'll be right back.
to use a restroom. I'll be right back.
And Whoops. Get token first. Uh and then
And Whoops. Get token first. Uh and then
we will actually start running some
we will actually start running some
experiments on this and see if we can
experiments on this and see if we can
ever get this to
ever get this to
outperform the uh the
outperform the uh the
current PPO
current PPO
implementation. Let me grab the graphs
implementation. Let me grab the graphs
for this.
Oh yeah, also we've got soda on neural
Oh yeah, also we've got soda on neural
MMO so far with uh it's just like barely
MMO so far with uh it's just like barely
better, but it is better with the new
better, but it is better with the new
advantage
advantage
filtering. Right, new graphs go
filtering. Right, new graphs go
here. Back in a minute.
Let me
Let me
pull Slack channel over to there. If I
pull Slack channel over to there. If I
don't show that this over
don't show that this over
here and yeah, we're good to go for dev.
here and yeah, we're good to go for dev.
Uh, so this doesn't do much worse, but
Uh, so this doesn't do much worse, but
it does do
it does do
worse,
right? Making sure I didn't screw
right? Making sure I didn't screw
anything up here because I was I was
anything up here because I was I was
messing around with um some weird
messing around with um some weird
stuff.
Okay, then the next question would
Okay, then the next question would
be if we do this less often.
There's also supposed to be a
There's also supposed to be a
coefficient on the cloning loss. Hang
on. They have a coefficient
on. They have a coefficient
here. Where's the cloning
here. Where's the cloning
loss? B
loss? B
clone. Let me make sure that it's not
clone. Let me make sure that it's not
like a super low
like a super low
hyper. I should have a table somewhere.
one.
Okay. They want to do this every six on
Okay. They want to do this every six on
average.
average.
So, every so often they
do. Six
epochs.
epochs.
16 mini batches
16 mini batches
per ox.
I mean, I think one thing we can do is
I mean, I think one thing we can do is
just
just
take this entire
block. And we only do this
block. And we only do this
10% of the time or
whatever. That's like close to what
whatever. That's like close to what
they're doing.
The goal here is that you should just be
The goal here is that you should just be
able to like once in a while make sure
able to like once in a while make sure
that you're training the value function
that you're training the value function
enough
Can you please open Dairy Web? I have no
Can you please open Dairy Web? I have no
idea what that
is. Oh, holy. That actually does
is. Oh, holy. That actually does
something. Wait, that's
something. Wait, that's
actually It's better. At least for a
actually It's better. At least for a
little bit.
little bit.
This is not going to be the best to test
This is not going to be the best to test
on. We could probably test this on like
on. We could probably test this on like
something a bit
harder. That's still pretty
decent. Can you please open dark web?
No, wrong stream, buddy. This is
No, wrong stream, buddy. This is
reinforcement learning,
Dev.
Dev.
Welcome. You just
Let me see if I match a little bit
Let me see if I match a little bit
closer to their hypers. If anything
closer to their hypers. If anything
amazing happens all of a
sudden. Where's the go?
So do this n pi
times. So there's n pi and then e ox is
times. So there's n pi and then e ox is
what I need to check,
right?
right?
32 and then this is
32 and then this is
six. So okay, that's actually pretty
six. So okay, that's actually pretty
different.
We set this to six,
We set this to six,
right? Is there
right? Is there
um there is a data epoch,
um there is a data epoch,
right? Hey
right? Hey
Ryan, we just do if data
Ryan, we just do if data
epoch percent
epoch percent
32 and do this, right?
That's pretty close to
That's pretty close to
PPG. Yeah, Ryan, I'm just trying to see
PPG. Yeah, Ryan, I'm just trying to see
if this does anything real quick. It's
if this does anything real quick. It's
like a total mess to implement this
like a total mess to implement this
thing. Um, but I just want to see real
thing. Um, but I just want to see real
quick if this does like if there's signs
quick if this does like if there's signs
of life
here. Is that good?
the way I have this implemented by the
the way I have this implemented by the
way it would be very very little uh per
And does that just
match? Did you add in the A stuff? Yeah,
match? Did you add in the A stuff? Yeah,
I got to test this now. on something
I got to test this now. on something
like a little
like a little
harder. I don't think what ends I want
harder. I don't think what ends I want
to use. I could do grid. Grid kind of
to use. I could do grid. Grid kind of
has a lot of variability,
but would grid be an end where you would
but would grid be an end where you would
think the value loss would be get would
think the value loss would be get would
get
get
stale?
stale?
Maybe. Let me see if I can do it on
Maybe. Let me see if I can do it on
grid.
Okay. Apparently it doesn't like
Okay. Apparently it doesn't like
that. We have a whole bunch of stuff to
that. We have a whole bunch of stuff to
fix with
fix with
um with some of the end findings in the
um with some of the end findings in the
latest. Yeah, totally screwed it
latest. Yeah, totally screwed it
here. We have some stuff to fix with the
here. We have some stuff to fix with the
latest uh end bindings. All
latest uh end bindings. All
right. Okay. I don't know. Maybe I
right. Okay. I don't know. Maybe I
tested on Snake or something real quick.
tested on Snake or something real quick.
I think that one works.
need to add in the offset. Not a big
need to add in the offset. Not a big
deal.
deal.
Okay, let me let me run this and then
Okay, let me let me run this and then
I'll show you how I implemented it
I'll show you how I implemented it
because it's a little different from
because it's a little different from
what you're thinking
of. Okay. So, the way that I have this
of. Okay. So, the way that I have this
implemented
here, actually the going to be a mess.
here, actually the going to be a mess.
It's easier to just show you on the
algorithm. So, the way that they do this
algorithm. So, the way that they do this
for like their full
method, they
method, they
do lip. This is the PO policy objective
do lip. This is the PO policy objective
and then this is the value loss
and then this is the value loss
objective, right?
objective, right?
And then every so often, not very often,
And then every so often, not very often,
they distill the value function into the
they distill the value function into the
policy,
policy,
right? My lab's interested in starting
right? My lab's interested in starting
large DRL projects and also process
large DRL projects and also process
building cluster. Wonder if you had any
building cluster. Wonder if you had any
recommendations on GPUs. Yep, just our
recommendations on GPUs. Yep, just our
exact blog post here. Um, I don't get
exact blog post here. Um, I don't get
Intel chips though is the only thing.
Intel chips though is the only thing.
It's We've had so many freaking
It's We've had so many freaking
problems. uh puffer stack in the blog.
problems. uh puffer stack in the blog.
You just buy desktop
You just buy desktop
boxes. You don't care as much about
boxes. You don't care as much about
VRAM. You do care about having good
VRAM. You do care about having good
cores. So, the latest builds we have are
cores. So, the latest builds we have are
9950X, highest end AMD chip. And then
9950X, highest end AMD chip. And then
these are 4090s. We're buying 5090s
these are 4090s. We're buying 5090s
now. That's what we're doing. Yeah. So,
now. That's what we're doing. Yeah. So,
Ryan,
um so that's what they do. So what I was
um so that's what they do. So what I was
going to do instead is this part we just
going to do instead is this part we just
do however many epochs of PO. So this is
do however many epochs of PO. So this is
just
PO and then every like 32 epochs of PO
PO and then every like 32 epochs of PO
because that's what the frequency they
because that's what the frequency they
do this with is right. So every 32
do this with is right. So every 32
epochs of PO you just do an additional
epochs of PO you just do an additional
few epochs of uh value function training
few epochs of uh value function training
while using the policy cloning objective
while using the policy cloning objective
so that the base policy doesn't
change. Does that make sense?
I don't think we can get 40950 due to
I don't think we can get 40950 due to
Nvidia policy on incorporating them.
Nvidia policy on incorporating them.
Well, that's the thing. You don't build
Well, that's the thing. You don't build
them into a clust into cluster machines.
them into a clust into cluster machines.
You just buy individual
You just buy individual
desktops. If you're going to buy H00s
desktops. If you're going to buy H00s
for RL, you're just burning money. Like,
for RL, you're just burning money. Like,
if you're doing like standard DRL stuff
if you're doing like standard DRL stuff
and you're buying H00s, you're just
and you're buying H00s, you're just
throwing away 90% of your budget because
throwing away 90% of your budget because
they're not any faster. and they just
they're not any faster. and they just
cost 10x
more. You don't do separate value policy
more. You don't do separate value policy
epochs yet. We do right here. Right.
epochs yet. We do right here. Right.
This is the separate this is training
This is the separate this is training
the value function while using the
the value function while using the
distillation
loss. How much are these? Are these
loss. How much are these? Are these
things? Seven
grand. I don't know if this is remotely
grand. I don't know if this is remotely
accurate,
accurate,
but all the data center cards are like
but all the data center cards are like
for RL. You're just lighting money on
for RL. You're just lighting money on
fire. Like if you're going to buy those
fire. Like if you're going to buy those
cards, don't buy your own hardware.
cards, don't buy your own hardware.
There's no point. just rent
There's no point. just rent
it. If you're gonna like if you want to
it. If you're gonna like if you want to
do your own cluster like do so like this
do your own cluster like do so like this
is the way that you actually do it cost
is the way that you actually do it cost
effective because this is like 50 grand
effective because this is like 50 grand
worth of hardware that pays for itself
worth of hardware that pays for itself
in 3 months.
I'm not really seeing
I'm not really seeing
this. It doesn't hurt, but it doesn't
this. It doesn't hurt, but it doesn't
really help anything so far
really help anything so far
either to break out.
The value loss on these is also just
The value loss on these is also just
really
low. You know what we can
low. You know what we can
do? Can look at
Sounds pretty similar to the
Sounds pretty similar to the
original. Stop grad may matter. We don't
original. Stop grad may matter. We don't
want to do the stop grad because then
want to do the stop grad because then
it's no longer compatible with
bo. You don't think CPU
cores even for GPU? Not for stuff like
cores even for GPU? Not for stuff like
Craftex. But here's the thing, there
Craftex. But here's the thing, there
aren't that many MS like that. And like
aren't that many MS like that. And like
we're collabing with that lab. If you
we're collabing with that lab. If you
like Craftex is not a good way to write
like Craftex is not a good way to write
an environment. Like the guys that wrote
an environment. Like the guys that wrote
that are incredibly talented and I
that are incredibly talented and I
couldn't have written it that way. But
couldn't have written it that way. But
like I could have I can make that M 10
like I could have I can make that M 10
times faster with less than half of the
times faster with less than half of the
effort. If you just write it and save,
effort. If you just write it and save,
there's literally no point whatsoever to
there's literally no point whatsoever to
writing environments like that on the
GPU. My advisor wants to be able to do
GPU. My advisor wants to be able to do
large model
large model
fine-tuning. Well, that's no longer
fine-tuning. Well, that's no longer
RL.
RL.
Like that's now a different class of
Like that's now a different class of
problem,
right? That's the only difference for
right? That's the only difference for
the first part. Yeah. Ryan, hang on. Let
the first part. Yeah. Ryan, hang on. Let
me let me get rid of some of these
me let me get rid of some of these
runs. Why don't we just do
runs. Why don't we just do
new new
new new
baselines? Let's just do new baseline so
baselines? Let's just do new baseline so
that we're absolutely
that we're absolutely
sure we're correct here.
Yeah, my suggestion would be
Yeah, my suggestion would be
um if you want to do RL, but like the
um if you want to do RL, but like the
lab's also messing with big models
lab's also messing with big models
sometimes, would be get a few desktops
sometimes, would be get a few desktops
for RL and then do um if you need H00s
for RL and then do um if you need H00s
or something, just rent those. Don't
or something, just rent those. Don't
don't set up your own H00s. There's no
don't set up your own H00s. There's no
point.
The arbitrage is on like desktop class
The arbitrage is on like desktop class
machines. It's not on the server grade
machines. It's not on the server grade
hardware. Those are actually really
hardware. Those are actually really
cheap for what they are.
The uh the CPU cores, by the way, are
The uh the CPU cores, by the way, are
basically so that if you need to run
basically so that if you need to run
slower RLMs, you at least kind of can.
slower RLMs, you at least kind of can.
If you don't have those and you want to
If you don't have those and you want to
do anything outside of the really fast
do anything outside of the really fast
ends, you just can't. You're just
ends, you just can't. You're just
screwed. there's no way around it. You
screwed. there's no way around it. You
just like straight up
just like straight up
lose. So like stuff like the Pokemon
lose. So like stuff like the Pokemon
project that we did wouldn't be possible
project that we did wouldn't be possible
on um like we could rent a $100,000
on um like we could rent a $100,000
server and it would be the speed of one
server and it would be the speed of one
of our $5,000 boxes. Like we've timed
of our $5,000 boxes. Like we've timed
that.
It's kind of weird that they do like
It's kind of weird that they do like
this is really not that much extra value
this is really not that much extra value
function training,
right? I guess we could crank up EOS.
Yeah, it looks like it still keeps going
Yeah, it looks like it still keeps going
up. So, we might just crank
up. So, we might just crank
that. This does better at first and then
that. This does better at first and then
worse
after. It's really not that much extra
after. It's really not that much extra
value function training, right?
value function training, right?
What if we like crank this up to like
What if we like crank this up to like
32? What
32? What
happens? The value law could really
happens? The value law could really
drop, right?
But do you see why I'm doing it this
But do you see why I'm doing it this
way, Ryan? Like the idea is that you
way, Ryan? Like the idea is that you
just keep
just keep
PO and then just do some extra value
PO and then just do some extra value
function training if you want to crank
function training if you want to crank
up
up
compute because they say that it
compute because they say that it
actually like if you just crank up POE
actually like if you just crank up POE
epochs above three, you literally do
epochs above three, you literally do
worse most of the time.
Well, their base algorithm doesn't work
Well, their base algorithm doesn't work
by default because if you just change
by default because if you just change
the x-axis to wall clock time, they're
the x-axis to wall clock time, they're
slower. So, I could have just done no
slower. So, I could have just done no
more
samples. So, we're absolutely not doing
that. And like the uh the separate value
that. And like the uh the separate value
function as well. It's not like just 2x
function as well. It's not like just 2x
memory or whatever. It's a half the
memory or whatever. It's a half the
speed. It's like one half
speed. It's like one half
speed. So, that doesn't seem
speed. So, that doesn't seem
particularly smart to me
either. 9950X
either. 9950X
re Don't get AMD chips. I mean, uh,
re Don't get AMD chips. I mean, uh,
Intel, don't get Intel chips. Intel
Intel, don't get Intel chips. Intel
screwed us so badly.
Yeah. So, this is like a $700 processor
Yeah. So, this is like a $700 processor
that will just shred everything. Now, if
that will just shred everything. Now, if
you if you have really really CPU
you if you have really really CPU
intensive environments and you really
intensive environments and you really
want to build like a machine that can
want to build like a machine that can
handle that, then you consider thread
handle that, then you consider thread
rippers, but those are way pricier and
rippers, but those are way pricier and
the individual cores are usually
the individual cores are usually
slower. Is it actually worse on time
slower. Is it actually worse on time
efficiency? Is it not
similar? Well, if you have two separate
similar? Well, if you have two separate
networks, you double the forward pass
networks, you double the forward pass
cost,
cost,
right? Which then doubles the train time
right? Which then doubles the train time
as
well. Okay, now we do see this thing as
well. Okay, now we do see this thing as
being slightly lower for most of it,
being slightly lower for most of it,
right? The spike is
weird. Plus sample efficiency but speed.
weird. Plus sample efficiency but speed.
You don't do plus sample efficiency but
You don't do plus sample efficiency but
speed because
speed because
like you don't want that as your base
like you don't want that as your base
case because if you have unlimited data,
case because if you have unlimited data,
you're just always happier chewing
you're just always happier chewing
through more data, right? So you like
through more data, right? So you like
you screw yourself on a big class of
you screw yourself on a big class of
problems if you do it that
problems if you do it that
way. Let me
try. What do you mean?
No. Here. So like if you make training
No. Here. So like if you make training
take twice as long, what's wrong with
take twice as long, what's wrong with
Intel CPU? They shipped two consecutive
Intel CPU? They shipped two consecutive
generations of broken
chips. No, my bad. It was one. Was it
chips. No, my bad. It was one. Was it
one or
one or
two? I think it was two. Either way, at
two? I think it was two. Either way, at
least one generation of chips that just
least one generation of chips that just
break after a few
break after a few
months. So, we literally had like it
months. So, we literally had like it
cost me like tens and tens of hours of
cost me like tens and tens of hours of
maintenance and like, you know, tons of
maintenance and like, you know, tons of
cluster downtime dealing with it. And
cluster downtime dealing with it. And
also, you have to have specific infra as
also, you have to have specific infra as
well because some of the cores are fast
well because some of the cores are fast
and some are slow. It's a pain in the
and some are slow. It's a pain in the
ass. Just get the just get the uh the
ass. Just get the just get the uh the
AMD chips.
AMD chips.
I'd always prefer method that runs at
I'd always prefer method that runs at
the same speed but fewer. It's not the
the same speed but fewer. It's not the
same speed though because when you have
same speed though because when you have
two separate networks
two separate networks
right in PO if you have a shared value
right in PO if you have a shared value
function like it's basically no extra
function like it's basically no extra
compute for the value head right if you
compute for the value head right if you
have two separate networks the torso is
have two separate networks the torso is
unshared. It's double the forward pass
unshared. It's double the forward pass
time and then you end up with double the
time and then you end up with double the
backward time as well in training. So
backward time as well in training. So
you just take a flat 2x cut to
you just take a flat 2x cut to
everything,
everything,
right? So if your sample efficiency like
right? So if your sample efficiency like
if you have a fast end, it doesn't
if you have a fast end, it doesn't
matter because you're still running at
matter because you're still running at
half the speed. So you're getting half
half the speed. So you're getting half
the data that PO would get uh in the
the data that PO would get uh in the
same time. So it literally has to be
same time. So it literally has to be
double the sample efficiency for having
double the sample efficiency for having
unshared value function for that to
unshared value function for that to
work.
And just unsharing definitely doesn't do
And just unsharing definitely doesn't do
that. Like maybe with the whole rest of
that. Like maybe with the whole rest of
ppg it does, but unclear, you know,
unclear. It is more sample efficient. It
unclear. It is more sample efficient. It
takes
takes
longer longer per sample.
I mean there's only so much sample
I mean there's only so much sample
efficiency you can get though, right?
efficiency you can get though, right?
Like some problems just need fresh
Like some problems just need fresh
data. Like you need to see the new stuff
data. Like you need to see the new stuff
in the end to learn it,
right? Okay, so this actually spiked the
right? Okay, so this actually spiked the
value loss up a ton.
Well, that's the thing. It's problem
Well, that's the thing. It's problem
dependent, right? And it like it's
dependent, right? And it like it's
problem
dependent, but you don't like you change
dependent, but you don't like you change
the base case. You kind of want to keep
the base case. You kind of want to keep
PO as the
PO as the
base to learn propg games. I mean, how
base to learn propg games. I mean, how
much do we trust that result, right?
They didn't control for wall clock at
all. Okay. So, this run is better.
If we do this, this is like the most we
If we do this, this is like the most we
could possibly
do. Have to run experiments.
Yeah. I'm trying to get a feel for if
Yeah. I'm trying to get a feel for if
this does anything at all.
and just pull the clean script and run
one. Well,
one. Well,
like does that even tell you because
like does that even tell you because
like
like
um the bottlenecks in the clean RL are
um the bottlenecks in the clean RL are
completely different from the
completely different from the
bottlenecks in an optimized RL setup.
now. This is like really slow.
This is why no one looks at time
This is why no one looks at time
efficiency. Well, but that's like stupid
efficiency. Well, but that's like stupid
academia [ __ ] right? But that's
academia [ __ ] right? But that's
ultimately what like the only thing that
matters. Like for any fixed end, you
matters. Like for any fixed end, you
want it to train faster in wall clock,
want it to train faster in wall clock,
right? So if you have a slow M, it's not
right? So if you have a slow M, it's not
like, oh, we care about sampling. No,
like, oh, we care about sampling. No,
you still care about wall clock. It's
you still care about wall clock. It's
just that the end is more of a
just that the end is more of a
bottleneck,
right? So, if you like take a slow end
right? So, if you like take a slow end
and then make your method run even
and then make your method run even
slower, you're just
slower, you're just
dumb,
right? Like ideally, you should be
right? Like ideally, you should be
consuming samples at the rate that you
consuming samples at the rate that you
can produce them.
Yeah. So, this totally just crashes up
Yeah. So, this totally just crashes up
if you do it too often, which is in line
if you do it too often, which is in line
with the result.
So I would agree with you if the field
So I would agree with you if the field
has not been like taken this to utterly
has not been like taken this to utterly
stupid extremes
stupid extremes
repeatedly. This learning 200x faster is
repeatedly. This learning 200x faster is
also known as how do we spend two weeks
also known as how do we spend two weeks
per Atari
per Atari
environment. 200x faster like this is
environment. 200x faster like this is
literally how do we spend two weeks per
literally how do we spend two weeks per
Atari end. It's insane.
And like if you actually look at the
And like if you actually look at the
methods in this, like they're just doing
methods in this, like they're just doing
insane [ __ ] that's just like how do we
insane [ __ ] that's just like how do we
burn as much compute as physically
possible? So this is like the give a
possible? So this is like the give a
mouse a muffin thing. It's like we've
mouse a muffin thing. It's like we've
given the mouse too many
given the mouse too many
muffins. Academ Academia has taken it as
muffins. Academ Academia has taken it as
license to just do stupid [ __ ] instead
license to just do stupid [ __ ] instead
of making real progress. And uh yeah,
of making real progress. And uh yeah,
we're not taking that
anymore. I haven't seen this do anything
anymore. I haven't seen this do anything
useful at the moment.
useful at the moment.
Um, do we even get like value
loss? We really don't even see anything
loss? We really don't even see anything
substantial on the value
loss. Let me make sure I'm doing it
loss. Let me make sure I'm doing it
right. Every sample we train a full
right. Every sample we train a full
agent with and without that sample.
I mean, they are literally doing stuff
I mean, they are literally doing stuff
like training populations of agents to
like training populations of agents to
see which one does better.
Yeah, it's kind of batshit.
This thing doesn't seem to actually
This thing doesn't seem to actually
reduce value
loss. Is that likely a bug? I don't know
loss. Is that likely a bug? I don't know
how it would be a
bug. I mean, it is actually lower than
bug. I mean, it is actually lower than
this for a lot of it,
right? It's a stochcastic policy.
right? It's a stochcastic policy.
There's like only so much certainty you
There's like only so much certainty you
can have. Like the value loss can't ever
can have. Like the value loss can't ever
go to zero with a stochcastic policy,
go to zero with a stochcastic policy,
right?
could well like you don't know if you're
could well like you don't know if you're
actually going to get hit the hit the
actually going to get hit the hit the
ball or just wobble, right? Like halfway
ball or just wobble, right? Like halfway
through training the paddle wobbles a
through training the paddle wobbles a
bunch so we're just randomly miss stuff.
bunch so we're just randomly miss stuff.
You can't predict
You can't predict
that. It's weird it's not decreasing in
that. It's weird it's not decreasing in
my Yeah, that is fair.
We have it right here though,
right? All right. Well, we'll do a
right? All right. Well, we'll do a
couple more things before I say this
couple more things before I say this
isn't worth
time. I don't necessarily really Like
time. I don't necessarily really Like
I'm not in love with this method or
I'm not in love with this method or
anything though.
So now this is no policy gradient
So now this is no policy gradient
loss just extra value
loss. Value loss consistently decreased.
That doesn't make sense to me. Value
That doesn't make sense to me. Value
loss should increase over
training. It should be end dependent
training. It should be end dependent
though.
breakout changes a lot. I mean most
should I mean breakout is like the
should I mean breakout is like the
fundamentally looks the same regardless
fundamentally looks the same regardless
and
right if anything like a lot of could be
right if anything like a lot of could be
way more volatile than
that. I mean, this was going well until
that. I mean, this was going well until
it
it
uh
collapsed. We could go back to like six
collapsed. We could go back to like six
epox or whatever.
Maybe this is a more reasonable thing to
Maybe this is a more reasonable thing to
do. Top block. It does change when you
do. Top block. It does change when you
break the top block.
Yeah. Is there a statebased version of
Yeah. Is there a statebased version of
procgen?
like those M's are actually fast.
like those M's are actually fast.
Technically, we could just like we could
Technically, we could just like we could
probably do a little a version of proc
probably do a little a version of proc
gener and gives you state based ops cuz
gener and gives you state based ops cuz
like procgen m themselves are solid C++.
like procgen m themselves are solid C++.
Like we could probably grab them and um
Like we could probably grab them and um
and no emulator, right? Like we could
and no emulator, right? Like we could
probably just grab those and like have a
probably just grab those and like have a
bunch of new M's to play with.
Yeah, the obs are always pixels, right?
Yeah, the obs are always pixels, right?
But like they have code somewhere that
But like they have code somewhere that
renders stuff.
like they're just individual C++ files,
like they're just individual C++ files,
right?
They don't render every frame. Well, can
They don't render every frame. Well, can
instead of rendering every like can we
instead of rendering every like can we
just get some buffer of obs out that's
just get some buffer of obs out that's
not
frames. Here's point run.
Oh, definitely
Oh, definitely
wood. And it's annoyingly it is
B++. But like I think they're all block
B++. But like I think they're all block
assets even, aren't they?
big
big
fish. Can chat GPT an option? I
fish. Can chat GPT an option? I
generally assume chat GPT can't do
anything.
Maybe maybe sitting chat GPT is just not
Maybe maybe sitting chat GPT is just not
my idea of a fun time.
neither is translating C
code. I mean, but like the thing with
code. I mean, but like the thing with
those two, it's it's annoying because
those two, it's it's annoying because
you actually have to think a little bit
you actually have to think a little bit
about how to replace data structures,
about how to replace data structures,
right, that don't
exist. I'm stuck in What are you doing
exist. I'm stuck in What are you doing
with
with
CUDA? Since when do you write CUDA?
Oh, installing it, not writing it. I
Oh, installing it, not writing it. I
mean, these are like reasonable. They
mean, these are like reasonable. They
all have like block based assets and
all have like block based assets and
then entities that can be discreet or
continuous. I mean, I wouldn't be so mad
continuous. I mean, I wouldn't be so mad
about using this as our image based like
about using this as our image based like
image based benchmark either because we
image based benchmark either because we
technically probably
technically probably
could if we do anything with image based
could if we do anything with image based
stuff up it would be
stuff up it would be
this VMs where it
works is it what you get for using
VMs you're lacking the puffer infra
VMs you're lacking the puffer infra
experience
ma'am no VM docker just raw install on a
ma'am no VM docker just raw install on a
docker so it's perfectly replicable
not using Docker. Yeah, that's your
not using Docker. Yeah, that's your
problem,
problem,
right? That's why you're
right? That's why you're
suffering. Don't suffer. Use
Puffer. So, I haven't been able to get
Puffer. So, I haven't been able to get
this version of this algorithm to do
this version of this algorithm to do
anything.
Um, why would you even need to convert
Um, why would you even need to convert
to C? Just find the existing. Yeah, we
to C? Just find the existing. Yeah, we
probably could, Captain.
I just I don't know how their whole
I just I don't know how their whole
render setup works.
I'm trying to think if there's anything
I'm trying to think if there's anything
I could possibly be missing
I could possibly be missing
with PPG.
I could I guess there's one other thing.
What's
What's
this? Oh, yeah. That's the old version.
this? Oh, yeah. That's the old version.
That doesn't
matter. So, let's just do the original
matter. So, let's just do the original
here. Okay. And then we'll do
up here. The B loss will get zeroed.
You can't copy VMs around like that,
You can't copy VMs around like that,
Ryan. You mess them links as well.
Okay. So, this doesn't work.
Well, you prepare you have a computer
Well, you prepare you have a computer
with seven different
with seven different
environments. In all fairness,
worked so far. Doesn't work
now. Just because it's something that
now. Just because it's something that
it's designed for doesn't mean it's not
it's designed for doesn't mean it's not
[ __ ]
I know. I
Yeah. So, this doesn't work at all
Yeah. So, this doesn't work at all
without the cloning boss,
right? Because it just
right? Because it just
diverges. Like it starts learning and
diverges. Like it starts learning and
then it'll diverge.
So cloning loss is a thing that makes it
So cloning loss is a thing that makes it
work,
work,
but it doesn't seem like it's clearly
but it doesn't seem like it's clearly
doing
anything. Okay, one last idea.
You do
You do
this this thing
normally and
normally and
[Music]
[Music]
then we do this loss. Where is it? The
then we do this loss. Where is it? The
whole loss here.
But we
But we
do set this to like what's it
six
six
two. Set this to
six every
16. What are you working on? I am
16. What are you working on? I am
currently Give me one second here. Um,
currently Give me one second here. Um,
I'm currently working on variations of
I'm currently working on variations of
basic policy gradients to see if they do
basic policy gradients to see if they do
anything for puffer lip. I'm trying to
anything for puffer lip. I'm trying to
like see if I can use some of the
like see if I can use some of the
techniques from this paper
techniques from this paper
uh in a way that doesn't slow down
uh in a way that doesn't slow down
learning so much.
Okay, so here here's the
Okay, so here here's the
uh here's the idea, right? What if they
uh here's the idea, right? What if they
didn't have their value function
didn't have their value function
coefficient trained when they wrote this
coefficient trained when they wrote this
paper? So what if it were something like
paper? So what if it were something like
this,
right? Does that change
it? Would that make sense? Actually,
it? Would that make sense? Actually,
Ryan, what if like what if they just had
Ryan, what if like what if they just had
a fiddly tuned value function
a fiddly tuned value function
coefficient, right? So, their value
coefficient, right? So, their value
function wasn't getting trained enough.
Okay. Okay, so this is PPG with shitty
Okay. Okay, so this is PPG with shitty
value function
value function
coefficient and
then we do it without PPG.
G. What was their value
coefficient? Feel like you need to make
coefficient? Feel like you need to make
sure your implementation
sure your implementation
replicates their results before testing
replicates their results before testing
stuff
stuff
though. It depends how conclusive we're
though. It depends how conclusive we're
being,
right? Because I don't actually want
right? Because I don't actually want
their version. Like I don't actually
their version. Like I don't actually
want their algorithm. I want some like
want their algorithm. I want some like
adjacent things from their algorithm.
So the aux phase code is literally just
So the aux phase code is literally just
copy paste the whole training loop and
copy paste the whole training loop and
change the
losses. I
losses. I
[Music]
[Music]
mean kind of right. Look at
this. That's a bigger gap than we've
this. That's a bigger gap than we've
seen anywhere else. Right.
They regenerate policy logics. No, I do
They regenerate policy logics. No, I do
regenerate policy logics. I implemented
regenerate policy logics. I implemented
that
today. So, first of all, I didn't scrub
today. So, first of all, I didn't scrub
that badly,
that badly,
Ryan. So, this is the main loop, all the
Ryan. So, this is the main loop, all the
freaking code, yada yada. And
freaking code, yada yada. And
then here's where I regenerate logs and
then here's where I regenerate logs and
values for
values for
baselining. And then we use those here
baselining. And then we use those here
in the uh in the KL loss and the value
in the uh in the KL loss and the value
loss. So there you go. So what you're
loss. So there you go. So what you're
looking at with this, right, is I just I
looking at with this, right, is I just I
took the value coefficient down to
0.5. So value coefficient at 0.5. Now
0.5. So value coefficient at 0.5. Now
ppg is better. than PO because you would
ppg is better. than PO because you would
do the additional value
training. So PPG is is pretty close to
training. So PPG is is pretty close to
the original tuned
PO and the PO with the lower coefficient
PO and the PO with the lower coefficient
isn't. I mean we could we could
isn't. I mean we could we could
technically exacerbate this as well
technically exacerbate this as well
because they have a worse optimizer than
because they have a worse optimizer than
we do, right?
So I think it's
So I think it's
here. So they have a worse optimizer as
here. So they have a worse optimizer as
well. So I could go down to like
well. So I could go down to like
0.25 and we can see what that does. Let
0.25 and we can see what that does. Let
me see what coefficient they
used. They don't have one in
used. They don't have one in
here, I guess. I would have
it 0.5
with the worst
optimizer. I
optimizer. I
mean,
yeah, and then we do six epochs of
yeah, and then we do six epochs of
ppg,
right? I don't think they changed any
right? I don't think they changed any
hypers.
Well, yeah. So, what that means, right,
Well, yeah. So, what that means, right,
is you could find
is you could find
like you found an algorithm like you
like you found an algorithm like you
tuned an algorithm to the current hypers
tuned an algorithm to the current hypers
is a possibility,
right? Wouldn't be the first time in RL.
I mean that looks
pretty. Yeah. So this is the only way
pretty. Yeah. So this is the only way
we've gotten ppg to do con to do
we've gotten ppg to do con to do
consistently better.
Right? This would be consistent with
Right? This would be consistent with
undertrain value function.
Arguably this M is also very easy. So
Arguably this M is also very easy. So
you know this effect could be magnified
you know this effect could be magnified
a ton in harder ends.
Right. Let me see if I can get one other
Right. Let me see if I can get one other
to
to
run Boba or something.
welcome.
were we doing PO breakout? Uh we were.
were we doing PO breakout? Uh we were.
Yeah, I think the M is a little too
Yeah, I think the M is a little too
simple. So basically what I'm trying to
simple. So basically what I'm trying to
figure out now
figure out now
is what uh where the per improvement
is what uh where the per improvement
from phasic policy gradients is coming
from phasic policy gradients is coming
from. And I'm suspecting that you can do
from. And I'm suspecting that you can do
similarly well just by increasing the
similarly well just by increasing the
value function coefficient.
Shoot. This isn't going to run, is
it? Yeah, we've got some screwy things
it? Yeah, we've got some screwy things
happening with some of these
happening with some of these
ends. We could do snake maybe.
Enduro. Let me see which of these we can
Enduro. Let me see which of these we can
get to like run
quickly. And these haven't been ported
quickly. And these haven't been ported
off to the new code yet, right?
We can do
We can do
snake. Let's at least see if we can
snake. Let's at least see if we can
replicate this one.
Thank. Is it hard to set up bindings for
Thank. Is it hard to set up bindings for
procgen?
procgen?
No, we can train progen. It's just
No, we can train progen. It's just
really freaking
slow. Like procgen is 300 times slower
slow. Like procgen is 300 times slower
than this with their base network that
than this with their base network that
they
use after optimizing.
I actually just run it on like actual
I actually just run it on like actual
breakout if we're doing that right
What do you mean by the coefficient of
What do you mean by the coefficient of
the value function? So, uh when you
the value function? So, uh when you
train the value loss, you usually apply
train the value loss, you usually apply
a coefficient to it. You usually like
a coefficient to it. You usually like
multiply it by coefficients and fixed
multiply it by coefficients and fixed
value as a hyperparam. So, their default
value as a hyperparam. So, their default
is like 0.5 and ours is usually like
is like 0.5 and ours is usually like
two. So, it's quite possible that they
two. So, it's quite possible that they
just undertuned the value
function. Okay, we'll do a pixelm
function. Okay, we'll do a pixelm
because apparently pixel ends are cool
because apparently pixel ends are cool
or
or
something. If I can get this to run
something. If I can get this to run
reasonably quickly at
least. I'm trying to think about this
least. I'm trying to think about this
and like
actually does this
work kind
of. It's going to be rough with the new
of. It's going to be rough with the new
vectorization, I think.
Haven't done anything on Atar in a long
Haven't done anything on Atar in a long
time.
This is why I didn't want to do this
This is why I didn't want to do this
because I just know that the current dev
because I just know that the current dev
state is
like like we need to like update
like like we need to like update
everything to the latest binding
everything to the latest binding
signature, right?
still just not going to be able to
still just not going to be able to
like there's just like a ton of work I
like there's just like a ton of work I
have to do on this in order to update
have to do on this in order to update
everything to the new
signatures. Let me go back to doing this
signatures. Let me go back to doing this
on snake at the very least.
Three runs real
Three runs real
quick. First run, normal
quick. First run, normal
baseline. Make sure I haven't broken
baseline. Make sure I haven't broken
anything doing all this [ __ ]
I've definitely broken something doing
I've definitely broken something doing
all this [ __ ]
Okay,
Okay,
there reasonable
there reasonable
baseline. So this is one window.
baseline. So this is one window.
Remember this second window.
baseline. Honestly, we don't even need
baseline. Honestly, we don't even need
this for more than 40
mil baseline
mil baseline
with shitty clipping
with shitty clipping
coefficient or shitty value function
coefficient or shitty value function
coefficient.
L does
better. To be fair, we didn't tune value
better. To be fair, we didn't tune value
function coefficient for this sound. We
function coefficient for this sound. We
tuned it for breakout.
Okay, unplanned. So that we'll just do
Okay, unplanned. So that we'll just do
um just do some ppg
um just do some ppg
epochs within without value or whatever.
Just like, do we get any signs of life
Just like, do we get any signs of life
whatsoever from this
thing? Okay. Underperforms this one.
What about with this?
Okay, that's
something. Barely something, but
Oh, you know
Oh, you know
what, dude? How did I let myself get
what, dude? How did I let myself get
nerd sniped by this? You know why this
nerd sniped by this? You know why this
thing probably doesn't
work? This is not any better, right?
Yeah, it's on par with original. So,
Yeah, it's on par with original. So,
here's the thing I always forget about,
here's the thing I always forget about,
right? I don't know why I like this
right? I don't know why I like this
happens every bloody time and I always
happens every bloody time and I always
forget about this. So, like
This is how you fudge all research by
This is how you fudge all research by
the way. So unintentionally as well I
the way. So unintentionally as well I
should say. So you see all these
should say. So you see all these
hyperpar. Yeah they just take these from
hyperpar. Yeah they just take these from
the original repo.
the original repo.
Right. So these are just from the
Right. So these are just from the
original repository. They don't reune
original repository. They don't reune
them for this work at all. And then they
them for this work at all. And then they
go introduce five six new
go introduce five six new
hyperparameters with this new algorithm
hyperparameters with this new algorithm
that they do
that they do
tune. So like when you introduce six new
tune. So like when you introduce six new
hyperparameters and that you are
hyperparameters and that you are
actually tuning them, you can basically
actually tuning them, you can basically
come up with any old stupid method and
come up with any old stupid method and
it'll
it'll
work. Now, to be fair to them, I think
work. Now, to be fair to them, I think
that the results they have here, like
that the results they have here, like
they've actually got pretty clean graphs
they've actually got pretty clean graphs
on a lot of these things showing that
on a lot of these things showing that
yeah, there's probably something
yeah, there's probably something
here, but
here, but
um I I'd be very surprised if the gap is
um I I'd be very surprised if the gap is
as big as
as big as
this in general.
Once you actually have correctly tuned
hypers I don't think you can just add
hypers I don't think you can just add
hypers and get good results across proc
hypers and get good results across proc
gen happens quite often.
I mean the idea there is like you're
I mean the idea there is like you're
adding extra tunable knobs,
adding extra tunable knobs,
right? So like here, let me give you a
right? So like here, let me give you a
really dumb example, right? Let's say
really dumb example, right? Let's say
that I just add another parameter in
that I just add another parameter in
front of gamma and lambda, right? That I
front of gamma and lambda, right? That I
call like my super awesome gamma and
call like my super awesome gamma and
lambda. And then I don't tune the
lambda. And then I don't tune the
originals, but I do tune my parameters.
originals, but I do tune my parameters.
Boom. I set soda, right?
And actually procgen was solved just by
And actually procgen was solved just by
tuning dbo hyperp
per assumes the original hyperparameters
per assumes the original hyperparameters
aren't tuned. Believe me, they're not.
aren't tuned. Believe me, they're not.
They're [ __ ]
They're [ __ ]
propgen was solved just by
propgen was solved just by
hyperparameter tuning by
imbue par isn't the same problem. Well,
imbue par isn't the same problem. Well,
the original problem stupid though
the original problem stupid though
because like J fundamentally means that
because like J fundamentally means that
you can't have optimal params and also
you can't have optimal params and also
the originals aren't tuned. Look at
the originals aren't tuned. Look at
them. They're like 0.5 and like 0.95.
them. They're like 0.5 and like 0.95.
They're just the ones that they grabbed
They're just the ones that they grabbed
from
from
Atari or whatever, right?
I guess they do like the long horizon
I guess they do like the long horizon
version of 999. Yeah, like these aren't
version of 999. Yeah, like these aren't
even
like second digit. Yeah, these aren't
like second digit. Yeah, these aren't
tuned at all. This is just Atari
tuned at all. This is just Atari
default, Atari
default, Atari
default. Like these are all just
default. Like these are all just
generalization is a dumb problem. Well,
generalization is a dumb problem. Well,
it is in this case because like you
it is in this case because like you
can't solve it with PO because of
can't solve it with PO because of
J, right? It is actually literally is a
J, right? It is actually literally is a
dumb problem trying to solve when you're
dumb problem trying to solve when you're
using J with a fixed coefficient because
using J with a fixed coefficient because
J says this is the time horizon I care
J says this is the time horizon I care
about and then you give it time horizons
about and then you give it time horizons
with different problems. Like the smart
with different problems. Like the smart
thing to do is to try to replace J with
thing to do is to try to replace J with
something that doesn't have that
something that doesn't have that
limitation. But just like oh we're going
limitation. But just like oh we're going
to use J as a core component and then
to use J as a core component and then
try to do it anyways is really stupid.
Yeah. I mean that's literally why this
Yeah. I mean that's literally why this
benchmark like this was this benchmark
benchmark like this was this benchmark
was unsolved for a long long time right
was unsolved for a long long time right
and then literally you take the dumbest
and then literally you take the dumbest
baseline you just tune the params per
baseline you just tune the params per
end and you full solve
end and you full solve
it that's not like and that's like
it that's not like and that's like
despite the best efforts of people doing
despite the best efforts of people doing
all sorts of fancy algorithms right
all sorts of fancy algorithms right
that's not like oh different problem
that's not like oh different problem
that's just the original problem spec
that's just the original problem spec
was dumb and it highlights like
was dumb and it highlights like
something dumb about po
Right. I don't know. I'd be I'd be
Right. I don't know. I'd be I'd be
interested to see like if you just tune
interested to see like if you just tune
gamma and lambda per n, right? That
gamma and lambda per n, right? That
would be
would be
interesting. Not poss. It's possible to
interesting. Not poss. It's possible to
do. Yeah, it is. But like you full solve
do. Yeah, it is. But like you full solve
it just with default PO, right? It's not
it just with default PO, right? It's not
hard. I agree. We should spend time more
hard. I agree. We should spend time more
time on GE replacements. This is why I
time on GE replacements. This is why I
was like banging my head on P3 for a
was like banging my head on P3 for a
while, right? And I'm still going to go
while, right? And I'm still going to go
back to that. I actually I would be
back to that. I actually I would be
interested to see how well you could do
interested to see how well you could do
if uh you tuned one set of hypers across
if uh you tuned one set of hypers across
all the M's, right? But you tune per M
all the M's, right? But you tune per M
gamma lambda. I think you'd do pretty
gamma lambda. I think you'd do pretty
well because since I added muon, pretty
well because since I added muon, pretty
much the only params I really have to
much the only params I really have to
tune very often when I have like
tune very often when I have like
comparable model and stuff are gamma
comparable model and stuff are gamma
like just gamma lambda. Everything else
like just gamma lambda. Everything else
is kind of
fine. The thing is we've actually kind
fine. The thing is we've actually kind
of done that in Puffer, right? Because
of done that in Puffer, right? Because
like we solved all the M's out of the
like we solved all the M's out of the
box in Puffer with Muon with pretty much
box in Puffer with Muon with pretty much
same hypers. I think we changed like
same hypers. I think we changed like
batch size for a couple of them because
batch size for a couple of them because
some are faster than others. But then
some are faster than others. But then
like there were a couple M's where we
like there were a couple M's where we
had to reduce lambda to
had to reduce lambda to
solve. So like there you kind of go
solve. So like there you kind of go
right there. And then I looked at the
right there. And then I looked at the
Proctton hyperparame sweep results and I
Proctton hyperparame sweep results and I
can tell you it's the exact same problem
can tell you it's the exact same problem
looking at those because they have like
looking at those because they have like
lambda or they have like gamma equal 0.7
lambda or they have like gamma equal 0.7
in some of them as
optimal. So actually there you go. I can
optimal. So actually there you go. I can
I can tell you the result of that right
I can tell you the result of that right
now is that you do pretty darn well.
I mean this
I mean this
definitely like this definitely is
definitely like this definitely is
tuning a value function coefficient
tuning a value function coefficient
right spending extra epochs on value
right spending extra epochs on value
function this means that you've
function this means that you've
basically tuned cross n value function
basically tuned cross n value function
coefficient when it wasn't tuned
or these results at the top are
or these results at the top are
interesting,
right? This is E
O and this is EI.
which helps so
which helps so
much. I don't think that they help so
much. I don't think that they help so
much. I think that you actually like
much. I think that you actually like
close this gap by at least half is most
close this gap by at least half is most
likely if you just
tune. I wouldn't expect most of this.
tune. I wouldn't expect most of this.
Yeah. No, I think the directionality of
Yeah. No, I think the directionality of
the result is interesting, right? But I
the result is interesting, right? But I
think that the magnitude is likely very
overstated. Actually, let me see. So,
overstated. Actually, let me see. So,
they didn't report this, right? They
they didn't report this, right? They
didn't report EV, did
they? See? Yeah. They don't actually
they? See? Yeah. They don't actually
have EV on here. Isn't that funny?
Well, they set this to
Well, they set this to
one. So, they don't actually even tune
one. So, they don't actually even tune
the value. Like, they don't even do this
the value. Like, they don't even do this
more.
Right. Let me see if that changes
anything. Well, this one here, they
anything. Well, this one here, they
actually do extra steps. They had an
actually do extra steps. They had an
ablation on this.
Right. Let me find it. I swear they had
Right. Let me find it. I swear they had
an inflation on
this. Okay.
this. Okay.
So they lose some of the
So they lose some of the
Perf if they do three value
updates and then they remove L value in
updates and then they remove L value in
ox phase.
Interesting. But this is also with the
Interesting. But this is also with the
unshared one,
right? This is with the unshared net as
right? This is with the unshared net as
well. I think that this this perf
well. I think that this this perf
degradation would probably stack really
degradation would probably stack really
badly with
badly with
with
with
this. Oh, also this is bucked,
this. Oh, also this is bucked,
right? This this baseline is screwed.
right? This this baseline is screwed.
Look at
Look at
this separate network
PO. Man, that makes me like not want to
PO. Man, that makes me like not want to
trust
trust
this at all with it with it like this.
There's no way,
right? There's like actually no way you
right? There's like actually no way you
get this big of a gap,
get this big of a gap,
right? Yeah, it does outperform shared
right? Yeah, it does outperform shared
network. But my point here is
network. But my point here is
like there's no way that you that like
like there's no way that you that like
doing separate networks which is
doing separate networks which is
literally more pip more parameters does
literally more pip more parameters does
like crazy worse and in fact like you
like crazy worse and in fact like you
know often people use separate networks
know often people use separate networks
because it does better. So I think that
because it does better. So I think that
this whole gap is hyperpar.
Heck, I think if you tuned it correctly,
Heck, I think if you tuned it correctly,
this should be above this
this should be above this
one, right? You have double capacity.
The heck is a value
feature? Does it make sense that that's
feature? Does it make sense that that's
actually a
thing? I guess the whole paper really
thing? I guess the whole paper really
hinges on this, right?
Like if not for this graph, I wouldn't
Like if not for this graph, I wouldn't
even pay attention to this paper.
Value prediction has to be harder than
Value prediction has to be harder than
learning the policy, it says, right?
learning the policy, it says, right?
Because otherwise, why would it benefit
Because otherwise, why would it benefit
from more
epochs? And value function usually lags
epochs? And value function usually lags
as well, right?
I'm trying to think here
like they probably do have something
like they probably do have something
here.
here.
My my best guess here is that they do
My my best guess here is that they do
have something, but the magnitude is way
have something, but the magnitude is way
lower than
stated because
like like would we care about this
like like would we care about this
paper, right? Let's say like how much do
paper, right? Let's say like how much do
you think you get off of just tuning the
you think you get off of just tuning the
hypers better, right?
hypers better, right?
Like if this gap were closed by half,
Like if this gap were closed by half,
would we really care that
would we really care that
much about
this? I mean, if you wanna if you want
this? I mean, if you wanna if you want
to do that, yeah, that would be awesome.
Um, but I don't
like I think it it needs a better tuned
like I think it it needs a better tuned
baseline,
right? Because I am I really think that
right? Because I am I really think that
there
there
is I think this is a weak baseline
is I think this is a weak baseline
problem.
Like these graphs are cool because
Like these graphs are cool because
like the fact that your policy does
like the fact that your policy does
worse when you reuse
worse when you reuse
it and the value function does
better some exact experiments you want
better some exact experiments you want
to
See, well hyper the most expensive thing
See, well hyper the most expensive thing
is going to be the freaking would be the
is going to be the freaking would be the
hyperparameter tuning,
right? I guess one thing would be to see
right? I guess one thing would be to see
whether the way I'm implementing it is
whether the way I'm implementing it is
just screwing it
just screwing it
up.
up.
So I think what you would do then is you
So I think what you would do then is you
would do full
would do full
PO. If you just do full PO, like one
PO. If you just do full PO, like one
epoch, full
epoch, full
PPO, right? And then every I think this
PPO, right? And then every I think this
is 16 or 32 epochs, you do the extra
is 16 or 32 epochs, you do the extra
value stuff with the distillation. So
value stuff with the distillation. So
basically
basically
does Yeah, remove the stock
does Yeah, remove the stock
brad. I think if you just remove the
brad. I think if you just remove the
stock brad, that kind of does it, right?
I don't know if it's implement how it's
I don't know if it's implement how it's
implemented in the clean RL repo, but I
implemented in the clean RL repo, but I
also would like to do these at the same
also would like to do these at the same
time. So do these like these should be
time. So do these like these should be
done jointly,
done jointly,
right? Well, because EPI and EV can be
right? Well, because EPI and EV can be
different. So I would do these jointly
different. So I would do these jointly
with the shared network. So do the
with the shared network. So do the
shared network variant with these steps
shared network variant with these steps
done
jointly. Clean RL doesn't implement
jointly. Clean RL doesn't implement
that. Perfect. So in that case, you can
that. Perfect. So in that case, you can
just do you can just do one
just do you can just do one
epoch. You can remove the stop
epoch. You can remove the stop
brad and you can see if that screws it
up. And then I what I'll do is I'll save
up. And then I what I'll do is I'll save
this stuff here.
I'll like add all this
Don't need that. Yeah.
Well, ironically, I think that if if the
Well, ironically, I think that if if the
stop grab thing doesn't
work well, I'm trying to think of what
work well, I'm trying to think of what
what is the case in which it is worth
what is the case in which it is worth
it.
it.
Um cuz if removing the stop
Um cuz if removing the stop
Brad doesn't break the method,
Brad doesn't break the method,
right? Then the fact that it doesn't
right? Then the fact that it doesn't
work in my code is like, okay, maybe the
work in my code is like, okay, maybe the
thing just doesn't work.
thing just doesn't work.
And if removing the stock
And if removing the stock
rad does break
rad does break
it, then it's like not super useful
it, then it's like not super useful
because it doesn't match PO dynamics.
because it doesn't match PO dynamics.
Though I guess technically we could
do actually here if stop does break it
do actually here if stop does break it
then yeah there's a way that I can slot
then yeah there's a way that I can slot
it in as like an extended compute
it in as like an extended compute
option.
option.
So what we'd want like what we'd see is
So what we'd want like what we'd see is
if this method is
if this method is
actually good then you would expect
actually good then you would expect
removing stop rad to break
removing stop rad to break
it. Yeah. So that would be the thing
it. Yeah. So that would be the thing
that we would be looking to
that we would be looking to
see. Let me use the restroom real quick
see. Let me use the restroom real quick
and then I'll think about what's next.
All
right. Miss one quick text and then we
right. Miss one quick text and then we
will work on the next thing.
All
right.
So, I think that we just figure out
So, I think that we just figure out
um we start figuring
um we start figuring
out some merge
out some merge
stuff. There kind of two parts to this.
stuff. There kind of two parts to this.
There's the new binding.
Let me see what's best
Let me see what's best
PR because there's like there's two
PR because there's like there's two
things that we need to do. There's the
things that we need to do. There's the
new binding stuff and then there's some
new binding stuff and then there's some
pretty serious vectorization
stuff. Okay. Okay. So like B has this
here. I the main thing right now I guess
here. I the main thing right now I guess
is like I'd like to just merge this into
is like I'd like to just merge this into
dev and then fix all the binding
crap. But the vectorzation stuff is
crap. But the vectorzation stuff is
going to be an issue.
Okay, let me think about what we can do
Okay, let me think about what we can do
about this.
So the problem is that the new buffer
So the problem is that the new buffer
stores segments. So it doesn't like it
stores segments. So it doesn't like it
when you get variable length segments.
my thing. Shouldn't my thing actually
my thing. Shouldn't my thing actually
work with
that? I think this actually should work.
So I actually think that there shouldn't
So I actually think that there shouldn't
really be any issue running any of the
M's. So maybe actually it is worth it to
M's. So maybe actually it is worth it to
see why Atari is hanging right
now. That might let me merge it.
Need to go back to my work. See you,
Need to go back to my work. See you,
Ryan. Get the thing done. I You got to
Ryan. Get the thing done. I You got to
just finish writing and submitting that
just finish writing and submitting that
thing. Call it a
thing. Call it a
day or whatever you're doing for
day or whatever you're doing for
finishing degree.
trying to do actual research
trying to do actual research
again. That's
again. That's
good. See you.
Where is this
hanging? Is this hanging on receipt?
Ah, I see
Ah, I see
it. Yeah, I see it.
Okay. Well, I know what the issue is
Okay. Well, I know what the issue is
now.
Yeah, that's also multi- discrete HQ,
Yeah, that's also multi- discrete HQ,
right?
You don't really do you need bats logs
You don't really do you need bats logs
for anything right
now? Not
really. Yes, this runs.
I think this just takes a while to log,
right? Yeah. There we
go. See if this trains at this
There we go. It's learning.
mil. Okay. So, this still
trains. That is good.
Okay. So, I think we will actually be
Okay. So, I think we will actually be
able to do the big merge relatively soon
able to do the big merge relatively soon
then. I don't want to start it right now
then. I don't want to start it right now
because I'm going to dinner in a bit.
because I'm going to dinner in a bit.
I'm also a little tired. I don't want to
I'm also a little tired. I don't want to
like screw this thing
like screw this thing
up. I do have a few other things to
do. Check one
thing. There was one other thing I had
thing. There was one other thing I had
to do
today. Okay, so
I think I actually
I think I actually
then I think what I
do go
here. I have to figure out how to run
this. That's
funny. Let me go find the thing. Oh, why
funny. Let me go find the thing. Oh, why
did it switch to
did it switch to
camera? That's weird.
Let me go grab all the stuff I need for
Let me go grab all the stuff I need for
this.
The other thing I had to do today was
The other thing I had to do today was
just checking on some of
just checking on some of
um this here is the animation gen work
um this here is the animation gen work
we
we
did. There's some reported issues with
did. There's some reported issues with
it.
going on
here. this
free. I actually thought that this one
free. I actually thought that this one
worked before.
Maybe I
Oh, maybe it's
this. There we
go. So, it was just too many damn
go. So, it was just too many damn
motions.
This is probably running 4096 or
This is probably running 4096 or
something.
See if I missed
anything.
anything.
No, should be fine.
This should be finished, right? Is it
This should be finished, right? Is it
actually even running
anything? It is just very inefficiently,
anything? It is just very inefficiently,
right?
Yeah, it's not even using any
Yeah, it's not even using any
CPU. I think it's just stuck.
It's like it should have spit out the
It's like it should have spit out the
results, but it didn't.
D-final
eval. Ah, space.
Let me figure out what the heck is
Let me figure out what the heck is
wrong.
This is like shared storage or some
This is like shared storage or some
[ __ ] right?
The heck is it even trying to write to
The heck is it even trying to write to
slashtemp? Oh, this is shitty internal
slashtemp? Oh, this is shitty internal
like stupid internal torch
like stupid internal torch
multipprocessing.
multipprocessing.
Yeah, and I remember this being an
Yeah, and I remember this being an
issue.
Hang on.
Seems like there's space
here. Porch elastic
I'm trying to think what I can do to get
I'm trying to think what I can do to get
this stupid thing to
this stupid thing to
run. I have space.
There shouldn't be a cap on the docker
There shouldn't be a cap on the docker
size, right?
that does
anything or if it
anything or if it
just we'll see.
That might be it. Right.
I think I might be able to just like
I think I might be able to just like
start the container separately. One
start the container separately. One
sec. Okay.
We can actually just do it with start.
We can actually just do it with start.
Hang on. Yeah. Yeah, this will
work. We can literally just do this
work. We can literally just do this
apparently.
I'm hoping that I don't have to remake
I'm hoping that I don't have to remake
the container. I think we can just
the container. I think we can just
reboot it and then we can actually get
reboot it and then we can actually get
some cool emails.
Unknown flag. Yeah. So, this this
Unknown flag. Yeah. So, this this
doesn't freaking
doesn't freaking
exist. Would drop
Groc. I don't want to remove the damn
container. We'll just make a separate
container. We'll just make a separate
container to test this. I think real
container to test this. I think real
quick. That's what we'll do.
There we go.
Now
Now
we reset up this
we reset up this
repo and hopefully I have all the data.
and that'll install that and then uh we
and that'll install that and then uh we
should be able to test this and
should be able to test this and
hopefully that fix the shared memor
[ __ ] We will hope.
So this right here, what we're waiting
So this right here, what we're waiting
on, this is why you don't use virtual
on, this is why you don't use virtual
MS. Um, if this were just part of the
MS. Um, if this were just part of the
Docker, we would be done
instantly. Instead, you sit here waiting
instantly. Instead, you sit here waiting
for 5, 10 minutes, whatever, every
for 5, 10 minutes, whatever, every
single time you want to like remake a
single time you want to like remake a
dev environment for whatever reason.
Okay, we get our shell
Hey, bet. We're just testing some
Hey, bet. We're just testing some
animation stuff for a bit. Um, I
tried I tried some stuff with basic
tried I tried some stuff with basic
policy
policy
gradients. It didn't really do much. We
gradients. It didn't really do much. We
might want to come back to it when we
might want to come back to it when we
have like a
have like a
stable version of dev so I have access
stable version of dev so I have access
to all the ends for testing
to all the ends for testing
correctly. But um initially it doesn't
correctly. But um initially it doesn't
do much
Yep.
Yep.
He's going to go run some experiments as
He's going to go run some experiments as
well.
Yeah, it's a count thing. Some folks are
Yeah, it's a count thing. Some folks are
having trouble with it, so I'm just like
having trouble with it, so I'm just like
seeing what I can repro.
Yes, we need the model.
See if there's
still this ones. We might just have to
still this ones. We might just have to
screw with something. I don't
know. Uh there's
know. Uh there's
like PyTorch multipprocessing kind of
like PyTorch multipprocessing kind of
sucks and there's like some weird shared
sucks and there's like some weird shared
memory resource out of memory thing.
memory resource out of memory thing.
It's not like
It's not like
It's not actual RAM. There's some like
It's not actual RAM. There's some like
weird shared resource
weird shared resource
thing. Yes. So, this seems like it's
thing. Yes. So, this seems like it's
still
stuck. Oh, there we go. No, that
stuck. Oh, there we go. No, that
actually works now. Perfect. So, that
actually works now. Perfect. So, that
did fix it.
Tyler, why are you writing fanfic in
Tyler, why are you writing fanfic in
the stream chat now? What are you
doing? No, that's Tyler. Tyler's not
doing? No, that's Tyler. Tyler's not
allowed.
Unless he's just pasting random crap in
Unless he's just pasting random crap in
now. Tyler actually does cool physics
[ __ ] What the hell are dumb? What the
[ __ ] What the hell are dumb? What the
hell article is
hell article is
this? We're not reading stupid White
this? We're not reading stupid White
House articles on stream.
success rate
zero. Oh, but this is Yeah, this is only
zero. Oh, but this is Yeah, this is only
on this
on this
one motion.
This is just dash
m less bureaucracy is good.
m less bureaucracy is good.
Yes. No AI regulation.
Yes. No AI regulation.
Please let us Leave us alone and let us
Please let us Leave us alone and let us
build stuff.
Yeah, all the code in this this is just
Yeah, all the code in this this is just
all so
slow. There's only so much we can do on
slow. There's only so much we can do on
this stuff, right? It's
this stuff, right? It's
like robotics just
like robotics just
has too many years worth of accumulated
has too many years worth of accumulated
god-awful
god-awful
software. It's the type of thing where
software. It's the type of thing where
I'd like have to really focus on it for
I'd like have to really focus on it for
quite a while to like fix
quite a while to like fix
everything. There's like a very large
everything. There's like a very large
amount of stuff that you just would have
amount of stuff that you just would have
to completely scrap and rewrite.
Okay, that does look
bad. Hey bud, you live today too? Yeah,
bad. Hey bud, you live today too? Yeah,
I was working on
I was working on
um phasic policy gradients a bit
um phasic policy gradients a bit
earlier and uh we're just checking
earlier and uh we're just checking
on some code we shipped recently. I
on some code we shipped recently. I
think there's just some dumb model load
think there's just some dumb model load
mismatch or something.
Oh well here look it's now we are
Oh well here look it's now we are
getting success
right this actually should be done
right this actually should be done
pretty soon then if it's this is how
pretty soon then if it's this is how
it's doing it because
Yeah, there's only 11k of them. Okay,
Yeah, there's only 11k of them. Okay,
we'll let it finish. Assuming that's
we'll let it finish. Assuming that's
what it's going to do.
Hello YouTube
folks. I mean for reference what this
folks. I mean for reference what this
stuff is here, this is animation genrel
stuff is here, this is animation genrel
stuff. So it takes um motion data like
stuff. So it takes um motion data like
captured
captured
uh or like generated even motion data
uh or like generated even motion data
that may be messy and then it runs it
that may be messy and then it runs it
through a robotic sim runs it through
through a robotic sim runs it through
Isaac
Isaac
Jim and I mean when you're running in a
Jim and I mean when you're running in a
sim like you your foot can't go through
sim like you your foot can't go through
the ground and you can't do things that
the ground and you can't do things that
don't work with physics right so then
don't work with physics right so then
you do RL on that sim to actually make
you do RL on that sim to actually make
the thing match the original motion
the thing match the original motion
within the bounds of physics and then
within the bounds of physics and then
you get better generated animation data
you get better generated animation data
out of
that only problem is that this whole
that only problem is that this whole
area has like total total total mess of
area has like total total total mess of
software like I did a little bit on
software like I did a little bit on
cleaning stuff up here did a lot
cleaning stuff up here did a lot
cleaning stuff up here. And uh we got it
cleaning stuff up here. And uh we got it
way better than, you know, than when we
way better than, you know, than when we
started, but there's still quite a lot
started, but there's still quite a lot
that's just
tough. Okay. So here we reproduce
tough. Okay. So here we reproduce
the we reproduce the back
the we reproduce the back
rate 987.
Oh, Kung's around. Perfect. Hey, Kung.
Oh, Kung's around. Perfect. Hey, Kung.
So, I we reproduced the batch success
So, I we reproduced the batch success
rate. Is there a way we can just like
rate. Is there a way we can just like
get random batches of motions without
get random batches of motions without
taking forever and just like see them
taking forever and just like see them
play so we can see if they're working?
That would be
ideal. Streaming. Looks like one minute
ideal. Streaming. Looks like one minute
delayed. It shouldn't
delayed. It shouldn't
be.
be.
Um, hang
Um, hang
on.
Oh, on this whole file.
Maybe this just
Maybe this just
works. Oh gosh.
It takes forever to
load. Oh, here it is.
You kind of
can't you can't move the camera, right?
Press left.
Press left.
Right.
Right.
Oh, thank you. Jump.
play shows you
16. So yeah, the sitting down one is
16. So yeah, the sitting down one is
like Oh, it actually even does that
like Oh, it actually even does that
sometimes. That's
sometimes. That's
crazy. Yeah, these are these look very
good. These look very good.
It looks to me like it works as is. I'm
It looks to me like it works as is. I'm
trying to figure out what the heck they
trying to figure out what the heck they
did now. They sent me a repo invite that
did now. They sent me a repo invite that
uh I can't show on
stream. Like they w they didn't give me
stream. Like they w they didn't give me
uh good information about like what it
uh good information about like what it
was that they like how it was that they
was that they like how it was that they
were trying to do stuff cuz like yeah,
were trying to do stuff cuz like yeah,
when we run your stuff it works as is.
The only thing that was rough, which is
The only thing that was rough, which is
why I had to bo, like why I started
why I had to bo, like why I started
bothering you about this, is I couldn't
bothering you about this, is I couldn't
get it to run initially. Um, I had to
get it to run initially. Um, I had to
modify the Docker container to have more
modify the Docker container to have more
memory or it would just crash. So, I was
memory or it would just crash. So, I was
like, okay, there's something screwy.
like, okay, there's something screwy.
And then when you only run like the
And then when you only run like the
first eval step or whatever, it shows
first eval step or whatever, it shows
zero success rate. I don't know why, but
zero success rate. I don't know why, but
then when you run the full data set, it
then when you run the full data set, it
shows way higher. To be clear, this is
shows way higher. To be clear, this is
not picking success motions out, right?
not picking success motions out, right?
This is just random
motions. Like there's occasionally nams,
motions. Like there's occasionally nams,
I guess, once in a while,
right? It looks
fine. Yeah, that's okay. Yeah, that's
fine. Yeah, that's okay. Yeah, that's
the thing Linky fixed, right? I got to
the thing Linky fixed, right? I got to
integrate all that stuff
in. I mean, that's pretty impressive,
in. I mean, that's pretty impressive,
right? That's like hard to
do. Most of them. Yeah, it's like 98 or
do. Most of them. Yeah, it's like 98 or
something percent.
Let me see if I can pull up this repo on
Let me see if I can pull up this repo on
in a separate tab and just see if
in a separate tab and just see if
there's
anything
Let's go over
here. They probably like doing something
here. They probably like doing something
spree with the loading.
Where do invites go?
See if I've gotten invites.
Oh, is
Oh, is
Hang on. This
is Let me see if this is open source. If
is Let me see if this is open source. If
it's open source, I can show
it's open source, I can show
it. It says it looks like they're
it. It says it looks like they're
intending to make it open source, but
um like they've got stuff in there like
um like they've got stuff in there like
that would imply that. But yeah. Okay. I
that would imply that. But yeah. Okay. I
think that they're going to release the
think that they're going to release the
thing with their modifications
soon. How would you upload these
soon. How would you upload these
movements to an actual
movements to an actual
robot? Um, so this is SNPL. You would
robot? Um, so this is SNPL. You would
have to do the same thing on like you
have to do the same thing on like you
would have to retarget the motions to
would have to retarget the motions to
uh to a robot like to the actual rig for
uh to a robot like to the actual rig for
the remote robot itself and then address
the remote robot itself and then address
like any weird Real stop.
See if there's anything I can
show. What's up with the Nans?
show. What's up with the Nans?
Presumably just diverging trajectories
Presumably just diverging trajectories
like the loss is going to be a squared
like the loss is going to be a squared
error. So as soon as the thing falls
error. So as soon as the thing falls
over, it just goes crazy.
Yeah, I'm doing
Yeah, I'm doing
uh RL pretty much 247 these
uh RL pretty much 247 these
days. Okay. Well, I don't think that
days. Okay. Well, I don't think that
there's too much I can do on the thing
there's too much I can do on the thing
for them now. Um, I kind of just got to
for them now. Um, I kind of just got to
chat with them at some point because
chat with them at some point because
like it looks like the code for this is
like it looks like the code for this is
fine, right? We get all the motions. The
fine, right? We get all the motions. The
motions look good.
Um, yeah, I don't see any issues. I
Um, yeah, I don't see any issues. I
mean, I would presume it's got to be
mean, I would presume it's got to be
like loading screw-ups, right? Like they
like loading screw-ups, right? Like they
have their own data formats and they're
have their own data formats and they're
doing a whole bunch of data conversions.
doing a whole bunch of data conversions.
there like a ton of places that you can
there like a ton of places that you can
get stuff wrong
there and like yeah, of course we'll
there and like yeah, of course we'll
help, but um I think that the thing that
help, but um I think that the thing that
we delivered
we delivered
matches what we were supposed to deliver
matches what we were supposed to deliver
here. I don't like I don't see anywhere
here. I don't like I don't see anywhere
where like oh actually the model's
where like oh actually the model's
screwy or anything weird like that. So
screwy or anything weird like that. So
I'm not too too concerned
there. So, as long as it's um that's
there. So, as long as it's um that's
taken care of, I'm happy at least. And
taken care of, I'm happy at least. And
then uh you know, if they need extra
then uh you know, if they need extra
help, I can deal with that as
help, I can deal with that as
separately. So, I guess we can go back
separately. So, I guess we can go back
to the merge
to the merge
stuff. There really isn't any impediment
stuff. There really isn't any impediment
now to merging,
now to merging,
right? It's 4:38. The only thing is like
right? It's 4:38. The only thing is like
I have an hour before I've got to run
I have an hour before I've got to run
for dinner. It's not a terrible thing.
for dinner. It's not a terrible thing.
Like the dev branch is broken anyways,
Like the dev branch is broken anyways,
right? It's not bad if I just do the
right? It's not bad if I just do the
merge and then start working on it and
merge and then start working on it and
get as far as I
get as far as I
can. I don't see any reason not to just
can. I don't see any reason not to just
do
that. Yeah, let's just do
that. Yeah, let's just do
that. Let me get my uh my original
that. Let me get my uh my original
Docker
back. So, now we'll actually get to some
back. So, now we'll actually get to some
interesting depth where I can actually
interesting depth where I can actually
show stuff.
I just wanted to make
I just wanted to make
sure that the thing that we delivered
sure that the thing that we delivered
was what we said it was. And it is
Just
Sorry.
Well, we can just do
merge. So, I'm going to have to
merge. So, I'm going to have to
immediately fix a ton of stuff with
immediately fix a ton of stuff with
this.
Um, not too well. That would be
Um, not too well. That would be
terrible. We do this first.
Big merch.
Okay. So, this is no big deal.
I'm gonna have to get Kung some robots
I'm gonna have to get Kung some robots
so like he can actually do
robotics. I wonder if I get him some
robotics. I wonder if I get him some
like some robot like some robots that he
like some robot like some robots that he
can remotely control.
can remotely control.
Maybe then I can get him to keep doing
Maybe then I can get him to keep doing
puffer dub
[Music]
stuff. Just like get him a whole ass
stuff. Just like get him a whole ass
unit tree or something that he can just
unit tree or something that he can just
like walk around the uh the puffer
like walk around the uh the puffer
facility. You can train the robot to
facility. You can train the robot to
like do cluster maintenance or
whatever or try to
Oops. Put a cam on it in the corner of
Oops. Put a cam on it in the corner of
your stream. Actually, the uh the new
your stream. Actually, the uh the new
stream is going to have a full view of
stream is going to have a full view of
the facility. It's going to be really
the facility. It's going to be really
cool. Have all the servers in the
background. It's nicely set up for that.
Feels good to be back on the dev branch.
Feels good to be back on the dev branch.
You have the oversized American flag
You have the oversized American flag
yet? We have one. I don't know if it's
yet? We have one. I don't know if it's
big enough. I think it's like a 15t
big enough. I think it's like a 15t
flag. I wanted to get like a 25 foot
flag. I wanted to get like a 25 foot
flag.
Okay. So,
Okay. So,
um, yeah, with the
bindings, there's like one annoying
bindings, there's like one annoying
thing.
I don't know why.
Um I guess cuz this is only a prototype.
Um I guess cuz this is only a prototype.
I thought you'd still be able to export
it. That's
weird. Yeah, this was supposed to be
optional like I can just comment this
optional like I can just comment this
for now and uh it'll
work. This is for grid
mostly. No, but we're not going to do it
mostly. No, but we're not going to do it
in a way that it'll conflict with each
in a way that it'll conflict with each
end,
man. Like we're going to find a better
man. Like we're going to find a better
way to do it.
Why is that
not rebuild all of it?
Is there a way to make it? Yeah, we
Is there a way to make it? Yeah, we
we'll figure it out,
right? Dash force. It's good to
know. Something seems sketchy there,
but what's happened here?
Yes. Right. Merger
Yes. Right. Merger
changes. All right. So, we do your
changes. All right. So, we do your
PR
next. This one,
right? Did you break snake in one of the
right? Did you break snake in one of the
recent ones?
Okay, you didn't PR it.
Good. Yeah, snake's kind of important.
Good. Yeah, snake's kind of important.
Like we use that one pretty often for
testing. A front. The
puffer. The puffer is quite
sizable. Puffer is indeed quite sizable.
Now we get to see
Now we get to see
um how all my new stuff works,
right? Presumably this is building
right? Presumably this is building
kernels.
or
something.
Yeah. Okay. So we can track
this pop
up. These guys messaged me at all. They
up. These guys messaged me at all. They
were supposed to tell me when they were
were supposed to tell me when they were
free to meet.
They just straight up didn't message
me at five. Yeah, it's
fine. Oh, also this is the latest Neural
fine. Oh, also this is the latest Neural
MMO 3 run with the new stuff. It's kind
MMO 3 run with the new stuff. It's kind
of
of
cool. So, you can
cool. So, you can
see right here. So, this is the old one
see right here. So, this is the old one
versus the new one, I guess.
versus the new one, I guess.
So you can see with the uh new advantage
So you can see with the uh new advantage
estimation, it's like a very
estimation, it's like a very
small but consistent upgrade. It's like
small but consistent upgrade. It's like
very small but
very small but
consistent. It's like across the whole
consistent. It's like across the whole
curve. It's just very slightly
above possibly a little more stable as
above possibly a little more stable as
well.
I believe this black one
is something have a name on
it. I believe that this one was just
it. I believe that this one was just
like bigger filters that I forgot to
like bigger filters that I forgot to
like add back
in. Yeah.
in. Yeah.
We'll get to that. No worries. I mean,
We'll get to that. No worries. I mean,
still this is good
soda.
soda.
So, this is our latest one.
So, this is our latest one.
Probably it's not
bad. Yeah, good
curve. 46 uh 864 is max, but yeah, it's
curve. 46 uh 864 is max, but yeah, it's
good. That's like basically full
self. That's like it dropped a point
self. That's like it dropped a point
once or
whatever. Um, I don't know, man.
Nobody knows how to write software
anymore. Okay. palm
anymore. Okay. palm
frames and then jumps to full sol 21's
frames and then jumps to full sol 21's
full
Good. Okay. So snake is not training
Good. Okay. So snake is not training
correctly, but I saw this in my branch
correctly, but I saw this in my branch
before. There
is there's like an inconsistency. I
think Yeah, there's some like weird
think Yeah, there's some like weird
inconsistency when you use um
inconsistency when you use um
multiprocessing with this.
like that took it way longer. To be
like that took it way longer. To be
fair, it's not bad actually. That just
fair, it's not bad actually. That just
like the curve is shallower early, but
like the curve is shallower early, but
that's where it should end
up. This is fine, right?
all the way
all the way
500. It is going to dip a little bit.
500. It is going to dip a little bit.
That's normal though. It shouldn't fully
That's normal though. It shouldn't fully
crack, but it'll dip into 70s
crack, but it'll dip into 70s
sometimes. It's like a competitive
sometimes. It's like a competitive
selfplay M, right? So, dynamics are kind
selfplay M, right? So, dynamics are kind
of dependent on all the other agents
of dependent on all the other agents
what they're
what they're
doing. Yeah. Go ahead, link your run.
This branch has some slightly better
This branch has some slightly better
stuff though than
stuff though than
um previous. Oh, we're also not using
um previous. Oh, we're also not using
puffer advantage
here. We should set this to true by
here. We should set this to true by
default.
Yeah. So, that's not good,
Yeah. So, that's not good,
right? I think this was before I fixed
right? I think this was before I fixed
uh there were a few things that I fixed
uh there were a few things that I fixed
since
since
then. I mean, obviously, like you didn't
then. I mean, obviously, like you didn't
get 80 And we have 80s
get 80 And we have 80s
here. This seems good to
me. Let's set puff advantage
true. I ran that yesterday. Yeah, you
true. I ran that yesterday. Yeah, you
ran it on dev branch though, not on
ran it on dev branch though, not on
buffer branch,
right? Like I had to fix some bugs.
So, this is
So, this is
good. Let's try it with software
good. Let's try it with software
advantage just to be sure.
So I I changed the default to use puffer
So I I changed the default to use puffer
advantage. Now
that goes wrong with
score. Oh, there we go. Oh, that
score. Oh, there we go. Oh, that
actually fixed it. The puffer advantage
actually fixed it. The puffer advantage
version actually trains way more
version actually trains way more
stably. Puffer advantage for the win.
Offer advantage for the win.
We
We
evalid. Uh
evalid. Uh
yeah, presumably this is saved a
yeah, presumably this is saved a
checkpoint by now, right?
these look good,
right? Full snake
ends. Does this Does have Dion
on? No, it doesn't have Dion on.
on? No, it doesn't have Dion on.
Perfect. Yeah, that's just base
Perfect. Yeah, that's just base
training. So, yeah, this is proper
training. So, yeah, this is proper
snake. I like this emblem a lot. It's
snake. I like this emblem a lot. It's
like a really It was a really simple to
like a really It was a really simple to
code in, but it's really nice for
code in, but it's really nice for
testing and it looks really
cool. Like really, if you just get ideas
cool. Like really, if you just get ideas
for cool projects like this, you can
for cool projects like this, you can
talk these out in a couple of days and
talk these out in a couple of days and
like have them in puffer lib. So for any
like have them in puffer lib. So for any
folks watching if you want to contribute
folks watching if you want to contribute
to puffer liib something like this is a
to puffer liib something like this is a
few hundred lines of
few hundred lines of
code like maybe 200 lines of actual
logic and this has been like one of the
logic and this has been like one of the
most useful test
most useful test
ends. This was actually I think this was
ends. This was actually I think this was
the
the
first and I wrote fullc as
well. Pretty
cool. Okay. Um MMO rework. That's kind
cool. Okay. Um MMO rework. That's kind
of important, right?
415K. Not
bad. So, yeah, this is good overall as
bad. So, yeah, this is good overall as
well. I think there's still a few MS
well. I think there's still a few MS
that are kind of busted, but this is
that are kind of busted, but this is
overall
overall
um this is overall quite good.
It's 502. Uh, if I wake myself up, I
It's 502. Uh, if I wake myself up, I
think we can do a little bit more cool
think we can do a little bit more cool
dev stuff
today. I don't have mental bandwidth.
today. I don't have mental bandwidth.
Long short, what is it? Fast blow RNN's
Long short, what is it? Fast blow RNN's
today. That's going to take like I'm
today. That's going to take like I'm
gonna have to be fresher for that. But I
gonna have to be fresher for that. But I
think we can do some dying experiments
think we can do some dying experiments
and see on that.
So, we'll do some uh we'll do some like
So, we'll do some uh we'll do some like
cool like
cool like
multi- was it like behavior conditioned
multi- was it like behavior conditioned
or skill condition policy experiments in
or skill condition policy experiments in
a second. Use the restroom and grab a
a second. Use the restroom and grab a
drink though and I'll be right back.
drink though and I'll be right back.
Give me like two three Yes.
Got a brief
Got a brief
spiral. Want to
spiral. Want to
merge blast star pool.
merge blast star pool.
Yeah, let me do that bit. And we'll do
Yeah, let me do that bit. And we'll do
the experiments.
First square tactical. Let me get
this. Oh, also since we're on the repo,
this. Oh, also since we're on the repo,
if you haven't started the repo, what do
if you haven't started the repo, what do
you do? It like it really helps us. Come
you do? It like it really helps us. Come
on, guys. We're almost at
2K. This one.
Yeah. Okay. New binding
file that second. So, don't merge this
file that second. So, don't merge this
first.
Okay.
puffer color is
good. Presumably, you're not looking for
good. Presumably, you're not looking for
feedback considering it's like it's a
feedback considering it's like it's a
pretty clearcut what the work is, right?
Yeah. And we need to figure out how to
Yeah. And we need to figure out how to
reduce boiler plate even more. But like
reduce boiler plate even more. But like
the new binding stuff is already a
the new binding stuff is already a
pretty darn good dent in the amount of
pretty darn good dent in the amount of
boiler plate, right? Like most of the PR
boiler plate, right? Like most of the PR
was deleting boiler plate. Very little
was deleting boiler plate. Very little
of it was adding it
back. Okay. Thank you for
back. Okay. Thank you for
PR next to PR. Oh, I didn't merge it,
PR next to PR. Oh, I didn't merge it,
did
I? Plus, plus I do this stuff. Oh, very
I? Plus, plus I do this stuff. Oh, very
nice. What's
that? I wish somebody would finish
that? I wish somebody would finish
tactical. That's a little too much for
tactical. That's a little too much for
you at the moment, bet. But
you at the moment, bet. But
um it could be a really nice end.
Yeah. So, you just messed with the
Yeah. So, you just messed with the
client a little bit,
client a little bit,
right? And
this change to client is
fine. Yeah, but it would take you quite
fine. Yeah, but it would take you quite
a while because there's like a lot of
a while because there's like a lot of
stuff going
on. I I think that The thing you would
on. I I think that The thing you would
get stuck on most likely would be the
get stuck on most likely would be the
um there's actually like probably some
um there's actually like probably some
scripted AI stuff that you'd have to do
scripted AI stuff that you'd have to do
with this, which to be fair is a great
with this, which to be fair is a great
thing to learn, but it's it's kind of
tricky. Scripted like doing scripted AI
tricky. Scripted like doing scripted AI
is honestly one of the best way to learn
is honestly one of the best way to learn
algorithm stuff.
algorithm stuff.
like because it's a ton of path finding.
like because it's a ton of path finding.
You occasionally do like mon Carlo
You occasionally do like mon Carlo
stuff. It's like search. They're like
stuff. It's like search. They're like
it's actually like a really good way to
it's actually like a really good way to
learn algo stuff, but like yeah, this
learn algo stuff, but like yeah, this
would be a bit much. Like you'd kind of
would be a bit much. Like you'd kind of
just be stuck doing this for a long
time. Like that's one of the things
time. Like that's one of the things
where it actually kind of helps to have
where it actually kind of helps to have
seen the algorithms done
seen the algorithms done
formally, right? So you're not just
formally, right? So you're not just
reading freaking Wikipedia articles.
This is just a find and replace on
This is just a find and replace on
client,
client,
right? Yeah, it totally is.
Maling
text and know that's like where you like
text and know that's like where you like
your first CS course or whatever like
your first CS course or whatever like
your first undergrad CS course or
your first undergrad CS course or
whatever usually just does
whatever usually just does
that covers all the data structures and
that covers all the data structures and
algorithms and then there's like very
algorithms and then there's like very
much diminishing it returns to
much diminishing it returns to
formalized learning after that but it's
formalized learning after that but it's
a decent base
So the 101's are kind of [ __ ] cuz a lot
So the 101's are kind of [ __ ] cuz a lot
of the first courses in CS are taught in
of the first courses in CS are taught in
Java or something just awful.
Um, I'm trying to think with the scale
Um, I'm trying to think with the scale
of stuff that you've
written. I'm trying to think if you know
written. I'm trying to think if you know
more or less CS than I
more or less CS than I
did before my freshman year.
Like I'd probably spent more time
Like I'd probably spent more time
writing code than you have by
writing code than you have by
then, but also
then, but also
like I was doing it without any form of
like I was doing it without any form of
reasonable guidance and I was just doing
reasonable guidance and I was just doing
stupid [ __ ] half the
time. So, it's kind of actually tough to
time. So, it's kind of actually tough to
say. I'll link you the course
say. I'll link you the course
afterwards. It's just 106x
I mean, there are like some obnoxious
I mean, there are like some obnoxious
things like it's taught in
things like it's taught in
C++ which is kind of
C++ which is kind of
shitty and like the lecture isn't very
shitty and like the lecture isn't very
good to be honest. The course material
good to be honest. The course material
is pretty good. The lecturer really
is pretty good. The lecturer really
isn't.
But
But
like I don't know if anybody knows if
like I don't know if anybody knows if
there's a university that has a better
there's a university that has a better
course than this, but
like they use their own shitty libraries
like they use their own shitty libraries
as well which is like it's annoying then
as well which is like it's annoying then
but yeah if you look at the assignments
but yeah if you look at the assignments
it's like implement game of life ads
boggle priority queue like these are
boggle priority queue like these are
good
good
things to implement but then that like
things to implement but then that like
the obnoxious thing about it is like so
the obnoxious thing about it is like so
you're like you open this [ __ ]
Right. This is the thing that always
Right. This is the thing that always
drove me [ __ ] crazy with
their unless it's
their unless it's
improved. Oh, actually this is better
improved. Oh, actually this is better
than it used to
be. I guess like they give you this
be. I guess like they give you this
obnoxious graphics
obnoxious graphics
library. This isn't that bad though.
library. This isn't that bad though.
So, one of my big complaints when I took
So, one of my big complaints when I took
it was they just gave you way too much
it was they just gave you way too much
starter code for [ __ ] So, like half the
starter code for [ __ ] So, like half the
assignment wasn't even implement X. It
assignment wasn't even implement X. It
was like figure out what their garbage
was like figure out what their garbage
starter code
starter code
does, which just drove me [ __ ]
does, which just drove me [ __ ]
nuts. But like this is stuff that you
nuts. But like this is stuff that you
generally should see in a formal
generally should see in a formal
setting.
Also, this course is intend this course
Also, this course is intend this course
is intended to be hard, by the way.
is intended to be hard, by the way.
Um, like this is usually the thing that
Um, like this is usually the thing that
most Stanford freshmen end up spending
most Stanford freshmen end up spending
20 hours a week
20 hours a week
on at least. Well, not really. 15 to 15
on at least. Well, not really. 15 to 15
to 25 hours a week.
It's a bunch of data structure stuff
that that's like very confusing when you
that that's like very confusing when you
see it for the first time.
Okay. So everything should be
merged. And we should still have a
merged. And we should still have a
little bit of time to a couple
experiments. I want to see what version
experiments. I want to see what version
I left in here.
Okay. So I want the other form of
this and I want the other form of this.
this and I want the other form of this.
So I basically there are two different
So I basically there are two different
forms of this algorithm I was
forms of this algorithm I was
experimenting with. One of them they
experimenting with. One of them they
both work on se on subsampled sequences.
both work on se on subsampled sequences.
So in one of them you take all the
So in one of them you take all the
observations from the trajectory
observations from the trajectory
segment. You down sample by a factor of
segment. You down sample by a factor of
eight. So you just take every eighth
eight. So you just take every eighth
sample, you run it through a little bit,
sample, you run it through a little bit,
a little model and you try to estimate
a little model and you try to estimate
which policy uh this segment came from.
which policy uh this segment came from.
So by what the agent was doing like
So by what the agent was doing like
which policy is
which policy is
this? The other form is you do the same
this? The other form is you do the same
thing except you use actions instead of
thing except you use actions instead of
states. So just by looking at the
states. So just by looking at the
sequence of actions the agent take uh
sequence of actions the agent take uh
took what policy is it? Uh the state one
took what policy is it? Uh the state one
is much more powerful, but you have to
is much more powerful, but you have to
do reinforcement learning to learn that
do reinforcement learning to learn that
objective. The the actionbased
objective. The the actionbased
formulation is a lot weaker because
formulation is a lot weaker because
you're only seeing the actions without
you're only seeing the actions without
the context of state, but it's fully
the context of state, but it's fully
differentiable. So you don't have to do
differentiable. So you don't have to do
RL. It's a supervised learning
RL. It's a supervised learning
task, which makes it really
easy. Actually, isn't this entire
thing? Yeah, this entire thing is
thing? Yeah, this entire thing is
redundant. If we're going to do the
redundant. If we're going to do the
other
version, wait,
what? Oh, I guess I just like moved the
what? Oh, I guess I just like moved the
previous. Yeah, that's fine. Just do
previous. Yeah, that's fine. Just do
this. It's basically the same
thing. State batch logs.
This isn't the spot for this boss to
go. I think I made a commit with the
go. I think I made a commit with the
exact version that I needed at some
exact version that I needed at some
point recently.
Where is this
thing? I know. I gave it a
thing? I know. I gave it a
decent commit message as
well. Dang. Okay. Well, we'll just redo
well. Dang. Okay. Well, we'll just redo
it. It's not a big
deal. It should just be like
something like that.
Yeah, something like
this. Then all we have to do
is discriminator here needs to not
is discriminator here needs to not
be this. It needs to be acting face
be this. It needs to be acting face
shape.
action space.
Then just trim forward. I think I
Then just trim forward. I think I
actually was doing this on snake before.
actually was doing this on snake before.
Why don't we just do it over
there? Just put this
model. Yeah. So there it is.
model. Yeah. So there it is.
You can see this was the supposed to be
You can see this was the supposed to be
the state based one or whatever.
That looks good to me. You just give it
That looks good to me. You just give it
like a little two layer net.
And this should have a brim forward,
And this should have a brim forward,
right? Maybe
snake. This
So this needs to get reshaped I
believe. Where is this getting called
believe. Where is this getting called
wrong?
Right. So,
Right. So,
uh this is not needed here. This is the
uh this is not needed here. This is the
other version of it.
This is 128x 64x4.
This is how you do
this. There was like a whole bunch of
this. There was like a whole bunch of
stuff I would do with this as well
stuff I would do with this as well
actually.
Yeah. Was
this I
I think I actually just put this into a
I think I actually just put this into a
soft max, didn't
soft max, didn't
I? Yeah, I think we just put this into
I? Yeah, I think we just put this into
softmax.
Let's see what this gives
Let's see what this gives
us. Welcome YouTube folks. We have quite
us. Welcome YouTube folks. We have quite
a fair few people watching this at the
a fair few people watching this at the
moment. I'm here for another 15 minutes
moment. I'm here for another 15 minutes
and then I probably will be back after
and then I probably will be back after
dinner. We'll see. But uh what this is
dinner. We'll see. But uh what this is
at the moment, this is diversity is all
at the moment, this is diversity is all
you need name of algo. um it works by
you need name of algo. um it works by
adding a one hot vector to the
adding a one hot vector to the
observation space of your agent uh that
observation space of your agent uh that
is representing a skill. So you come up
is representing a skill. So you come up
with eight skills for instance and you
with eight skills for instance and you
give each agent a skill vector and then
give each agent a skill vector and then
what you try to do is you try to train a
what you try to do is you try to train a
separate network that predicts which
separate network that predicts which
agent uh it is like which skill vector
agent uh it is like which skill vector
it actually has based on what the agent
it actually has based on what the agent
does. So in doing that you try to create
does. So in doing that you try to create
a policy that can behave in many
a policy that can behave in many
different distinguishable ways. So you
different distinguishable ways. So you
have one policy that can take lots of
have one policy that can take lots of
different sort of types of play. That's
different sort of types of play. That's
what we're doing at the moment. Uh this
what we're doing at the moment. Uh this
is actually now in the dev branch as
is actually now in the dev branch as
well of puffer. So you can check it out
well of puffer. So you can check it out
there and do start the repo. It helps me
there and do start the repo. It helps me
a
ton. Fix grid reset. Grid reset is kind
ton. Fix grid reset. Grid reset is kind
of hard. Uh, Bridge is the one that
of hard. Uh, Bridge is the one that
needs the shared stuff,
but I want to at least see if I can get
but I want to at least see if I can get
this to work as well because this is
this to work as well because this is
going to be more
entertaining. Okay, so this is 32 input
entertaining. Okay, so this is 32 input
dim,
right?
right?
Reasonable. Mostly reasonable.
Uh, grid is the one that has the shared
Uh, grid is the one that has the shared
thing
that
mute. That's a weird
error. Just scrim forward.
Really? Oh, probably the one hop, right?
Okay, this
Okay, this
runs. Put on Neptune.
So the one thing with this is that the
So the one thing with this is that the
uh the loss is usually like really
uh the loss is usually like really
really low. The neural net is really
really low. The neural net is really
good at figuring out which agent has
good at figuring out which agent has
which skill vector.
that goes up a little bit
sometimes. So, we will see what this
does. There
does. There
are So, here's the thing that I was
are So, here's the thing that I was
trying to figure out with this
trying to figure out with this
algorithm, right? I pulled up the paper.
algorithm, right? I pulled up the paper.
needs. So, okay. Let
needs. So, okay. Let
me So, it's this paper right here. It's
me So, it's this paper right here. It's
a pretty cool paper. Uh the math in here
a pretty cool paper. Uh the math in here
is like makes it sound way more
is like makes it sound way more
complicated than it
complicated than it
is. This is kind of the algorithm
is. This is kind of the algorithm
here. This math is like pretty
here. This math is like pretty
redundant. The thing is that there are
redundant. The thing is that there are
if you like look at this, there are some
if you like look at this, there are some
obvious extensions of this and like the
obvious extensions of this and like the
original form is not great. So I kind of
original form is not great. So I kind of
took the idea of
took the idea of
conditioning an agent with a skill
conditioning an agent with a skill
vector in order to distinguish between
vector in order to distinguish between
different uh different
different uh different
behaviors and I instead of doing it on
behaviors and I instead of doing it on
the transition level I do it at the
the transition level I do it at the
segment
segment
level. So uh you take the whole like
level. So uh you take the whole like
64st step segment or something like
64st step segment or something like
that,
that,
right? And you just take uh you down
right? And you just take uh you down
sample it, you pass it into the
sample it, you pass it into the
discriminator and then you determine
discriminator and then you determine
what policy it is based on that.
Now, what I would really like to do
Now, what I would really like to do
ideally is I'd like to have some way of
ideally is I'd like to have some way of
defining a supervised loss that takes
defining a supervised loss that takes
into account the agent actions and the
into account the agent actions and the
agent observations or even just the
agent observations or even just the
agent
agent
observations. But the thing is like
observations. But the thing is like
observations are not
observations are not
differentiable and there's no way that
differentiable and there's no way that
observations directly are differentiably
observations directly are differentiably
affect the policy.
affect the policy.
So if you try to do it this way, you
So if you try to do it this way, you
need to use reinforcement learning to
need to use reinforcement learning to
learn which skill belongs to which
learn which skill belongs to which
agent. And like yeah, we do
agent. And like yeah, we do
reinforcement learning all day, but
reinforcement learning all day, but
ideally we don't have to add a secondary
ideally we don't have to add a secondary
RL objective into what is already an RL
RL objective into what is already an RL
problem. It's a lot cleaner and a lot
problem. It's a lot cleaner and a lot
easier to learn if you can just like add
easier to learn if you can just like add
it as an auxiliary loss
it as an auxiliary loss
basically that is supervised.
This is doing some weird interesting
things. It's definitely doing some weird
things. It's definitely doing some weird
interesting
things. How's the Dian
loss? It's just been very low the whole
loss? It's just been very low the whole
time.
I mean, it's gone back up now,
right? That snake, that is my curve from
right? That snake, that is my curve from
yesterday. The curve that you sent me
yesterday. The curve that you sent me
was in the
30s. There's a big difference between
30s. There's a big difference between
this curve being in the 30s and then
this curve being in the 30s and then
this curve being like up around here,
right? I think I will just have enough
right? I think I will just have enough
time to like get this result and then
time to like get this result and then
look at it a little bit.
shape is similar but shape that is a
shape is similar but shape that is a
reasonable shape for snake often
reasonable shape for snake often
times. Let me make sure the roll out is
times. Let me make sure the roll out is
going to be there. So we can look at
going to be there. So we can look at
these. Now the problem with this right
these. Now the problem with this right
the problem with the actionbased
the problem with the actionbased
formulation
formulation
um is that the neural net can very very
um is that the neural net can very very
accurately tell apart which agents are
accurately tell apart which agents are
doing what but we can't always so we'd
doing what but we can't always so we'd
really like it to be highle
really like it to be highle
distinguishable skills but that's very
distinguishable skills but that's very
difficult to convey right what does it
difficult to convey right what does it
mean to have highle differentiable
mean to have highle differentiable
skills that's pretty hard so this will
skills that's pretty hard so this will
be done in two minutes which will be
be done in two minutes which will be
perfect timing because we'll just we'll
perfect timing because we'll just we'll
see this we'll see the results we'll see
see this we'll see the results we'll see
what the policy is
what the policy is
And then I will uh get ready to go to
And then I will uh get ready to go to
dinner out to dinner with some
family. To be fair, that is like a nice
family. To be fair, that is like a nice
stable
stable
curve. This dip is very common as well.
curve. This dip is very common as well.
Like I've seen this even without this
Like I've seen this even without this
algorithm before. It's just like all the
algorithm before. It's just like all the
agents learn how to do stuff. Oh, shoot.
agents learn how to do stuff. Oh, shoot.
All my opponents are kind of smart now.
All my opponents are kind of smart now.
And then they kind of like figure stuff
out. Okay, we are going to see these
out. Okay, we are going to see these
results, but I will do outro stuff now
results, but I will do outro stuff now
uh before results while this finishes
uh before results while this finishes
because we do have like nine or 10 folks
because we do have like nine or 10 folks
watching now. Uh, so if you're
watching now. Uh, so if you're
interested in all this stuff, it's all
interested in all this stuff, it's all
open source reinforcement learning. You
open source reinforcement learning. You
can check it out on GitHub, start the
can check it out on GitHub, start the
repo, help me out, tough.ai. If you want
repo, help me out, tough.ai. If you want
to get involved in dev, join the
to get involved in dev, join the
Discord. Most of our top contributors
Discord. Most of our top contributors
came in with zero RL experience. Like,
came in with zero RL experience. Like,
we're happy to show you the ropes and it
we're happy to show you the ropes and it
really doesn't take much before you can
really doesn't take much before you can
start contributing really cool stuff to
start contributing really cool stuff to
this. Uh, and you can also follow me on
this. Uh, and you can also follow me on
X for more RL content. We've got a quick
X for more RL content. We've got a quick
start guide on the blog as well as on X
start guide on the blog as well as on X
that I really recommend to new folks,
that I really recommend to new folks,
but uh there's more on X as well. Okay,
but uh there's more on X as well. Okay,
let's work
let's work
on almost there. Let's see what this
on almost there. Let's see what this
policy
does. So close to 2K stars as well. Like
does. So close to 2K stars as well. Like
just a few
just a few
more. 2K is a huge repo in RL.
more. 2K is a huge repo in RL.
like I'm pretty happy with
like I'm pretty happy with
it. Thanks for the link.
Bet 92. Okay, that's actually a very
Bet 92. Okay, that's actually a very
good score. And that was like a pretty
good score. And that was like a pretty
stable
So each color should be a different
scale. The model can tell these apart
scale. The model can tell these apart
like perfectly.
like perfectly.
is the other funny thing about
this. First of all, this is just like a
this. First of all, this is just like a
very good
model. But the model can tell these
model. But the model can tell these
apart perfectly just by looking at the
apart perfectly just by looking at the
actions that each one of these is
actions that each one of these is
taking. Not even looking at their
taking. Not even looking at their
surroundings, just looking at the
surroundings, just looking at the
actions that each one of these is
actions that each one of these is
taking.
Um, I can't personally say for sure
Um, I can't personally say for sure
which a how each agent is different
here. But also, this might not be the
here. But also, this might not be the
best end for testing that, right? We
best end for testing that, right? We
could probably come up with some ends
could probably come up with some ends
where it would be a lot more
where it would be a lot more
clear, like the play style difference
clear, like the play style difference
maybe.
they're doing. Yeah, this is 90. This is
they're doing. Yeah, this is 90. This is
92 score. So, this is very
good. We will continue doing research on
good. We will continue doing research on
this, I think, over the next couple of
this, I think, over the next couple of
days. Like, this is one of the things we
days. Like, this is one of the things we
definitely want to uh we definitely want
definitely want to uh we definitely want
to include in the stuff that we're
to include in the stuff that we're
looking at. So very likely that this
looking at. So very likely that this
will be part of Puffer in some
will be part of Puffer in some
way. So yeah, thank you folks for tuning
way. So yeah, thank you folks for tuning
in. I will probably be back after
in. I will probably be back after
dinner. puffer.ai for all the things.
And uh Discord is just discord

Kind: captions
Language: en
for a little bit here.
for a little bit here.
Um, got a meeting that should have
Um, got a meeting that should have
happened,
happened,
but I guess I'll uh it's gotten
but I guess I'll uh it's gotten
postponed a bit. So, I don't know how
postponed a bit. So, I don't know how
long I'm going to be live for right now,
long I'm going to be live for right now,
but I figured we'd at least see if we
but I figured we'd at least see if we
can get a short stream in for a bit of
can get a short stream in for a bit of
work. Hang on. Let me make sure this
work. Hang on. Let me make sure this
thing's working and then I'll talk about
thing's working and then I'll talk about
what I want to do. Yeah, this works.
what I want to do. Yeah, this works.
Cool. So uh I want to do
Cool. So uh I want to do
something kind of similar to phasic
something kind of similar to phasic
policy
policy
gradients. I have
maybe 50% confidence at best that this
maybe 50% confidence at best that this
is going to actually be useful, but um
is going to actually be useful, but um
we're kind of at a spot where it would
we're kind of at a spot where it would
be relatively easy to add.
be relatively easy to add.
So, I I sort of just want to do it and
see. That better not be Yeah. Okay,
see. That better not be Yeah. Okay,
we're
good. Something like this.
Oops.
little scattered
little scattered
today. Yesterday was like just cranking
today. Yesterday was like just cranking
cranking on work and I'm a little
cranking on work and I'm a little
scattered today. I had to catch up on
scattered today. I had to catch up on
meetings and stuff. Um, all right. So we
meetings and stuff. Um, all right. So we
get ppg epox
get ppg epox
here and then the only thing that we
here and then the only thing that we
have to really add to this
have to really add to this
uh to make this
uh to make this
work is this like extra
work is this like extra
phase after
phase after
training. You know, technically I think
training. You know, technically I think
that I can just
that I can just
do I just want to test something quick,
do I just want to test something quick,
right? Probably just copy paste a lot of
this. It's a little awkward.
It is a little awkward.
I guess we do just literally paste for
I guess we do just literally paste for
now. We just repaste
this and we'll just like delete
stuff. So all the freaking code
We'll like remove all the sections we
We'll like remove all the sections we
don't need at least and then we'll come
don't need at least and then we'll come
up with a cleaner way to do it if
um well we'll come up with a cleaner way
um well we'll come up with a cleaner way
to do it if it
works.
This
Let's do a little minimal version of
it. Does need
it. Does need
this. Doesn't really need
this. And we don't really have kale
this. And we don't really have kale
target.
This is the third person I've had asking
This is the third person I've had asking
me about hierarchical RL this
me about hierarchical RL this
week. I guess we will have to do
week. I guess we will have to do
something in that
area. I think we're just going to do the
area. I think we're just going to do the
simple thing though like fast slow LSTM.
simple thing though like fast slow LSTM.
That I actually think will work. That
That I actually think will work. That
should just be like free win.
implementation's a little tricky. I have
implementation's a little tricky. I have
to think about it.
So the only thing that's really
So the only thing that's really
different with
different with
the iterations here,
right, as you do this like K loss
And of course I now I get the right as
And of course I now I get the right as
soon as I start streaming I get meeting
soon as I start streaming I get meeting
call. Okay. Um let me see. I think I'm
call. Okay. Um let me see. I think I'm
going to have to just go take this and
going to have to just go take this and
this will be just like a quick 10-minute
this will be just like a quick 10-minute
thing and then I'll come back and get to
this. Let me make sure.
Okay. No, they're going to they're at
Okay. No, they're going to they're at
lunch now. So, we we will keep
lunch now. So, we we will keep
streaming.
streaming.
Cool.
Cool.
Perfect. So, we will get uh to finish
Perfect. So, we will get uh to finish
this
This is kind of it, isn't
it? Oh, yeah. The one thing that we
it? Oh, yeah. The one thing that we
forgot here, the annoying bit,
forgot here, the annoying bit,
right? So, you have to do
You actually like need to do this thing
again. Maybe just this block.
You have to like recmp compute logits on
You have to like recmp compute logits on
everything in the data
set. I think how we would do that.
Oh, actually this is kind of easy, isn't
it? Yeah, this is kind of
easy. At least to do this as a hack is
easy. At least to do this as a hack is
kind of
easy. We just need to go through the
easy. We just need to go through the
full data set here. Uh, I wrote it in a
full data set here. Uh, I wrote it in a
way where it's a little awkward to do
way where it's a little awkward to do
that, but I can just
do something like this.
something like
something like
this. And then what we do
this. And then what we do
is experience
dot log props of
dot log props of
index. It's set to new log
index. It's set to new log
props. I think that's the only thing we
props. I think that's the only thing we
need, right?
the
the
heck. Hang
on. I assume that's just a battery
on. I assume that's just a battery
test. That's weird.
Somebody's trying to get my
attention. No, just a battery test, I
guess. All right. So, um,
I think this is just
it. Forgot state. I'm sorry.
state.
Hang on. I think I screwed something up
Hang on. I think I screwed something up
here.
Yeah, I totally screwed this up.
Um, this can be and samples and this
Um, this can be and samples and this
is data experience.
We don't even need this.
deal with one message.
This is still totally screwed, right?
Pretty much all I'm trying to do here is
Pretty much all I'm trying to do here is
I'm just trying to hack this super quick
I'm just trying to hack this super quick
so that we can do regular PO EPO eval
so that we can do regular PO EPO eval
the entire data set or the entire batch
the entire data set or the entire batch
so that we can update the log props and
so that we can update the log props and
then run additional value function
then run additional value function
training. That's all I'm trying to
do. Yeah. Okay. So, this seems like this
do. Yeah. Okay. So, this seems like this
is
is
fine. Why is log props like
fine. Why is log props like
that? Wait, why is
Oh
Oh
shoot. You need log. It's not log prop,
right? So what you need is
It's something like this experience
It's something like this experience
rows and
then like
that. See if that runs.
It doesn't matter if this is a hack. I
It doesn't matter if this is a hack. I
just need to like have something that I
just need to like have something that I
can test this with for now. And then I
can test this with for now. And then I
like if this is actually good, then I
like if this is actually good, then I
will think about how I can do this
will think about how I can do this
without reading a ton of code.
Okay, so that actually
Okay, so that actually
runs. Um, we need to
now so this needs to get
now so this needs to get
normed. Where's the KL
normed. Where's the KL
here? Yeah. Okay. So, this is this can't
here? Yeah. Okay. So, this is this can't
be bash.log props. So, ppg log props
be bash.log props. So, ppg log props
equals all
equals all
logs
logs
idx. Then this has got to be this is not
idx. Then this has got to be this is not
new log
new log
prop. This is
logs logs.
Something like this, I
Something like this, I
think. We'll see how this does.
It's probably better to
have first of
all
all
patch and then
I actually don't know how this is going
I actually don't know how this is going
to work back. We'll
see. Okay. Is this obviously wrong or
not? Seems pretty wrong, right?
Okay. So, that doesn't work, right?
Okay. So, this doesn't make sense
Okay. So, this doesn't make sense
because like
somehow we've somehow like broken
this. We didn't mess up the
this. We didn't mess up the
scheduleuler.
We just comment
We just comment
this whole block. It should work
right. Yeah. So if you just comment this
right. Yeah. So if you just comment this
lock out. It works. So, we're clearly
lock out. It works. So, we're clearly
just breaking something
just breaking something
because this shouldn't even be
because this shouldn't even be
optimizing anything with the loss of
optimizing anything with the loss of
zero. So, like some variables getting
zero. So, like some variables getting
updated that shouldn't
be. Where's this lined up?
That's lined up
correctly. Welcome YouTube folks. So
correctly. Welcome YouTube folks. So
what this is
what this is
here uh I am currently attempting to
do some weird hodge podgeic policy
do some weird hodge podgeic policy
gradients.
This thing separates policy learning
This thing separates policy learning
from value learning. It's kind of slow
from value learning. It's kind of slow
though. So I was coming up with a
though. So I was coming up with a
version of this that lets you just do PO
version of this that lets you just do PO
for one epoch because they say that you
for one epoch because they say that you
don't really benefit beyond one epoch
don't really benefit beyond one epoch
except for training the value function
except for training the value function
and that let you do more epochs on the
and that let you do more epochs on the
value function using the ppg style
value function using the ppg style
loss. So that's what I'm currently
loss. So that's what I'm currently
trying. I have no idea if this works. I
trying. I have no idea if this works. I
do know that the current version uh it
do know that the current version uh it
should work better than this. So I'm
should work better than this. So I'm
somehow breaking it here. So goal here
somehow breaking it here. So goal here
is just to see if we get anything out of
is just to see if we get anything out of
this. This is kind of like a invest a
this. This is kind of like a invest a
few hours, see if anything works kind of
few hours, see if anything works kind of
a
gig. If it did work, best case result
gig. If it did work, best case result
would be that uh this lets us get more
would be that uh this lets us get more
sample efficient learning when we want
sample efficient learning when we want
it and then have exactly the same
it and then have exactly the same
behavior and per as po uh when we don't
behavior and per as po uh when we don't
want to crank up compute.
Let me see what variables would be
Let me see what variables would be
getting overwritten in
place. Maybe that's
place. Maybe that's
This should get zeroed anyways
though. It should be getting zeroed
though. It should be getting zeroed
anyways. Yeah.
I don't know why we do
this. It should be up
this. It should be up
top. What language do you use? Just
Abuntu. We tried running Debian on the
Abuntu. We tried running Debian on the
servers was more of a pain in the ass
servers was more of a pain in the ass
than
abundu. I ran like a crazy custom arch
abundu. I ran like a crazy custom arch
setup during my cringe undergrad
setup during my cringe undergrad
years. Uh now we just just a bunt
years. Uh now we just just a bunt
two. It honestly really doesn't matter
two. It honestly really doesn't matter
that much cuz like all the dev is
that much cuz like all the dev is
containerized
containerized
anyways. like this. I'm editing this
anyways. like this. I'm editing this
locally on this machine, but inside of a
locally on this machine, but inside of a
container that's identical to the
container that's identical to the
container that'll run on our servers.
So like host OS doesn't really matter
So like host OS doesn't really matter
that much except for it being a pain in
that much except for it being a pain in
the ass to get drivers correct on some
the ass to get drivers correct on some
of them.
Okay, let me just sanity a thing because
like Yeah, let me just sanity a thing.
Okay, this does work,
right? So, what the heck
right? So, what the heck
is there? Shouldn't even be a loss
is there? Shouldn't even be a loss
here. It's zero, right?
Oh
man. That'll do
it. Wise lost man.
Does KL explode if um the distributions
Does KL explode if um the distributions
are
identical? Shouldn't, right?
identical? Shouldn't, right?
Hang
on. What app or program are you doing?
on. What app or program are you doing?
I'm here. New
I'm here. New
here. So, this is I work on
here. So, this is I work on
reinforcement learning dev full-time.
reinforcement learning dev full-time.
It's all at puffer.ai.
It's all at puffer.ai.
We do like a really high performance
We do like a really high performance
games and other types of simulators and
games and other types of simulators and
we train uh agents from scratch on them
we train uh agents from scratch on them
and we work on all the tech behind that.
and we work on all the tech behind that.
So this is like superhuman agent running
So this is like superhuman agent running
playing
playing
enduro. We have like simple games like
enduro. We have like simple games like
this and like uh breakout and stuff. And
this and like uh breakout and stuff. And
then we have more complicated stuff like
then we have more complicated stuff like
uh this miniature
uh this miniature
MMO is really big.
So stream is a mix
So stream is a mix
of doing math on the various different
of doing math on the various different
algorithms that go into this uh
algorithms that go into this uh
low-level engineering. All the M's are
low-level engineering. All the M's are
in C. We have some CUDA extensions,
in C. We have some CUDA extensions,
stuff like that. And yeah, just
stuff like that. And yeah, just
generally all the stuff that goes into
generally all the stuff that goes into
making RL work.
Oh, hang on. Can you not do this? I
Oh, hang on. Can you not do this? I
might just be using this loss
might just be using this loss
incorrectly, right? Does this
incorrectly, right? Does this
expect the output of a
expect the output of a
model? What are you supposed to call
model? What are you supposed to call
this thing
this thing
with log softmax? I see. So you're
with log softmax? I see. So you're
supposed to call log softmax followed by
k. Why do they Why is the input log
k. Why do they Why is the input log
softmax and the target is
softmax? Log target.
softmax? Log target.
Okay.
Okay.
So yeah, I just messed up the usage of
So yeah, I just messed up the usage of
this. So the whole thing is cracking
this. So the whole thing is cracking
because I get nan losses.
It isn't it? It's input, target. Yeah,
It isn't it? It's input, target. Yeah,
that's
correct. It's
true. Let's see what this does.
cannot
access. Okay, so now we actually get
access. Okay, so now we actually get
something.
They shouldn't these be the
same? Hang on. Something's wrong here
same? Hang on. Something's wrong here
because I'm pretty sure these should be
because I'm pretty sure these should be
the same.
Wait, this is
bash.index zero.
bash.index zero.
Perfect. Now, this should no longer
Perfect. Now, this should no longer
break everything. If I just run
break everything. If I just run
this and what are we getting spammed on
this and what are we getting spammed on
here?
Nothing. Okay. So, this is still somehow
exploding. Maybe we're just screwing
exploding. Maybe we're just screwing
over the optimizer
somehow. It is technically shared. What
somehow. It is technically shared. What
happens if we actually run with
this? Okay, now it actually runs
this? Okay, now it actually runs
reasonably. So, we were just screwing
reasonably. So, we were just screwing
over the optimizer somehow.
get the graphs for this going. I'm going
get the graphs for this going. I'm going
to use a restroom. I'll be right back.
to use a restroom. I'll be right back.
And Whoops. Get token first. Uh and then
And Whoops. Get token first. Uh and then
we will actually start running some
we will actually start running some
experiments on this and see if we can
experiments on this and see if we can
ever get this to
ever get this to
outperform the uh the
outperform the uh the
current PPO
current PPO
implementation. Let me grab the graphs
implementation. Let me grab the graphs
for this.
Oh yeah, also we've got soda on neural
Oh yeah, also we've got soda on neural
MMO so far with uh it's just like barely
MMO so far with uh it's just like barely
better, but it is better with the new
better, but it is better with the new
advantage
advantage
filtering. Right, new graphs go
filtering. Right, new graphs go
here. Back in a minute.
Let me
Let me
pull Slack channel over to there. If I
pull Slack channel over to there. If I
don't show that this over
don't show that this over
here and yeah, we're good to go for dev.
here and yeah, we're good to go for dev.
Uh, so this doesn't do much worse, but
Uh, so this doesn't do much worse, but
it does do
it does do
worse,
right? Making sure I didn't screw
right? Making sure I didn't screw
anything up here because I was I was
anything up here because I was I was
messing around with um some weird
messing around with um some weird
stuff.
Okay, then the next question would
Okay, then the next question would
be if we do this less often.
There's also supposed to be a
There's also supposed to be a
coefficient on the cloning loss. Hang
on. They have a coefficient
on. They have a coefficient
here. Where's the cloning
here. Where's the cloning
loss? B
loss? B
clone. Let me make sure that it's not
clone. Let me make sure that it's not
like a super low
like a super low
hyper. I should have a table somewhere.
one.
Okay. They want to do this every six on
Okay. They want to do this every six on
average.
average.
So, every so often they
do. Six
epochs.
epochs.
16 mini batches
16 mini batches
per ox.
I mean, I think one thing we can do is
I mean, I think one thing we can do is
just
just
take this entire
block. And we only do this
block. And we only do this
10% of the time or
whatever. That's like close to what
whatever. That's like close to what
they're doing.
The goal here is that you should just be
The goal here is that you should just be
able to like once in a while make sure
able to like once in a while make sure
that you're training the value function
that you're training the value function
enough
Can you please open Dairy Web? I have no
Can you please open Dairy Web? I have no
idea what that
is. Oh, holy. That actually does
is. Oh, holy. That actually does
something. Wait, that's
something. Wait, that's
actually It's better. At least for a
actually It's better. At least for a
little bit.
little bit.
This is not going to be the best to test
This is not going to be the best to test
on. We could probably test this on like
on. We could probably test this on like
something a bit
harder. That's still pretty
decent. Can you please open dark web?
No, wrong stream, buddy. This is
No, wrong stream, buddy. This is
reinforcement learning,
Dev.
Dev.
Welcome. You just
Let me see if I match a little bit
Let me see if I match a little bit
closer to their hypers. If anything
closer to their hypers. If anything
amazing happens all of a
sudden. Where's the go?
So do this n pi
times. So there's n pi and then e ox is
times. So there's n pi and then e ox is
what I need to check,
right?
right?
32 and then this is
32 and then this is
six. So okay, that's actually pretty
six. So okay, that's actually pretty
different.
We set this to six,
We set this to six,
right? Is there
right? Is there
um there is a data epoch,
um there is a data epoch,
right? Hey
right? Hey
Ryan, we just do if data
Ryan, we just do if data
epoch percent
epoch percent
32 and do this, right?
That's pretty close to
That's pretty close to
PPG. Yeah, Ryan, I'm just trying to see
PPG. Yeah, Ryan, I'm just trying to see
if this does anything real quick. It's
if this does anything real quick. It's
like a total mess to implement this
like a total mess to implement this
thing. Um, but I just want to see real
thing. Um, but I just want to see real
quick if this does like if there's signs
quick if this does like if there's signs
of life
here. Is that good?
the way I have this implemented by the
the way I have this implemented by the
way it would be very very little uh per
And does that just
match? Did you add in the A stuff? Yeah,
match? Did you add in the A stuff? Yeah,
I got to test this now. on something
I got to test this now. on something
like a little
like a little
harder. I don't think what ends I want
harder. I don't think what ends I want
to use. I could do grid. Grid kind of
to use. I could do grid. Grid kind of
has a lot of variability,
but would grid be an end where you would
but would grid be an end where you would
think the value loss would be get would
think the value loss would be get would
get
get
stale?
stale?
Maybe. Let me see if I can do it on
Maybe. Let me see if I can do it on
grid.
Okay. Apparently it doesn't like
Okay. Apparently it doesn't like
that. We have a whole bunch of stuff to
that. We have a whole bunch of stuff to
fix with
fix with
um with some of the end findings in the
um with some of the end findings in the
latest. Yeah, totally screwed it
latest. Yeah, totally screwed it
here. We have some stuff to fix with the
here. We have some stuff to fix with the
latest uh end bindings. All
latest uh end bindings. All
right. Okay. I don't know. Maybe I
right. Okay. I don't know. Maybe I
tested on Snake or something real quick.
tested on Snake or something real quick.
I think that one works.
need to add in the offset. Not a big
need to add in the offset. Not a big
deal.
deal.
Okay, let me let me run this and then
Okay, let me let me run this and then
I'll show you how I implemented it
I'll show you how I implemented it
because it's a little different from
because it's a little different from
what you're thinking
of. Okay. So, the way that I have this
of. Okay. So, the way that I have this
implemented
here, actually the going to be a mess.
here, actually the going to be a mess.
It's easier to just show you on the
algorithm. So, the way that they do this
algorithm. So, the way that they do this
for like their full
method, they
method, they
do lip. This is the PO policy objective
do lip. This is the PO policy objective
and then this is the value loss
and then this is the value loss
objective, right?
objective, right?
And then every so often, not very often,
And then every so often, not very often,
they distill the value function into the
they distill the value function into the
policy,
policy,
right? My lab's interested in starting
right? My lab's interested in starting
large DRL projects and also process
large DRL projects and also process
building cluster. Wonder if you had any
building cluster. Wonder if you had any
recommendations on GPUs. Yep, just our
recommendations on GPUs. Yep, just our
exact blog post here. Um, I don't get
exact blog post here. Um, I don't get
Intel chips though is the only thing.
Intel chips though is the only thing.
It's We've had so many freaking
It's We've had so many freaking
problems. uh puffer stack in the blog.
problems. uh puffer stack in the blog.
You just buy desktop
You just buy desktop
boxes. You don't care as much about
boxes. You don't care as much about
VRAM. You do care about having good
VRAM. You do care about having good
cores. So, the latest builds we have are
cores. So, the latest builds we have are
9950X, highest end AMD chip. And then
9950X, highest end AMD chip. And then
these are 4090s. We're buying 5090s
these are 4090s. We're buying 5090s
now. That's what we're doing. Yeah. So,
now. That's what we're doing. Yeah. So,
Ryan,
um so that's what they do. So what I was
um so that's what they do. So what I was
going to do instead is this part we just
going to do instead is this part we just
do however many epochs of PO. So this is
do however many epochs of PO. So this is
just
PO and then every like 32 epochs of PO
PO and then every like 32 epochs of PO
because that's what the frequency they
because that's what the frequency they
do this with is right. So every 32
do this with is right. So every 32
epochs of PO you just do an additional
epochs of PO you just do an additional
few epochs of uh value function training
few epochs of uh value function training
while using the policy cloning objective
while using the policy cloning objective
so that the base policy doesn't
change. Does that make sense?
I don't think we can get 40950 due to
I don't think we can get 40950 due to
Nvidia policy on incorporating them.
Nvidia policy on incorporating them.
Well, that's the thing. You don't build
Well, that's the thing. You don't build
them into a clust into cluster machines.
them into a clust into cluster machines.
You just buy individual
You just buy individual
desktops. If you're going to buy H00s
desktops. If you're going to buy H00s
for RL, you're just burning money. Like,
for RL, you're just burning money. Like,
if you're doing like standard DRL stuff
if you're doing like standard DRL stuff
and you're buying H00s, you're just
and you're buying H00s, you're just
throwing away 90% of your budget because
throwing away 90% of your budget because
they're not any faster. and they just
they're not any faster. and they just
cost 10x
more. You don't do separate value policy
more. You don't do separate value policy
epochs yet. We do right here. Right.
epochs yet. We do right here. Right.
This is the separate this is training
This is the separate this is training
the value function while using the
the value function while using the
distillation
loss. How much are these? Are these
loss. How much are these? Are these
things? Seven
grand. I don't know if this is remotely
grand. I don't know if this is remotely
accurate,
accurate,
but all the data center cards are like
but all the data center cards are like
for RL. You're just lighting money on
for RL. You're just lighting money on
fire. Like if you're going to buy those
fire. Like if you're going to buy those
cards, don't buy your own hardware.
cards, don't buy your own hardware.
There's no point. just rent
There's no point. just rent
it. If you're gonna like if you want to
it. If you're gonna like if you want to
do your own cluster like do so like this
do your own cluster like do so like this
is the way that you actually do it cost
is the way that you actually do it cost
effective because this is like 50 grand
effective because this is like 50 grand
worth of hardware that pays for itself
worth of hardware that pays for itself
in 3 months.
I'm not really seeing
I'm not really seeing
this. It doesn't hurt, but it doesn't
this. It doesn't hurt, but it doesn't
really help anything so far
really help anything so far
either to break out.
The value loss on these is also just
The value loss on these is also just
really
low. You know what we can
low. You know what we can
do? Can look at
Sounds pretty similar to the
Sounds pretty similar to the
original. Stop grad may matter. We don't
original. Stop grad may matter. We don't
want to do the stop grad because then
want to do the stop grad because then
it's no longer compatible with
bo. You don't think CPU
cores even for GPU? Not for stuff like
cores even for GPU? Not for stuff like
Craftex. But here's the thing, there
Craftex. But here's the thing, there
aren't that many MS like that. And like
aren't that many MS like that. And like
we're collabing with that lab. If you
we're collabing with that lab. If you
like Craftex is not a good way to write
like Craftex is not a good way to write
an environment. Like the guys that wrote
an environment. Like the guys that wrote
that are incredibly talented and I
that are incredibly talented and I
couldn't have written it that way. But
couldn't have written it that way. But
like I could have I can make that M 10
like I could have I can make that M 10
times faster with less than half of the
times faster with less than half of the
effort. If you just write it and save,
effort. If you just write it and save,
there's literally no point whatsoever to
there's literally no point whatsoever to
writing environments like that on the
GPU. My advisor wants to be able to do
GPU. My advisor wants to be able to do
large model
large model
fine-tuning. Well, that's no longer
fine-tuning. Well, that's no longer
RL.
RL.
Like that's now a different class of
Like that's now a different class of
problem,
right? That's the only difference for
right? That's the only difference for
the first part. Yeah. Ryan, hang on. Let
the first part. Yeah. Ryan, hang on. Let
me let me get rid of some of these
me let me get rid of some of these
runs. Why don't we just do
runs. Why don't we just do
new new
new new
baselines? Let's just do new baseline so
baselines? Let's just do new baseline so
that we're absolutely
that we're absolutely
sure we're correct here.
Yeah, my suggestion would be
Yeah, my suggestion would be
um if you want to do RL, but like the
um if you want to do RL, but like the
lab's also messing with big models
lab's also messing with big models
sometimes, would be get a few desktops
sometimes, would be get a few desktops
for RL and then do um if you need H00s
for RL and then do um if you need H00s
or something, just rent those. Don't
or something, just rent those. Don't
don't set up your own H00s. There's no
don't set up your own H00s. There's no
point.
The arbitrage is on like desktop class
The arbitrage is on like desktop class
machines. It's not on the server grade
machines. It's not on the server grade
hardware. Those are actually really
hardware. Those are actually really
cheap for what they are.
The uh the CPU cores, by the way, are
The uh the CPU cores, by the way, are
basically so that if you need to run
basically so that if you need to run
slower RLMs, you at least kind of can.
slower RLMs, you at least kind of can.
If you don't have those and you want to
If you don't have those and you want to
do anything outside of the really fast
do anything outside of the really fast
ends, you just can't. You're just
ends, you just can't. You're just
screwed. there's no way around it. You
screwed. there's no way around it. You
just like straight up
just like straight up
lose. So like stuff like the Pokemon
lose. So like stuff like the Pokemon
project that we did wouldn't be possible
project that we did wouldn't be possible
on um like we could rent a $100,000
on um like we could rent a $100,000
server and it would be the speed of one
server and it would be the speed of one
of our $5,000 boxes. Like we've timed
of our $5,000 boxes. Like we've timed
that.
It's kind of weird that they do like
It's kind of weird that they do like
this is really not that much extra value
this is really not that much extra value
function training,
right? I guess we could crank up EOS.
Yeah, it looks like it still keeps going
Yeah, it looks like it still keeps going
up. So, we might just crank
up. So, we might just crank
that. This does better at first and then
that. This does better at first and then
worse
after. It's really not that much extra
after. It's really not that much extra
value function training, right?
value function training, right?
What if we like crank this up to like
What if we like crank this up to like
32? What
32? What
happens? The value law could really
happens? The value law could really
drop, right?
But do you see why I'm doing it this
But do you see why I'm doing it this
way, Ryan? Like the idea is that you
way, Ryan? Like the idea is that you
just keep
just keep
PO and then just do some extra value
PO and then just do some extra value
function training if you want to crank
function training if you want to crank
up
up
compute because they say that it
compute because they say that it
actually like if you just crank up POE
actually like if you just crank up POE
epochs above three, you literally do
epochs above three, you literally do
worse most of the time.
Well, their base algorithm doesn't work
Well, their base algorithm doesn't work
by default because if you just change
by default because if you just change
the x-axis to wall clock time, they're
the x-axis to wall clock time, they're
slower. So, I could have just done no
slower. So, I could have just done no
more
samples. So, we're absolutely not doing
that. And like the uh the separate value
that. And like the uh the separate value
function as well. It's not like just 2x
function as well. It's not like just 2x
memory or whatever. It's a half the
memory or whatever. It's a half the
speed. It's like one half
speed. It's like one half
speed. So, that doesn't seem
speed. So, that doesn't seem
particularly smart to me
either. 9950X
either. 9950X
re Don't get AMD chips. I mean, uh,
re Don't get AMD chips. I mean, uh,
Intel, don't get Intel chips. Intel
Intel, don't get Intel chips. Intel
screwed us so badly.
Yeah. So, this is like a $700 processor
Yeah. So, this is like a $700 processor
that will just shred everything. Now, if
that will just shred everything. Now, if
you if you have really really CPU
you if you have really really CPU
intensive environments and you really
intensive environments and you really
want to build like a machine that can
want to build like a machine that can
handle that, then you consider thread
handle that, then you consider thread
rippers, but those are way pricier and
rippers, but those are way pricier and
the individual cores are usually
the individual cores are usually
slower. Is it actually worse on time
slower. Is it actually worse on time
efficiency? Is it not
similar? Well, if you have two separate
similar? Well, if you have two separate
networks, you double the forward pass
networks, you double the forward pass
cost,
cost,
right? Which then doubles the train time
right? Which then doubles the train time
as
well. Okay, now we do see this thing as
well. Okay, now we do see this thing as
being slightly lower for most of it,
being slightly lower for most of it,
right? The spike is
weird. Plus sample efficiency but speed.
weird. Plus sample efficiency but speed.
You don't do plus sample efficiency but
You don't do plus sample efficiency but
speed because
speed because
like you don't want that as your base
like you don't want that as your base
case because if you have unlimited data,
case because if you have unlimited data,
you're just always happier chewing
you're just always happier chewing
through more data, right? So you like
through more data, right? So you like
you screw yourself on a big class of
you screw yourself on a big class of
problems if you do it that
problems if you do it that
way. Let me
try. What do you mean?
No. Here. So like if you make training
No. Here. So like if you make training
take twice as long, what's wrong with
take twice as long, what's wrong with
Intel CPU? They shipped two consecutive
Intel CPU? They shipped two consecutive
generations of broken
chips. No, my bad. It was one. Was it
chips. No, my bad. It was one. Was it
one or
one or
two? I think it was two. Either way, at
two? I think it was two. Either way, at
least one generation of chips that just
least one generation of chips that just
break after a few
break after a few
months. So, we literally had like it
months. So, we literally had like it
cost me like tens and tens of hours of
cost me like tens and tens of hours of
maintenance and like, you know, tons of
maintenance and like, you know, tons of
cluster downtime dealing with it. And
cluster downtime dealing with it. And
also, you have to have specific infra as
also, you have to have specific infra as
well because some of the cores are fast
well because some of the cores are fast
and some are slow. It's a pain in the
and some are slow. It's a pain in the
ass. Just get the just get the uh the
ass. Just get the just get the uh the
AMD chips.
AMD chips.
I'd always prefer method that runs at
I'd always prefer method that runs at
the same speed but fewer. It's not the
the same speed but fewer. It's not the
same speed though because when you have
same speed though because when you have
two separate networks
two separate networks
right in PO if you have a shared value
right in PO if you have a shared value
function like it's basically no extra
function like it's basically no extra
compute for the value head right if you
compute for the value head right if you
have two separate networks the torso is
have two separate networks the torso is
unshared. It's double the forward pass
unshared. It's double the forward pass
time and then you end up with double the
time and then you end up with double the
backward time as well in training. So
backward time as well in training. So
you just take a flat 2x cut to
you just take a flat 2x cut to
everything,
everything,
right? So if your sample efficiency like
right? So if your sample efficiency like
if you have a fast end, it doesn't
if you have a fast end, it doesn't
matter because you're still running at
matter because you're still running at
half the speed. So you're getting half
half the speed. So you're getting half
the data that PO would get uh in the
the data that PO would get uh in the
same time. So it literally has to be
same time. So it literally has to be
double the sample efficiency for having
double the sample efficiency for having
unshared value function for that to
unshared value function for that to
work.
And just unsharing definitely doesn't do
And just unsharing definitely doesn't do
that. Like maybe with the whole rest of
that. Like maybe with the whole rest of
ppg it does, but unclear, you know,
unclear. It is more sample efficient. It
unclear. It is more sample efficient. It
takes
takes
longer longer per sample.
I mean there's only so much sample
I mean there's only so much sample
efficiency you can get though, right?
efficiency you can get though, right?
Like some problems just need fresh
Like some problems just need fresh
data. Like you need to see the new stuff
data. Like you need to see the new stuff
in the end to learn it,
right? Okay, so this actually spiked the
right? Okay, so this actually spiked the
value loss up a ton.
Well, that's the thing. It's problem
Well, that's the thing. It's problem
dependent, right? And it like it's
dependent, right? And it like it's
problem
dependent, but you don't like you change
dependent, but you don't like you change
the base case. You kind of want to keep
the base case. You kind of want to keep
PO as the
PO as the
base to learn propg games. I mean, how
base to learn propg games. I mean, how
much do we trust that result, right?
They didn't control for wall clock at
all. Okay. So, this run is better.
If we do this, this is like the most we
If we do this, this is like the most we
could possibly
do. Have to run experiments.
Yeah. I'm trying to get a feel for if
Yeah. I'm trying to get a feel for if
this does anything at all.
and just pull the clean script and run
one. Well,
one. Well,
like does that even tell you because
like does that even tell you because
like
like
um the bottlenecks in the clean RL are
um the bottlenecks in the clean RL are
completely different from the
completely different from the
bottlenecks in an optimized RL setup.
now. This is like really slow.
This is why no one looks at time
This is why no one looks at time
efficiency. Well, but that's like stupid
efficiency. Well, but that's like stupid
academia [ __ ] right? But that's
academia [ __ ] right? But that's
ultimately what like the only thing that
matters. Like for any fixed end, you
matters. Like for any fixed end, you
want it to train faster in wall clock,
want it to train faster in wall clock,
right? So if you have a slow M, it's not
right? So if you have a slow M, it's not
like, oh, we care about sampling. No,
like, oh, we care about sampling. No,
you still care about wall clock. It's
you still care about wall clock. It's
just that the end is more of a
just that the end is more of a
bottleneck,
right? So, if you like take a slow end
right? So, if you like take a slow end
and then make your method run even
and then make your method run even
slower, you're just
slower, you're just
dumb,
right? Like ideally, you should be
right? Like ideally, you should be
consuming samples at the rate that you
consuming samples at the rate that you
can produce them.
Yeah. So, this totally just crashes up
Yeah. So, this totally just crashes up
if you do it too often, which is in line
if you do it too often, which is in line
with the result.
So I would agree with you if the field
So I would agree with you if the field
has not been like taken this to utterly
has not been like taken this to utterly
stupid extremes
stupid extremes
repeatedly. This learning 200x faster is
repeatedly. This learning 200x faster is
also known as how do we spend two weeks
also known as how do we spend two weeks
per Atari
per Atari
environment. 200x faster like this is
environment. 200x faster like this is
literally how do we spend two weeks per
literally how do we spend two weeks per
Atari end. It's insane.
And like if you actually look at the
And like if you actually look at the
methods in this, like they're just doing
methods in this, like they're just doing
insane [ __ ] that's just like how do we
insane [ __ ] that's just like how do we
burn as much compute as physically
possible? So this is like the give a
possible? So this is like the give a
mouse a muffin thing. It's like we've
mouse a muffin thing. It's like we've
given the mouse too many
given the mouse too many
muffins. Academ Academia has taken it as
muffins. Academ Academia has taken it as
license to just do stupid [ __ ] instead
license to just do stupid [ __ ] instead
of making real progress. And uh yeah,
of making real progress. And uh yeah,
we're not taking that
anymore. I haven't seen this do anything
anymore. I haven't seen this do anything
useful at the moment.
useful at the moment.
Um, do we even get like value
loss? We really don't even see anything
loss? We really don't even see anything
substantial on the value
loss. Let me make sure I'm doing it
loss. Let me make sure I'm doing it
right. Every sample we train a full
right. Every sample we train a full
agent with and without that sample.
I mean, they are literally doing stuff
I mean, they are literally doing stuff
like training populations of agents to
like training populations of agents to
see which one does better.
Yeah, it's kind of batshit.
This thing doesn't seem to actually
This thing doesn't seem to actually
reduce value
loss. Is that likely a bug? I don't know
loss. Is that likely a bug? I don't know
how it would be a
bug. I mean, it is actually lower than
bug. I mean, it is actually lower than
this for a lot of it,
right? It's a stochcastic policy.
right? It's a stochcastic policy.
There's like only so much certainty you
There's like only so much certainty you
can have. Like the value loss can't ever
can have. Like the value loss can't ever
go to zero with a stochcastic policy,
go to zero with a stochcastic policy,
right?
could well like you don't know if you're
could well like you don't know if you're
actually going to get hit the hit the
actually going to get hit the hit the
ball or just wobble, right? Like halfway
ball or just wobble, right? Like halfway
through training the paddle wobbles a
through training the paddle wobbles a
bunch so we're just randomly miss stuff.
bunch so we're just randomly miss stuff.
You can't predict
You can't predict
that. It's weird it's not decreasing in
that. It's weird it's not decreasing in
my Yeah, that is fair.
We have it right here though,
right? All right. Well, we'll do a
right? All right. Well, we'll do a
couple more things before I say this
couple more things before I say this
isn't worth
time. I don't necessarily really Like
time. I don't necessarily really Like
I'm not in love with this method or
I'm not in love with this method or
anything though.
So now this is no policy gradient
So now this is no policy gradient
loss just extra value
loss. Value loss consistently decreased.
That doesn't make sense to me. Value
That doesn't make sense to me. Value
loss should increase over
training. It should be end dependent
training. It should be end dependent
though.
breakout changes a lot. I mean most
should I mean breakout is like the
should I mean breakout is like the
fundamentally looks the same regardless
fundamentally looks the same regardless
and
right if anything like a lot of could be
right if anything like a lot of could be
way more volatile than
that. I mean, this was going well until
that. I mean, this was going well until
it
it
uh
collapsed. We could go back to like six
collapsed. We could go back to like six
epox or whatever.
Maybe this is a more reasonable thing to
Maybe this is a more reasonable thing to
do. Top block. It does change when you
do. Top block. It does change when you
break the top block.
Yeah. Is there a statebased version of
Yeah. Is there a statebased version of
procgen?
like those M's are actually fast.
like those M's are actually fast.
Technically, we could just like we could
Technically, we could just like we could
probably do a little a version of proc
probably do a little a version of proc
gener and gives you state based ops cuz
gener and gives you state based ops cuz
like procgen m themselves are solid C++.
like procgen m themselves are solid C++.
Like we could probably grab them and um
Like we could probably grab them and um
and no emulator, right? Like we could
and no emulator, right? Like we could
probably just grab those and like have a
probably just grab those and like have a
bunch of new M's to play with.
Yeah, the obs are always pixels, right?
Yeah, the obs are always pixels, right?
But like they have code somewhere that
But like they have code somewhere that
renders stuff.
like they're just individual C++ files,
like they're just individual C++ files,
right?
They don't render every frame. Well, can
They don't render every frame. Well, can
instead of rendering every like can we
instead of rendering every like can we
just get some buffer of obs out that's
just get some buffer of obs out that's
not
frames. Here's point run.
Oh, definitely
Oh, definitely
wood. And it's annoyingly it is
B++. But like I think they're all block
B++. But like I think they're all block
assets even, aren't they?
big
big
fish. Can chat GPT an option? I
fish. Can chat GPT an option? I
generally assume chat GPT can't do
anything.
Maybe maybe sitting chat GPT is just not
Maybe maybe sitting chat GPT is just not
my idea of a fun time.
neither is translating C
code. I mean, but like the thing with
code. I mean, but like the thing with
those two, it's it's annoying because
those two, it's it's annoying because
you actually have to think a little bit
you actually have to think a little bit
about how to replace data structures,
about how to replace data structures,
right, that don't
exist. I'm stuck in What are you doing
exist. I'm stuck in What are you doing
with
with
CUDA? Since when do you write CUDA?
Oh, installing it, not writing it. I
Oh, installing it, not writing it. I
mean, these are like reasonable. They
mean, these are like reasonable. They
all have like block based assets and
all have like block based assets and
then entities that can be discreet or
continuous. I mean, I wouldn't be so mad
continuous. I mean, I wouldn't be so mad
about using this as our image based like
about using this as our image based like
image based benchmark either because we
image based benchmark either because we
technically probably
technically probably
could if we do anything with image based
could if we do anything with image based
stuff up it would be
stuff up it would be
this VMs where it
works is it what you get for using
VMs you're lacking the puffer infra
VMs you're lacking the puffer infra
experience
ma'am no VM docker just raw install on a
ma'am no VM docker just raw install on a
docker so it's perfectly replicable
not using Docker. Yeah, that's your
not using Docker. Yeah, that's your
problem,
problem,
right? That's why you're
right? That's why you're
suffering. Don't suffer. Use
Puffer. So, I haven't been able to get
Puffer. So, I haven't been able to get
this version of this algorithm to do
this version of this algorithm to do
anything.
Um, why would you even need to convert
Um, why would you even need to convert
to C? Just find the existing. Yeah, we
to C? Just find the existing. Yeah, we
probably could, Captain.
I just I don't know how their whole
I just I don't know how their whole
render setup works.
I'm trying to think if there's anything
I'm trying to think if there's anything
I could possibly be missing
I could possibly be missing
with PPG.
I could I guess there's one other thing.
What's
What's
this? Oh, yeah. That's the old version.
this? Oh, yeah. That's the old version.
That doesn't
matter. So, let's just do the original
matter. So, let's just do the original
here. Okay. And then we'll do
up here. The B loss will get zeroed.
You can't copy VMs around like that,
You can't copy VMs around like that,
Ryan. You mess them links as well.
Okay. So, this doesn't work.
Well, you prepare you have a computer
Well, you prepare you have a computer
with seven different
with seven different
environments. In all fairness,
worked so far. Doesn't work
now. Just because it's something that
now. Just because it's something that
it's designed for doesn't mean it's not
it's designed for doesn't mean it's not
[ __ ]
I know. I
Yeah. So, this doesn't work at all
Yeah. So, this doesn't work at all
without the cloning boss,
right? Because it just
right? Because it just
diverges. Like it starts learning and
diverges. Like it starts learning and
then it'll diverge.
So cloning loss is a thing that makes it
So cloning loss is a thing that makes it
work,
work,
but it doesn't seem like it's clearly
but it doesn't seem like it's clearly
doing
anything. Okay, one last idea.
You do
You do
this this thing
normally and
normally and
[Music]
[Music]
then we do this loss. Where is it? The
then we do this loss. Where is it? The
whole loss here.
But we
But we
do set this to like what's it
six
six
two. Set this to
six every
16. What are you working on? I am
16. What are you working on? I am
currently Give me one second here. Um,
currently Give me one second here. Um,
I'm currently working on variations of
I'm currently working on variations of
basic policy gradients to see if they do
basic policy gradients to see if they do
anything for puffer lip. I'm trying to
anything for puffer lip. I'm trying to
like see if I can use some of the
like see if I can use some of the
techniques from this paper
techniques from this paper
uh in a way that doesn't slow down
uh in a way that doesn't slow down
learning so much.
Okay, so here here's the
Okay, so here here's the
uh here's the idea, right? What if they
uh here's the idea, right? What if they
didn't have their value function
didn't have their value function
coefficient trained when they wrote this
coefficient trained when they wrote this
paper? So what if it were something like
paper? So what if it were something like
this,
right? Does that change
it? Would that make sense? Actually,
it? Would that make sense? Actually,
Ryan, what if like what if they just had
Ryan, what if like what if they just had
a fiddly tuned value function
a fiddly tuned value function
coefficient, right? So, their value
coefficient, right? So, their value
function wasn't getting trained enough.
Okay. Okay, so this is PPG with shitty
Okay. Okay, so this is PPG with shitty
value function
value function
coefficient and
then we do it without PPG.
G. What was their value
coefficient? Feel like you need to make
coefficient? Feel like you need to make
sure your implementation
sure your implementation
replicates their results before testing
replicates their results before testing
stuff
stuff
though. It depends how conclusive we're
though. It depends how conclusive we're
being,
right? Because I don't actually want
right? Because I don't actually want
their version. Like I don't actually
their version. Like I don't actually
want their algorithm. I want some like
want their algorithm. I want some like
adjacent things from their algorithm.
So the aux phase code is literally just
So the aux phase code is literally just
copy paste the whole training loop and
copy paste the whole training loop and
change the
losses. I
losses. I
[Music]
[Music]
mean kind of right. Look at
this. That's a bigger gap than we've
this. That's a bigger gap than we've
seen anywhere else. Right.
They regenerate policy logics. No, I do
They regenerate policy logics. No, I do
regenerate policy logics. I implemented
regenerate policy logics. I implemented
that
today. So, first of all, I didn't scrub
today. So, first of all, I didn't scrub
that badly,
that badly,
Ryan. So, this is the main loop, all the
Ryan. So, this is the main loop, all the
freaking code, yada yada. And
freaking code, yada yada. And
then here's where I regenerate logs and
then here's where I regenerate logs and
values for
values for
baselining. And then we use those here
baselining. And then we use those here
in the uh in the KL loss and the value
in the uh in the KL loss and the value
loss. So there you go. So what you're
loss. So there you go. So what you're
looking at with this, right, is I just I
looking at with this, right, is I just I
took the value coefficient down to
0.5. So value coefficient at 0.5. Now
0.5. So value coefficient at 0.5. Now
ppg is better. than PO because you would
ppg is better. than PO because you would
do the additional value
training. So PPG is is pretty close to
training. So PPG is is pretty close to
the original tuned
PO and the PO with the lower coefficient
PO and the PO with the lower coefficient
isn't. I mean we could we could
isn't. I mean we could we could
technically exacerbate this as well
technically exacerbate this as well
because they have a worse optimizer than
because they have a worse optimizer than
we do, right?
So I think it's
So I think it's
here. So they have a worse optimizer as
here. So they have a worse optimizer as
well. So I could go down to like
well. So I could go down to like
0.25 and we can see what that does. Let
0.25 and we can see what that does. Let
me see what coefficient they
used. They don't have one in
used. They don't have one in
here, I guess. I would have
it 0.5
with the worst
optimizer. I
optimizer. I
mean,
yeah, and then we do six epochs of
yeah, and then we do six epochs of
ppg,
right? I don't think they changed any
right? I don't think they changed any
hypers.
Well, yeah. So, what that means, right,
Well, yeah. So, what that means, right,
is you could find
is you could find
like you found an algorithm like you
like you found an algorithm like you
tuned an algorithm to the current hypers
tuned an algorithm to the current hypers
is a possibility,
right? Wouldn't be the first time in RL.
I mean that looks
pretty. Yeah. So this is the only way
pretty. Yeah. So this is the only way
we've gotten ppg to do con to do
we've gotten ppg to do con to do
consistently better.
Right? This would be consistent with
Right? This would be consistent with
undertrain value function.
Arguably this M is also very easy. So
Arguably this M is also very easy. So
you know this effect could be magnified
you know this effect could be magnified
a ton in harder ends.
Right. Let me see if I can get one other
Right. Let me see if I can get one other
to
to
run Boba or something.
welcome.
were we doing PO breakout? Uh we were.
were we doing PO breakout? Uh we were.
Yeah, I think the M is a little too
Yeah, I think the M is a little too
simple. So basically what I'm trying to
simple. So basically what I'm trying to
figure out now
figure out now
is what uh where the per improvement
is what uh where the per improvement
from phasic policy gradients is coming
from phasic policy gradients is coming
from. And I'm suspecting that you can do
from. And I'm suspecting that you can do
similarly well just by increasing the
similarly well just by increasing the
value function coefficient.
Shoot. This isn't going to run, is
it? Yeah, we've got some screwy things
it? Yeah, we've got some screwy things
happening with some of these
happening with some of these
ends. We could do snake maybe.
Enduro. Let me see which of these we can
Enduro. Let me see which of these we can
get to like run
quickly. And these haven't been ported
quickly. And these haven't been ported
off to the new code yet, right?
We can do
We can do
snake. Let's at least see if we can
snake. Let's at least see if we can
replicate this one.
Thank. Is it hard to set up bindings for
Thank. Is it hard to set up bindings for
procgen?
procgen?
No, we can train progen. It's just
No, we can train progen. It's just
really freaking
slow. Like procgen is 300 times slower
slow. Like procgen is 300 times slower
than this with their base network that
than this with their base network that
they
use after optimizing.
I actually just run it on like actual
I actually just run it on like actual
breakout if we're doing that right
What do you mean by the coefficient of
What do you mean by the coefficient of
the value function? So, uh when you
the value function? So, uh when you
train the value loss, you usually apply
train the value loss, you usually apply
a coefficient to it. You usually like
a coefficient to it. You usually like
multiply it by coefficients and fixed
multiply it by coefficients and fixed
value as a hyperparam. So, their default
value as a hyperparam. So, their default
is like 0.5 and ours is usually like
is like 0.5 and ours is usually like
two. So, it's quite possible that they
two. So, it's quite possible that they
just undertuned the value
function. Okay, we'll do a pixelm
function. Okay, we'll do a pixelm
because apparently pixel ends are cool
because apparently pixel ends are cool
or
or
something. If I can get this to run
something. If I can get this to run
reasonably quickly at
least. I'm trying to think about this
least. I'm trying to think about this
and like
actually does this
work kind
of. It's going to be rough with the new
of. It's going to be rough with the new
vectorization, I think.
Haven't done anything on Atar in a long
Haven't done anything on Atar in a long
time.
This is why I didn't want to do this
This is why I didn't want to do this
because I just know that the current dev
because I just know that the current dev
state is
like like we need to like update
like like we need to like update
everything to the latest binding
everything to the latest binding
signature, right?
still just not going to be able to
still just not going to be able to
like there's just like a ton of work I
like there's just like a ton of work I
have to do on this in order to update
have to do on this in order to update
everything to the new
signatures. Let me go back to doing this
signatures. Let me go back to doing this
on snake at the very least.
Three runs real
Three runs real
quick. First run, normal
quick. First run, normal
baseline. Make sure I haven't broken
baseline. Make sure I haven't broken
anything doing all this [ __ ]
I've definitely broken something doing
I've definitely broken something doing
all this [ __ ]
Okay,
Okay,
there reasonable
there reasonable
baseline. So this is one window.
baseline. So this is one window.
Remember this second window.
baseline. Honestly, we don't even need
baseline. Honestly, we don't even need
this for more than 40
mil baseline
mil baseline
with shitty clipping
with shitty clipping
coefficient or shitty value function
coefficient or shitty value function
coefficient.
L does
better. To be fair, we didn't tune value
better. To be fair, we didn't tune value
function coefficient for this sound. We
function coefficient for this sound. We
tuned it for breakout.
Okay, unplanned. So that we'll just do
Okay, unplanned. So that we'll just do
um just do some ppg
um just do some ppg
epochs within without value or whatever.
Just like, do we get any signs of life
Just like, do we get any signs of life
whatsoever from this
thing? Okay. Underperforms this one.
What about with this?
Okay, that's
something. Barely something, but
Oh, you know
Oh, you know
what, dude? How did I let myself get
what, dude? How did I let myself get
nerd sniped by this? You know why this
nerd sniped by this? You know why this
thing probably doesn't
work? This is not any better, right?
Yeah, it's on par with original. So,
Yeah, it's on par with original. So,
here's the thing I always forget about,
here's the thing I always forget about,
right? I don't know why I like this
right? I don't know why I like this
happens every bloody time and I always
happens every bloody time and I always
forget about this. So, like
This is how you fudge all research by
This is how you fudge all research by
the way. So unintentionally as well I
the way. So unintentionally as well I
should say. So you see all these
should say. So you see all these
hyperpar. Yeah they just take these from
hyperpar. Yeah they just take these from
the original repo.
the original repo.
Right. So these are just from the
Right. So these are just from the
original repository. They don't reune
original repository. They don't reune
them for this work at all. And then they
them for this work at all. And then they
go introduce five six new
go introduce five six new
hyperparameters with this new algorithm
hyperparameters with this new algorithm
that they do
that they do
tune. So like when you introduce six new
tune. So like when you introduce six new
hyperparameters and that you are
hyperparameters and that you are
actually tuning them, you can basically
actually tuning them, you can basically
come up with any old stupid method and
come up with any old stupid method and
it'll
it'll
work. Now, to be fair to them, I think
work. Now, to be fair to them, I think
that the results they have here, like
that the results they have here, like
they've actually got pretty clean graphs
they've actually got pretty clean graphs
on a lot of these things showing that
on a lot of these things showing that
yeah, there's probably something
yeah, there's probably something
here, but
here, but
um I I'd be very surprised if the gap is
um I I'd be very surprised if the gap is
as big as
as big as
this in general.
Once you actually have correctly tuned
hypers I don't think you can just add
hypers I don't think you can just add
hypers and get good results across proc
hypers and get good results across proc
gen happens quite often.
I mean the idea there is like you're
I mean the idea there is like you're
adding extra tunable knobs,
adding extra tunable knobs,
right? So like here, let me give you a
right? So like here, let me give you a
really dumb example, right? Let's say
really dumb example, right? Let's say
that I just add another parameter in
that I just add another parameter in
front of gamma and lambda, right? That I
front of gamma and lambda, right? That I
call like my super awesome gamma and
call like my super awesome gamma and
lambda. And then I don't tune the
lambda. And then I don't tune the
originals, but I do tune my parameters.
originals, but I do tune my parameters.
Boom. I set soda, right?
And actually procgen was solved just by
And actually procgen was solved just by
tuning dbo hyperp
per assumes the original hyperparameters
per assumes the original hyperparameters
aren't tuned. Believe me, they're not.
aren't tuned. Believe me, they're not.
They're [ __ ]
They're [ __ ]
propgen was solved just by
propgen was solved just by
hyperparameter tuning by
imbue par isn't the same problem. Well,
imbue par isn't the same problem. Well,
the original problem stupid though
the original problem stupid though
because like J fundamentally means that
because like J fundamentally means that
you can't have optimal params and also
you can't have optimal params and also
the originals aren't tuned. Look at
the originals aren't tuned. Look at
them. They're like 0.5 and like 0.95.
them. They're like 0.5 and like 0.95.
They're just the ones that they grabbed
They're just the ones that they grabbed
from
from
Atari or whatever, right?
I guess they do like the long horizon
I guess they do like the long horizon
version of 999. Yeah, like these aren't
version of 999. Yeah, like these aren't
even
like second digit. Yeah, these aren't
like second digit. Yeah, these aren't
tuned at all. This is just Atari
tuned at all. This is just Atari
default, Atari
default, Atari
default. Like these are all just
default. Like these are all just
generalization is a dumb problem. Well,
generalization is a dumb problem. Well,
it is in this case because like you
it is in this case because like you
can't solve it with PO because of
can't solve it with PO because of
J, right? It is actually literally is a
J, right? It is actually literally is a
dumb problem trying to solve when you're
dumb problem trying to solve when you're
using J with a fixed coefficient because
using J with a fixed coefficient because
J says this is the time horizon I care
J says this is the time horizon I care
about and then you give it time horizons
about and then you give it time horizons
with different problems. Like the smart
with different problems. Like the smart
thing to do is to try to replace J with
thing to do is to try to replace J with
something that doesn't have that
something that doesn't have that
limitation. But just like oh we're going
limitation. But just like oh we're going
to use J as a core component and then
to use J as a core component and then
try to do it anyways is really stupid.
Yeah. I mean that's literally why this
Yeah. I mean that's literally why this
benchmark like this was this benchmark
benchmark like this was this benchmark
was unsolved for a long long time right
was unsolved for a long long time right
and then literally you take the dumbest
and then literally you take the dumbest
baseline you just tune the params per
baseline you just tune the params per
end and you full solve
end and you full solve
it that's not like and that's like
it that's not like and that's like
despite the best efforts of people doing
despite the best efforts of people doing
all sorts of fancy algorithms right
all sorts of fancy algorithms right
that's not like oh different problem
that's not like oh different problem
that's just the original problem spec
that's just the original problem spec
was dumb and it highlights like
was dumb and it highlights like
something dumb about po
Right. I don't know. I'd be I'd be
Right. I don't know. I'd be I'd be
interested to see like if you just tune
interested to see like if you just tune
gamma and lambda per n, right? That
gamma and lambda per n, right? That
would be
would be
interesting. Not poss. It's possible to
interesting. Not poss. It's possible to
do. Yeah, it is. But like you full solve
do. Yeah, it is. But like you full solve
it just with default PO, right? It's not
it just with default PO, right? It's not
hard. I agree. We should spend time more
hard. I agree. We should spend time more
time on GE replacements. This is why I
time on GE replacements. This is why I
was like banging my head on P3 for a
was like banging my head on P3 for a
while, right? And I'm still going to go
while, right? And I'm still going to go
back to that. I actually I would be
back to that. I actually I would be
interested to see how well you could do
interested to see how well you could do
if uh you tuned one set of hypers across
if uh you tuned one set of hypers across
all the M's, right? But you tune per M
all the M's, right? But you tune per M
gamma lambda. I think you'd do pretty
gamma lambda. I think you'd do pretty
well because since I added muon, pretty
well because since I added muon, pretty
much the only params I really have to
much the only params I really have to
tune very often when I have like
tune very often when I have like
comparable model and stuff are gamma
comparable model and stuff are gamma
like just gamma lambda. Everything else
like just gamma lambda. Everything else
is kind of
fine. The thing is we've actually kind
fine. The thing is we've actually kind
of done that in Puffer, right? Because
of done that in Puffer, right? Because
like we solved all the M's out of the
like we solved all the M's out of the
box in Puffer with Muon with pretty much
box in Puffer with Muon with pretty much
same hypers. I think we changed like
same hypers. I think we changed like
batch size for a couple of them because
batch size for a couple of them because
some are faster than others. But then
some are faster than others. But then
like there were a couple M's where we
like there were a couple M's where we
had to reduce lambda to
had to reduce lambda to
solve. So like there you kind of go
solve. So like there you kind of go
right there. And then I looked at the
right there. And then I looked at the
Proctton hyperparame sweep results and I
Proctton hyperparame sweep results and I
can tell you it's the exact same problem
can tell you it's the exact same problem
looking at those because they have like
looking at those because they have like
lambda or they have like gamma equal 0.7
lambda or they have like gamma equal 0.7
in some of them as
optimal. So actually there you go. I can
optimal. So actually there you go. I can
I can tell you the result of that right
I can tell you the result of that right
now is that you do pretty darn well.
I mean this
I mean this
definitely like this definitely is
definitely like this definitely is
tuning a value function coefficient
tuning a value function coefficient
right spending extra epochs on value
right spending extra epochs on value
function this means that you've
function this means that you've
basically tuned cross n value function
basically tuned cross n value function
coefficient when it wasn't tuned
or these results at the top are
or these results at the top are
interesting,
right? This is E
O and this is EI.
which helps so
which helps so
much. I don't think that they help so
much. I don't think that they help so
much. I think that you actually like
much. I think that you actually like
close this gap by at least half is most
close this gap by at least half is most
likely if you just
tune. I wouldn't expect most of this.
tune. I wouldn't expect most of this.
Yeah. No, I think the directionality of
Yeah. No, I think the directionality of
the result is interesting, right? But I
the result is interesting, right? But I
think that the magnitude is likely very
overstated. Actually, let me see. So,
overstated. Actually, let me see. So,
they didn't report this, right? They
they didn't report this, right? They
didn't report EV, did
they? See? Yeah. They don't actually
they? See? Yeah. They don't actually
have EV on here. Isn't that funny?
Well, they set this to
Well, they set this to
one. So, they don't actually even tune
one. So, they don't actually even tune
the value. Like, they don't even do this
the value. Like, they don't even do this
more.
Right. Let me see if that changes
anything. Well, this one here, they
anything. Well, this one here, they
actually do extra steps. They had an
actually do extra steps. They had an
ablation on this.
Right. Let me find it. I swear they had
Right. Let me find it. I swear they had
an inflation on
this. Okay.
this. Okay.
So they lose some of the
So they lose some of the
Perf if they do three value
updates and then they remove L value in
updates and then they remove L value in
ox phase.
Interesting. But this is also with the
Interesting. But this is also with the
unshared one,
right? This is with the unshared net as
right? This is with the unshared net as
well. I think that this this perf
well. I think that this this perf
degradation would probably stack really
degradation would probably stack really
badly with
badly with
with
with
this. Oh, also this is bucked,
this. Oh, also this is bucked,
right? This this baseline is screwed.
right? This this baseline is screwed.
Look at
Look at
this separate network
PO. Man, that makes me like not want to
PO. Man, that makes me like not want to
trust
trust
this at all with it with it like this.
There's no way,
right? There's like actually no way you
right? There's like actually no way you
get this big of a gap,
get this big of a gap,
right? Yeah, it does outperform shared
right? Yeah, it does outperform shared
network. But my point here is
network. But my point here is
like there's no way that you that like
like there's no way that you that like
doing separate networks which is
doing separate networks which is
literally more pip more parameters does
literally more pip more parameters does
like crazy worse and in fact like you
like crazy worse and in fact like you
know often people use separate networks
know often people use separate networks
because it does better. So I think that
because it does better. So I think that
this whole gap is hyperpar.
Heck, I think if you tuned it correctly,
Heck, I think if you tuned it correctly,
this should be above this
this should be above this
one, right? You have double capacity.
The heck is a value
feature? Does it make sense that that's
feature? Does it make sense that that's
actually a
thing? I guess the whole paper really
thing? I guess the whole paper really
hinges on this, right?
Like if not for this graph, I wouldn't
Like if not for this graph, I wouldn't
even pay attention to this paper.
Value prediction has to be harder than
Value prediction has to be harder than
learning the policy, it says, right?
learning the policy, it says, right?
Because otherwise, why would it benefit
Because otherwise, why would it benefit
from more
epochs? And value function usually lags
epochs? And value function usually lags
as well, right?
I'm trying to think here
like they probably do have something
like they probably do have something
here.
here.
My my best guess here is that they do
My my best guess here is that they do
have something, but the magnitude is way
have something, but the magnitude is way
lower than
stated because
like like would we care about this
like like would we care about this
paper, right? Let's say like how much do
paper, right? Let's say like how much do
you think you get off of just tuning the
you think you get off of just tuning the
hypers better, right?
hypers better, right?
Like if this gap were closed by half,
Like if this gap were closed by half,
would we really care that
would we really care that
much about
this? I mean, if you wanna if you want
this? I mean, if you wanna if you want
to do that, yeah, that would be awesome.
Um, but I don't
like I think it it needs a better tuned
like I think it it needs a better tuned
baseline,
right? Because I am I really think that
right? Because I am I really think that
there
there
is I think this is a weak baseline
is I think this is a weak baseline
problem.
Like these graphs are cool because
Like these graphs are cool because
like the fact that your policy does
like the fact that your policy does
worse when you reuse
worse when you reuse
it and the value function does
better some exact experiments you want
better some exact experiments you want
to
See, well hyper the most expensive thing
See, well hyper the most expensive thing
is going to be the freaking would be the
is going to be the freaking would be the
hyperparameter tuning,
right? I guess one thing would be to see
right? I guess one thing would be to see
whether the way I'm implementing it is
whether the way I'm implementing it is
just screwing it
just screwing it
up.
up.
So I think what you would do then is you
So I think what you would do then is you
would do full
would do full
PO. If you just do full PO, like one
PO. If you just do full PO, like one
epoch, full
epoch, full
PPO, right? And then every I think this
PPO, right? And then every I think this
is 16 or 32 epochs, you do the extra
is 16 or 32 epochs, you do the extra
value stuff with the distillation. So
value stuff with the distillation. So
basically
basically
does Yeah, remove the stock
does Yeah, remove the stock
brad. I think if you just remove the
brad. I think if you just remove the
stock brad, that kind of does it, right?
I don't know if it's implement how it's
I don't know if it's implement how it's
implemented in the clean RL repo, but I
implemented in the clean RL repo, but I
also would like to do these at the same
also would like to do these at the same
time. So do these like these should be
time. So do these like these should be
done jointly,
done jointly,
right? Well, because EPI and EV can be
right? Well, because EPI and EV can be
different. So I would do these jointly
different. So I would do these jointly
with the shared network. So do the
with the shared network. So do the
shared network variant with these steps
shared network variant with these steps
done
jointly. Clean RL doesn't implement
jointly. Clean RL doesn't implement
that. Perfect. So in that case, you can
that. Perfect. So in that case, you can
just do you can just do one
just do you can just do one
epoch. You can remove the stop
epoch. You can remove the stop
brad and you can see if that screws it
up. And then I what I'll do is I'll save
up. And then I what I'll do is I'll save
this stuff here.
I'll like add all this
Don't need that. Yeah.
Well, ironically, I think that if if the
Well, ironically, I think that if if the
stop grab thing doesn't
work well, I'm trying to think of what
work well, I'm trying to think of what
what is the case in which it is worth
what is the case in which it is worth
it.
it.
Um cuz if removing the stop
Um cuz if removing the stop
Brad doesn't break the method,
Brad doesn't break the method,
right? Then the fact that it doesn't
right? Then the fact that it doesn't
work in my code is like, okay, maybe the
work in my code is like, okay, maybe the
thing just doesn't work.
thing just doesn't work.
And if removing the stock
And if removing the stock
rad does break
rad does break
it, then it's like not super useful
it, then it's like not super useful
because it doesn't match PO dynamics.
because it doesn't match PO dynamics.
Though I guess technically we could
do actually here if stop does break it
do actually here if stop does break it
then yeah there's a way that I can slot
then yeah there's a way that I can slot
it in as like an extended compute
it in as like an extended compute
option.
option.
So what we'd want like what we'd see is
So what we'd want like what we'd see is
if this method is
if this method is
actually good then you would expect
actually good then you would expect
removing stop rad to break
removing stop rad to break
it. Yeah. So that would be the thing
it. Yeah. So that would be the thing
that we would be looking to
that we would be looking to
see. Let me use the restroom real quick
see. Let me use the restroom real quick
and then I'll think about what's next.
All
right. Miss one quick text and then we
right. Miss one quick text and then we
will work on the next thing.
All
right.
So, I think that we just figure out
So, I think that we just figure out
um we start figuring
um we start figuring
out some merge
out some merge
stuff. There kind of two parts to this.
stuff. There kind of two parts to this.
There's the new binding.
Let me see what's best
Let me see what's best
PR because there's like there's two
PR because there's like there's two
things that we need to do. There's the
things that we need to do. There's the
new binding stuff and then there's some
new binding stuff and then there's some
pretty serious vectorization
stuff. Okay. Okay. So like B has this
here. I the main thing right now I guess
here. I the main thing right now I guess
is like I'd like to just merge this into
is like I'd like to just merge this into
dev and then fix all the binding
crap. But the vectorzation stuff is
crap. But the vectorzation stuff is
going to be an issue.
Okay, let me think about what we can do
Okay, let me think about what we can do
about this.
So the problem is that the new buffer
So the problem is that the new buffer
stores segments. So it doesn't like it
stores segments. So it doesn't like it
when you get variable length segments.
my thing. Shouldn't my thing actually
my thing. Shouldn't my thing actually
work with
that? I think this actually should work.
So I actually think that there shouldn't
So I actually think that there shouldn't
really be any issue running any of the
M's. So maybe actually it is worth it to
M's. So maybe actually it is worth it to
see why Atari is hanging right
now. That might let me merge it.
Need to go back to my work. See you,
Need to go back to my work. See you,
Ryan. Get the thing done. I You got to
Ryan. Get the thing done. I You got to
just finish writing and submitting that
just finish writing and submitting that
thing. Call it a
thing. Call it a
day or whatever you're doing for
day or whatever you're doing for
finishing degree.
trying to do actual research
trying to do actual research
again. That's
again. That's
good. See you.
Where is this
hanging? Is this hanging on receipt?
Ah, I see
Ah, I see
it. Yeah, I see it.
Okay. Well, I know what the issue is
Okay. Well, I know what the issue is
now.
Yeah, that's also multi- discrete HQ,
Yeah, that's also multi- discrete HQ,
right?
You don't really do you need bats logs
You don't really do you need bats logs
for anything right
now? Not
really. Yes, this runs.
I think this just takes a while to log,
right? Yeah. There we
go. See if this trains at this
There we go. It's learning.
mil. Okay. So, this still
trains. That is good.
Okay. So, I think we will actually be
Okay. So, I think we will actually be
able to do the big merge relatively soon
able to do the big merge relatively soon
then. I don't want to start it right now
then. I don't want to start it right now
because I'm going to dinner in a bit.
because I'm going to dinner in a bit.
I'm also a little tired. I don't want to
I'm also a little tired. I don't want to
like screw this thing
like screw this thing
up. I do have a few other things to
do. Check one
thing. There was one other thing I had
thing. There was one other thing I had
to do
today. Okay, so
I think I actually
I think I actually
then I think what I
do go
here. I have to figure out how to run
this. That's
funny. Let me go find the thing. Oh, why
funny. Let me go find the thing. Oh, why
did it switch to
did it switch to
camera? That's weird.
Let me go grab all the stuff I need for
Let me go grab all the stuff I need for
this.
The other thing I had to do today was
The other thing I had to do today was
just checking on some of
just checking on some of
um this here is the animation gen work
um this here is the animation gen work
we
we
did. There's some reported issues with
did. There's some reported issues with
it.
going on
here. this
free. I actually thought that this one
free. I actually thought that this one
worked before.
Maybe I
Oh, maybe it's
this. There we
go. So, it was just too many damn
go. So, it was just too many damn
motions.
This is probably running 4096 or
This is probably running 4096 or
something.
See if I missed
anything.
anything.
No, should be fine.
This should be finished, right? Is it
This should be finished, right? Is it
actually even running
anything? It is just very inefficiently,
anything? It is just very inefficiently,
right?
Yeah, it's not even using any
Yeah, it's not even using any
CPU. I think it's just stuck.
It's like it should have spit out the
It's like it should have spit out the
results, but it didn't.
D-final
eval. Ah, space.
Let me figure out what the heck is
Let me figure out what the heck is
wrong.
This is like shared storage or some
This is like shared storage or some
[ __ ] right?
The heck is it even trying to write to
The heck is it even trying to write to
slashtemp? Oh, this is shitty internal
slashtemp? Oh, this is shitty internal
like stupid internal torch
like stupid internal torch
multipprocessing.
multipprocessing.
Yeah, and I remember this being an
Yeah, and I remember this being an
issue.
Hang on.
Seems like there's space
here. Porch elastic
I'm trying to think what I can do to get
I'm trying to think what I can do to get
this stupid thing to
this stupid thing to
run. I have space.
There shouldn't be a cap on the docker
There shouldn't be a cap on the docker
size, right?
that does
anything or if it
anything or if it
just we'll see.
That might be it. Right.
I think I might be able to just like
I think I might be able to just like
start the container separately. One
start the container separately. One
sec. Okay.
We can actually just do it with start.
We can actually just do it with start.
Hang on. Yeah. Yeah, this will
work. We can literally just do this
work. We can literally just do this
apparently.
I'm hoping that I don't have to remake
I'm hoping that I don't have to remake
the container. I think we can just
the container. I think we can just
reboot it and then we can actually get
reboot it and then we can actually get
some cool emails.
Unknown flag. Yeah. So, this this
Unknown flag. Yeah. So, this this
doesn't freaking
doesn't freaking
exist. Would drop
Groc. I don't want to remove the damn
container. We'll just make a separate
container. We'll just make a separate
container to test this. I think real
container to test this. I think real
quick. That's what we'll do.
There we go.
Now
Now
we reset up this
we reset up this
repo and hopefully I have all the data.
and that'll install that and then uh we
and that'll install that and then uh we
should be able to test this and
should be able to test this and
hopefully that fix the shared memor
[ __ ] We will hope.
So this right here, what we're waiting
So this right here, what we're waiting
on, this is why you don't use virtual
on, this is why you don't use virtual
MS. Um, if this were just part of the
MS. Um, if this were just part of the
Docker, we would be done
instantly. Instead, you sit here waiting
instantly. Instead, you sit here waiting
for 5, 10 minutes, whatever, every
for 5, 10 minutes, whatever, every
single time you want to like remake a
single time you want to like remake a
dev environment for whatever reason.
Okay, we get our shell
Hey, bet. We're just testing some
Hey, bet. We're just testing some
animation stuff for a bit. Um, I
tried I tried some stuff with basic
tried I tried some stuff with basic
policy
policy
gradients. It didn't really do much. We
gradients. It didn't really do much. We
might want to come back to it when we
might want to come back to it when we
have like a
have like a
stable version of dev so I have access
stable version of dev so I have access
to all the ends for testing
to all the ends for testing
correctly. But um initially it doesn't
correctly. But um initially it doesn't
do much
Yep.
Yep.
He's going to go run some experiments as
He's going to go run some experiments as
well.
Yeah, it's a count thing. Some folks are
Yeah, it's a count thing. Some folks are
having trouble with it, so I'm just like
having trouble with it, so I'm just like
seeing what I can repro.
Yes, we need the model.
See if there's
still this ones. We might just have to
still this ones. We might just have to
screw with something. I don't
know. Uh there's
know. Uh there's
like PyTorch multipprocessing kind of
like PyTorch multipprocessing kind of
sucks and there's like some weird shared
sucks and there's like some weird shared
memory resource out of memory thing.
memory resource out of memory thing.
It's not like
It's not like
It's not actual RAM. There's some like
It's not actual RAM. There's some like
weird shared resource
weird shared resource
thing. Yes. So, this seems like it's
thing. Yes. So, this seems like it's
still
stuck. Oh, there we go. No, that
stuck. Oh, there we go. No, that
actually works now. Perfect. So, that
actually works now. Perfect. So, that
did fix it.
Tyler, why are you writing fanfic in
Tyler, why are you writing fanfic in
the stream chat now? What are you
doing? No, that's Tyler. Tyler's not
doing? No, that's Tyler. Tyler's not
allowed.
Unless he's just pasting random crap in
Unless he's just pasting random crap in
now. Tyler actually does cool physics
[ __ ] What the hell are dumb? What the
[ __ ] What the hell are dumb? What the
hell article is
hell article is
this? We're not reading stupid White
this? We're not reading stupid White
House articles on stream.
success rate
zero. Oh, but this is Yeah, this is only
zero. Oh, but this is Yeah, this is only
on this
on this
one motion.
This is just dash
m less bureaucracy is good.
m less bureaucracy is good.
Yes. No AI regulation.
Yes. No AI regulation.
Please let us Leave us alone and let us
Please let us Leave us alone and let us
build stuff.
Yeah, all the code in this this is just
Yeah, all the code in this this is just
all so
slow. There's only so much we can do on
slow. There's only so much we can do on
this stuff, right? It's
this stuff, right? It's
like robotics just
like robotics just
has too many years worth of accumulated
has too many years worth of accumulated
god-awful
god-awful
software. It's the type of thing where
software. It's the type of thing where
I'd like have to really focus on it for
I'd like have to really focus on it for
quite a while to like fix
quite a while to like fix
everything. There's like a very large
everything. There's like a very large
amount of stuff that you just would have
amount of stuff that you just would have
to completely scrap and rewrite.
Okay, that does look
bad. Hey bud, you live today too? Yeah,
bad. Hey bud, you live today too? Yeah,
I was working on
I was working on
um phasic policy gradients a bit
um phasic policy gradients a bit
earlier and uh we're just checking
earlier and uh we're just checking
on some code we shipped recently. I
on some code we shipped recently. I
think there's just some dumb model load
think there's just some dumb model load
mismatch or something.
Oh well here look it's now we are
Oh well here look it's now we are
getting success
right this actually should be done
right this actually should be done
pretty soon then if it's this is how
pretty soon then if it's this is how
it's doing it because
Yeah, there's only 11k of them. Okay,
Yeah, there's only 11k of them. Okay,
we'll let it finish. Assuming that's
we'll let it finish. Assuming that's
what it's going to do.
Hello YouTube
folks. I mean for reference what this
folks. I mean for reference what this
stuff is here, this is animation genrel
stuff is here, this is animation genrel
stuff. So it takes um motion data like
stuff. So it takes um motion data like
captured
captured
uh or like generated even motion data
uh or like generated even motion data
that may be messy and then it runs it
that may be messy and then it runs it
through a robotic sim runs it through
through a robotic sim runs it through
Isaac
Isaac
Jim and I mean when you're running in a
Jim and I mean when you're running in a
sim like you your foot can't go through
sim like you your foot can't go through
the ground and you can't do things that
the ground and you can't do things that
don't work with physics right so then
don't work with physics right so then
you do RL on that sim to actually make
you do RL on that sim to actually make
the thing match the original motion
the thing match the original motion
within the bounds of physics and then
within the bounds of physics and then
you get better generated animation data
you get better generated animation data
out of
that only problem is that this whole
that only problem is that this whole
area has like total total total mess of
area has like total total total mess of
software like I did a little bit on
software like I did a little bit on
cleaning stuff up here did a lot
cleaning stuff up here did a lot
cleaning stuff up here. And uh we got it
cleaning stuff up here. And uh we got it
way better than, you know, than when we
way better than, you know, than when we
started, but there's still quite a lot
started, but there's still quite a lot
that's just
tough. Okay. So here we reproduce
tough. Okay. So here we reproduce
the we reproduce the back
the we reproduce the back
rate 987.
Oh, Kung's around. Perfect. Hey, Kung.
Oh, Kung's around. Perfect. Hey, Kung.
So, I we reproduced the batch success
So, I we reproduced the batch success
rate. Is there a way we can just like
rate. Is there a way we can just like
get random batches of motions without
get random batches of motions without
taking forever and just like see them
taking forever and just like see them
play so we can see if they're working?
That would be
ideal. Streaming. Looks like one minute
ideal. Streaming. Looks like one minute
delayed. It shouldn't
delayed. It shouldn't
be.
be.
Um, hang
Um, hang
on.
Oh, on this whole file.
Maybe this just
Maybe this just
works. Oh gosh.
It takes forever to
load. Oh, here it is.
You kind of
can't you can't move the camera, right?
Press left.
Press left.
Right.
Right.
Oh, thank you. Jump.
play shows you
16. So yeah, the sitting down one is
16. So yeah, the sitting down one is
like Oh, it actually even does that
like Oh, it actually even does that
sometimes. That's
sometimes. That's
crazy. Yeah, these are these look very
good. These look very good.
It looks to me like it works as is. I'm
It looks to me like it works as is. I'm
trying to figure out what the heck they
trying to figure out what the heck they
did now. They sent me a repo invite that
did now. They sent me a repo invite that
uh I can't show on
stream. Like they w they didn't give me
stream. Like they w they didn't give me
uh good information about like what it
uh good information about like what it
was that they like how it was that they
was that they like how it was that they
were trying to do stuff cuz like yeah,
were trying to do stuff cuz like yeah,
when we run your stuff it works as is.
The only thing that was rough, which is
The only thing that was rough, which is
why I had to bo, like why I started
why I had to bo, like why I started
bothering you about this, is I couldn't
bothering you about this, is I couldn't
get it to run initially. Um, I had to
get it to run initially. Um, I had to
modify the Docker container to have more
modify the Docker container to have more
memory or it would just crash. So, I was
memory or it would just crash. So, I was
like, okay, there's something screwy.
like, okay, there's something screwy.
And then when you only run like the
And then when you only run like the
first eval step or whatever, it shows
first eval step or whatever, it shows
zero success rate. I don't know why, but
zero success rate. I don't know why, but
then when you run the full data set, it
then when you run the full data set, it
shows way higher. To be clear, this is
shows way higher. To be clear, this is
not picking success motions out, right?
not picking success motions out, right?
This is just random
motions. Like there's occasionally nams,
motions. Like there's occasionally nams,
I guess, once in a while,
right? It looks
fine. Yeah, that's okay. Yeah, that's
fine. Yeah, that's okay. Yeah, that's
the thing Linky fixed, right? I got to
the thing Linky fixed, right? I got to
integrate all that stuff
in. I mean, that's pretty impressive,
in. I mean, that's pretty impressive,
right? That's like hard to
do. Most of them. Yeah, it's like 98 or
do. Most of them. Yeah, it's like 98 or
something percent.
Let me see if I can pull up this repo on
Let me see if I can pull up this repo on
in a separate tab and just see if
in a separate tab and just see if
there's
anything
Let's go over
here. They probably like doing something
here. They probably like doing something
spree with the loading.
Where do invites go?
See if I've gotten invites.
Oh, is
Oh, is
Hang on. This
is Let me see if this is open source. If
is Let me see if this is open source. If
it's open source, I can show
it's open source, I can show
it. It says it looks like they're
it. It says it looks like they're
intending to make it open source, but
um like they've got stuff in there like
um like they've got stuff in there like
that would imply that. But yeah. Okay. I
that would imply that. But yeah. Okay. I
think that they're going to release the
think that they're going to release the
thing with their modifications
soon. How would you upload these
soon. How would you upload these
movements to an actual
movements to an actual
robot? Um, so this is SNPL. You would
robot? Um, so this is SNPL. You would
have to do the same thing on like you
have to do the same thing on like you
would have to retarget the motions to
would have to retarget the motions to
uh to a robot like to the actual rig for
uh to a robot like to the actual rig for
the remote robot itself and then address
the remote robot itself and then address
like any weird Real stop.
See if there's anything I can
show. What's up with the Nans?
show. What's up with the Nans?
Presumably just diverging trajectories
Presumably just diverging trajectories
like the loss is going to be a squared
like the loss is going to be a squared
error. So as soon as the thing falls
error. So as soon as the thing falls
over, it just goes crazy.
Yeah, I'm doing
Yeah, I'm doing
uh RL pretty much 247 these
uh RL pretty much 247 these
days. Okay. Well, I don't think that
days. Okay. Well, I don't think that
there's too much I can do on the thing
there's too much I can do on the thing
for them now. Um, I kind of just got to
for them now. Um, I kind of just got to
chat with them at some point because
chat with them at some point because
like it looks like the code for this is
like it looks like the code for this is
fine, right? We get all the motions. The
fine, right? We get all the motions. The
motions look good.
Um, yeah, I don't see any issues. I
Um, yeah, I don't see any issues. I
mean, I would presume it's got to be
mean, I would presume it's got to be
like loading screw-ups, right? Like they
like loading screw-ups, right? Like they
have their own data formats and they're
have their own data formats and they're
doing a whole bunch of data conversions.
doing a whole bunch of data conversions.
there like a ton of places that you can
there like a ton of places that you can
get stuff wrong
there and like yeah, of course we'll
there and like yeah, of course we'll
help, but um I think that the thing that
help, but um I think that the thing that
we delivered
we delivered
matches what we were supposed to deliver
matches what we were supposed to deliver
here. I don't like I don't see anywhere
here. I don't like I don't see anywhere
where like oh actually the model's
where like oh actually the model's
screwy or anything weird like that. So
screwy or anything weird like that. So
I'm not too too concerned
there. So, as long as it's um that's
there. So, as long as it's um that's
taken care of, I'm happy at least. And
taken care of, I'm happy at least. And
then uh you know, if they need extra
then uh you know, if they need extra
help, I can deal with that as
help, I can deal with that as
separately. So, I guess we can go back
separately. So, I guess we can go back
to the merge
to the merge
stuff. There really isn't any impediment
stuff. There really isn't any impediment
now to merging,
now to merging,
right? It's 4:38. The only thing is like
right? It's 4:38. The only thing is like
I have an hour before I've got to run
I have an hour before I've got to run
for dinner. It's not a terrible thing.
for dinner. It's not a terrible thing.
Like the dev branch is broken anyways,
Like the dev branch is broken anyways,
right? It's not bad if I just do the
right? It's not bad if I just do the
merge and then start working on it and
merge and then start working on it and
get as far as I
get as far as I
can. I don't see any reason not to just
can. I don't see any reason not to just
do
that. Yeah, let's just do
that. Yeah, let's just do
that. Let me get my uh my original
that. Let me get my uh my original
Docker
back. So, now we'll actually get to some
back. So, now we'll actually get to some
interesting depth where I can actually
interesting depth where I can actually
show stuff.
I just wanted to make
I just wanted to make
sure that the thing that we delivered
sure that the thing that we delivered
was what we said it was. And it is
Just
Sorry.
Well, we can just do
merge. So, I'm going to have to
merge. So, I'm going to have to
immediately fix a ton of stuff with
immediately fix a ton of stuff with
this.
Um, not too well. That would be
Um, not too well. That would be
terrible. We do this first.
Big merch.
Okay. So, this is no big deal.
I'm gonna have to get Kung some robots
I'm gonna have to get Kung some robots
so like he can actually do
robotics. I wonder if I get him some
robotics. I wonder if I get him some
like some robot like some robots that he
like some robot like some robots that he
can remotely control.
can remotely control.
Maybe then I can get him to keep doing
Maybe then I can get him to keep doing
puffer dub
[Music]
stuff. Just like get him a whole ass
stuff. Just like get him a whole ass
unit tree or something that he can just
unit tree or something that he can just
like walk around the uh the puffer
like walk around the uh the puffer
facility. You can train the robot to
facility. You can train the robot to
like do cluster maintenance or
whatever or try to
Oops. Put a cam on it in the corner of
Oops. Put a cam on it in the corner of
your stream. Actually, the uh the new
your stream. Actually, the uh the new
stream is going to have a full view of
stream is going to have a full view of
the facility. It's going to be really
the facility. It's going to be really
cool. Have all the servers in the
background. It's nicely set up for that.
Feels good to be back on the dev branch.
Feels good to be back on the dev branch.
You have the oversized American flag
You have the oversized American flag
yet? We have one. I don't know if it's
yet? We have one. I don't know if it's
big enough. I think it's like a 15t
big enough. I think it's like a 15t
flag. I wanted to get like a 25 foot
flag. I wanted to get like a 25 foot
flag.
Okay. So,
Okay. So,
um, yeah, with the
bindings, there's like one annoying
bindings, there's like one annoying
thing.
I don't know why.
Um I guess cuz this is only a prototype.
Um I guess cuz this is only a prototype.
I thought you'd still be able to export
it. That's
weird. Yeah, this was supposed to be
optional like I can just comment this
optional like I can just comment this
for now and uh it'll
work. This is for grid
mostly. No, but we're not going to do it
mostly. No, but we're not going to do it
in a way that it'll conflict with each
in a way that it'll conflict with each
end,
man. Like we're going to find a better
man. Like we're going to find a better
way to do it.
Why is that
not rebuild all of it?
Is there a way to make it? Yeah, we
Is there a way to make it? Yeah, we
we'll figure it out,
right? Dash force. It's good to
know. Something seems sketchy there,
but what's happened here?
Yes. Right. Merger
Yes. Right. Merger
changes. All right. So, we do your
changes. All right. So, we do your
PR
next. This one,
right? Did you break snake in one of the
right? Did you break snake in one of the
recent ones?
Okay, you didn't PR it.
Good. Yeah, snake's kind of important.
Good. Yeah, snake's kind of important.
Like we use that one pretty often for
testing. A front. The
puffer. The puffer is quite
sizable. Puffer is indeed quite sizable.
Now we get to see
Now we get to see
um how all my new stuff works,
right? Presumably this is building
right? Presumably this is building
kernels.
or
something.
Yeah. Okay. So we can track
this pop
up. These guys messaged me at all. They
up. These guys messaged me at all. They
were supposed to tell me when they were
were supposed to tell me when they were
free to meet.
They just straight up didn't message
me at five. Yeah, it's
fine. Oh, also this is the latest Neural
fine. Oh, also this is the latest Neural
MMO 3 run with the new stuff. It's kind
MMO 3 run with the new stuff. It's kind
of
of
cool. So, you can
cool. So, you can
see right here. So, this is the old one
see right here. So, this is the old one
versus the new one, I guess.
versus the new one, I guess.
So you can see with the uh new advantage
So you can see with the uh new advantage
estimation, it's like a very
estimation, it's like a very
small but consistent upgrade. It's like
small but consistent upgrade. It's like
very small but
very small but
consistent. It's like across the whole
consistent. It's like across the whole
curve. It's just very slightly
above possibly a little more stable as
above possibly a little more stable as
well.
I believe this black one
is something have a name on
it. I believe that this one was just
it. I believe that this one was just
like bigger filters that I forgot to
like bigger filters that I forgot to
like add back
in. Yeah.
in. Yeah.
We'll get to that. No worries. I mean,
We'll get to that. No worries. I mean,
still this is good
soda.
soda.
So, this is our latest one.
So, this is our latest one.
Probably it's not
bad. Yeah, good
curve. 46 uh 864 is max, but yeah, it's
curve. 46 uh 864 is max, but yeah, it's
good. That's like basically full
self. That's like it dropped a point
self. That's like it dropped a point
once or
whatever. Um, I don't know, man.
Nobody knows how to write software
anymore. Okay. palm
anymore. Okay. palm
frames and then jumps to full sol 21's
frames and then jumps to full sol 21's
full
Good. Okay. So snake is not training
Good. Okay. So snake is not training
correctly, but I saw this in my branch
correctly, but I saw this in my branch
before. There
is there's like an inconsistency. I
think Yeah, there's some like weird
think Yeah, there's some like weird
inconsistency when you use um
inconsistency when you use um
multiprocessing with this.
like that took it way longer. To be
like that took it way longer. To be
fair, it's not bad actually. That just
fair, it's not bad actually. That just
like the curve is shallower early, but
like the curve is shallower early, but
that's where it should end
up. This is fine, right?
all the way
all the way
500. It is going to dip a little bit.
500. It is going to dip a little bit.
That's normal though. It shouldn't fully
That's normal though. It shouldn't fully
crack, but it'll dip into 70s
crack, but it'll dip into 70s
sometimes. It's like a competitive
sometimes. It's like a competitive
selfplay M, right? So, dynamics are kind
selfplay M, right? So, dynamics are kind
of dependent on all the other agents
of dependent on all the other agents
what they're
what they're
doing. Yeah. Go ahead, link your run.
This branch has some slightly better
This branch has some slightly better
stuff though than
stuff though than
um previous. Oh, we're also not using
um previous. Oh, we're also not using
puffer advantage
here. We should set this to true by
here. We should set this to true by
default.
Yeah. So, that's not good,
Yeah. So, that's not good,
right? I think this was before I fixed
right? I think this was before I fixed
uh there were a few things that I fixed
uh there were a few things that I fixed
since
since
then. I mean, obviously, like you didn't
then. I mean, obviously, like you didn't
get 80 And we have 80s
get 80 And we have 80s
here. This seems good to
me. Let's set puff advantage
true. I ran that yesterday. Yeah, you
true. I ran that yesterday. Yeah, you
ran it on dev branch though, not on
ran it on dev branch though, not on
buffer branch,
right? Like I had to fix some bugs.
So, this is
So, this is
good. Let's try it with software
good. Let's try it with software
advantage just to be sure.
So I I changed the default to use puffer
So I I changed the default to use puffer
advantage. Now
that goes wrong with
score. Oh, there we go. Oh, that
score. Oh, there we go. Oh, that
actually fixed it. The puffer advantage
actually fixed it. The puffer advantage
version actually trains way more
version actually trains way more
stably. Puffer advantage for the win.
Offer advantage for the win.
We
We
evalid. Uh
evalid. Uh
yeah, presumably this is saved a
yeah, presumably this is saved a
checkpoint by now, right?
these look good,
right? Full snake
ends. Does this Does have Dion
on? No, it doesn't have Dion on.
on? No, it doesn't have Dion on.
Perfect. Yeah, that's just base
Perfect. Yeah, that's just base
training. So, yeah, this is proper
training. So, yeah, this is proper
snake. I like this emblem a lot. It's
snake. I like this emblem a lot. It's
like a really It was a really simple to
like a really It was a really simple to
code in, but it's really nice for
code in, but it's really nice for
testing and it looks really
cool. Like really, if you just get ideas
cool. Like really, if you just get ideas
for cool projects like this, you can
for cool projects like this, you can
talk these out in a couple of days and
talk these out in a couple of days and
like have them in puffer lib. So for any
like have them in puffer lib. So for any
folks watching if you want to contribute
folks watching if you want to contribute
to puffer liib something like this is a
to puffer liib something like this is a
few hundred lines of
few hundred lines of
code like maybe 200 lines of actual
logic and this has been like one of the
logic and this has been like one of the
most useful test
most useful test
ends. This was actually I think this was
ends. This was actually I think this was
the
the
first and I wrote fullc as
well. Pretty
cool. Okay. Um MMO rework. That's kind
cool. Okay. Um MMO rework. That's kind
of important, right?
415K. Not
bad. So, yeah, this is good overall as
bad. So, yeah, this is good overall as
well. I think there's still a few MS
well. I think there's still a few MS
that are kind of busted, but this is
that are kind of busted, but this is
overall
overall
um this is overall quite good.
It's 502. Uh, if I wake myself up, I
It's 502. Uh, if I wake myself up, I
think we can do a little bit more cool
think we can do a little bit more cool
dev stuff
today. I don't have mental bandwidth.
today. I don't have mental bandwidth.
Long short, what is it? Fast blow RNN's
Long short, what is it? Fast blow RNN's
today. That's going to take like I'm
today. That's going to take like I'm
gonna have to be fresher for that. But I
gonna have to be fresher for that. But I
think we can do some dying experiments
think we can do some dying experiments
and see on that.
So, we'll do some uh we'll do some like
So, we'll do some uh we'll do some like
cool like
cool like
multi- was it like behavior conditioned
multi- was it like behavior conditioned
or skill condition policy experiments in
or skill condition policy experiments in
a second. Use the restroom and grab a
a second. Use the restroom and grab a
drink though and I'll be right back.
drink though and I'll be right back.
Give me like two three Yes.
Got a brief
Got a brief
spiral. Want to
spiral. Want to
merge blast star pool.
merge blast star pool.
Yeah, let me do that bit. And we'll do
Yeah, let me do that bit. And we'll do
the experiments.
First square tactical. Let me get
this. Oh, also since we're on the repo,
this. Oh, also since we're on the repo,
if you haven't started the repo, what do
if you haven't started the repo, what do
you do? It like it really helps us. Come
you do? It like it really helps us. Come
on, guys. We're almost at
2K. This one.
Yeah. Okay. New binding
file that second. So, don't merge this
file that second. So, don't merge this
first.
Okay.
puffer color is
good. Presumably, you're not looking for
good. Presumably, you're not looking for
feedback considering it's like it's a
feedback considering it's like it's a
pretty clearcut what the work is, right?
Yeah. And we need to figure out how to
Yeah. And we need to figure out how to
reduce boiler plate even more. But like
reduce boiler plate even more. But like
the new binding stuff is already a
the new binding stuff is already a
pretty darn good dent in the amount of
pretty darn good dent in the amount of
boiler plate, right? Like most of the PR
boiler plate, right? Like most of the PR
was deleting boiler plate. Very little
was deleting boiler plate. Very little
of it was adding it
back. Okay. Thank you for
back. Okay. Thank you for
PR next to PR. Oh, I didn't merge it,
PR next to PR. Oh, I didn't merge it,
did
I? Plus, plus I do this stuff. Oh, very
I? Plus, plus I do this stuff. Oh, very
nice. What's
that? I wish somebody would finish
that? I wish somebody would finish
tactical. That's a little too much for
tactical. That's a little too much for
you at the moment, bet. But
you at the moment, bet. But
um it could be a really nice end.
Yeah. So, you just messed with the
Yeah. So, you just messed with the
client a little bit,
client a little bit,
right? And
this change to client is
fine. Yeah, but it would take you quite
fine. Yeah, but it would take you quite
a while because there's like a lot of
a while because there's like a lot of
stuff going
on. I I think that The thing you would
on. I I think that The thing you would
get stuck on most likely would be the
get stuck on most likely would be the
um there's actually like probably some
um there's actually like probably some
scripted AI stuff that you'd have to do
scripted AI stuff that you'd have to do
with this, which to be fair is a great
with this, which to be fair is a great
thing to learn, but it's it's kind of
tricky. Scripted like doing scripted AI
tricky. Scripted like doing scripted AI
is honestly one of the best way to learn
is honestly one of the best way to learn
algorithm stuff.
algorithm stuff.
like because it's a ton of path finding.
like because it's a ton of path finding.
You occasionally do like mon Carlo
You occasionally do like mon Carlo
stuff. It's like search. They're like
stuff. It's like search. They're like
it's actually like a really good way to
it's actually like a really good way to
learn algo stuff, but like yeah, this
learn algo stuff, but like yeah, this
would be a bit much. Like you'd kind of
would be a bit much. Like you'd kind of
just be stuck doing this for a long
time. Like that's one of the things
time. Like that's one of the things
where it actually kind of helps to have
where it actually kind of helps to have
seen the algorithms done
seen the algorithms done
formally, right? So you're not just
formally, right? So you're not just
reading freaking Wikipedia articles.
This is just a find and replace on
This is just a find and replace on
client,
client,
right? Yeah, it totally is.
Maling
text and know that's like where you like
text and know that's like where you like
your first CS course or whatever like
your first CS course or whatever like
your first undergrad CS course or
your first undergrad CS course or
whatever usually just does
whatever usually just does
that covers all the data structures and
that covers all the data structures and
algorithms and then there's like very
algorithms and then there's like very
much diminishing it returns to
much diminishing it returns to
formalized learning after that but it's
formalized learning after that but it's
a decent base
So the 101's are kind of [ __ ] cuz a lot
So the 101's are kind of [ __ ] cuz a lot
of the first courses in CS are taught in
of the first courses in CS are taught in
Java or something just awful.
Um, I'm trying to think with the scale
Um, I'm trying to think with the scale
of stuff that you've
written. I'm trying to think if you know
written. I'm trying to think if you know
more or less CS than I
more or less CS than I
did before my freshman year.
Like I'd probably spent more time
Like I'd probably spent more time
writing code than you have by
writing code than you have by
then, but also
then, but also
like I was doing it without any form of
like I was doing it without any form of
reasonable guidance and I was just doing
reasonable guidance and I was just doing
stupid [ __ ] half the
time. So, it's kind of actually tough to
time. So, it's kind of actually tough to
say. I'll link you the course
say. I'll link you the course
afterwards. It's just 106x
I mean, there are like some obnoxious
I mean, there are like some obnoxious
things like it's taught in
things like it's taught in
C++ which is kind of
C++ which is kind of
shitty and like the lecture isn't very
shitty and like the lecture isn't very
good to be honest. The course material
good to be honest. The course material
is pretty good. The lecturer really
is pretty good. The lecturer really
isn't.
But
But
like I don't know if anybody knows if
like I don't know if anybody knows if
there's a university that has a better
there's a university that has a better
course than this, but
like they use their own shitty libraries
like they use their own shitty libraries
as well which is like it's annoying then
as well which is like it's annoying then
but yeah if you look at the assignments
but yeah if you look at the assignments
it's like implement game of life ads
boggle priority queue like these are
boggle priority queue like these are
good
good
things to implement but then that like
things to implement but then that like
the obnoxious thing about it is like so
the obnoxious thing about it is like so
you're like you open this [ __ ]
Right. This is the thing that always
Right. This is the thing that always
drove me [ __ ] crazy with
their unless it's
their unless it's
improved. Oh, actually this is better
improved. Oh, actually this is better
than it used to
be. I guess like they give you this
be. I guess like they give you this
obnoxious graphics
obnoxious graphics
library. This isn't that bad though.
library. This isn't that bad though.
So, one of my big complaints when I took
So, one of my big complaints when I took
it was they just gave you way too much
it was they just gave you way too much
starter code for [ __ ] So, like half the
starter code for [ __ ] So, like half the
assignment wasn't even implement X. It
assignment wasn't even implement X. It
was like figure out what their garbage
was like figure out what their garbage
starter code
starter code
does, which just drove me [ __ ]
does, which just drove me [ __ ]
nuts. But like this is stuff that you
nuts. But like this is stuff that you
generally should see in a formal
generally should see in a formal
setting.
Also, this course is intend this course
Also, this course is intend this course
is intended to be hard, by the way.
is intended to be hard, by the way.
Um, like this is usually the thing that
Um, like this is usually the thing that
most Stanford freshmen end up spending
most Stanford freshmen end up spending
20 hours a week
20 hours a week
on at least. Well, not really. 15 to 15
on at least. Well, not really. 15 to 15
to 25 hours a week.
It's a bunch of data structure stuff
that that's like very confusing when you
that that's like very confusing when you
see it for the first time.
Okay. So everything should be
merged. And we should still have a
merged. And we should still have a
little bit of time to a couple
experiments. I want to see what version
experiments. I want to see what version
I left in here.
Okay. So I want the other form of
this and I want the other form of this.
this and I want the other form of this.
So I basically there are two different
So I basically there are two different
forms of this algorithm I was
forms of this algorithm I was
experimenting with. One of them they
experimenting with. One of them they
both work on se on subsampled sequences.
both work on se on subsampled sequences.
So in one of them you take all the
So in one of them you take all the
observations from the trajectory
observations from the trajectory
segment. You down sample by a factor of
segment. You down sample by a factor of
eight. So you just take every eighth
eight. So you just take every eighth
sample, you run it through a little bit,
sample, you run it through a little bit,
a little model and you try to estimate
a little model and you try to estimate
which policy uh this segment came from.
which policy uh this segment came from.
So by what the agent was doing like
So by what the agent was doing like
which policy is
which policy is
this? The other form is you do the same
this? The other form is you do the same
thing except you use actions instead of
thing except you use actions instead of
states. So just by looking at the
states. So just by looking at the
sequence of actions the agent take uh
sequence of actions the agent take uh
took what policy is it? Uh the state one
took what policy is it? Uh the state one
is much more powerful, but you have to
is much more powerful, but you have to
do reinforcement learning to learn that
do reinforcement learning to learn that
objective. The the actionbased
objective. The the actionbased
formulation is a lot weaker because
formulation is a lot weaker because
you're only seeing the actions without
you're only seeing the actions without
the context of state, but it's fully
the context of state, but it's fully
differentiable. So you don't have to do
differentiable. So you don't have to do
RL. It's a supervised learning
RL. It's a supervised learning
task, which makes it really
easy. Actually, isn't this entire
thing? Yeah, this entire thing is
thing? Yeah, this entire thing is
redundant. If we're going to do the
redundant. If we're going to do the
other
version, wait,
what? Oh, I guess I just like moved the
what? Oh, I guess I just like moved the
previous. Yeah, that's fine. Just do
previous. Yeah, that's fine. Just do
this. It's basically the same
thing. State batch logs.
This isn't the spot for this boss to
go. I think I made a commit with the
go. I think I made a commit with the
exact version that I needed at some
exact version that I needed at some
point recently.
Where is this
thing? I know. I gave it a
thing? I know. I gave it a
decent commit message as
well. Dang. Okay. Well, we'll just redo
well. Dang. Okay. Well, we'll just redo
it. It's not a big
deal. It should just be like
something like that.
Yeah, something like
this. Then all we have to do
is discriminator here needs to not
is discriminator here needs to not
be this. It needs to be acting face
be this. It needs to be acting face
shape.
action space.
Then just trim forward. I think I
Then just trim forward. I think I
actually was doing this on snake before.
actually was doing this on snake before.
Why don't we just do it over
there? Just put this
model. Yeah. So there it is.
model. Yeah. So there it is.
You can see this was the supposed to be
You can see this was the supposed to be
the state based one or whatever.
That looks good to me. You just give it
That looks good to me. You just give it
like a little two layer net.
And this should have a brim forward,
And this should have a brim forward,
right? Maybe
snake. This
So this needs to get reshaped I
believe. Where is this getting called
believe. Where is this getting called
wrong?
Right. So,
Right. So,
uh this is not needed here. This is the
uh this is not needed here. This is the
other version of it.
This is 128x 64x4.
This is how you do
this. There was like a whole bunch of
this. There was like a whole bunch of
stuff I would do with this as well
stuff I would do with this as well
actually.
Yeah. Was
this I
I think I actually just put this into a
I think I actually just put this into a
soft max, didn't
soft max, didn't
I? Yeah, I think we just put this into
I? Yeah, I think we just put this into
softmax.
Let's see what this gives
Let's see what this gives
us. Welcome YouTube folks. We have quite
us. Welcome YouTube folks. We have quite
a fair few people watching this at the
a fair few people watching this at the
moment. I'm here for another 15 minutes
moment. I'm here for another 15 minutes
and then I probably will be back after
and then I probably will be back after
dinner. We'll see. But uh what this is
dinner. We'll see. But uh what this is
at the moment, this is diversity is all
at the moment, this is diversity is all
you need name of algo. um it works by
you need name of algo. um it works by
adding a one hot vector to the
adding a one hot vector to the
observation space of your agent uh that
observation space of your agent uh that
is representing a skill. So you come up
is representing a skill. So you come up
with eight skills for instance and you
with eight skills for instance and you
give each agent a skill vector and then
give each agent a skill vector and then
what you try to do is you try to train a
what you try to do is you try to train a
separate network that predicts which
separate network that predicts which
agent uh it is like which skill vector
agent uh it is like which skill vector
it actually has based on what the agent
it actually has based on what the agent
does. So in doing that you try to create
does. So in doing that you try to create
a policy that can behave in many
a policy that can behave in many
different distinguishable ways. So you
different distinguishable ways. So you
have one policy that can take lots of
have one policy that can take lots of
different sort of types of play. That's
different sort of types of play. That's
what we're doing at the moment. Uh this
what we're doing at the moment. Uh this
is actually now in the dev branch as
is actually now in the dev branch as
well of puffer. So you can check it out
well of puffer. So you can check it out
there and do start the repo. It helps me
there and do start the repo. It helps me
a
ton. Fix grid reset. Grid reset is kind
ton. Fix grid reset. Grid reset is kind
of hard. Uh, Bridge is the one that
of hard. Uh, Bridge is the one that
needs the shared stuff,
but I want to at least see if I can get
but I want to at least see if I can get
this to work as well because this is
this to work as well because this is
going to be more
entertaining. Okay, so this is 32 input
entertaining. Okay, so this is 32 input
dim,
right?
right?
Reasonable. Mostly reasonable.
Uh, grid is the one that has the shared
Uh, grid is the one that has the shared
thing
that
mute. That's a weird
error. Just scrim forward.
Really? Oh, probably the one hop, right?
Okay, this
Okay, this
runs. Put on Neptune.
So the one thing with this is that the
So the one thing with this is that the
uh the loss is usually like really
uh the loss is usually like really
really low. The neural net is really
really low. The neural net is really
good at figuring out which agent has
good at figuring out which agent has
which skill vector.
that goes up a little bit
sometimes. So, we will see what this
does. There
does. There
are So, here's the thing that I was
are So, here's the thing that I was
trying to figure out with this
trying to figure out with this
algorithm, right? I pulled up the paper.
algorithm, right? I pulled up the paper.
needs. So, okay. Let
needs. So, okay. Let
me So, it's this paper right here. It's
me So, it's this paper right here. It's
a pretty cool paper. Uh the math in here
a pretty cool paper. Uh the math in here
is like makes it sound way more
is like makes it sound way more
complicated than it
complicated than it
is. This is kind of the algorithm
is. This is kind of the algorithm
here. This math is like pretty
here. This math is like pretty
redundant. The thing is that there are
redundant. The thing is that there are
if you like look at this, there are some
if you like look at this, there are some
obvious extensions of this and like the
obvious extensions of this and like the
original form is not great. So I kind of
original form is not great. So I kind of
took the idea of
took the idea of
conditioning an agent with a skill
conditioning an agent with a skill
vector in order to distinguish between
vector in order to distinguish between
different uh different
different uh different
behaviors and I instead of doing it on
behaviors and I instead of doing it on
the transition level I do it at the
the transition level I do it at the
segment
segment
level. So uh you take the whole like
level. So uh you take the whole like
64st step segment or something like
64st step segment or something like
that,
that,
right? And you just take uh you down
right? And you just take uh you down
sample it, you pass it into the
sample it, you pass it into the
discriminator and then you determine
discriminator and then you determine
what policy it is based on that.
Now, what I would really like to do
Now, what I would really like to do
ideally is I'd like to have some way of
ideally is I'd like to have some way of
defining a supervised loss that takes
defining a supervised loss that takes
into account the agent actions and the
into account the agent actions and the
agent observations or even just the
agent observations or even just the
agent
agent
observations. But the thing is like
observations. But the thing is like
observations are not
observations are not
differentiable and there's no way that
differentiable and there's no way that
observations directly are differentiably
observations directly are differentiably
affect the policy.
affect the policy.
So if you try to do it this way, you
So if you try to do it this way, you
need to use reinforcement learning to
need to use reinforcement learning to
learn which skill belongs to which
learn which skill belongs to which
agent. And like yeah, we do
agent. And like yeah, we do
reinforcement learning all day, but
reinforcement learning all day, but
ideally we don't have to add a secondary
ideally we don't have to add a secondary
RL objective into what is already an RL
RL objective into what is already an RL
problem. It's a lot cleaner and a lot
problem. It's a lot cleaner and a lot
easier to learn if you can just like add
easier to learn if you can just like add
it as an auxiliary loss
it as an auxiliary loss
basically that is supervised.
This is doing some weird interesting
things. It's definitely doing some weird
things. It's definitely doing some weird
interesting
things. How's the Dian
loss? It's just been very low the whole
loss? It's just been very low the whole
time.
I mean, it's gone back up now,
right? That snake, that is my curve from
right? That snake, that is my curve from
yesterday. The curve that you sent me
yesterday. The curve that you sent me
was in the
30s. There's a big difference between
30s. There's a big difference between
this curve being in the 30s and then
this curve being in the 30s and then
this curve being like up around here,
right? I think I will just have enough
right? I think I will just have enough
time to like get this result and then
time to like get this result and then
look at it a little bit.
shape is similar but shape that is a
shape is similar but shape that is a
reasonable shape for snake often
reasonable shape for snake often
times. Let me make sure the roll out is
times. Let me make sure the roll out is
going to be there. So we can look at
going to be there. So we can look at
these. Now the problem with this right
these. Now the problem with this right
the problem with the actionbased
the problem with the actionbased
formulation
formulation
um is that the neural net can very very
um is that the neural net can very very
accurately tell apart which agents are
accurately tell apart which agents are
doing what but we can't always so we'd
doing what but we can't always so we'd
really like it to be highle
really like it to be highle
distinguishable skills but that's very
distinguishable skills but that's very
difficult to convey right what does it
difficult to convey right what does it
mean to have highle differentiable
mean to have highle differentiable
skills that's pretty hard so this will
skills that's pretty hard so this will
be done in two minutes which will be
be done in two minutes which will be
perfect timing because we'll just we'll
perfect timing because we'll just we'll
see this we'll see the results we'll see
see this we'll see the results we'll see
what the policy is
what the policy is
And then I will uh get ready to go to
And then I will uh get ready to go to
dinner out to dinner with some
family. To be fair, that is like a nice
family. To be fair, that is like a nice
stable
stable
curve. This dip is very common as well.
curve. This dip is very common as well.
Like I've seen this even without this
Like I've seen this even without this
algorithm before. It's just like all the
algorithm before. It's just like all the
agents learn how to do stuff. Oh, shoot.
agents learn how to do stuff. Oh, shoot.
All my opponents are kind of smart now.
All my opponents are kind of smart now.
And then they kind of like figure stuff
out. Okay, we are going to see these
out. Okay, we are going to see these
results, but I will do outro stuff now
results, but I will do outro stuff now
uh before results while this finishes
uh before results while this finishes
because we do have like nine or 10 folks
because we do have like nine or 10 folks
watching now. Uh, so if you're
watching now. Uh, so if you're
interested in all this stuff, it's all
interested in all this stuff, it's all
open source reinforcement learning. You
open source reinforcement learning. You
can check it out on GitHub, start the
can check it out on GitHub, start the
repo, help me out, tough.ai. If you want
repo, help me out, tough.ai. If you want
to get involved in dev, join the
to get involved in dev, join the
Discord. Most of our top contributors
Discord. Most of our top contributors
came in with zero RL experience. Like,
came in with zero RL experience. Like,
we're happy to show you the ropes and it
we're happy to show you the ropes and it
really doesn't take much before you can
really doesn't take much before you can
start contributing really cool stuff to
start contributing really cool stuff to
this. Uh, and you can also follow me on
this. Uh, and you can also follow me on
X for more RL content. We've got a quick
X for more RL content. We've got a quick
start guide on the blog as well as on X
start guide on the blog as well as on X
that I really recommend to new folks,
that I really recommend to new folks,
but uh there's more on X as well. Okay,
but uh there's more on X as well. Okay,
let's work
let's work
on almost there. Let's see what this
on almost there. Let's see what this
policy
does. So close to 2K stars as well. Like
does. So close to 2K stars as well. Like
just a few
just a few
more. 2K is a huge repo in RL.
more. 2K is a huge repo in RL.
like I'm pretty happy with
like I'm pretty happy with
it. Thanks for the link.
Bet 92. Okay, that's actually a very
Bet 92. Okay, that's actually a very
good score. And that was like a pretty
good score. And that was like a pretty
stable
So each color should be a different
scale. The model can tell these apart
scale. The model can tell these apart
like perfectly.
like perfectly.
is the other funny thing about
this. First of all, this is just like a
this. First of all, this is just like a
very good
model. But the model can tell these
model. But the model can tell these
apart perfectly just by looking at the
apart perfectly just by looking at the
actions that each one of these is
actions that each one of these is
taking. Not even looking at their
taking. Not even looking at their
surroundings, just looking at the
surroundings, just looking at the
actions that each one of these is
actions that each one of these is
taking.
Um, I can't personally say for sure
Um, I can't personally say for sure
which a how each agent is different
here. But also, this might not be the
here. But also, this might not be the
best end for testing that, right? We
best end for testing that, right? We
could probably come up with some ends
could probably come up with some ends
where it would be a lot more
where it would be a lot more
clear, like the play style difference
clear, like the play style difference
maybe.
they're doing. Yeah, this is 90. This is
they're doing. Yeah, this is 90. This is
92 score. So, this is very
good. We will continue doing research on
good. We will continue doing research on
this, I think, over the next couple of
this, I think, over the next couple of
days. Like, this is one of the things we
days. Like, this is one of the things we
definitely want to uh we definitely want
definitely want to uh we definitely want
to include in the stuff that we're
to include in the stuff that we're
looking at. So very likely that this
looking at. So very likely that this
will be part of Puffer in some
will be part of Puffer in some
way. So yeah, thank you folks for tuning
way. So yeah, thank you folks for tuning
in. I will probably be back after
in. I will probably be back after
dinner. puffer.ai for all the things.
And uh Discord is just discord
