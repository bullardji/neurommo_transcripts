Kind: captions
Language: en
good
good
afternoon we are
live stuff has been busy but I got a
live stuff has been busy but I got a
couple hours to get some things done on
couple hours to get some things done on
stream
stream
now so I'm back for a little
now so I'm back for a little
bit let's
see is anything blowing up in Puffer
what it you just have to
add uh actually no the way I have it is
add uh actually no the way I have it is
is pretty tricky
realize there's a
realize there's a
[Music]
Discord all
Discord all
right so we have uh the stuff I want to
right so we have uh the stuff I want to
do than C
welcome got tied up with meetings today
welcome got tied up with meetings today
meetings and trying to finish assembling
meetings and trying to finish assembling
my power rack it's not fully done yet
my power rack it's not fully done yet
it's
it's
usable but uh we have a mess to deal
usable but uh we have a mess to deal
with on that tomorrow
with on that tomorrow
anyways
anyways
um I want to look at some of our
um I want to look at some of our
experiments right now so we can figure
experiments right now so we can figure
out what's going to happen next with uh
out what's going to happen next with uh
the new algorithm with sweeps with
everything when you little analysis
everything when you little analysis
probably implement a few small things
probably implement a few small things
and then we will see from
here there are a couple different things
here there are a couple different things
I'd like to try actually I'm to think of
it
tag okay
you got guys you got to Center this like
you got guys you got to Center this like
this has to be left aligned I don't know
this has to be left aligned I don't know
what they're doing
here this one is auto scale
p301 okay so this is
p301 okay so this is
P30 and then I think this
P30 and then I think this
is break up fast okay
let's see if this is what we
expect so both of
expect so both of
these score just
fine time step breakdown is
fine time step breakdown is
similar it's like we should actually
similar it's like we should actually
increase Horizon Maybe
you can see here gamma and Lambda are
you can see here gamma and Lambda are
more directed
more directed
looking they're all over the place here
looking they're all over the place here
because they don't
matter learning rate is way more
matter learning rate is way more
controlled here as well which is
interesting do they end up in a similar
interesting do they end up in a similar
spot
spot
01 no they don't don't end up in a
01 no they don't don't end up in a
similar spot at
similar spot at
all difference the left is p3o which is
all difference the left is p3o which is
the new algorithm the right is
p
ends this is also you know I actually do
ends this is also you know I actually do
have some hope
have some hope
here
um CU it looks like the one on the left
um CU it looks like the one on the left
hasn't found the uh the fast settings
hasn't found the uh the fast settings
yet what do you think about the kinetics
yet what do you think about the kinetics
frame work uh we just we started adding
frame work uh we just we started adding
a preliminary binding for kinetics last
a preliminary binding for kinetics last
week to puffer lib and we got stuck we
week to puffer lib and we got stuck we
did add add one for craftex we have a
did add add one for craftex we have a
formal collaboration with uh Jacob
formal collaboration with uh Jacob
forester's lab as well to like add
forester's lab as well to like add
bindings and stuff for their stuff um I
bindings and stuff for their stuff um I
was supposed to do this like right after
was supposed to do this like right after
Nerfs and then I was in the hospital
Nerfs and then I was in the hospital
with pneumonia and then everything got
with pneumonia and then everything got
shaken up so I started on that last week
shaken up so I started on that last week
and we will be continuing that you know
and we will be continuing that you know
periodically we do a couple things for
periodically we do a couple things for
other
other
labs but we have to get our own research
labs but we have to get our own research
and our own stuff on track as
and our own stuff on track as
well connetics is a very good project I
well connetics is a very good project I
the one thing I will say it's an
the one thing I will say it's an
incredibly impressive project uh even if
incredibly impressive project uh even if
I were they were to have done it the way
I were they were to have done it the way
that I would have suggested the way they
that I would have suggested the way they
did it it like it was about 10 times
did it it like it was about 10 times
more work than it needed to be I think
more work than it needed to be I think
that if they built the ends the way that
that if they built the ends the way that
we build ends in puffer they could have
we build ends in puffer they could have
done it and it would have still been
done it and it would have still been
hard even then but it would have been
hard even then but it would have been
like a tenth of the work as it actually
like a tenth of the work as it actually
took them so I hope that in the future
took them so I hope that in the future
we can make it way easier for them to uh
we can make it way easier for them to uh
to be building new Ms like this because
to be building new Ms like this because
writing stuff in Jacks it's just not a
writing stuff in Jacks it's just not a
fun
fun
time I mean literally they went and
time I mean literally they went and
reimplemented the entire thing in
reimplemented the entire thing in
JavaScript just to have it be playable
JavaScript just to have it be playable
on the web so that you could fiddle with
on the web so that you could fiddle with
it there and like we get that for free
it there and like we get that for free
with all of our
Puffs and they're faster
okay
okay
so we can see that this is about twice
so we can see that this is about twice
as
as
expensive uh in terms of wall clock time
expensive uh in terms of wall clock time
as this now if I were to
do what if I were to do total time steps
do what if I were to do total time steps
instead
okay okay so you get out to about 75
okay okay so you get out to about 75
million
million
here 8 2 million here so these are
here 8 2 million here so these are
actually very
actually very
close these are very very
close I think if we can just fiddle
close I think if we can just fiddle
with nice cup bro that's crazy
with nice cup bro that's crazy
yeah um
yeah um
if we can just get this thing to be a
if we can just get this thing to be a
little faster in wall clock time which
little faster in wall clock time which
we have optimizations for
we have optimizations for
that and then if we can get this to
that and then if we can get this to
discover these hyper parameters I think
discover these hyper parameters I think
we can get this to work I think we
we can get this to work I think we
should be able to get this to
work actually is this let me
work actually is this let me
see cost
yeah so this
is it's actually a little faster now
is it's actually a little faster now
it's like a little under 100 seconds
it's like a little under 100 seconds
this is a little under 200ish right yeah
this is a little under 200ish right yeah
so it's got
so it's got
2x but then it didn't figure out the
2x but then it didn't figure out the
number of end thing
number of end thing
right I go to sample
right I go to sample
here go to numm
63 oh no it figured out uh
63 oh no it figured out uh
500 it's pretty well there with a
500 it's pretty well there with a
th000 oh but it didn't do 2,000 that's
th000 oh but it didn't do 2,000 that's
the issue so it didn't get it with 2,000
the issue so it didn't get it with 2,000
Ms and then update Epoch
Ms and then update Epoch
maybe mostly with one update so it's
maybe mostly with one update so it's
very close though that's very close
why are you
why are you
sweeping it doesn't matter it should
sweeping it doesn't matter it should
just learn to ignore it I mean I could
just learn to ignore it I mean I could
take it out but you can see based on the
take it out but you can see based on the
charts though that it doesn't
matter okay so I mean the only thing
matter okay so I mean the only thing
that this one didn't
that this one didn't
find and to be fair this one is
find and to be fair this one is
probably these are probably some of the
probably these are probably some of the
best runs right
here so it didn't find these
points and then mini badge
signs it also have smaller mini batch
signs it also have smaller mini batch
size it didn't find 8K mini batch
size it didn't find 8K mini batch
interesting I wonder if that is
interesting I wonder if that is
something fundamental with the
something fundamental with the
algor I
algor I
wonder but we can basically see that it
wonder but we can basically see that it
has it's using half the number of
has it's using half the number of
environments and half the mini batch
environments and half the mini batch
size and then also it has um there's
size and then also it has um there's
just some CPU overhead that we have to
just some CPU overhead that we have to
fix
fix
um so I don't know if we can get it to
um so I don't know if we can get it to
train as well with the same params as po
train as well with the same params as po
we'll see
we'll see
we're definitely going to
try do we also know the uh the steps per
try do we also know the uh the steps per
second that would actually be a good one
second that would actually be a good one
to know do we log SPS I think we
to know do we log SPS I think we
do hold on if I were to just
add
scatter and then what we do is yes
scatter and then what we do is yes
PS
last
score ah there we
score ah there we
go that's clever
right I refresh
right I refresh
this there we go
this there we go
so you can see the speed difference
so you can see the speed difference
right
so
so
PO is able to get Max score up to about
PO is able to get Max score up to about
1.1 million steps per
1.1 million steps per
second where our P30 only goes up to a
second where our P30 only goes up to a
bit over
400k so
we can bring that up I think we might
we can bring that up I think we might
have a chance of M of
matching first thing is going to
matching first thing is going to
be to deal with the
be to deal with the
overhead of the current P30
overhead of the current P30
implementation we move over to coding
Land where's our term
the in I need to get myself a little
the in I need to get myself a little
stream
overlay that'd be
fun Dev
so breakout
so breakout
mode when we run this thing
mode when we run this thing
normally 1.2 million steps per
normally 1.2 million steps per
second misk is train Mis percentage is
second misk is train Mis percentage is
about 8% here
about 8% here
but 8% in frame
miss.
then goes up
to about
30% 30%
30% 30%
so we have about
so we have about
22% right here uh that we are leaking
22% right here uh that we are leaking
now this does not account for the perf
now this does not account for the perf
gap on its
gap on its
own does not account for the perf gap on
own does not account for the perf gap on
its
its
own but this is a good first
own but this is a good first
step and I think that we can maybe even
step and I think that we can maybe even
correct some stuff in the
correct some stuff in the
process breakout. C let me see okay
process breakout. C let me see okay
nothing important here change that we
nothing important here change that we
need to
recompile so the major major issue at
recompile so the major major issue at
the moment is
in these
functions I see
functions I see
so the issue here right is that
so the issue here right is that
advantages NP here this is all in cython
advantages NP here this is all in cython
whereas for
whereas for
p3o only a part of it is in syon so if
p3o only a part of it is in syon so if
we were to Port this to scon I think we
we were to Port this to scon I think we
would be
good so let me see what variables this
good so let me see what variables this
needs this already has GS this already
needs this already has GS this already
has
has
rewards I think we need values mean and
rewards I think we need values mean and
log standard deviation don't
log standard deviation don't
we W block ask
we W block ask
block also do we need
um do we need this reward block in this
um do we need this reward block in this
mask
block let me
see yeah we do need this for a
see yeah we do need this for a
prediction
prediction
of of the value function right
okay so we will leave those as is and
okay so we will leave those as is and
then
advantages compute J
advantages ah I see the zero
here will be like this
we need to pass in
values yeah DS value is
values yeah DS value is
effectful advantages reward block is
it D forward to UNP
it D forward to UNP
value where is
it hi
now these ones here get passed
now these ones here get passed
to this rewards and mask and then this
to this rewards and mask and then this
all is going to be what we're going to P
all is going to be what we're going to P
to
see all right so we put this here as a
see all right so we put this here as a
reference
that's
me just see how this works we need to
me just see how this works we need to
pre-compute a couple things
man oh and actually we can use this as
man oh and actually we can use this as
an opportunity
to compute the uh the MTH term as well
to compute the uh the MTH term as well
can't
we but I have to figure that
out
out
well initially I think we do the simple
well initially I think we do the simple
one because this is quite a bit to
one because this is quite a bit to
figure out so essentially like all these
figure out so essentially like all these
Transformations there's stuff that can
Transformations there's stuff that can
happen with the masking to make it
happen with the masking to make it
slightly more
slightly more
correct uh and we have to make sure
correct uh and we have to make sure
that we're doing all of that
go now we have M Min and Ma Max
this is the reward this is the mask
this is the reward this is the mask
right
minus sum values equal one okay
so
so
advantages of
advantages of
I is I
FL
FL
R are
rewards
R
minus
minus
values we also need to add the uh where
values we also need to add the uh where
is
is
it values mean it
it values mean it
float values
float values
mean
Lo
Lo
values STG
[Music]
okay and if you're here you already have
okay and if you're here you already have
checked the mass block so we can skip
checked the mass block so we can skip
that so now the only thing we need to do
that so now the only thing we need to do
is multiply by Advantage scale
Advantage
scale value standard deviation okay so
scale value standard deviation okay so
we do
we do
advantages I is divided
advantages I is divided
by no times
by no times
equal and then we have to compute
equal and then we have to compute
Advantage
Advantage
scale which
is M Max
minus values standard deviation over and
minus values standard deviation over and
we're going to just call this
Delta see float Delta equals
okay so now we
okay so now we
take advantages it's going to be equal
take advantages it's going to be equal
to
to
this
this
difference divide by
Delta but you forgot the clipping right
so we can do at the end we can
so we can do at the end we can
do
do
if Delta is greater than
if Delta is greater than
zero or and we can do this at the end
zero or and we can do this at the end
which is going to save us a little bit
it's a little different
it's a little different
actually cuz you still need to scale it
okay let me think about this path first
divide
divide
by
Delta
see scale scale
equal now we need clip
it oh
it oh
shoot damn
shoot damn
it we forgot to Norm this didn't
we hang on maybe there's a way around
we hang on maybe there's a way around
this
look at the
math Vantage scale
times this
times this
difference dot
sum but then way to Advantage
scale
minus I actually can't tell if there's a
minus I actually can't tell if there's a
way to reduce this
AIS = -1
I just need to compute the sum per
I just need to compute the sum per
right yeah so I think that what we're
right yeah so I think that what we're
going to have to
do let's tab this
in this out
and then Advantage
and then Advantage
sum we add
hang on I'm very confused
hang on I'm very confused
here Vantage scale
man this thing is fiddly to implement
fast I'm just looking at what I've
fast I'm just looking at what I've
written
here cuz you have advantage
scale reward block minus value mean
okay the scale is the max minus the
okay the scale is the max minus the
standard
standard
deviation divide by Delta
deviation divide by Delta
clipped and then
normalized yeah I mean you need to make
normalized yeah I mean you need to make
uh
you need to make this work
It's tricky because you don't want to
have I mean the fastest thing might be
have I mean the fastest thing might be
to have
to have
uh a full advantages
buffer really prefer to avoid that but I
buffer really prefer to avoid that but I
don't see any way around it
man I can make it temporary right
Advantage
scale
e e
okay so we have now this
portion uh and actually this needs to
portion uh and actually this needs to
be X
right oh and then this is totally
right oh and then this is totally
different because this
is standard
deviation right
or is this the
same yeah this
is wait
values
Max and that is really obnoxious isn't
Max and that is really obnoxious isn't
it it's really
it it's really
obnoxious uh I think you can't compute
obnoxious uh I think you can't compute
ma Max though like
ma Max though like
this
this
because yeah you cannot compute ma
Max cuz the thing is that this is
Max cuz the thing is that this is
actually 2D
okay
okay
so Advantage
scale so now we have Max and Men right
value standard deviation
nump so we
nump so we
do B SD is going to be this XD
okay now you have Max and Men
right hold on did you just normalize
right hold on did you just normalize
this by the
entire wait you normalized this by the
entire wait you normalized this by the
entire Min and Max didn't you
entire Min and Max didn't you
uh that's
harder that is
harder that is
harder right because
then can you even do it
now you can't even do it now can you
you need a second Loop over this whole
thing I mean I can do um
bounds of um steps right
so
fiddly okay so let me try it this way
okay do this now we have the Mac we got
okay do this now we have the Mac we got
the in we got i j
k
JT delete all this
JT delete all this
and now what we do
is this is going to drive me nuts you
is this is going to drive me nuts you
can't even you still can't even do it
can't even you still can't even do it
because you still need an intermediate
buffer I don't want to recompute this x
buffer I don't want to recompute this x
it's the problem
I'm going to just Chuck this into Gro
I'm going to just Chuck this into Gro
real quick just to see not to write the
real quick just to see not to write the
code but I just want to see if there's a
simplification
e e
I just wanted this to give me like lch
I just wanted this to give me like lch
for
this okay so
this okay so
Mass block times Advantage scale times
Mass block times Advantage scale times
the word block
the word block
okay Su J yeah this is correct and then
oh it's
oh it's
stupid for
wondering if a better tool than the
wondering if a better tool than the
massively expensive llm would have been
massively expensive llm would have been
a piece of paper to write this out
myself oh it's not capable of doing it
myself oh it's not capable of doing it
it's just that stupid okay uh we're
it's just that stupid okay uh we're
closing this because this is dog [ __ ]
closing this because this is dog [ __ ]
good job Brock I don't know why I even
good job Brock I don't know why I even
bother with uh with llms it's like hey
bother with uh with llms it's like hey
they're smart now they're really smart
they're smart now they're really smart
no they're not they
no they're not they
suck waste my time almost every single
suck waste my time almost every single
time
time
it's like it's like just like lazy like
it's like it's like just like lazy like
oh yeah maybe it'll just do it for me no
oh yeah maybe it'll just do it for me no
it never does just waste the
it never does just waste the
time
stupid let me see if I can just see a
stupid let me see if I can just see a
simplification here
simplification here
so this formula where Advantage scale
is it's essentially Norm of Max minus
is it's essentially Norm of Max minus
value standard
deviation yeah so the problem here is
deviation yeah so the problem here is
that you need
um in order to normalize something
um in order to normalize something
right you either need to do it in
place you either need to do it in place
place you either need to do it in place
or uh you need to
damn it or you need another
buffer let see where I do this
batch yeah it's noxious isn't
it I don't want to change the formula at
all I guess we'll do temporary buffer
all I guess we'll do temporary buffer
for now so we can finish the experiments
for now so we can finish the experiments
and then we'll
and then we'll
uh figure out after
that for
let's go
back we're just going to assume that we
back we're just going to assume that we
have whatever we want in terms of
have whatever we want in terms of
buffers here let's just write this out
take that
then we have vstd
Max just fine
okay so we divide by
okay so we divide by
this k =
this k =
1 we do uh
1 we do uh
bounds of IAL k
scale advantage scale. suum
I'm just going to do it as stupid as I
I'm just going to do it as stupid as I
can and like get it to work and then I'm
can and like get it to work and then I'm
going to optimize some stuff I guess
going to optimize some stuff I guess
that's
that's
tricky turns out not having array
tricky turns out not having array
operations and having to not think about
operations and having to not think about
redundant copies and buffers and stuff
redundant copies and buffers and stuff
it's
hard a big deal
not advantages of IO for
not advantages of IO for
Delta it
is
is
Max
minus I and
J and then if
Delta greater than
zero divide by
Delta scale
this
this
in it's the clip
add scale equals
man do you need another buffer here this
man do you need another buffer here this
is
ridiculous I mean we're going to have to
ridiculous I mean we're going to have to
find a way to do it with fewer
buffers yeah because you need the
um you need the sum don't
you you need the sum of Advantage you
you you need the sum of Advantage you
need the sum of
need the sum of
values is that
it e
I think if you if I could do it with
I think if you if I could do it with
just
a uh log standard deviation
yeah I think if I could do this with
yeah I think if I could do this with
just uh a
just uh a
values standard deviation buffer it
values standard deviation buffer it
would be good right
so we'll just do buff
f
fine I think we're getting
fine I think we're getting
somewhere so now I have this
buffer and I can Loop over this multiple
buffer and I can Loop over this multiple
times um
potentially the first thing I need to do
potentially the first thing I need to do
with this buffer
and then we also have this bounce here
and then we also have this bounce here
which is fine
man it is crazy
man it is crazy
what a pain this just max operation and
what a pain this just max operation and
Min operation
Min operation
causes I can see why it's slow now
causes I can see why it's slow now
because this is making a million copies
because this is making a million copies
of a big array in
of a big array in
numpy so I'm not just wasting time op uh
numpy so I'm not just wasting time op uh
optimizing python overhead this is
optimizing python overhead this is
actually fundamentally too many data
actually fundamentally too many data
copies at least we're doing that
right e
yeah the segment's length buffer is
yeah the segment's length buffer is
basically
basically
required but I think that we're probably
required but I think that we're probably
going to end
going to end
up we're probably going to end up
up we're probably going to end up
providing this in the future anyways
providing this in the future anyways
so we'll keep bounds okay let's say that
so we'll keep bounds okay let's say that
we have bounds still
okay so now we have the X D stt cool now
okay so now we have the X D stt cool now
this is clipping is
this is clipping is
done now we have the Min and Max as
well now be now this is in the buffer
right it's minus vspd okay and then if
right it's minus vspd okay and then if
Delta's
Delta's
greater than zero divide by
greater than zero divide by
Delta
clip and then we have to divide
clip and then we have to divide
by the advantage scale right
by the advantage scale right
Advantage scale.
suum we do
suum we do
buff P to Advantage scale
again
bounds range
bounds range
K
okay
okay
okay what are we going to
do okay we only need to do this if
do okay we only need to do this if
uh
Delta is greater than zero this is the
Delta is greater than zero this is the
last
last
step and then we
do scale
[Music]
zero I and
J some
sum okay so we do this now we actually
sum okay so we do this now we actually
just have the sum
here Advantage
scale then we divide these by the
sum
okay and now we have it
okay and potentially we can compress
okay and potentially we can compress
those Loops but now I think we actually
those Loops but now I think we actually
have it fully
vantages
I we don't need to do mask
I we don't need to do mask
block this is buff i
block this is buff i
j times reward block
j times reward block
IJ minus values
mean see this is i
j you
j you
beautiful I'm going to go use the
beautiful I'm going to go use the
restroom and then we are going to check
restroom and then we are going to check
this be right
back
e e
all right so I actually think this is
all right so I actually think this is
going to be better than the original
going to be better than the original
because this one actually correctly
because this one actually correctly
accounts for um for
accounts for um for
masking if it's worse then that'll be
masking if it's worse then that'll be
weird but we'll see
let me make sure that we get this
let me make sure that we get this
correct fully though actually I'm going
correct fully though actually I'm going
to pull up the so here's the original
to pull up the so here's the original
right
here so the first thing we do is we
compute here's the
compute here's the
original this to
original this to
zero what did we end up needing as well
zero what did we end up needing as well
we ended up needing one buffer
we ended up needing one buffer
array we ended up needing
bounds and then we ended up
needing advantages okay so we have to
needing advantages okay so we have to
set advantages to
zero okay cool
zero okay cool
now this one here
has this is going to compute
has this is going to compute
the so this has to be k equals
the so this has to be k equals
z i j k and t set K to zero
here me see if we're done we increment K
here me see if we're done we increment K
so we actually get our our bound length
so we actually get our our bound length
reward is t + one we set this to reward
reward is t + one we set this to reward
we set the mask to
one yeah because the rest of the Mask is
one yeah because the rest of the Mask is
zeroed by default okay advantages this
zeroed by default okay advantages this
is
is
not this is not used
not this is not used
right R minus values mean yeah this is
right R minus values mean yeah this is
not
used we get the value log standard
used we get the value log standard
deviation
deviation
T we clamp it we take X which
T we clamp it we take X which
is
X it's
FX isn't
it oh it's just
X by X of the standard deviation
X by X of the standard deviation
then we
then we
set all so now we have standard
set all so now we have standard
deviations computed and then we do Max
deviations computed and then we do Max
Max Min Min this is online Max and Min
Max Min Min this is online Max and Min
cool Delta
cool Delta
[Music]
is wrong way Max minus
is wrong way Max minus
Min we have Advantage scale and
Min we have Advantage scale and
Advantage sum
two
two
floats we're going to go up to the
floats we're going to go up to the
bounds Advantage scale
bounds Advantage scale
is Max minus standard
deviation Delta's bigger than
deviation Delta's bigger than
zero then we
will divide by Max minus
will divide by Max minus
Min and then we will clamp it
Min and then we will clamp it
from 0.5 to
one and then we're going to add this
one and then we're going to add this
to
Advantage
Advantage
sum so sum has to be set to zero
sum so sum has to be set to zero
here okay and we set this
here okay and we set this
scale
scale
here okay and then the if uh
here okay and then the if uh
Delta is greater than zero then we
Delta is greater than zero then we
divide by Advantage sum so we nor them
divide by Advantage sum so we nor them
by that
by that
row and then we just have to compute the
row and then we just have to compute the
final Advantage
final Advantage
here which is going to be the
here which is going to be the
buffer
buffer
times reward
times reward
block minus the value
block minus the value
mean and since this is an accumulation
this should give us the correct
advantages
advantages
okay sure we'll have to fix some stuff
okay sure we'll have to fix some stuff
but this is pretty
but this is pretty
good pretty pretty
good pretty pretty
good let's just figure out the order
good let's just figure out the order
that we want this
signature
buffer advantages
bounce let's just do
this now let's go see where we call this
this now let's go see where we call this
so we know the order to call it
in the reward
in the reward
block reward
block reward
mask values me numpy
mask values me numpy
values
values
buff and then was an experienced do
buff experience
bouns
gu hang on Buffer
DS NP rewards
NP
advantages inst start bounds inst start
advantages inst start bounds inst start
Horizon so this is now the right order
Horizon so this is now the right order
for these and we have to allocate these
for these and we have to allocate these
extra
buffers it shouldn't be too bad
[Music]
[Music]
use values
Norm hang values
Norm hang values
Norm this is not
Norm this is not
used all right so Advantage is
nump self.
nump self.
buff give it a buffer give it
buff give it a buffer give it
advantages
bounce get another one of
these so buff advantages and I think
these so buff advantages and I think
that's it
and now you
and now you
have
advantages find B dis
advantages find B dis
[Music]
[Music]
advantages and you don't actually
advantages and you don't actually
want no this is
want no this is
fine and you don't need this to be a by
fine and you don't need this to be a by
ex's either it's just a
buffer do like this
what I do
here values
I this is buff
canot change aign type float to
int there we
go Max maybe where is it
M Min may be used
uninitialized yep it
uninitialized yep it
is this is
is this is
vstd vstd MX
M and then this doesn't need to be M Max
M and then this doesn't need to be M Max
it's
Max all right now does compile without
Max all right now does compile without
warnings
no okay now this works
no okay now this works
okay yeah this
works must be real
works must be real
number not C advantage. memory view
number not C advantage. memory view
slice
slice
so let me see
log this is not t this is I and J is
log this is not t this is I and J is
what this has to be
there we
go okay so this runs I assume that this
go okay so this runs I assume that this
is
now scyon
where's my HTML file
there we
go okay and now this is going to show up
uh I actually do not
uh I actually do not
see yeah there's nothing wrong with this
see yeah there's nothing wrong with this
so why is it so
slow on
what with uh
what with uh
profiles C
profiles C
and the profile custom was at zero
and the profile custom was at zero
before right
yeah
and run the setup. p
okay down to 14 what is it
okay down to 14 what is it
15% but MK is just as
15% but MK is just as
high not
high evidently we need this um
high evidently we need this um
this function to be much
this function to be much
faster it's very weird
though that's very weird
this function is very expensive
I mean this is written
I mean this is written
correctly oh wait nope I'm wrong
yeah this is wait isn't
yeah this is wait isn't
this th
steps oh no yeah this is
right
what I did not expect this to still
what I did not expect this to still
still be slow
I guess one of the things we can
I guess one of the things we can
do so we have
do so we have
uh where is it this
one it's got to be this one
one it's got to be this one
right yeah this
one there's the burito front
okay this looks pretty good
right so let's take these
parameters for
oh we don't need Lambda and Gamma for
oh we don't need Lambda and Gamma for
this
this
lovely so we do learning
rate for
there update
epox where's batch size as well we
epox where's batch size as well we
forgot batch size
now this is
now this is
exactly exactly what we want
TR this
this then we do
this then we do
this
charts and
charts and
yeah here we
are essentially we will see whether I
are essentially we will see whether I
toally toally messed up the function IF
toally toally messed up the function IF
function is correct and just slow or
function is correct and just slow or
what's going on
it is possible that hypers need to be
it is possible that hypers need to be
retuned a little bit
h
I don't know I was hoping this would
I don't know I was hoping this would
just work better because we technically
just work better because we technically
I think fixed the uh fix some bugs with
I think fixed the uh fix some bugs with
the
the
formula it is possible though that our
formula it is possible though that our
new implementation has errors in
it I think I also changed the Horizon
it I think I also changed the Horizon
for training a little bit bit for
for training a little bit bit for
um for these to give it more
time no no that's what it is okay this
time no no that's what it is okay this
does not
does not
match
match
H okay no it's actually it is pretty
H okay no it's actually it is pretty
close
and again maybe needs to
retune now my question is why
retune now my question is why
is oh hang on over the whole run custom
is oh hang on over the whole run custom
was only
9% of the
9% of the
total Customs only
total Customs only
9% so that is lower
9% so that is lower
right it's still not fast enough but
right it's still not fast enough but
it's
it's
lower but then the 24% MK okay we
lower but then the 24% MK okay we
definitely need to not have 24% MK time
okay we have 6% 7%
yeah we're leaking time all over the
yeah we're leaking time all over the
place
and then I suppose the other place that
and then I suppose the other place that
this could potentially be would be
this could potentially be would be
like right
here oh no it still doesn't quite add
here oh no it still doesn't quite add
does it
oh wait hold on
with
with
custom there we go try
this only 1%
only
1% where's the rest of it then flatten
1% where's the rest of it then flatten
batch
maybe what's this
cost
1%
e e
well I think the easiest thing to start
well I think the easiest thing to start
with is going to be the
with is going to be the
C for
yeah it's 9% or
whatever why is it
whatever why is it
9% of course
this how do I make this
faster for
rewards and
masks
e e
just seeing if I can find the actual
just seeing if I can find the actual
code that got generated
anywhere nope can't find it The Annoying
anywhere nope can't find it The Annoying
Thing with scon
I could implement it and see but I I
I could implement it and see but I I
don't know if that's the
solution e
I just want to see something
here I don't even zero the I don't I
here I don't even zero the I don't I
don't need to zero the buffer
don't need to zero the buffer
right I don't need to zero the buffer
and why is
this is this just genuinely doing that
this is this just genuinely doing that
much
much
work I think it
is
e
e e
I mean I guess I can do
uh what was the original algorithm
I see like one small thing I can improve
M
M
Max minus standard deviation
is
zero wait hang on
if oh yeah so that's zero
it should just be one
it should just be one
right let me do
that
e e
if that does
anything
anything
nope there's no way it's slower don't
nope there's no way it's slower don't
[ __ ] me
now that cannot be slower there's just
now that cannot be slower there's just
no
way was this 11% %
compute e
possibly doing okay but that's about it
11%
see the flags that it's compiled with
be a little lazy here here every time I
be a little lazy here here every time I
get lazy with this it's like ends up a
get lazy with this it's like ends up a
bad idea but
sometimes
e e
I don't think that there should be
I don't think that there should be
like I don't think scyon should just
like I don't think scyon should just
generate slow code right
let's
return that's
fine yeah this whole thing is
fine yeah this whole thing is
fine
for
e e
considering just writing it in C
it's really obnoxious
not missing anything obvious right like
not missing anything obvious right like
this
is I mean this is pretty well what you'd
expect
for e
I mean the compiler should be able to do
this that should not change anything
yeah I'd rather leave it the way it
was up that that's
was up that that's
fine over Delta like that
oh wait hang on maybe I do see
oh wait hang on maybe I do see
[Music]
[Music]
something
something
no oh that's right
Dam
e
e
e e
get this to
work maybe this gives me
uh maybe this gives me
something
for
e
e
e
e e
see if this does
anything oh I think we also have to
anything oh I think we also have to
recompile the syon let's do that as
well have to make it make sure it's
well have to make it make sure it's
changed
there we
go and hopefully this giv me lines
that didn't work didn't go through the
line e
BG no because scyon generates
BG no because scyon generates
garbage this is one of the problems with
garbage this is one of the problems with
scyon generates a ton of
crap do scon have a line TR I don't
crap do scon have a line TR I don't
think
so I remember doing this before actually
so I remember doing this before actually
I just don't remember how it's been like
I just don't remember how it's been like
many
many
months let me make
sure
e e
oh I
see
e e
do I need to add profile in the ithon
do I need to add profile in the ithon
hang
hang
on I might need to do that
no you can't do
that damn it I remember I used to do
that damn it I remember I used to do
this and I don't remember how I did it
uh wait line
Trace maybe it's
this I'll try that
still no damn
it scon profile true
there we
go oh get out of here bot go away
so I don't use the line profiler at
all
okay
e e
still now really
rot profile results. demo. P.L
rot profile results. demo. P.L
proo
okay e
still
know
e
e e
I really don't remember how the hell
I really don't remember how the hell
they did
they did
this really
obnoxious and I don't have any other way
obnoxious and I don't have any other way
of optimizing this
one last thing
Maybe This Is It
nope nothing
nope nothing
okay well that
sucks love to do this
way e
as [ __ ]
oh okay no longer works in Python 312
oh okay no longer works in Python 312
good job I'm not crazy it's just broken
good job I'm not crazy it's just broken
good
job let's get rid of that
this
for
e e
try some stuff
here yeah so these Max functions
here yeah so these Max functions
actually do
matter e
I wonder if their if else is implemented
for e
TR e
see what this compiles to
see how [ __ ] that
is yeah that compiles to be way faster
is yeah that compiles to be way faster
isn't that
isn't that
funny so that's half of the compute cost
funny so that's half of the compute cost
gone from
gone from
this okay what else have we screwed
up how much is the X
yeah the x is half of the remaining
this takes a double
this takes a double
they X app
try x
f see if there's an
X by %
about the
about the
same but it's definitely this because if
same but it's definitely this because if
I comment it entirely
right okay so we're
right okay so we're
[Music]
paying yeah we're paying quite a lot on
paying yeah we're paying quite a lot on
this
me try something
just try something real quick here
[Music]
[Music]
right we get
right we get
it oh no we didn't I'm just stupid hold
on hang on I didn't get I might I think
on hang on I didn't get I might I think
I'm just
stupid yeah damn it I'm just stupid
dang
there an easy way to vectorize
this e
so this is still massively slower than
so this is still massively slower than
it could be because I'm guessing this
it could be because I'm guessing this
isn't doing any
isn't doing any
simd because it's like all these
simd because it's like all these
instructions here
down to 5% but I'm still not happy with
this okay here's what we're going to do
this okay here's what we're going to do
we're going to start let's get this to
we're going to start let's get this to
the Baseline
it's the 5%
it's the 5%
right about
5% how much is this
taking 1%
so it's not the looping that is
so it's not the looping that is
slow it's not the looping that is
slow e
I could go extreme with this but
I could go extreme with this but
um you
see I don't think this is going to help
see I don't think this is going to help
can try it
though e
you know what actually might make a
you know what actually might make a
difference
here let
here let
me we can actually do some of these as M
me we can actually do some of these as M
sets I
sets I
believe I don't know if it's going to be
believe I don't know if it's going to be
better in this case to be honest with
better in this case to be honest with
you but we will try something
you but we will try something
so T is I +
J Hang on we're going to start with
this 5%
okay and
okay and
now this goes
now this goes
here this comes
down
i k bound I
we no longer want
we no longer want
T M
Copy
Copy
float set
let's go down
here
here
uninitialized may be unused int J
not any faster
slower now it's not slower
either
for e
I'm just seeing if anything happens with
I'm just seeing if anything happens with
a timd magically
nah
nah
nothing yeah it's slower cuz we're
nothing yeah it's slower cuz we're
redoing the loops
redoing the loops
okay well this doesn't
okay well this doesn't
help and go back right up until I did
help and go back right up until I did
this I
think
e
e e
XF is float
right e
yeah no we're do we're just being silly
yeah no we're do we're just being silly
at this point
let's go back to this one
this one should go first right
no visible
effect cuz the main time is from that X
effect cuz the main time is from that X
function and a couple other small things
function and a couple other small things
right
is there a reason hold on maybe we can
is there a reason hold on maybe we can
be smarter
be smarter
right maybe we can be
right maybe we can be
smarter is there a
reason to do this on the CPU
why do we need log standard deviation
why do we need log standard deviation
maybe we can be smarter that
way and maybe we can just be smarter
way and maybe we can just be smarter
over
over
there ah shoot it's
there ah shoot it's
6:30 I've been optimizing too long
6:30 I've been optimizing too long
without noticing
without noticing
it I'm going to check one
it I'm going to check one
thing though before I get dinner which
thing though before I get dinner which
is
is
think we can be a little bit more
clever where do we use log standard
clever where do we use log standard
deviation
do we use this every time we do
right
okay yeah we immediately call expon
this so we'll just have the Network
this so we'll just have the Network
return standard deviation instead of log
return standard deviation instead of log
standard Dev ation
right and then it'll be done on the GPU
right and then it'll be done on the GPU
and we won't have to parallelize
it now we do lose this
clamp but we can do the clamp on the GPU
clamp but we can do the clamp on the GPU
as
well yeah do that and that actually will
well yeah do that and that actually will
save quite a
lot that should be very very parallel
right and that gets compiled
right and that gets compiled
perfect so that will save
us this
us this
line oh and then I think Max and Min
line oh and then I think Max and Min
should get um Sim deed as a result Maybe
we can also potentially keep this on the
we can also potentially keep this on the
GPU for
GPU for
longer
longer
right because I think we don't really
right because I think we don't really
care about
care about
doing me see Advantage
doing me see Advantage
scale actually a lot of this can be done
scale actually a lot of this can be done
on the GPU now that I'm looking at
on the GPU now that I'm looking at
it it's right up
it it's right up
until I think here is where it's sketchy
maybe yeah okay so we'll play with that
maybe yeah okay so we'll play with that
after um because I think we're kind of
after um because I think we're kind of
at the limits of what we can optimize in
at the limits of what we can optimize in
the C we're still leaking 5% perf I do
the C we're still leaking 5% perf I do
not like that they should not leak any
not like that they should not leak any
per
per
uh and then after that we still have to
uh and then after that we still have to
update this other function down
here I don't think that what I have
here I don't think that what I have
planned will improve this but maybe all
planned will improve this but maybe all
right I'm going to go get some dinner uh
right I'm going to go get some dinner uh
for folks
for folks
watching all my stuff's at
watching all my stuff's at
puff. Star of the GitHub really helps us
puff. Star of the GitHub really helps us
out Jo Discord if you want and follow on
out Jo Discord if you want and follow on
X more content I'll be back at

Kind: captions
Language: en
good
good
afternoon we are
live stuff has been busy but I got a
live stuff has been busy but I got a
couple hours to get some things done on
couple hours to get some things done on
stream
stream
now so I'm back for a little
now so I'm back for a little
bit let's
see is anything blowing up in Puffer
what it you just have to
add uh actually no the way I have it is
add uh actually no the way I have it is
is pretty tricky
realize there's a
realize there's a
[Music]
Discord all
Discord all
right so we have uh the stuff I want to
right so we have uh the stuff I want to
do than C
welcome got tied up with meetings today
welcome got tied up with meetings today
meetings and trying to finish assembling
meetings and trying to finish assembling
my power rack it's not fully done yet
my power rack it's not fully done yet
it's
it's
usable but uh we have a mess to deal
usable but uh we have a mess to deal
with on that tomorrow
with on that tomorrow
anyways
anyways
um I want to look at some of our
um I want to look at some of our
experiments right now so we can figure
experiments right now so we can figure
out what's going to happen next with uh
out what's going to happen next with uh
the new algorithm with sweeps with
everything when you little analysis
everything when you little analysis
probably implement a few small things
probably implement a few small things
and then we will see from
here there are a couple different things
here there are a couple different things
I'd like to try actually I'm to think of
it
tag okay
you got guys you got to Center this like
you got guys you got to Center this like
this has to be left aligned I don't know
this has to be left aligned I don't know
what they're doing
here this one is auto scale
p301 okay so this is
p301 okay so this is
P30 and then I think this
P30 and then I think this
is break up fast okay
let's see if this is what we
expect so both of
expect so both of
these score just
fine time step breakdown is
fine time step breakdown is
similar it's like we should actually
similar it's like we should actually
increase Horizon Maybe
you can see here gamma and Lambda are
you can see here gamma and Lambda are
more directed
more directed
looking they're all over the place here
looking they're all over the place here
because they don't
matter learning rate is way more
matter learning rate is way more
controlled here as well which is
interesting do they end up in a similar
interesting do they end up in a similar
spot
spot
01 no they don't don't end up in a
01 no they don't don't end up in a
similar spot at
similar spot at
all difference the left is p3o which is
all difference the left is p3o which is
the new algorithm the right is
p
ends this is also you know I actually do
ends this is also you know I actually do
have some hope
have some hope
here
um CU it looks like the one on the left
um CU it looks like the one on the left
hasn't found the uh the fast settings
hasn't found the uh the fast settings
yet what do you think about the kinetics
yet what do you think about the kinetics
frame work uh we just we started adding
frame work uh we just we started adding
a preliminary binding for kinetics last
a preliminary binding for kinetics last
week to puffer lib and we got stuck we
week to puffer lib and we got stuck we
did add add one for craftex we have a
did add add one for craftex we have a
formal collaboration with uh Jacob
formal collaboration with uh Jacob
forester's lab as well to like add
forester's lab as well to like add
bindings and stuff for their stuff um I
bindings and stuff for their stuff um I
was supposed to do this like right after
was supposed to do this like right after
Nerfs and then I was in the hospital
Nerfs and then I was in the hospital
with pneumonia and then everything got
with pneumonia and then everything got
shaken up so I started on that last week
shaken up so I started on that last week
and we will be continuing that you know
and we will be continuing that you know
periodically we do a couple things for
periodically we do a couple things for
other
other
labs but we have to get our own research
labs but we have to get our own research
and our own stuff on track as
and our own stuff on track as
well connetics is a very good project I
well connetics is a very good project I
the one thing I will say it's an
the one thing I will say it's an
incredibly impressive project uh even if
incredibly impressive project uh even if
I were they were to have done it the way
I were they were to have done it the way
that I would have suggested the way they
that I would have suggested the way they
did it it like it was about 10 times
did it it like it was about 10 times
more work than it needed to be I think
more work than it needed to be I think
that if they built the ends the way that
that if they built the ends the way that
we build ends in puffer they could have
we build ends in puffer they could have
done it and it would have still been
done it and it would have still been
hard even then but it would have been
hard even then but it would have been
like a tenth of the work as it actually
like a tenth of the work as it actually
took them so I hope that in the future
took them so I hope that in the future
we can make it way easier for them to uh
we can make it way easier for them to uh
to be building new Ms like this because
to be building new Ms like this because
writing stuff in Jacks it's just not a
writing stuff in Jacks it's just not a
fun
fun
time I mean literally they went and
time I mean literally they went and
reimplemented the entire thing in
reimplemented the entire thing in
JavaScript just to have it be playable
JavaScript just to have it be playable
on the web so that you could fiddle with
on the web so that you could fiddle with
it there and like we get that for free
it there and like we get that for free
with all of our
Puffs and they're faster
okay
okay
so we can see that this is about twice
so we can see that this is about twice
as
as
expensive uh in terms of wall clock time
expensive uh in terms of wall clock time
as this now if I were to
do what if I were to do total time steps
do what if I were to do total time steps
instead
okay okay so you get out to about 75
okay okay so you get out to about 75
million
million
here 8 2 million here so these are
here 8 2 million here so these are
actually very
actually very
close these are very very
close I think if we can just fiddle
close I think if we can just fiddle
with nice cup bro that's crazy
with nice cup bro that's crazy
yeah um
yeah um
if we can just get this thing to be a
if we can just get this thing to be a
little faster in wall clock time which
little faster in wall clock time which
we have optimizations for
we have optimizations for
that and then if we can get this to
that and then if we can get this to
discover these hyper parameters I think
discover these hyper parameters I think
we can get this to work I think we
we can get this to work I think we
should be able to get this to
work actually is this let me
work actually is this let me
see cost
yeah so this
is it's actually a little faster now
is it's actually a little faster now
it's like a little under 100 seconds
it's like a little under 100 seconds
this is a little under 200ish right yeah
this is a little under 200ish right yeah
so it's got
so it's got
2x but then it didn't figure out the
2x but then it didn't figure out the
number of end thing
number of end thing
right I go to sample
right I go to sample
here go to numm
63 oh no it figured out uh
63 oh no it figured out uh
500 it's pretty well there with a
500 it's pretty well there with a
th000 oh but it didn't do 2,000 that's
th000 oh but it didn't do 2,000 that's
the issue so it didn't get it with 2,000
the issue so it didn't get it with 2,000
Ms and then update Epoch
Ms and then update Epoch
maybe mostly with one update so it's
maybe mostly with one update so it's
very close though that's very close
why are you
why are you
sweeping it doesn't matter it should
sweeping it doesn't matter it should
just learn to ignore it I mean I could
just learn to ignore it I mean I could
take it out but you can see based on the
take it out but you can see based on the
charts though that it doesn't
matter okay so I mean the only thing
matter okay so I mean the only thing
that this one didn't
that this one didn't
find and to be fair this one is
find and to be fair this one is
probably these are probably some of the
probably these are probably some of the
best runs right
here so it didn't find these
points and then mini badge
signs it also have smaller mini batch
signs it also have smaller mini batch
size it didn't find 8K mini batch
size it didn't find 8K mini batch
interesting I wonder if that is
interesting I wonder if that is
something fundamental with the
something fundamental with the
algor I
algor I
wonder but we can basically see that it
wonder but we can basically see that it
has it's using half the number of
has it's using half the number of
environments and half the mini batch
environments and half the mini batch
size and then also it has um there's
size and then also it has um there's
just some CPU overhead that we have to
just some CPU overhead that we have to
fix
fix
um so I don't know if we can get it to
um so I don't know if we can get it to
train as well with the same params as po
train as well with the same params as po
we'll see
we'll see
we're definitely going to
try do we also know the uh the steps per
try do we also know the uh the steps per
second that would actually be a good one
second that would actually be a good one
to know do we log SPS I think we
to know do we log SPS I think we
do hold on if I were to just
add
scatter and then what we do is yes
scatter and then what we do is yes
PS
last
score ah there we
score ah there we
go that's clever
right I refresh
right I refresh
this there we go
this there we go
so you can see the speed difference
so you can see the speed difference
right
so
so
PO is able to get Max score up to about
PO is able to get Max score up to about
1.1 million steps per
1.1 million steps per
second where our P30 only goes up to a
second where our P30 only goes up to a
bit over
400k so
we can bring that up I think we might
we can bring that up I think we might
have a chance of M of
matching first thing is going to
matching first thing is going to
be to deal with the
be to deal with the
overhead of the current P30
overhead of the current P30
implementation we move over to coding
Land where's our term
the in I need to get myself a little
the in I need to get myself a little
stream
overlay that'd be
fun Dev
so breakout
so breakout
mode when we run this thing
mode when we run this thing
normally 1.2 million steps per
normally 1.2 million steps per
second misk is train Mis percentage is
second misk is train Mis percentage is
about 8% here
about 8% here
but 8% in frame
miss.
then goes up
to about
30% 30%
30% 30%
so we have about
so we have about
22% right here uh that we are leaking
22% right here uh that we are leaking
now this does not account for the perf
now this does not account for the perf
gap on its
gap on its
own does not account for the perf gap on
own does not account for the perf gap on
its
its
own but this is a good first
own but this is a good first
step and I think that we can maybe even
step and I think that we can maybe even
correct some stuff in the
correct some stuff in the
process breakout. C let me see okay
process breakout. C let me see okay
nothing important here change that we
nothing important here change that we
need to
recompile so the major major issue at
recompile so the major major issue at
the moment is
in these
functions I see
functions I see
so the issue here right is that
so the issue here right is that
advantages NP here this is all in cython
advantages NP here this is all in cython
whereas for
whereas for
p3o only a part of it is in syon so if
p3o only a part of it is in syon so if
we were to Port this to scon I think we
we were to Port this to scon I think we
would be
good so let me see what variables this
good so let me see what variables this
needs this already has GS this already
needs this already has GS this already
has
has
rewards I think we need values mean and
rewards I think we need values mean and
log standard deviation don't
log standard deviation don't
we W block ask
we W block ask
block also do we need
um do we need this reward block in this
um do we need this reward block in this
mask
block let me
see yeah we do need this for a
see yeah we do need this for a
prediction
prediction
of of the value function right
okay so we will leave those as is and
okay so we will leave those as is and
then
advantages compute J
advantages ah I see the zero
here will be like this
we need to pass in
values yeah DS value is
values yeah DS value is
effectful advantages reward block is
it D forward to UNP
it D forward to UNP
value where is
it hi
now these ones here get passed
now these ones here get passed
to this rewards and mask and then this
to this rewards and mask and then this
all is going to be what we're going to P
all is going to be what we're going to P
to
see all right so we put this here as a
see all right so we put this here as a
reference
that's
me just see how this works we need to
me just see how this works we need to
pre-compute a couple things
man oh and actually we can use this as
man oh and actually we can use this as
an opportunity
to compute the uh the MTH term as well
to compute the uh the MTH term as well
can't
we but I have to figure that
out
out
well initially I think we do the simple
well initially I think we do the simple
one because this is quite a bit to
one because this is quite a bit to
figure out so essentially like all these
figure out so essentially like all these
Transformations there's stuff that can
Transformations there's stuff that can
happen with the masking to make it
happen with the masking to make it
slightly more
slightly more
correct uh and we have to make sure
correct uh and we have to make sure
that we're doing all of that
go now we have M Min and Ma Max
this is the reward this is the mask
this is the reward this is the mask
right
minus sum values equal one okay
so
so
advantages of
advantages of
I is I
FL
FL
R are
rewards
R
minus
minus
values we also need to add the uh where
values we also need to add the uh where
is
is
it values mean it
it values mean it
float values
float values
mean
Lo
Lo
values STG
[Music]
okay and if you're here you already have
okay and if you're here you already have
checked the mass block so we can skip
checked the mass block so we can skip
that so now the only thing we need to do
that so now the only thing we need to do
is multiply by Advantage scale
Advantage
scale value standard deviation okay so
scale value standard deviation okay so
we do
we do
advantages I is divided
advantages I is divided
by no times
by no times
equal and then we have to compute
equal and then we have to compute
Advantage
Advantage
scale which
is M Max
minus values standard deviation over and
minus values standard deviation over and
we're going to just call this
Delta see float Delta equals
okay so now we
okay so now we
take advantages it's going to be equal
take advantages it's going to be equal
to
to
this
this
difference divide by
Delta but you forgot the clipping right
so we can do at the end we can
so we can do at the end we can
do
do
if Delta is greater than
if Delta is greater than
zero or and we can do this at the end
zero or and we can do this at the end
which is going to save us a little bit
it's a little different
it's a little different
actually cuz you still need to scale it
okay let me think about this path first
divide
divide
by
Delta
see scale scale
equal now we need clip
it oh
it oh
shoot damn
shoot damn
it we forgot to Norm this didn't
we hang on maybe there's a way around
we hang on maybe there's a way around
this
look at the
math Vantage scale
times this
times this
difference dot
sum but then way to Advantage
scale
minus I actually can't tell if there's a
minus I actually can't tell if there's a
way to reduce this
AIS = -1
I just need to compute the sum per
I just need to compute the sum per
right yeah so I think that what we're
right yeah so I think that what we're
going to have to
do let's tab this
in this out
and then Advantage
and then Advantage
sum we add
hang on I'm very confused
hang on I'm very confused
here Vantage scale
man this thing is fiddly to implement
fast I'm just looking at what I've
fast I'm just looking at what I've
written
here cuz you have advantage
scale reward block minus value mean
okay the scale is the max minus the
okay the scale is the max minus the
standard
standard
deviation divide by Delta
deviation divide by Delta
clipped and then
normalized yeah I mean you need to make
normalized yeah I mean you need to make
uh
you need to make this work
It's tricky because you don't want to
have I mean the fastest thing might be
have I mean the fastest thing might be
to have
to have
uh a full advantages
buffer really prefer to avoid that but I
buffer really prefer to avoid that but I
don't see any way around it
man I can make it temporary right
Advantage
scale
e e
okay so we have now this
portion uh and actually this needs to
portion uh and actually this needs to
be X
right oh and then this is totally
right oh and then this is totally
different because this
is standard
deviation right
or is this the
same yeah this
is wait
values
Max and that is really obnoxious isn't
Max and that is really obnoxious isn't
it it's really
it it's really
obnoxious uh I think you can't compute
obnoxious uh I think you can't compute
ma Max though like
ma Max though like
this
this
because yeah you cannot compute ma
Max cuz the thing is that this is
Max cuz the thing is that this is
actually 2D
okay
okay
so Advantage
scale so now we have Max and Men right
value standard deviation
nump so we
nump so we
do B SD is going to be this XD
okay now you have Max and Men
right hold on did you just normalize
right hold on did you just normalize
this by the
entire wait you normalized this by the
entire wait you normalized this by the
entire Min and Max didn't you
entire Min and Max didn't you
uh that's
harder that is
harder that is
harder right because
then can you even do it
now you can't even do it now can you
you need a second Loop over this whole
thing I mean I can do um
bounds of um steps right
so
fiddly okay so let me try it this way
okay do this now we have the Mac we got
okay do this now we have the Mac we got
the in we got i j
k
JT delete all this
JT delete all this
and now what we do
is this is going to drive me nuts you
is this is going to drive me nuts you
can't even you still can't even do it
can't even you still can't even do it
because you still need an intermediate
buffer I don't want to recompute this x
buffer I don't want to recompute this x
it's the problem
I'm going to just Chuck this into Gro
I'm going to just Chuck this into Gro
real quick just to see not to write the
real quick just to see not to write the
code but I just want to see if there's a
simplification
e e
I just wanted this to give me like lch
I just wanted this to give me like lch
for
this okay so
this okay so
Mass block times Advantage scale times
Mass block times Advantage scale times
the word block
the word block
okay Su J yeah this is correct and then
oh it's
oh it's
stupid for
wondering if a better tool than the
wondering if a better tool than the
massively expensive llm would have been
massively expensive llm would have been
a piece of paper to write this out
myself oh it's not capable of doing it
myself oh it's not capable of doing it
it's just that stupid okay uh we're
it's just that stupid okay uh we're
closing this because this is dog [ __ ]
closing this because this is dog [ __ ]
good job Brock I don't know why I even
good job Brock I don't know why I even
bother with uh with llms it's like hey
bother with uh with llms it's like hey
they're smart now they're really smart
they're smart now they're really smart
no they're not they
no they're not they
suck waste my time almost every single
suck waste my time almost every single
time
time
it's like it's like just like lazy like
it's like it's like just like lazy like
oh yeah maybe it'll just do it for me no
oh yeah maybe it'll just do it for me no
it never does just waste the
it never does just waste the
time
stupid let me see if I can just see a
stupid let me see if I can just see a
simplification here
simplification here
so this formula where Advantage scale
is it's essentially Norm of Max minus
is it's essentially Norm of Max minus
value standard
deviation yeah so the problem here is
deviation yeah so the problem here is
that you need
um in order to normalize something
um in order to normalize something
right you either need to do it in
place you either need to do it in place
place you either need to do it in place
or uh you need to
damn it or you need another
buffer let see where I do this
batch yeah it's noxious isn't
it I don't want to change the formula at
all I guess we'll do temporary buffer
all I guess we'll do temporary buffer
for now so we can finish the experiments
for now so we can finish the experiments
and then we'll
and then we'll
uh figure out after
that for
let's go
back we're just going to assume that we
back we're just going to assume that we
have whatever we want in terms of
have whatever we want in terms of
buffers here let's just write this out
take that
then we have vstd
Max just fine
okay so we divide by
okay so we divide by
this k =
this k =
1 we do uh
1 we do uh
bounds of IAL k
scale advantage scale. suum
I'm just going to do it as stupid as I
I'm just going to do it as stupid as I
can and like get it to work and then I'm
can and like get it to work and then I'm
going to optimize some stuff I guess
going to optimize some stuff I guess
that's
that's
tricky turns out not having array
tricky turns out not having array
operations and having to not think about
operations and having to not think about
redundant copies and buffers and stuff
redundant copies and buffers and stuff
it's
hard a big deal
not advantages of IO for
not advantages of IO for
Delta it
is
is
Max
minus I and
J and then if
Delta greater than
zero divide by
Delta scale
this
this
in it's the clip
add scale equals
man do you need another buffer here this
man do you need another buffer here this
is
ridiculous I mean we're going to have to
ridiculous I mean we're going to have to
find a way to do it with fewer
buffers yeah because you need the
um you need the sum don't
you you need the sum of Advantage you
you you need the sum of Advantage you
need the sum of
need the sum of
values is that
it e
I think if you if I could do it with
I think if you if I could do it with
just
a uh log standard deviation
yeah I think if I could do this with
yeah I think if I could do this with
just uh a
just uh a
values standard deviation buffer it
values standard deviation buffer it
would be good right
so we'll just do buff
f
fine I think we're getting
fine I think we're getting
somewhere so now I have this
buffer and I can Loop over this multiple
buffer and I can Loop over this multiple
times um
potentially the first thing I need to do
potentially the first thing I need to do
with this buffer
and then we also have this bounce here
and then we also have this bounce here
which is fine
man it is crazy
man it is crazy
what a pain this just max operation and
what a pain this just max operation and
Min operation
Min operation
causes I can see why it's slow now
causes I can see why it's slow now
because this is making a million copies
because this is making a million copies
of a big array in
of a big array in
numpy so I'm not just wasting time op uh
numpy so I'm not just wasting time op uh
optimizing python overhead this is
optimizing python overhead this is
actually fundamentally too many data
actually fundamentally too many data
copies at least we're doing that
right e
yeah the segment's length buffer is
yeah the segment's length buffer is
basically
basically
required but I think that we're probably
required but I think that we're probably
going to end
going to end
up we're probably going to end up
up we're probably going to end up
providing this in the future anyways
providing this in the future anyways
so we'll keep bounds okay let's say that
so we'll keep bounds okay let's say that
we have bounds still
okay so now we have the X D stt cool now
okay so now we have the X D stt cool now
this is clipping is
this is clipping is
done now we have the Min and Max as
well now be now this is in the buffer
right it's minus vspd okay and then if
right it's minus vspd okay and then if
Delta's
Delta's
greater than zero divide by
greater than zero divide by
Delta
clip and then we have to divide
clip and then we have to divide
by the advantage scale right
by the advantage scale right
Advantage scale.
suum we do
suum we do
buff P to Advantage scale
again
bounds range
bounds range
K
okay
okay
okay what are we going to
do okay we only need to do this if
do okay we only need to do this if
uh
Delta is greater than zero this is the
Delta is greater than zero this is the
last
last
step and then we
do scale
[Music]
zero I and
J some
sum okay so we do this now we actually
sum okay so we do this now we actually
just have the sum
here Advantage
scale then we divide these by the
sum
okay and now we have it
okay and potentially we can compress
okay and potentially we can compress
those Loops but now I think we actually
those Loops but now I think we actually
have it fully
vantages
I we don't need to do mask
I we don't need to do mask
block this is buff i
block this is buff i
j times reward block
j times reward block
IJ minus values
mean see this is i
j you
j you
beautiful I'm going to go use the
beautiful I'm going to go use the
restroom and then we are going to check
restroom and then we are going to check
this be right
back
e e
all right so I actually think this is
all right so I actually think this is
going to be better than the original
going to be better than the original
because this one actually correctly
because this one actually correctly
accounts for um for
accounts for um for
masking if it's worse then that'll be
masking if it's worse then that'll be
weird but we'll see
let me make sure that we get this
let me make sure that we get this
correct fully though actually I'm going
correct fully though actually I'm going
to pull up the so here's the original
to pull up the so here's the original
right
here so the first thing we do is we
compute here's the
compute here's the
original this to
original this to
zero what did we end up needing as well
zero what did we end up needing as well
we ended up needing one buffer
we ended up needing one buffer
array we ended up needing
bounds and then we ended up
needing advantages okay so we have to
needing advantages okay so we have to
set advantages to
zero okay cool
zero okay cool
now this one here
has this is going to compute
has this is going to compute
the so this has to be k equals
the so this has to be k equals
z i j k and t set K to zero
here me see if we're done we increment K
here me see if we're done we increment K
so we actually get our our bound length
so we actually get our our bound length
reward is t + one we set this to reward
reward is t + one we set this to reward
we set the mask to
one yeah because the rest of the Mask is
one yeah because the rest of the Mask is
zeroed by default okay advantages this
zeroed by default okay advantages this
is
is
not this is not used
not this is not used
right R minus values mean yeah this is
right R minus values mean yeah this is
not
used we get the value log standard
used we get the value log standard
deviation
deviation
T we clamp it we take X which
T we clamp it we take X which
is
X it's
FX isn't
it oh it's just
X by X of the standard deviation
X by X of the standard deviation
then we
then we
set all so now we have standard
set all so now we have standard
deviations computed and then we do Max
deviations computed and then we do Max
Max Min Min this is online Max and Min
Max Min Min this is online Max and Min
cool Delta
cool Delta
[Music]
is wrong way Max minus
is wrong way Max minus
Min we have Advantage scale and
Min we have Advantage scale and
Advantage sum
two
two
floats we're going to go up to the
floats we're going to go up to the
bounds Advantage scale
bounds Advantage scale
is Max minus standard
deviation Delta's bigger than
deviation Delta's bigger than
zero then we
will divide by Max minus
will divide by Max minus
Min and then we will clamp it
Min and then we will clamp it
from 0.5 to
one and then we're going to add this
one and then we're going to add this
to
Advantage
Advantage
sum so sum has to be set to zero
sum so sum has to be set to zero
here okay and we set this
here okay and we set this
scale
scale
here okay and then the if uh
here okay and then the if uh
Delta is greater than zero then we
Delta is greater than zero then we
divide by Advantage sum so we nor them
divide by Advantage sum so we nor them
by that
by that
row and then we just have to compute the
row and then we just have to compute the
final Advantage
final Advantage
here which is going to be the
here which is going to be the
buffer
buffer
times reward
times reward
block minus the value
block minus the value
mean and since this is an accumulation
this should give us the correct
advantages
advantages
okay sure we'll have to fix some stuff
okay sure we'll have to fix some stuff
but this is pretty
but this is pretty
good pretty pretty
good pretty pretty
good let's just figure out the order
good let's just figure out the order
that we want this
signature
buffer advantages
bounce let's just do
this now let's go see where we call this
this now let's go see where we call this
so we know the order to call it
in the reward
in the reward
block reward
block reward
mask values me numpy
mask values me numpy
values
values
buff and then was an experienced do
buff experience
bouns
gu hang on Buffer
DS NP rewards
NP
advantages inst start bounds inst start
advantages inst start bounds inst start
Horizon so this is now the right order
Horizon so this is now the right order
for these and we have to allocate these
for these and we have to allocate these
extra
buffers it shouldn't be too bad
[Music]
[Music]
use values
Norm hang values
Norm hang values
Norm this is not
Norm this is not
used all right so Advantage is
nump self.
nump self.
buff give it a buffer give it
buff give it a buffer give it
advantages
bounce get another one of
these so buff advantages and I think
these so buff advantages and I think
that's it
and now you
and now you
have
advantages find B dis
advantages find B dis
[Music]
[Music]
advantages and you don't actually
advantages and you don't actually
want no this is
want no this is
fine and you don't need this to be a by
fine and you don't need this to be a by
ex's either it's just a
buffer do like this
what I do
here values
I this is buff
canot change aign type float to
int there we
go Max maybe where is it
M Min may be used
uninitialized yep it
uninitialized yep it
is this is
is this is
vstd vstd MX
M and then this doesn't need to be M Max
M and then this doesn't need to be M Max
it's
Max all right now does compile without
Max all right now does compile without
warnings
no okay now this works
no okay now this works
okay yeah this
works must be real
works must be real
number not C advantage. memory view
number not C advantage. memory view
slice
slice
so let me see
log this is not t this is I and J is
log this is not t this is I and J is
what this has to be
there we
go okay so this runs I assume that this
go okay so this runs I assume that this
is
now scyon
where's my HTML file
there we
go okay and now this is going to show up
uh I actually do not
uh I actually do not
see yeah there's nothing wrong with this
see yeah there's nothing wrong with this
so why is it so
slow on
what with uh
what with uh
profiles C
profiles C
and the profile custom was at zero
and the profile custom was at zero
before right
yeah
and run the setup. p
okay down to 14 what is it
okay down to 14 what is it
15% but MK is just as
15% but MK is just as
high not
high evidently we need this um
high evidently we need this um
this function to be much
this function to be much
faster it's very weird
though that's very weird
this function is very expensive
I mean this is written
I mean this is written
correctly oh wait nope I'm wrong
yeah this is wait isn't
yeah this is wait isn't
this th
steps oh no yeah this is
right
what I did not expect this to still
what I did not expect this to still
still be slow
I guess one of the things we can
I guess one of the things we can
do so we have
do so we have
uh where is it this
one it's got to be this one
one it's got to be this one
right yeah this
one there's the burito front
okay this looks pretty good
right so let's take these
parameters for
oh we don't need Lambda and Gamma for
oh we don't need Lambda and Gamma for
this
this
lovely so we do learning
rate for
there update
epox where's batch size as well we
epox where's batch size as well we
forgot batch size
now this is
now this is
exactly exactly what we want
TR this
this then we do
this then we do
this
charts and
charts and
yeah here we
are essentially we will see whether I
are essentially we will see whether I
toally toally messed up the function IF
toally toally messed up the function IF
function is correct and just slow or
function is correct and just slow or
what's going on
it is possible that hypers need to be
it is possible that hypers need to be
retuned a little bit
h
I don't know I was hoping this would
I don't know I was hoping this would
just work better because we technically
just work better because we technically
I think fixed the uh fix some bugs with
I think fixed the uh fix some bugs with
the
the
formula it is possible though that our
formula it is possible though that our
new implementation has errors in
it I think I also changed the Horizon
it I think I also changed the Horizon
for training a little bit bit for
for training a little bit bit for
um for these to give it more
time no no that's what it is okay this
time no no that's what it is okay this
does not
does not
match
match
H okay no it's actually it is pretty
H okay no it's actually it is pretty
close
and again maybe needs to
retune now my question is why
retune now my question is why
is oh hang on over the whole run custom
is oh hang on over the whole run custom
was only
9% of the
9% of the
total Customs only
total Customs only
9% so that is lower
9% so that is lower
right it's still not fast enough but
right it's still not fast enough but
it's
it's
lower but then the 24% MK okay we
lower but then the 24% MK okay we
definitely need to not have 24% MK time
okay we have 6% 7%
yeah we're leaking time all over the
yeah we're leaking time all over the
place
and then I suppose the other place that
and then I suppose the other place that
this could potentially be would be
this could potentially be would be
like right
here oh no it still doesn't quite add
here oh no it still doesn't quite add
does it
oh wait hold on
with
with
custom there we go try
this only 1%
only
1% where's the rest of it then flatten
1% where's the rest of it then flatten
batch
maybe what's this
cost
1%
e e
well I think the easiest thing to start
well I think the easiest thing to start
with is going to be the
with is going to be the
C for
yeah it's 9% or
whatever why is it
whatever why is it
9% of course
this how do I make this
faster for
rewards and
masks
e e
just seeing if I can find the actual
just seeing if I can find the actual
code that got generated
anywhere nope can't find it The Annoying
anywhere nope can't find it The Annoying
Thing with scon
I could implement it and see but I I
I could implement it and see but I I
don't know if that's the
solution e
I just want to see something
here I don't even zero the I don't I
here I don't even zero the I don't I
don't need to zero the buffer
don't need to zero the buffer
right I don't need to zero the buffer
and why is
this is this just genuinely doing that
this is this just genuinely doing that
much
much
work I think it
is
e
e e
I mean I guess I can do
uh what was the original algorithm
I see like one small thing I can improve
M
M
Max minus standard deviation
is
zero wait hang on
if oh yeah so that's zero
it should just be one
it should just be one
right let me do
that
e e
if that does
anything
anything
nope there's no way it's slower don't
nope there's no way it's slower don't
[ __ ] me
now that cannot be slower there's just
now that cannot be slower there's just
no
way was this 11% %
compute e
possibly doing okay but that's about it
11%
see the flags that it's compiled with
be a little lazy here here every time I
be a little lazy here here every time I
get lazy with this it's like ends up a
get lazy with this it's like ends up a
bad idea but
sometimes
e e
I don't think that there should be
I don't think that there should be
like I don't think scyon should just
like I don't think scyon should just
generate slow code right
let's
return that's
fine yeah this whole thing is
fine yeah this whole thing is
fine
for
e e
considering just writing it in C
it's really obnoxious
not missing anything obvious right like
not missing anything obvious right like
this
is I mean this is pretty well what you'd
expect
for e
I mean the compiler should be able to do
this that should not change anything
yeah I'd rather leave it the way it
was up that that's
was up that that's
fine over Delta like that
oh wait hang on maybe I do see
oh wait hang on maybe I do see
[Music]
[Music]
something
something
no oh that's right
Dam
e
e
e e
get this to
work maybe this gives me
uh maybe this gives me
something
for
e
e
e
e e
see if this does
anything oh I think we also have to
anything oh I think we also have to
recompile the syon let's do that as
well have to make it make sure it's
well have to make it make sure it's
changed
there we
go and hopefully this giv me lines
that didn't work didn't go through the
line e
BG no because scyon generates
BG no because scyon generates
garbage this is one of the problems with
garbage this is one of the problems with
scyon generates a ton of
crap do scon have a line TR I don't
crap do scon have a line TR I don't
think
so I remember doing this before actually
so I remember doing this before actually
I just don't remember how it's been like
I just don't remember how it's been like
many
many
months let me make
sure
e e
oh I
see
e e
do I need to add profile in the ithon
do I need to add profile in the ithon
hang
hang
on I might need to do that
no you can't do
that damn it I remember I used to do
that damn it I remember I used to do
this and I don't remember how I did it
uh wait line
Trace maybe it's
this I'll try that
still no damn
it scon profile true
there we
go oh get out of here bot go away
so I don't use the line profiler at
all
okay
e e
still now really
rot profile results. demo. P.L
rot profile results. demo. P.L
proo
okay e
still
know
e
e e
I really don't remember how the hell
I really don't remember how the hell
they did
they did
this really
obnoxious and I don't have any other way
obnoxious and I don't have any other way
of optimizing this
one last thing
Maybe This Is It
nope nothing
nope nothing
okay well that
sucks love to do this
way e
as [ __ ]
oh okay no longer works in Python 312
oh okay no longer works in Python 312
good job I'm not crazy it's just broken
good job I'm not crazy it's just broken
good
job let's get rid of that
this
for
e e
try some stuff
here yeah so these Max functions
here yeah so these Max functions
actually do
matter e
I wonder if their if else is implemented
for e
TR e
see what this compiles to
see how [ __ ] that
is yeah that compiles to be way faster
is yeah that compiles to be way faster
isn't that
isn't that
funny so that's half of the compute cost
funny so that's half of the compute cost
gone from
gone from
this okay what else have we screwed
up how much is the X
yeah the x is half of the remaining
this takes a double
this takes a double
they X app
try x
f see if there's an
X by %
about the
about the
same but it's definitely this because if
same but it's definitely this because if
I comment it entirely
right okay so we're
right okay so we're
[Music]
paying yeah we're paying quite a lot on
paying yeah we're paying quite a lot on
this
me try something
just try something real quick here
[Music]
[Music]
right we get
right we get
it oh no we didn't I'm just stupid hold
on hang on I didn't get I might I think
on hang on I didn't get I might I think
I'm just
stupid yeah damn it I'm just stupid
dang
there an easy way to vectorize
this e
so this is still massively slower than
so this is still massively slower than
it could be because I'm guessing this
it could be because I'm guessing this
isn't doing any
isn't doing any
simd because it's like all these
simd because it's like all these
instructions here
down to 5% but I'm still not happy with
this okay here's what we're going to do
this okay here's what we're going to do
we're going to start let's get this to
we're going to start let's get this to
the Baseline
it's the 5%
it's the 5%
right about
5% how much is this
taking 1%
so it's not the looping that is
so it's not the looping that is
slow it's not the looping that is
slow e
I could go extreme with this but
I could go extreme with this but
um you
see I don't think this is going to help
see I don't think this is going to help
can try it
though e
you know what actually might make a
you know what actually might make a
difference
here let
here let
me we can actually do some of these as M
me we can actually do some of these as M
sets I
sets I
believe I don't know if it's going to be
believe I don't know if it's going to be
better in this case to be honest with
better in this case to be honest with
you but we will try something
you but we will try something
so T is I +
J Hang on we're going to start with
this 5%
okay and
okay and
now this goes
now this goes
here this comes
down
i k bound I
we no longer want
we no longer want
T M
Copy
Copy
float set
let's go down
here
here
uninitialized may be unused int J
not any faster
slower now it's not slower
either
for e
I'm just seeing if anything happens with
I'm just seeing if anything happens with
a timd magically
nah
nah
nothing yeah it's slower cuz we're
nothing yeah it's slower cuz we're
redoing the loops
redoing the loops
okay well this doesn't
okay well this doesn't
help and go back right up until I did
help and go back right up until I did
this I
think
e
e e
XF is float
right e
yeah no we're do we're just being silly
yeah no we're do we're just being silly
at this point
let's go back to this one
this one should go first right
no visible
effect cuz the main time is from that X
effect cuz the main time is from that X
function and a couple other small things
function and a couple other small things
right
is there a reason hold on maybe we can
is there a reason hold on maybe we can
be smarter
be smarter
right maybe we can be
right maybe we can be
smarter is there a
reason to do this on the CPU
why do we need log standard deviation
why do we need log standard deviation
maybe we can be smarter that
way and maybe we can just be smarter
way and maybe we can just be smarter
over
over
there ah shoot it's
there ah shoot it's
6:30 I've been optimizing too long
6:30 I've been optimizing too long
without noticing
without noticing
it I'm going to check one
it I'm going to check one
thing though before I get dinner which
thing though before I get dinner which
is
is
think we can be a little bit more
clever where do we use log standard
clever where do we use log standard
deviation
do we use this every time we do
right
okay yeah we immediately call expon
this so we'll just have the Network
this so we'll just have the Network
return standard deviation instead of log
return standard deviation instead of log
standard Dev ation
right and then it'll be done on the GPU
right and then it'll be done on the GPU
and we won't have to parallelize
it now we do lose this
clamp but we can do the clamp on the GPU
clamp but we can do the clamp on the GPU
as
well yeah do that and that actually will
well yeah do that and that actually will
save quite a
lot that should be very very parallel
right and that gets compiled
right and that gets compiled
perfect so that will save
us this
us this
line oh and then I think Max and Min
line oh and then I think Max and Min
should get um Sim deed as a result Maybe
we can also potentially keep this on the
we can also potentially keep this on the
GPU for
GPU for
longer
longer
right because I think we don't really
right because I think we don't really
care about
care about
doing me see Advantage
doing me see Advantage
scale actually a lot of this can be done
scale actually a lot of this can be done
on the GPU now that I'm looking at
on the GPU now that I'm looking at
it it's right up
it it's right up
until I think here is where it's sketchy
maybe yeah okay so we'll play with that
maybe yeah okay so we'll play with that
after um because I think we're kind of
after um because I think we're kind of
at the limits of what we can optimize in
at the limits of what we can optimize in
the C we're still leaking 5% perf I do
the C we're still leaking 5% perf I do
not like that they should not leak any
not like that they should not leak any
per
per
uh and then after that we still have to
uh and then after that we still have to
update this other function down
here I don't think that what I have
here I don't think that what I have
planned will improve this but maybe all
planned will improve this but maybe all
right I'm going to go get some dinner uh
right I'm going to go get some dinner uh
for folks
for folks
watching all my stuff's at
watching all my stuff's at
puff. Star of the GitHub really helps us
puff. Star of the GitHub really helps us
out Jo Discord if you want and follow on
out Jo Discord if you want and follow on
X more content I'll be back at
