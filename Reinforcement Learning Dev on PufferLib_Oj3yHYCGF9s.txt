Kind: captions
Language: en
Okay, we are back live. Good
evening. I figure we uh we'll get some
evening. I figure we uh we'll get some
experiments
done. Take a look at some stuff.
Okay, so we have 85
experiments. The main
experiments. The main
question, did we fix the bug?
I think that this is just the uh hyper
I think that this is just the uh hyper
prem sweep taking
prem sweep taking
forever. We shall
see. Yes.
I'm going to give it until the end of
I'm going to give it until the end of
this stream to blast the hell out of bet
this stream to blast the hell out of bet
for doing this [ __ ] Literally cost me
for doing this [ __ ] Literally cost me
the entire
day.
Uhoh.
Uhoh.
Huh. This is a dramatically different
Huh. This is a dramatically different
result from before.
But we will let it keep
running. Think what else there
running. Think what else there
is. Actually made very very good
is. Actually made very very good
progress then if this is
progress then if this is
fixed. Um I did change a few things on
fixed. Um I did change a few things on
the sweeps that could have caused this.
the sweeps that could have caused this.
be able to uh to check on
that. We could start on
meta stuff would be good.
sync the
sync the
metaphor. So, uh, let me talk a little
metaphor. So, uh, let me talk a little
bit about this environment and what it
bit about this environment and what it
is. So, I think we're going to be doing
is. So, I think we're going to be doing
a little bit of work on this over the
a little bit of work on this over the
next couple of
next couple of
weeks. So, this environment
here, it's kind of like this
here, it's kind of like this
factoryesque end.
which they're resources and agents run
which they're resources and agents run
around and they convert stuff to
around and they convert stuff to
different resources.
old
syntax. Okay. So now for meta we have
syntax. Okay. So now for meta we have
to pip install mega conf
to pip install mega conf
Hydra
core and duct
DB. It changed the observation space.
DB. It changed the observation space.
They told me about this.
It should actually make it just a tidbit
It should actually make it just a tidbit
faster.
And
uh I need to know what is the maxv
now guys.
They have the max anywhere.
Yeah, that's a bit
annoying. I don't know uh which of
these. Huh. They're not going to reply
these. Huh. They're not going to reply
because it's Memorial Day, right?
Holder.
There.
There.
Okay. So, it runs
Meta. So this is the best one it seems.
Meta. So this is the best one it seems.
33172.
If you ever find yourself adding a
If you ever find yourself adding a
loading screen, it's cuz your code's
loading screen, it's cuz your code's
freaking slow.
M's they're all maintained the
same 32k mini
same 32k mini
batch and then We can
batch and then We can
uh add all the weird
parameters this thing
discovered. The learning rate is going
discovered. The learning rate is going
to be true.
At
least it shouldn't be uh that long to
least it shouldn't be uh that long to
run this, right?
All this goes
away. Do we run it
away. Do we run it
for how
long?
long?
500. Yeah, that's probably decent.
500. Yeah, that's probably decent.
Uh, we do need to figure
out I think I do need to at least figure
out I think I do need to at least figure
out a little bit this end,
right? All right. So, what we're going
right? All right. So, what we're going
to do here
to do here
is
obser
obser
this. That's just features.
That doesn't tell me much, huh?
See, I know that that's a different
function. Put this knot in the way.
function. Put this knot in the way.
Yeah, this is torch maximum, not
max. So the idea here is I'm just going
max. So the idea here is I'm just going
to like get an approximate Max.
I have no many no idea how many batches
I have no many no idea how many batches
this is going to
this is going to
be. Not that many.
Okay, this is something to work with.
We're just not going to hit the break
We're just not going to hit the break
point
again. Give it a
second. So, the idea here is just to get
second. So, the idea here is just to get
an empirical maximum.
an empirical maximum.
They're not going to let me know for
They're not going to let me know for
probably until tomorrow what the actual
probably until tomorrow what the actual
max
is. This is
is. This is
probably a pretty darn good
estimate. In
estimate. In
fact, I could use this online, but I
fact, I could use this online, but I
think it'll slow us down a little
think it'll slow us down a little
bit. What I'm going to do is
We got to replace the zeros with
ones. We don't divide by zero
ones. We don't divide by zero
immediately.
like
this. Cool.
size of
tensor. It's going to be
tensor. It's going to be
like none none.
probably like this, right?
Yeah.
Good. This has 500k
Good. This has 500k
train. A little slower than it was
train. A little slower than it was
before, which is odd,
but we have
but we have
25 No, we don't. Oh, yeah. We have 50%
25 No, we don't. Oh, yeah. We have 50%
end of overhead.
You have 16
You have 16
workers. A batch size of 128 seems
workers. A batch size of 128 seems
uh very
uh very
odd. Probably this way because the NV is
odd. Probably this way because the NV is
so slow.
The end is Wait, hang on. The end is not
slow. This is
8192. Let's do 256, right?
8192. Let's do 256, right?
Unless this gives you a ton of envo
overhead
overhead
fine
10%. Your env is not crazy slow. Poppy
10%. Your env is not crazy slow. Poppy
overhead will get you.
Copy overhead will get
Copy overhead will get
you. They just have too many
you. They just have too many
channels. The ops channels. They're all
channels. The ops channels. They're all
floats.
And now we go find
And now we go find
our
pyramid. Yep.
Uh, this not the right
one. Yeah, this is
They change the metric
name or is it just being
name or is it just being
weird? Sometimes it takes a while to get
weird? Sometimes it takes a while to get
the
metric. This does seem odd though.
We've got zero reward sum as well.
Yeah.
Zero. That looks good.
The stats do change
occasionally. This doesn't seem to work.
occasionally. This doesn't seem to work.
So, let's go back to the old hypers.
This will Tell us if it's just the
This will Tell us if it's just the
hypers that are screwed
up. New M is
up. New M is
slower or the new hypers are slower.
slower or the new hypers are slower.
Okay, new hypers are slower. That's
weird. Think I changed anything that
weird. Think I changed anything that
should affect
should affect
that. Okay.
Let's see if this one has a heart. Get
Yeah, this one also gets no reward.
Yeah, I think they broke
Yeah, I think they broke
it. I'm seeing them using attacks at
it. I'm seeing them using attacks at
least
least
now. But
now. But
like, yeah, they must have broken it,
like, yeah, they must have broken it,
right? Zero reward 75 mil.
if they zeroed out the rewards or what
if they zeroed out the rewards or what
they did. Definitely not working
they did. Definitely not working
though. That's
sketchy. Well crap here. probably
sketchy. Well crap here. probably
thought I was going to be able to get
thought I was going to be able to get
some stuff done on their end, but
Okay,
Okay,
8:00.
8:00.
Um, let's have the goal
Um, let's have the goal
be to have our experiments in
spot. This is a good indicator. So, this
spot. This is a good indicator. So, this
is our good sweep, I believe.
So this is sweet progress.
Go
here. Okay, so this took way too long to
here. Okay, so this took way too long to
solve and it only produced like two
solve and it only produced like two
solving
solving
runs. It did up to 200 mil.
runs. It did up to 200 mil.
This one had a lot more long
runs initially.
Perhaps let's revert the sampling
Perhaps let's revert the sampling
change.
Revert the sampling change.
No, the other thing I want to check here
Like I have all these curves,
Like I have all these curves,
right? They
right? They
finish what was like 18 20
seconds. Pretty far
seconds. Pretty far
back. This even the good
back. This even the good
sweep. This is like the good old sweep,
sweep. This is like the good old sweep,
I
think. Not this
one. This is This one is good. This
one. This is This one is good. This
one's 123 experiments. So, I guess we do
one's 123 experiments. So, I guess we do
get good results in 123 experiments. Um,
get good results in 123 experiments. Um,
I guess I want what I want to figure out
I guess I want what I want to figure out
is if we can afford to just do a 100
is if we can afford to just do a 100
experiment sweep for a lot of these now.
Welcome
pub. This should be our benchmark or
pub. This should be our benchmark or
reference right here. This is 123
runs and we get the uh the sub 202
runs and we get the uh the sub 202
several sub 202 runs.
The fact that it'll launch one good run
The fact that it'll launch one good run
though and then immediately just dive
though and then immediately just dive
bomb five is
bomb five is
not not great.
Okay. So they say that their models work
Okay. So they say that their models work
on the latest
on the latest
version like you know very helpful.
Don't there's Anything else obvious,
right? It should at least not get zero
score. Let me make sure I'm not being
score. Let me make sure I'm not being
completely stupid
here. Just make sure I'm not being like
here. Just make sure I'm not being like
totally stupid.
I could be norming it wrong to be fair,
I could be norming it wrong to be fair,
right? I don't see how I would be, but I
right? I don't see how I would be, but I
it's technically possible.
It's a
float. MaxV is a float.
Not doing any weird
division. I mess with like our main
division. I mess with like our main
defaults or something.
We should definitely be getting some
We should definitely be getting some
sort of reward
here. Getting all the normal stats but
here. Getting all the normal stats but
no reward.
Okay, this sweep has warmed up
nicely. See if this does well.
and that seems like an M screw up,
and that seems like an M screw up,
right?
Wait. This update the buffers in
Wait. This update the buffers in
place. Welcome Hyper. Uh, welcome
Hyper. Don't even know you have a fellow
Hyper. Don't even know you have a fellow
programmer. This is reinforcement
programmer. This is reinforcement
learning dev. Currently just running
learning dev. Currently just running
some experiments and seeing what
some experiments and seeing what
happened with this uh environment here.
happened with this uh environment here.
I do ultra high performance simulation
I do ultra high performance simulation
reinforcement learning
reinforcement learning
tooling among other
tooling among other
things. What are you doing
things. What are you doing
though? So this is my main
though? So this is my main
jam. Puffer Lib is our toolkit. We train
jam. Puffer Lib is our toolkit. We train
really small models to do really
really small models to do really
impressive things very
quickly. We got a whole bunch of games
quickly. We got a whole bunch of games
we use for testing. They all run
we use for testing. They all run
ridiculously fast and watch neural
ridiculously fast and watch neural
networks play them pretty well in your
networks play them pretty well in your
browser.
browser.
simple arcade games. We got multi-agent
simple arcade games. We got multi-agent
stuff. Here's like a bajillion snakes
stuff. Here's like a bajillion snakes
all controlled by neural
all controlled by neural
nets. And we even have, this is from my
nets. And we even have, this is from my
PhD thesis, neural MMO. You can watch
PhD thesis, neural MMO. You can watch
agents play this little MMO with an
agents play this little MMO with an
economy and trade and all sorts of
economy and trade and all sorts of
stuff. And uh we do stuff like train on
stuff. And uh we do stuff like train on
2,000 years worth of simulated games on
2,000 years worth of simulated games on
like your desktop in a few days.
like your desktop in a few days.
Um, this is my comprehensive effort to
Um, this is my comprehensive effort to
make this area of science work.
That's the jam around
here. Yeah. Well, our environments run
here. Yeah. Well, our environments run
really fast.
really fast.
like we run like millions of steps per
like we run like millions of steps per
second. Um because all of our
second. Um because all of our
environments are written in optimize C,
environments are written in optimize C,
at least somewhat optimized C, they
at least somewhat optimized C, they
could be even
faster. RL with real robots is a
faster. RL with real robots is a
possibility. Yeah, if you train a decent
possibility. Yeah, if you train a decent
bit of it in simulation or if you have
bit of it in simulation or if you have
enough money to buy a ton of
enough money to buy a ton of
them, you just need a lot of
them, you just need a lot of
data.
Right. So something is not happening
Right. So something is not happening
correctly here I
think. Something is not happening.
bottleneck was reward
bottleneck was reward
engineering. No, the way that they frame
engineering. No, the way that they frame
reward engineering for like humanoid
reward engineering for like humanoid
robotics is just really
stupid. That's all.
It's really just mostly hyperf
simulation. Actions
works. I think this would have changed.
works. I think this would have changed.
It's been like this for a while.
We haven't uh we haven't messed with
We haven't uh we haven't messed with
this. Got three viewers in live trying
this. Got three viewers in live trying
to live yet trying to trying here trying
to live yet trying to trying here trying
to hire
to hire
you. Well, that name is
Korean and yeah, it's going to be a
Korean and yeah, it's going to be a
small stream. It's uh let's fix the ISO
small stream. It's uh let's fix the ISO
on this. This is like specialized
on this. This is like specialized
technical stuff. Yeah.
getting stable
diffusion. You don't have to hire me uh
diffusion. You don't have to hire me uh
to get access to all this stuff. This is
to get access to all this stuff. This is
all free open source code. All our tools
all free open source code. All our tools
are up on uh up on there and you can
are up on uh up on there and you can
actually come build new environments
actually come build new environments
with us as well. I've taught a lot of
with us as well. I've taught a lot of
people the
people the
ropes though. That said, we do have uh
ropes though. That said, we do have uh
service packages for companies. How I
service packages for companies. How I
pay for servers
Something's just something screw here. I
Something's just something screw here. I
think they just they did something
think they just they did something
weird. I don't know what they
did. This is getting updated in place.
did. This is getting updated in place.
What the heck this
E, that's
weird. So, should I
Oh, so their environment was completely
Oh, so their environment was completely
freaking broken.
Well, I
Just do something real quick.
Just do something real quick.
think this will work, What?
Is it zero reward or is it very low
Is it zero reward or is it very low
reward?
Oh, it's zero
reward. Actually, zero
reward. Actually, zero
reward unless they messed up the logging
reward unless they messed up the logging
now.
But it's also not getting any
hearts. That's straight up zero reward.
Oh, size
Oh, size
of that's probably it,
Okay. Why is it a bull?
This is still zero reward.
thing render.
There.
Help. What is auto
evening
bet.
bet.
Well, I will uh I'll wait to tell you
Well, I will uh I'll wait to tell you
about the bug that I found until I'm
about the bug that I found until I'm
sure.
sure.
that I actually found
it. I'm 95% sure it's your [ __ ] bug,
it. I'm 95% sure it's your [ __ ] bug,
though.
I was spent all day finding this bug.
So, okay, they just have this end.
They just have this
end. Oh
end. Oh
jeez. We'll see what this is.
No, you didn't mess with
meta. That's them having too many
meta. That's them having too many
engineers editing [ __ ] constantly.
You'll see if it's You'll see when I'm
You'll see if it's You'll see when I'm
sure I'm
correct. It was not a fun day today.
I'll say
that. Oh, I have to load the bloody
that. Oh, I have to load the bloody
config, don't I for them?
There's some
runs. Oh, it's
runs. Oh, it's
like 22.
Okay. I mean, this is
stuff fills
stuff fills
in.
Yeah. One could be
good. I mean, the real time on that,
good. I mean, the real time on that,
that's a 19 second plus eval.
trying to figure out what they keep they
trying to figure out what they keep they
keep freaking editing like everything
keep freaking editing like everything
constantly which is like I do the
same. It's two lists. T O L I S
same. It's two lists. T O L I S
T. I don't see T O L I E T. Do
you? Do you see it? I I don't see one of
those. Ouch.
those. Ouch.
Bet you've caused enough bugs today
Bet you've caused enough bugs today
without making up more. All right.
Uh they not have an example
anywhere. Get new end config.
What is
this? Oh Jesus. They did
this? Oh Jesus. They did
freaking Okay.
Oh, I just had one of their devs tell me
Oh, I just had one of their devs tell me
that they're also now getting zero
that they're also now getting zero
rewards everywhere. Good.
this PR for them.
What is this big ass
PR?
Oh yeah.
Okay. Where's the split view
thing?
Typed. They they do everything
Typed. They they do everything
different. Look, they they do everything
different. Look, they they do everything
the opposite of the way that I would do
the opposite of the way that I would do
it. Like it's pretty much as exact
it. Like it's pretty much as exact
opposite as you possibly
could. I don't
could. I don't
Yeah, I don't freaking know. They do
Yeah, I don't freaking know. They do
everything the exact opposite of the way
everything the exact opposite of the way
that I do it. It's very big tech.
Yeah, they added types on Everything.
I'm trying to figure out what freaking
I'm trying to figure out what freaking
code I'm supposed to look at.
Is
this make unique?
Oh.
I don't think I'm going to be able to do
I don't think I'm going to be able to do
anything with this today. Like, they're
anything with this today. Like, they're
going to have to unbreak it. They've
going to have to unbreak it. They've
kind of just made a mess of the
project. Can I like just look at this
project. Can I like just look at this
thing at least?
thing at least?
Maybe. But what the hell is in
this freaking dozen plus
HPs? C++. Modern C++ hurts to look at.
on this guy. Right.
I can't tell if this is worse than
before. Can I at least get this config
before. Can I at least get this config
to load or no?
Just ask this guy.
I'll link this guy the tutorial.
All right.
Well, I've asked two different people
Well, I've asked two different people
and none of them are answering. Neither
and none of them are answering. Neither
of them are answering uh on the config,
of them are answering uh on the config,
so I don't think that they know.
Is this supposed to get past I guess
Is this supposed to get past I guess
something? But it
something? But it
doesn't freaking know, man.
many
many
experiments and this will definitely
experiments and this will definitely
finish
finish
now. At least get the full sweep.
Hey,
hyper. Damn. What?
going to get this guy to help me load
going to get this guy to help me load
this. Um
Okay, so we are actually starting to get
Okay, so we are actually starting to get
some better runs here. It looks
some better runs here. It looks
like I was hoping we would be able to
like I was hoping we would be able to
get away with doing like 100 experiment
sweeps, but it's okay.
is decent at
least. So, let's say this works.
If this works, then we launch Pong
If this works, then we launch Pong
speedun and then we just like slowly
speedun and then we just like slowly
sweep all the new M's,
sweep all the new M's,
right? I think that's
it. Do a quick set real quick. One more
it. Do a quick set real quick. One more
quick set for the evening.
I figure how the hell they load their
I figure how the hell they load their
freaking script from
freaking script from
this. Damn
this. Damn
it. God damn it.
a fall
a fall
back. I need
back. I need
this. This what I need for this thing to
this. This what I need for this thing to
freaking work.
freaking work.
changing everything's
asked. Five rewards.
Five rewards for
Not
too. That's just ridiculous.
pass in Ven.
Make back self and
config.
config.
Um make
veen self config. Huh.
Meta sim import
make config.
Big render mode stat
writer play
writer play
writer make
writer make
and it seems like this config just
and it seems like this config just
doesn't work.
Hey, I'm Ed. How's it going,
man? Wait, what? Uh, where did Puffer
man? Wait, what? Uh, where did Puffer
go?
go?
Didn't I just have a puffery a second
ago? Am I crazy or did I just have I
ago? Am I crazy or did I just have I
thought there was just a puffer yl in
thought there was just a puffer yl in
here. Config meta
metag config. Nope.
there. What is puffer? Was that puffer
there. What is puffer? Was that puffer
lib? What are you doing today? Puffer li
lib? What are you doing today? Puffer li
is ultra high performance reinforcement
is ultra high performance reinforcement
learning. We have all these demos on
learning. We have all these demos on
puffer.ai. All sorts of games. Neural
puffer.ai. All sorts of games. Neural
nets. Play them in your browser. We
nets. Play them in your browser. We
train uh agents on like thousands of
train uh agents on like thousands of
years worth of simulated experience.
years worth of simulated experience.
It's pretty
It's pretty
cool. Check that out here. Oh, 2.1k
cool. Check that out here. Oh, 2.1k
stars. Speaking of which, star the
stars. Speaking of which, star the
puffer helps out a
puffer helps out a
lot. Good
lot. Good
growth.
Um I guess I should probably just
Um I guess I should probably just
like run their tool.
like run their tool.
[Music]
Okay. Like
Okay. Like
realistically, there's no way I'm going
realistically, there's no way I'm going
to be able to figure this out tonight,
right? I go kill one vast or not. Well,
right? I go kill one vast or not. Well,
actually both of them.
Get the machines here tomorrow.
Just see if this bloody thing does
Just see if this bloody thing does
anything at this point.
What in the
And I didn't kill the other
And I didn't kill the other
machine. Keep
going. Okay, so not a super productive
going. Okay, so not a super productive
evening. Not really my fault.
evening. Not really my fault.
Um, it's kind of just been a bunch of
Um, it's kind of just been a bunch of
[ __ ] to deal with today.
[ __ ] to deal with today.
Well, I
Well, I
think all I really got to do is keep
think all I really got to do is keep
running these
running these
experiments. It took it a little while,
experiments. It took it a little while,
but like I'm actually we're getting the
but like I'm actually we're getting the
uh the hypers at the top
here. Oh,
yeah. God damn
it. There are no commands.
it. There are no commands.
Yeah, neck. It's just stream
Yeah, neck. It's just stream
content. We just do the
research. It's a little bit odd that
research. It's a little bit odd that
this takes a while to get going.
this takes a while to get going.
Like actually, I guess we can real quick
Like actually, I guess we can real quick
do a little analysis on this,
do a little analysis on this,
right? Let's do star of the puffer.
Like possibly some of these params just
Like possibly some of these params just
have some drift to them that they take a
have some drift to them that they take a
while to uh to equalize
out is interesting.
Is there any reason not to just do it in
Is there any reason not to just do it in
multiples of
four? I guess cuz I don't have it set up
four? I guess cuz I don't have it set up
to do
to do
that. That's okay. We'll keep it this
that. That's okay. We'll keep it this
way then. That's not too big of a
limitation. We'll see this this finishes
limitation. We'll see this this finishes
tomorrow.
I
I
guess should I just start working on new
M's? I think we're pretty much good to
M's? I think we're pretty much good to
go
otherwise like the final experiments.
But I'd like to do some stuff on meta,
But I'd like to do some stuff on meta,
but it's like not just not
but it's like not just not
going. I need to get me some good
configs. Vector
configs. Vector
changes. Uh, no. And I'm doing stability
changes. Uh, no. And I'm doing stability
testing right now.
I looked through a little bit of the No,
I looked through a little bit of the No,
the Mac OS. I didn't. I looked through
the Mac OS. I didn't. I looked through
the other thing. What happened with
Mac? Oops.
Why does torch not have a uint?
Yeah, running with train.optimizer Adam
Yeah, running with train.optimizer Adam
just like sends you back to the [ __ ]
just like sends you back to the [ __ ]
dark ages is the
dark ages is the
thing. It doesn't define
thing. It doesn't define
those. You're kidding. The Mac version
those. You're kidding. The Mac version
doesn't have unsigned integers.
It doesn't have standard types
though. That's so dumb.
You can't do anything if you don't have
You can't do anything if you don't have
a heavy ball. Like, if you just have
a heavy ball. Like, if you just have
Adam, you're not going to be able to do
Adam, you're not going to be able to do
anything. It's a massive
difference. What does it Why doesn't it
difference. What does it Why doesn't it
build?
is compiling
is compiling
symbol. Wait, why do you why are you
symbol. Wait, why do you why are you
using torch 2.2.2? Is that the latest
using torch 2.2.2? Is that the latest
available for
Mac? No, they have 2.7.
Well, you're on a super
Well, you're on a super
old You're on a super old
old You're on a super old
torch.
torch.
2.2. They're on
2.7. Hey, that
guy. Yeah, cuz for some reason people
guy. Yeah, cuz for some reason people
develop on Macs. I don't get a real
develop on Macs. I don't get a real
operating system. I don't freaking get
operating system. I don't freaking get
it, but we'll try to make it
it, but we'll try to make it
work. I'm being rate limited on Twitch.
work. I'm being rate limited on Twitch.
I don't I don't have any default set to
I don't I don't have any default set to
do that. And it doesn't give me any
do that. And it doesn't give me any
options to control
it. I'm not sure why 2.2.2 was the
it. I'm not sure why 2.2.2 was the
version
version
installed. That must be the default on
installed. That must be the default on
Mac OS, which is pathetic.
I don't know why you have
2.2.2. I got a UV setup working.
We're using UV in the We're using VMs in
We're using UV in the We're using VMs in
the container now because Python devs
the container now because Python devs
have [ __ ] for brains and like I'm sick
have [ __ ] for brains and like I'm sick
of fighting
it. UV has a torch mode. Wait,
what? Yeah. Okay.
is this this is just 24.04 pretty
vanilla. Well, this doesn't do anything
vanilla. Well, this doesn't do anything
though. Like that guy. This doesn't do
though. Like that guy. This doesn't do
anything because then you're just like
anything because then you're just like
creating a different install pattern for
creating a different install pattern for
UV users versus everyone
UV users versus everyone
else, right?
Does this actually work?
I'll try it.
Yeah, I'm not screwing with any of the
Yeah, I'm not screwing with any of the
lock files. like they can [ __ ] off with
that. I don't know if I trust this
that. I don't know if I trust this
versus um just having it
pinned.
Here, I'll show you our
current. So, here's the new
current. So, here's the new
Docker. You can see you pretty much can
Docker. You can see you pretty much can
just use UV with it and it's
fine. The only gotcha is imagine that we
fine. The only gotcha is imagine that we
ship the pit package, right? The only
ship the pit package, right? The only
gotcha is you have to install your torch
gotcha is you have to install your torch
version, okay? Which is like standard if
version, okay? Which is like standard if
you need a different torch version. And
you need a different torch version. And
if you have a different torch version
if you have a different torch version
from the default, you have to install
from the default, you have to install
with no build isolation. Those are the
with no build isolation. Those are the
only
gotchas. Everything else I made to
work. Last version of Torchwood that
work. Last version of Torchwood that
shipped with x86
shipped with x86
compat.
compat.
Jeez. All right. There you go.
Enjoy having literal unsupported
hardware. Can't make the index URL a
hardware. Can't make the index URL a
build arg as far as I'm aware
build arg as far as I'm aware
because wait, can you make the index URL
because wait, can you make the index URL
a build arg?
Wait, first of all, one, can you make
Wait, first of all, one, can you make
can the user pass buildtime args? And
can the user pass buildtime args? And
then two, even if you can, why would I
then two, even if you can, why would I
then want to make you install with build
then want to make you install with build
isolation where it's just going to go
isolation where it's just going to go
spend twice as long downloading a second
spend twice as long downloading a second
copy of
torch d-build
argu.
Yes. Oh, to Docker. No, you're getting
Yes. Oh, to Docker. No, you're getting
this Docker file. You're just getting
this Docker file. You're just getting
shipped this freaking Docker. You're
shipped this freaking Docker. You're
just getting shipped the Docker image.
just getting shipped the Docker image.
You're not messing with the Docker file.
You're not messing with the Docker file.
I meant like if I'm going to because
I meant like if I'm going to because
there's going to be just a UV option as
there's going to be just a UV option as
well, right? Or just like a standard
well, right? Or just like a standard
like um a no container option.
like um a no container option.
So like you can't pass
So like you can't pass
args to setup.py build,
args to setup.py build,
right? Sucks. You have to use
right? Sucks. You have to use
divval. It's like a few
divval. It's like a few
gigs.
gigs.
Whatever. I'm not shipping kernel
Whatever. I'm not shipping kernel
binaries. I'm not doing it.
I've literally spent like a couple
I've literally spent like a couple
hundred hours fighting [ __ ] in this
hundred hours fighting [ __ ] in this
release. Like over the last few weeks
release. Like over the last few weeks
already, several weeks, I should
say. Yes.
So, when do
So, when do
we I mean, we can we can do this live.
we I mean, we can we can do this live.
Bet gets to
Bet gets to
[ __ ] Let's just blast Bet live on the
[ __ ] Let's just blast Bet live on the
freaking
Discord. You used an LLM
Discord. You used an LLM
to edit
to edit
critical infra. You
didn't
didn't
understand and broke
everything. If
everything. If
free a pointer
But
not whenever it
not whenever it
wants. I got to spend all
day figuring out why I had
day figuring out why I had
randomly
randomly
fragmented memory address space
seg Python. Nowhere I can even get a
seg Python. Nowhere I can even get a
stack
stack
trace
trace
because you had to
touch had to with it to do
this. And there's your get
blame. There you go.
So, thank you, Bet. I got to spend six
So, thank you, Bet. I got to spend six
[ __ ] hours debugging that because of
[ __ ] hours debugging that because of
your dumbass
your dumbass
today. Don't paste [ __ ] into an LLM when
today. Don't paste [ __ ] into an LLM when
it's critical info you don't understand.
I switch to Abuntu. Go to
I switch to Abuntu. Go to
apps. This is literally just default
apps. This is literally just default
Abuntu, man. This is default Abuntu with
Abuntu, man. This is default Abuntu with
like the background set to like a
like the background set to like a
specific puffer shade of
teal. I I just want you to understand
teal. I I just want you to understand
how [ __ ] hard this was to debug
how [ __ ] hard this was to debug
today.
today.
Okay, this is not solarized dark blue.
Okay, this is not solarized dark blue.
Oh, if you want the config for my code,
Oh, if you want the config for my code,
you can get that as well. That's on our
you can get that as well. That's on our
Docker page, but that's a little bit
Docker page, but that's a little bit
more out there. Let me just show you
more out there. Let me just show you
something bad. This is what I had to
something bad. This is what I had to
[ __ ] do all
day. Okay. And look, I can tell you used
day. Okay. And look, I can tell you used
an
an
LLM because the comments are like I can
LLM because the comments are like I can
tell because of the damn
comments. Okay. Like I can see like
comments. Okay. Like I can see like
there are like a bunch of these and
there are like a bunch of these and
there were like a couple others like
there were like a couple others like
this. We need to Yeah, this is total
this. We need to Yeah, this is total
LLM. So you have this and then what you
LLM. So you have this and then what you
were doing is you had this free up here.
were doing is you had this free up here.
Okay. So when you have this free up here
Okay. So when you have this free up here
inside of the for loop, it's going to
inside of the for loop, it's going to
free it a whole bunch of times, which
free it a whole bunch of times, which
means that randomly Python can just
means that randomly Python can just
decide whenever the hell it wants to
decide whenever the hell it wants to
free that pointer. And if it just so
free that pointer. And if it just so
happens to free that pointer right
happens to free that pointer right
before you go to use it, then you're
before you go to use it, then you're
[ __ ] because it fragments memory
[ __ ] because it fragments memory
space. And this thing would happen after
space. And this thing would happen after
like an average of 80 experiments. All
like an average of 80 experiments. All
right. So, it like it was a hugely
right. So, it like it was a hugely
intermittent bug and I suspect that this
intermittent bug and I suspect that this
bug was actually screwing up the other
bug was actually screwing up the other
contract work I had because we had a
contract work I had because we had a
random seg fault we couldn't reproduce
random seg fault we couldn't reproduce
there either. So, yeah, it's
there either. So, yeah, it's
like this
[ __ ] like let me show you the stack
[ __ ] like let me show you the stack
trace I got from
trace I got from
this. This is the stack trace you get.
this. This is the stack trace you get.
No, this doesn't come up in GDB or
No, this doesn't come up in GDB or
Mammandan even with all the work I did
Mammandan even with all the work I did
because guess what? This fragments
because guess what? This fragments
memory and then it's just going to error
memory and then it's just going to error
randomly somewhere else in Python. So
randomly somewhere else in Python. So
unless you compile all of Python with
unless you compile all of Python with
mem sanitizer, then maybe you could
mem sanitizer, then maybe you could
catch it. This is the stack trace I get.
catch it. This is the stack trace I get.
This is a stack trace that doesn't
This is a stack trace that doesn't
include anything in my entire codebase.
include anything in my entire codebase.
This is purely a Python stack trace that
This is purely a Python stack trace that
seg faults on a malik. Yeah, you can seg
seg faults on a malik. Yeah, you can seg
fault on a malak.
fault on a malak.
Not a reed, a malac.
Not a reed, a malac.
Great. So, what did I have to do was
Great. So, what did I have to do was
eventually I got lucky. I found a good
eventually I got lucky. I found a good
seed on which I could like reproduce
seed on which I could like reproduce
this thing in a reasonable amount of
this thing in a reasonable amount of
time. I had to not even add prints on
time. I had to not even add prints on
specific lines because that would screw
specific lines because that would screw
with memory space and cause it to
with memory space and cause it to
non-deterministically jump. I had to
non-deterministically jump. I had to
eventually debug it down to I got a
eventually debug it down to I got a
config where it would seg only calling
config where it would seg only calling
veanit, not calling the rest of the
veanit, not calling the rest of the
functions. So that narrowed it down to
functions. So that narrowed it down to
vechanit and then I had to go through
vechanit and then I had to go through
that like very very closely until
that like very very closely until
eventually I saw that the deck ref was
eventually I saw that the deck ref was
in the wrong
loop. God damn. This was the single
loop. God damn. This was the single
hardest bug I've had to fix in the last
hardest bug I've had to fix in the last
several months because of your [ __ ]
several months because of your [ __ ]
LL. Don't use it. Just don't. Not for
LL. Don't use it. Just don't. Not for
critical infrastructure.
And here I see like you open Twitch all
And here I see like you open Twitch all
day and you see this brain rot like
day and you see this brain rot like
hardy dirty dur. Let's see how long does
hardy dirty dur. Let's see how long does
it take to find an LLM's good post.
it take to find an LLM's good post.
Let's see. Uh let's see. Uh fine. I'm
Let's see. Uh let's see. Uh fine. I'm
guarantee you this is vibe coded. Let's
see. How long does it take to find a
see. How long does it take to find a
dumbass LLM post? Yeah, here's LLM
dumbass LLM post? Yeah, here's LLM
[ __ ] Where's more LLM [ __ ]
[ __ ] Where's more LLM [ __ ]
Oh, here's llm
[ __ ] Okay, I think I've muted a
[ __ ] Okay, I think I've muted a
hell of a lot of it on my timeline, but
hell of a lot of it on my timeline, but
there's a lot of LM [ __ ] LM solve
there's a lot of LM [ __ ] LM solve
everything except when they break your
everything except when they break your
entire [ __ ] code base.
So yeah, this
sucked. And the thing was originally
sucked. And the thing was originally
when I wrote the original version, I
when I wrote the original version, I
wrote it without deck refs. So, I wrote
wrote it without deck refs. So, I wrote
the thing just to leak a little bit of
the thing just to leak a little bit of
memory so that I wouldn't have to deal
memory so that I wouldn't have to deal
with Python's awful garbage collecting
with Python's awful garbage collecting
mechanics. All
right. Yeah, you wouldn't be able to fix
right. Yeah, you wouldn't be able to fix
this.
God, you need to not use LLMs to
God, you need to not use LLMs to
interact with complicated [ __ ] without
interact with complicated [ __ ] without
understanding it.
piraf
piraf
debug. No idea what that
debug. No idea what that
is. You got to realize I had to debug
is. You got to realize I had to debug
this. This is the first thing I've had
this. This is the first thing I've had
to do with the C API in Python. The endb
to do with the C API in Python. The endb
finding code is not great. It could be
finding code is not great. It could be
much better. This is V1 of the new ends.
That probably would have caught
it. How do I open this thing?
But the fact that this can cause a seg
But the fact that this can cause a seg
not with a stack trace that is not in
not with a stack trace that is not in
your code
sucks. Well, the thing is it had some
sucks. Well, the thing is it had some
stuff about ref counting, but it also
stuff about ref counting, but it also
generated like 10 pages of other
generated like 10 pages of other
garbage. So, uh, like of the rest of
garbage. So, uh, like of the rest of
which almost all was wrong. So, it's
which almost all was wrong. So, it's
like great. I could just give you the
like great. I could just give you the
program. The program also has the right
program. The program also has the right
information in there
somewhere. Also, here's a fun one. uh
somewhere. Also, here's a fun one. uh
loading
loading
in um setting LD preload flags to enable
in um setting LD preload flags to enable
debugging causes the process to take 20
debugging causes the process to take 20
terab of virtual address space. So
terab of virtual address space. So
that's a cool thing to find
out. Yeah, Gemini 25 Pro caused the bug.
All right. Well, I will use that in the
All right. Well, I will use that in the
future if I need to deck ref stuff.
But wait, if it ends at
zero, you could still Yeah, you can
zero, you could still Yeah, you can
still break
it. Oh,
it. Oh,
this
here. Why aren't you in here?
Hey,
Hey,
Weston. It was just a really [ __ ]
Weston. It was just a really [ __ ]
hard bug.
And oh, by the way, this stack trace,
And oh, by the way, this stack trace,
you don't even get this stack trace for
you don't even get this stack trace for
free. You have to compile, you have to
free. You have to compile, you have to
compile everything with super duper
compile everything with super duper
debug mode and set a bunch of symbols to
debug mode and set a bunch of symbols to
even get
this. All right.
this. All right.
At first, I just got hanging. And then
At first, I just got hanging. And then
eventually, I reproduced this bug in
eventually, I reproduced this bug in
serial mode with a seg fault after
serial mode with a seg fault after
running it for like, you know, 10
running it for like, you know, 10
minutes with a custom test script
minutes with a custom test script
intended to go really fast. And then I
intended to go really fast. And then I
tuned that a bunch and I got like
tuned that a bunch and I got like
intermittent issues with a bunch of
intermittent issues with a bunch of
different versions. And then eventually
different versions. And then eventually
I got like the jank thing where I like I
I got like the jank thing where I like I
got it to take fault at the same place,
got it to take fault at the same place,
but only with that seed and only if you
but only with that seed and only if you
didn't like put a print statement in the
didn't like put a print statement in the
wrong place that changed address space.
wrong place that changed address space.
Um, and then eventually like I got it to
Um, and then eventually like I got it to
like I got to strip out some additional
like I got to strip out some additional
functions and still get to seg fault.
functions and still get to seg fault.
Eventually I like you know bisected it
Eventually I like you know bisected it
down to the right
spot. So anything except this if you do
spot. So anything except this if you do
anything except what you did here you
anything except what you did here you
will actually get a stack trace out of
will actually get a stack trace out of
puffer in debug mode.
anything but the exact thing that you
anything but the exact thing that you
did
here. I'm pretty sure you can even
here. I'm pretty sure you can even
detect this in C. You can't detect it
detect this in C. You can't detect it
with Python's garbage collection. You
with Python's garbage collection. You
could even I think use after free you
could even I think use after free you
can even detect with the C uh C flags.
can even detect with the C uh C flags.
Just this specific thing. You found the
Just this specific thing. You found the
one thing I couldn't catch.
That's seep hanging
That's seep hanging
bug. What was the solution to that one?
Oh yeah, that was
ridiculous. What the hell? It's It's
ridiculous. What the hell? It's It's
like that there's some other function
like that there's some other function
like there's some core function called
like there's some core function called
step, right?
Can you not just object dump it? I don't
Can you not just object dump it? I don't
know how the hell you would find that
know how the hell you would find that
one deck
one deck
ref. Maybe there are additional debug
ref. Maybe there are additional debug
tools. The thing that guy said would
tools. The thing that guy said would
probably work, but like literally this
probably work, but like literally this
is the first piece of code I've had to
is the first piece of code I've had to
write with the Python C API. All right,
write with the Python C API. All right,
this is V1 of the end of binding. It's
this is V1 of the end of binding. It's
the least mature spot of like where we
the least mature spot of like where we
have debug stuff for and like know like
have debug stuff for and like know like
the least like the spot I least know how
the least like the spot I least know how
to fix stuff in the whole code
base. A real pain in the
base. A real pain in the
ass. All right. How are we doing
here? I mean, this doesn't seem to be
here? I mean, this doesn't seem to be
doing quite as
doing quite as
well as
before. Hard to
before. Hard to
say. We'll let this full run overnight,
say. We'll let this full run overnight,
though. We'll let this finish full
though. We'll let this finish full
running overnight.
running overnight.
So, the plan is to just run experiments,
So, the plan is to just run experiments,
probably work on some different
probably work on some different
environments. Um, I got to start doing
environments. Um, I got to start doing
like stuff for after 3 0
now. So, we're not going to insta
now. So, we're not going to insta
release 3, but I am going to start on
release 3, but I am going to start on
like the new sim work and all that
stuff. Exhausting.
This
is what's that going to do, Linky? It's
is what's that going to do, Linky? It's
like there's a deck ref in one spot and
like there's a deck ref in one spot and
then Python's garbage collector randomly
then Python's garbage collector randomly
frees the thing in another spot and then
frees the thing in another spot and then
in a third spot a me a a Malik fails
in a third spot a me a a Malik fails
because of it
somehow all
somehow all
um freaking randomly
It was a rough thing to
debug. All we got to do now though is
debug. All we got to do now though is
make sure that I didn't break um our
make sure that I didn't break um our
sweeps with any of the latest stuff.
Trying to think if I want to kill this
Trying to think if I want to kill this
and if I want to run
and if I want to run
um 10 10 subsample points instead.
I think
I think
so. Five is going to
faster. This is probably going to need a
faster. This is probably going to need a
revamp at some point anyways cuz it ends
revamp at some point anyways cuz it ends
up taking
up taking
like a couple minutes per
like a couple minutes per
um per suggestion.
full sweep should be done in like an
full sweep should be done in like an
hour or
two. But I think that the I think that
two. But I think that the I think that
this adds like double it doubles the
this adds like double it doubles the
time
basically. It is only really a problem
basically. It is only really a problem
for these tiny little experiments
for these tiny little experiments
though.
We'll leave it for
We'll leave it for
now. Can only do so much for no
release. I'll deal with meta as soon as
release. I'll deal with meta as soon as
they have stable version for
they have stable version for
me.
Um, a few other small things to do for
Um, a few other small things to do for
clients. I think we'll just start on
clients. I think we'll just start on
Terraform stuff. I think that'll be a
Terraform stuff. I think that'll be a
fun thing to do to start on terraform
fun thing to do to start on terraform
stuff. Be way better.
All right, I think I'm going to just go
All right, I think I'm going to just go
get some sleep
get some sleep
then. Get some rest. Start this thing
tomorrow. Yeah, then breakout will
tomorrow. Yeah, then breakout will
finish.
finish.
I'll
have Yeah, because I could write some
have Yeah, because I could write some
basic configs for the next experiments,
basic configs for the next experiments,
but I'm getting tired. So, I think I'm
but I'm getting tired. So, I think I'm
just going to call it for
just going to call it for
tonight. I think we're going to work on
tonight. I think we're going to work on
tomorrow the terraform again. So, it's
tomorrow the terraform again. So, it's
like this
like this
digging like move dirt from one place to
digging like move dirt from one place to
other terraform
other terraform
environment and work on that tomorrow
environment and work on that tomorrow
potentially. I want to write more C. I'm
potentially. I want to write more C. I'm
sick of debugging like
sick of debugging like
shitty annoying Python
shitty annoying Python
loops and build systems and all
loops and build systems and all
that. We'll do some sim sim side work.
that. We'll do some sim sim side work.
Maybe algorithms at some point soon as
Maybe algorithms at some point soon as
well, but also simside
well, but also simside
stuff.
stuff.
Okay. Um well, decent outcome for today
Okay. Um well, decent outcome for today
and that uh we actually did get that bug
and that uh we actually did get that bug
resolved.
folks
folks
watching all the things of
watching all the things of
Puffer.ai. It's all free and open
Puffer.ai. It's all free and open
source. Want to get into reinforcement
source. Want to get into reinforcement
learning? Good way to do
things. You will not get yelled at as
things. You will not get yelled at as
badly as BET did for making mistakes
badly as BET did for making mistakes
unless you make them because you just
unless you make them because you just
blindly copy paste from an
blindly copy paste from an
LLM. That's about the only pet peeve.
Um, yeah, start the repo on GitHub to
Um, yeah, start the repo on GitHub to
help me out a lot. Really
help me out a lot. Really
helps. Other than that, join Discord.
helps. Other than that, join Discord.
You can also follow me on X for more
You can also follow me on X for more
content where I occasionally post things
content where I occasionally post things
and I try not to read X too much because
and I try not to read X too much because
it's way better when you just write
it's way better when you just write
stuff and don't read
stuff and don't read
it. Now, the only good thing about this
it. Now, the only good thing about this
stupid
website is that occasionally uh where is
website is that occasionally uh where is
it? Can I even scroll and find
it? Can I even scroll and find
one? Where is
one? Where is
he? Oh, yeah. Look. Sometimes there's
he? Oh, yeah. Look. Sometimes there's
fun stuff like look at the
manatees. That's
funny. All right. Good night.

Kind: captions
Language: en
Okay, we are back live. Good
evening. I figure we uh we'll get some
evening. I figure we uh we'll get some
experiments
done. Take a look at some stuff.
Okay, so we have 85
experiments. The main
experiments. The main
question, did we fix the bug?
I think that this is just the uh hyper
I think that this is just the uh hyper
prem sweep taking
prem sweep taking
forever. We shall
see. Yes.
I'm going to give it until the end of
I'm going to give it until the end of
this stream to blast the hell out of bet
this stream to blast the hell out of bet
for doing this [ __ ] Literally cost me
for doing this [ __ ] Literally cost me
the entire
day.
Uhoh.
Uhoh.
Huh. This is a dramatically different
Huh. This is a dramatically different
result from before.
But we will let it keep
running. Think what else there
running. Think what else there
is. Actually made very very good
is. Actually made very very good
progress then if this is
progress then if this is
fixed. Um I did change a few things on
fixed. Um I did change a few things on
the sweeps that could have caused this.
the sweeps that could have caused this.
be able to uh to check on
that. We could start on
meta stuff would be good.
sync the
sync the
metaphor. So, uh, let me talk a little
metaphor. So, uh, let me talk a little
bit about this environment and what it
bit about this environment and what it
is. So, I think we're going to be doing
is. So, I think we're going to be doing
a little bit of work on this over the
a little bit of work on this over the
next couple of
next couple of
weeks. So, this environment
here, it's kind of like this
here, it's kind of like this
factoryesque end.
which they're resources and agents run
which they're resources and agents run
around and they convert stuff to
around and they convert stuff to
different resources.
old
syntax. Okay. So now for meta we have
syntax. Okay. So now for meta we have
to pip install mega conf
to pip install mega conf
Hydra
core and duct
DB. It changed the observation space.
DB. It changed the observation space.
They told me about this.
It should actually make it just a tidbit
It should actually make it just a tidbit
faster.
And
uh I need to know what is the maxv
now guys.
They have the max anywhere.
Yeah, that's a bit
annoying. I don't know uh which of
these. Huh. They're not going to reply
these. Huh. They're not going to reply
because it's Memorial Day, right?
Holder.
There.
There.
Okay. So, it runs
Meta. So this is the best one it seems.
Meta. So this is the best one it seems.
33172.
If you ever find yourself adding a
If you ever find yourself adding a
loading screen, it's cuz your code's
loading screen, it's cuz your code's
freaking slow.
M's they're all maintained the
same 32k mini
same 32k mini
batch and then We can
batch and then We can
uh add all the weird
parameters this thing
discovered. The learning rate is going
discovered. The learning rate is going
to be true.
At
least it shouldn't be uh that long to
least it shouldn't be uh that long to
run this, right?
All this goes
away. Do we run it
away. Do we run it
for how
long?
long?
500. Yeah, that's probably decent.
500. Yeah, that's probably decent.
Uh, we do need to figure
out I think I do need to at least figure
out I think I do need to at least figure
out a little bit this end,
right? All right. So, what we're going
right? All right. So, what we're going
to do here
to do here
is
obser
obser
this. That's just features.
That doesn't tell me much, huh?
See, I know that that's a different
function. Put this knot in the way.
function. Put this knot in the way.
Yeah, this is torch maximum, not
max. So the idea here is I'm just going
max. So the idea here is I'm just going
to like get an approximate Max.
I have no many no idea how many batches
I have no many no idea how many batches
this is going to
this is going to
be. Not that many.
Okay, this is something to work with.
We're just not going to hit the break
We're just not going to hit the break
point
again. Give it a
second. So, the idea here is just to get
second. So, the idea here is just to get
an empirical maximum.
an empirical maximum.
They're not going to let me know for
They're not going to let me know for
probably until tomorrow what the actual
probably until tomorrow what the actual
max
is. This is
is. This is
probably a pretty darn good
estimate. In
estimate. In
fact, I could use this online, but I
fact, I could use this online, but I
think it'll slow us down a little
think it'll slow us down a little
bit. What I'm going to do is
We got to replace the zeros with
ones. We don't divide by zero
ones. We don't divide by zero
immediately.
like
this. Cool.
size of
tensor. It's going to be
tensor. It's going to be
like none none.
probably like this, right?
Yeah.
Good. This has 500k
Good. This has 500k
train. A little slower than it was
train. A little slower than it was
before, which is odd,
but we have
but we have
25 No, we don't. Oh, yeah. We have 50%
25 No, we don't. Oh, yeah. We have 50%
end of overhead.
You have 16
You have 16
workers. A batch size of 128 seems
workers. A batch size of 128 seems
uh very
uh very
odd. Probably this way because the NV is
odd. Probably this way because the NV is
so slow.
The end is Wait, hang on. The end is not
slow. This is
8192. Let's do 256, right?
8192. Let's do 256, right?
Unless this gives you a ton of envo
overhead
overhead
fine
10%. Your env is not crazy slow. Poppy
10%. Your env is not crazy slow. Poppy
overhead will get you.
Copy overhead will get
Copy overhead will get
you. They just have too many
you. They just have too many
channels. The ops channels. They're all
channels. The ops channels. They're all
floats.
And now we go find
And now we go find
our
pyramid. Yep.
Uh, this not the right
one. Yeah, this is
They change the metric
name or is it just being
name or is it just being
weird? Sometimes it takes a while to get
weird? Sometimes it takes a while to get
the
metric. This does seem odd though.
We've got zero reward sum as well.
Yeah.
Zero. That looks good.
The stats do change
occasionally. This doesn't seem to work.
occasionally. This doesn't seem to work.
So, let's go back to the old hypers.
This will Tell us if it's just the
This will Tell us if it's just the
hypers that are screwed
up. New M is
up. New M is
slower or the new hypers are slower.
slower or the new hypers are slower.
Okay, new hypers are slower. That's
weird. Think I changed anything that
weird. Think I changed anything that
should affect
should affect
that. Okay.
Let's see if this one has a heart. Get
Yeah, this one also gets no reward.
Yeah, I think they broke
Yeah, I think they broke
it. I'm seeing them using attacks at
it. I'm seeing them using attacks at
least
least
now. But
now. But
like, yeah, they must have broken it,
like, yeah, they must have broken it,
right? Zero reward 75 mil.
if they zeroed out the rewards or what
if they zeroed out the rewards or what
they did. Definitely not working
they did. Definitely not working
though. That's
sketchy. Well crap here. probably
sketchy. Well crap here. probably
thought I was going to be able to get
thought I was going to be able to get
some stuff done on their end, but
Okay,
Okay,
8:00.
8:00.
Um, let's have the goal
Um, let's have the goal
be to have our experiments in
spot. This is a good indicator. So, this
spot. This is a good indicator. So, this
is our good sweep, I believe.
So this is sweet progress.
Go
here. Okay, so this took way too long to
here. Okay, so this took way too long to
solve and it only produced like two
solve and it only produced like two
solving
solving
runs. It did up to 200 mil.
runs. It did up to 200 mil.
This one had a lot more long
runs initially.
Perhaps let's revert the sampling
Perhaps let's revert the sampling
change.
Revert the sampling change.
No, the other thing I want to check here
Like I have all these curves,
Like I have all these curves,
right? They
right? They
finish what was like 18 20
seconds. Pretty far
seconds. Pretty far
back. This even the good
back. This even the good
sweep. This is like the good old sweep,
sweep. This is like the good old sweep,
I
think. Not this
one. This is This one is good. This
one. This is This one is good. This
one's 123 experiments. So, I guess we do
one's 123 experiments. So, I guess we do
get good results in 123 experiments. Um,
get good results in 123 experiments. Um,
I guess I want what I want to figure out
I guess I want what I want to figure out
is if we can afford to just do a 100
is if we can afford to just do a 100
experiment sweep for a lot of these now.
Welcome
pub. This should be our benchmark or
pub. This should be our benchmark or
reference right here. This is 123
runs and we get the uh the sub 202
runs and we get the uh the sub 202
several sub 202 runs.
The fact that it'll launch one good run
The fact that it'll launch one good run
though and then immediately just dive
though and then immediately just dive
bomb five is
bomb five is
not not great.
Okay. So they say that their models work
Okay. So they say that their models work
on the latest
on the latest
version like you know very helpful.
Don't there's Anything else obvious,
right? It should at least not get zero
score. Let me make sure I'm not being
score. Let me make sure I'm not being
completely stupid
here. Just make sure I'm not being like
here. Just make sure I'm not being like
totally stupid.
I could be norming it wrong to be fair,
I could be norming it wrong to be fair,
right? I don't see how I would be, but I
right? I don't see how I would be, but I
it's technically possible.
It's a
float. MaxV is a float.
Not doing any weird
division. I mess with like our main
division. I mess with like our main
defaults or something.
We should definitely be getting some
We should definitely be getting some
sort of reward
here. Getting all the normal stats but
here. Getting all the normal stats but
no reward.
Okay, this sweep has warmed up
nicely. See if this does well.
and that seems like an M screw up,
and that seems like an M screw up,
right?
Wait. This update the buffers in
Wait. This update the buffers in
place. Welcome Hyper. Uh, welcome
Hyper. Don't even know you have a fellow
Hyper. Don't even know you have a fellow
programmer. This is reinforcement
programmer. This is reinforcement
learning dev. Currently just running
learning dev. Currently just running
some experiments and seeing what
some experiments and seeing what
happened with this uh environment here.
happened with this uh environment here.
I do ultra high performance simulation
I do ultra high performance simulation
reinforcement learning
reinforcement learning
tooling among other
tooling among other
things. What are you doing
things. What are you doing
though? So this is my main
though? So this is my main
jam. Puffer Lib is our toolkit. We train
jam. Puffer Lib is our toolkit. We train
really small models to do really
really small models to do really
impressive things very
quickly. We got a whole bunch of games
quickly. We got a whole bunch of games
we use for testing. They all run
we use for testing. They all run
ridiculously fast and watch neural
ridiculously fast and watch neural
networks play them pretty well in your
networks play them pretty well in your
browser.
browser.
simple arcade games. We got multi-agent
simple arcade games. We got multi-agent
stuff. Here's like a bajillion snakes
stuff. Here's like a bajillion snakes
all controlled by neural
all controlled by neural
nets. And we even have, this is from my
nets. And we even have, this is from my
PhD thesis, neural MMO. You can watch
PhD thesis, neural MMO. You can watch
agents play this little MMO with an
agents play this little MMO with an
economy and trade and all sorts of
economy and trade and all sorts of
stuff. And uh we do stuff like train on
stuff. And uh we do stuff like train on
2,000 years worth of simulated games on
2,000 years worth of simulated games on
like your desktop in a few days.
like your desktop in a few days.
Um, this is my comprehensive effort to
Um, this is my comprehensive effort to
make this area of science work.
That's the jam around
here. Yeah. Well, our environments run
here. Yeah. Well, our environments run
really fast.
really fast.
like we run like millions of steps per
like we run like millions of steps per
second. Um because all of our
second. Um because all of our
environments are written in optimize C,
environments are written in optimize C,
at least somewhat optimized C, they
at least somewhat optimized C, they
could be even
faster. RL with real robots is a
faster. RL with real robots is a
possibility. Yeah, if you train a decent
possibility. Yeah, if you train a decent
bit of it in simulation or if you have
bit of it in simulation or if you have
enough money to buy a ton of
enough money to buy a ton of
them, you just need a lot of
them, you just need a lot of
data.
Right. So something is not happening
Right. So something is not happening
correctly here I
think. Something is not happening.
bottleneck was reward
bottleneck was reward
engineering. No, the way that they frame
engineering. No, the way that they frame
reward engineering for like humanoid
reward engineering for like humanoid
robotics is just really
stupid. That's all.
It's really just mostly hyperf
simulation. Actions
works. I think this would have changed.
works. I think this would have changed.
It's been like this for a while.
We haven't uh we haven't messed with
We haven't uh we haven't messed with
this. Got three viewers in live trying
this. Got three viewers in live trying
to live yet trying to trying here trying
to live yet trying to trying here trying
to hire
to hire
you. Well, that name is
Korean and yeah, it's going to be a
Korean and yeah, it's going to be a
small stream. It's uh let's fix the ISO
small stream. It's uh let's fix the ISO
on this. This is like specialized
on this. This is like specialized
technical stuff. Yeah.
getting stable
diffusion. You don't have to hire me uh
diffusion. You don't have to hire me uh
to get access to all this stuff. This is
to get access to all this stuff. This is
all free open source code. All our tools
all free open source code. All our tools
are up on uh up on there and you can
are up on uh up on there and you can
actually come build new environments
actually come build new environments
with us as well. I've taught a lot of
with us as well. I've taught a lot of
people the
people the
ropes though. That said, we do have uh
ropes though. That said, we do have uh
service packages for companies. How I
service packages for companies. How I
pay for servers
Something's just something screw here. I
Something's just something screw here. I
think they just they did something
think they just they did something
weird. I don't know what they
did. This is getting updated in place.
did. This is getting updated in place.
What the heck this
E, that's
weird. So, should I
Oh, so their environment was completely
Oh, so their environment was completely
freaking broken.
Well, I
Just do something real quick.
Just do something real quick.
think this will work, What?
Is it zero reward or is it very low
Is it zero reward or is it very low
reward?
Oh, it's zero
reward. Actually, zero
reward. Actually, zero
reward unless they messed up the logging
reward unless they messed up the logging
now.
But it's also not getting any
hearts. That's straight up zero reward.
Oh, size
Oh, size
of that's probably it,
Okay. Why is it a bull?
This is still zero reward.
thing render.
There.
Help. What is auto
evening
bet.
bet.
Well, I will uh I'll wait to tell you
Well, I will uh I'll wait to tell you
about the bug that I found until I'm
about the bug that I found until I'm
sure.
sure.
that I actually found
it. I'm 95% sure it's your [ __ ] bug,
it. I'm 95% sure it's your [ __ ] bug,
though.
I was spent all day finding this bug.
So, okay, they just have this end.
They just have this
end. Oh
end. Oh
jeez. We'll see what this is.
No, you didn't mess with
meta. That's them having too many
meta. That's them having too many
engineers editing [ __ ] constantly.
You'll see if it's You'll see when I'm
You'll see if it's You'll see when I'm
sure I'm
correct. It was not a fun day today.
I'll say
that. Oh, I have to load the bloody
that. Oh, I have to load the bloody
config, don't I for them?
There's some
runs. Oh, it's
runs. Oh, it's
like 22.
Okay. I mean, this is
stuff fills
stuff fills
in.
Yeah. One could be
good. I mean, the real time on that,
good. I mean, the real time on that,
that's a 19 second plus eval.
trying to figure out what they keep they
trying to figure out what they keep they
keep freaking editing like everything
keep freaking editing like everything
constantly which is like I do the
same. It's two lists. T O L I S
same. It's two lists. T O L I S
T. I don't see T O L I E T. Do
you? Do you see it? I I don't see one of
those. Ouch.
those. Ouch.
Bet you've caused enough bugs today
Bet you've caused enough bugs today
without making up more. All right.
Uh they not have an example
anywhere. Get new end config.
What is
this? Oh Jesus. They did
this? Oh Jesus. They did
freaking Okay.
Oh, I just had one of their devs tell me
Oh, I just had one of their devs tell me
that they're also now getting zero
that they're also now getting zero
rewards everywhere. Good.
this PR for them.
What is this big ass
PR?
Oh yeah.
Okay. Where's the split view
thing?
Typed. They they do everything
Typed. They they do everything
different. Look, they they do everything
different. Look, they they do everything
the opposite of the way that I would do
the opposite of the way that I would do
it. Like it's pretty much as exact
it. Like it's pretty much as exact
opposite as you possibly
could. I don't
could. I don't
Yeah, I don't freaking know. They do
Yeah, I don't freaking know. They do
everything the exact opposite of the way
everything the exact opposite of the way
that I do it. It's very big tech.
Yeah, they added types on Everything.
I'm trying to figure out what freaking
I'm trying to figure out what freaking
code I'm supposed to look at.
Is
this make unique?
Oh.
I don't think I'm going to be able to do
I don't think I'm going to be able to do
anything with this today. Like, they're
anything with this today. Like, they're
going to have to unbreak it. They've
going to have to unbreak it. They've
kind of just made a mess of the
project. Can I like just look at this
project. Can I like just look at this
thing at least?
thing at least?
Maybe. But what the hell is in
this freaking dozen plus
HPs? C++. Modern C++ hurts to look at.
on this guy. Right.
I can't tell if this is worse than
before. Can I at least get this config
before. Can I at least get this config
to load or no?
Just ask this guy.
I'll link this guy the tutorial.
All right.
Well, I've asked two different people
Well, I've asked two different people
and none of them are answering. Neither
and none of them are answering. Neither
of them are answering uh on the config,
of them are answering uh on the config,
so I don't think that they know.
Is this supposed to get past I guess
Is this supposed to get past I guess
something? But it
something? But it
doesn't freaking know, man.
many
many
experiments and this will definitely
experiments and this will definitely
finish
finish
now. At least get the full sweep.
Hey,
hyper. Damn. What?
going to get this guy to help me load
going to get this guy to help me load
this. Um
Okay, so we are actually starting to get
Okay, so we are actually starting to get
some better runs here. It looks
some better runs here. It looks
like I was hoping we would be able to
like I was hoping we would be able to
get away with doing like 100 experiment
sweeps, but it's okay.
is decent at
least. So, let's say this works.
If this works, then we launch Pong
If this works, then we launch Pong
speedun and then we just like slowly
speedun and then we just like slowly
sweep all the new M's,
sweep all the new M's,
right? I think that's
it. Do a quick set real quick. One more
it. Do a quick set real quick. One more
quick set for the evening.
I figure how the hell they load their
I figure how the hell they load their
freaking script from
freaking script from
this. Damn
this. Damn
it. God damn it.
a fall
a fall
back. I need
back. I need
this. This what I need for this thing to
this. This what I need for this thing to
freaking work.
freaking work.
changing everything's
asked. Five rewards.
Five rewards for
Not
too. That's just ridiculous.
pass in Ven.
Make back self and
config.
config.
Um make
veen self config. Huh.
Meta sim import
make config.
Big render mode stat
writer play
writer play
writer make
writer make
and it seems like this config just
and it seems like this config just
doesn't work.
Hey, I'm Ed. How's it going,
man? Wait, what? Uh, where did Puffer
man? Wait, what? Uh, where did Puffer
go?
go?
Didn't I just have a puffery a second
ago? Am I crazy or did I just have I
ago? Am I crazy or did I just have I
thought there was just a puffer yl in
thought there was just a puffer yl in
here. Config meta
metag config. Nope.
there. What is puffer? Was that puffer
there. What is puffer? Was that puffer
lib? What are you doing today? Puffer li
lib? What are you doing today? Puffer li
is ultra high performance reinforcement
is ultra high performance reinforcement
learning. We have all these demos on
learning. We have all these demos on
puffer.ai. All sorts of games. Neural
puffer.ai. All sorts of games. Neural
nets. Play them in your browser. We
nets. Play them in your browser. We
train uh agents on like thousands of
train uh agents on like thousands of
years worth of simulated experience.
years worth of simulated experience.
It's pretty
It's pretty
cool. Check that out here. Oh, 2.1k
cool. Check that out here. Oh, 2.1k
stars. Speaking of which, star the
stars. Speaking of which, star the
puffer helps out a
puffer helps out a
lot. Good
lot. Good
growth.
Um I guess I should probably just
Um I guess I should probably just
like run their tool.
like run their tool.
[Music]
Okay. Like
Okay. Like
realistically, there's no way I'm going
realistically, there's no way I'm going
to be able to figure this out tonight,
right? I go kill one vast or not. Well,
right? I go kill one vast or not. Well,
actually both of them.
Get the machines here tomorrow.
Just see if this bloody thing does
Just see if this bloody thing does
anything at this point.
What in the
And I didn't kill the other
And I didn't kill the other
machine. Keep
going. Okay, so not a super productive
going. Okay, so not a super productive
evening. Not really my fault.
evening. Not really my fault.
Um, it's kind of just been a bunch of
Um, it's kind of just been a bunch of
[ __ ] to deal with today.
[ __ ] to deal with today.
Well, I
Well, I
think all I really got to do is keep
think all I really got to do is keep
running these
running these
experiments. It took it a little while,
experiments. It took it a little while,
but like I'm actually we're getting the
but like I'm actually we're getting the
uh the hypers at the top
here. Oh,
yeah. God damn
it. There are no commands.
it. There are no commands.
Yeah, neck. It's just stream
Yeah, neck. It's just stream
content. We just do the
research. It's a little bit odd that
research. It's a little bit odd that
this takes a while to get going.
this takes a while to get going.
Like actually, I guess we can real quick
Like actually, I guess we can real quick
do a little analysis on this,
do a little analysis on this,
right? Let's do star of the puffer.
Like possibly some of these params just
Like possibly some of these params just
have some drift to them that they take a
have some drift to them that they take a
while to uh to equalize
out is interesting.
Is there any reason not to just do it in
Is there any reason not to just do it in
multiples of
four? I guess cuz I don't have it set up
four? I guess cuz I don't have it set up
to do
to do
that. That's okay. We'll keep it this
that. That's okay. We'll keep it this
way then. That's not too big of a
limitation. We'll see this this finishes
limitation. We'll see this this finishes
tomorrow.
I
I
guess should I just start working on new
M's? I think we're pretty much good to
M's? I think we're pretty much good to
go
otherwise like the final experiments.
But I'd like to do some stuff on meta,
But I'd like to do some stuff on meta,
but it's like not just not
but it's like not just not
going. I need to get me some good
configs. Vector
configs. Vector
changes. Uh, no. And I'm doing stability
changes. Uh, no. And I'm doing stability
testing right now.
I looked through a little bit of the No,
I looked through a little bit of the No,
the Mac OS. I didn't. I looked through
the Mac OS. I didn't. I looked through
the other thing. What happened with
Mac? Oops.
Why does torch not have a uint?
Yeah, running with train.optimizer Adam
Yeah, running with train.optimizer Adam
just like sends you back to the [ __ ]
just like sends you back to the [ __ ]
dark ages is the
dark ages is the
thing. It doesn't define
thing. It doesn't define
those. You're kidding. The Mac version
those. You're kidding. The Mac version
doesn't have unsigned integers.
It doesn't have standard types
though. That's so dumb.
You can't do anything if you don't have
You can't do anything if you don't have
a heavy ball. Like, if you just have
a heavy ball. Like, if you just have
Adam, you're not going to be able to do
Adam, you're not going to be able to do
anything. It's a massive
difference. What does it Why doesn't it
difference. What does it Why doesn't it
build?
is compiling
is compiling
symbol. Wait, why do you why are you
symbol. Wait, why do you why are you
using torch 2.2.2? Is that the latest
using torch 2.2.2? Is that the latest
available for
Mac? No, they have 2.7.
Well, you're on a super
Well, you're on a super
old You're on a super old
old You're on a super old
torch.
torch.
2.2. They're on
2.7. Hey, that
guy. Yeah, cuz for some reason people
guy. Yeah, cuz for some reason people
develop on Macs. I don't get a real
develop on Macs. I don't get a real
operating system. I don't freaking get
operating system. I don't freaking get
it, but we'll try to make it
it, but we'll try to make it
work. I'm being rate limited on Twitch.
work. I'm being rate limited on Twitch.
I don't I don't have any default set to
I don't I don't have any default set to
do that. And it doesn't give me any
do that. And it doesn't give me any
options to control
it. I'm not sure why 2.2.2 was the
it. I'm not sure why 2.2.2 was the
version
version
installed. That must be the default on
installed. That must be the default on
Mac OS, which is pathetic.
I don't know why you have
2.2.2. I got a UV setup working.
We're using UV in the We're using VMs in
We're using UV in the We're using VMs in
the container now because Python devs
the container now because Python devs
have [ __ ] for brains and like I'm sick
have [ __ ] for brains and like I'm sick
of fighting
it. UV has a torch mode. Wait,
what? Yeah. Okay.
is this this is just 24.04 pretty
vanilla. Well, this doesn't do anything
vanilla. Well, this doesn't do anything
though. Like that guy. This doesn't do
though. Like that guy. This doesn't do
anything because then you're just like
anything because then you're just like
creating a different install pattern for
creating a different install pattern for
UV users versus everyone
UV users versus everyone
else, right?
Does this actually work?
I'll try it.
Yeah, I'm not screwing with any of the
Yeah, I'm not screwing with any of the
lock files. like they can [ __ ] off with
that. I don't know if I trust this
that. I don't know if I trust this
versus um just having it
pinned.
Here, I'll show you our
current. So, here's the new
current. So, here's the new
Docker. You can see you pretty much can
Docker. You can see you pretty much can
just use UV with it and it's
fine. The only gotcha is imagine that we
fine. The only gotcha is imagine that we
ship the pit package, right? The only
ship the pit package, right? The only
gotcha is you have to install your torch
gotcha is you have to install your torch
version, okay? Which is like standard if
version, okay? Which is like standard if
you need a different torch version. And
you need a different torch version. And
if you have a different torch version
if you have a different torch version
from the default, you have to install
from the default, you have to install
with no build isolation. Those are the
with no build isolation. Those are the
only
gotchas. Everything else I made to
work. Last version of Torchwood that
work. Last version of Torchwood that
shipped with x86
shipped with x86
compat.
compat.
Jeez. All right. There you go.
Enjoy having literal unsupported
hardware. Can't make the index URL a
hardware. Can't make the index URL a
build arg as far as I'm aware
build arg as far as I'm aware
because wait, can you make the index URL
because wait, can you make the index URL
a build arg?
Wait, first of all, one, can you make
Wait, first of all, one, can you make
can the user pass buildtime args? And
can the user pass buildtime args? And
then two, even if you can, why would I
then two, even if you can, why would I
then want to make you install with build
then want to make you install with build
isolation where it's just going to go
isolation where it's just going to go
spend twice as long downloading a second
spend twice as long downloading a second
copy of
torch d-build
argu.
Yes. Oh, to Docker. No, you're getting
Yes. Oh, to Docker. No, you're getting
this Docker file. You're just getting
this Docker file. You're just getting
shipped this freaking Docker. You're
shipped this freaking Docker. You're
just getting shipped the Docker image.
just getting shipped the Docker image.
You're not messing with the Docker file.
You're not messing with the Docker file.
I meant like if I'm going to because
I meant like if I'm going to because
there's going to be just a UV option as
there's going to be just a UV option as
well, right? Or just like a standard
well, right? Or just like a standard
like um a no container option.
like um a no container option.
So like you can't pass
So like you can't pass
args to setup.py build,
args to setup.py build,
right? Sucks. You have to use
right? Sucks. You have to use
divval. It's like a few
divval. It's like a few
gigs.
gigs.
Whatever. I'm not shipping kernel
Whatever. I'm not shipping kernel
binaries. I'm not doing it.
I've literally spent like a couple
I've literally spent like a couple
hundred hours fighting [ __ ] in this
hundred hours fighting [ __ ] in this
release. Like over the last few weeks
release. Like over the last few weeks
already, several weeks, I should
say. Yes.
So, when do
So, when do
we I mean, we can we can do this live.
we I mean, we can we can do this live.
Bet gets to
Bet gets to
[ __ ] Let's just blast Bet live on the
[ __ ] Let's just blast Bet live on the
freaking
Discord. You used an LLM
Discord. You used an LLM
to edit
to edit
critical infra. You
didn't
didn't
understand and broke
everything. If
everything. If
free a pointer
But
not whenever it
not whenever it
wants. I got to spend all
day figuring out why I had
day figuring out why I had
randomly
randomly
fragmented memory address space
seg Python. Nowhere I can even get a
seg Python. Nowhere I can even get a
stack
stack
trace
trace
because you had to
touch had to with it to do
this. And there's your get
blame. There you go.
So, thank you, Bet. I got to spend six
So, thank you, Bet. I got to spend six
[ __ ] hours debugging that because of
[ __ ] hours debugging that because of
your dumbass
your dumbass
today. Don't paste [ __ ] into an LLM when
today. Don't paste [ __ ] into an LLM when
it's critical info you don't understand.
I switch to Abuntu. Go to
I switch to Abuntu. Go to
apps. This is literally just default
apps. This is literally just default
Abuntu, man. This is default Abuntu with
Abuntu, man. This is default Abuntu with
like the background set to like a
like the background set to like a
specific puffer shade of
teal. I I just want you to understand
teal. I I just want you to understand
how [ __ ] hard this was to debug
how [ __ ] hard this was to debug
today.
today.
Okay, this is not solarized dark blue.
Okay, this is not solarized dark blue.
Oh, if you want the config for my code,
Oh, if you want the config for my code,
you can get that as well. That's on our
you can get that as well. That's on our
Docker page, but that's a little bit
Docker page, but that's a little bit
more out there. Let me just show you
more out there. Let me just show you
something bad. This is what I had to
something bad. This is what I had to
[ __ ] do all
day. Okay. And look, I can tell you used
day. Okay. And look, I can tell you used
an
an
LLM because the comments are like I can
LLM because the comments are like I can
tell because of the damn
comments. Okay. Like I can see like
comments. Okay. Like I can see like
there are like a bunch of these and
there are like a bunch of these and
there were like a couple others like
there were like a couple others like
this. We need to Yeah, this is total
this. We need to Yeah, this is total
LLM. So you have this and then what you
LLM. So you have this and then what you
were doing is you had this free up here.
were doing is you had this free up here.
Okay. So when you have this free up here
Okay. So when you have this free up here
inside of the for loop, it's going to
inside of the for loop, it's going to
free it a whole bunch of times, which
free it a whole bunch of times, which
means that randomly Python can just
means that randomly Python can just
decide whenever the hell it wants to
decide whenever the hell it wants to
free that pointer. And if it just so
free that pointer. And if it just so
happens to free that pointer right
happens to free that pointer right
before you go to use it, then you're
before you go to use it, then you're
[ __ ] because it fragments memory
[ __ ] because it fragments memory
space. And this thing would happen after
space. And this thing would happen after
like an average of 80 experiments. All
like an average of 80 experiments. All
right. So, it like it was a hugely
right. So, it like it was a hugely
intermittent bug and I suspect that this
intermittent bug and I suspect that this
bug was actually screwing up the other
bug was actually screwing up the other
contract work I had because we had a
contract work I had because we had a
random seg fault we couldn't reproduce
random seg fault we couldn't reproduce
there either. So, yeah, it's
there either. So, yeah, it's
like this
[ __ ] like let me show you the stack
[ __ ] like let me show you the stack
trace I got from
trace I got from
this. This is the stack trace you get.
this. This is the stack trace you get.
No, this doesn't come up in GDB or
No, this doesn't come up in GDB or
Mammandan even with all the work I did
Mammandan even with all the work I did
because guess what? This fragments
because guess what? This fragments
memory and then it's just going to error
memory and then it's just going to error
randomly somewhere else in Python. So
randomly somewhere else in Python. So
unless you compile all of Python with
unless you compile all of Python with
mem sanitizer, then maybe you could
mem sanitizer, then maybe you could
catch it. This is the stack trace I get.
catch it. This is the stack trace I get.
This is a stack trace that doesn't
This is a stack trace that doesn't
include anything in my entire codebase.
include anything in my entire codebase.
This is purely a Python stack trace that
This is purely a Python stack trace that
seg faults on a malik. Yeah, you can seg
seg faults on a malik. Yeah, you can seg
fault on a malak.
fault on a malak.
Not a reed, a malac.
Not a reed, a malac.
Great. So, what did I have to do was
Great. So, what did I have to do was
eventually I got lucky. I found a good
eventually I got lucky. I found a good
seed on which I could like reproduce
seed on which I could like reproduce
this thing in a reasonable amount of
this thing in a reasonable amount of
time. I had to not even add prints on
time. I had to not even add prints on
specific lines because that would screw
specific lines because that would screw
with memory space and cause it to
with memory space and cause it to
non-deterministically jump. I had to
non-deterministically jump. I had to
eventually debug it down to I got a
eventually debug it down to I got a
config where it would seg only calling
config where it would seg only calling
veanit, not calling the rest of the
veanit, not calling the rest of the
functions. So that narrowed it down to
functions. So that narrowed it down to
vechanit and then I had to go through
vechanit and then I had to go through
that like very very closely until
that like very very closely until
eventually I saw that the deck ref was
eventually I saw that the deck ref was
in the wrong
loop. God damn. This was the single
loop. God damn. This was the single
hardest bug I've had to fix in the last
hardest bug I've had to fix in the last
several months because of your [ __ ]
several months because of your [ __ ]
LL. Don't use it. Just don't. Not for
LL. Don't use it. Just don't. Not for
critical infrastructure.
And here I see like you open Twitch all
And here I see like you open Twitch all
day and you see this brain rot like
day and you see this brain rot like
hardy dirty dur. Let's see how long does
hardy dirty dur. Let's see how long does
it take to find an LLM's good post.
it take to find an LLM's good post.
Let's see. Uh let's see. Uh fine. I'm
Let's see. Uh let's see. Uh fine. I'm
guarantee you this is vibe coded. Let's
see. How long does it take to find a
see. How long does it take to find a
dumbass LLM post? Yeah, here's LLM
dumbass LLM post? Yeah, here's LLM
[ __ ] Where's more LLM [ __ ]
[ __ ] Where's more LLM [ __ ]
Oh, here's llm
[ __ ] Okay, I think I've muted a
[ __ ] Okay, I think I've muted a
hell of a lot of it on my timeline, but
hell of a lot of it on my timeline, but
there's a lot of LM [ __ ] LM solve
there's a lot of LM [ __ ] LM solve
everything except when they break your
everything except when they break your
entire [ __ ] code base.
So yeah, this
sucked. And the thing was originally
sucked. And the thing was originally
when I wrote the original version, I
when I wrote the original version, I
wrote it without deck refs. So, I wrote
wrote it without deck refs. So, I wrote
the thing just to leak a little bit of
the thing just to leak a little bit of
memory so that I wouldn't have to deal
memory so that I wouldn't have to deal
with Python's awful garbage collecting
with Python's awful garbage collecting
mechanics. All
right. Yeah, you wouldn't be able to fix
right. Yeah, you wouldn't be able to fix
this.
God, you need to not use LLMs to
God, you need to not use LLMs to
interact with complicated [ __ ] without
interact with complicated [ __ ] without
understanding it.
piraf
piraf
debug. No idea what that
debug. No idea what that
is. You got to realize I had to debug
is. You got to realize I had to debug
this. This is the first thing I've had
this. This is the first thing I've had
to do with the C API in Python. The endb
to do with the C API in Python. The endb
finding code is not great. It could be
finding code is not great. It could be
much better. This is V1 of the new ends.
That probably would have caught
it. How do I open this thing?
But the fact that this can cause a seg
But the fact that this can cause a seg
not with a stack trace that is not in
not with a stack trace that is not in
your code
sucks. Well, the thing is it had some
sucks. Well, the thing is it had some
stuff about ref counting, but it also
stuff about ref counting, but it also
generated like 10 pages of other
generated like 10 pages of other
garbage. So, uh, like of the rest of
garbage. So, uh, like of the rest of
which almost all was wrong. So, it's
which almost all was wrong. So, it's
like great. I could just give you the
like great. I could just give you the
program. The program also has the right
program. The program also has the right
information in there
somewhere. Also, here's a fun one. uh
somewhere. Also, here's a fun one. uh
loading
loading
in um setting LD preload flags to enable
in um setting LD preload flags to enable
debugging causes the process to take 20
debugging causes the process to take 20
terab of virtual address space. So
terab of virtual address space. So
that's a cool thing to find
out. Yeah, Gemini 25 Pro caused the bug.
All right. Well, I will use that in the
All right. Well, I will use that in the
future if I need to deck ref stuff.
But wait, if it ends at
zero, you could still Yeah, you can
zero, you could still Yeah, you can
still break
it. Oh,
it. Oh,
this
here. Why aren't you in here?
Hey,
Hey,
Weston. It was just a really [ __ ]
Weston. It was just a really [ __ ]
hard bug.
And oh, by the way, this stack trace,
And oh, by the way, this stack trace,
you don't even get this stack trace for
you don't even get this stack trace for
free. You have to compile, you have to
free. You have to compile, you have to
compile everything with super duper
compile everything with super duper
debug mode and set a bunch of symbols to
debug mode and set a bunch of symbols to
even get
this. All right.
this. All right.
At first, I just got hanging. And then
At first, I just got hanging. And then
eventually, I reproduced this bug in
eventually, I reproduced this bug in
serial mode with a seg fault after
serial mode with a seg fault after
running it for like, you know, 10
running it for like, you know, 10
minutes with a custom test script
minutes with a custom test script
intended to go really fast. And then I
intended to go really fast. And then I
tuned that a bunch and I got like
tuned that a bunch and I got like
intermittent issues with a bunch of
intermittent issues with a bunch of
different versions. And then eventually
different versions. And then eventually
I got like the jank thing where I like I
I got like the jank thing where I like I
got it to take fault at the same place,
got it to take fault at the same place,
but only with that seed and only if you
but only with that seed and only if you
didn't like put a print statement in the
didn't like put a print statement in the
wrong place that changed address space.
wrong place that changed address space.
Um, and then eventually like I got it to
Um, and then eventually like I got it to
like I got to strip out some additional
like I got to strip out some additional
functions and still get to seg fault.
functions and still get to seg fault.
Eventually I like you know bisected it
Eventually I like you know bisected it
down to the right
spot. So anything except this if you do
spot. So anything except this if you do
anything except what you did here you
anything except what you did here you
will actually get a stack trace out of
will actually get a stack trace out of
puffer in debug mode.
anything but the exact thing that you
anything but the exact thing that you
did
here. I'm pretty sure you can even
here. I'm pretty sure you can even
detect this in C. You can't detect it
detect this in C. You can't detect it
with Python's garbage collection. You
with Python's garbage collection. You
could even I think use after free you
could even I think use after free you
can even detect with the C uh C flags.
can even detect with the C uh C flags.
Just this specific thing. You found the
Just this specific thing. You found the
one thing I couldn't catch.
That's seep hanging
That's seep hanging
bug. What was the solution to that one?
Oh yeah, that was
ridiculous. What the hell? It's It's
ridiculous. What the hell? It's It's
like that there's some other function
like that there's some other function
like there's some core function called
like there's some core function called
step, right?
Can you not just object dump it? I don't
Can you not just object dump it? I don't
know how the hell you would find that
know how the hell you would find that
one deck
one deck
ref. Maybe there are additional debug
ref. Maybe there are additional debug
tools. The thing that guy said would
tools. The thing that guy said would
probably work, but like literally this
probably work, but like literally this
is the first piece of code I've had to
is the first piece of code I've had to
write with the Python C API. All right,
write with the Python C API. All right,
this is V1 of the end of binding. It's
this is V1 of the end of binding. It's
the least mature spot of like where we
the least mature spot of like where we
have debug stuff for and like know like
have debug stuff for and like know like
the least like the spot I least know how
the least like the spot I least know how
to fix stuff in the whole code
base. A real pain in the
base. A real pain in the
ass. All right. How are we doing
here? I mean, this doesn't seem to be
here? I mean, this doesn't seem to be
doing quite as
doing quite as
well as
before. Hard to
before. Hard to
say. We'll let this full run overnight,
say. We'll let this full run overnight,
though. We'll let this finish full
though. We'll let this finish full
running overnight.
running overnight.
So, the plan is to just run experiments,
So, the plan is to just run experiments,
probably work on some different
probably work on some different
environments. Um, I got to start doing
environments. Um, I got to start doing
like stuff for after 3 0
now. So, we're not going to insta
now. So, we're not going to insta
release 3, but I am going to start on
release 3, but I am going to start on
like the new sim work and all that
stuff. Exhausting.
This
is what's that going to do, Linky? It's
is what's that going to do, Linky? It's
like there's a deck ref in one spot and
like there's a deck ref in one spot and
then Python's garbage collector randomly
then Python's garbage collector randomly
frees the thing in another spot and then
frees the thing in another spot and then
in a third spot a me a a Malik fails
in a third spot a me a a Malik fails
because of it
somehow all
somehow all
um freaking randomly
It was a rough thing to
debug. All we got to do now though is
debug. All we got to do now though is
make sure that I didn't break um our
make sure that I didn't break um our
sweeps with any of the latest stuff.
Trying to think if I want to kill this
Trying to think if I want to kill this
and if I want to run
and if I want to run
um 10 10 subsample points instead.
I think
I think
so. Five is going to
faster. This is probably going to need a
faster. This is probably going to need a
revamp at some point anyways cuz it ends
revamp at some point anyways cuz it ends
up taking
up taking
like a couple minutes per
like a couple minutes per
um per suggestion.
full sweep should be done in like an
full sweep should be done in like an
hour or
two. But I think that the I think that
two. But I think that the I think that
this adds like double it doubles the
this adds like double it doubles the
time
basically. It is only really a problem
basically. It is only really a problem
for these tiny little experiments
for these tiny little experiments
though.
We'll leave it for
We'll leave it for
now. Can only do so much for no
release. I'll deal with meta as soon as
release. I'll deal with meta as soon as
they have stable version for
they have stable version for
me.
Um, a few other small things to do for
Um, a few other small things to do for
clients. I think we'll just start on
clients. I think we'll just start on
Terraform stuff. I think that'll be a
Terraform stuff. I think that'll be a
fun thing to do to start on terraform
fun thing to do to start on terraform
stuff. Be way better.
All right, I think I'm going to just go
All right, I think I'm going to just go
get some sleep
get some sleep
then. Get some rest. Start this thing
tomorrow. Yeah, then breakout will
tomorrow. Yeah, then breakout will
finish.
finish.
I'll
have Yeah, because I could write some
have Yeah, because I could write some
basic configs for the next experiments,
basic configs for the next experiments,
but I'm getting tired. So, I think I'm
but I'm getting tired. So, I think I'm
just going to call it for
just going to call it for
tonight. I think we're going to work on
tonight. I think we're going to work on
tomorrow the terraform again. So, it's
tomorrow the terraform again. So, it's
like this
like this
digging like move dirt from one place to
digging like move dirt from one place to
other terraform
other terraform
environment and work on that tomorrow
environment and work on that tomorrow
potentially. I want to write more C. I'm
potentially. I want to write more C. I'm
sick of debugging like
sick of debugging like
shitty annoying Python
shitty annoying Python
loops and build systems and all
loops and build systems and all
that. We'll do some sim sim side work.
that. We'll do some sim sim side work.
Maybe algorithms at some point soon as
Maybe algorithms at some point soon as
well, but also simside
well, but also simside
stuff.
stuff.
Okay. Um well, decent outcome for today
Okay. Um well, decent outcome for today
and that uh we actually did get that bug
and that uh we actually did get that bug
resolved.
folks
folks
watching all the things of
watching all the things of
Puffer.ai. It's all free and open
Puffer.ai. It's all free and open
source. Want to get into reinforcement
source. Want to get into reinforcement
learning? Good way to do
things. You will not get yelled at as
things. You will not get yelled at as
badly as BET did for making mistakes
badly as BET did for making mistakes
unless you make them because you just
unless you make them because you just
blindly copy paste from an
blindly copy paste from an
LLM. That's about the only pet peeve.
Um, yeah, start the repo on GitHub to
Um, yeah, start the repo on GitHub to
help me out a lot. Really
help me out a lot. Really
helps. Other than that, join Discord.
helps. Other than that, join Discord.
You can also follow me on X for more
You can also follow me on X for more
content where I occasionally post things
content where I occasionally post things
and I try not to read X too much because
and I try not to read X too much because
it's way better when you just write
it's way better when you just write
stuff and don't read
stuff and don't read
it. Now, the only good thing about this
it. Now, the only good thing about this
stupid
website is that occasionally uh where is
website is that occasionally uh where is
it? Can I even scroll and find
it? Can I even scroll and find
one? Where is
one? Where is
he? Oh, yeah. Look. Sometimes there's
he? Oh, yeah. Look. Sometimes there's
fun stuff like look at the
manatees. That's
funny. All right. Good night.
