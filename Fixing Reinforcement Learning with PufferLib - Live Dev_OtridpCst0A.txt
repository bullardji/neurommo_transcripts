Kind: captions
Language: en
okay we are
okay we are
live
cool
man
man
yeah right we have things to
yeah right we have things to
do many things to do
F
GitHub let's see
one second
one second
folks we do
this for
okay we are set over
there silly somebody wanted to do a
there silly somebody wanted to do a
poker agent
all
all
right
uhoh e
I want to work on I pram sweeps
cool we get back on stream we do this uh
cool we get back on stream we do this uh
not
not
this
this
blinding hyperr
blinding hyperr
stuff want to focus up on this a little
bit this
is going to take a little bit of
is going to take a little bit of
thought maybe not necessarily too much
thought so I've got this test gelian
thought so I've got this test gelian
process thingy
this is just a throwaway
this is just a throwaway
script and the only thing I really want
script and the only thing I really want
to figure out today is what the hell is
to figure out today is what the hell is
wrong with Gan process variance all
wrong with Gan process variance all
right that's all I want to figure
right that's all I want to figure
out so
um let's just do
um let's just do
this um
score equal for.
Rand oops
what's the freaking torch
random torch Rand
duh all
right
50 um
50 um
let's
let's
see
OBS and then we
do we do some stuff so we have
do we do some stuff so we have
this we got the error
this we got the error
we don't need
this nope there's no
this nope there's no
token the one that's using my name is by
token the one that's using my name is by
somebody stealing my name that is a scam
okay how obvious can you
okay how obvious can you
be no you can't just join this stream
be no you can't just join this stream
with multiple accounts at the exact same
with multiple accounts at the exact same
time and expect me to believe this is
time and expect me to believe this is
real
bye-bye stupid
no
way e
Christ man do you have enough accounts
Christ man do you have enough accounts
holy hell do you have nothing better to
holy hell do you have nothing better to
do leave me
alone
no for
hey we don't really need this Beast do
we hey very low
error very low
variance for
oh that actually worked
oh that actually worked
better so whatever happened before was
weird yeah
okay for
know why tries to keep adding this 10
along the lines of alpha go
along the lines of alpha go
zero I built
zero I built
a Monte Carlo Tre search algorithm and
a Monte Carlo Tre search algorithm and
in testing perf for some simple games
in testing perf for some simple games
with a euristic
with a euristic
function I assume this is from
function I assume this is from
uh the Discord messages
uh the Discord messages
before does puffer have a selfplay
before does puffer have a selfplay
transcript to train One agent while it's
transcript to train One agent while it's
opponent
opponent
uses a fixed
uses a fixed
policy so I think you could just pretty
policy so I think you could just pretty
darn easily
like yeah you could very easily do that
like yeah you could very easily do that
um does it have like a module for it no
um does it have like a module for it no
but I think you could do it in like 10
but I think you could do it in like 10
lines of code change so this is what you
lines of code change so this is what you
would do yeah okay my bad I'm a bit on
would do yeah okay my bad I'm a bit on
edge because I've been getting brigaded
edge because I've been getting brigaded
by like crypto nerds on my stream I just
by like crypto nerds on my stream I just
banned three
banned three
accounts
accounts
um I for a second I thought you were
um I for a second I thought you were
another one but more good um
another one but more good um
so this is what you would
so this is what you would
do let me find
it okay so there's this thing called
it okay so there's this thing called
masks in the
masks in the
environment um if you pass something to
environment um if you pass something to
masks uh it doesn't get used in training
masks uh it doesn't get used in training
so if you set the mask one on a specific
so if you set the mask one on a specific
agent it doesn't get used in training so
agent it doesn't get used in training so
for like a two agent environment if you
for like a two agent environment if you
have a bunch of copies you just set like
have a bunch of copies you just set like
every other one of these to one or to
every other one of these to one or to
true or
true or
whatever um false I think masks it out
whatever um false I think masks it out
yeah so You' set every other one of
yeah so You' set every other one of
these to false to mask out half of the
these to false to mask out half of the
policies and then all you would
policies and then all you would
do is inside of um clean puff
out which is right
here okay all you would do is you would
here okay all you would do is you would
take the
take the
observation and uh you would you would
observation and uh you would you would
just reshape it you know you would just
just reshape it you know you would just
split it every other one or fancy index
split it every other one or fancy index
it so you take every other one and you'd
it so you take every other one and you'd
use one policy for one and one policy
use one policy for one and one policy
for the other right so you take your
for the other right so you take your
fancy indices actions of odd actions of
fancy indices actions of odd actions of
odd log prob of odd whatever value of
odd log prob of odd whatever value of
odd equals policy zero of O divice of
odd equals policy zero of O divice of
odd and then actions of even log prop of
odd and then actions of even log prop of
even you know you get the point that
even you know you get the point that
would be the like few line quick way of
would be the like few line quick way of
doing it it would still be pretty darn
doing it it would still be pretty darn
fast um it would work just natively with
fast um it would work just natively with
training and it would let you use a
training and it would let you use a
fixed neuronet policy accelerated by
fixed neuronet policy accelerated by
puffer
lip it requires you change a couple
lip it requires you change a couple
little things custom but hey every other
little things custom but hey every other
library that supports this or like can
library that supports this or like can
support this uh has way way way heavier
support this uh has way way way heavier
and slow stuff usually
and slow stuff usually
so I think that's a pretty easy way to
so I think that's a pretty easy way to
get it working
actually you know I want to do something
actually you know I want to do something
a little better than this
yeah yeah let's do something a little
yeah yeah let's do something a little
better than
this e
look at
look at
this we got a speed up from 2,000 to
this we got a speed up from 2,000 to
450,000 steps per second
so nice to see that though look just
so nice to see that though look just
right out of the box they mess with
right out of the box they mess with
puffer for a few
puffer for a few
days and they get 200 xped
up
e e
would you recommend creating two agents
would you recommend creating two agents
which train against each other or only
which train against each other or only
train one and have the rest be fixed
train one and have the rest be fixed
previous iterations of itself oo
um if you want to start with the most
um if you want to start with the most
basic version of historical selfplay
basic version of historical selfplay
which doesn't have sampling or anything
which doesn't have sampling or anything
and maybe is enough to bootstrap off the
and maybe is enough to bootstrap off the
ground um what I would probably start
with I would just have one opponent and
with I would just have one opponent and
um I would basically whenever you get
um I would basically whenever you get
above a certain win rate above against
above a certain win rate above against
that opponent I would replace the
that opponent I would replace the
opponent with the current
opponent with the current
checkpoint and then you should be able
checkpoint and then you should be able
to very easily verify whether this is
to very easily verify whether this is
working
working
because your train curve should start
because your train curve should start
off at 50% if it's random policy versus
off at 50% if it's random policy versus
random policy and then it goes up to
random policy and then it goes up to
let's say 80% win rate is your threshold
let's say 80% win rate is your threshold
right and then it drops immediately to
right and then it drops immediately to
50 because you again you're playing
50 because you again you're playing
against yourself and then it goes back
against yourself and then it goes back
up to 80 so you should get the saw too
up to 80 so you should get the saw too
kind of a
curve e
thank you yeah no worries
anytime let me know how that goes as
anytime let me know how that goes as
well and if you end up making you know a
well and if you end up making you know a
fast M code to go with this stuff we are
fast M code to go with this stuff we are
very happy to have this stuff in puffer
very happy to have this stuff in puffer
and I don't know your engineering
and I don't know your engineering
background but if you haven't seen like
background but if you haven't seen like
CMS like ours before they're very very
CMS like ours before they're very very
easy to write I say this to somebody who
easy to write I say this to somebody who
wrote python for 10 years
we've got brand new devs writing these
we've got brand new devs writing these
environments at a million steps a
second e
we just want this right test PR
we just want this right test PR
minus obs
ums
where is
where is
it test
GPM why
I don't think I posted anything I uh my
I don't think I posted anything I uh my
ex and socials and stuff are very
ex and socials and stuff are very
intentionally apolitical except for
intentionally apolitical except for
Stuff specifically concerned with AI so
Stuff specifically concerned with AI so
I will comment on AI legislation and
I will comment on AI legislation and
things that pertain AI but that is
it I don't think I made any post to the
it I don't think I made any post to the
contrary did I
contrary did I
I don't think
so no I made one comment to the CEO of
so no I made one comment to the CEO of
Razer that was a game
Razer that was a game
meme that's it
something screwy here
yeah I'm not going to comment on
yeah I'm not going to comment on
political stuff outside of
political stuff outside of
um outside of
um outside of
AI that's been my policy for
AI that's been my policy for
years at least not on
years at least not on
um stream or you know socials or
anything I'm not here to tell you about
anything I'm not here to tell you about
politics I'm here
politics I'm here
to I mean my content is purely on
to I mean my content is purely on
reinforcement learning in the science in
reinforcement learning in the science in
the engineering
this
this
work this one is spot on right
wait
synthetic work on project that use RL
synthetic work on project that use RL
for process automation so yeah I'm here
for process automation so yeah I'm here
for it yeah and that sounds awesome
for it yeah and that sounds awesome
right the idea with with puffer is that
right the idea with with puffer is that
um we're going to start off right like
um we're going to start off right like
most of the companies and stuff that
most of the companies and stuff that
we're going to be working with starting
we're going to be working with starting
off it's going to be applications where
off it's going to be applications where
people have a clear-cut RL problem and
people have a clear-cut RL problem and
are just having a hard time with it
are just having a hard time with it
something where we can build a fast Sim
something where we can build a fast Sim
you know we can easily help with stuff
you know we can easily help with stuff
or else just hard and finicky we make it
or else just hard and finicky we make it
easier but as we build out better stuff
easier but as we build out better stuff
with puffer harder problems across
with puffer harder problems across
Automation in various Industries
Automation in various Industries
especially manufacturing and the like um
especially manufacturing and the like um
industrial processes really just various
industrial processes really just various
industrial processes are going to be uh
industrial processes are going to be uh
definitely targets for RL and God damn
definitely targets for RL and God damn
it this
it this
freaking not Julia
freaking not Julia
discussion again
sick of the damn programming language
sick of the damn programming language
discussion in the freaking Discord
[Laughter]
freaking
freaking
ridiculous we're here for RL come on
ridiculous we're here for RL come on
okay this is this is hyper parameter
okay this is this is hyper parameter
tuning hour so I I guess I should have
tuning hour so I I guess I should have
probably explain to what it is I'm doing
probably explain to what it is I'm doing
um while Discord is not distracting
um while Discord is not distracting
me um
me um
clean RL PPO no clean puff RL clean puff
clean RL PPO no clean puff RL clean puff
RL is the cleaned up one that's super
RL is the cleaned up one that's super
fast handle opponents making moves they
fast handle opponents making moves they
don't that's the thing you set the mask
don't that's the thing you set the mask
to false every other one every other
to false every other one every other
mask you set to false and that data will
mask you set to false and that data will
go through the forward path but it won't
go through the forward path but it won't
go through the backward
path you
path you
see yeah you're looking at the wrong
see yeah you're looking at the wrong
script is why
here so
write find
it yeah so right here this is stored and
it yeah so right here this is stored and
it's stored using the mask you see and
it's stored using the mask you see and
then when we
store we only store stuff where the mask
store we only store stuff where the mask
is true so if you set the mask to false
is true so if you set the mask to false
every other one it'll just be gone and
every other one it'll just be gone and
then all you have to do is use the fancy
then all you have to do is use the fancy
indexing in that forward path so you
indexing in that forward path so you
literally have like three lines of code
literally have like three lines of code
to change and you're good to go you just
to change and you're good to go you just
have to remember to set the
masks so if we focus on YouTube because
masks so if we focus on YouTube because
we've got six people watching now there
we've got six people watching now there
uh what I'm going to be trying to do for
uh what I'm going to be trying to do for
the next hour hour and a half until I
the next hour hour and a half until I
get tired uh I'm just testing out some
get tired uh I'm just testing out some
gaan process stuff because we have this
gaan process stuff because we have this
really snazzy hyperparameter tuning
really snazzy hyperparameter tuning
algorithm which I am very proud of it uh
algorithm which I am very proud of it uh
it gets some very good samples it's like
it gets some very good samples it's like
a very nice sampling distribution but
a very nice sampling distribution but
it's very dependent on the accuracy of
it's very dependent on the accuracy of
the internal gussian processes for
the internal gussian processes for
modeling which points to select and
modeling which points to select and
right now they're very high variance and
right now they're very high variance and
they're very overconfident so I'm trying
they're very overconfident so I'm trying
to figure out what's up with the Gan
to figure out what's up with the Gan
processes here just by doing some
processes here just by doing some
synthetic tests to evaluate where gum
synthetic tests to evaluate where gum
processes are Act accurate how accuracy
processes are Act accurate how accuracy
falls off over time as you get farther
falls off over time as you get farther
away from the points in the data set and
away from the points in the data set and
so on sub on YouTube fair enough welcome
so on sub on YouTube fair enough welcome
back
I'm just weird with this error thing
I'm just weird with this error thing
right test
error yeah for Insomniac I do stuff like
error yeah for Insomniac I do stuff like
this where I think that hyper pram
this where I think that hyper pram
tuning is one of the highest leverage
tuning is one of the highest leverage
things in RL right now because they're
things in RL right now because they're
so finicky and if you can just make if
so finicky and if you can just make if
you can make it so that if you run a 100
you can make it so that if you run a 100
experiment sweep you are just absolutely
experiment sweep you are just absolutely
confident that you have good hypers and
confident that you have good hypers and
anything that's wrong with your
anything that's wrong with your
experiment it's not hypers and if it
experiment it's not hypers and if it
works it'll get the best hypers like
works it'll get the best hypers like
it's going to make all of ourl feel so
it's going to make all of ourl feel so
much more polished and
consistent oh look at
consistent oh look at
this keep getting distracted here with
this keep getting distracted here with
other RL things but uh user wants
other RL things but uh user wants
assistance I am on stream to
assistance I am on stream to
assist particularly for folks that are
assist particularly for folks that are
open sourcing stuff and writing M for
open sourcing stuff and writing M for
Puffer
too many variables in
cstep let's say C
cstep let's say C
reset RN d
f ah Ray cast okay how many
Rays eight that's not
Rays eight that's not
bad eight Ray casts is
fine up
I'm kind of surprised if this is
I'm kind of surprised if this is
slow let me say if where are your Loops
slow let me say if where are your Loops
man there should be slow
things I wonder if they're just
things I wonder if they're just
profiling it wrong let me see
doesn't look like
it e
450k with training well why didn't you
450k with training well why didn't you
say
say
so my
guy wait with training well what's the M
guy wait with training well what's the M
don't you have an M
don't you have an M
profiler you have an M profiler
profiler you have an M profiler
right right here
did you run
this this font is way too
gigantic I'm going to say that looked
gigantic I'm going to say that looked
like it should be faster than that
uh
drone I'll run this real quick as well
we
compile
what oh
that's kind of
silly e
how the hell did I manage to break this
the funny thing about this is this
the funny thing about this is this
should be literally impossible because
should be literally impossible because
it's
it's
not it's uh everything statically
linked e
dude what the hell is
this does this run for
this does this run for
you okay good cuz I messed around with
you okay good cuz I messed around with
some stuff earlier and I must have
some stuff earlier and I must have
broken some things locally and I am too
broken some things locally and I am too
tired to fix this at the moment I want
tired to fix this at the moment I want
to just do my gum process stuff and go
to just do my gum process stuff and go
to bed 7 million FPS very nice um so in
to bed 7 million FPS very nice um so in
that case I will fix your model or
that case I will fix your model or
whatever real quick and then I will
whatever real quick and then I will
sleep uh not sleep I'll do this and go
sleep uh not sleep I'll do this and go
to sleep um what is what's your graphics
card they model on this
default oh well that's
default oh well that's
why it's actually that's kind of
why it's actually that's kind of
impressive that this gets
impressive that this gets
um 450,000 on
um 450,000 on
CPU it's only going to be training on
CPU it's only going to be training on
one4 of
that maybe we should well the thing is
that maybe we should well the thing is
you're probably running a tiny little
you're probably running a tiny little
model if it's just default
policy you could add the um the lstm
policy you could add the um the lstm
wrapper into this recurrent or whatever
wrapper into this recurrent or whatever
here it'll train slower you need a GPU
here it'll train slower you need a GPU
to train properly if you need help
to train properly if you need help
running some sweeps I can probably do
running some sweeps I can probably do
that for you we have 409s with
puffer
um are you running it with
um are you running it with
multiprocessing
multiprocessing
no well that's weird because because um
no well that's weird because because um
our M here this only uses One Core with
our M here this only uses One Core with
Native VEC uh so I don't know what P
Native VEC uh so I don't know what P
torch is doing maybe P torch CPU knows
torch is doing maybe P torch CPU knows
how to multi core or whatever I don't
how to multi core or whatever I don't
know but 450k on that yeah that's pretty
know but 450k on that yeah that's pretty
good in that case uh with a small policy
good in that case uh with a small policy
like this typically we can go above a
like this typically we can go above a
million on a
4090 all right
4090 all right
I will answer whatever additional
I will answer whatever additional
questions but there you go your M is so
questions but there you go your M is so
fast that you don't even need to worry
fast that you don't even need to worry
about multiprocessing it when you're at
about multiprocessing it when you're at
7 million when you start getting close
7 million when you start getting close
to like a million or below then that's
to like a million or below then that's
when you start thinking about
when you start thinking about
multiprocessing it well 7 million is
multiprocessing it well 7 million is
just fast
just fast
enough that you don't have to care about
enough that you don't have to care about
anything
oh reward scheme um hold
on analyze it for hitting a wall
I don't know what this galing
is
is
closest yeah I don't know what this
closest yeah I don't know what this
scaling is here
I don't like this continuous
I don't like this continuous
reward yeah I don't like this continuous
reward yeah I don't like this continuous
reward scheme I would just give it a
reward scheme I would just give it a
flat negative .5 on the step that it
flat negative .5 on the step that it
runs into
runs into
something and call it a day like
something and call it a day like
negative. five or something for running
negative. five or something for running
into an
into an
obstacle scaling is from a p
obstacle scaling is from a p
really okay I would still as a b line I
really okay I would still as a b line I
would see if you do better just giving
would see if you do better just giving
it5 on the step it collides cuz I don't
it5 on the step it collides cuz I don't
know how many times this gets applied
know how many times this gets applied
right this could get applied repeatedly
right this could get applied repeatedly
a whole
bunch you should be able to learn to fly
bunch you should be able to learn to fly
around pretty
around pretty
easily you also um do you guys have one
easily you also um do you guys have one
B set up or Neptune or one of
B set up or Neptune or one of
those are you getting logs from this
those are you getting logs from this
thing yet
you should be getting
logs cuz I want to see your
logs cuz I want to see your
losses because like look at your hyper
losses because like look at your hyper
parameters all right you've got a batch
parameters all right you've got a batch
size of
size of
260k a mini batch size of
260k a mini batch size of
so division is hard at this
so division is hard at this
to oh link wab be if you
can h
these are cool
looking if you have one you can link it
looking if you have one you can link it
real quick I can just take a quick look
real quick I can just take a quick look
at your losses and save you some time
at your losses and save you some time
before I go back to my other
stuff I suspect this batch size with
stuff I suspect this batch size with
this mini batch SI and these Epoch is
this mini batch SI and these Epoch is
horribly unstable
horribly unstable
and that's what's getting
and that's what's getting
you also these lambdas and gamas are
you also these lambdas and gamas are
insane I don't know where you got them
insane I don't know where you got them
from actually most of these hyper
from actually most of these hyper
parameters are utterly
insane where did you get these
do I link if it's a public WB you just
do I link if it's a public WB you just
link the uh the wandb like dashboard
link the uh the wandb like dashboard
link if it's not public then you can
link if it's not public then you can
either make it public or
either make it public or
whatever yeah you swept to much stuff is
whatever yeah you swept to much stuff is
what
happened I can show you I I will I will
happened I can show you I I will I will
fix this for you real quick if I have
fix this for you real quick if I have
the link so I can show it to
the link so I can show it to
you or just the losses screenshot I
you or just the losses screenshot I
guess
gotcha I'll let you do that so I don't
gotcha I'll let you do that so I don't
talk at the same time and confuse you
talk at the same time and confuse you
I'll just look at my stuff in a in the
I'll just look at my stuff in a in the
meanwhile for a second
[Music]
St
very weird
test OBS test PR
why is this so
high oh stupid okay
hi brother new here what's happening a
hi brother new here what's happening a
few things at the moment I'm working on
few things at the moment I'm working on
a hyper param some testing for a
a hyper param some testing for a
hyperparameter sweep algorithm for
hyperparameter sweep algorithm for
reinforcement learning this is all like
reinforcement learning this is all like
reinforcement learning Dev and I'm also
reinforcement learning Dev and I'm also
waiting for a user of our library to
waiting for a user of our library to
post a uh some links to some experiments
post a uh some links to some experiments
so I can do a little bit of quick
so I can do a little bit of quick
analysis for them get them on the right
track
track
car see if this is fixed yes so this is
car see if this is fixed yes so this is
now fixed
now fixed
perfect
um yeah this is the exact graph that we
um yeah this is the exact graph that we
would
like oh here we go
like oh here we go
fix my
fix my
graph and now I have some experiments to
graph and now I have some experiments to
look
look
at all right so for folks watching who
at all right so for folks watching who
are new to
are new to
RL this is probably when you'd want to
RL this is probably when you'd want to
tab back in because this is likely to be
tab back in because this is likely to be
very informative for
very informative for
you uh we're going to go look at two
you uh we're going to go look at two
different
different
things and this is going to look a
things and this is going to look a
little silly but now this is of course
little silly but now this is of course
you're going to
you're going to
not know this it's a
newcomer everyone literally everyone
newcomer everyone literally everyone
makes this
mistake I'm going to look real stupid if
mistake I'm going to look real stupid if
it's not this and the losses but I'm
it's not this and the losses but I'm
pretty confident it will
pretty confident it will
be yeah
so and we need to change the axis as
so and we need to change the axis as
well
they always change they change their UI
they always change they change their UI
man so I can't see
the
the
xais there it
is okay so 100 million
is okay so 100 million
uh whatever this is it was added later I
guess okay we've got uh exploding
guess okay we've got uh exploding
entropy
entropy
here we have
got weird policy dip and
got weird policy dip and
then this actually surprisingly doesn't
then this actually surprisingly doesn't
look too bad but the value loss here is
look too bad but the value loss here is
unstable you can see this and here as
unstable you can see this and here as
well
huh I actually wouldn't blame you for
huh I actually wouldn't blame you for
missing this except for the entropy the
missing this except for the entropy the
entropy one's pretty obvious but
entropy one's pretty obvious but
otherwise I wouldn't blame you for
otherwise I wouldn't blame you for
missing this here because uh it's not as
missing this here because uh it's not as
obvious on the graphs but I can tell you
obvious on the graphs but I can tell you
from the hyper parameters
from the hyper parameters
so you don't want to sweep all of this
so you don't want to sweep all of this
um if you sweep
um if you sweep
grad Max grad
grad Max grad
Norm uh value function coefficient and
Norm uh value function coefficient and
you didn't sweep the clip coefficient so
you didn't sweep the clip coefficient so
it's kind of interesting that it still
it's kind of interesting that it still
did
this one thing that happens that's kind
this one thing that happens that's kind
of weird is it'll lower the value
of weird is it'll lower the value
function coefficient a lot so that's why
function coefficient a lot so that's why
the value function is exploding it's not
the value function is exploding it's not
training the value function and um it'll
training the value function and um it'll
produce these like weird on ril runs
produce these like weird on ril runs
where you can get pretty decent
where you can get pretty decent
performance for a while but then the run
performance for a while but then the run
just collapses
just collapses
catastrophically so what I generally
catastrophically so what I generally
suggest for people is unless you really
suggest for people is unless you really
have a good
have a good
reason don't tune value function
reason don't tune value function
coefficient don't tune Max grad norm and
coefficient don't tune Max grad norm and
don't tune tune any of the clip
don't tune tune any of the clip
coefficients you can tune the rest of
coefficients you can tune the rest of
them you should probably also
them you should probably also
limit this mini batch size is crazy
limit this mini batch size is crazy
um you have a a ridiculous ratio here so
um you have a a ridiculous ratio here so
whatever this divided by this is is too
whatever this divided by this is is too
big this is like 50 or something 64
big this is like 50 or something 64
probably yeah this is too big and then
probably yeah this is too big and then
you multiply by update Epoch and you're
you multiply by update Epoch and you're
doing like 100 some odd updates uh on
doing like 100 some odd updates uh on
stale data now why would you do that you
stale data now why would you do that you
have a really fast environment right you
have a really fast environment right you
have unlimited brand new fresh data so
have unlimited brand new fresh data so
use your unlimited brand new fresh data
use your unlimited brand new fresh data
you can leave this like this if you want
you can leave this like this if you want
want so it's like very big batches but
want so it's like very big batches but
then this is going to have to go to like
then this is going to have to go to like
32k and then update EPO we'll see if
32k and then update EPO we'll see if
this needs to be three I'd be surprised
this needs to be three I'd be surprised
it's probably going to end up at one or
it's probably going to end up at one or
two um let's see what else uh Lambda and
two um let's see what else uh Lambda and
Gamma are just insane these are set for
Gamma are just insane these are set for
like twostep Horizon problems this is
like twostep Horizon problems this is
like what you would expect for a
like what you would expect for a
multi-armed bandit or something
multi-armed bandit or something
ridiculous so whatever gave you this is
ridiculous so whatever gave you this is
insane
insane
and yeah this is what'll happen when
and yeah this is what'll happen when
your hyper parameters get into wonky
your hyper parameters get into wonky
unstable
regime that probably would have been
regime that probably would have been
more eloquent in the morning rather than
more eloquent in the morning rather than
at 8:00 p.m. after I've been doing stuff
at 8:00 p.m. after I've been doing stuff
all day
all day
but that should
but that should
be sufficient quantities of RL
be sufficient quantities of RL
insights to get you on the right track
insights to get you on the right track
here I bet this one's pretty bad in
here I bet this one's pretty bad in
terms of the hypers
right H this is this run yeah 27 value
right H this is this run yeah 27 value
function that's why the value function
function that's why the value function
was exploding
also render your agents so you can
also render your agents so you can
actually see what they're
actually see what they're
doing it's other good thing you want to
doing it's other good thing you want to
be
doing okay we'll answer whatever
doing okay we'll answer whatever
follow-ups on that but that should
follow-ups on that but that should
be that should be what you need to get
be that should be what you need to get
on the right track
here sweep goddess weird hypers what did
here sweep goddess weird hypers what did
you
run what did you run this with cuz this
run what did you run this with cuz this
isn't a
isn't a
sweep like a Wy sweep
yeah those are some crazy hypers
it's good to learn to know the like the
it's good to learn to know the like the
interpretation of of the hyper
parameters we can render we use drone.
parameters we can render we use drone.
Pi very
Pi very
good yes so watch them we didn't
sweep that one should work just a random
sweep that one should work just a random
search so it's not a great sweep
the carbs demo in there should be decent
the carbs demo in there should be decent
as well but
as well but
um the problem isn't the sweep algorithm
um the problem isn't the sweep algorithm
in your case the problem is the um is
in your case the problem is the um is
sweeping too many parameters so I don't
sweeping too many parameters so I don't
know what's in the base sweep config on
know what's in the base sweep config on
the main branch but take out you know
the main branch but take out you know
all the Redundant stuff really the most
all the Redundant stuff really the most
important parameters you can just even
important parameters you can just even
set a man like manually you could set
set a man like manually you could set
this to be 130 or 260 and just set the
this to be 130 or 260 and just set the
um mini batch size to 32k and you'll
um mini batch size to 32k and you'll
probably find some decent parameters
probably find some decent parameters
just sweeping learning rate entropy
just sweeping learning rate entropy
Lambda and
Lambda and
Gamma you'll probably find some decent
Gamma you'll probably find some decent
parameters in
there as for better hyper parameter
there as for better hyper parameter
sweeps it's coming we're going to have
sweeps it's coming we're going to have
the best hyper param sweeps in the
the best hyper param sweeps in the
business once I finish this
and once I figure out insane giian
and once I figure out insane giian
process
things of course always happy to
help back for status update tomorrow
help back for status update tomorrow
very
good yeah I'm particularly always happy
good yeah I'm particularly always happy
to help um you know academic people uh
to help um you know academic people uh
who are like contributing know
who are like contributing know
environment code and stuff I'm very
environment code and stuff I'm very
happy to help with
happy to help with
that pretty much the only thing that I
that pretty much the only thing that I
won't help with is when um
won't help with is when um
you know like substantial size companies
you know like substantial size companies
are demanding uh large amounts of
are demanding uh large amounts of
support help for free that's the only
support help for free that's the only
time where it's like okay guys you
time where it's like okay guys you
should get a priority service contract
should get a priority service contract
um pretty much everyone else it's like
um pretty much everyone else it's like
yeah we're
good
e e
why is the error in this specific
why is the error in this specific
Direction I
wonder test
prediction minus test op so it
undershoots why don't I just put
undershoots why don't I just put
in test
in test
observation and test
observation and test
prediction all right we know it should
prediction all right we know it should
be a
line what
[Music]
something weird
here oops
[Music]
why did test error work
before the access toay off
yeah know this doesn't make any freaking
yeah know this doesn't make any freaking
sense this test error is like
sense this test error is like
this x
scores
scores
right no this doesn't make sense so
right no this doesn't make sense so
unless I'm being particularly stupid
okay so this is
okay so this is
there
there
red test
red test
Ops red my
test okay
first of all it should be test OBS minus
first of all it should be test OBS minus
test
test
sprad be the way to go
here that just flips it
this doesn't make much sense oh unless
this doesn't make much sense oh unless
the axes were off hold on
yep the axes are
off you can see that the slope is wrong
off you can see that the slope is wrong
here
right so in this regime right this is
right so in this regime right this is
perfect and then the predictions are
perfect and then the predictions are
totally wrong over here
CU it should continue this way and it
CU it should continue this way and it
Slants off this
Slants off this
way it's a very weird error pattern that
way it's a very weird error pattern that
it's like this perfectly consistent
it's like this perfectly consistent
predictor on the wrong
line
okay let's see the standard
deviation well if anything this is Harsh
deviation well if anything this is Harsh
right says it knows that it's wrong
so already by cost two they've got an
so already by cost two they've got an
error of one factored
in
right we can do
air okay so here's your variance
and here's your
error so by two it's got a one factored
in and the error is only 0
five error goes up to four
I mean we're happy with that
I mean this is the pattern
what if we do this
H the error suddenly gets
better and if we look at the
better and if we look at the
predictions are the predictions good
oh yeah the predictions are solid look
oh yeah the predictions are solid look
at that now the thing is there's a
at that now the thing is there's a
linear kernel in here
linear kernel in here
right so we're going to have to do
right so we're going to have to do
a let's make this a little harder
right x equals
right x equals
Rand
Rand
5050 y
5050 y
equals
equals
uh log of
x
one
for e
X that's
y e
does this
work what we're going to try to do is
work what we're going to try to do is
we're going to
we're going to
fit the we're going to fit this to a log
fit the we're going to fit this to a log
distribution and we're going to watch
distribution and we're going to watch
the error and we're see we're going to
the error and we're see we're going to
see if we can figure out any issues with
see if we can figure out any issues with
the error pattern of gussian processes
the error pattern of gussian processes
which is going to be important for this
which is going to be important for this
hyper parameter sweep getting kind of
hyper parameter sweep getting kind of
tired so brain not fully working but uh
tired so brain not fully working but uh
you know it's going to well we'll get
you know it's going to well we'll get
there I mean yeah we'll get
there I mean yeah we'll get
there
um I'd like to at least have something
um I'd like to at least have something
to show here before I go to
to show here before I go to
sleep okay cool
so test prediction
we'll just do test
y s y
y s y
= s y
= s y
and then because python doesn't care
and then because python doesn't care
where you define
things p.
scatter
scatter
purple
purple
guess Secret
okay and then we just do
this see if this does
it doesn't like that
it doesn't like that
I just want to put them on the same
I just want to put them on the same
graph come on
graph come on
man why do all plotting libraries just
man why do all plotting libraries just
why are they all
pain I think it's y equals test y
pain I think it's y equals test y
right yeah silly me all right that's on
me columns must be the same length
me columns must be the same length
this is xal test
this is xal test
X add this in like
X add this in like
this come
on come on how's this not handled yet
eror columns data source must be Oh
eror columns data source must be Oh
serious
play okay
play okay
fine uh
oh this plot's going to be
useful hey there we go
what
oh
silly okay um somehow that's perfect
silly okay um somehow that's perfect
right
oh wait no it's perfect
because yeah we're silly we're just very
silly can't be perfect perfect that
silly can't be perfect perfect that
would be
ridiculous yay there we
go n there's no way it's that bad
go n there's no way it's that bad
right we should plot the um
right we should plot the um
the true data on the bottom I would
say so we plot this
first so can we see from here yeah they
first so can we see from here yeah they
overlap look you see
overlap look you see
this they overlap perfectly within the
support you see the purple mixed in
support you see the purple mixed in
and then right around here they break
away and they break away in like a weird
away and they break away in like a weird
catastrophic way as
well what happens if we do
well what happens if we do
this I'm hoping here this doesn't just
this I'm hoping here this doesn't just
immediately fix well I'm not hoping I
immediately fix well I'm not hoping I
expect it's not going to immediately fix
expect it's not going to immediately fix
yeah so this makes it more linear you
yeah so this makes it more linear you
see this when you put 10 in it just
see this when you put 10 in it just
makes your prediction a
line and then we can try
line and then we can try
0.1 which means the matern kernel takes
over and you still get this fit actually
over and you still get this fit actually
with the mat return kernel up to here
with the mat return kernel up to here
but then the kernel does this
but then the kernel does this
somehow so neither of these kernels is
somehow so neither of these kernels is
going to save you essentially
so we may as well go with the
default that's kind of useless isn't it
all right let's do another
all right let's do another
Experiment 2 * Rand
100 now you have more data can you
100 now you have more data can you
fit no you get the exact same pattern
fit no you get the exact same pattern
Right double the data
double the data
here Al so why is the coloration so
weird that's weird but
weird that's weird but
whatever so you double the data you get
whatever so you double the data you get
the exact same error pattern this thing
the exact same error pattern this thing
will not learn no matter how much data
will not learn no matter how much data
you throw at
it that's kind of bad
okay what if we
do do we have to scale all the data is
do do we have to scale all the data is
that a thing
don't need any of this
so for training
here x Norm
then what we
then what we
[Music]
do test
do test
Norm test
PR test
y hang on
what happens if we do
this for
okay so here's before
okay so here's before
norm and now after
norm and now after
Norm huh it makes the right shape at
Norm huh it makes the right shape at
completely the wrong
scale e
it's kind of
funny I mean does this really even make
funny I mean does this really even make
sense
right the output variable of the
right the output variable of the
gaussian process
the output variable of a gum process is
the output variable of a gum process is
never going to be like a normal
never going to be like a normal
distribution ever in the case of hyper
distribution ever in the case of hyper
parameter tun
parameter tun
in so you can like try to force it to be
in so you can like try to force it to be
a
a
normal right
but you're going to get stuff like this
hold on is this even possible it doesn't
hold on is this even possible it doesn't
match at all like it doesn't match
match at all like it doesn't match
anywhere on the
anywhere on the
distribution I do this
distribution I do this
right let me just make absolutely
sure e
now this is correct this should be
now this is correct this should be
totally
correct I just change the scale a little
correct I just change the scale a little
bit with different data
[Music]
temp to like go get logistic
regression it's literally just um
yeah
sigmoid that's all it is
right does that even make sense
right does that even make sense
either like no it doesn't right
yeah this
yeah this
is but it's really
is but it's really
crap
because uh you're depending on the
because uh you're depending on the
output variable to be a standard normal
output variable to be a standard normal
but it's never going to be a standard
but it's never going to be a standard
normal so you're basically trying to
normal so you're basically trying to
come up with clever transformations to
come up with clever transformations to
fit it to a standard normal but the
fit it to a standard normal but the
thing is it's never going to be the like
thing is it's never going to be the like
a reasonable standard normal so you get
a reasonable standard normal so you get
this weird shift where it's like it has
this weird shift where it's like it has
the right shape but it doesn't match the
the right shape but it doesn't match the
uh the target distribution at
all e
h
you don't want to fit a curve you don't
you don't want to fit a curve you don't
want like a classic curve
fit because
fit because
um you got a bunch of input
variables so that'll overfit
it's like deceptively
simple Maybe it's just the colonel this
simple Maybe it's just the colonel this
stupid you
know it's just the colonel is stupid
know it's just the colonel is stupid
hold on
an RBF
an RBF
kernel okay the predictions go back to
zero e

Kind: captions
Language: en
okay we are
okay we are
live
cool
man
man
yeah right we have things to
yeah right we have things to
do many things to do
F
GitHub let's see
one second
one second
folks we do
this for
okay we are set over
there silly somebody wanted to do a
there silly somebody wanted to do a
poker agent
all
all
right
uhoh e
I want to work on I pram sweeps
cool we get back on stream we do this uh
cool we get back on stream we do this uh
not
not
this
this
blinding hyperr
blinding hyperr
stuff want to focus up on this a little
bit this
is going to take a little bit of
is going to take a little bit of
thought maybe not necessarily too much
thought so I've got this test gelian
thought so I've got this test gelian
process thingy
this is just a throwaway
this is just a throwaway
script and the only thing I really want
script and the only thing I really want
to figure out today is what the hell is
to figure out today is what the hell is
wrong with Gan process variance all
wrong with Gan process variance all
right that's all I want to figure
right that's all I want to figure
out so
um let's just do
um let's just do
this um
score equal for.
Rand oops
what's the freaking torch
random torch Rand
duh all
right
50 um
50 um
let's
let's
see
OBS and then we
do we do some stuff so we have
do we do some stuff so we have
this we got the error
this we got the error
we don't need
this nope there's no
this nope there's no
token the one that's using my name is by
token the one that's using my name is by
somebody stealing my name that is a scam
okay how obvious can you
okay how obvious can you
be no you can't just join this stream
be no you can't just join this stream
with multiple accounts at the exact same
with multiple accounts at the exact same
time and expect me to believe this is
time and expect me to believe this is
real
bye-bye stupid
no
way e
Christ man do you have enough accounts
Christ man do you have enough accounts
holy hell do you have nothing better to
holy hell do you have nothing better to
do leave me
alone
no for
hey we don't really need this Beast do
we hey very low
error very low
variance for
oh that actually worked
oh that actually worked
better so whatever happened before was
weird yeah
okay for
know why tries to keep adding this 10
along the lines of alpha go
along the lines of alpha go
zero I built
zero I built
a Monte Carlo Tre search algorithm and
a Monte Carlo Tre search algorithm and
in testing perf for some simple games
in testing perf for some simple games
with a euristic
with a euristic
function I assume this is from
function I assume this is from
uh the Discord messages
uh the Discord messages
before does puffer have a selfplay
before does puffer have a selfplay
transcript to train One agent while it's
transcript to train One agent while it's
opponent
opponent
uses a fixed
uses a fixed
policy so I think you could just pretty
policy so I think you could just pretty
darn easily
like yeah you could very easily do that
like yeah you could very easily do that
um does it have like a module for it no
um does it have like a module for it no
but I think you could do it in like 10
but I think you could do it in like 10
lines of code change so this is what you
lines of code change so this is what you
would do yeah okay my bad I'm a bit on
would do yeah okay my bad I'm a bit on
edge because I've been getting brigaded
edge because I've been getting brigaded
by like crypto nerds on my stream I just
by like crypto nerds on my stream I just
banned three
banned three
accounts
accounts
um I for a second I thought you were
um I for a second I thought you were
another one but more good um
another one but more good um
so this is what you would
so this is what you would
do let me find
it okay so there's this thing called
it okay so there's this thing called
masks in the
masks in the
environment um if you pass something to
environment um if you pass something to
masks uh it doesn't get used in training
masks uh it doesn't get used in training
so if you set the mask one on a specific
so if you set the mask one on a specific
agent it doesn't get used in training so
agent it doesn't get used in training so
for like a two agent environment if you
for like a two agent environment if you
have a bunch of copies you just set like
have a bunch of copies you just set like
every other one of these to one or to
every other one of these to one or to
true or
true or
whatever um false I think masks it out
whatever um false I think masks it out
yeah so You' set every other one of
yeah so You' set every other one of
these to false to mask out half of the
these to false to mask out half of the
policies and then all you would
policies and then all you would
do is inside of um clean puff
out which is right
here okay all you would do is you would
here okay all you would do is you would
take the
take the
observation and uh you would you would
observation and uh you would you would
just reshape it you know you would just
just reshape it you know you would just
split it every other one or fancy index
split it every other one or fancy index
it so you take every other one and you'd
it so you take every other one and you'd
use one policy for one and one policy
use one policy for one and one policy
for the other right so you take your
for the other right so you take your
fancy indices actions of odd actions of
fancy indices actions of odd actions of
odd log prob of odd whatever value of
odd log prob of odd whatever value of
odd equals policy zero of O divice of
odd equals policy zero of O divice of
odd and then actions of even log prop of
odd and then actions of even log prop of
even you know you get the point that
even you know you get the point that
would be the like few line quick way of
would be the like few line quick way of
doing it it would still be pretty darn
doing it it would still be pretty darn
fast um it would work just natively with
fast um it would work just natively with
training and it would let you use a
training and it would let you use a
fixed neuronet policy accelerated by
fixed neuronet policy accelerated by
puffer
lip it requires you change a couple
lip it requires you change a couple
little things custom but hey every other
little things custom but hey every other
library that supports this or like can
library that supports this or like can
support this uh has way way way heavier
support this uh has way way way heavier
and slow stuff usually
and slow stuff usually
so I think that's a pretty easy way to
so I think that's a pretty easy way to
get it working
actually you know I want to do something
actually you know I want to do something
a little better than this
yeah yeah let's do something a little
yeah yeah let's do something a little
better than
this e
look at
look at
this we got a speed up from 2,000 to
this we got a speed up from 2,000 to
450,000 steps per second
so nice to see that though look just
so nice to see that though look just
right out of the box they mess with
right out of the box they mess with
puffer for a few
puffer for a few
days and they get 200 xped
up
e e
would you recommend creating two agents
would you recommend creating two agents
which train against each other or only
which train against each other or only
train one and have the rest be fixed
train one and have the rest be fixed
previous iterations of itself oo
um if you want to start with the most
um if you want to start with the most
basic version of historical selfplay
basic version of historical selfplay
which doesn't have sampling or anything
which doesn't have sampling or anything
and maybe is enough to bootstrap off the
and maybe is enough to bootstrap off the
ground um what I would probably start
with I would just have one opponent and
with I would just have one opponent and
um I would basically whenever you get
um I would basically whenever you get
above a certain win rate above against
above a certain win rate above against
that opponent I would replace the
that opponent I would replace the
opponent with the current
opponent with the current
checkpoint and then you should be able
checkpoint and then you should be able
to very easily verify whether this is
to very easily verify whether this is
working
working
because your train curve should start
because your train curve should start
off at 50% if it's random policy versus
off at 50% if it's random policy versus
random policy and then it goes up to
random policy and then it goes up to
let's say 80% win rate is your threshold
let's say 80% win rate is your threshold
right and then it drops immediately to
right and then it drops immediately to
50 because you again you're playing
50 because you again you're playing
against yourself and then it goes back
against yourself and then it goes back
up to 80 so you should get the saw too
up to 80 so you should get the saw too
kind of a
curve e
thank you yeah no worries
anytime let me know how that goes as
anytime let me know how that goes as
well and if you end up making you know a
well and if you end up making you know a
fast M code to go with this stuff we are
fast M code to go with this stuff we are
very happy to have this stuff in puffer
very happy to have this stuff in puffer
and I don't know your engineering
and I don't know your engineering
background but if you haven't seen like
background but if you haven't seen like
CMS like ours before they're very very
CMS like ours before they're very very
easy to write I say this to somebody who
easy to write I say this to somebody who
wrote python for 10 years
we've got brand new devs writing these
we've got brand new devs writing these
environments at a million steps a
second e
we just want this right test PR
we just want this right test PR
minus obs
ums
where is
where is
it test
GPM why
I don't think I posted anything I uh my
I don't think I posted anything I uh my
ex and socials and stuff are very
ex and socials and stuff are very
intentionally apolitical except for
intentionally apolitical except for
Stuff specifically concerned with AI so
Stuff specifically concerned with AI so
I will comment on AI legislation and
I will comment on AI legislation and
things that pertain AI but that is
it I don't think I made any post to the
it I don't think I made any post to the
contrary did I
contrary did I
I don't think
so no I made one comment to the CEO of
so no I made one comment to the CEO of
Razer that was a game
Razer that was a game
meme that's it
something screwy here
yeah I'm not going to comment on
yeah I'm not going to comment on
political stuff outside of
political stuff outside of
um outside of
um outside of
AI that's been my policy for
AI that's been my policy for
years at least not on
years at least not on
um stream or you know socials or
anything I'm not here to tell you about
anything I'm not here to tell you about
politics I'm here
politics I'm here
to I mean my content is purely on
to I mean my content is purely on
reinforcement learning in the science in
reinforcement learning in the science in
the engineering
this
this
work this one is spot on right
wait
synthetic work on project that use RL
synthetic work on project that use RL
for process automation so yeah I'm here
for process automation so yeah I'm here
for it yeah and that sounds awesome
for it yeah and that sounds awesome
right the idea with with puffer is that
right the idea with with puffer is that
um we're going to start off right like
um we're going to start off right like
most of the companies and stuff that
most of the companies and stuff that
we're going to be working with starting
we're going to be working with starting
off it's going to be applications where
off it's going to be applications where
people have a clear-cut RL problem and
people have a clear-cut RL problem and
are just having a hard time with it
are just having a hard time with it
something where we can build a fast Sim
something where we can build a fast Sim
you know we can easily help with stuff
you know we can easily help with stuff
or else just hard and finicky we make it
or else just hard and finicky we make it
easier but as we build out better stuff
easier but as we build out better stuff
with puffer harder problems across
with puffer harder problems across
Automation in various Industries
Automation in various Industries
especially manufacturing and the like um
especially manufacturing and the like um
industrial processes really just various
industrial processes really just various
industrial processes are going to be uh
industrial processes are going to be uh
definitely targets for RL and God damn
definitely targets for RL and God damn
it this
it this
freaking not Julia
freaking not Julia
discussion again
sick of the damn programming language
sick of the damn programming language
discussion in the freaking Discord
[Laughter]
freaking
freaking
ridiculous we're here for RL come on
ridiculous we're here for RL come on
okay this is this is hyper parameter
okay this is this is hyper parameter
tuning hour so I I guess I should have
tuning hour so I I guess I should have
probably explain to what it is I'm doing
probably explain to what it is I'm doing
um while Discord is not distracting
um while Discord is not distracting
me um
me um
clean RL PPO no clean puff RL clean puff
clean RL PPO no clean puff RL clean puff
RL is the cleaned up one that's super
RL is the cleaned up one that's super
fast handle opponents making moves they
fast handle opponents making moves they
don't that's the thing you set the mask
don't that's the thing you set the mask
to false every other one every other
to false every other one every other
mask you set to false and that data will
mask you set to false and that data will
go through the forward path but it won't
go through the forward path but it won't
go through the backward
path you
path you
see yeah you're looking at the wrong
see yeah you're looking at the wrong
script is why
here so
write find
it yeah so right here this is stored and
it yeah so right here this is stored and
it's stored using the mask you see and
it's stored using the mask you see and
then when we
store we only store stuff where the mask
store we only store stuff where the mask
is true so if you set the mask to false
is true so if you set the mask to false
every other one it'll just be gone and
every other one it'll just be gone and
then all you have to do is use the fancy
then all you have to do is use the fancy
indexing in that forward path so you
indexing in that forward path so you
literally have like three lines of code
literally have like three lines of code
to change and you're good to go you just
to change and you're good to go you just
have to remember to set the
masks so if we focus on YouTube because
masks so if we focus on YouTube because
we've got six people watching now there
we've got six people watching now there
uh what I'm going to be trying to do for
uh what I'm going to be trying to do for
the next hour hour and a half until I
the next hour hour and a half until I
get tired uh I'm just testing out some
get tired uh I'm just testing out some
gaan process stuff because we have this
gaan process stuff because we have this
really snazzy hyperparameter tuning
really snazzy hyperparameter tuning
algorithm which I am very proud of it uh
algorithm which I am very proud of it uh
it gets some very good samples it's like
it gets some very good samples it's like
a very nice sampling distribution but
a very nice sampling distribution but
it's very dependent on the accuracy of
it's very dependent on the accuracy of
the internal gussian processes for
the internal gussian processes for
modeling which points to select and
modeling which points to select and
right now they're very high variance and
right now they're very high variance and
they're very overconfident so I'm trying
they're very overconfident so I'm trying
to figure out what's up with the Gan
to figure out what's up with the Gan
processes here just by doing some
processes here just by doing some
synthetic tests to evaluate where gum
synthetic tests to evaluate where gum
processes are Act accurate how accuracy
processes are Act accurate how accuracy
falls off over time as you get farther
falls off over time as you get farther
away from the points in the data set and
away from the points in the data set and
so on sub on YouTube fair enough welcome
so on sub on YouTube fair enough welcome
back
I'm just weird with this error thing
I'm just weird with this error thing
right test
error yeah for Insomniac I do stuff like
error yeah for Insomniac I do stuff like
this where I think that hyper pram
this where I think that hyper pram
tuning is one of the highest leverage
tuning is one of the highest leverage
things in RL right now because they're
things in RL right now because they're
so finicky and if you can just make if
so finicky and if you can just make if
you can make it so that if you run a 100
you can make it so that if you run a 100
experiment sweep you are just absolutely
experiment sweep you are just absolutely
confident that you have good hypers and
confident that you have good hypers and
anything that's wrong with your
anything that's wrong with your
experiment it's not hypers and if it
experiment it's not hypers and if it
works it'll get the best hypers like
works it'll get the best hypers like
it's going to make all of ourl feel so
it's going to make all of ourl feel so
much more polished and
consistent oh look at
consistent oh look at
this keep getting distracted here with
this keep getting distracted here with
other RL things but uh user wants
other RL things but uh user wants
assistance I am on stream to
assistance I am on stream to
assist particularly for folks that are
assist particularly for folks that are
open sourcing stuff and writing M for
open sourcing stuff and writing M for
Puffer
too many variables in
cstep let's say C
cstep let's say C
reset RN d
f ah Ray cast okay how many
Rays eight that's not
Rays eight that's not
bad eight Ray casts is
fine up
I'm kind of surprised if this is
I'm kind of surprised if this is
slow let me say if where are your Loops
slow let me say if where are your Loops
man there should be slow
things I wonder if they're just
things I wonder if they're just
profiling it wrong let me see
doesn't look like
it e
450k with training well why didn't you
450k with training well why didn't you
say
say
so my
guy wait with training well what's the M
guy wait with training well what's the M
don't you have an M
don't you have an M
profiler you have an M profiler
profiler you have an M profiler
right right here
did you run
this this font is way too
gigantic I'm going to say that looked
gigantic I'm going to say that looked
like it should be faster than that
uh
drone I'll run this real quick as well
we
compile
what oh
that's kind of
silly e
how the hell did I manage to break this
the funny thing about this is this
the funny thing about this is this
should be literally impossible because
should be literally impossible because
it's
it's
not it's uh everything statically
linked e
dude what the hell is
this does this run for
this does this run for
you okay good cuz I messed around with
you okay good cuz I messed around with
some stuff earlier and I must have
some stuff earlier and I must have
broken some things locally and I am too
broken some things locally and I am too
tired to fix this at the moment I want
tired to fix this at the moment I want
to just do my gum process stuff and go
to just do my gum process stuff and go
to bed 7 million FPS very nice um so in
to bed 7 million FPS very nice um so in
that case I will fix your model or
that case I will fix your model or
whatever real quick and then I will
whatever real quick and then I will
sleep uh not sleep I'll do this and go
sleep uh not sleep I'll do this and go
to sleep um what is what's your graphics
card they model on this
default oh well that's
default oh well that's
why it's actually that's kind of
why it's actually that's kind of
impressive that this gets
impressive that this gets
um 450,000 on
um 450,000 on
CPU it's only going to be training on
CPU it's only going to be training on
one4 of
that maybe we should well the thing is
that maybe we should well the thing is
you're probably running a tiny little
you're probably running a tiny little
model if it's just default
policy you could add the um the lstm
policy you could add the um the lstm
wrapper into this recurrent or whatever
wrapper into this recurrent or whatever
here it'll train slower you need a GPU
here it'll train slower you need a GPU
to train properly if you need help
to train properly if you need help
running some sweeps I can probably do
running some sweeps I can probably do
that for you we have 409s with
puffer
um are you running it with
um are you running it with
multiprocessing
multiprocessing
no well that's weird because because um
no well that's weird because because um
our M here this only uses One Core with
our M here this only uses One Core with
Native VEC uh so I don't know what P
Native VEC uh so I don't know what P
torch is doing maybe P torch CPU knows
torch is doing maybe P torch CPU knows
how to multi core or whatever I don't
how to multi core or whatever I don't
know but 450k on that yeah that's pretty
know but 450k on that yeah that's pretty
good in that case uh with a small policy
good in that case uh with a small policy
like this typically we can go above a
like this typically we can go above a
million on a
4090 all right
4090 all right
I will answer whatever additional
I will answer whatever additional
questions but there you go your M is so
questions but there you go your M is so
fast that you don't even need to worry
fast that you don't even need to worry
about multiprocessing it when you're at
about multiprocessing it when you're at
7 million when you start getting close
7 million when you start getting close
to like a million or below then that's
to like a million or below then that's
when you start thinking about
when you start thinking about
multiprocessing it well 7 million is
multiprocessing it well 7 million is
just fast
just fast
enough that you don't have to care about
enough that you don't have to care about
anything
oh reward scheme um hold
on analyze it for hitting a wall
I don't know what this galing
is
is
closest yeah I don't know what this
closest yeah I don't know what this
scaling is here
I don't like this continuous
I don't like this continuous
reward yeah I don't like this continuous
reward yeah I don't like this continuous
reward scheme I would just give it a
reward scheme I would just give it a
flat negative .5 on the step that it
flat negative .5 on the step that it
runs into
runs into
something and call it a day like
something and call it a day like
negative. five or something for running
negative. five or something for running
into an
into an
obstacle scaling is from a p
obstacle scaling is from a p
really okay I would still as a b line I
really okay I would still as a b line I
would see if you do better just giving
would see if you do better just giving
it5 on the step it collides cuz I don't
it5 on the step it collides cuz I don't
know how many times this gets applied
know how many times this gets applied
right this could get applied repeatedly
right this could get applied repeatedly
a whole
bunch you should be able to learn to fly
bunch you should be able to learn to fly
around pretty
around pretty
easily you also um do you guys have one
easily you also um do you guys have one
B set up or Neptune or one of
B set up or Neptune or one of
those are you getting logs from this
those are you getting logs from this
thing yet
you should be getting
logs cuz I want to see your
logs cuz I want to see your
losses because like look at your hyper
losses because like look at your hyper
parameters all right you've got a batch
parameters all right you've got a batch
size of
size of
260k a mini batch size of
260k a mini batch size of
so division is hard at this
so division is hard at this
to oh link wab be if you
can h
these are cool
looking if you have one you can link it
looking if you have one you can link it
real quick I can just take a quick look
real quick I can just take a quick look
at your losses and save you some time
at your losses and save you some time
before I go back to my other
stuff I suspect this batch size with
stuff I suspect this batch size with
this mini batch SI and these Epoch is
this mini batch SI and these Epoch is
horribly unstable
horribly unstable
and that's what's getting
and that's what's getting
you also these lambdas and gamas are
you also these lambdas and gamas are
insane I don't know where you got them
insane I don't know where you got them
from actually most of these hyper
from actually most of these hyper
parameters are utterly
insane where did you get these
do I link if it's a public WB you just
do I link if it's a public WB you just
link the uh the wandb like dashboard
link the uh the wandb like dashboard
link if it's not public then you can
link if it's not public then you can
either make it public or
either make it public or
whatever yeah you swept to much stuff is
whatever yeah you swept to much stuff is
what
happened I can show you I I will I will
happened I can show you I I will I will
fix this for you real quick if I have
fix this for you real quick if I have
the link so I can show it to
the link so I can show it to
you or just the losses screenshot I
you or just the losses screenshot I
guess
gotcha I'll let you do that so I don't
gotcha I'll let you do that so I don't
talk at the same time and confuse you
talk at the same time and confuse you
I'll just look at my stuff in a in the
I'll just look at my stuff in a in the
meanwhile for a second
[Music]
St
very weird
test OBS test PR
why is this so
high oh stupid okay
hi brother new here what's happening a
hi brother new here what's happening a
few things at the moment I'm working on
few things at the moment I'm working on
a hyper param some testing for a
a hyper param some testing for a
hyperparameter sweep algorithm for
hyperparameter sweep algorithm for
reinforcement learning this is all like
reinforcement learning this is all like
reinforcement learning Dev and I'm also
reinforcement learning Dev and I'm also
waiting for a user of our library to
waiting for a user of our library to
post a uh some links to some experiments
post a uh some links to some experiments
so I can do a little bit of quick
so I can do a little bit of quick
analysis for them get them on the right
track
track
car see if this is fixed yes so this is
car see if this is fixed yes so this is
now fixed
now fixed
perfect
um yeah this is the exact graph that we
um yeah this is the exact graph that we
would
like oh here we go
like oh here we go
fix my
fix my
graph and now I have some experiments to
graph and now I have some experiments to
look
look
at all right so for folks watching who
at all right so for folks watching who
are new to
are new to
RL this is probably when you'd want to
RL this is probably when you'd want to
tab back in because this is likely to be
tab back in because this is likely to be
very informative for
very informative for
you uh we're going to go look at two
you uh we're going to go look at two
different
different
things and this is going to look a
things and this is going to look a
little silly but now this is of course
little silly but now this is of course
you're going to
you're going to
not know this it's a
newcomer everyone literally everyone
newcomer everyone literally everyone
makes this
mistake I'm going to look real stupid if
mistake I'm going to look real stupid if
it's not this and the losses but I'm
it's not this and the losses but I'm
pretty confident it will
pretty confident it will
be yeah
so and we need to change the axis as
so and we need to change the axis as
well
they always change they change their UI
they always change they change their UI
man so I can't see
the
the
xais there it
is okay so 100 million
is okay so 100 million
uh whatever this is it was added later I
guess okay we've got uh exploding
guess okay we've got uh exploding
entropy
entropy
here we have
got weird policy dip and
got weird policy dip and
then this actually surprisingly doesn't
then this actually surprisingly doesn't
look too bad but the value loss here is
look too bad but the value loss here is
unstable you can see this and here as
unstable you can see this and here as
well
huh I actually wouldn't blame you for
huh I actually wouldn't blame you for
missing this except for the entropy the
missing this except for the entropy the
entropy one's pretty obvious but
entropy one's pretty obvious but
otherwise I wouldn't blame you for
otherwise I wouldn't blame you for
missing this here because uh it's not as
missing this here because uh it's not as
obvious on the graphs but I can tell you
obvious on the graphs but I can tell you
from the hyper parameters
from the hyper parameters
so you don't want to sweep all of this
so you don't want to sweep all of this
um if you sweep
um if you sweep
grad Max grad
grad Max grad
Norm uh value function coefficient and
Norm uh value function coefficient and
you didn't sweep the clip coefficient so
you didn't sweep the clip coefficient so
it's kind of interesting that it still
it's kind of interesting that it still
did
this one thing that happens that's kind
this one thing that happens that's kind
of weird is it'll lower the value
of weird is it'll lower the value
function coefficient a lot so that's why
function coefficient a lot so that's why
the value function is exploding it's not
the value function is exploding it's not
training the value function and um it'll
training the value function and um it'll
produce these like weird on ril runs
produce these like weird on ril runs
where you can get pretty decent
where you can get pretty decent
performance for a while but then the run
performance for a while but then the run
just collapses
just collapses
catastrophically so what I generally
catastrophically so what I generally
suggest for people is unless you really
suggest for people is unless you really
have a good
have a good
reason don't tune value function
reason don't tune value function
coefficient don't tune Max grad norm and
coefficient don't tune Max grad norm and
don't tune tune any of the clip
don't tune tune any of the clip
coefficients you can tune the rest of
coefficients you can tune the rest of
them you should probably also
them you should probably also
limit this mini batch size is crazy
limit this mini batch size is crazy
um you have a a ridiculous ratio here so
um you have a a ridiculous ratio here so
whatever this divided by this is is too
whatever this divided by this is is too
big this is like 50 or something 64
big this is like 50 or something 64
probably yeah this is too big and then
probably yeah this is too big and then
you multiply by update Epoch and you're
you multiply by update Epoch and you're
doing like 100 some odd updates uh on
doing like 100 some odd updates uh on
stale data now why would you do that you
stale data now why would you do that you
have a really fast environment right you
have a really fast environment right you
have unlimited brand new fresh data so
have unlimited brand new fresh data so
use your unlimited brand new fresh data
use your unlimited brand new fresh data
you can leave this like this if you want
you can leave this like this if you want
want so it's like very big batches but
want so it's like very big batches but
then this is going to have to go to like
then this is going to have to go to like
32k and then update EPO we'll see if
32k and then update EPO we'll see if
this needs to be three I'd be surprised
this needs to be three I'd be surprised
it's probably going to end up at one or
it's probably going to end up at one or
two um let's see what else uh Lambda and
two um let's see what else uh Lambda and
Gamma are just insane these are set for
Gamma are just insane these are set for
like twostep Horizon problems this is
like twostep Horizon problems this is
like what you would expect for a
like what you would expect for a
multi-armed bandit or something
multi-armed bandit or something
ridiculous so whatever gave you this is
ridiculous so whatever gave you this is
insane
insane
and yeah this is what'll happen when
and yeah this is what'll happen when
your hyper parameters get into wonky
your hyper parameters get into wonky
unstable
regime that probably would have been
regime that probably would have been
more eloquent in the morning rather than
more eloquent in the morning rather than
at 8:00 p.m. after I've been doing stuff
at 8:00 p.m. after I've been doing stuff
all day
all day
but that should
but that should
be sufficient quantities of RL
be sufficient quantities of RL
insights to get you on the right track
insights to get you on the right track
here I bet this one's pretty bad in
here I bet this one's pretty bad in
terms of the hypers
right H this is this run yeah 27 value
right H this is this run yeah 27 value
function that's why the value function
function that's why the value function
was exploding
also render your agents so you can
also render your agents so you can
actually see what they're
actually see what they're
doing it's other good thing you want to
doing it's other good thing you want to
be
doing okay we'll answer whatever
doing okay we'll answer whatever
follow-ups on that but that should
follow-ups on that but that should
be that should be what you need to get
be that should be what you need to get
on the right track
here sweep goddess weird hypers what did
here sweep goddess weird hypers what did
you
run what did you run this with cuz this
run what did you run this with cuz this
isn't a
isn't a
sweep like a Wy sweep
yeah those are some crazy hypers
it's good to learn to know the like the
it's good to learn to know the like the
interpretation of of the hyper
parameters we can render we use drone.
parameters we can render we use drone.
Pi very
Pi very
good yes so watch them we didn't
sweep that one should work just a random
sweep that one should work just a random
search so it's not a great sweep
the carbs demo in there should be decent
the carbs demo in there should be decent
as well but
as well but
um the problem isn't the sweep algorithm
um the problem isn't the sweep algorithm
in your case the problem is the um is
in your case the problem is the um is
sweeping too many parameters so I don't
sweeping too many parameters so I don't
know what's in the base sweep config on
know what's in the base sweep config on
the main branch but take out you know
the main branch but take out you know
all the Redundant stuff really the most
all the Redundant stuff really the most
important parameters you can just even
important parameters you can just even
set a man like manually you could set
set a man like manually you could set
this to be 130 or 260 and just set the
this to be 130 or 260 and just set the
um mini batch size to 32k and you'll
um mini batch size to 32k and you'll
probably find some decent parameters
probably find some decent parameters
just sweeping learning rate entropy
just sweeping learning rate entropy
Lambda and
Lambda and
Gamma you'll probably find some decent
Gamma you'll probably find some decent
parameters in
there as for better hyper parameter
there as for better hyper parameter
sweeps it's coming we're going to have
sweeps it's coming we're going to have
the best hyper param sweeps in the
the best hyper param sweeps in the
business once I finish this
and once I figure out insane giian
and once I figure out insane giian
process
things of course always happy to
help back for status update tomorrow
help back for status update tomorrow
very
good yeah I'm particularly always happy
good yeah I'm particularly always happy
to help um you know academic people uh
to help um you know academic people uh
who are like contributing know
who are like contributing know
environment code and stuff I'm very
environment code and stuff I'm very
happy to help with
happy to help with
that pretty much the only thing that I
that pretty much the only thing that I
won't help with is when um
won't help with is when um
you know like substantial size companies
you know like substantial size companies
are demanding uh large amounts of
are demanding uh large amounts of
support help for free that's the only
support help for free that's the only
time where it's like okay guys you
time where it's like okay guys you
should get a priority service contract
should get a priority service contract
um pretty much everyone else it's like
um pretty much everyone else it's like
yeah we're
good
e e
why is the error in this specific
why is the error in this specific
Direction I
wonder test
prediction minus test op so it
undershoots why don't I just put
undershoots why don't I just put
in test
in test
observation and test
observation and test
prediction all right we know it should
prediction all right we know it should
be a
line what
[Music]
something weird
here oops
[Music]
why did test error work
before the access toay off
yeah know this doesn't make any freaking
yeah know this doesn't make any freaking
sense this test error is like
sense this test error is like
this x
scores
scores
right no this doesn't make sense so
right no this doesn't make sense so
unless I'm being particularly stupid
okay so this is
okay so this is
there
there
red test
red test
Ops red my
test okay
first of all it should be test OBS minus
first of all it should be test OBS minus
test
test
sprad be the way to go
here that just flips it
this doesn't make much sense oh unless
this doesn't make much sense oh unless
the axes were off hold on
yep the axes are
off you can see that the slope is wrong
off you can see that the slope is wrong
here
right so in this regime right this is
right so in this regime right this is
perfect and then the predictions are
perfect and then the predictions are
totally wrong over here
CU it should continue this way and it
CU it should continue this way and it
Slants off this
Slants off this
way it's a very weird error pattern that
way it's a very weird error pattern that
it's like this perfectly consistent
it's like this perfectly consistent
predictor on the wrong
line
okay let's see the standard
deviation well if anything this is Harsh
deviation well if anything this is Harsh
right says it knows that it's wrong
so already by cost two they've got an
so already by cost two they've got an
error of one factored
in
right we can do
air okay so here's your variance
and here's your
error so by two it's got a one factored
in and the error is only 0
five error goes up to four
I mean we're happy with that
I mean this is the pattern
what if we do this
H the error suddenly gets
better and if we look at the
better and if we look at the
predictions are the predictions good
oh yeah the predictions are solid look
oh yeah the predictions are solid look
at that now the thing is there's a
at that now the thing is there's a
linear kernel in here
linear kernel in here
right so we're going to have to do
right so we're going to have to do
a let's make this a little harder
right x equals
right x equals
Rand
Rand
5050 y
5050 y
equals
equals
uh log of
x
one
for e
X that's
y e
does this
work what we're going to try to do is
work what we're going to try to do is
we're going to
we're going to
fit the we're going to fit this to a log
fit the we're going to fit this to a log
distribution and we're going to watch
distribution and we're going to watch
the error and we're see we're going to
the error and we're see we're going to
see if we can figure out any issues with
see if we can figure out any issues with
the error pattern of gussian processes
the error pattern of gussian processes
which is going to be important for this
which is going to be important for this
hyper parameter sweep getting kind of
hyper parameter sweep getting kind of
tired so brain not fully working but uh
tired so brain not fully working but uh
you know it's going to well we'll get
you know it's going to well we'll get
there I mean yeah we'll get
there I mean yeah we'll get
there
um I'd like to at least have something
um I'd like to at least have something
to show here before I go to
to show here before I go to
sleep okay cool
so test prediction
we'll just do test
y s y
y s y
= s y
= s y
and then because python doesn't care
and then because python doesn't care
where you define
things p.
scatter
scatter
purple
purple
guess Secret
okay and then we just do
this see if this does
it doesn't like that
it doesn't like that
I just want to put them on the same
I just want to put them on the same
graph come on
graph come on
man why do all plotting libraries just
man why do all plotting libraries just
why are they all
pain I think it's y equals test y
pain I think it's y equals test y
right yeah silly me all right that's on
me columns must be the same length
me columns must be the same length
this is xal test
this is xal test
X add this in like
X add this in like
this come
on come on how's this not handled yet
eror columns data source must be Oh
eror columns data source must be Oh
serious
play okay
play okay
fine uh
oh this plot's going to be
useful hey there we go
what
oh
silly okay um somehow that's perfect
silly okay um somehow that's perfect
right
oh wait no it's perfect
because yeah we're silly we're just very
silly can't be perfect perfect that
silly can't be perfect perfect that
would be
ridiculous yay there we
go n there's no way it's that bad
go n there's no way it's that bad
right we should plot the um
right we should plot the um
the true data on the bottom I would
say so we plot this
first so can we see from here yeah they
first so can we see from here yeah they
overlap look you see
overlap look you see
this they overlap perfectly within the
support you see the purple mixed in
support you see the purple mixed in
and then right around here they break
away and they break away in like a weird
away and they break away in like a weird
catastrophic way as
well what happens if we do
well what happens if we do
this I'm hoping here this doesn't just
this I'm hoping here this doesn't just
immediately fix well I'm not hoping I
immediately fix well I'm not hoping I
expect it's not going to immediately fix
expect it's not going to immediately fix
yeah so this makes it more linear you
yeah so this makes it more linear you
see this when you put 10 in it just
see this when you put 10 in it just
makes your prediction a
line and then we can try
line and then we can try
0.1 which means the matern kernel takes
over and you still get this fit actually
over and you still get this fit actually
with the mat return kernel up to here
with the mat return kernel up to here
but then the kernel does this
but then the kernel does this
somehow so neither of these kernels is
somehow so neither of these kernels is
going to save you essentially
so we may as well go with the
default that's kind of useless isn't it
all right let's do another
all right let's do another
Experiment 2 * Rand
100 now you have more data can you
100 now you have more data can you
fit no you get the exact same pattern
fit no you get the exact same pattern
Right double the data
double the data
here Al so why is the coloration so
weird that's weird but
weird that's weird but
whatever so you double the data you get
whatever so you double the data you get
the exact same error pattern this thing
the exact same error pattern this thing
will not learn no matter how much data
will not learn no matter how much data
you throw at
it that's kind of bad
okay what if we
do do we have to scale all the data is
do do we have to scale all the data is
that a thing
don't need any of this
so for training
here x Norm
then what we
then what we
[Music]
do test
do test
Norm test
PR test
y hang on
what happens if we do
this for
okay so here's before
okay so here's before
norm and now after
norm and now after
Norm huh it makes the right shape at
Norm huh it makes the right shape at
completely the wrong
scale e
it's kind of
funny I mean does this really even make
funny I mean does this really even make
sense
right the output variable of the
right the output variable of the
gaussian process
the output variable of a gum process is
the output variable of a gum process is
never going to be like a normal
never going to be like a normal
distribution ever in the case of hyper
distribution ever in the case of hyper
parameter tun
parameter tun
in so you can like try to force it to be
in so you can like try to force it to be
a
a
normal right
but you're going to get stuff like this
hold on is this even possible it doesn't
hold on is this even possible it doesn't
match at all like it doesn't match
match at all like it doesn't match
anywhere on the
anywhere on the
distribution I do this
distribution I do this
right let me just make absolutely
sure e
now this is correct this should be
now this is correct this should be
totally
correct I just change the scale a little
correct I just change the scale a little
bit with different data
[Music]
temp to like go get logistic
regression it's literally just um
yeah
sigmoid that's all it is
right does that even make sense
right does that even make sense
either like no it doesn't right
yeah this
yeah this
is but it's really
is but it's really
crap
because uh you're depending on the
because uh you're depending on the
output variable to be a standard normal
output variable to be a standard normal
but it's never going to be a standard
but it's never going to be a standard
normal so you're basically trying to
normal so you're basically trying to
come up with clever transformations to
come up with clever transformations to
fit it to a standard normal but the
fit it to a standard normal but the
thing is it's never going to be the like
thing is it's never going to be the like
a reasonable standard normal so you get
a reasonable standard normal so you get
this weird shift where it's like it has
this weird shift where it's like it has
the right shape but it doesn't match the
the right shape but it doesn't match the
uh the target distribution at
all e
h
you don't want to fit a curve you don't
you don't want to fit a curve you don't
want like a classic curve
fit because
fit because
um you got a bunch of input
variables so that'll overfit
it's like deceptively
simple Maybe it's just the colonel this
simple Maybe it's just the colonel this
stupid you
know it's just the colonel is stupid
know it's just the colonel is stupid
hold on
an RBF
an RBF
kernel okay the predictions go back to
zero e
