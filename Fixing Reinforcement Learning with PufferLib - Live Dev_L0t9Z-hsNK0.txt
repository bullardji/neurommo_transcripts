Kind: captions
Language: en
Okay, we are live.
Hello. Notifications blowing up on
here. What the heck is this?
Academia is a crazy place.
silly auto correct.
This is not This is like completely
This is not This is like completely
disrespectful.
That's a bit much.
Morning.
That's
ridiculous. You can't just slap safety
ridiculous. You can't just slap safety
on a sub field. That's really
on a sub field. That's really
constrained optimization and then claim
constrained optimization and then claim
the moral high ground. That's just not
the moral high ground. That's just not
how this
works. See anything else on
this? More Pokemon stuff. Let me go see
this? More Pokemon stuff. Let me go see
if we have any more Pokemon stuff or if
if we have any more Pokemon stuff or if
I should
just double check.
Okay, I guess it's on me to tweet out uh
Okay, I guess it's on me to tweet out uh
additional stuff on
Pokemon. This is cool.
I miss
I miss
[Music]
[Music]
anybody? I think so.
Just drafting this and then we'll do
Just drafting this and then we'll do
some uh some depth.
Okay, that's
Okay, that's
good. Twitter's been uh popping here.
Oops. No, I am skeptical of this.
I'm very skeptical of this.
I don't get this like this take
here. I know Jeff is good, but like I
here. I know Jeff is good, but like I
don't like you can't demonstrate these
don't like you can't demonstrate these
methods on like really small academic
methods on like really small academic
tasks and then just claim that they'll
tasks and then just claim that they'll
solve everything.
That's
That's
disrespectful cuz he does a lot of good
disrespectful cuz he does a lot of good
stuff. I didn't mean it that way.
the heck's really hard. Like I don't
the heck's really hard. Like I don't
trust any like you know go explore is a
trust any like you know go explore is a
method that just seems to make a lot of
method that just seems to make a lot of
sense but like I don't trust methods
sense but like I don't trust methods
just because they seem to make a lot of
just because they seem to make a lot of
sense if they haven't been demonstrated
sense if they haven't been demonstrated
on uh know something much
bigger. I got to love the box.
Okay, so we have stuff to do.
Okay. So, we
Okay. So, we
have a lot of points right
have a lot of points right
around 110
around 110
seconds. It looks
seconds. It looks
like there's something about this,
like there's something about this,
right? I assume with the
parameters. So let me think what we want
parameters. So let me think what we want
to do today. There's quite a bit of
to do today. There's quite a bit of
stuff to look
stuff to look
at. Me double check one thing. There are
at. Me double check one thing. There are
two different directions we could take
two different directions we could take
for
for
now. Okay, that's taken care of. Cool.
now. Okay, that's taken care of. Cool.
Um I really want to get this algorithm
Um I really want to get this algorithm
into a decent spot. Oh yeah, I also I
into a decent spot. Oh yeah, I also I
think I forgot one one message. Where
think I forgot one one message. Where
did it go?
I think that the what that what we're
I think that the what that what we're
going to do right now is we're going to
going to do right now is we're going to
decide based on what this result tells
me. So I think if I just
me. So I think if I just
filter I have this
15.
15.
[Music]
Okay. So, here are the runs for
this learning rate.
this learning rate.
pretty
robust. Gamma shouldn't matter because
robust. Gamma shouldn't matter because
it's real. Lambda shouldn't matter,
it's real. Lambda shouldn't matter,
right? It doesn't
right? It doesn't
matter. Almost all just one update
matter. Almost all just one update
epoch. Okay.
front
front
here. Oh, most of these are at
150. And most of these are at
150. And most of these are at
150. So, some of these are much faster
150. So, some of these are much faster
than others for some reason. It's got to
than others for some reason. It's got to
be mini batches or something,
be mini batches or something,
right? They all have 1024 MS.
They all have the same b
They all have the same b
size. And there it is. Mini bap
size.
size.
So why is this so slow? It's just like
Let me think about this. There are a
Let me think about this. There are a
couple things here that I I have uh
couple things here that I I have uh
ideas
ideas
for. Can I find the baseline that we uh
for. Can I find the baseline that we uh
we trained in
here breakout fast? Okay, this should be
here breakout fast? Okay, this should be
good. All
right, there we
go. Yeah. So, here's the big difference,
go. Yeah. So, here's the big difference,
right?
right?
This
This
algorithm is able to train with a mini
algorithm is able to train with a mini
batch size of
batch size of
8192. I believe this is the difference,
8192. I believe this is the difference,
right? Oh, there also
right? Oh, there also
some with 2048 ms as
some with 2048 ms as
well. But, uh, if I'm looking at
well. But, uh, if I'm looking at
differences, that's the biggest one I
differences, that's the biggest one I
see. There's a lot of one epoch right
see. There's a lot of one epoch right
here. So, the biggest update is that for
here. So, the biggest update is that for
whatever
whatever
reason, GA works with bigger mini
reason, GA works with bigger mini
batches
batches
and more
and more
ends. Why would that be the
ends. Why would that be the
case? What is it about the algorithm
itself? Hold on. It could just be total
itself? Hold on. It could just be total
time steps, right?
Maybe I'm shooting myself in the foot by
Maybe I'm shooting myself in the foot by
making this the
making this the
max. Look at
max. Look at
this. What do we have total time steps
this. What do we have total time steps
wise? Yeah, we're pretty much pressing
wise? Yeah, we're pretty much pressing
up against the maximum here, aren't we?
So maybe if I increase total time
So maybe if I increase total time
steps and maybe if I increase the
steps and maybe if I increase the
maximum total time steps it would
maximum total time steps it would
find faster parameters for
solvent. Does that make
solvent. Does that make
sense? Let's assume okay here's an idea.
sense? Let's assume okay here's an idea.
If we assume that there is a small
If we assume that there is a small
difference in sample efficiency even if
difference in sample efficiency even if
it's initial sample efficiency but our
it's initial sample efficiency but our
methods are a bit different right so
methods are a bit different right so
let's say that my method
let's say that my method
takes you know 20 million more
takes you know 20 million more
samples to
optimize that
consistent I could see that being
consistent I could see that being
consistent
consistent
because you know these ones could be
because you know these ones could be
slower over here. Okay. So, if mine
slower over here. Okay. So, if mine
takes 20 million steps more to
takes 20 million steps more to
optimize and you're not allowing it to
optimize and you're not allowing it to
get those additional 20 million steps,
get those additional 20 million steps,
which should just take 20% more compute,
which should just take 20% more compute,
it could have to go to fewer M's and
it could have to go to fewer M's and
smaller mini batches, which could be a
smaller mini batches, which could be a
much bigger than 20% performance
much bigger than 20% performance
penalty. But that makes
penalty. But that makes
sense. I think it does.
sense. I think it does.
I think that makes
sense. I mean what other parameters are
sense. I mean what other parameters are
there here? one update epoch 32
horizon. Can we just do this for a
second and just see like what this thing
second and just see like what this thing
finds.
It does get mini batch of
It does get mini batch of
4096. It really doesn't try very
4096. It really doesn't try very
hard over here, does
hard over here, does
it? It just didn't try.
it? It just didn't try.
I wonder why
I wonder why
not the results over
here. Maybe it had to adjust different
here. Maybe it had to adjust different
things in order to make that fast enough
things in order to make that fast enough
though. I don't
though. I don't
know. It's a time steps problem,
know. It's a time steps problem,
right? What else do we have here?
ends. Yeah.
ends. Yeah.
Missing. Oh, no. You know, it's actually
Missing. Oh, no. You know, it's actually
it is starting to do some
it is starting to do some
stuff. 2,00
stuff. 2,00
here. It just takes it a
while. It's aren't that different
while. It's aren't that different
really.
Rise to
32 16. Yeah, whatever. They both
32 16. Yeah, whatever. They both
work. One update epoch for the most part
work. One update epoch for the most part
with a couple
exceptions. Value
exceptions. Value
co that's pretty similar, right? It's
co that's pretty similar, right? It's
stable. Same with max gradorm.
stable. Same with max gradorm.
Max Bradnorm goes we have a much wider
Max Bradnorm goes we have a much wider
range for max grad
range for max grad
norm which is
interesting. We have a different loss
interesting. We have a different loss
function
though. Gamma doesn't matter. Lambda
though. Gamma doesn't matter. Lambda
doesn't matter.
should be
coefficient. You kind of get a big
coefficient. You kind of get a big
stable range. Does the learning rate
stable range. Does the learning rate
different? That's what I'm curious
different? That's what I'm curious
about. O2.
about. O2.
And here you have 02, but it also goes
And here you have 02, but it also goes
all the way to up to
0.01.
0.01.
Um
Um
05. It's off by maybe a back two from
05. It's off by maybe a back two from
there. I wouldn't call these ranges way
there. I wouldn't call these ranges way
too different.
too different.
And then the burrito
And then the burrito
front
is very very
is very very
similar. This is so
close. It really just seems like it's
[Music]
there is still like a 10% speed
there is still like a 10% speed
difference,
right? So with that, they're not that
right? So with that, they're not that
far apart. And also there's another 30
far apart. And also there's another 30
runs to go here as well.
Well, hang on.
Well, hang on.
Right. If you have an algorithm with
Right. If you have an algorithm with
more
more
hyperparameters, you're pretty much
hyperparameters, you're pretty much
always going to be able to get it to be
always going to be able to get it to be
slightly faster,
slightly faster,
right? in terms of uh total time steps
right? in terms of uh total time steps
if they're reasonable hypers because
if they're reasonable hypers because
each of those is tunable and gives you
each of those is tunable and gives you
an inductive bias on the environment
an inductive bias on the environment
that you have to learn from scratch
that you have to learn from scratch
otherwise. So this is kind of
otherwise. So this is kind of
fine for there to be a tiny perf
fine for there to be a tiny perf
gap. I think that we should be pretty
gap. I think that we should be pretty
happy with
happy with
this. And instead of trying to close
this. And instead of trying to close
this last little 10%, which will
this last little 10%, which will
probably go away eventually anyways,
probably go away eventually anyways,
maybe it'll get like slimmed at
maybe it'll get like slimmed at
least. We should probably think about
least. We should probably think about
some of the
some of the
um larger issues with
this. Yeah.
this. Yeah.
So I think what we should do is we
So I think what we should do is we
should just like kind of say
should just like kind of say
okay these are very
okay these are very
close. You don't have to beat the PF
close. You don't have to beat the PF
of PO in terms of samples or in terms of
of PO in terms of samples or in terms of
like wall clock. No in terms of samples
like wall clock. No in terms of samples
should be similar in terms of wall clock
should be similar in terms of wall clock
on an environment for which you've
on an environment for which you've
heavily heavily tuned the parameters for
heavily heavily tuned the parameters for
the baseline. You just need to about
the baseline. You just need to about
match
match
it and then you need to demonstrate that
it and then you need to demonstrate that
it can learn things that PO can't on the
it can learn things that PO can't on the
harder environments. That would be the
harder environments. That would be the
test of this more than
test of this more than
anything. Yeah, that makes sense. Okay.
anything. Yeah, that makes sense. Okay.
So, if we're going to say
So, if we're going to say
that, then the main thing is figuring
that, then the main thing is figuring
out why this doesn't play nice
out why this doesn't play nice
with longer
with longer
horizons. Yeah, with longer
horizons. Let's take one of these
horizons. Let's take one of these
parames that
parames that
seems it seems good.
22054. One of the earliest
runs. Oh, this one only ran
runs. Oh, this one only ran
um 79
um 79
mil. It's probably a lucky run.
It looks very clean, but it's probably a
It looks very clean, but it's probably a
lucky
run. I might just killed the container
run. I might just killed the container
by
by
mistake. That's fine.
So new parameters
here. This
here. This
is 66 million steps is what this took to
is 66 million steps is what this took to
solve right
solve right
there. So we'll give it a few
there. So we'll give it a few
additional what that's doing. We'll give
additional what that's doing. We'll give
it the full
it the full
80 just to give it a little bit of
80 just to give it a little bit of
wiggle room in case there's variance.
wiggle room in case there's variance.
We'll do
total
total
HTML. There we
go. And 24.
batch size
2048. Yeah, this is a way smaller mini
2048. Yeah, this is a way smaller mini
batch size. So, this is why it's going
batch size. So, this is why it's going
to be
slower. It does seem like the max grad
slower. It does seem like the max grad
norm parameter changes quite
norm parameter changes quite
substantially.
substantially.
gets to be a much wider
gets to be a much wider
spread. Then we do VFX
coefficient. I forget any update epox is
multiple. Where is
multiple. Where is
this one update
epoch? Okay. So we have batch
epoch? Okay. So we have batch
size epoch
size epoch
entropy don't need gamma lambda anymore
entropy don't need gamma lambda anymore
which is great learning rate I only
which is great learning rate I only
forgot the most important parameter
forgot the most important parameter
that's a funny
recommendation
radorm I think this is
Good. Comment all
these. I just want something decent, you
these. I just want something decent, you
know, to work off
of. Oops. I don't know what I'm
doing. Okay.
list index out of
range.
range.
Lovely. Got to love container driver
Lovely. Got to love container driver
detaching for no reason.
This is [ __ ]
uh MIT professor being kind of rude to
uh MIT professor being kind of rude to
Richard Sutton and a very silly way and
Richard Sutton and a very silly way and
then went on a big long big long thread
then went on a big long big long thread
about it.
You make you can't make a thread here.
What do we think on this?
actually. No, it's worse than that.
Right. Is it just me or is the Minecraft
Right. Is it just me or is the Minecraft
diamonds thing actually look very simple
diamonds thing actually look very simple
in comparison to
in comparison to
this? Cuz I like look, if you're getting
this? Cuz I like look, if you're getting
diamond in general and you're like going
diamond in general and you're like going
to do it through exploration or
to do it through exploration or
whatever, sure. If you're going to like
whatever, sure. If you're going to like
go caving, that's kind kind of
go caving, that's kind kind of
interesting. But um I'd still nowhere
interesting. But um I'd still nowhere
near Pokemon even if you do that. And
near Pokemon even if you do that. And
that's not what these models do. They
that's not what these models do. They
just dig down and hope they get lucky. I
just dig down and hope they get lucky. I
don't even think that they dig down two
don't even think that they dig down two
by two. They just yolo it and say if I
by two. They just yolo it and say if I
hit lava, I hit lava.
I disagree with this.
Oops. Stupid auto cracked.
Lucky
Lucky
trajectories is also possible.
Well, I guess this
Well, I guess this
doesn't apply as well,
right? No, that would be multi seed.
I don't even know if you need different
I don't even know if you need different
seeds. Robotics doesn't really add seeds
seeds. Robotics doesn't really add seeds
in the same way.
Why be Why behavioral
cloning? Guess today's a Today is a
cloning? Guess today's a Today is a
common Twitter day.
I think RL is one of the better ones for
I think RL is one of the better ones for
open source, isn't it?
This doesn't make sense to me either.
field is valued. I don't understand.
field is valued. I don't understand.
Like there's these are two different
Like there's these are two different
things.
things.
Like I don't even know what the heck to
Like I don't even know what the heck to
say. This is just like a Byzantine
I don't even think self-driving uses
RL. I convince this guy.
Are there even any of
Are there even any of
these where there's been like an
these where there's been like an
irresponsible deployment? I don't know
irresponsible deployment? I don't know
of any.
Why why can you explain to me why the
Why why can you explain to me why the
Twitter auto checker doesn't like it's
Twitter auto checker doesn't like it's
like gaslighting me into thinking I
like gaslighting me into thinking I
can't spell stupid
can't spell stupid
thing. Maybe it's the OS. I don't know.
What's on the docket today? I don't
What's on the docket today? I don't
know. There's a lot of random stuff on
know. There's a lot of random stuff on
Twitter that keeps distracting me. I
Twitter that keeps distracting me. I
mean, to be fair, stuff is uh stuff's
mean, to be fair, stuff is uh stuff's
doing pretty well.
doing pretty well.
This is the new post from today. I just
This is the new post from today. I just
did this. It's already at
did this. It's already at
48. I'm just going to keep posting stuff
48. I'm just going to keep posting stuff
every day with the uh with different
every day with the uh with different
graphics and then um you know, hopefully
graphics and then um you know, hopefully
it transfers over. He's at 180 already.
it transfers over. He's at 180 already.
That's pretty good, right?
How'd this do? This finished a long time
How'd this do? This finished a long time
ago. This did not
ago. This did not
do. Wait, what? Where'd it go?
do. Wait, what? Where'd it go?
Oh, hang on.
Grand
Yeah, these hypers are just slow because
Yeah, these hypers are just slow because
the mini batches are too small, right?
the mini batches are too small, right?
There's too much overhead in
There's too much overhead in
learn mainly in
learn mainly in
learn and forward maybe
Where did this
go? Why is this like Nowhere close to
go? Why is this like Nowhere close to
the
original. Huge blog on Pokemon
original. Huge blog on Pokemon
Red. Congrats. The group didn't get
Red. Congrats. The group didn't get
close to 50K views. I don't know. How
close to 50K views. I don't know. How
can you see the uh the blog post views?
can you see the uh the blog post views?
Cuz it was also on Hacker News. I can
Cuz it was also on Hacker News. I can
see my post on it and the original
15K on the
15K on the
retweet. Oh yeah, 40K on the original.
retweet. Oh yeah, 40K on the original.
Very
nice. Yeah, this did pretty
nice. Yeah, this did pretty
well. Yeah, 40K on the original, 15 on
well. Yeah, 40K on the original, 15 on
my retweet of
it. And uh I mean, we're not done yet.
it. And uh I mean, we're not done yet.
We're going to keep posting stuff.
So, this didn't work at all. Um, I
So, this didn't work at all. Um, I
assume I must have mucked up the
assume I must have mucked up the
parameters or something,
right? Wait, what? What happened here?
Oh, I probably grabbed one from the
Oh, I probably grabbed one from the
wrong the wrong list, right? Unless I
wrong the wrong list, right? Unless I
messed this up massively as well. That
messed this up massively as well. That
would actually be really funny if I mess
would actually be really funny if I mess
this up
this up
massively. Let me see.
22 197. Let's do that one.
Use P30 is true, right?
100k time 100 mil time
steps
steps
T
T
entropy mini batch 4096 mini batch is
entropy mini batch 4096 mini batch is
better. I wonder if it's going to
better. I wonder if it's going to
compensate with two update epochs.
No, it's one update. Epoch. Okay, maybe
No, it's one update. Epoch. Okay, maybe
there's something
here. Good luck. We'll be tuning in.
here. Good luck. We'll be tuning in.
Yeah, I'm going to be probably debubbing
Yeah, I'm going to be probably debubbing
all day on
Saturday. I have uh well, we'll see
Saturday. I have uh well, we'll see
where I go today, but I have some
where I go today, but I have some
algorithm dev plans for
Saturday. There's also some new research
Saturday. There's also some new research
that I'm want to get started on.
that I'm want to get started on.
Lot to do on puffer these days. Lot to
Lot to do on puffer these days. Lot to
do is a busy
Hey, welcome
Let's see if this one
frames. Okay, Pokemon stuff still doing
frames. Okay, Pokemon stuff still doing
well.
All right, that's
All right, that's
better. That is better at
better. That is better at
least. Does it
solve? I would have to Yeah, there it
solve? I would have to Yeah, there it
goes. Solves right at the end, which is
goes. Solves right at the end, which is
kind of
kind of
funny. It like needs that last little
funny. It like needs that last little
update, I
update, I
guess. Weird how that
works. 56. Yeah, this matches
works. 56. Yeah, this matches
nicely. 120 seconds. But I gave it some
nicely. 120 seconds. But I gave it some
extra steps to account for um seed to
extra steps to account for um seed to
seed
variance. Okay, it is
variance. Okay, it is
1:30. I've gotten super distracted by
1:30. I've gotten super distracted by
all this
mess. Um what I'm going to do is I'm
mess. Um what I'm going to do is I'm
just going to close Twitter. I'm going
just going to close Twitter. I'm going
to take a minute, go use the restroom,
to take a minute, go use the restroom,
clear my head. been kind of like
clear my head. been kind of like
babysitting all these posts and stuff,
babysitting all these posts and stuff,
the engagement because there are some
the engagement because there are some
cool people responding to stuff as well.
cool people responding to stuff as well.
Uh and now that we have a good baseline
Uh and now that we have a good baseline
with the new algorithm that is
with the new algorithm that is
relatively fast, we are going to use
relatively fast, we are going to use
this uh as a launch point for exploring
this uh as a launch point for exploring
the one issue, the one main issue I have
the one issue, the one main issue I have
with this algorithm at the moment, which
with this algorithm at the moment, which
is there's uh there's this horizon that
is there's uh there's this horizon that
you define that is not supposed to be a
you define that is not supposed to be a
hyperparameter, but kind of works as a
hyperparameter, but kind of works as a
hyperparameter at the moment because of
hyperparameter at the moment because of
quirks. I think the same thing uh there
quirks. I think the same thing uh there
are some potential issues even with our
are some potential issues even with our
PO implementation because of this. So
PO implementation because of this. So
essentially this is something that has a
essentially this is something that has a
high chance of uh resulting in a a
high chance of uh resulting in a a
general improvement to puffer lib
general improvement to puffer lib
overall and then b making this algorithm
overall and then b making this algorithm
actually work uh way better in the way
actually work uh way better in the way
that we would expect it to. We'll do
that we would expect it to. We'll do
some analysis on that. But uh yeah, take
some analysis on that. But uh yeah, take
in two minutes. I'll be right back.
Okay, we are
back. Boom. Goes over there. No
back. Boom. Goes over there. No
more. We've done enough on X for now.
more. We've done enough on X for now.
Let's get some real work
done. Now, it will be tricky.
done. Now, it will be tricky.
So I think that the main
So I think that the main
issue before we
issue before we
uh P30
horizon want to just double check to
horizon want to just double check to
make sure this actually doesn't just
make sure this actually doesn't just
work. I don't think it
does. Come on.
does. Come on.
Where's the
Where's the
uh where's the new
run? There it
run? There it
is. Yeah. So, this is going to take way
is. Yeah. So, this is going to take way
longer here, right?
I think that the main issue with
I think that the main issue with
this, maybe I should
this, maybe I should
uh elaborate a little bit. Right now,
uh elaborate a little bit. Right now,
when you train this new algorithm, it
when you train this new algorithm, it
requires a horizon parameter that tells
requires a horizon parameter that tells
you how many time steps ahead to look.
you how many time steps ahead to look.
Now, you actually get to choose or learn
Now, you actually get to choose or learn
how much you pay attention to those time
how much you pay attention to those time
steps, each of those time steps, which
steps, each of those time steps, which
is the important part. So really what
is the important part. So really what
this parameter is supposed to be is just
this parameter is supposed to be is just
like a compute budget parameter where it
like a compute budget parameter where it
shouldn't even be that expensive to look
shouldn't even be that expensive to look
farther ahead but you know it's a little
farther ahead but you know it's a little
bit it adds a little bit of overhead.
Um now in practice what's happening is
Um now in practice what's happening is
it just doesn't learn properly when you
it just doesn't learn properly when you
set it
set it
longer. And I think let me make sure
longer. And I think let me make sure
that this makes sense. I think that the
that this makes sense. I think that the
reason it doesn't learn, we have how
reason it doesn't learn, we have how
many M's
here, let's
see, 124
see, 124
environments in a batch size
environments in a batch size
ofund. So, it's 128 steps per
ofund. So, it's 128 steps per
environment that are uh in the rollouts.
So if we
So if we
assume that the environments take longer
assume that the environments take longer
than 128 steps, which they mostly do,
than 128 steps, which they mostly do,
you can see at the episode length, then
you can see at the episode length, then
when you compute the
when you compute the
value for
value for
uh like the last 127 steps, you're
uh like the last 127 steps, you're
actually going to be pulling data in
actually going to be pulling data in
from the next environment by accident,
from the next environment by accident,
which you don't want.
which you don't want.
So I think that that is what is
So I think that that is what is
happening here is that you are pulling
happening here is that you are pulling
in data from environments that you
in data from environments that you
shouldn't be looking at because we can't
shouldn't be looking at because we can't
separate boundary conditions the way we
separate boundary conditions the way we
want
want
to. Mind you, it still actually learns
to. Mind you, it still actually learns
just doesn't learn anywhere near as
just doesn't learn anywhere near as
well. Okay.
well. Okay.
So is there an easy way to confirm this?
I don't think
so. I don't think so. I think we have to
so. I don't think so. I think we have to
update the kernel which is annoying.
How do we update
it? I guess it would just be
There's going to be a little bit of
There's going to be a little bit of
fiddly algorithm development for the
fiddly algorithm development for the
next bit here, but it's going to be
next bit here, but it's going to be
important. This could be the thing that
important. This could be the thing that
makes this
makes this
algorithm what it's supposed to be.
I just need to make sure I get it
I just need to make sure I get it
right. Taking different environment
right. Taking different environment
actions. It's not that it's taking
actions. It's not that it's taking
different environment actions. So this
different environment actions. So this
is in the computation of the advantage
is in the computation of the advantage
function. Normally when you compute an
function. Normally when you compute an
advantage function, you start at the
advantage function, you start at the
last time step you have from each
last time step you have from each
environment and then you roll it
environment and then you roll it
backwards. But uh what happens here is
backwards. But uh what happens here is
that you've collected trajectories for a
that you've collected trajectories for a
lot of different environments and you
lot of different environments and you
haven't gotten the done signals from
haven't gotten the done signals from
them yet. So they're just in the buffer
them yet. So they're just in the buffer
partially completed and since there's no
partially completed and since there's no
stop at the end of them uh which it's
stop at the end of them uh which it's
kind of hard to add a stop in this
kind of hard to add a stop in this
situation. It's going to use information
situation. It's going to use information
from the next environment to compute the
from the next environment to compute the
advantage and that gives you a wrong
advantage and that gives you a wrong
calculation. This effect is mitigated in
calculation. This effect is mitigated in
uh generalized advantage estimation
uh generalized advantage estimation
somewhat but uh it's going to be much
somewhat but uh it's going to be much
more important in this algorithm. To be
more important in this algorithm. To be
fair, maybe it affects generalized
fair, maybe it affects generalized
advantage estimation as well. Maybe our
advantage estimation as well. Maybe our
PPO just gets better from this too,
PPO just gets better from this too,
which would be
which would be
fine. Which would be
fine. But yeah, I think what we're going
fine. But yeah, I think what we're going
to do is we're going to have to pass
to do is we're going to have to pass
sort keys cuz this sort keys
thing, it's kind of tricky to calculate
thing, it's kind of tricky to calculate
those bounds.
those bounds.
Honestly, kind of tricky.
Honestly, kind of tricky.
You can't wait for the buffer to
You can't wait for the buffer to
complete. It doesn't work that way. The
complete. It doesn't work that way. The
buffer just stores all of the data
flat. I mean, well, I maybe you can
flat. I mean, well, I maybe you can
maybe I'm being a little bit too
maybe I'm being a little bit too
dismissive. Let me
think. I don't know how you would
The thing is you ne you also wouldn't
The thing is you ne you also wouldn't
necessarily want to because you have to
necessarily want to because you have to
wait for the ms to finish. You can't do
wait for the ms to finish. You can't do
full environment rollouts, right? Some
full environment rollouts, right? Some
environments just take a very long time
environments just take a very long time
to run. So you do need to have
to run. So you do need to have
environment segments.
environment segments.
And this is basically there's no cap on
And this is basically there's no cap on
the end of the segment. It's kind of
the end of the segment. It's kind of
hard to add a
cap, but I like I have a way of doing it
cap, but I like I have a way of doing it
at the moment. I just have to figure out
at the moment. I just have to figure out
it involves a little bit of fiddly index
it involves a little bit of fiddly index
checking. And then I have to actually do
checking. And then I have to actually do
this fiddly index checking in CUDA,
this fiddly index checking in CUDA,
which is
which is
annoying. Um, but if I can figure
out, maybe it's not that bad. If I can
out, maybe it's not that bad. If I can
figure this
figure this
out. Well, hang on. I don't
out. Well, hang on. I don't
have this. Just returns the
indices. That's
rough. I think you sort by N by ID and
rough. I think you sort by N by ID and
then by time step, right?
It' be so much easier to just add
um like you have a truncated signal for
um like you have a truncated signal for
this, don't
this, don't
you? Like wouldn't it be so much easier
you? Like wouldn't it be so much easier
to just
to just
add truncated signal
here? I mean, I can technically do it
here? I mean, I can technically do it
here as a hack and then implement it
here as a hack and then implement it
more generally if it
more generally if it
works. That might do
works. That might do
it. Maybe extend compute
it. Maybe extend compute
time when the buffer
time when the buffer
finishes. Extend compute time. I don't
finishes. Extend compute time. I don't
know how you do that. It's the problem's
know how you do that. It's the problem's
kind of
like it's not that you need more data
like it's not that you need more data
than you have. It's just that you need
than you have. It's just that you need
to know when to stop with the data that
to know when to stop with the data that
you do have. You're basically
you do have. You're basically
overrunning the buffer. I actually So
overrunning the buffer. I actually So
this doesn't work generally because you
this doesn't work generally because you
have asynchronous environments. But I
have asynchronous environments. But I
think that in this case I might have a
think that in this case I might have a
quick
quick
hack if I can just do
D +
T. How do you not
T. How do you not
log? you do log d
here because you don't handle truncated
here because you don't handle truncated
at all.
Okay. I think I have a way to hack it
Okay. I think I have a way to hack it
for now that will let me run my
for now that will let me run my
experiments and see if this actually
matters. Define the number of steps if
matters. Define the number of steps if
you want it to work.
you want it to work.
going to work as
going to work as
intended. So, I don't mind. Yeah. So,
intended. So, I don't mind. Yeah. So,
it's a little fiddly because the thing
it's a little fiddly because the thing
is in the general case, you have
is in the general case, you have
environments that are running in
environments that are running in
different
different
speeds and uh you just get you basically
speeds and uh you just get you basically
just get a bunch of flat data that you
just get a bunch of flat data that you
don't have any way to organize until you
don't have any way to organize until you
have all of it. But then when you have
have all of it. But then when you have
all of it, right, each environment,
all of it, right, each environment,
maybe you've collected some full
maybe you've collected some full
episodes, but then each environment has
episodes, but then each environment has
a piece at the end that kind of hangs
a piece at the end that kind of hangs
off and you don't have any way of
off and you don't have any way of
telling that. I mean, like I have the
telling that. I mean, like I have the
general purpose way of fixing this is to
general purpose way of fixing this is to
fiddle with the indices and um propagate
fiddle with the indices and um propagate
that change into CUDA and then the issue
that change into CUDA and then the issue
should be fixed. But
should be fixed. But
um before then it's a little hard.
I say
10:24. 1024. So
Let's do it this
way. Experience
way. Experience
pointer batch size
minus. Uh, you can't do that. So, I got
minus. Uh, you can't do that. So, I got
to do
to do
We'll just hard code.
Okay, let's see. Uh let's see what this
Okay, let's see. Uh let's see what this
does for comparison.
Yeah, if this is not going to be like an
Yeah, if this is not going to be like an
instantaneous
instantaneous
fix.
fix.
Huh? Hang
Huh? Hang
on. Oh, no. It's pretty darn close to
on. Oh, no. It's pretty darn close to
the original
the original
curve. We'll see if it breaks away. if
curve. We'll see if it breaks away. if
there's like a big
there's like a big
difference. Maybe this is not the issue
difference. Maybe this is not the issue
though. We'll see.
This could totally also be a
This could totally also be a
normalization issue, couldn't
normalization issue, couldn't
it? Let's go look at
it? Let's go look at
that. How do we compute
stuff? Oh, wait. Actually, I think I
stuff? Oh, wait. Actually, I think I
might know.
might know.
missing
advantage. Yeah. So the advantage
advantage. Yeah. So the advantage
is we make those sum to
one
but we don't
but we don't
bother with the other loss making that
bother with the other loss making that
sum to one. Okay, hang
sum to one. Okay, hang
on.
on.
So how do we test
that? I guess what we do is
be
lost. Okay, so this actually does do
lost. Okay, so this actually does do
better. I don't know if it's
better. I don't know if it's
significantly better, but we will see.
significantly better, but we will see.
The next thing I want to try is this in
The next thing I want to try is this in
which we mask the value
loss. And we'll see what this
loss. And we'll see what this
does. Essentially, this would say that
does. Essentially, this would say that
hey, the problem
hey, the problem
is the problem is not in the advantage
is the problem is not in the advantage
function. The problem's right here. This
function. The problem's right here. This
worked.
Oh, this is
worse. How's that possible,
worse. How's that possible,
right? Did I mess something
up? Shouldn't be possible for this to be
up? Shouldn't be possible for this to be
worse.
Okay, it catches back up. It has a weird
Okay, it catches back up. It has a weird
curve
though. Very weird
though. Very weird
curve. Yeah, these are still definitely
curve. Yeah, these are still definitely
different. I'm going to run it again
different. I'm going to run it again
just because there's crazy seed variance
just because there's crazy seed variance
in RL sometimes, but I'm guessing Okay.
interesting.
So, we should probably check to make
So, we should probably check to make
sure that the original still works under
sure that the original still works under
this condition, right?
So, I can't think of
So, I can't think of
why why
why why
else this doesn't work. Unless I've
else this doesn't work. Unless I've
messed up the indexing, which would be
messed up the indexing, which would be
hilarious in its own way. But looking at
hilarious in its own way. But looking at
this, the curves are actually relatively
this, the curves are actually relatively
consistent.
The curves are relatively
consistent. Is it actually possible I
consistent. Is it actually possible I
messed up the ordering of this?
That would be really out there.
Okay, we'll try this as a baseline.
Okay, we'll try this as a baseline.
Whoops, not this one. Hold
on. Okay, we'll let that run.
on. Okay, we'll let that run.
buffer
buffer
size. It's not that
size. It's not that
anymore. There's something else weird
anymore. There's something else weird
going on that we have to figure out.
going on that we have to figure out.
Reply to this guy real quick.
I'll do it here. This one makes more
I'll do it here. This one makes more
sense.
I it drives me nuts because the thing is
I it drives me nuts because the thing is
it's not that these things aren't
it's not that these things aren't
important. It's that in the context that
important. It's that in the context that
they were brought up, they're completely
they were brought up, they're completely
irrelevant.
Oops. Let's get rid of that
Oops. Let's get rid of that
bot. Stupid
bot. Stupid
thing. Victorious. Yeah, great username.
thing. Victorious. Yeah, great username.
That
Okay. Yeah.
preprint. There's a blog
And the funny thing about this is that
And the funny thing about this is that
all this conversation does is like
all this conversation does is like
reinforces that a lot of safety research
reinforces that a lot of safety research
are just very unserious people.
It's like mandate of heaven must do
It's like mandate of heaven must do
safety in all things even where safety
safety in all things even where safety
is not even a remotely a
concern. Okay. So this original here
concern. Okay. So this original here
this still works. So that's very
this still works. So that's very
interesting, right? This original
interesting, right? This original
here still pretty well works. Yeah, this
here still pretty well works. Yeah, this
is about the same as
is about the same as
before. Don't want their internal
before. Don't want their internal
data. This again, it's not what this is.
data. This again, it's not what this is.
I mean, this is literally godfather of
I mean, this is literally godfather of
RL giving his opinion on like what
RL giving his opinion on like what
directions are promising or not. if you
directions are promising or not. if you
want to understand intelligence and it's
want to understand intelligence and it's
like yeah I don't think safety is
like yeah I don't think safety is
particular like safety or privacy are
particular like safety or privacy are
particularly relevant here and it's like
particularly relevant here and it's like
ah but this is morally distasteful that
ah but this is morally distasteful that
you haven't considered safety and
you haven't considered safety and
privacy in not deploying AI but in
privacy in not deploying AI but in
sitting in your lab doing algorithms
research. I mean this is like ah but you
research. I mean this is like ah but you
in your lab did you think of the
in your lab did you think of the
children in Africa while you were doing
children in Africa while you were doing
that? It's like, okay, maybe I thought
that? It's like, okay, maybe I thought
about them another time, but now not now
about them another time, but now not now
specifically because there's no
specifically because there's no
relevance whatsoever, right? It's just
relevance whatsoever, right? It's just
like, this is the problem that you see
like, this is the problem that you see
though with a lot of the safety folks is
though with a lot of the safety folks is
it's just moral grandstanding where it's
it's just moral grandstanding where it's
completely
completely
unjustified. A lot of the times it's
unjustified. A lot of the times it's
like, yeah, you're also sitting in your
like, yeah, you're also sitting in your
lab writing algorithms, but you're being
lab writing algorithms, but you're being
holier than thou about it and insulting
holier than thou about it and insulting
other researchers.
Ridiculous. Well, that was at least the
Ridiculous. Well, that was at least the
most respectful conversation I've had
most respectful conversation I've had
with somebody in in safety. So, I'll
with somebody in in safety. So, I'll
give it that. I just It's just a
give it that. I just It's just a
Byzantine argument to me, though. It's a
Byzantine argument to me, though. It's a
Byzantine argument. Probably to slow
Byzantine argument. Probably to slow
down progress. Now, if we want to get on
down progress. Now, if we want to get on
moral high ground, that I cannot accept
moral high ground, that I cannot accept
because we're building tech that
because we're building tech that
genuinely improves a lot of stuff. And
genuinely improves a lot of stuff. And
this will get into medicine. This will
this will get into medicine. This will
get into a ton of really important
get into a ton of really important
areas. That's why I get up in the
areas. That's why I get up in the
morning. All right. So, slowing down
morning. All right. So, slowing down
progress. No, no quarter giving.
I don't know. There are a lot of like
I don't know. There are a lot of like
really crazy ideas on these topics as
really crazy ideas on these topics as
well that are like mainly SF bros being
well that are like mainly SF bros being
very very very out of touch with
very very very out of touch with
reality. This wasn't that to be fair.
reality. This wasn't that to be fair.
This was somewhat more down to earth,
This was somewhat more down to earth,
but still
but still
it's there's
it's there's
like it's just not getting
through. Well, we have a clear clearcut
through. Well, we have a clear clearcut
example here
example here
of what's going
wrong. There are a couple possibilities,
wrong. There are a couple possibilities,
I guess.
I guess.
So let me think here we get values
So let me think here we get values
mean values standard
deviation of indices
here. And then we pass this
in to the advantage
function. Does this get done
function. Does this get done
twice? I think it gets done twice,
right?
Those are the blocks we need to move
Those are the blocks we need to move
past. Find this happening in government
past. Find this happening in government
security a lot. Probably spoken a lot of
security a lot. Probably spoken a lot of
them. Yeah.
them. Yeah.
And it's just
like the thing that drives me crazy is
like the thing that drives me crazy is
that like the thing that they say that
that like the thing that they say that
they're worried about doesn't even make
they're worried about doesn't even make
sense if you use their own arguments,
sense if you use their own arguments,
right? They say like we should slow down
right? They say like we should slow down
tech in order to make sure stuff is
tech in order to make sure stuff is
safe, right? And then they like they
safe, right? And then they like they
talk about like, you know, doomer type
talk about like, you know, doomer type
stuff. It's like, well, okay, this
stuff. It's like, well, okay, this
doesn't even make sense from your
doesn't even make sense from your
perspective because even if we were to
perspective because even if we were to
suppose that the concerns that you're
suppose that the concerns that you're
raising, which may or may not even hold
raising, which may or may not even hold
any water, if even if we assume you're
any water, if even if we assume you're
100% correct about everything and like
100% correct about everything and like
AI is going to destroy everything if we
AI is going to destroy everything if we
do it wrong and like AI is going to get
do it wrong and like AI is going to get
into all the bad applications and
into all the bad applications and
whatever, if you slow it down, China or
whatever, if you slow it down, China or
another country is just going to do it
another country is just going to do it
first. Do you think they care about any
first. Do you think they care about any
of this stuff? No. No, they
don't. So, you're just guaranteeing that
don't. So, you're just guaranteeing that
it's done, you know, in the exact way
it's done, you know, in the exact way
that you don't want by slowing it down.
that you don't want by slowing it down.
That's
all. It makes no sense to me at
all. It's like a very, very weird
all. It's like a very, very weird
academic perspective.
Let me try one other
thing. Can I even do
thing. Can I even do
this values man?
this values man?
think I
can. Yeah, this will work if I just
do academic people. It is
weird. Well, but the thing is nobody's
weird. Well, but the thing is nobody's
telling you that you have to expose like
telling you that you have to expose like
nobody's telling you that you have to,
nobody's telling you that you have to,
right? It's an invented concern. If you
right? It's an invented concern. If you
don't want to use tech that leaks data,
don't want to use tech that leaks data,
don't use the tech.
And also like privacy stuff going wrong
And also like privacy stuff going wrong
is more like big supervised ML people,
is more like big supervised ML people,
not RL people anyway. So it's
not RL people anyway. So it's
moot. I haven't really seen anything
moot. I haven't really seen anything
like this in RL going wrong.
We'll see what this
We'll see what this
does. If this doesn't work, then there's
does. If this doesn't work, then there's
a data
a data
problem. This doesn't work, then there
problem. This doesn't work, then there
should be a data
problem. But the Pokemon stuff's doing
problem. But the Pokemon stuff's doing
pretty nice.
Okay. So, we shouldn't build gradient
descent. It just that just doesn't make
descent. It just that just doesn't make
any sense.
Yeah, that's very
Yeah, that's very
weird. This is
weird. This is
funny. I love it when he just sets me up
funny. I love it when he just sets me up
for
for
this. Thanks for the ad, Sam.
lots of assumptions without oh the uh
lots of assumptions without oh the uh
the net hack thing. Yeah, it's well the
the net hack thing. Yeah, it's well the
other thing that's just like is kind of
other thing that's just like is kind of
bullshitty here. So Tim is a Google
bullshitty here. So Tim is a Google
DeepMind researcher, right? He has he
DeepMind researcher, right? He has he
runs a team at DeepMind. So like yeah,
runs a team at DeepMind. So like yeah,
they've got all the compute in the world
they've got all the compute in the world
to do whatever they want and like armies
to do whatever they want and like armies
of people on the internet who are going
of people on the internet who are going
to go run evaluations on their stuff
to go run evaluations on their stuff
because LLMs are currently the hot
because LLMs are currently the hot
thing, right? But like the stuff we're
thing, right? But like the stuff we're
doing nobody else is doing and like know
doing nobody else is doing and like know
there's a lot of potential that you're
there's a lot of potential that you're
wrong and that we're going to come up
wrong and that we're going to come up
with some cool generalizable methods
with some cool generalizable methods
because we can run experiments in RL a
because we can run experiments in RL a
thousand times faster than the vast
thousand times faster than the vast
majority of researchers were ever able
majority of researchers were ever able
to run experiments in RL. Right? You do
to run experiments in RL. Right? You do
a thousand times more experiments. So
a thousand times more experiments. So
you're going to uncover some cool stuff
you're going to uncover some cool stuff
probably.
probably.
Um so I don't know. It's like Tim used
Um so I don't know. It's like Tim used
to do uh used to do like pure RL stuff
to do uh used to do like pure RL stuff
and kind of just went all the way onto
and kind of just went all the way onto
LLM
train. I think that the LLMs are
train. I think that the LLMs are
currently taking too many resources away
currently taking too many resources away
from the rest of research. Like don't
from the rest of research. Like don't
get me wrong, what's going on is kind of
get me wrong, what's going on is kind of
crazy with them, but they should take
crazy with them, but they should take
80% of the research uh resources from
80% of the research uh resources from
research, not 99% of the
resources. Okay, perfect. So, this is a
resources. Okay, perfect. So, this is a
clearcut case of unless I'm missing
clearcut case of unless I'm missing
anything. I don't think I am. This is a
anything. I don't think I am. This is a
clearcut
clearcut
case. Something's just
case. Something's just
brewy right
here. Okay.
So, B flat
values
mean B values
mean. There's no way this should be
mean. There's no way this should be
different. This should be identical to
different. This should be identical to
the previous.
This is exciting though because if
This is exciting though because if
there's actually a bug and it's already
there's actually a bug and it's already
working this
working this
well, just a tactic to slow things
well, just a tactic to slow things
down. They didn't have anything to say
down. They didn't have anything to say
when LM are being
when LM are being
trained now that they aren't post
trained now that they aren't post
training. I wouldn't say that so much
training. I wouldn't say that so much
because a lot of the LLM people, there
because a lot of the LLM people, there
are LLM people that are like
are LLM people that are like
legitimately just full steam ahead
legitimately just full steam ahead
trying to make AI work, right? But the
trying to make AI work, right? But the
thing that they don't realize is the way
thing that they don't realize is the way
to do that, like you don't need to crowd
to do that, like you don't need to crowd
out the rest of AI. You already have all
out the rest of AI. You already have all
the resources, right?
the resources, right?
Like I just like leave a couple scraps
Like I just like leave a couple scraps
so we can investigate some other areas
so we can investigate some other areas
in case you're wrong, right?
Do you know how much easier it would be
Do you know how much easier it would be
to do what I'm doing right now with
to do what I'm doing right now with
Puffer? If I were doing this
Puffer? If I were doing this
in
in
2018, like when RL was all the rage,
2018, like when RL was all the rage,
we'd have like dozens and dozens of
we'd have like dozens and dozens of
people building these environments. Like
people building these environments. Like
RL would actually be so so far ahead.
RL would actually be so so far ahead.
Heck, you know, if OpenAI had just left
Heck, you know, if OpenAI had just left
left their Dota team alone and let them
left their Dota team alone and let them
keep doing some RL and keep pushing out
keep doing some RL and keep pushing out
some results, we'd be in a good place
some results, we'd be in a good place
even now. It's just that like all the
even now. It's just that like all the
resources were drained out of RL. And um
resources were drained out of RL. And um
you know, it's fine. Like I'm fixing it
you know, it's fine. Like I'm fixing it
now, but it's it's a heck of a lot of
now, but it's it's a heck of a lot of
work and it's a lot more work than it
work and it's a lot more work than it
had to have
had to have
been. Unfortunately, you know, back in
been. Unfortunately, you know, back in
20 uh like 2018, I was like a plucky 20
20 uh like 2018, I was like a plucky 20
year old who didn't have the uh the
year old who didn't have the uh the
engineering skills to do all of this,
engineering skills to do all of this,
which is why I couldn't do it back then.
which is why I couldn't do it back then.
But uh you know, now I do have the
But uh you know, now I do have the
skills, but okay, you know, stuff's
skills, but okay, you know, stuff's
cooled down a little bit. So, bad
cooled down a little bit. So, bad
timing, but we'll get it working
timing, but we'll get it working
anyways.
damn their compute for commercial
damn their compute for commercial
purposes.
Yeah. Well, with Puffer now, we don't
Yeah. Well, with Puffer now, we don't
need a ton of compute to be running all
need a ton of compute to be running all
these experiments, which is the cool
these experiments, which is the cool
thing. We still need a little bit. And
thing. We still need a little bit. And
we need a little bit more than we have
we need a little bit more than we have
now. So, I'm dealing with fixing that.
now. So, I'm dealing with fixing that.
Uh I'm going to be fixing that pretty
Uh I'm going to be fixing that pretty
soon.
But yeah,
Where does this get
used values
mean? We get B values
mean? We get B values
mean,
right? So how then does this get messed
right? So how then does this get messed
up?
And something's clearly very
wrong. So we debug
wrong. So we debug
this new value mean new value
this new value mean new value
std reward block
right be reward
block. Oh, hang
on. I think I see
it. Wait. Reward block master
it. Wait. Reward block master
block
advantages block.
Isn't this it right
here? Isn't this of
here? Isn't this of
idxes or is it
not? Wait. Reward
not? Wait. Reward
block. Mask block.
Hang
on. Oh, it probably gets copied as Y,
right? Yeah, hang on. It probably just
right? Yeah, hang on. It probably just
gets copied.
So, how do I do this
then? Let me try something else.
Maybe if I do it this way.
I times horizon. No, this still doesn't
I times horizon. No, this still doesn't
work. No point in even trying
work. No point in even trying
that.
Um, that's rough.
I do this. Does this do anything?
Missing
horizon. Maybe we don't have a straight
horizon. Maybe we don't have a straight
up bug
yet. But it is
suspicious. It is suspicious.
We shall see.
Okay. Is this
something?
Hello. Oh, wrong
one. So, it's still screwy, huh?
one. So, it's still screwy, huh?
Unless it's going to dissolve it right
Unless it's going to dissolve it right
now, but I don't think
so. So
so. So
there's I guess to explain what's
there's I guess to explain what's
happening
happening
here. Um the algorithm has a horizon
here. Um the algorithm has a horizon
parameter. It performs way way it should
parameter. It performs way way it should
strictly perform better with longer
strictly perform better with longer
horizon. it performs pretty much way
horizon. it performs pretty much way
worse with larger uh larger
worse with larger uh larger
horizon
horizon
and like setting it to longer horizon
and like setting it to longer horizon
but then nulling out the effect of what
but then nulling out the effect of what
should be happening with the extra extra
should be happening with the extra extra
time steps doesn't
time steps doesn't
help. So
essentially something is broken about
essentially something is broken about
the way that it
the way that it
is. Something's just fundamentally
is. Something's just fundamentally
broken about the implementation and I'm
broken about the implementation and I'm
trying to figure out
what mass
what mass
block. Word block. Mass block.
I've checked this portion of the code to
I've checked this portion of the code to
death, haven't
I? B
values
values
flat turns
You pass these in nicely sorted
You pass these in nicely sorted
already. Word block and mass block get
already. Word block and mass block get
passed in.
Unless I have this
wrong. I wonder if this is
wrong. I
think this could be wrong, couldn't it?
Wait, where's BPT Horizon
Wait, where's BPT Horizon
here?
here?
Reshape. Uhoh.
Okay, you you use this in a
Okay, you you use this in a
flat output
here. This could be it,
here. This could be it,
right? That you have this messed up.
Use returns
just
reshape mini batches.
reshape mini batches.
mini batch
size. It's tough to know. Like, it's
size. It's tough to know. Like, it's
tough when you don't know for sure.
Why does this even need to be reshaped
again? Bet rows. Nin
batches. It seems weird to
batches. It seems weird to
me. that this uh that you even need that
me. that this uh that you even need that
transpose, doesn't
We can just look at
We can just look at
these. We might be able to get something
these. We might be able to get something
just out of this. Let's take Neptune
just out of this. Let's take Neptune
off. Close this down.
Fiddly debugging. Fiddly debugging.
Okay, this one is the same.
And these are the
same. I'm trying to think what else it
same. I'm trying to think what else it
would be
though.
Hang on. Maybe we need to look a little
Hang on. Maybe we need to look a little
bit more closely.
Try
Try
this Neptune back on as well.
That should definitely compute the same
That should definitely compute the same
thing as as uh
thing as as uh
before. I'm going have to remember to
before. I'm going have to remember to
just take that out immediately so I
just take that out immediately so I
don't
forget. It's a little
silly. The notifications just keep
silly. The notifications just keep
rolling on these. That's crazy.
Yeah, but Atari 100K was just a
Yeah, but Atari 100K was just a
god-awwful
benchmark. Okay, this may be something.
Okay, maybe this actually
works. Yeah. Okay. So, this actually
works. Yeah. Okay. So, this actually
works. Interesting.
So, it is the fact that you're using the
So, it is the fact that you're using the
additional data that screws you
up that this makes sense. Here's a rest.
up that this makes sense. Here's a rest.
I'll be right back and then we'll think
I'll be right back and then we'll think
about what that means.
Oops. A little hiccup at the end of the
Oops. A little hiccup at the end of the
training there, but that's way closer.
training there, but that's way closer.
So, it is
So, it is
legitimately that including the extra
legitimately that including the extra
data somehow messes you
data somehow messes you
up. Hey, I can deal with that. At least
up. Hey, I can deal with that. At least
there's a target to hit.
[Music]
X
Oh, hang on. Is this what you
want? I think this is what you want.
Didn't you just completely clip this
wrong? I think you just massively
wrong? I think you just massively
screwed up your clipping factor.
Vantage
scale B
max. Why would you do that?
Oh, I think it's because um Hang
on. Yeah. No, I think you just messed up
on. Yeah. No, I think you just messed up
the way that you were trying to wait
the way that you were trying to wait
this thing, didn't you?
So let me let me look at
this value standard deviation.
Advantage
scale. Hang on.
Max minus standard deviation over
delta. How's that make
delta. How's that make
sense? You just do this one, right? And
sense? You just do this one, right? And
then if anything, you're supposed to
then if anything, you're supposed to
clip later on. Let's let's run this and
clip later on. Let's let's run this and
see what happens.
Now, I remember what I was trying to do
Now, I remember what I was trying to do
with this, but I don't think I actually
with this, but I don't think I actually
implemented
implemented
it correctly.
it correctly.
Holy, these just notifications just keep
Holy, these just notifications just keep
going.
Yeah, I'm updating my take on this
Yeah, I'm updating my take on this
following the responses to this.
following the responses to this.
Um, the thing that makes me now more
Um, the thing that makes me now more
suspicious of LMS is the types of
suspicious of LMS is the types of
comments I get from people that are
comments I get from people that are
clearly using them heavily. Holy
hell. There's some of these out.
I mean, it was a comment more about
I mean, it was a comment more about
programming in general. It's just
programming in general. It's just
like you get better at programming and
like you get better at programming and
you understand how to solve more
you understand how to solve more
problems by getting closer to the
problems by getting closer to the
hardware, not by like pretending it
hardware, not by like pretending it
doesn't exist and programming in
doesn't exist and programming in
English. That's not even a phrase that
English. That's not even a phrase that
makes
sense. It's like, yeah, eventually I can
sense. It's like, yeah, eventually I can
do all the programming and everything
do all the programming and everything
else, but that doesn't mean that like,
else, but that doesn't mean that like,
oh yeah, now we do whatever. It's like,
oh yeah, now we do whatever. It's like,
no, you have no added value
whatsoever. It's like you're bragging
whatsoever. It's like you're bragging
that you didn't learn anything and now
that you didn't learn anything and now
you can do something that previously
you can do something that previously
took training worse than somebody who's
took training worse than somebody who's
trained at it.
Congratulations. You're basically
Congratulations. You're basically
bragging that you're lazy and you don't
bragging that you're lazy and you don't
want to learn anything.
All right, here we
All right, here we
are. Okay, so we can cut this norm
are. Okay, so we can cut this norm
factor out, I guess. I don't know what I
factor out, I guess. I don't know what I
was trying to do with this, but uh it
was trying to do with this, but uh it
doesn't really make sense, whatever it
doesn't really make sense, whatever it
is. I think it was like legacy,
is. I think it was like legacy,
honestly, from when I
had Let me
had Let me
see. I'll use
see. I'll use
mean. Yeah, this must have been
legacy. I think the issue is
legacy. I think the issue is
um was with this scale, wasn't
um was with this scale, wasn't
it? Minus V standard deviation.
it? Minus V standard deviation.
Wait. VSTD
Max. Oh, of
course. Of course I get bitten for like
course. Of course I get bitten for like
of course I uh I get penalized for this
of course I uh I get penalized for this
freaking
freaking
llm. The one time I actually tried to uh
llm. The one time I actually tried to uh
to just translate a piece of code, not
to just translate a piece of code, not
even to write new code, just to
even to write new code, just to
translate code, I get dinged for it. Of
translate code, I get dinged for it. Of
course. serves me
right. What I was trying to do
right. What I was trying to do
originally
here, B standard deviation minus
buff. Thank
buff. Thank
you. This is going to be a very
you. This is going to be a very
unstable sort of situation, isn't
unstable sort of situation, isn't
it? Maybe not.
Okay, let me think about how we
Okay, let me think about how we
normalize this because this is all in
normalize this because this is all in
the norm.
Now you have a distribution
Does this need to be normal to
Huh? It would seem weird to normalize
Huh? It would seem weird to normalize
this to one.
How weird is it that if you norm it to
How weird is it that if you norm it to
one
Not that weird
Not that weird
actually. I think we should try it.
subtract the
subtract the
min and you divide by the
min and you divide by the
max minus the min,
right? But that doesn't penalize uh
right? But that doesn't penalize uh
uncertainty either.
Why can't this just be
Why can't this just be
VFPD minus VFPD
min? Like is there a problem with
this? Oops. What happened here?
Oh, yeah. This totally works,
right? Except that you have it Wait, you
right? Except that you have it Wait, you
have it backwards here. So, it's got to
be Yeah, it's got to be like this. Max
be Yeah, it's got to be like this. Max
minus
min. So you subtract them in, you divide
min. So you subtract them in, you divide
by this delta. So you linearize
um you just linearize
um you just linearize
this and then you
this and then you
divide that they sum to one.
We'll see how that plays out.
CUDA
error device side
assert.
Lovely probability contains in or nan.
Subtract men divide by
Subtract men divide by
delta advantage
sum.
Lovely. Halfway decent
engineer. I was like, what the hell?
engineer. I was like, what the hell?
Halfway decent engineer. What the hell
Halfway decent engineer. What the hell
do you see me deving right here?
have to deal with coup errors which is
have to deal with coup errors which is
always
fun. It's probably all in just this
fun. It's probably all in just this
advantage scale
advantage scale
thing. Wouldn't be surprised.
We'll have to do a little bit of
We'll have to do a little bit of
separate normalization on the uh other
separate normalization on the uh other
part of the value function
part of the value function
but be fine
otherwise still yeah cuda error
otherwise still yeah cuda error
lovely all right what's going to nanner
lovely all right what's going to nanner
in for whatever
here maxus
and BSTD minus
um I don't understand what it would be
um I don't understand what it would be
that would be out of bounds
that would be out of bounds
here. It's got to be the sum is zero,
here. It's got to be the sum is zero,
right?
But that's sketchy as hell.
Okay. So it is this thing somehow being
Okay. So it is this thing somehow being
zero which
is means that this thing somehow has to
be this thing somehow has to be zero.
crazy that that actually kind of learns.
I think we want to just
I think we want to just
subtract not the overall
And vantage scale.
I think we want to do this a little
differently. The SGD men
about to make an order for personal
about to make an order for personal
machine. Well, I know that I ordered my
machine. Well, I know that I ordered my
machine a long time ago and haven't
machine a long time ago and haven't
gotten it
yet. So, I would check on how long it
yet. So, I would check on how long it
takes him to get you the machine.
takes him to get you the machine.
I haven't heard anything specifically on
I haven't heard anything specifically on
the power cable issues, but yeah, I
the power cable issues, but yeah, I
think it's still an issue.
8 to 12 weeks.
Crazy. Yeah. I don't know what we're
Crazy. Yeah. I don't know what we're
going to do with compute with the uh the
going to do with compute with the uh the
mess this thing's been
in. I mean, I don't think I should have
in. I mean, I don't think I should have
just like ordered all the
just like ordered all the
machines like day one.
without testing to see if they even
without testing to see if they even
work. That would have been a nightmare,
work. That would have been a nightmare,
but takes a while.
Okay. So we compute this.
Okay. Try this.
Whoops. That has to be
deleted.
deleted.
T. Why don't I do T?
forget the trailing
forget the trailing
comm. There we go.
So now this is going to be normalized to
So now this is going to be normalized to
uh the individual
uh the individual
row. That will give you a lot more
row. That will give you a lot more
stable time stepwise
stable time stepwise
estimate. I don't think it messes
estimate. I don't think it messes
anything up. We'll see.
138 likes on the uh the tweet from today
138 likes on the uh the tweet from today
on uh
Pokemon. Not bad for the day two one.
Pokemon. Not bad for the day two one.
So that's
So that's
another 4,000 some odd
another 4,000 some odd
views. We're doing good advertising for
views. We're doing good advertising for
Pokemon
still
still
runs
782. Now
782. Now
what? I should be able to get rid of
what? I should be able to get rid of
this term, right? That'll tell me
this term, right? That'll tell me
something if this still crashes.
Yeah. So, this should not change PF very
Yeah. So, this should not change PF very
much at
much at
all. Uh if it even has any effect. It
all. Uh if it even has any effect. It
really shouldn't do anything. But, uh
really shouldn't do anything. But, uh
the fact that the kernel was crashing
the fact that the kernel was crashing
before was an issue.
before was an issue.
This should now be reasonably
correct. Yeah, it looks nice.
Okay.
Okay.
Now, is this
Now, is this
enough? I mean, we now
enough? I mean, we now
have
linearized we have linearized
linearized we have linearized
advantages.
So, I mean, we should in theory just be
So, I mean, we should in theory just be
able to set
able to set
this back to horizon 128 steps and it
this back to horizon 128 steps and it
should work
theory and if not, we'll have to look at
theory and if not, we'll have to look at
why. Yeah, these latest graphs are uh we
why. Yeah, these latest graphs are uh we
have any graphs on this or is this
have any graphs on this or is this
offline? Okay, I didn't log in to
offline? Okay, I didn't log in to
Neptune,
but this will be reasonable. Now, mind
but this will be reasonable. Now, mind
you, the when we change the algorithm at
you, the when we change the algorithm at
all, uh it's optimized for a specific
all, uh it's optimized for a specific
set of hyperparameters. So, little perf
set of hyperparameters. So, little perf
dip is kind of
dip is kind of
okay if we think it's going to make it
okay if we think it's going to make it
more robust. So, we can always
more robust. So, we can always
retune. Big PF dip should not really
retune. Big PF dip should not really
happen.
We
We
go. And there we And it solves anyways.
go. And there we And it solves anyways.
There you
There you
go. Basically
solves
840. Next will be
and presumably this screws stuff up,
and presumably this screws stuff up,
right? Because it always
does. But now we at least have some way
does. But now we at least have some way
of looking at uh
of looking at uh
What's getting screwed up and
why? All
why? All
right. Yeah. So, this is again way
worse. I am curious to see if it's going
worse. I am curious to see if it's going
to line up with the previous curves
to line up with the previous curves
though or if there will at least be some
difference. I'll be right back while
difference. I'll be right back while
this runs
400 score. Just in time to see 400
score. Very much in line with the
score. Very much in line with the
previous.
previous.
Okay. A little better. Probably not
Okay. A little better. Probably not
statistically significant.
statistically. What's in buffer? Buffer
statistically. What's in buffer? Buffer
contains the advantage skills, doesn't
contains the advantage skills, doesn't
it? Buffer contains advantage
skills. So, if I just go
here's this
thing. No, it's um P30 should work. It
thing. No, it's um P30 should work. It
should work the same or better if you
should work the same or better if you
increase the horizon. And there's
increase the horizon. And there's
something screwy with the way that I
something screwy with the way that I
have it set up that it doesn't. So, I
have it set up that it doesn't. So, I
think that I'm going to be able to make
think that I'm going to be able to make
the algorithm much better, but um I have
the algorithm much better, but um I have
to, you know, it relies on me being able
to, you know, it relies on me being able
to figure out this
thing. Okay. So, there is
thing. Okay. So, there is
There is what is in
buff. That doesn't look right to me.
buff. That doesn't look right to me.
Does that look right to
Does that look right to
you? Not at
you? Not at
all.
0.5 standard deviation is all
0.5 standard deviation is all
one. How's that work?
value standard deviation minus the
mean. Oops.
No zeros in here,
No zeros in here,
right?
One. So that ought to be I mean that
One. So that ought to be I mean that
ought to be just
ought to be just
one. Why does it contain 0.5s?
What the heck is this?
0.5
0.5
delta. What's delta in
delta. What's delta in
here? Delta
here? Delta
is max minus min.
There's no log in CUDA is
there over
delta. Delta equals Z.
delta. Delta equals Z.
Don't modify the buffer anymore though,
Don't modify the buffer anymore though,
do
you? 7 126
you? 7 126
125. And that seems kind of weird to me,
125. And that seems kind of weird to me,
doesn't
doesn't
it? 126 125
Oh no, it doesn't. This is fine.
Why in the
heck? Oh, hold
heck? Oh, hold
on. Did I mess something up
on. Did I mess something up
here? Because if you divided
here? Because if you divided
by the delta would still be one though,
by the delta would still be one though,
right?
Nauseous. Yeah, it's all once.
Buffer is equal to advantage scale.
Hang on. That last one is like blue,
Hang on. That last one is like blue,
isn't
it?
Dun. Ah, okay.
Dun. Ah, okay.
[Music]
So yeah, you have the done at the end
So yeah, you have the done at the end
there.
there.
Okay, so you get the standard
deviations, you go up to
127, you set it
127, you set it
to scale over
to scale over
delta, which
delta, which
is max minus min.
That's going to either it's that's going
That's going to either it's that's going
to be
one delta is one. Yeah, I don't see how
one delta is one. Yeah, I don't see how
this gets to be 0.5 instead of
two. I have to put this on
B standard deviation.
Okay. Well, this is going to drive me
Okay. Well, this is going to drive me
insane. I'm going to just try some stuff
insane. I'm going to just try some stuff
so that we don't spend forever on this.
I don't see anything wrong with this
I don't see anything wrong with this
code. I'm getting kind of tired.
E10. Ah, lovely.
You did
this. That's a major error. I'm
this. That's a major error. I'm
surprised it worked at all.
Okay. So now this is all
Okay. So now this is all
ones except for the zero where
ones except for the zero where
it's not applicable.
it's not applicable.
Right. Perfect. And then you're dividing
Right. Perfect. And then you're dividing
by sum.
Five now.
Interesting that they all went down by
Interesting that they all went down by
the same
amount. There might need to be some
amount. There might need to be some
symmetry breaking
here. But then what happened to buff
That's all over the place, isn't
it? Value of standard deviation of
index delta is equal to
index delta is equal to
zero. And none of this modifies the
zero. And none of this modifies the
buffer. The only place the buffer gets
buffer. The only place the buffer gets
modified is right there at the
start. It's men divide by
delta. Okay. The values means all
delta. Okay. The values means all
different but that doesn't matter
right there isn't even 32
elements there 16
elements there 16
elements. How does that make any sense?
This is 32
This is 32
elements. How this happened
Maybe it didn't get
set. Or maybe you didn't zero
set. Or maybe you didn't zero
it. It wouldn't make sense for you not
it. It wouldn't make sense for you not
just to have not zeroed it.
just to have not zeroed it.
Like that would just leave ones in it.
It's the
men
delta. That was very weird. That was
delta. That was very weird. That was
very very weird.
So many
questions. Second
epoch. First of all, the values are all
epoch. First of all, the values are all
the same for some reason still.
Second of
Second of
all, scale still
zero. It should be like one.
zero. It should be like one.
Unless Dun's different. Hold on. Maybe
Unless Dun's different. Hold on. Maybe
Dun's
Dun's
off. Ah, wait. Maybe that's what it is.
off. Ah, wait. Maybe that's what it is.
Hang on.
Okay. So, there's your done.
Okay. So, there's your done.
Stop
this 16 steps
in. So that's why you only have 16
in. So that's why you only have 16
values. So that's
values. So that's
fine. Then the values
themselves advantage
scale. Yeah, that doesn't make any sense
scale. Yeah, that doesn't make any sense
to me.
not overwriting it or anything,
right?
Very
Very
weird. Um,
weird. Um,
okay. We're going to start this
okay. We're going to start this
shenanigans again.
You can't do break points in right
Is
there could
GDP? You just install this thing and
GDP? You just install this thing and
Hang
on. Okay. So, yeah, that changes it a
on. Okay. So, yeah, that changes it a
lot. So, there's like some noise or
lot. So, there's like some noise or
something here, I think. Yeah, there's
something here, I think. Yeah, there's
some like very slight
some like very slight
noise thing going on
noise thing going on
here. Let's see if this works.
Oh, this does work.
I see. So, if I wanted to go through
I see. So, if I wanted to go through
this, I'd actually have to like write a
this, I'd actually have to like write a
CUDA test or something, which is a
CUDA test or something, which is a
little annoying
little annoying
with the the way that this is bound to
with the the way that this is bound to
Python.
Okay. But the fact that this
Okay. But the fact that this
is there's like a very slight difference
is there's like a very slight difference
here and I think it's getting
here and I think it's getting
accentuated or
accentuated or
something. Um, but this is kind of an
something. Um, but this is kind of an
extreme
extreme
case like why hang on. Why is this even
case like why hang on. Why is this even
happening in
happening in
the first place here?
value function should not
value function should not
be subject to this,
right? Maybe I just give it a couple
right? Maybe I just give it a couple
continues first.
Okay, so this is what we get
above. Oh, there is a symmetry problem.
above. Oh, there is a symmetry problem.
That's really
weird. Give it a few more of these.
Oh no. Okay. It's just it takes it a
Oh no. Okay. It's just it takes it a
second.
second.
So if we look at this
now,
now,
okay, you do have this
okay, you do have this
backwards. So you want to
subtract the
max. I think it's going to take us right
max. I think it's going to take us right
back to where we started to be honest.
Not quite. We have better stats at
Not quite. We have better stats at
least.
Congrats on the Pokemon Red Achievement.
Congrats on the Pokemon Red Achievement.
Thank you. Yeah, it's a result we've
Thank you. Yeah, it's a result we've
been looking at for a while. We wanted
been looking at for a while. We wanted
to get rid of all the scripts.
to get rid of all the scripts.
Um I mean really that guy's been the
Um I mean really that guy's been the
lead of it or I guess um David now that
lead of it or I guess um David now that
guy in the Discord. Um, we wanted to get
guy in the Discord. Um, we wanted to get
rid of all the scripts and I think we
rid of all the scripts and I think we
could have still gotten rid of more of
could have still gotten rid of more of
the scripts than we currently have in
the scripts than we currently have in
there, but at some point you just have
there, but at some point you just have
to run a lot a lot of experiments. And
to run a lot a lot of experiments. And
uh, Pokemon is nowhere near as fast as
uh, Pokemon is nowhere near as fast as
all the other MS that we're making in
all the other MS that we're making in
Puffer since it's an existing game.
Puffer since it's an existing game.
That's tough.
Like literally if you were to just write
Like literally if you were to just write
if you just had Pokemon not running
if you just had Pokemon not running
through an emulator just like the same
through an emulator just like the same
thing just not written for an emulator
thing just not written for an emulator
it would be the project would have been
it would be the project would have been
much much much easier to get results on
much much much easier to get results on
faster. It's just a pure speed
limitation. But still I mean it's it
limitation. But still I mean it's it
changes the way I think about R a little
changes the way I think about R a little
bit knowing that that is a possibility.
Okay.
So this is negative.
We can just make
We can just make
this. We just do this
this. We just do this
one. And that'll fix
it. This will fix it.
There's so many cool gifts here to post.
That's fine.
Okay.
11.66 11.98 is zero somehow.
Uh,
what? Oh, that's that's something right
what? Oh, that's that's something right
there. Okay.
there. Okay.
So, this first
So, this first
bit 23 is a
bit 23 is a
segment. 12.3 and then
segment. 12.3 and then
O.
O.
Okay. And then
What happened
here? Wait, actually what happened here?
I don't have a 32 in here anywhere, do
I don't have a 32 in here anywhere, do
I?
No. Stop buff.
Oh, okay. It's because this doesn't the
Oh, okay. It's because this doesn't the
rest doesn't get trained.
Yeah. So, that'll totally mess it up.
Yeah. So, that'll totally mess it up.
Let's do
Let's do
um let's undo that for now.
Huh? Why is the value of standard
Huh? Why is the value of standard
deviation
That's weird as hell.
Yeah, definitely something wrong with
Yeah, definitely something wrong with
this. Probably this loss, right?
Maybe this is
different. Oops.
this optimizing backwards or
Something's weird.
Yeah. Okay. So, this math block is not
Yeah. Okay. So, this math block is not
getting I mean nothing.
I think you forgot to zero it right.
I think you forgot to zero it right.
Mass block.
Okay. I don't know about the 1.0 at the
Okay. I don't know about the 1.0 at the
end like
this, but uh that's closer.
or maybe it
is now. Maybe it is
still not handling this portion
still not handling this portion
correctly. I don't
think
think
buff divide
buff divide
by vantage sum.
Subract the
max subtracted the max, right? What was
max subtracted the max, right? What was
the max?
the max?
15.
It's almost that the difference is very
It's almost that the difference is very
small.
Yeah, this is getting very diluted.
Yeah, this is getting very diluted.
Here it's very diluted.
I'm not quite sure how you deal with
I'm not quite sure how you deal with
this sort of a thing.
If you initialize standard deviation to
If you initialize standard deviation to
one
When does a point stop mattering?
Not a huge fan of the way this is
working. I mean, this is just going to
working. I mean, this is just going to
be a lot of thinking work.
Is there an existing thing that you can
Is there an existing thing that you can
throw at
throw at
this? I don't think so.
I mean the standard deviation of your
I mean the standard deviation of your
prediction if you know it perfectly is
prediction if you know it perfectly is
zero,
right? You subtract the largest of these
right? You subtract the largest of these
values. That's a
values. That's a
great way to check the baseline of it.
I mean, maybe these get more consistent
I mean, maybe these get more consistent
if you let it run a little
longer. So now we have this one for
longer. So now we have this one for
values.
Okay. I mean, that's something, right?
Is there one in
there? Oh, yeah. No, it's just going to
there? Oh, yeah. No, it's just going to
give me
these. Those are some weights.
these. Those are some weights.
You don't necessarily want to subtract
You don't necessarily want to subtract
the
um the men there though, do you?
Maybe you want to subtract the
Maybe you want to subtract the
global global That's
If I do this, does it fix the problem?
If I do this, does it fix the problem?
If I replace this with a
If I replace this with a
global global m uh global
pass. Well, this isn't going to help me
pass. Well, this isn't going to help me
because
Yeah, this doesn't get
Yeah, this doesn't get
trained the way this
is. The segments happen to line up like
is. The segments happen to line up like
this.
Okay.
Okay.
Um, I could modify the signature, right?
Yeah, I'm kind of just getting tired
Yeah, I'm kind of just getting tired
here. It's I I I know what I think I
here. It's I I I know what I think I
need to do.
Want to zero one. Normalize this.
the ROM That's
That has to also
That has to also
return has to return that as well,
return has to return that as well,
doesn't it?
Gosh, freaking pie bind.
Does this do anything?
How do you return this stupid thing?
You can't even do this, can you?
Okay. So, what you're going to
do this
do this
one. Okay.
one. Okay.
pass in a
pass in a
max,
but it's going to be a little different
but it's going to be a little different
from Yes.
Okay.
Boom. What is this [ __ ]
Very
Very
fiddly. Very very fiddly.
All
right,
right,
finally we're getting somewhere
potentially. Lovely.
potentially. Lovely.
Going a little bit
more. Yay, we get something.
Not
bad. And then what do we do? Do we clip
this? Do we clip this?
or what?
0 to 0.1 maybe
Yeah, that's a clip.
Okay. Let's see if this does anything.
And then the question would be would
And then the question would be would
like what do you actually initialize
like what do you actually initialize
this thing too?
Are we just
stuck? No. We do
stuck? No. We do
something. It's in the compute.
something. It's in the compute.
What do you
mean?
mean?
Um the issue
Um the issue
is Oh, compute advantages. Yeah, the
is Oh, compute advantages. Yeah, the
issue is
issue is
um I think it's just the way that we
um I think it's just the way that we
are when you expand the horizon to 128
are when you expand the horizon to 128
elements, there's a little bit of noise
elements, there's a little bit of noise
and if you don't account for that noise,
and if you don't account for that noise,
then you kind of just smear your credit
then you kind of just smear your credit
assignment. I mean, we've got to be able
assignment. I mean, we've got to be able
to do something better than this, I
to do something better than this, I
would imagine, but
Where' this run
Where' this run
go? And I have
go? And I have
uh Yeah, here it
is. This wasn't what I was looking at,
is. This wasn't what I was looking at,
is
is
it? Maybe it was.
a big boost at the end,
a big boost at the end,
huh? Well, kind
of still causing issues.
Just this is kind of ridiculous, but
Just this is kind of ridiculous, but
let's just clamp to
20. I actually wonder what um
So
2/3.99. Are you kidding me? What's with
2/3.99. Are you kidding me? What's with
this device side shenanigans?
Nothing's greater than
2. Yep, that hack is
2. Yep, that hack is
good. Lots of Pokemon as well. Hey Ryan,
good. Lots of Pokemon as well. Hey Ryan,
we're working on a new algorithm. It's a
we're working on a new algorithm. It's a
pain in the
ass. New
ass. New
algorithm. I think I'm going to be able
algorithm. I think I'm going to be able
to beat
to beat
PO, but it's kind of hard.
Wait, if you just do this division by
Wait, if you just do this division by
advantage sum
advantage sum
here, right?
Maybe we do this
instead. What's
this? What is this that you linked me?
C3PO. This image doesn't load, but I see
C3PO. This image doesn't load, but I see
from the
from the
URL. Um, I was thinking about 3PO,
URL. Um, I was thinking about 3PO,
but I don't
but I don't
know. Not really a Star Wars kind of
know. Not really a Star Wars kind of
guy.
I am currently stuck fiddling with CUDA
I am currently stuck fiddling with CUDA
kernel for this new
kernel for this new
algorithm. What is the difference from
algorithm. What is the difference from
PO?
PO?
Um long horizon variational value
Um long horizon variational value
function and a different advantage
function and a different advantage
function and it cuts two it cuts two
function and it cuts two it cuts two
hyperparameters out of PO. No more gamma
hyperparameters out of PO. No more gamma
and
and
lambda. So if it works and I get it to
lambda. So if it works and I get it to
work well, it's very big. And I actually
work well, it's very big. And I actually
do kind of already have it matching on
do kind of already have it matching on
Breakout. Very, very close to matching
Breakout. Very, very close to matching
PF on Breakout.
PF on Breakout.
Um, but there are a couple quirks I need
Um, but there are a couple quirks I need
to
to
fix. My Twitter feed is just blowing up
fix. My Twitter feed is just blowing up
repeatedly.
gamma free stuff from continual
gamma free stuff from continual
learning. Do they have anything that
learning. Do they have anything that
actually works that I should look
at? Does I have something that seems to
at? Does I have something that seems to
actually work
testing PO and continual MS. What is a
testing PO and continual MS. What is a
continual
M. That has no relation though
M. That has no relation though
whatsoever
whatsoever
to whether you need gamma or
lambda. Okay, so this didn't
help. Back to
help. Back to
this. I'm going to have to think about
this. I'm going to have to think about
this.
That's kind of funny that they invented
That's kind of funny that they invented
a whole branch of RL for like
a whole branch of RL for like
non-epodic. It's the same damn thing.
really don't like the way that I'm doing
really don't like the way that I'm doing
the clipping
the clipping
here. And I assume that this is probably
here. And I assume that this is probably
the main
the main
issue, you may think. Does that make
issue, you may think. Does that make
sense?
It makes sense for this to be the main
issue. No point where you're
just That seems like an entirely
just That seems like an entirely
academic distinction.
average
forward. Yeah, I pretty much don't have
forward. Yeah, I pretty much don't have
any idea what they're doing there. Uh I
any idea what they're doing there. Uh I
have very very little
have very very little
confidence in that line of work just
confidence in that line of work just
just because of how it's framed because
just because of how it's framed because
it doesn't seem to be framed
correctly. Stand RL methods don't work
correctly. Stand RL methods don't work
well in these
well in these
zones. I've been doing I mean neural MMO
zones. I've been doing I mean neural MMO
doesn't exactly reset either like
doesn't exactly reset either like
there's really no
difference. Yeah. Well, everything's
difference. Yeah. Well, everything's
going to forget unless you have a replay
going to forget unless you have a replay
buffer and then it won't,
right? I don't
right? I don't
know. I've kind of been relying less and
know. I've kind of been relying less and
less on the literature in RL because
less on the literature in RL because
like most of it is poorly motivated and
like most of it is poorly motivated and
most of what is correctly motivated is
most of what is correctly motivated is
wrong.
wrong.
Like I just keep finding I keep finding
Like I just keep finding I keep finding
so many errors and stuff that it's just
so many errors and stuff that it's just
like I've completely lost confidence in
like I've completely lost confidence in
the accuracy of basically every
the accuracy of basically every
publication.
I think what I do with
this big
claims sometimes there isn't even new
claims sometimes there isn't even new
knowledge though is the thing because
knowledge though is the thing because
it's like it's not underneath there's
it's like it's not underneath there's
new knowledge it's you have to do an
new knowledge it's you have to do an
additional three papers worth of work
additional three papers worth of work
that they didn't do of ablation notes in
that they didn't do of ablation notes in
order to see if their thing actually
works like you're tuning graduate
works like you're tuning graduate
students to environments
for the most
part.
part.
Yeah. But the thing is the leg work is
Yeah. But the thing is the leg work is
the hard part, right?
Okay. Coming up with pretty sounding
Okay. Coming up with pretty sounding
ideas is not
contribution. Man, this is very weird
contribution. Man, this is very weird
because like right here, I wonder what
because like right here, I wonder what
happens if I run this with the original
happens if I run this with the original
32 horizon. Does it work? Does it work
32 horizon. Does it work? Does it work
again?
again?
The thing that's just tricky here is
The thing that's just tricky here is
like I have this thing working when you
like I have this thing working when you
specify a short horizon. It should work
specify a short horizon. It should work
identically or better with a long
identically or better with a long
horizon, but like you kind of need to
horizon, but like you kind of need to
nor like you need to smooth out the
nor like you need to smooth out the
noise in your predictions uh when you do
noise in your predictions uh when you do
that. Otherwise, you just smear all the
that. Otherwise, you just smear all the
credit assignment.
use some of that light work. Well, yeah,
use some of that light work. Well, yeah,
but the issue there is mainly just that
but the issue there is mainly just that
the env is like 100x slower than the
the env is like 100x slower than the
other M's in Puffarel. So, we can run
other M's in Puffarel. So, we can run
100x fewer experiments on the same
100x fewer experiments on the same
hardware.
That's the main
That's the main
issue. I mean, literally more than
issue. I mean, literally more than
anything you could do on the science
anything you could do on the science
side, like the best things you could do
side, like the best things you could do
for Pokemon would just be rewriting the
for Pokemon would just be rewriting the
game off an emulator, like without the
game off an emulator, like without the
emulator, get it to be 100x faster, and
emulator, get it to be 100x faster, and
then it would just be
then it would just be
easy if I don't get booted. Hey, I mean,
easy if I don't get booted. Hey, I mean,
drop in the Discord. We would very much
drop in the Discord. We would very much
appreciate that. We are going to try to
appreciate that. We are going to try to
get our own compute soon as well. It's
get our own compute soon as well. It's
just they're long lead times on the
just they're long lead times on the
5090s and I need to make sure they don't
5090s and I need to make sure they don't
catch on
fire. And we'll get the popper cluster.
Do you think Pokemon experiments can
Do you think Pokemon experiments can
finish in three
days? Probably
not. Actually, definitely not with
not. Actually, definitely not with
HCPUs.
um up to a week on our
um up to a week on our
machines, which are at least 3x faster
machines, which are at least 3x faster
than your
machines. It's a pain in the
ass. Shorter ablation, too.
How do you do
this? It's very weird.
Clusters aren't good for long
Clusters aren't good for long
experiments, but we have popper hardware
experiments, but we have popper hardware
4.
Leave you to it. I owe them a review.
Leave you to it. I owe them a review.
Pokemon paper. Yeah, that'd be good.
Pokemon paper. Yeah, that'd be good.
Thank you for
Thank you for
that, man. I'm like so annoyed with
that, man. I'm like so annoyed with
this. I'm trying to think what the hell
this. I'm trying to think what the hell
it even is. What the hell is even the
it even is. What the hell is even the
problem here?
This does seem reasonable to me. So why
This does seem reasonable to me. So why
is this not
good? You're good.
What the hell is wrong with this?
[ __ ] Hello.
somehow just
crashed. I guess if you just kill it
crashed. I guess if you just kill it
halfway
halfway
through just crashes.
Ridiculous.
Come on. Get 10 now.
That looks not bad to
me. Hang on. Wait a second. Does
me. Hang on. Wait a second. Does
this make
this make
sense? Why is that five and not one?
Something's definitely
screwy. Then do you want it to be
screwy. Then do you want it to be
clipped like
clipped like
this or do you want to like subtract
Delta will be
So
So
fiddly. There's got to be something
fiddly. There's got to be something
simple I can do for this scaling.
Hang on. Maybe I can do
I've got to be massively over
I've got to be massively over
complicating this. There's just got to
complicating this. There's just got to
be a way simpler way I can normalize
be a way simpler way I can normalize
this.
What's this freaking
What's this freaking
paper? What is this
paper? This is the sen paper. That
paper? This is the sen paper. That
doesn't make any bloody sense, right?
is 50,000
Apparently the appendix for this
Apparently the appendix for this
actually has experiments.
I'll look at this paper more, but I no
I'll look at this paper more, but I no
confidence in that.
Come on. You
have standard
deviation. It's going to be scaled
deviation. It's going to be scaled
differently.
So it is the scale of the standard
So it is the scale of the standard
deviation that is off right.
What if you were to
What if you were to
just center the standard deviation? Can
just center the standard deviation? Can
you do that?
Can you do
Can you do
that? I don't think so.
They're going to drive me nuts.
I doubt I'm getting anything out of
I doubt I'm getting anything out of
Groth, but I'm out of ideas for now.
Can I do Wait, wait, wait. Can I just
do I'll see a negative log
likely. Maybe it's just this
That would be kind of silly, wouldn't
That would be kind of silly, wouldn't
it?
It's a minus target.
Well, you can't square it.
divide by the
divide by the
variance. Hang on.
Isn't it just it's one over it, right?
Isn't it just it's one over it, right?
Or one minus like
targets are treated from samples as
targets are treated from samples as
samples from a Gaussian distribution.
samples from a Gaussian distribution.
Okay.
Function term is emitted unless full is
Function term is emitted unless full is
true.
Reward
Reward
minus quantity.
So it's just one. Yeah. So this is what
So it's just one. Yeah. So this is what
I was looking at
before. You could square
before. You could square
this variance.
It's only
It's only
um 4x or whatever.
You subtract out the uh
You can't subract the mini here
anymore. Can divide. Does that help
anymore. Can divide. Does that help
though? No, it doesn't help.
A thinking
A thinking
day. Today is a thinking day.
And the issue is that
like standard deviation of these
like standard deviation of these
predictions
Church.
This is massively irritating.
Maybe I haven't thought about the
Maybe I haven't thought about the
advantage function well enough.
problem is there's
problem is there's
like if you just predict
like if you just predict
randomly there's a certain standard
randomly there's a certain standard
deviation you're going to have from
deviation you're going to have from
that it's not randomly it's predict
that it's not randomly it's predict
majority I Yes.
All
right. Well, I have a meeting in a few.
right. Well, I have a meeting in a few.
Um, yeah, this is hard. I like I'm going
Um, yeah, this is hard. I like I'm going
to really have to think about how I deal
to really have to think about how I deal
with the advantage function for this.
with the advantage function for this.
This is just going to be like a thinking
This is just going to be like a thinking
problem.
problem.
Um, yeah, it's all there is to
it. I know I have a version that works
it. I know I have a version that works
at
at
32, so we just have to think about how
32, so we just have to think about how
that's set up and what I can do on top
that's set up and what I can do on top
of that. All right. Um, yeah, I will be
of that. All right. Um, yeah, I will be
back later tonight or tomorrow. We'll
back later tonight or tomorrow. We'll
see. Thank you. And, uh, yeah, check out
see. Thank you. And, uh, yeah, check out
puffer.ai AI for more.

Kind: captions
Language: en
Okay, we are live.
Hello. Notifications blowing up on
here. What the heck is this?
Academia is a crazy place.
silly auto correct.
This is not This is like completely
This is not This is like completely
disrespectful.
That's a bit much.
Morning.
That's
ridiculous. You can't just slap safety
ridiculous. You can't just slap safety
on a sub field. That's really
on a sub field. That's really
constrained optimization and then claim
constrained optimization and then claim
the moral high ground. That's just not
the moral high ground. That's just not
how this
works. See anything else on
this? More Pokemon stuff. Let me go see
this? More Pokemon stuff. Let me go see
if we have any more Pokemon stuff or if
if we have any more Pokemon stuff or if
I should
just double check.
Okay, I guess it's on me to tweet out uh
Okay, I guess it's on me to tweet out uh
additional stuff on
Pokemon. This is cool.
I miss
I miss
[Music]
[Music]
anybody? I think so.
Just drafting this and then we'll do
Just drafting this and then we'll do
some uh some depth.
Okay, that's
Okay, that's
good. Twitter's been uh popping here.
Oops. No, I am skeptical of this.
I'm very skeptical of this.
I don't get this like this take
here. I know Jeff is good, but like I
here. I know Jeff is good, but like I
don't like you can't demonstrate these
don't like you can't demonstrate these
methods on like really small academic
methods on like really small academic
tasks and then just claim that they'll
tasks and then just claim that they'll
solve everything.
That's
That's
disrespectful cuz he does a lot of good
disrespectful cuz he does a lot of good
stuff. I didn't mean it that way.
the heck's really hard. Like I don't
the heck's really hard. Like I don't
trust any like you know go explore is a
trust any like you know go explore is a
method that just seems to make a lot of
method that just seems to make a lot of
sense but like I don't trust methods
sense but like I don't trust methods
just because they seem to make a lot of
just because they seem to make a lot of
sense if they haven't been demonstrated
sense if they haven't been demonstrated
on uh know something much
bigger. I got to love the box.
Okay, so we have stuff to do.
Okay. So, we
Okay. So, we
have a lot of points right
have a lot of points right
around 110
around 110
seconds. It looks
seconds. It looks
like there's something about this,
like there's something about this,
right? I assume with the
parameters. So let me think what we want
parameters. So let me think what we want
to do today. There's quite a bit of
to do today. There's quite a bit of
stuff to look
stuff to look
at. Me double check one thing. There are
at. Me double check one thing. There are
two different directions we could take
two different directions we could take
for
for
now. Okay, that's taken care of. Cool.
now. Okay, that's taken care of. Cool.
Um I really want to get this algorithm
Um I really want to get this algorithm
into a decent spot. Oh yeah, I also I
into a decent spot. Oh yeah, I also I
think I forgot one one message. Where
think I forgot one one message. Where
did it go?
I think that the what that what we're
I think that the what that what we're
going to do right now is we're going to
going to do right now is we're going to
decide based on what this result tells
me. So I think if I just
me. So I think if I just
filter I have this
15.
15.
[Music]
Okay. So, here are the runs for
this learning rate.
this learning rate.
pretty
robust. Gamma shouldn't matter because
robust. Gamma shouldn't matter because
it's real. Lambda shouldn't matter,
it's real. Lambda shouldn't matter,
right? It doesn't
right? It doesn't
matter. Almost all just one update
matter. Almost all just one update
epoch. Okay.
front
front
here. Oh, most of these are at
150. And most of these are at
150. And most of these are at
150. So, some of these are much faster
150. So, some of these are much faster
than others for some reason. It's got to
than others for some reason. It's got to
be mini batches or something,
be mini batches or something,
right? They all have 1024 MS.
They all have the same b
They all have the same b
size. And there it is. Mini bap
size.
size.
So why is this so slow? It's just like
Let me think about this. There are a
Let me think about this. There are a
couple things here that I I have uh
couple things here that I I have uh
ideas
ideas
for. Can I find the baseline that we uh
for. Can I find the baseline that we uh
we trained in
here breakout fast? Okay, this should be
here breakout fast? Okay, this should be
good. All
right, there we
go. Yeah. So, here's the big difference,
go. Yeah. So, here's the big difference,
right?
right?
This
This
algorithm is able to train with a mini
algorithm is able to train with a mini
batch size of
batch size of
8192. I believe this is the difference,
8192. I believe this is the difference,
right? Oh, there also
right? Oh, there also
some with 2048 ms as
some with 2048 ms as
well. But, uh, if I'm looking at
well. But, uh, if I'm looking at
differences, that's the biggest one I
differences, that's the biggest one I
see. There's a lot of one epoch right
see. There's a lot of one epoch right
here. So, the biggest update is that for
here. So, the biggest update is that for
whatever
whatever
reason, GA works with bigger mini
reason, GA works with bigger mini
batches
batches
and more
and more
ends. Why would that be the
ends. Why would that be the
case? What is it about the algorithm
itself? Hold on. It could just be total
itself? Hold on. It could just be total
time steps, right?
Maybe I'm shooting myself in the foot by
Maybe I'm shooting myself in the foot by
making this the
making this the
max. Look at
max. Look at
this. What do we have total time steps
this. What do we have total time steps
wise? Yeah, we're pretty much pressing
wise? Yeah, we're pretty much pressing
up against the maximum here, aren't we?
So maybe if I increase total time
So maybe if I increase total time
steps and maybe if I increase the
steps and maybe if I increase the
maximum total time steps it would
maximum total time steps it would
find faster parameters for
solvent. Does that make
solvent. Does that make
sense? Let's assume okay here's an idea.
sense? Let's assume okay here's an idea.
If we assume that there is a small
If we assume that there is a small
difference in sample efficiency even if
difference in sample efficiency even if
it's initial sample efficiency but our
it's initial sample efficiency but our
methods are a bit different right so
methods are a bit different right so
let's say that my method
let's say that my method
takes you know 20 million more
takes you know 20 million more
samples to
optimize that
consistent I could see that being
consistent I could see that being
consistent
consistent
because you know these ones could be
because you know these ones could be
slower over here. Okay. So, if mine
slower over here. Okay. So, if mine
takes 20 million steps more to
takes 20 million steps more to
optimize and you're not allowing it to
optimize and you're not allowing it to
get those additional 20 million steps,
get those additional 20 million steps,
which should just take 20% more compute,
which should just take 20% more compute,
it could have to go to fewer M's and
it could have to go to fewer M's and
smaller mini batches, which could be a
smaller mini batches, which could be a
much bigger than 20% performance
much bigger than 20% performance
penalty. But that makes
penalty. But that makes
sense. I think it does.
sense. I think it does.
I think that makes
sense. I mean what other parameters are
sense. I mean what other parameters are
there here? one update epoch 32
horizon. Can we just do this for a
second and just see like what this thing
second and just see like what this thing
finds.
It does get mini batch of
It does get mini batch of
4096. It really doesn't try very
4096. It really doesn't try very
hard over here, does
hard over here, does
it? It just didn't try.
it? It just didn't try.
I wonder why
I wonder why
not the results over
here. Maybe it had to adjust different
here. Maybe it had to adjust different
things in order to make that fast enough
things in order to make that fast enough
though. I don't
though. I don't
know. It's a time steps problem,
know. It's a time steps problem,
right? What else do we have here?
ends. Yeah.
ends. Yeah.
Missing. Oh, no. You know, it's actually
Missing. Oh, no. You know, it's actually
it is starting to do some
it is starting to do some
stuff. 2,00
stuff. 2,00
here. It just takes it a
while. It's aren't that different
while. It's aren't that different
really.
Rise to
32 16. Yeah, whatever. They both
32 16. Yeah, whatever. They both
work. One update epoch for the most part
work. One update epoch for the most part
with a couple
exceptions. Value
exceptions. Value
co that's pretty similar, right? It's
co that's pretty similar, right? It's
stable. Same with max gradorm.
stable. Same with max gradorm.
Max Bradnorm goes we have a much wider
Max Bradnorm goes we have a much wider
range for max grad
range for max grad
norm which is
interesting. We have a different loss
interesting. We have a different loss
function
though. Gamma doesn't matter. Lambda
though. Gamma doesn't matter. Lambda
doesn't matter.
should be
coefficient. You kind of get a big
coefficient. You kind of get a big
stable range. Does the learning rate
stable range. Does the learning rate
different? That's what I'm curious
different? That's what I'm curious
about. O2.
about. O2.
And here you have 02, but it also goes
And here you have 02, but it also goes
all the way to up to
0.01.
0.01.
Um
Um
05. It's off by maybe a back two from
05. It's off by maybe a back two from
there. I wouldn't call these ranges way
there. I wouldn't call these ranges way
too different.
too different.
And then the burrito
And then the burrito
front
is very very
is very very
similar. This is so
close. It really just seems like it's
[Music]
there is still like a 10% speed
there is still like a 10% speed
difference,
right? So with that, they're not that
right? So with that, they're not that
far apart. And also there's another 30
far apart. And also there's another 30
runs to go here as well.
Well, hang on.
Well, hang on.
Right. If you have an algorithm with
Right. If you have an algorithm with
more
more
hyperparameters, you're pretty much
hyperparameters, you're pretty much
always going to be able to get it to be
always going to be able to get it to be
slightly faster,
slightly faster,
right? in terms of uh total time steps
right? in terms of uh total time steps
if they're reasonable hypers because
if they're reasonable hypers because
each of those is tunable and gives you
each of those is tunable and gives you
an inductive bias on the environment
an inductive bias on the environment
that you have to learn from scratch
that you have to learn from scratch
otherwise. So this is kind of
otherwise. So this is kind of
fine for there to be a tiny perf
fine for there to be a tiny perf
gap. I think that we should be pretty
gap. I think that we should be pretty
happy with
happy with
this. And instead of trying to close
this. And instead of trying to close
this last little 10%, which will
this last little 10%, which will
probably go away eventually anyways,
probably go away eventually anyways,
maybe it'll get like slimmed at
maybe it'll get like slimmed at
least. We should probably think about
least. We should probably think about
some of the
some of the
um larger issues with
this. Yeah.
this. Yeah.
So I think what we should do is we
So I think what we should do is we
should just like kind of say
should just like kind of say
okay these are very
okay these are very
close. You don't have to beat the PF
close. You don't have to beat the PF
of PO in terms of samples or in terms of
of PO in terms of samples or in terms of
like wall clock. No in terms of samples
like wall clock. No in terms of samples
should be similar in terms of wall clock
should be similar in terms of wall clock
on an environment for which you've
on an environment for which you've
heavily heavily tuned the parameters for
heavily heavily tuned the parameters for
the baseline. You just need to about
the baseline. You just need to about
match
match
it and then you need to demonstrate that
it and then you need to demonstrate that
it can learn things that PO can't on the
it can learn things that PO can't on the
harder environments. That would be the
harder environments. That would be the
test of this more than
test of this more than
anything. Yeah, that makes sense. Okay.
anything. Yeah, that makes sense. Okay.
So, if we're going to say
So, if we're going to say
that, then the main thing is figuring
that, then the main thing is figuring
out why this doesn't play nice
out why this doesn't play nice
with longer
with longer
horizons. Yeah, with longer
horizons. Let's take one of these
horizons. Let's take one of these
parames that
parames that
seems it seems good.
22054. One of the earliest
runs. Oh, this one only ran
runs. Oh, this one only ran
um 79
um 79
mil. It's probably a lucky run.
It looks very clean, but it's probably a
It looks very clean, but it's probably a
lucky
run. I might just killed the container
run. I might just killed the container
by
by
mistake. That's fine.
So new parameters
here. This
here. This
is 66 million steps is what this took to
is 66 million steps is what this took to
solve right
solve right
there. So we'll give it a few
there. So we'll give it a few
additional what that's doing. We'll give
additional what that's doing. We'll give
it the full
it the full
80 just to give it a little bit of
80 just to give it a little bit of
wiggle room in case there's variance.
wiggle room in case there's variance.
We'll do
total
total
HTML. There we
go. And 24.
batch size
2048. Yeah, this is a way smaller mini
2048. Yeah, this is a way smaller mini
batch size. So, this is why it's going
batch size. So, this is why it's going
to be
slower. It does seem like the max grad
slower. It does seem like the max grad
norm parameter changes quite
norm parameter changes quite
substantially.
substantially.
gets to be a much wider
gets to be a much wider
spread. Then we do VFX
coefficient. I forget any update epox is
multiple. Where is
multiple. Where is
this one update
epoch? Okay. So we have batch
epoch? Okay. So we have batch
size epoch
size epoch
entropy don't need gamma lambda anymore
entropy don't need gamma lambda anymore
which is great learning rate I only
which is great learning rate I only
forgot the most important parameter
forgot the most important parameter
that's a funny
recommendation
radorm I think this is
Good. Comment all
these. I just want something decent, you
these. I just want something decent, you
know, to work off
of. Oops. I don't know what I'm
doing. Okay.
list index out of
range.
range.
Lovely. Got to love container driver
Lovely. Got to love container driver
detaching for no reason.
This is [ __ ]
uh MIT professor being kind of rude to
uh MIT professor being kind of rude to
Richard Sutton and a very silly way and
Richard Sutton and a very silly way and
then went on a big long big long thread
then went on a big long big long thread
about it.
You make you can't make a thread here.
What do we think on this?
actually. No, it's worse than that.
Right. Is it just me or is the Minecraft
Right. Is it just me or is the Minecraft
diamonds thing actually look very simple
diamonds thing actually look very simple
in comparison to
in comparison to
this? Cuz I like look, if you're getting
this? Cuz I like look, if you're getting
diamond in general and you're like going
diamond in general and you're like going
to do it through exploration or
to do it through exploration or
whatever, sure. If you're going to like
whatever, sure. If you're going to like
go caving, that's kind kind of
go caving, that's kind kind of
interesting. But um I'd still nowhere
interesting. But um I'd still nowhere
near Pokemon even if you do that. And
near Pokemon even if you do that. And
that's not what these models do. They
that's not what these models do. They
just dig down and hope they get lucky. I
just dig down and hope they get lucky. I
don't even think that they dig down two
don't even think that they dig down two
by two. They just yolo it and say if I
by two. They just yolo it and say if I
hit lava, I hit lava.
I disagree with this.
Oops. Stupid auto cracked.
Lucky
Lucky
trajectories is also possible.
Well, I guess this
Well, I guess this
doesn't apply as well,
right? No, that would be multi seed.
I don't even know if you need different
I don't even know if you need different
seeds. Robotics doesn't really add seeds
seeds. Robotics doesn't really add seeds
in the same way.
Why be Why behavioral
cloning? Guess today's a Today is a
cloning? Guess today's a Today is a
common Twitter day.
I think RL is one of the better ones for
I think RL is one of the better ones for
open source, isn't it?
This doesn't make sense to me either.
field is valued. I don't understand.
field is valued. I don't understand.
Like there's these are two different
Like there's these are two different
things.
things.
Like I don't even know what the heck to
Like I don't even know what the heck to
say. This is just like a Byzantine
I don't even think self-driving uses
RL. I convince this guy.
Are there even any of
Are there even any of
these where there's been like an
these where there's been like an
irresponsible deployment? I don't know
irresponsible deployment? I don't know
of any.
Why why can you explain to me why the
Why why can you explain to me why the
Twitter auto checker doesn't like it's
Twitter auto checker doesn't like it's
like gaslighting me into thinking I
like gaslighting me into thinking I
can't spell stupid
can't spell stupid
thing. Maybe it's the OS. I don't know.
What's on the docket today? I don't
What's on the docket today? I don't
know. There's a lot of random stuff on
know. There's a lot of random stuff on
Twitter that keeps distracting me. I
Twitter that keeps distracting me. I
mean, to be fair, stuff is uh stuff's
mean, to be fair, stuff is uh stuff's
doing pretty well.
doing pretty well.
This is the new post from today. I just
This is the new post from today. I just
did this. It's already at
did this. It's already at
48. I'm just going to keep posting stuff
48. I'm just going to keep posting stuff
every day with the uh with different
every day with the uh with different
graphics and then um you know, hopefully
graphics and then um you know, hopefully
it transfers over. He's at 180 already.
it transfers over. He's at 180 already.
That's pretty good, right?
How'd this do? This finished a long time
How'd this do? This finished a long time
ago. This did not
ago. This did not
do. Wait, what? Where'd it go?
do. Wait, what? Where'd it go?
Oh, hang on.
Grand
Yeah, these hypers are just slow because
Yeah, these hypers are just slow because
the mini batches are too small, right?
the mini batches are too small, right?
There's too much overhead in
There's too much overhead in
learn mainly in
learn mainly in
learn and forward maybe
Where did this
go? Why is this like Nowhere close to
go? Why is this like Nowhere close to
the
original. Huge blog on Pokemon
original. Huge blog on Pokemon
Red. Congrats. The group didn't get
Red. Congrats. The group didn't get
close to 50K views. I don't know. How
close to 50K views. I don't know. How
can you see the uh the blog post views?
can you see the uh the blog post views?
Cuz it was also on Hacker News. I can
Cuz it was also on Hacker News. I can
see my post on it and the original
15K on the
15K on the
retweet. Oh yeah, 40K on the original.
retweet. Oh yeah, 40K on the original.
Very
nice. Yeah, this did pretty
nice. Yeah, this did pretty
well. Yeah, 40K on the original, 15 on
well. Yeah, 40K on the original, 15 on
my retweet of
it. And uh I mean, we're not done yet.
it. And uh I mean, we're not done yet.
We're going to keep posting stuff.
So, this didn't work at all. Um, I
So, this didn't work at all. Um, I
assume I must have mucked up the
assume I must have mucked up the
parameters or something,
right? Wait, what? What happened here?
Oh, I probably grabbed one from the
Oh, I probably grabbed one from the
wrong the wrong list, right? Unless I
wrong the wrong list, right? Unless I
messed this up massively as well. That
messed this up massively as well. That
would actually be really funny if I mess
would actually be really funny if I mess
this up
this up
massively. Let me see.
22 197. Let's do that one.
Use P30 is true, right?
100k time 100 mil time
steps
steps
T
T
entropy mini batch 4096 mini batch is
entropy mini batch 4096 mini batch is
better. I wonder if it's going to
better. I wonder if it's going to
compensate with two update epochs.
No, it's one update. Epoch. Okay, maybe
No, it's one update. Epoch. Okay, maybe
there's something
here. Good luck. We'll be tuning in.
here. Good luck. We'll be tuning in.
Yeah, I'm going to be probably debubbing
Yeah, I'm going to be probably debubbing
all day on
Saturday. I have uh well, we'll see
Saturday. I have uh well, we'll see
where I go today, but I have some
where I go today, but I have some
algorithm dev plans for
Saturday. There's also some new research
Saturday. There's also some new research
that I'm want to get started on.
that I'm want to get started on.
Lot to do on puffer these days. Lot to
Lot to do on puffer these days. Lot to
do is a busy
Hey, welcome
Let's see if this one
frames. Okay, Pokemon stuff still doing
frames. Okay, Pokemon stuff still doing
well.
All right, that's
All right, that's
better. That is better at
better. That is better at
least. Does it
solve? I would have to Yeah, there it
solve? I would have to Yeah, there it
goes. Solves right at the end, which is
goes. Solves right at the end, which is
kind of
kind of
funny. It like needs that last little
funny. It like needs that last little
update, I
update, I
guess. Weird how that
works. 56. Yeah, this matches
works. 56. Yeah, this matches
nicely. 120 seconds. But I gave it some
nicely. 120 seconds. But I gave it some
extra steps to account for um seed to
extra steps to account for um seed to
seed
variance. Okay, it is
variance. Okay, it is
1:30. I've gotten super distracted by
1:30. I've gotten super distracted by
all this
mess. Um what I'm going to do is I'm
mess. Um what I'm going to do is I'm
just going to close Twitter. I'm going
just going to close Twitter. I'm going
to take a minute, go use the restroom,
to take a minute, go use the restroom,
clear my head. been kind of like
clear my head. been kind of like
babysitting all these posts and stuff,
babysitting all these posts and stuff,
the engagement because there are some
the engagement because there are some
cool people responding to stuff as well.
cool people responding to stuff as well.
Uh and now that we have a good baseline
Uh and now that we have a good baseline
with the new algorithm that is
with the new algorithm that is
relatively fast, we are going to use
relatively fast, we are going to use
this uh as a launch point for exploring
this uh as a launch point for exploring
the one issue, the one main issue I have
the one issue, the one main issue I have
with this algorithm at the moment, which
with this algorithm at the moment, which
is there's uh there's this horizon that
is there's uh there's this horizon that
you define that is not supposed to be a
you define that is not supposed to be a
hyperparameter, but kind of works as a
hyperparameter, but kind of works as a
hyperparameter at the moment because of
hyperparameter at the moment because of
quirks. I think the same thing uh there
quirks. I think the same thing uh there
are some potential issues even with our
are some potential issues even with our
PO implementation because of this. So
PO implementation because of this. So
essentially this is something that has a
essentially this is something that has a
high chance of uh resulting in a a
high chance of uh resulting in a a
general improvement to puffer lib
general improvement to puffer lib
overall and then b making this algorithm
overall and then b making this algorithm
actually work uh way better in the way
actually work uh way better in the way
that we would expect it to. We'll do
that we would expect it to. We'll do
some analysis on that. But uh yeah, take
some analysis on that. But uh yeah, take
in two minutes. I'll be right back.
Okay, we are
back. Boom. Goes over there. No
back. Boom. Goes over there. No
more. We've done enough on X for now.
more. We've done enough on X for now.
Let's get some real work
done. Now, it will be tricky.
done. Now, it will be tricky.
So I think that the main
So I think that the main
issue before we
issue before we
uh P30
horizon want to just double check to
horizon want to just double check to
make sure this actually doesn't just
make sure this actually doesn't just
work. I don't think it
does. Come on.
does. Come on.
Where's the
Where's the
uh where's the new
run? There it
run? There it
is. Yeah. So, this is going to take way
is. Yeah. So, this is going to take way
longer here, right?
I think that the main issue with
I think that the main issue with
this, maybe I should
this, maybe I should
uh elaborate a little bit. Right now,
uh elaborate a little bit. Right now,
when you train this new algorithm, it
when you train this new algorithm, it
requires a horizon parameter that tells
requires a horizon parameter that tells
you how many time steps ahead to look.
you how many time steps ahead to look.
Now, you actually get to choose or learn
Now, you actually get to choose or learn
how much you pay attention to those time
how much you pay attention to those time
steps, each of those time steps, which
steps, each of those time steps, which
is the important part. So really what
is the important part. So really what
this parameter is supposed to be is just
this parameter is supposed to be is just
like a compute budget parameter where it
like a compute budget parameter where it
shouldn't even be that expensive to look
shouldn't even be that expensive to look
farther ahead but you know it's a little
farther ahead but you know it's a little
bit it adds a little bit of overhead.
Um now in practice what's happening is
Um now in practice what's happening is
it just doesn't learn properly when you
it just doesn't learn properly when you
set it
set it
longer. And I think let me make sure
longer. And I think let me make sure
that this makes sense. I think that the
that this makes sense. I think that the
reason it doesn't learn, we have how
reason it doesn't learn, we have how
many M's
here, let's
see, 124
see, 124
environments in a batch size
environments in a batch size
ofund. So, it's 128 steps per
ofund. So, it's 128 steps per
environment that are uh in the rollouts.
So if we
So if we
assume that the environments take longer
assume that the environments take longer
than 128 steps, which they mostly do,
than 128 steps, which they mostly do,
you can see at the episode length, then
you can see at the episode length, then
when you compute the
when you compute the
value for
value for
uh like the last 127 steps, you're
uh like the last 127 steps, you're
actually going to be pulling data in
actually going to be pulling data in
from the next environment by accident,
from the next environment by accident,
which you don't want.
which you don't want.
So I think that that is what is
So I think that that is what is
happening here is that you are pulling
happening here is that you are pulling
in data from environments that you
in data from environments that you
shouldn't be looking at because we can't
shouldn't be looking at because we can't
separate boundary conditions the way we
separate boundary conditions the way we
want
want
to. Mind you, it still actually learns
to. Mind you, it still actually learns
just doesn't learn anywhere near as
just doesn't learn anywhere near as
well. Okay.
well. Okay.
So is there an easy way to confirm this?
I don't think
so. I don't think so. I think we have to
so. I don't think so. I think we have to
update the kernel which is annoying.
How do we update
it? I guess it would just be
There's going to be a little bit of
There's going to be a little bit of
fiddly algorithm development for the
fiddly algorithm development for the
next bit here, but it's going to be
next bit here, but it's going to be
important. This could be the thing that
important. This could be the thing that
makes this
makes this
algorithm what it's supposed to be.
I just need to make sure I get it
I just need to make sure I get it
right. Taking different environment
right. Taking different environment
actions. It's not that it's taking
actions. It's not that it's taking
different environment actions. So this
different environment actions. So this
is in the computation of the advantage
is in the computation of the advantage
function. Normally when you compute an
function. Normally when you compute an
advantage function, you start at the
advantage function, you start at the
last time step you have from each
last time step you have from each
environment and then you roll it
environment and then you roll it
backwards. But uh what happens here is
backwards. But uh what happens here is
that you've collected trajectories for a
that you've collected trajectories for a
lot of different environments and you
lot of different environments and you
haven't gotten the done signals from
haven't gotten the done signals from
them yet. So they're just in the buffer
them yet. So they're just in the buffer
partially completed and since there's no
partially completed and since there's no
stop at the end of them uh which it's
stop at the end of them uh which it's
kind of hard to add a stop in this
kind of hard to add a stop in this
situation. It's going to use information
situation. It's going to use information
from the next environment to compute the
from the next environment to compute the
advantage and that gives you a wrong
advantage and that gives you a wrong
calculation. This effect is mitigated in
calculation. This effect is mitigated in
uh generalized advantage estimation
uh generalized advantage estimation
somewhat but uh it's going to be much
somewhat but uh it's going to be much
more important in this algorithm. To be
more important in this algorithm. To be
fair, maybe it affects generalized
fair, maybe it affects generalized
advantage estimation as well. Maybe our
advantage estimation as well. Maybe our
PPO just gets better from this too,
PPO just gets better from this too,
which would be
which would be
fine. Which would be
fine. But yeah, I think what we're going
fine. But yeah, I think what we're going
to do is we're going to have to pass
to do is we're going to have to pass
sort keys cuz this sort keys
thing, it's kind of tricky to calculate
thing, it's kind of tricky to calculate
those bounds.
those bounds.
Honestly, kind of tricky.
Honestly, kind of tricky.
You can't wait for the buffer to
You can't wait for the buffer to
complete. It doesn't work that way. The
complete. It doesn't work that way. The
buffer just stores all of the data
flat. I mean, well, I maybe you can
flat. I mean, well, I maybe you can
maybe I'm being a little bit too
maybe I'm being a little bit too
dismissive. Let me
think. I don't know how you would
The thing is you ne you also wouldn't
The thing is you ne you also wouldn't
necessarily want to because you have to
necessarily want to because you have to
wait for the ms to finish. You can't do
wait for the ms to finish. You can't do
full environment rollouts, right? Some
full environment rollouts, right? Some
environments just take a very long time
environments just take a very long time
to run. So you do need to have
to run. So you do need to have
environment segments.
environment segments.
And this is basically there's no cap on
And this is basically there's no cap on
the end of the segment. It's kind of
the end of the segment. It's kind of
hard to add a
cap, but I like I have a way of doing it
cap, but I like I have a way of doing it
at the moment. I just have to figure out
at the moment. I just have to figure out
it involves a little bit of fiddly index
it involves a little bit of fiddly index
checking. And then I have to actually do
checking. And then I have to actually do
this fiddly index checking in CUDA,
this fiddly index checking in CUDA,
which is
which is
annoying. Um, but if I can figure
out, maybe it's not that bad. If I can
out, maybe it's not that bad. If I can
figure this
figure this
out. Well, hang on. I don't
out. Well, hang on. I don't
have this. Just returns the
indices. That's
rough. I think you sort by N by ID and
rough. I think you sort by N by ID and
then by time step, right?
It' be so much easier to just add
um like you have a truncated signal for
um like you have a truncated signal for
this, don't
this, don't
you? Like wouldn't it be so much easier
you? Like wouldn't it be so much easier
to just
to just
add truncated signal
here? I mean, I can technically do it
here? I mean, I can technically do it
here as a hack and then implement it
here as a hack and then implement it
more generally if it
more generally if it
works. That might do
works. That might do
it. Maybe extend compute
it. Maybe extend compute
time when the buffer
time when the buffer
finishes. Extend compute time. I don't
finishes. Extend compute time. I don't
know how you do that. It's the problem's
know how you do that. It's the problem's
kind of
like it's not that you need more data
like it's not that you need more data
than you have. It's just that you need
than you have. It's just that you need
to know when to stop with the data that
to know when to stop with the data that
you do have. You're basically
you do have. You're basically
overrunning the buffer. I actually So
overrunning the buffer. I actually So
this doesn't work generally because you
this doesn't work generally because you
have asynchronous environments. But I
have asynchronous environments. But I
think that in this case I might have a
think that in this case I might have a
quick
quick
hack if I can just do
D +
T. How do you not
T. How do you not
log? you do log d
here because you don't handle truncated
here because you don't handle truncated
at all.
Okay. I think I have a way to hack it
Okay. I think I have a way to hack it
for now that will let me run my
for now that will let me run my
experiments and see if this actually
matters. Define the number of steps if
matters. Define the number of steps if
you want it to work.
you want it to work.
going to work as
going to work as
intended. So, I don't mind. Yeah. So,
intended. So, I don't mind. Yeah. So,
it's a little fiddly because the thing
it's a little fiddly because the thing
is in the general case, you have
is in the general case, you have
environments that are running in
environments that are running in
different
different
speeds and uh you just get you basically
speeds and uh you just get you basically
just get a bunch of flat data that you
just get a bunch of flat data that you
don't have any way to organize until you
don't have any way to organize until you
have all of it. But then when you have
have all of it. But then when you have
all of it, right, each environment,
all of it, right, each environment,
maybe you've collected some full
maybe you've collected some full
episodes, but then each environment has
episodes, but then each environment has
a piece at the end that kind of hangs
a piece at the end that kind of hangs
off and you don't have any way of
off and you don't have any way of
telling that. I mean, like I have the
telling that. I mean, like I have the
general purpose way of fixing this is to
general purpose way of fixing this is to
fiddle with the indices and um propagate
fiddle with the indices and um propagate
that change into CUDA and then the issue
that change into CUDA and then the issue
should be fixed. But
should be fixed. But
um before then it's a little hard.
I say
10:24. 1024. So
Let's do it this
way. Experience
way. Experience
pointer batch size
minus. Uh, you can't do that. So, I got
minus. Uh, you can't do that. So, I got
to do
to do
We'll just hard code.
Okay, let's see. Uh let's see what this
Okay, let's see. Uh let's see what this
does for comparison.
Yeah, if this is not going to be like an
Yeah, if this is not going to be like an
instantaneous
instantaneous
fix.
fix.
Huh? Hang
Huh? Hang
on. Oh, no. It's pretty darn close to
on. Oh, no. It's pretty darn close to
the original
the original
curve. We'll see if it breaks away. if
curve. We'll see if it breaks away. if
there's like a big
there's like a big
difference. Maybe this is not the issue
difference. Maybe this is not the issue
though. We'll see.
This could totally also be a
This could totally also be a
normalization issue, couldn't
normalization issue, couldn't
it? Let's go look at
it? Let's go look at
that. How do we compute
stuff? Oh, wait. Actually, I think I
stuff? Oh, wait. Actually, I think I
might know.
might know.
missing
advantage. Yeah. So the advantage
advantage. Yeah. So the advantage
is we make those sum to
one
but we don't
but we don't
bother with the other loss making that
bother with the other loss making that
sum to one. Okay, hang
sum to one. Okay, hang
on.
on.
So how do we test
that? I guess what we do is
be
lost. Okay, so this actually does do
lost. Okay, so this actually does do
better. I don't know if it's
better. I don't know if it's
significantly better, but we will see.
significantly better, but we will see.
The next thing I want to try is this in
The next thing I want to try is this in
which we mask the value
loss. And we'll see what this
loss. And we'll see what this
does. Essentially, this would say that
does. Essentially, this would say that
hey, the problem
hey, the problem
is the problem is not in the advantage
is the problem is not in the advantage
function. The problem's right here. This
function. The problem's right here. This
worked.
Oh, this is
worse. How's that possible,
worse. How's that possible,
right? Did I mess something
up? Shouldn't be possible for this to be
up? Shouldn't be possible for this to be
worse.
Okay, it catches back up. It has a weird
Okay, it catches back up. It has a weird
curve
though. Very weird
though. Very weird
curve. Yeah, these are still definitely
curve. Yeah, these are still definitely
different. I'm going to run it again
different. I'm going to run it again
just because there's crazy seed variance
just because there's crazy seed variance
in RL sometimes, but I'm guessing Okay.
interesting.
So, we should probably check to make
So, we should probably check to make
sure that the original still works under
sure that the original still works under
this condition, right?
So, I can't think of
So, I can't think of
why why
why why
else this doesn't work. Unless I've
else this doesn't work. Unless I've
messed up the indexing, which would be
messed up the indexing, which would be
hilarious in its own way. But looking at
hilarious in its own way. But looking at
this, the curves are actually relatively
this, the curves are actually relatively
consistent.
The curves are relatively
consistent. Is it actually possible I
consistent. Is it actually possible I
messed up the ordering of this?
That would be really out there.
Okay, we'll try this as a baseline.
Okay, we'll try this as a baseline.
Whoops, not this one. Hold
on. Okay, we'll let that run.
on. Okay, we'll let that run.
buffer
buffer
size. It's not that
size. It's not that
anymore. There's something else weird
anymore. There's something else weird
going on that we have to figure out.
going on that we have to figure out.
Reply to this guy real quick.
I'll do it here. This one makes more
I'll do it here. This one makes more
sense.
I it drives me nuts because the thing is
I it drives me nuts because the thing is
it's not that these things aren't
it's not that these things aren't
important. It's that in the context that
important. It's that in the context that
they were brought up, they're completely
they were brought up, they're completely
irrelevant.
Oops. Let's get rid of that
Oops. Let's get rid of that
bot. Stupid
bot. Stupid
thing. Victorious. Yeah, great username.
thing. Victorious. Yeah, great username.
That
Okay. Yeah.
preprint. There's a blog
And the funny thing about this is that
And the funny thing about this is that
all this conversation does is like
all this conversation does is like
reinforces that a lot of safety research
reinforces that a lot of safety research
are just very unserious people.
It's like mandate of heaven must do
It's like mandate of heaven must do
safety in all things even where safety
safety in all things even where safety
is not even a remotely a
concern. Okay. So this original here
concern. Okay. So this original here
this still works. So that's very
this still works. So that's very
interesting, right? This original
interesting, right? This original
here still pretty well works. Yeah, this
here still pretty well works. Yeah, this
is about the same as
is about the same as
before. Don't want their internal
before. Don't want their internal
data. This again, it's not what this is.
data. This again, it's not what this is.
I mean, this is literally godfather of
I mean, this is literally godfather of
RL giving his opinion on like what
RL giving his opinion on like what
directions are promising or not. if you
directions are promising or not. if you
want to understand intelligence and it's
want to understand intelligence and it's
like yeah I don't think safety is
like yeah I don't think safety is
particular like safety or privacy are
particular like safety or privacy are
particularly relevant here and it's like
particularly relevant here and it's like
ah but this is morally distasteful that
ah but this is morally distasteful that
you haven't considered safety and
you haven't considered safety and
privacy in not deploying AI but in
privacy in not deploying AI but in
sitting in your lab doing algorithms
research. I mean this is like ah but you
research. I mean this is like ah but you
in your lab did you think of the
in your lab did you think of the
children in Africa while you were doing
children in Africa while you were doing
that? It's like, okay, maybe I thought
that? It's like, okay, maybe I thought
about them another time, but now not now
about them another time, but now not now
specifically because there's no
specifically because there's no
relevance whatsoever, right? It's just
relevance whatsoever, right? It's just
like, this is the problem that you see
like, this is the problem that you see
though with a lot of the safety folks is
though with a lot of the safety folks is
it's just moral grandstanding where it's
it's just moral grandstanding where it's
completely
completely
unjustified. A lot of the times it's
unjustified. A lot of the times it's
like, yeah, you're also sitting in your
like, yeah, you're also sitting in your
lab writing algorithms, but you're being
lab writing algorithms, but you're being
holier than thou about it and insulting
holier than thou about it and insulting
other researchers.
Ridiculous. Well, that was at least the
Ridiculous. Well, that was at least the
most respectful conversation I've had
most respectful conversation I've had
with somebody in in safety. So, I'll
with somebody in in safety. So, I'll
give it that. I just It's just a
give it that. I just It's just a
Byzantine argument to me, though. It's a
Byzantine argument to me, though. It's a
Byzantine argument. Probably to slow
Byzantine argument. Probably to slow
down progress. Now, if we want to get on
down progress. Now, if we want to get on
moral high ground, that I cannot accept
moral high ground, that I cannot accept
because we're building tech that
because we're building tech that
genuinely improves a lot of stuff. And
genuinely improves a lot of stuff. And
this will get into medicine. This will
this will get into medicine. This will
get into a ton of really important
get into a ton of really important
areas. That's why I get up in the
areas. That's why I get up in the
morning. All right. So, slowing down
morning. All right. So, slowing down
progress. No, no quarter giving.
I don't know. There are a lot of like
I don't know. There are a lot of like
really crazy ideas on these topics as
really crazy ideas on these topics as
well that are like mainly SF bros being
well that are like mainly SF bros being
very very very out of touch with
very very very out of touch with
reality. This wasn't that to be fair.
reality. This wasn't that to be fair.
This was somewhat more down to earth,
This was somewhat more down to earth,
but still
but still
it's there's
it's there's
like it's just not getting
through. Well, we have a clear clearcut
through. Well, we have a clear clearcut
example here
example here
of what's going
wrong. There are a couple possibilities,
wrong. There are a couple possibilities,
I guess.
I guess.
So let me think here we get values
So let me think here we get values
mean values standard
deviation of indices
here. And then we pass this
in to the advantage
function. Does this get done
function. Does this get done
twice? I think it gets done twice,
right?
Those are the blocks we need to move
Those are the blocks we need to move
past. Find this happening in government
past. Find this happening in government
security a lot. Probably spoken a lot of
security a lot. Probably spoken a lot of
them. Yeah.
them. Yeah.
And it's just
like the thing that drives me crazy is
like the thing that drives me crazy is
that like the thing that they say that
that like the thing that they say that
they're worried about doesn't even make
they're worried about doesn't even make
sense if you use their own arguments,
sense if you use their own arguments,
right? They say like we should slow down
right? They say like we should slow down
tech in order to make sure stuff is
tech in order to make sure stuff is
safe, right? And then they like they
safe, right? And then they like they
talk about like, you know, doomer type
talk about like, you know, doomer type
stuff. It's like, well, okay, this
stuff. It's like, well, okay, this
doesn't even make sense from your
doesn't even make sense from your
perspective because even if we were to
perspective because even if we were to
suppose that the concerns that you're
suppose that the concerns that you're
raising, which may or may not even hold
raising, which may or may not even hold
any water, if even if we assume you're
any water, if even if we assume you're
100% correct about everything and like
100% correct about everything and like
AI is going to destroy everything if we
AI is going to destroy everything if we
do it wrong and like AI is going to get
do it wrong and like AI is going to get
into all the bad applications and
into all the bad applications and
whatever, if you slow it down, China or
whatever, if you slow it down, China or
another country is just going to do it
another country is just going to do it
first. Do you think they care about any
first. Do you think they care about any
of this stuff? No. No, they
don't. So, you're just guaranteeing that
don't. So, you're just guaranteeing that
it's done, you know, in the exact way
it's done, you know, in the exact way
that you don't want by slowing it down.
that you don't want by slowing it down.
That's
all. It makes no sense to me at
all. It's like a very, very weird
all. It's like a very, very weird
academic perspective.
Let me try one other
thing. Can I even do
thing. Can I even do
this values man?
this values man?
think I
can. Yeah, this will work if I just
do academic people. It is
weird. Well, but the thing is nobody's
weird. Well, but the thing is nobody's
telling you that you have to expose like
telling you that you have to expose like
nobody's telling you that you have to,
nobody's telling you that you have to,
right? It's an invented concern. If you
right? It's an invented concern. If you
don't want to use tech that leaks data,
don't want to use tech that leaks data,
don't use the tech.
And also like privacy stuff going wrong
And also like privacy stuff going wrong
is more like big supervised ML people,
is more like big supervised ML people,
not RL people anyway. So it's
not RL people anyway. So it's
moot. I haven't really seen anything
moot. I haven't really seen anything
like this in RL going wrong.
We'll see what this
We'll see what this
does. If this doesn't work, then there's
does. If this doesn't work, then there's
a data
a data
problem. This doesn't work, then there
problem. This doesn't work, then there
should be a data
problem. But the Pokemon stuff's doing
problem. But the Pokemon stuff's doing
pretty nice.
Okay. So, we shouldn't build gradient
descent. It just that just doesn't make
descent. It just that just doesn't make
any sense.
Yeah, that's very
Yeah, that's very
weird. This is
weird. This is
funny. I love it when he just sets me up
funny. I love it when he just sets me up
for
for
this. Thanks for the ad, Sam.
lots of assumptions without oh the uh
lots of assumptions without oh the uh
the net hack thing. Yeah, it's well the
the net hack thing. Yeah, it's well the
other thing that's just like is kind of
other thing that's just like is kind of
bullshitty here. So Tim is a Google
bullshitty here. So Tim is a Google
DeepMind researcher, right? He has he
DeepMind researcher, right? He has he
runs a team at DeepMind. So like yeah,
runs a team at DeepMind. So like yeah,
they've got all the compute in the world
they've got all the compute in the world
to do whatever they want and like armies
to do whatever they want and like armies
of people on the internet who are going
of people on the internet who are going
to go run evaluations on their stuff
to go run evaluations on their stuff
because LLMs are currently the hot
because LLMs are currently the hot
thing, right? But like the stuff we're
thing, right? But like the stuff we're
doing nobody else is doing and like know
doing nobody else is doing and like know
there's a lot of potential that you're
there's a lot of potential that you're
wrong and that we're going to come up
wrong and that we're going to come up
with some cool generalizable methods
with some cool generalizable methods
because we can run experiments in RL a
because we can run experiments in RL a
thousand times faster than the vast
thousand times faster than the vast
majority of researchers were ever able
majority of researchers were ever able
to run experiments in RL. Right? You do
to run experiments in RL. Right? You do
a thousand times more experiments. So
a thousand times more experiments. So
you're going to uncover some cool stuff
you're going to uncover some cool stuff
probably.
probably.
Um so I don't know. It's like Tim used
Um so I don't know. It's like Tim used
to do uh used to do like pure RL stuff
to do uh used to do like pure RL stuff
and kind of just went all the way onto
and kind of just went all the way onto
LLM
train. I think that the LLMs are
train. I think that the LLMs are
currently taking too many resources away
currently taking too many resources away
from the rest of research. Like don't
from the rest of research. Like don't
get me wrong, what's going on is kind of
get me wrong, what's going on is kind of
crazy with them, but they should take
crazy with them, but they should take
80% of the research uh resources from
80% of the research uh resources from
research, not 99% of the
resources. Okay, perfect. So, this is a
resources. Okay, perfect. So, this is a
clearcut case of unless I'm missing
clearcut case of unless I'm missing
anything. I don't think I am. This is a
anything. I don't think I am. This is a
clearcut
clearcut
case. Something's just
case. Something's just
brewy right
here. Okay.
So, B flat
values
mean B values
mean. There's no way this should be
mean. There's no way this should be
different. This should be identical to
different. This should be identical to
the previous.
This is exciting though because if
This is exciting though because if
there's actually a bug and it's already
there's actually a bug and it's already
working this
working this
well, just a tactic to slow things
well, just a tactic to slow things
down. They didn't have anything to say
down. They didn't have anything to say
when LM are being
when LM are being
trained now that they aren't post
trained now that they aren't post
training. I wouldn't say that so much
training. I wouldn't say that so much
because a lot of the LLM people, there
because a lot of the LLM people, there
are LLM people that are like
are LLM people that are like
legitimately just full steam ahead
legitimately just full steam ahead
trying to make AI work, right? But the
trying to make AI work, right? But the
thing that they don't realize is the way
thing that they don't realize is the way
to do that, like you don't need to crowd
to do that, like you don't need to crowd
out the rest of AI. You already have all
out the rest of AI. You already have all
the resources, right?
the resources, right?
Like I just like leave a couple scraps
Like I just like leave a couple scraps
so we can investigate some other areas
so we can investigate some other areas
in case you're wrong, right?
Do you know how much easier it would be
Do you know how much easier it would be
to do what I'm doing right now with
to do what I'm doing right now with
Puffer? If I were doing this
Puffer? If I were doing this
in
in
2018, like when RL was all the rage,
2018, like when RL was all the rage,
we'd have like dozens and dozens of
we'd have like dozens and dozens of
people building these environments. Like
people building these environments. Like
RL would actually be so so far ahead.
RL would actually be so so far ahead.
Heck, you know, if OpenAI had just left
Heck, you know, if OpenAI had just left
left their Dota team alone and let them
left their Dota team alone and let them
keep doing some RL and keep pushing out
keep doing some RL and keep pushing out
some results, we'd be in a good place
some results, we'd be in a good place
even now. It's just that like all the
even now. It's just that like all the
resources were drained out of RL. And um
resources were drained out of RL. And um
you know, it's fine. Like I'm fixing it
you know, it's fine. Like I'm fixing it
now, but it's it's a heck of a lot of
now, but it's it's a heck of a lot of
work and it's a lot more work than it
work and it's a lot more work than it
had to have
had to have
been. Unfortunately, you know, back in
been. Unfortunately, you know, back in
20 uh like 2018, I was like a plucky 20
20 uh like 2018, I was like a plucky 20
year old who didn't have the uh the
year old who didn't have the uh the
engineering skills to do all of this,
engineering skills to do all of this,
which is why I couldn't do it back then.
which is why I couldn't do it back then.
But uh you know, now I do have the
But uh you know, now I do have the
skills, but okay, you know, stuff's
skills, but okay, you know, stuff's
cooled down a little bit. So, bad
cooled down a little bit. So, bad
timing, but we'll get it working
timing, but we'll get it working
anyways.
damn their compute for commercial
damn their compute for commercial
purposes.
Yeah. Well, with Puffer now, we don't
Yeah. Well, with Puffer now, we don't
need a ton of compute to be running all
need a ton of compute to be running all
these experiments, which is the cool
these experiments, which is the cool
thing. We still need a little bit. And
thing. We still need a little bit. And
we need a little bit more than we have
we need a little bit more than we have
now. So, I'm dealing with fixing that.
now. So, I'm dealing with fixing that.
Uh I'm going to be fixing that pretty
Uh I'm going to be fixing that pretty
soon.
But yeah,
Where does this get
used values
mean? We get B values
mean? We get B values
mean,
right? So how then does this get messed
right? So how then does this get messed
up?
And something's clearly very
wrong. So we debug
wrong. So we debug
this new value mean new value
this new value mean new value
std reward block
right be reward
block. Oh, hang
on. I think I see
it. Wait. Reward block master
it. Wait. Reward block master
block
advantages block.
Isn't this it right
here? Isn't this of
here? Isn't this of
idxes or is it
not? Wait. Reward
not? Wait. Reward
block. Mask block.
Hang
on. Oh, it probably gets copied as Y,
right? Yeah, hang on. It probably just
right? Yeah, hang on. It probably just
gets copied.
So, how do I do this
then? Let me try something else.
Maybe if I do it this way.
I times horizon. No, this still doesn't
I times horizon. No, this still doesn't
work. No point in even trying
work. No point in even trying
that.
Um, that's rough.
I do this. Does this do anything?
Missing
horizon. Maybe we don't have a straight
horizon. Maybe we don't have a straight
up bug
yet. But it is
suspicious. It is suspicious.
We shall see.
Okay. Is this
something?
Hello. Oh, wrong
one. So, it's still screwy, huh?
one. So, it's still screwy, huh?
Unless it's going to dissolve it right
Unless it's going to dissolve it right
now, but I don't think
so. So
so. So
there's I guess to explain what's
there's I guess to explain what's
happening
happening
here. Um the algorithm has a horizon
here. Um the algorithm has a horizon
parameter. It performs way way it should
parameter. It performs way way it should
strictly perform better with longer
strictly perform better with longer
horizon. it performs pretty much way
horizon. it performs pretty much way
worse with larger uh larger
worse with larger uh larger
horizon
horizon
and like setting it to longer horizon
and like setting it to longer horizon
but then nulling out the effect of what
but then nulling out the effect of what
should be happening with the extra extra
should be happening with the extra extra
time steps doesn't
time steps doesn't
help. So
essentially something is broken about
essentially something is broken about
the way that it
the way that it
is. Something's just fundamentally
is. Something's just fundamentally
broken about the implementation and I'm
broken about the implementation and I'm
trying to figure out
what mass
what mass
block. Word block. Mass block.
I've checked this portion of the code to
I've checked this portion of the code to
death, haven't
I? B
values
values
flat turns
You pass these in nicely sorted
You pass these in nicely sorted
already. Word block and mass block get
already. Word block and mass block get
passed in.
Unless I have this
wrong. I wonder if this is
wrong. I
think this could be wrong, couldn't it?
Wait, where's BPT Horizon
Wait, where's BPT Horizon
here?
here?
Reshape. Uhoh.
Okay, you you use this in a
Okay, you you use this in a
flat output
here. This could be it,
here. This could be it,
right? That you have this messed up.
Use returns
just
reshape mini batches.
reshape mini batches.
mini batch
size. It's tough to know. Like, it's
size. It's tough to know. Like, it's
tough when you don't know for sure.
Why does this even need to be reshaped
again? Bet rows. Nin
batches. It seems weird to
batches. It seems weird to
me. that this uh that you even need that
me. that this uh that you even need that
transpose, doesn't
We can just look at
We can just look at
these. We might be able to get something
these. We might be able to get something
just out of this. Let's take Neptune
just out of this. Let's take Neptune
off. Close this down.
Fiddly debugging. Fiddly debugging.
Okay, this one is the same.
And these are the
same. I'm trying to think what else it
same. I'm trying to think what else it
would be
though.
Hang on. Maybe we need to look a little
Hang on. Maybe we need to look a little
bit more closely.
Try
Try
this Neptune back on as well.
That should definitely compute the same
That should definitely compute the same
thing as as uh
thing as as uh
before. I'm going have to remember to
before. I'm going have to remember to
just take that out immediately so I
just take that out immediately so I
don't
forget. It's a little
silly. The notifications just keep
silly. The notifications just keep
rolling on these. That's crazy.
Yeah, but Atari 100K was just a
Yeah, but Atari 100K was just a
god-awwful
benchmark. Okay, this may be something.
Okay, maybe this actually
works. Yeah. Okay. So, this actually
works. Yeah. Okay. So, this actually
works. Interesting.
So, it is the fact that you're using the
So, it is the fact that you're using the
additional data that screws you
up that this makes sense. Here's a rest.
up that this makes sense. Here's a rest.
I'll be right back and then we'll think
I'll be right back and then we'll think
about what that means.
Oops. A little hiccup at the end of the
Oops. A little hiccup at the end of the
training there, but that's way closer.
training there, but that's way closer.
So, it is
So, it is
legitimately that including the extra
legitimately that including the extra
data somehow messes you
data somehow messes you
up. Hey, I can deal with that. At least
up. Hey, I can deal with that. At least
there's a target to hit.
[Music]
X
Oh, hang on. Is this what you
want? I think this is what you want.
Didn't you just completely clip this
wrong? I think you just massively
wrong? I think you just massively
screwed up your clipping factor.
Vantage
scale B
max. Why would you do that?
Oh, I think it's because um Hang
on. Yeah. No, I think you just messed up
on. Yeah. No, I think you just messed up
the way that you were trying to wait
the way that you were trying to wait
this thing, didn't you?
So let me let me look at
this value standard deviation.
Advantage
scale. Hang on.
Max minus standard deviation over
delta. How's that make
delta. How's that make
sense? You just do this one, right? And
sense? You just do this one, right? And
then if anything, you're supposed to
then if anything, you're supposed to
clip later on. Let's let's run this and
clip later on. Let's let's run this and
see what happens.
Now, I remember what I was trying to do
Now, I remember what I was trying to do
with this, but I don't think I actually
with this, but I don't think I actually
implemented
implemented
it correctly.
it correctly.
Holy, these just notifications just keep
Holy, these just notifications just keep
going.
Yeah, I'm updating my take on this
Yeah, I'm updating my take on this
following the responses to this.
following the responses to this.
Um, the thing that makes me now more
Um, the thing that makes me now more
suspicious of LMS is the types of
suspicious of LMS is the types of
comments I get from people that are
comments I get from people that are
clearly using them heavily. Holy
hell. There's some of these out.
I mean, it was a comment more about
I mean, it was a comment more about
programming in general. It's just
programming in general. It's just
like you get better at programming and
like you get better at programming and
you understand how to solve more
you understand how to solve more
problems by getting closer to the
problems by getting closer to the
hardware, not by like pretending it
hardware, not by like pretending it
doesn't exist and programming in
doesn't exist and programming in
English. That's not even a phrase that
English. That's not even a phrase that
makes
sense. It's like, yeah, eventually I can
sense. It's like, yeah, eventually I can
do all the programming and everything
do all the programming and everything
else, but that doesn't mean that like,
else, but that doesn't mean that like,
oh yeah, now we do whatever. It's like,
oh yeah, now we do whatever. It's like,
no, you have no added value
whatsoever. It's like you're bragging
whatsoever. It's like you're bragging
that you didn't learn anything and now
that you didn't learn anything and now
you can do something that previously
you can do something that previously
took training worse than somebody who's
took training worse than somebody who's
trained at it.
Congratulations. You're basically
Congratulations. You're basically
bragging that you're lazy and you don't
bragging that you're lazy and you don't
want to learn anything.
All right, here we
All right, here we
are. Okay, so we can cut this norm
are. Okay, so we can cut this norm
factor out, I guess. I don't know what I
factor out, I guess. I don't know what I
was trying to do with this, but uh it
was trying to do with this, but uh it
doesn't really make sense, whatever it
doesn't really make sense, whatever it
is. I think it was like legacy,
is. I think it was like legacy,
honestly, from when I
had Let me
had Let me
see. I'll use
see. I'll use
mean. Yeah, this must have been
legacy. I think the issue is
legacy. I think the issue is
um was with this scale, wasn't
um was with this scale, wasn't
it? Minus V standard deviation.
it? Minus V standard deviation.
Wait. VSTD
Max. Oh, of
course. Of course I get bitten for like
course. Of course I get bitten for like
of course I uh I get penalized for this
of course I uh I get penalized for this
freaking
freaking
llm. The one time I actually tried to uh
llm. The one time I actually tried to uh
to just translate a piece of code, not
to just translate a piece of code, not
even to write new code, just to
even to write new code, just to
translate code, I get dinged for it. Of
translate code, I get dinged for it. Of
course. serves me
right. What I was trying to do
right. What I was trying to do
originally
here, B standard deviation minus
buff. Thank
buff. Thank
you. This is going to be a very
you. This is going to be a very
unstable sort of situation, isn't
unstable sort of situation, isn't
it? Maybe not.
Okay, let me think about how we
Okay, let me think about how we
normalize this because this is all in
normalize this because this is all in
the norm.
Now you have a distribution
Does this need to be normal to
Huh? It would seem weird to normalize
Huh? It would seem weird to normalize
this to one.
How weird is it that if you norm it to
How weird is it that if you norm it to
one
Not that weird
Not that weird
actually. I think we should try it.
subtract the
subtract the
min and you divide by the
min and you divide by the
max minus the min,
right? But that doesn't penalize uh
right? But that doesn't penalize uh
uncertainty either.
Why can't this just be
Why can't this just be
VFPD minus VFPD
min? Like is there a problem with
this? Oops. What happened here?
Oh, yeah. This totally works,
right? Except that you have it Wait, you
right? Except that you have it Wait, you
have it backwards here. So, it's got to
be Yeah, it's got to be like this. Max
be Yeah, it's got to be like this. Max
minus
min. So you subtract them in, you divide
min. So you subtract them in, you divide
by this delta. So you linearize
um you just linearize
um you just linearize
this and then you
this and then you
divide that they sum to one.
We'll see how that plays out.
CUDA
error device side
assert.
Lovely probability contains in or nan.
Subtract men divide by
Subtract men divide by
delta advantage
sum.
Lovely. Halfway decent
engineer. I was like, what the hell?
engineer. I was like, what the hell?
Halfway decent engineer. What the hell
Halfway decent engineer. What the hell
do you see me deving right here?
have to deal with coup errors which is
have to deal with coup errors which is
always
fun. It's probably all in just this
fun. It's probably all in just this
advantage scale
advantage scale
thing. Wouldn't be surprised.
We'll have to do a little bit of
We'll have to do a little bit of
separate normalization on the uh other
separate normalization on the uh other
part of the value function
part of the value function
but be fine
otherwise still yeah cuda error
otherwise still yeah cuda error
lovely all right what's going to nanner
lovely all right what's going to nanner
in for whatever
here maxus
and BSTD minus
um I don't understand what it would be
um I don't understand what it would be
that would be out of bounds
that would be out of bounds
here. It's got to be the sum is zero,
here. It's got to be the sum is zero,
right?
But that's sketchy as hell.
Okay. So it is this thing somehow being
Okay. So it is this thing somehow being
zero which
is means that this thing somehow has to
be this thing somehow has to be zero.
crazy that that actually kind of learns.
I think we want to just
I think we want to just
subtract not the overall
And vantage scale.
I think we want to do this a little
differently. The SGD men
about to make an order for personal
about to make an order for personal
machine. Well, I know that I ordered my
machine. Well, I know that I ordered my
machine a long time ago and haven't
machine a long time ago and haven't
gotten it
yet. So, I would check on how long it
yet. So, I would check on how long it
takes him to get you the machine.
takes him to get you the machine.
I haven't heard anything specifically on
I haven't heard anything specifically on
the power cable issues, but yeah, I
the power cable issues, but yeah, I
think it's still an issue.
8 to 12 weeks.
Crazy. Yeah. I don't know what we're
Crazy. Yeah. I don't know what we're
going to do with compute with the uh the
going to do with compute with the uh the
mess this thing's been
in. I mean, I don't think I should have
in. I mean, I don't think I should have
just like ordered all the
just like ordered all the
machines like day one.
without testing to see if they even
without testing to see if they even
work. That would have been a nightmare,
work. That would have been a nightmare,
but takes a while.
Okay. So we compute this.
Okay. Try this.
Whoops. That has to be
deleted.
deleted.
T. Why don't I do T?
forget the trailing
forget the trailing
comm. There we go.
So now this is going to be normalized to
So now this is going to be normalized to
uh the individual
uh the individual
row. That will give you a lot more
row. That will give you a lot more
stable time stepwise
stable time stepwise
estimate. I don't think it messes
estimate. I don't think it messes
anything up. We'll see.
138 likes on the uh the tweet from today
138 likes on the uh the tweet from today
on uh
Pokemon. Not bad for the day two one.
Pokemon. Not bad for the day two one.
So that's
So that's
another 4,000 some odd
another 4,000 some odd
views. We're doing good advertising for
views. We're doing good advertising for
Pokemon
still
still
runs
782. Now
782. Now
what? I should be able to get rid of
what? I should be able to get rid of
this term, right? That'll tell me
this term, right? That'll tell me
something if this still crashes.
Yeah. So, this should not change PF very
Yeah. So, this should not change PF very
much at
much at
all. Uh if it even has any effect. It
all. Uh if it even has any effect. It
really shouldn't do anything. But, uh
really shouldn't do anything. But, uh
the fact that the kernel was crashing
the fact that the kernel was crashing
before was an issue.
before was an issue.
This should now be reasonably
correct. Yeah, it looks nice.
Okay.
Okay.
Now, is this
Now, is this
enough? I mean, we now
enough? I mean, we now
have
linearized we have linearized
linearized we have linearized
advantages.
So, I mean, we should in theory just be
So, I mean, we should in theory just be
able to set
able to set
this back to horizon 128 steps and it
this back to horizon 128 steps and it
should work
theory and if not, we'll have to look at
theory and if not, we'll have to look at
why. Yeah, these latest graphs are uh we
why. Yeah, these latest graphs are uh we
have any graphs on this or is this
have any graphs on this or is this
offline? Okay, I didn't log in to
offline? Okay, I didn't log in to
Neptune,
but this will be reasonable. Now, mind
but this will be reasonable. Now, mind
you, the when we change the algorithm at
you, the when we change the algorithm at
all, uh it's optimized for a specific
all, uh it's optimized for a specific
set of hyperparameters. So, little perf
set of hyperparameters. So, little perf
dip is kind of
dip is kind of
okay if we think it's going to make it
okay if we think it's going to make it
more robust. So, we can always
more robust. So, we can always
retune. Big PF dip should not really
retune. Big PF dip should not really
happen.
We
We
go. And there we And it solves anyways.
go. And there we And it solves anyways.
There you
There you
go. Basically
solves
840. Next will be
and presumably this screws stuff up,
and presumably this screws stuff up,
right? Because it always
does. But now we at least have some way
does. But now we at least have some way
of looking at uh
of looking at uh
What's getting screwed up and
why? All
why? All
right. Yeah. So, this is again way
worse. I am curious to see if it's going
worse. I am curious to see if it's going
to line up with the previous curves
to line up with the previous curves
though or if there will at least be some
difference. I'll be right back while
difference. I'll be right back while
this runs
400 score. Just in time to see 400
score. Very much in line with the
score. Very much in line with the
previous.
previous.
Okay. A little better. Probably not
Okay. A little better. Probably not
statistically significant.
statistically. What's in buffer? Buffer
statistically. What's in buffer? Buffer
contains the advantage skills, doesn't
contains the advantage skills, doesn't
it? Buffer contains advantage
skills. So, if I just go
here's this
thing. No, it's um P30 should work. It
thing. No, it's um P30 should work. It
should work the same or better if you
should work the same or better if you
increase the horizon. And there's
increase the horizon. And there's
something screwy with the way that I
something screwy with the way that I
have it set up that it doesn't. So, I
have it set up that it doesn't. So, I
think that I'm going to be able to make
think that I'm going to be able to make
the algorithm much better, but um I have
the algorithm much better, but um I have
to, you know, it relies on me being able
to, you know, it relies on me being able
to figure out this
thing. Okay. So, there is
thing. Okay. So, there is
There is what is in
buff. That doesn't look right to me.
buff. That doesn't look right to me.
Does that look right to
Does that look right to
you? Not at
you? Not at
all.
0.5 standard deviation is all
0.5 standard deviation is all
one. How's that work?
value standard deviation minus the
mean. Oops.
No zeros in here,
No zeros in here,
right?
One. So that ought to be I mean that
One. So that ought to be I mean that
ought to be just
ought to be just
one. Why does it contain 0.5s?
What the heck is this?
0.5
0.5
delta. What's delta in
delta. What's delta in
here? Delta
here? Delta
is max minus min.
There's no log in CUDA is
there over
delta. Delta equals Z.
delta. Delta equals Z.
Don't modify the buffer anymore though,
Don't modify the buffer anymore though,
do
you? 7 126
you? 7 126
125. And that seems kind of weird to me,
125. And that seems kind of weird to me,
doesn't
doesn't
it? 126 125
Oh no, it doesn't. This is fine.
Why in the
heck? Oh, hold
heck? Oh, hold
on. Did I mess something up
on. Did I mess something up
here? Because if you divided
here? Because if you divided
by the delta would still be one though,
by the delta would still be one though,
right?
Nauseous. Yeah, it's all once.
Buffer is equal to advantage scale.
Hang on. That last one is like blue,
Hang on. That last one is like blue,
isn't
it?
Dun. Ah, okay.
Dun. Ah, okay.
[Music]
So yeah, you have the done at the end
So yeah, you have the done at the end
there.
there.
Okay, so you get the standard
deviations, you go up to
127, you set it
127, you set it
to scale over
to scale over
delta, which
delta, which
is max minus min.
That's going to either it's that's going
That's going to either it's that's going
to be
one delta is one. Yeah, I don't see how
one delta is one. Yeah, I don't see how
this gets to be 0.5 instead of
two. I have to put this on
B standard deviation.
Okay. Well, this is going to drive me
Okay. Well, this is going to drive me
insane. I'm going to just try some stuff
insane. I'm going to just try some stuff
so that we don't spend forever on this.
I don't see anything wrong with this
I don't see anything wrong with this
code. I'm getting kind of tired.
E10. Ah, lovely.
You did
this. That's a major error. I'm
this. That's a major error. I'm
surprised it worked at all.
Okay. So now this is all
Okay. So now this is all
ones except for the zero where
ones except for the zero where
it's not applicable.
it's not applicable.
Right. Perfect. And then you're dividing
Right. Perfect. And then you're dividing
by sum.
Five now.
Interesting that they all went down by
Interesting that they all went down by
the same
amount. There might need to be some
amount. There might need to be some
symmetry breaking
here. But then what happened to buff
That's all over the place, isn't
it? Value of standard deviation of
index delta is equal to
index delta is equal to
zero. And none of this modifies the
zero. And none of this modifies the
buffer. The only place the buffer gets
buffer. The only place the buffer gets
modified is right there at the
start. It's men divide by
delta. Okay. The values means all
delta. Okay. The values means all
different but that doesn't matter
right there isn't even 32
elements there 16
elements there 16
elements. How does that make any sense?
This is 32
This is 32
elements. How this happened
Maybe it didn't get
set. Or maybe you didn't zero
set. Or maybe you didn't zero
it. It wouldn't make sense for you not
it. It wouldn't make sense for you not
just to have not zeroed it.
just to have not zeroed it.
Like that would just leave ones in it.
It's the
men
delta. That was very weird. That was
delta. That was very weird. That was
very very weird.
So many
questions. Second
epoch. First of all, the values are all
epoch. First of all, the values are all
the same for some reason still.
Second of
Second of
all, scale still
zero. It should be like one.
zero. It should be like one.
Unless Dun's different. Hold on. Maybe
Unless Dun's different. Hold on. Maybe
Dun's
Dun's
off. Ah, wait. Maybe that's what it is.
off. Ah, wait. Maybe that's what it is.
Hang on.
Okay. So, there's your done.
Okay. So, there's your done.
Stop
this 16 steps
in. So that's why you only have 16
in. So that's why you only have 16
values. So that's
values. So that's
fine. Then the values
themselves advantage
scale. Yeah, that doesn't make any sense
scale. Yeah, that doesn't make any sense
to me.
not overwriting it or anything,
right?
Very
Very
weird. Um,
weird. Um,
okay. We're going to start this
okay. We're going to start this
shenanigans again.
You can't do break points in right
Is
there could
GDP? You just install this thing and
GDP? You just install this thing and
Hang
on. Okay. So, yeah, that changes it a
on. Okay. So, yeah, that changes it a
lot. So, there's like some noise or
lot. So, there's like some noise or
something here, I think. Yeah, there's
something here, I think. Yeah, there's
some like very slight
some like very slight
noise thing going on
noise thing going on
here. Let's see if this works.
Oh, this does work.
I see. So, if I wanted to go through
I see. So, if I wanted to go through
this, I'd actually have to like write a
this, I'd actually have to like write a
CUDA test or something, which is a
CUDA test or something, which is a
little annoying
little annoying
with the the way that this is bound to
with the the way that this is bound to
Python.
Okay. But the fact that this
Okay. But the fact that this
is there's like a very slight difference
is there's like a very slight difference
here and I think it's getting
here and I think it's getting
accentuated or
accentuated or
something. Um, but this is kind of an
something. Um, but this is kind of an
extreme
extreme
case like why hang on. Why is this even
case like why hang on. Why is this even
happening in
happening in
the first place here?
value function should not
value function should not
be subject to this,
right? Maybe I just give it a couple
right? Maybe I just give it a couple
continues first.
Okay, so this is what we get
above. Oh, there is a symmetry problem.
above. Oh, there is a symmetry problem.
That's really
weird. Give it a few more of these.
Oh no. Okay. It's just it takes it a
Oh no. Okay. It's just it takes it a
second.
second.
So if we look at this
now,
now,
okay, you do have this
okay, you do have this
backwards. So you want to
subtract the
max. I think it's going to take us right
max. I think it's going to take us right
back to where we started to be honest.
Not quite. We have better stats at
Not quite. We have better stats at
least.
Congrats on the Pokemon Red Achievement.
Congrats on the Pokemon Red Achievement.
Thank you. Yeah, it's a result we've
Thank you. Yeah, it's a result we've
been looking at for a while. We wanted
been looking at for a while. We wanted
to get rid of all the scripts.
to get rid of all the scripts.
Um I mean really that guy's been the
Um I mean really that guy's been the
lead of it or I guess um David now that
lead of it or I guess um David now that
guy in the Discord. Um, we wanted to get
guy in the Discord. Um, we wanted to get
rid of all the scripts and I think we
rid of all the scripts and I think we
could have still gotten rid of more of
could have still gotten rid of more of
the scripts than we currently have in
the scripts than we currently have in
there, but at some point you just have
there, but at some point you just have
to run a lot a lot of experiments. And
to run a lot a lot of experiments. And
uh, Pokemon is nowhere near as fast as
uh, Pokemon is nowhere near as fast as
all the other MS that we're making in
all the other MS that we're making in
Puffer since it's an existing game.
Puffer since it's an existing game.
That's tough.
Like literally if you were to just write
Like literally if you were to just write
if you just had Pokemon not running
if you just had Pokemon not running
through an emulator just like the same
through an emulator just like the same
thing just not written for an emulator
thing just not written for an emulator
it would be the project would have been
it would be the project would have been
much much much easier to get results on
much much much easier to get results on
faster. It's just a pure speed
limitation. But still I mean it's it
limitation. But still I mean it's it
changes the way I think about R a little
changes the way I think about R a little
bit knowing that that is a possibility.
Okay.
So this is negative.
We can just make
We can just make
this. We just do this
this. We just do this
one. And that'll fix
it. This will fix it.
There's so many cool gifts here to post.
That's fine.
Okay.
11.66 11.98 is zero somehow.
Uh,
what? Oh, that's that's something right
what? Oh, that's that's something right
there. Okay.
there. Okay.
So, this first
So, this first
bit 23 is a
bit 23 is a
segment. 12.3 and then
segment. 12.3 and then
O.
O.
Okay. And then
What happened
here? Wait, actually what happened here?
I don't have a 32 in here anywhere, do
I don't have a 32 in here anywhere, do
I?
No. Stop buff.
Oh, okay. It's because this doesn't the
Oh, okay. It's because this doesn't the
rest doesn't get trained.
Yeah. So, that'll totally mess it up.
Yeah. So, that'll totally mess it up.
Let's do
Let's do
um let's undo that for now.
Huh? Why is the value of standard
Huh? Why is the value of standard
deviation
That's weird as hell.
Yeah, definitely something wrong with
Yeah, definitely something wrong with
this. Probably this loss, right?
Maybe this is
different. Oops.
this optimizing backwards or
Something's weird.
Yeah. Okay. So, this math block is not
Yeah. Okay. So, this math block is not
getting I mean nothing.
I think you forgot to zero it right.
I think you forgot to zero it right.
Mass block.
Okay. I don't know about the 1.0 at the
Okay. I don't know about the 1.0 at the
end like
this, but uh that's closer.
or maybe it
is now. Maybe it is
still not handling this portion
still not handling this portion
correctly. I don't
think
think
buff divide
buff divide
by vantage sum.
Subract the
max subtracted the max, right? What was
max subtracted the max, right? What was
the max?
the max?
15.
It's almost that the difference is very
It's almost that the difference is very
small.
Yeah, this is getting very diluted.
Yeah, this is getting very diluted.
Here it's very diluted.
I'm not quite sure how you deal with
I'm not quite sure how you deal with
this sort of a thing.
If you initialize standard deviation to
If you initialize standard deviation to
one
When does a point stop mattering?
Not a huge fan of the way this is
working. I mean, this is just going to
working. I mean, this is just going to
be a lot of thinking work.
Is there an existing thing that you can
Is there an existing thing that you can
throw at
throw at
this? I don't think so.
I mean the standard deviation of your
I mean the standard deviation of your
prediction if you know it perfectly is
prediction if you know it perfectly is
zero,
right? You subtract the largest of these
right? You subtract the largest of these
values. That's a
values. That's a
great way to check the baseline of it.
I mean, maybe these get more consistent
I mean, maybe these get more consistent
if you let it run a little
longer. So now we have this one for
longer. So now we have this one for
values.
Okay. I mean, that's something, right?
Is there one in
there? Oh, yeah. No, it's just going to
there? Oh, yeah. No, it's just going to
give me
these. Those are some weights.
these. Those are some weights.
You don't necessarily want to subtract
You don't necessarily want to subtract
the
um the men there though, do you?
Maybe you want to subtract the
Maybe you want to subtract the
global global That's
If I do this, does it fix the problem?
If I do this, does it fix the problem?
If I replace this with a
If I replace this with a
global global m uh global
pass. Well, this isn't going to help me
pass. Well, this isn't going to help me
because
Yeah, this doesn't get
Yeah, this doesn't get
trained the way this
is. The segments happen to line up like
is. The segments happen to line up like
this.
Okay.
Okay.
Um, I could modify the signature, right?
Yeah, I'm kind of just getting tired
Yeah, I'm kind of just getting tired
here. It's I I I know what I think I
here. It's I I I know what I think I
need to do.
Want to zero one. Normalize this.
the ROM That's
That has to also
That has to also
return has to return that as well,
return has to return that as well,
doesn't it?
Gosh, freaking pie bind.
Does this do anything?
How do you return this stupid thing?
You can't even do this, can you?
Okay. So, what you're going to
do this
do this
one. Okay.
one. Okay.
pass in a
pass in a
max,
but it's going to be a little different
but it's going to be a little different
from Yes.
Okay.
Boom. What is this [ __ ]
Very
Very
fiddly. Very very fiddly.
All
right,
right,
finally we're getting somewhere
potentially. Lovely.
potentially. Lovely.
Going a little bit
more. Yay, we get something.
Not
bad. And then what do we do? Do we clip
this? Do we clip this?
or what?
0 to 0.1 maybe
Yeah, that's a clip.
Okay. Let's see if this does anything.
And then the question would be would
And then the question would be would
like what do you actually initialize
like what do you actually initialize
this thing too?
Are we just
stuck? No. We do
stuck? No. We do
something. It's in the compute.
something. It's in the compute.
What do you
mean?
mean?
Um the issue
Um the issue
is Oh, compute advantages. Yeah, the
is Oh, compute advantages. Yeah, the
issue is
issue is
um I think it's just the way that we
um I think it's just the way that we
are when you expand the horizon to 128
are when you expand the horizon to 128
elements, there's a little bit of noise
elements, there's a little bit of noise
and if you don't account for that noise,
and if you don't account for that noise,
then you kind of just smear your credit
then you kind of just smear your credit
assignment. I mean, we've got to be able
assignment. I mean, we've got to be able
to do something better than this, I
to do something better than this, I
would imagine, but
Where' this run
Where' this run
go? And I have
go? And I have
uh Yeah, here it
is. This wasn't what I was looking at,
is. This wasn't what I was looking at,
is
is
it? Maybe it was.
a big boost at the end,
a big boost at the end,
huh? Well, kind
of still causing issues.
Just this is kind of ridiculous, but
Just this is kind of ridiculous, but
let's just clamp to
20. I actually wonder what um
So
2/3.99. Are you kidding me? What's with
2/3.99. Are you kidding me? What's with
this device side shenanigans?
Nothing's greater than
2. Yep, that hack is
2. Yep, that hack is
good. Lots of Pokemon as well. Hey Ryan,
good. Lots of Pokemon as well. Hey Ryan,
we're working on a new algorithm. It's a
we're working on a new algorithm. It's a
pain in the
ass. New
ass. New
algorithm. I think I'm going to be able
algorithm. I think I'm going to be able
to beat
to beat
PO, but it's kind of hard.
Wait, if you just do this division by
Wait, if you just do this division by
advantage sum
advantage sum
here, right?
Maybe we do this
instead. What's
this? What is this that you linked me?
C3PO. This image doesn't load, but I see
C3PO. This image doesn't load, but I see
from the
from the
URL. Um, I was thinking about 3PO,
URL. Um, I was thinking about 3PO,
but I don't
but I don't
know. Not really a Star Wars kind of
know. Not really a Star Wars kind of
guy.
I am currently stuck fiddling with CUDA
I am currently stuck fiddling with CUDA
kernel for this new
kernel for this new
algorithm. What is the difference from
algorithm. What is the difference from
PO?
PO?
Um long horizon variational value
Um long horizon variational value
function and a different advantage
function and a different advantage
function and it cuts two it cuts two
function and it cuts two it cuts two
hyperparameters out of PO. No more gamma
hyperparameters out of PO. No more gamma
and
and
lambda. So if it works and I get it to
lambda. So if it works and I get it to
work well, it's very big. And I actually
work well, it's very big. And I actually
do kind of already have it matching on
do kind of already have it matching on
Breakout. Very, very close to matching
Breakout. Very, very close to matching
PF on Breakout.
PF on Breakout.
Um, but there are a couple quirks I need
Um, but there are a couple quirks I need
to
to
fix. My Twitter feed is just blowing up
fix. My Twitter feed is just blowing up
repeatedly.
gamma free stuff from continual
gamma free stuff from continual
learning. Do they have anything that
learning. Do they have anything that
actually works that I should look
at? Does I have something that seems to
at? Does I have something that seems to
actually work
testing PO and continual MS. What is a
testing PO and continual MS. What is a
continual
M. That has no relation though
M. That has no relation though
whatsoever
whatsoever
to whether you need gamma or
lambda. Okay, so this didn't
help. Back to
help. Back to
this. I'm going to have to think about
this. I'm going to have to think about
this.
That's kind of funny that they invented
That's kind of funny that they invented
a whole branch of RL for like
a whole branch of RL for like
non-epodic. It's the same damn thing.
really don't like the way that I'm doing
really don't like the way that I'm doing
the clipping
the clipping
here. And I assume that this is probably
here. And I assume that this is probably
the main
the main
issue, you may think. Does that make
issue, you may think. Does that make
sense?
It makes sense for this to be the main
issue. No point where you're
just That seems like an entirely
just That seems like an entirely
academic distinction.
average
forward. Yeah, I pretty much don't have
forward. Yeah, I pretty much don't have
any idea what they're doing there. Uh I
any idea what they're doing there. Uh I
have very very little
have very very little
confidence in that line of work just
confidence in that line of work just
just because of how it's framed because
just because of how it's framed because
it doesn't seem to be framed
correctly. Stand RL methods don't work
correctly. Stand RL methods don't work
well in these
well in these
zones. I've been doing I mean neural MMO
zones. I've been doing I mean neural MMO
doesn't exactly reset either like
doesn't exactly reset either like
there's really no
difference. Yeah. Well, everything's
difference. Yeah. Well, everything's
going to forget unless you have a replay
going to forget unless you have a replay
buffer and then it won't,
right? I don't
right? I don't
know. I've kind of been relying less and
know. I've kind of been relying less and
less on the literature in RL because
less on the literature in RL because
like most of it is poorly motivated and
like most of it is poorly motivated and
most of what is correctly motivated is
most of what is correctly motivated is
wrong.
wrong.
Like I just keep finding I keep finding
Like I just keep finding I keep finding
so many errors and stuff that it's just
so many errors and stuff that it's just
like I've completely lost confidence in
like I've completely lost confidence in
the accuracy of basically every
the accuracy of basically every
publication.
I think what I do with
this big
claims sometimes there isn't even new
claims sometimes there isn't even new
knowledge though is the thing because
knowledge though is the thing because
it's like it's not underneath there's
it's like it's not underneath there's
new knowledge it's you have to do an
new knowledge it's you have to do an
additional three papers worth of work
additional three papers worth of work
that they didn't do of ablation notes in
that they didn't do of ablation notes in
order to see if their thing actually
works like you're tuning graduate
works like you're tuning graduate
students to environments
for the most
part.
part.
Yeah. But the thing is the leg work is
Yeah. But the thing is the leg work is
the hard part, right?
Okay. Coming up with pretty sounding
Okay. Coming up with pretty sounding
ideas is not
contribution. Man, this is very weird
contribution. Man, this is very weird
because like right here, I wonder what
because like right here, I wonder what
happens if I run this with the original
happens if I run this with the original
32 horizon. Does it work? Does it work
32 horizon. Does it work? Does it work
again?
again?
The thing that's just tricky here is
The thing that's just tricky here is
like I have this thing working when you
like I have this thing working when you
specify a short horizon. It should work
specify a short horizon. It should work
identically or better with a long
identically or better with a long
horizon, but like you kind of need to
horizon, but like you kind of need to
nor like you need to smooth out the
nor like you need to smooth out the
noise in your predictions uh when you do
noise in your predictions uh when you do
that. Otherwise, you just smear all the
that. Otherwise, you just smear all the
credit assignment.
use some of that light work. Well, yeah,
use some of that light work. Well, yeah,
but the issue there is mainly just that
but the issue there is mainly just that
the env is like 100x slower than the
the env is like 100x slower than the
other M's in Puffarel. So, we can run
other M's in Puffarel. So, we can run
100x fewer experiments on the same
100x fewer experiments on the same
hardware.
That's the main
That's the main
issue. I mean, literally more than
issue. I mean, literally more than
anything you could do on the science
anything you could do on the science
side, like the best things you could do
side, like the best things you could do
for Pokemon would just be rewriting the
for Pokemon would just be rewriting the
game off an emulator, like without the
game off an emulator, like without the
emulator, get it to be 100x faster, and
emulator, get it to be 100x faster, and
then it would just be
then it would just be
easy if I don't get booted. Hey, I mean,
easy if I don't get booted. Hey, I mean,
drop in the Discord. We would very much
drop in the Discord. We would very much
appreciate that. We are going to try to
appreciate that. We are going to try to
get our own compute soon as well. It's
get our own compute soon as well. It's
just they're long lead times on the
just they're long lead times on the
5090s and I need to make sure they don't
5090s and I need to make sure they don't
catch on
fire. And we'll get the popper cluster.
Do you think Pokemon experiments can
Do you think Pokemon experiments can
finish in three
days? Probably
not. Actually, definitely not with
not. Actually, definitely not with
HCPUs.
um up to a week on our
um up to a week on our
machines, which are at least 3x faster
machines, which are at least 3x faster
than your
machines. It's a pain in the
ass. Shorter ablation, too.
How do you do
this? It's very weird.
Clusters aren't good for long
Clusters aren't good for long
experiments, but we have popper hardware
experiments, but we have popper hardware
4.
Leave you to it. I owe them a review.
Leave you to it. I owe them a review.
Pokemon paper. Yeah, that'd be good.
Pokemon paper. Yeah, that'd be good.
Thank you for
Thank you for
that, man. I'm like so annoyed with
that, man. I'm like so annoyed with
this. I'm trying to think what the hell
this. I'm trying to think what the hell
it even is. What the hell is even the
it even is. What the hell is even the
problem here?
This does seem reasonable to me. So why
This does seem reasonable to me. So why
is this not
good? You're good.
What the hell is wrong with this?
[ __ ] Hello.
somehow just
crashed. I guess if you just kill it
crashed. I guess if you just kill it
halfway
halfway
through just crashes.
Ridiculous.
Come on. Get 10 now.
That looks not bad to
me. Hang on. Wait a second. Does
me. Hang on. Wait a second. Does
this make
this make
sense? Why is that five and not one?
Something's definitely
screwy. Then do you want it to be
screwy. Then do you want it to be
clipped like
clipped like
this or do you want to like subtract
Delta will be
So
So
fiddly. There's got to be something
fiddly. There's got to be something
simple I can do for this scaling.
Hang on. Maybe I can do
I've got to be massively over
I've got to be massively over
complicating this. There's just got to
complicating this. There's just got to
be a way simpler way I can normalize
be a way simpler way I can normalize
this.
What's this freaking
What's this freaking
paper? What is this
paper? This is the sen paper. That
paper? This is the sen paper. That
doesn't make any bloody sense, right?
is 50,000
Apparently the appendix for this
Apparently the appendix for this
actually has experiments.
I'll look at this paper more, but I no
I'll look at this paper more, but I no
confidence in that.
Come on. You
have standard
deviation. It's going to be scaled
deviation. It's going to be scaled
differently.
So it is the scale of the standard
So it is the scale of the standard
deviation that is off right.
What if you were to
What if you were to
just center the standard deviation? Can
just center the standard deviation? Can
you do that?
Can you do
Can you do
that? I don't think so.
They're going to drive me nuts.
I doubt I'm getting anything out of
I doubt I'm getting anything out of
Groth, but I'm out of ideas for now.
Can I do Wait, wait, wait. Can I just
do I'll see a negative log
likely. Maybe it's just this
That would be kind of silly, wouldn't
That would be kind of silly, wouldn't
it?
It's a minus target.
Well, you can't square it.
divide by the
divide by the
variance. Hang on.
Isn't it just it's one over it, right?
Isn't it just it's one over it, right?
Or one minus like
targets are treated from samples as
targets are treated from samples as
samples from a Gaussian distribution.
samples from a Gaussian distribution.
Okay.
Function term is emitted unless full is
Function term is emitted unless full is
true.
Reward
Reward
minus quantity.
So it's just one. Yeah. So this is what
So it's just one. Yeah. So this is what
I was looking at
before. You could square
before. You could square
this variance.
It's only
It's only
um 4x or whatever.
You subtract out the uh
You can't subract the mini here
anymore. Can divide. Does that help
anymore. Can divide. Does that help
though? No, it doesn't help.
A thinking
A thinking
day. Today is a thinking day.
And the issue is that
like standard deviation of these
like standard deviation of these
predictions
Church.
This is massively irritating.
Maybe I haven't thought about the
Maybe I haven't thought about the
advantage function well enough.
problem is there's
problem is there's
like if you just predict
like if you just predict
randomly there's a certain standard
randomly there's a certain standard
deviation you're going to have from
deviation you're going to have from
that it's not randomly it's predict
that it's not randomly it's predict
majority I Yes.
All
right. Well, I have a meeting in a few.
right. Well, I have a meeting in a few.
Um, yeah, this is hard. I like I'm going
Um, yeah, this is hard. I like I'm going
to really have to think about how I deal
to really have to think about how I deal
with the advantage function for this.
with the advantage function for this.
This is just going to be like a thinking
This is just going to be like a thinking
problem.
problem.
Um, yeah, it's all there is to
it. I know I have a version that works
it. I know I have a version that works
at
at
32, so we just have to think about how
32, so we just have to think about how
that's set up and what I can do on top
that's set up and what I can do on top
of that. All right. Um, yeah, I will be
of that. All right. Um, yeah, I will be
back later tonight or tomorrow. We'll
back later tonight or tomorrow. We'll
see. Thank you. And, uh, yeah, check out
see. Thank you. And, uh, yeah, check out
puffer.ai AI for more.
