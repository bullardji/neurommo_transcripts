Kind: captions
Language: en
Okay, we should be
Okay, we should be
live. Hopefully this wall works.
live. Hopefully this wall works.
Hi. Quite the new setup
Hi. Quite the new setup
here. The plan right now is to just do a
here. The plan right now is to just do a
uh a quick test stream for the next 45
uh a quick test stream for the next 45
minutes or so. uh do a couple things,
minutes or so. uh do a couple things,
make sure chat works, make sure
make sure chat works, make sure
everything else
everything else
works, and uh then after breakfast, I
works, and uh then after breakfast, I
will be back for the rest of the day,
will be back for the rest of the day,
and then this is going to be my schedule
and then this is going to be my schedule
for quite a while now, just trying to
for quite a while now, just trying to
fix the uh the next release, fix up
fix the uh the next release, fix up
puffer liib, fix up all the stuff for
puffer liib, fix up all the stuff for
next release, and then we have a lot of
next release, and then we have a lot of
research planned from there. So there
research planned from there. So there
will be a lot of stuff to go through
will be a lot of stuff to go through
uh quite soon, but I think for now we're
uh quite soon, but I think for now we're
just going to start looking at some of
just going to start looking at some of
the latest
experiments. Let me just make sure this
experiments. Let me just make sure this
thing is actually
thing is actually
working. Seems to
working. Seems to
be
okay. So here's the plan.
okay. So here's the plan.
This is the current best performance on
This is the current best performance on
neural MMO
3. I usually go by this metric here,
3. I usually go by this metric here,
which is the same
shape. This is a run from last night
shape. This is a run from last night
that is probably going to do a little
that is probably going to do a little
bit better, though at the price of being
bit better, though at the price of being
quite a bit slower.
I'm going to have to run this thing uh
I'm going to have to run this thing uh
for
for
longer since it was running on my
longer since it was running on my
local. This is another run that probably
local. This is another run that probably
should have done better than this. Uh
should have done better than this. Uh
and it is interesting that it didn't.
and it is interesting that it didn't.
So, I think what we will do right now to
So, I think what we will do right now to
get started, I'm going to set up a
get started, I'm going to set up a
couple of new runs. Uh this place is
couple of new runs. Uh this place is
kind of fun. We have capacity for a
kind of fun. We have capacity for a
whole bunch of new boxes.
whole bunch of new boxes.
back there. You can see I just have one
back there. You can see I just have one
on there now. And there actually there
on there now. And there actually there
are four more shelves that we can put
are four more shelves that we can put
together for
together for
this. Uh so that's going to hold 40
this. Uh so that's going to hold 40
boxes, but I have to wait for tariffs to
boxes, but I have to wait for tariffs to
come down in order to buy
come down in order to buy
those. But for now, we're just going to
those. But for now, we're just going to
start launching some runs on there. Uh
start launching some runs on there. Uh
make sure our new setup is stable. Make
make sure our new setup is stable. Make
sure everything is good. See if we can
sure everything is good. See if we can
set a little bit of a ping for mint on
set a little bit of a ping for mint on
neural MMO 3. And then what I want to
neural MMO 3. And then what I want to
start doing today and tomorrow is really
start doing today and tomorrow is really
doing a big refactor on uh the puffer
doing a big refactor on uh the puffer
training scripts to make them way easier
training scripts to make them way easier
to use, to make them more
to use, to make them more
self-contained, and also to get them
self-contained, and also to get them
into the puffer pip package. You can
into the puffer pip package. You can
just pip install puffer and start
just pip install puffer and start
training. I don't want to commit to like
training. I don't want to commit to like
an abstracted RL API though. I think
an abstracted RL API though. I think
that that is it's too high level. It's
that that is it's too high level. It's
the wrong move. So I have to balance
the wrong move. So I have to balance
those two things. I think what's going
those two things. I think what's going
to be cool over the next couple days is
to be cool over the next couple days is
that anybody dropping by stream is going
that anybody dropping by stream is going
to be able to give input on, you know,
to be able to give input on, you know,
how the new uh how the new transcript
how the new uh how the new transcript
should look, where they should go,
should look, where they should go,
what's going to be easiest to use, that
what's going to be easiest to use, that
type of a thing. We'll have these runs
type of a thing. We'll have these runs
going in the background. And then the
going in the background. And then the
only other small wrinkle uh I have a
only other small wrinkle uh I have a
couple meetings and then there is one
couple meetings and then there is one
environment that seems to not be working
environment that seems to not be working
suddenly and I don't know if something
suddenly and I don't know if something
broke in puffer or if something broke in
broke in puffer or if something broke in
um the environment. I would suspect the
um the environment. I would suspect the
latter because looking at these curves
latter because looking at these curves
these match what I would expect on
these match what I would expect on
neural MMO 3. So we are probably good
here. Yeah.
And I don't know if I actually want to
And I don't know if I actually want to
keep I guess I should probably let's do
keep I guess I should probably let's do
this run for longer to see how this
this run for longer to see how this
changes over time. We'll kill this one
changes over time. We'll kill this one
and we'll come back to this.
Yeah. So, we're now training at 650,000
Yeah. So, we're now training at 650,000
steps per second with a three, what is
steps per second with a three, what is
this? 2.4 million parameter model on
this? 2.4 million parameter model on
here.
So this is what I did for the run that
So this is what I did for the run that
did better. I just increased the number
did better. I just increased the number
of
channels. Yeah. Same as there.
Then here what I tried to do was
Then here what I tried to do was
something a little different. I tried to
something a little different. I tried to
go with a entity encoder for all the
go with a entity encoder for all the
different
attributes. So if you look here, there's
attributes. So if you look here, there's
this max.
this was going to cut down the network
this was going to cut down the network
size quite a bit, but for some reason
size quite a bit, but for some reason
that seems to do way worse. So, I will
that seems to do way worse. So, I will
have to think about why that is, but in
have to think about why that is, but in
the
meantime, yeah, the non- entity encoder
meantime, yeah, the non- entity encoder
just blows up the size of this hidden
just blows up the size of this hidden
layer,
unfortunately. But we will do this for
unfortunately. But we will do this for
now. So, we have 256 hidden and I
now. So, we have 256 hidden and I
believe that this should do
believe that this should do
uh this should actually run. We will
see. Quick test without
Neptune. I got to figure out why the
Neptune. I got to figure out why the
Nvidia drivers just occasionally
Nvidia drivers just occasionally
crashed. It's kind of
crashed. It's kind of
jank. It's not that hard to fix.
But it's a little
silly. So if anybody knows why that
silly. So if anybody knows why that
happens occasionally just Docker loses
happens occasionally just Docker loses
access, you can let me know.
So 4.2 mil parameter model. And I forgot
So 4.2 mil parameter model. And I forgot
one other
thing. It's left
over. And I'm not seeing the chat, but I
over. And I'm not seeing the chat, but I
think it should be working. Yeah, there
think it should be working. Yeah, there
we go. Hey,
we go. Hey,
Captain. Up close and personal. Well,
Captain. Up close and personal. Well,
we'll see if that stays. Um, it's very
we'll see if that stays. Um, it's very
difficult to actually get this setup
difficult to actually get this setup
correct because I also have this whole
correct because I also have this whole
big microphone and pop filter on a boom
big microphone and pop filter on a boom
arm.
arm.
So, we got to figure this out. It's a
So, we got to figure this out. It's a
little close.
interested to see pics of the
interested to see pics of the
setup. Uh, one
setup. Uh, one
moment. The thing is, we still need all
moment. The thing is, we still need all
the new machines, right? So, I just have
the new machines, right? So, I just have
the one box on there at the
the one box on there at the
moment, but it does work and it's very
moment, but it does work and it's very
nice to wire stuff.
As soon as I get this run
As soon as I get this run
going, I think the camera will
autofocus. I also would like to check if
autofocus. I also would like to check if
this compile even does anything with the
this compile even does anything with the
optimizer. Okay, so there we go. So, so
optimizer. Okay, so there we go. So, so
that's still
that's still
500K on the uh the nicer GPU.
So you can see, yeah, I have it in the
So you can see, yeah, I have it in the
shot. So right
shot. So right
back there, we have one of the boxes.
back there, we have one of the boxes.
That's the first uh 5090 box on there.
That's the first uh 5090 box on there.
Uh the wiring isn't in the shot, but you
Uh the wiring isn't in the shot, but you
can kind of see in the background with
can kind of see in the background with
all those
all those
rails, we've got 40 outlets there. Uh,
rails, we've got 40 outlets there. Uh,
and they're going to be there's room for
and they're going to be there's room for
four of those additional racks. Uh, and
four of those additional racks. Uh, and
then there's also room for Yeah, you can
then there's also room for Yeah, you can
see the server frame like the open frame
see the server frame like the open frame
back there that's got UPS that's got um
back there that's got UPS that's got um
switches and stuff and then that will
switches and stuff and then that will
contain anything else that we acquire.
contain anything else that we acquire.
So, we have plenty of capacity for
So, we have plenty of capacity for
hardware now. And uh the GPU machines,
hardware now. And uh the GPU machines,
it's just going to be a matter of when
it's just going to be a matter of when
tariffs come down. Are all the puffer
tariffs come down. Are all the puffer
boxes up now? They should be except for
boxes up now? They should be except for
six. Uh that went back to main gear for
six. Uh that went back to main gear for
maintenance.
Um, but yeah, the for the 40, I mean,
Um, but yeah, the for the 40, I mean,
those those can get here pretty quick,
those those can get here pretty quick,
I'm told. Like just 3 4 weeks lead. Um,
I'm told. Like just 3 4 weeks lead. Um,
but the tariffs are like plus 40% price
but the tariffs are like plus 40% price
on all of them right now. So, I'm hoping
on all of them right now. So, I'm hoping
that those are going to come down.
Okay, we have this run
going. Rack is nice
stagnars. Yeah, those are fun.
stagnars. Yeah, those are fun.
Um, they're a little sketchy because you
Um, they're a little sketchy because you
actually you're pretty high up if you
actually you're pretty high up if you
miss. But I'm just messing around on the
miss. But I'm just messing around on the
bottom two, getting used to it for a bit
bottom two, getting used to it for a bit
before I do the whole
thing. This is also not all the
thing. This is also not all the
equipment yet. Right now, we just have
equipment yet. Right now, we just have
the uh the big rack. There's the bench.
the uh the big rack. There's the bench.
I got like an adjustable bench and I've
I got like an adjustable bench and I've
got a log. More stuff is going to be
arriving. Puffer training facility.
arriving. Puffer training facility.
Training for me, training for our
Training for me, training for our
allegiance.
So, the thing that I want to get started
So, the thing that I want to get started
on, at least just to get a start on for
now. I think I want to merge this with
now. I think I want to merge this with
demo. Interesting project. Was the most
demo. Interesting project. Was the most
valuable thing you learned during your
valuable thing you learned during your
time at MIT?
time at MIT?
Man, that's a hard like hard general
Man, that's a hard like hard general
question.
Um, probably just getting a perspective
Um, probably just getting a perspective
on how academia operates
on how academia operates
and where the way that academia operates
and where the way that academia operates
is effective, but then also where it
is effective, but then also where it
isn't. So, knowing where to look for
isn't. So, knowing where to look for
major major gaps and like surely all the
major major gaps and like surely all the
world's top scientists didn't miss
world's top scientists didn't miss
something. No. Yeah, they absolutely
something. No. Yeah, they absolutely
did. and knowing how they operate so you
did. and knowing how they operate so you
can identify places uh where that's
can identify places uh where that's
going to be the case. I mean puffer liib
going to be the case. I mean puffer liib
is something that I just could not have
is something that I just could not have
built really in academia at
built really in academia at
all and uh it was really using that you
all and uh it was really using that you
know that insight after I
know that insight after I
graduated that took me down this
graduated that took me down this
direction.
So this is what I want to do. This is a
So this is what I want to do. This is a
little crazy because this is already an
little crazy because this is already an
1100 line uh trainer file and I do want
1100 line uh trainer file and I do want
to compress this a whole bunch even
to compress this a whole bunch even
though you know a lot of this is just
though you know a lot of this is just
like perf monitoring and stuff. Um but
like perf monitoring and stuff. Um but
what I would like to do
what I would like to do
here I want to combine this with the
here I want to combine this with the
demo
demo
file which is
file which is
381. So that gives you about 1500 lines.
381. So that gives you about 1500 lines.
And then I think there's one or two
And then I think there's one or two
other
things. I think some of the PyTorch
things. I think some of the PyTorch
utils maybe can just go in here as
utils maybe can just go in here as
well. Maybe not. Maybe it is just those
well. Maybe not. Maybe it is just those
two. We'll
two. We'll
see. I think the only thing we're using
see. I think the only thing we're using
from
from
utils is this like tiny
utils is this like tiny
function, right? And
then yeah, so there are a couple things
then yeah, so there are a couple things
here. Um, I think we can get this to the
here. Um, I think we can get this to the
point that it's other than using, you
point that it's other than using, you
know, our base models and stuff like
know, our base models and stuff like
that, it's pretty self-contained. And
that, it's pretty self-contained. And
then the point of doing that, uh, would
then the point of doing that, uh, would
be that we could then put this as a
be that we could then put this as a
single file into the pit package. Let me
single file into the pit package. Let me
show you what I'm sort of thinking
show you what I'm sort of thinking
there. And this is one spot that I
there. And this is one spot that I
definitely want user feedback on what's
definitely want user feedback on what's
going to be easier for folks. But the
going to be easier for folks. But the
way we have this set up in 2.0,
way we have this set up in 2.0,
Now we have this pretty, you know,
Now we have this pretty, you know,
pretty small uh top directory that has a
pretty small uh top directory that has a
few scripts for you. So this has
few scripts for you. So this has
generalized advantage
generalized advantage
estimation. Um this
estimation. Um this
has like a couple clean RL demos and a
has like a couple clean RL demos and a
few
few
utilities. And what you do is if you
utilities. And what you do is if you
just want our environments, you can pip
just want our environments, you can pip
install it. But if you want to use our
install it. But if you want to use our
stuff for training, then you
stuff for training, then you
uh you know, you have to clone
uh you know, you have to clone
it. And I think most people are going to
it. And I think most people are going to
want to clone it anyways because as soon
want to clone it anyways because as soon
as you want to do any research and hack
as you want to do any research and hack
on stuff, uh you do need the source
on stuff, uh you do need the source
code.
code.
But I think for um people who are just
But I think for um people who are just
like trying to run our trainer or run
like trying to run our trainer or run
our stuff on new M's and don't really
our stuff on new M's and don't really
want to be doing research side stuff,
want to be doing research side stuff,
you know, kind of just
you know, kind of just
tinkering, we could probably make it pip
tinkering, we could probably make it pip
installable, including the training.
installable, including the training.
That doesn't mean I want to commit to an
That doesn't mean I want to commit to an
API necessarily, but we could put the
API necessarily, but we could put the
demo behind like an entry point in um in
demo behind like an entry point in um in
the pip package. So you could just do
the pip package. So you could just do
like puffer train or something and it
like puffer train or something and it
will just call that file. And I would if
will just call that file. And I would if
we're going to do that though, I want
we're going to do that though, I want
that to be like as minimal as possible.
that to be like as minimal as possible.
I don't want to have like an ever
I don't want to have like an ever
expanding folder and then we become like
expanding folder and then we become like
a RL
a RL
API. And I think that the main impetus
API. And I think that the main impetus
for this is just like how much better
for this is just like how much better
our train demo has gotten. You know,
our train demo has gotten. You know,
when I started Puffer, I thought it was
when I started Puffer, I thought it was
going to be low-level utilities around
going to be low-level utilities around
MS and training and stuff. And what's
MS and training and stuff. And what's
happened since then is like we've just
happened since then is like we've just
eaten the whole stack and now
eaten the whole stack and now
um our implementation is just so much
um our implementation is just so much
faster than everything else that you're
faster than everything else that you're
probably going to want to use
probably going to want to use
puffer. So I mean we could have
puffer. So I mean we could have
something in
something in
here. We could have like clean puff RL
here. We could have like clean puff RL
in here. Some of this stuff could get
in here. Some of this stuff could get
squashed like this folder will get
squashed like this folder will get
smaller.
Let's see how it is in
Let's see how it is in
dev. We do have some CUDA stuff. So,
dev. We do have some CUDA stuff. So,
there will have to be like some CUDA
there will have to be like some CUDA
stuff in
there. I could just put it all inside of
there. I could just put it all inside of
like a puffer li, right?
The thing that I don't want, right, is I
The thing that I don't want, right, is I
don't want Puffer Lib to become
don't want Puffer Lib to become
like I think it's either too early or
like I think it's either too early or
entirely the wrong idea to try to like
entirely the wrong idea to try to like
Here, look at all the libraries that
Here, look at all the libraries that
have tried to do
this. So like here stable baselines 3,
this. So like here stable baselines 3,
they tried to modularize stuff. This is
they tried to modularize stuff. This is
like one of the common ones. It's really
like one of the common ones. It's really
slow. It's really hard to hack on
slow. It's really hard to hack on
anything that's not covered. And ours is
anything that's not covered. And ours is
just like faster and better with a tiny
just like faster and better with a tiny
tiny amount of the code at this point.
tiny amount of the code at this point.
Like you don't need all these
Like you don't need all these
implementations if this one is just
implementations if this one is just
better and works and is faster.
better and works and is faster.
Um, so like a lot of the different
Um, so like a lot of the different
libraries like they they kind of want to
libraries like they they kind of want to
have all the different algorithms and
have all the different algorithms and
then they try to come up. Yeah, look at
then they try to come up. Yeah, look at
all this stuff. And then they try to
all this stuff. And then they try to
come up with like ways to make them all
come up with like ways to make them all
play nicely with the same experience
play nicely with the same experience
buffer or stuff like that. I don't want
buffer or stuff like that. I don't want
to do
to do
that. Yeah, I don't want to do that at
that. Yeah, I don't want to do that at
all. I want to go the opposite
all. I want to go the opposite
direction. I want it to be a lot more
direction. I want it to be a lot more
like clean RL and get as like close to
like clean RL and get as like close to
this simplicity as we possibly
can. So like this is clean po and they
can. So like this is clean po and they
only have 286 lines here. I guess 329
only have 286 lines here. I guess 329
counting white space and
stuff and it's like so
stuff and it's like so
simple, but I really want to get closer
simple, but I really want to get closer
and closer to
and closer to
this. Well, of course, you know, we have
this. Well, of course, you know, we have
we have stuff we have to handle in order
we have stuff we have to handle in order
to make it
to make it
fast. But as close as we can get to this
fast. But as close as we can get to this
level of simplicity, the better. Now, I
level of simplicity, the better. Now, I
don't think like this you're literally
don't think like this you're literally
just intended to edit this one file and
just intended to edit this one file and
then this one file is kind of like one
then this one file is kind of like one
environment, one experiment, whatever.
environment, one experiment, whatever.
So, we want a little bit more
So, we want a little bit more
flexibility than that. You know, I'd
flexibility than that. You know, I'd
like to be able to run this uh on
like to be able to run this uh on
different environments and on different
different environments and on different
policies. So instead of just having the
policies. So instead of just having the
environment hardcoded in the policy in
environment hardcoded in the policy in
here, I'd like to be able to load in a
here, I'd like to be able to load in a
different environment and a different
different environment and a different
policy, uh, I would like RNN support. So
policy, uh, I would like RNN support. So
maybe I should compare more to
maybe I should compare more to
this. There's only
375, but I
375, but I
like it bothers me that we have so so
like it bothers me that we have so so
much more code than this. And like I
much more code than this. And like I
know why everything is there but
know why everything is there but
still cuz
like so first of all we we have like
like so first of all we we have like
this eval train split right you don't
this eval train split right you don't
just run the script you run eval and
just run the script you run eval and
then you run train and you run eval and
then you run train and you run eval and
you have run train and that's done that
you have run train and that's done that
way so it's easier to like evaluate
way so it's easier to like evaluate
existing
existing
policies and it's kind of
fine this whole name space thing is
ridiculous. That's 45 lines right
ridiculous. That's 45 lines right
there. We've got all this different
there. We've got all this different
optimizer
config. We've got all this like LSTM
config. We've got all this like LSTM
nonLSTM stuff to support both.
We've got P30, which is still like work
We've got P30, which is still like work
in progress that I need to go back
to. And all these things kind of add up
to. And all these things kind of add up
and just add a bunch of bulk. Now, the
and just add a bunch of bulk. Now, the
one thing I was really proud of lately
one thing I was really proud of lately
is I did fix our profiling. So, our
is I did fix our profiling. So, our
profiling is very light now. You know,
profiling is very light now. You know,
you just have a few lines and you get
you just have a few lines and you get
comprehensive
comprehensive
profiling. So, most of this stuff is not
profiling. So, most of this stuff is not
too much overhead over um over clean RL.
too much overhead over um over clean RL.
And I think once we evaluate Diane and
And I think once we evaluate Diane and
we evaluate P30 and like figure out what
we evaluate P30 and like figure out what
matters there, this will be pretty close
matters there, this will be pretty close
to comparable stuff like this, I can
to comparable stuff like this, I can
definitely crunch up a little bit. If I
definitely crunch up a little bit. If I
try and then like this whole block is
try and then like this whole block is
P30. So, I think
P30. So, I think
like if we once we really know what we
like if we once we really know what we
need to keep and what we don't need to
need to keep and what we don't need to
keep and we kind of just keep the one
keep and we kind of just keep the one
path that we really want, like we can
path that we really want, like we can
cut out a lot of this stuff. A lot of
cut out a lot of this stuff. A lot of
this extra that's been in here is just
this extra that's been in here is just
not really
needed. It's going to be a lot of
needed. It's going to be a lot of
experiments to figure out for sure what
experiments to figure out for sure what
matters and what doesn't, but um we
matters and what doesn't, but um we
should be able to do that.
experience buffer
experience buffer
stuff maybe can compress a little
stuff maybe can compress a little
bit. This is more experience buffer
bit. This is more experience buffer
stuff. We have distributed, we've got
stuff. We have distributed, we've got
logging and now we are at 750 lines of
logging and now we are at 750 lines of
which we can probably delete
which we can probably delete
250 at
250 at
least. And then we have features that
least. And then we have features that
clean RL just doesn't have, right? They
clean RL just doesn't have, right? They
don't have checkpointing, model saving
don't have checkpointing, model saving
and loading
and loading
stuff. Um, we have this eval mode so you
stuff. Um, we have this eval mode so you
can like run
can like run
rollouts and then we have profiling
rollouts and then we have profiling
quite a bit of
quite a bit of
profiling and the dashboard. All this is
profiling and the dashboard. All this is
just to print that local the little
just to print that local the little
local
dashboard. So this type of stuff
dashboard. So this type of stuff
probably there's not much to save. So
probably there's not much to save. So
this is going to be
200ish
lines. Yeah. So, there's like 200 lines
lines. Yeah. So, there's like 200 lines
of profiling at the
bottom and another like almost 200 lines
bottom and another like almost 200 lines
of utils.
of utils.
Okay. Well, I'm not too beat up over
Okay. Well, I'm not too beat up over
those.
Like I don't it doesn't make sense to
Like I don't it doesn't make sense to
have like a line target or anything for
have like a line target or anything for
this. That's kind of just stupid. Um but
this. That's kind of just stupid. Um but
I think that the thing is going to be to
I think that the thing is going to be to
just like put the two files together and
just like put the two files together and
then just try to remove anything that is
then just try to remove anything that is
redundant.
redundant.
Most of the redundant stuff looks like
Most of the redundant stuff looks like
it comes from
it comes from
optional args of like supporting
optional args of like supporting
different settings where really we want
different settings where really we want
to run all the experiments and only
to run all the experiments and only
support the settings we care about. So
support the settings we care about. So
that should get better.
Um and then what about the demo file?
Um and then what about the demo file?
The demo file has WB and Neptune. We do
The demo file has WB and Neptune. We do
need to support both of
need to support both of
those. This policy load stuff can get
those. This policy load stuff can get
simplified. Sweep configs already pretty
simplified. Sweep configs already pretty
simple. Maybe we can do something for
simple. Maybe we can do something for
this. We probably can totally do
this. We probably can totally do
something for this,
right? Yeah, we can to we can totally do
right? Yeah, we can to we can totally do
something for that.
uh carbs will be gone once we have
uh carbs will be gone once we have
evaluated it
thoroughly cuz I'm sure we outperformed
thoroughly cuz I'm sure we outperformed
that. Got this training stuff some
that. Got this training stuff some
little jank injection whatever here
little jank injection whatever here
backend stuff. I think a lot of this
backend stuff. I think a lot of this
like multi selection thing we can
like multi selection thing we can
probably
probably
do much more easily without having all
this like we can probably just
this like we can probably just
dynamically load whichever one you have
dynamically load whichever one you have
in the
in the
config. We have
DDP. Here's the loop.
DDP. Here's the loop.
We have this like jank data collection
We have this like jank data collection
thing on like down sampling the
thing on like down sampling the
trajectory for protein. Whether or not
trajectory for protein. Whether or not
that's useful, we'll have to see
that's useful, we'll have to see
still. Yeah, this down
still. Yeah, this down
sampler DDP. And
sampler DDP. And
then 230 down to 381. So 150 lines of
then 230 down to 381. So 150 lines of
this main
this main
file. Setting up
arg reading configs. this bit
arg reading configs. this bit
here and then calling all the associated
methods.
methods.
Oh, no time like the present.
And now we see all the stuff that we
And now we see all the stuff that we
also import from puffer lip here as
also import from puffer lip here as
well. Right.
Yeah, this is much easier.
And we've got
rich. Now we're no longer calling this
rich. Now we're no longer calling this
externally as if it were like some API.
1473 starting
1473 starting
lines. And this should work already
lines. And this should work already
unless they're name
complex missing four
arguments. So there is a name conflict
arguments. So there is a name conflict
here.
So it
So it
is the fact that we have this wrapped
is the fact that we have this wrapped
trainer is interesting.
As ridiculous as this is, this is like
As ridiculous as this is, this is like
one of my favorite things to do is to
one of my favorite things to do is to
just paste all the code together and
just paste all the code together and
then like see what ends up being
then like see what ends up being
redundant when you have everything next
redundant when you have everything next
to each other. It ends up being
to each other. It ends up being
ridiculously effective, but like I do
ridiculously effective, but like I do
end up with very long files as a result
end up with very long files as a result
of that.
of that.
Um, but like I end up with one file that
Um, but like I end up with one file that
is a third of the length of the 10 files
is a third of the length of the 10 files
you would have written
otherwise. Okay, so there's breakout at
otherwise. Okay, so there's breakout at
3 million steps per second. That is a 26
3 million steps per second. That is a 26
second training
loop. And this already runs.
So, I would like to ideally do this
So, I would like to ideally do this
without introducing any major bugs,
without introducing any major bugs,
which means smaller little refactor hops
which means smaller little refactor hops
than I would normally do.
And for reference, the plan here is I
And for reference, the plan here is I
just wanted to get like the test stream
just wanted to get like the test stream
in this morning. Uh, you know, the whole
in this morning. Uh, you know, the whole
new setup
here and then I will be back for the
here and then I will be back for the
whole rest of the day after breakfast
whole rest of the day after breakfast
working on this.
minus or modulo one I believe one call
minus or modulo one I believe one call
in the mid-after
afternoon so what is there okay here's
afternoon so what is there okay here's
another question right what is there in
another question right what is there in
here that I can cut out that is not
here that I can cut out that is not
related to me supporting like more
related to me supporting like more
options that I have not thoroughly
options that I have not thoroughly
evaluated yet because we know that
evaluated yet because we know that
there's like different advantage
there's like different advantage
functions and stuff like
functions and stuff like
that. But what is there in here that's
that. But what is there in here that's
just like
ridiculous? I mean, the way that I have
ridiculous? I mean, the way that I have
this create
function, man, I really hate to admit
function, man, I really hate to admit
that this should probably just be a
that this should probably just be a
class. There's this thing at the bottom
class. There's this thing at the bottom
that's like a data like this thing is
that's like a data like this thing is
ridiculous here,
right? And yeah, I can get rid of a lot
right? And yeah, I can get rid of a lot
of these, but
still I guess what I was going for here,
still I guess what I was going for here,
right? So easy in clean RL because they
right? So easy in clean RL because they
just have this one function and
just have this one function and
everything is just global. You
everything is just global. You
see like everything is just global. So
see like everything is just global. So
they don't have this
they don't have this
issue. But if you actually figure out
issue. But if you actually figure out
and like try to pass everything that you
and like try to pass everything that you
need for eval and everything you need
need for eval and everything you need
for trains like separately, the
for trains like separately, the
signatures of these get gigantic. So I
signatures of these get gigantic. So I
stuff this into a giant data structure
stuff this into a giant data structure
which then obviously grows and grows and
which then obviously grows and grows and
then like accumulates everything.
Okay, what are options? Option one is
Okay, what are options? Option one is
leave it as
is. Option
is. Option
two, just bite the bullet and convert
two, just bite the bullet and convert
this to a class.
Then each of these things would get
Then each of these things would get
assigned when they're
needed. Option three would be to create
needed. Option three would be to create
this thing
dynamically. So like I can assign stuff
dynamically. So like I can assign stuff
to this after it's
to this after it's
made. That's kind of just like making it
made. That's kind of just like making it
sort of like a dictionary.
The original reason that I didn't want
The original reason that I didn't want
this to be a class was
this to be a class was
what? Was it literally just the
indenting? So you go
indenting? So you go
train or
Other than this,
like most of this is pretty
reasonable. I think that what happened
reasonable. I think that what happened
was before like because we had all the
was before like because we had all the
profiling code
profiling code
indenting I like I thought it was just
indenting I like I thought it was just
getting to be absolutely ridiculous like
getting to be absolutely ridiculous like
you're writing code halfway across the
screen. It probably wasn't a great
screen. It probably wasn't a great
reason to do this
though. A lot of this is also kind of
though. A lot of this is also kind of
left over because
left over because
like this is a language thing, right?
like this is a language thing, right?
Like I know how I would do this in C and
Like I know how I would do this in C and
it would look pretty similar to this
it would look pretty similar to this
except that there would just there'd be
except that there would just there'd be
a strct because that's how you would
a strct because that's how you would
have to do it in C and it would be very
have to do it in C and it would be very
simple, right? Because everything that's
simple, right? Because everything that's
zero would default to zero
and like the actual creation of the
and like the actual creation of the
strct would be
strct would be
smaller. Uh but that's not really how
smaller. Uh but that's not really how
Python works.
I guess technically I could put it as a
I guess technically I could put it as a
data
data
class. I've not liked those in the
past. I mean this is basically a strct,
past. I mean this is basically a strct,
right?
This does not feel good to me
though. You know, I think the reason
though. You know, I think the reason
that I like
that I like
this, the reason I like this in C and
this, the reason I like this in C and
not in
not in
Python is because C is typed, right?
Python is because C is typed, right?
So I would have this function not be a
So I would have this function not be a
part of the data class but then it would
part of the data class but then it would
take the type which is inventory
item. So here it's like this data class
item. So here it's like this data class
is kind
of hang on. Do you even need data class
of hang on. Do you even need data class
like this? What does data class even do?
I thought this was changed.
Yeah. So you don't even need that data
Yeah. So you don't even need that data
class annotator.
Okay.
So, you know, I agonize over like these
So, you know, I agonize over like these
little details like this. This is
little details like this. This is
probably the fifth time I've thought
probably the fifth time I've thought
about this, but it matters a lot.
Half of this is me fighting against like
Half of this is me fighting against like
me wanting to write C in Python, which
me wanting to write C in Python, which
is just not smart. The other half is me
is just not smart. The other half is me
fighting against like doing it the
fighting against like doing it the
really dumb Python
really dumb Python
way. Okay, so what if I just made
way. Okay, so what if I just made
it what if I just took all these things
it what if I just took all these things
that have obvious defaults, right?
that have obvious defaults, right?
So what if I make this thing a class? I
So what if I make this thing a class? I
have all these things that are like
have all these things that are like
obvious
obvious
defaults, all these zeros and
defaults, all these zeros and
things.
Um I can put those up
top. What happens if you have like this
top. What happens if you have like this
be another in an instance of a class?
be another in an instance of a class?
Does that happen? Like does that work?
like
Oh, I think it was because you can just
do Yeah, you can't do this. That's what
do Yeah, you can't do this. That's what
data class gives you,
data class gives you,
right? And we don't need
that. So,
that. So,
um, okay. What would this look like
um, okay. What would this look like
then? A lot of these, this junk, this
then? A lot of these, this junk, this
junk, right, would be
junk, right, would be
at the
top and then we would have an init
function that sets all
this. A lot of these things don't even
this. A lot of these things don't even
necessarily need to be in an init
though. Like this is a global, right?
though. Like this is a global, right?
Like this is a global setting for
Like this is a global setting for
torch. Putting it inside of this
torch. Putting it inside of this
function doesn't do
anything. The seeding stuff. Yeah, cuz
anything. The seeding stuff. Yeah, cuz
there's a seed that you can
set. I don't even know if we need to do
set. I don't even know if we need to do
that though because like realistically
that though because like realistically
you're not getting that same curve back
you're not getting that same curve back
anyways.
maybe
R. I guess it depends on whether you're
R. I guess it depends on whether you're
MC
correctly. Okay. So, I think what I'm
correctly. Okay. So, I think what I'm
going to do, I'm going to go get
going to do, I'm going to go get
breakfast in a minute here.
Um, yeah, like even this losses thing is
Um, yeah, like even this losses thing is
is kind of
is kind of
ridiculous. Okay, I'm going to think
ridiculous. Okay, I'm going to think
about this a little bit over breakfast.
about this a little bit over breakfast.
I think that the main
I think that the main
thing for this is like figuring out what
thing for this is like figuring out what
we do with the structure of this whole
we do with the structure of this whole
training code because everything else
training code because everything else
for the most part, I mean, at least a
for the most part, I mean, at least a
lot of it is just us supporting a ton of
lot of it is just us supporting a ton of
settings that we haven't decided which
settings that we haven't decided which
ones we want to keep.
ones we want to keep.
Um, yeah, I think that over the next
Um, yeah, I think that over the next
couple days, the plan is going to be to
couple days, the plan is going to be to
see if we can really condense this thing
see if we can really condense this thing
down into a nice simple, easy to use uh
down into a nice simple, easy to use uh
single file transcript for Puffer Lib.
single file transcript for Puffer Lib.
If you want to be a part of that and you
If you want to be a part of that and you
want to give feedback on how this thing
want to give feedback on how this thing
should look and what would be the
should look and what would be the
easiest for you to use in Puffer and uh,
easiest for you to use in Puffer and uh,
you know, how hyper RL should work, then
you know, how hyper RL should work, then
you can drop by the streams for that.
you can drop by the streams for that.
I'm going to go get breakfast. I'll be
I'm going to go get breakfast. I'll be
live for pretty much the rest of the day
live for pretty much the rest of the day
outside of one meeting and then all day
outside of one meeting and then all day
tomorrow as well. And pretty much this
tomorrow as well. And pretty much this
is the schedule going forward. I'm back
is the schedule going forward. I'm back
to dev and uh aiming to try to finish up
to dev and uh aiming to try to finish up
the next release over the next few
the next release over the next few
weeks, get something shipped, get a
weeks, get something shipped, get a
whole bunch of stuff written on that as
whole bunch of stuff written on that as
well, which I'll probably also deal on
well, which I'll probably also deal on
stream cuz why not?
stream cuz why not?
And other than that uh yeah I have some
And other than that uh yeah I have some
research ideas for after the release but
research ideas for after the release but
I think the initial goal is just ultra
I think the initial goal is just ultra
high performance really stable hyper
high performance really stable hyper
pram robust uh easy to use version next
pram robust uh easy to use version next
version of puffer lip and I still
version of puffer lip and I still
haven't decided on a version number for
haven't decided on a version number for
that. So thanks for dropping by. I will
that. So thanks for dropping by. I will
be back in probably only like half an
be back in probably only like half an
hour or so.
hour or so.
Uh, if you want to check out all this
Uh, if you want to check out all this
stuff, it's all open source at
stuff, it's all open source at
puffer.ai. You can start on GitHub to
puffer.ai. You can start on GitHub to
really help us out. You can join the
really help us out. You can join the
Discord to get involved with dev. Most
Discord to get involved with dev. Most
of our contributors came in with zero RL
of our contributors came in with zero RL
experience and are now doing really
experience and are now doing really
awesome stuff, really cutting edge RL
awesome stuff, really cutting edge RL
stuff. So, uh, thanks and I will be back
stuff. So, uh, thanks and I will be back
in a bit.

Kind: captions
Language: en
Okay, we should be
Okay, we should be
live. Hopefully this wall works.
live. Hopefully this wall works.
Hi. Quite the new setup
Hi. Quite the new setup
here. The plan right now is to just do a
here. The plan right now is to just do a
uh a quick test stream for the next 45
uh a quick test stream for the next 45
minutes or so. uh do a couple things,
minutes or so. uh do a couple things,
make sure chat works, make sure
make sure chat works, make sure
everything else
everything else
works, and uh then after breakfast, I
works, and uh then after breakfast, I
will be back for the rest of the day,
will be back for the rest of the day,
and then this is going to be my schedule
and then this is going to be my schedule
for quite a while now, just trying to
for quite a while now, just trying to
fix the uh the next release, fix up
fix the uh the next release, fix up
puffer liib, fix up all the stuff for
puffer liib, fix up all the stuff for
next release, and then we have a lot of
next release, and then we have a lot of
research planned from there. So there
research planned from there. So there
will be a lot of stuff to go through
will be a lot of stuff to go through
uh quite soon, but I think for now we're
uh quite soon, but I think for now we're
just going to start looking at some of
just going to start looking at some of
the latest
experiments. Let me just make sure this
experiments. Let me just make sure this
thing is actually
thing is actually
working. Seems to
working. Seems to
be
okay. So here's the plan.
okay. So here's the plan.
This is the current best performance on
This is the current best performance on
neural MMO
3. I usually go by this metric here,
3. I usually go by this metric here,
which is the same
shape. This is a run from last night
shape. This is a run from last night
that is probably going to do a little
that is probably going to do a little
bit better, though at the price of being
bit better, though at the price of being
quite a bit slower.
I'm going to have to run this thing uh
I'm going to have to run this thing uh
for
for
longer since it was running on my
longer since it was running on my
local. This is another run that probably
local. This is another run that probably
should have done better than this. Uh
should have done better than this. Uh
and it is interesting that it didn't.
and it is interesting that it didn't.
So, I think what we will do right now to
So, I think what we will do right now to
get started, I'm going to set up a
get started, I'm going to set up a
couple of new runs. Uh this place is
couple of new runs. Uh this place is
kind of fun. We have capacity for a
kind of fun. We have capacity for a
whole bunch of new boxes.
whole bunch of new boxes.
back there. You can see I just have one
back there. You can see I just have one
on there now. And there actually there
on there now. And there actually there
are four more shelves that we can put
are four more shelves that we can put
together for
together for
this. Uh so that's going to hold 40
this. Uh so that's going to hold 40
boxes, but I have to wait for tariffs to
boxes, but I have to wait for tariffs to
come down in order to buy
come down in order to buy
those. But for now, we're just going to
those. But for now, we're just going to
start launching some runs on there. Uh
start launching some runs on there. Uh
make sure our new setup is stable. Make
make sure our new setup is stable. Make
sure everything is good. See if we can
sure everything is good. See if we can
set a little bit of a ping for mint on
set a little bit of a ping for mint on
neural MMO 3. And then what I want to
neural MMO 3. And then what I want to
start doing today and tomorrow is really
start doing today and tomorrow is really
doing a big refactor on uh the puffer
doing a big refactor on uh the puffer
training scripts to make them way easier
training scripts to make them way easier
to use, to make them more
to use, to make them more
self-contained, and also to get them
self-contained, and also to get them
into the puffer pip package. You can
into the puffer pip package. You can
just pip install puffer and start
just pip install puffer and start
training. I don't want to commit to like
training. I don't want to commit to like
an abstracted RL API though. I think
an abstracted RL API though. I think
that that is it's too high level. It's
that that is it's too high level. It's
the wrong move. So I have to balance
the wrong move. So I have to balance
those two things. I think what's going
those two things. I think what's going
to be cool over the next couple days is
to be cool over the next couple days is
that anybody dropping by stream is going
that anybody dropping by stream is going
to be able to give input on, you know,
to be able to give input on, you know,
how the new uh how the new transcript
how the new uh how the new transcript
should look, where they should go,
should look, where they should go,
what's going to be easiest to use, that
what's going to be easiest to use, that
type of a thing. We'll have these runs
type of a thing. We'll have these runs
going in the background. And then the
going in the background. And then the
only other small wrinkle uh I have a
only other small wrinkle uh I have a
couple meetings and then there is one
couple meetings and then there is one
environment that seems to not be working
environment that seems to not be working
suddenly and I don't know if something
suddenly and I don't know if something
broke in puffer or if something broke in
broke in puffer or if something broke in
um the environment. I would suspect the
um the environment. I would suspect the
latter because looking at these curves
latter because looking at these curves
these match what I would expect on
these match what I would expect on
neural MMO 3. So we are probably good
here. Yeah.
And I don't know if I actually want to
And I don't know if I actually want to
keep I guess I should probably let's do
keep I guess I should probably let's do
this run for longer to see how this
this run for longer to see how this
changes over time. We'll kill this one
changes over time. We'll kill this one
and we'll come back to this.
Yeah. So, we're now training at 650,000
Yeah. So, we're now training at 650,000
steps per second with a three, what is
steps per second with a three, what is
this? 2.4 million parameter model on
this? 2.4 million parameter model on
here.
So this is what I did for the run that
So this is what I did for the run that
did better. I just increased the number
did better. I just increased the number
of
channels. Yeah. Same as there.
Then here what I tried to do was
Then here what I tried to do was
something a little different. I tried to
something a little different. I tried to
go with a entity encoder for all the
go with a entity encoder for all the
different
attributes. So if you look here, there's
attributes. So if you look here, there's
this max.
this was going to cut down the network
this was going to cut down the network
size quite a bit, but for some reason
size quite a bit, but for some reason
that seems to do way worse. So, I will
that seems to do way worse. So, I will
have to think about why that is, but in
have to think about why that is, but in
the
meantime, yeah, the non- entity encoder
meantime, yeah, the non- entity encoder
just blows up the size of this hidden
just blows up the size of this hidden
layer,
unfortunately. But we will do this for
unfortunately. But we will do this for
now. So, we have 256 hidden and I
now. So, we have 256 hidden and I
believe that this should do
believe that this should do
uh this should actually run. We will
see. Quick test without
Neptune. I got to figure out why the
Neptune. I got to figure out why the
Nvidia drivers just occasionally
Nvidia drivers just occasionally
crashed. It's kind of
crashed. It's kind of
jank. It's not that hard to fix.
But it's a little
silly. So if anybody knows why that
silly. So if anybody knows why that
happens occasionally just Docker loses
happens occasionally just Docker loses
access, you can let me know.
So 4.2 mil parameter model. And I forgot
So 4.2 mil parameter model. And I forgot
one other
thing. It's left
over. And I'm not seeing the chat, but I
over. And I'm not seeing the chat, but I
think it should be working. Yeah, there
think it should be working. Yeah, there
we go. Hey,
we go. Hey,
Captain. Up close and personal. Well,
Captain. Up close and personal. Well,
we'll see if that stays. Um, it's very
we'll see if that stays. Um, it's very
difficult to actually get this setup
difficult to actually get this setup
correct because I also have this whole
correct because I also have this whole
big microphone and pop filter on a boom
big microphone and pop filter on a boom
arm.
arm.
So, we got to figure this out. It's a
So, we got to figure this out. It's a
little close.
interested to see pics of the
interested to see pics of the
setup. Uh, one
setup. Uh, one
moment. The thing is, we still need all
moment. The thing is, we still need all
the new machines, right? So, I just have
the new machines, right? So, I just have
the one box on there at the
the one box on there at the
moment, but it does work and it's very
moment, but it does work and it's very
nice to wire stuff.
As soon as I get this run
As soon as I get this run
going, I think the camera will
autofocus. I also would like to check if
autofocus. I also would like to check if
this compile even does anything with the
this compile even does anything with the
optimizer. Okay, so there we go. So, so
optimizer. Okay, so there we go. So, so
that's still
that's still
500K on the uh the nicer GPU.
So you can see, yeah, I have it in the
So you can see, yeah, I have it in the
shot. So right
shot. So right
back there, we have one of the boxes.
back there, we have one of the boxes.
That's the first uh 5090 box on there.
That's the first uh 5090 box on there.
Uh the wiring isn't in the shot, but you
Uh the wiring isn't in the shot, but you
can kind of see in the background with
can kind of see in the background with
all those
all those
rails, we've got 40 outlets there. Uh,
rails, we've got 40 outlets there. Uh,
and they're going to be there's room for
and they're going to be there's room for
four of those additional racks. Uh, and
four of those additional racks. Uh, and
then there's also room for Yeah, you can
then there's also room for Yeah, you can
see the server frame like the open frame
see the server frame like the open frame
back there that's got UPS that's got um
back there that's got UPS that's got um
switches and stuff and then that will
switches and stuff and then that will
contain anything else that we acquire.
contain anything else that we acquire.
So, we have plenty of capacity for
So, we have plenty of capacity for
hardware now. And uh the GPU machines,
hardware now. And uh the GPU machines,
it's just going to be a matter of when
it's just going to be a matter of when
tariffs come down. Are all the puffer
tariffs come down. Are all the puffer
boxes up now? They should be except for
boxes up now? They should be except for
six. Uh that went back to main gear for
six. Uh that went back to main gear for
maintenance.
Um, but yeah, the for the 40, I mean,
Um, but yeah, the for the 40, I mean,
those those can get here pretty quick,
those those can get here pretty quick,
I'm told. Like just 3 4 weeks lead. Um,
I'm told. Like just 3 4 weeks lead. Um,
but the tariffs are like plus 40% price
but the tariffs are like plus 40% price
on all of them right now. So, I'm hoping
on all of them right now. So, I'm hoping
that those are going to come down.
Okay, we have this run
going. Rack is nice
stagnars. Yeah, those are fun.
stagnars. Yeah, those are fun.
Um, they're a little sketchy because you
Um, they're a little sketchy because you
actually you're pretty high up if you
actually you're pretty high up if you
miss. But I'm just messing around on the
miss. But I'm just messing around on the
bottom two, getting used to it for a bit
bottom two, getting used to it for a bit
before I do the whole
thing. This is also not all the
thing. This is also not all the
equipment yet. Right now, we just have
equipment yet. Right now, we just have
the uh the big rack. There's the bench.
the uh the big rack. There's the bench.
I got like an adjustable bench and I've
I got like an adjustable bench and I've
got a log. More stuff is going to be
arriving. Puffer training facility.
arriving. Puffer training facility.
Training for me, training for our
Training for me, training for our
allegiance.
So, the thing that I want to get started
So, the thing that I want to get started
on, at least just to get a start on for
now. I think I want to merge this with
now. I think I want to merge this with
demo. Interesting project. Was the most
demo. Interesting project. Was the most
valuable thing you learned during your
valuable thing you learned during your
time at MIT?
time at MIT?
Man, that's a hard like hard general
Man, that's a hard like hard general
question.
Um, probably just getting a perspective
Um, probably just getting a perspective
on how academia operates
on how academia operates
and where the way that academia operates
and where the way that academia operates
is effective, but then also where it
is effective, but then also where it
isn't. So, knowing where to look for
isn't. So, knowing where to look for
major major gaps and like surely all the
major major gaps and like surely all the
world's top scientists didn't miss
world's top scientists didn't miss
something. No. Yeah, they absolutely
something. No. Yeah, they absolutely
did. and knowing how they operate so you
did. and knowing how they operate so you
can identify places uh where that's
can identify places uh where that's
going to be the case. I mean puffer liib
going to be the case. I mean puffer liib
is something that I just could not have
is something that I just could not have
built really in academia at
built really in academia at
all and uh it was really using that you
all and uh it was really using that you
know that insight after I
know that insight after I
graduated that took me down this
graduated that took me down this
direction.
So this is what I want to do. This is a
So this is what I want to do. This is a
little crazy because this is already an
little crazy because this is already an
1100 line uh trainer file and I do want
1100 line uh trainer file and I do want
to compress this a whole bunch even
to compress this a whole bunch even
though you know a lot of this is just
though you know a lot of this is just
like perf monitoring and stuff. Um but
like perf monitoring and stuff. Um but
what I would like to do
what I would like to do
here I want to combine this with the
here I want to combine this with the
demo
demo
file which is
file which is
381. So that gives you about 1500 lines.
381. So that gives you about 1500 lines.
And then I think there's one or two
And then I think there's one or two
other
things. I think some of the PyTorch
things. I think some of the PyTorch
utils maybe can just go in here as
utils maybe can just go in here as
well. Maybe not. Maybe it is just those
well. Maybe not. Maybe it is just those
two. We'll
two. We'll
see. I think the only thing we're using
see. I think the only thing we're using
from
from
utils is this like tiny
utils is this like tiny
function, right? And
then yeah, so there are a couple things
then yeah, so there are a couple things
here. Um, I think we can get this to the
here. Um, I think we can get this to the
point that it's other than using, you
point that it's other than using, you
know, our base models and stuff like
know, our base models and stuff like
that, it's pretty self-contained. And
that, it's pretty self-contained. And
then the point of doing that, uh, would
then the point of doing that, uh, would
be that we could then put this as a
be that we could then put this as a
single file into the pit package. Let me
single file into the pit package. Let me
show you what I'm sort of thinking
show you what I'm sort of thinking
there. And this is one spot that I
there. And this is one spot that I
definitely want user feedback on what's
definitely want user feedback on what's
going to be easier for folks. But the
going to be easier for folks. But the
way we have this set up in 2.0,
way we have this set up in 2.0,
Now we have this pretty, you know,
Now we have this pretty, you know,
pretty small uh top directory that has a
pretty small uh top directory that has a
few scripts for you. So this has
few scripts for you. So this has
generalized advantage
generalized advantage
estimation. Um this
estimation. Um this
has like a couple clean RL demos and a
has like a couple clean RL demos and a
few
few
utilities. And what you do is if you
utilities. And what you do is if you
just want our environments, you can pip
just want our environments, you can pip
install it. But if you want to use our
install it. But if you want to use our
stuff for training, then you
stuff for training, then you
uh you know, you have to clone
uh you know, you have to clone
it. And I think most people are going to
it. And I think most people are going to
want to clone it anyways because as soon
want to clone it anyways because as soon
as you want to do any research and hack
as you want to do any research and hack
on stuff, uh you do need the source
on stuff, uh you do need the source
code.
code.
But I think for um people who are just
But I think for um people who are just
like trying to run our trainer or run
like trying to run our trainer or run
our stuff on new M's and don't really
our stuff on new M's and don't really
want to be doing research side stuff,
want to be doing research side stuff,
you know, kind of just
you know, kind of just
tinkering, we could probably make it pip
tinkering, we could probably make it pip
installable, including the training.
installable, including the training.
That doesn't mean I want to commit to an
That doesn't mean I want to commit to an
API necessarily, but we could put the
API necessarily, but we could put the
demo behind like an entry point in um in
demo behind like an entry point in um in
the pip package. So you could just do
the pip package. So you could just do
like puffer train or something and it
like puffer train or something and it
will just call that file. And I would if
will just call that file. And I would if
we're going to do that though, I want
we're going to do that though, I want
that to be like as minimal as possible.
that to be like as minimal as possible.
I don't want to have like an ever
I don't want to have like an ever
expanding folder and then we become like
expanding folder and then we become like
a RL
a RL
API. And I think that the main impetus
API. And I think that the main impetus
for this is just like how much better
for this is just like how much better
our train demo has gotten. You know,
our train demo has gotten. You know,
when I started Puffer, I thought it was
when I started Puffer, I thought it was
going to be low-level utilities around
going to be low-level utilities around
MS and training and stuff. And what's
MS and training and stuff. And what's
happened since then is like we've just
happened since then is like we've just
eaten the whole stack and now
eaten the whole stack and now
um our implementation is just so much
um our implementation is just so much
faster than everything else that you're
faster than everything else that you're
probably going to want to use
probably going to want to use
puffer. So I mean we could have
puffer. So I mean we could have
something in
something in
here. We could have like clean puff RL
here. We could have like clean puff RL
in here. Some of this stuff could get
in here. Some of this stuff could get
squashed like this folder will get
squashed like this folder will get
smaller.
Let's see how it is in
Let's see how it is in
dev. We do have some CUDA stuff. So,
dev. We do have some CUDA stuff. So,
there will have to be like some CUDA
there will have to be like some CUDA
stuff in
there. I could just put it all inside of
there. I could just put it all inside of
like a puffer li, right?
The thing that I don't want, right, is I
The thing that I don't want, right, is I
don't want Puffer Lib to become
don't want Puffer Lib to become
like I think it's either too early or
like I think it's either too early or
entirely the wrong idea to try to like
entirely the wrong idea to try to like
Here, look at all the libraries that
Here, look at all the libraries that
have tried to do
this. So like here stable baselines 3,
this. So like here stable baselines 3,
they tried to modularize stuff. This is
they tried to modularize stuff. This is
like one of the common ones. It's really
like one of the common ones. It's really
slow. It's really hard to hack on
slow. It's really hard to hack on
anything that's not covered. And ours is
anything that's not covered. And ours is
just like faster and better with a tiny
just like faster and better with a tiny
tiny amount of the code at this point.
tiny amount of the code at this point.
Like you don't need all these
Like you don't need all these
implementations if this one is just
implementations if this one is just
better and works and is faster.
better and works and is faster.
Um, so like a lot of the different
Um, so like a lot of the different
libraries like they they kind of want to
libraries like they they kind of want to
have all the different algorithms and
have all the different algorithms and
then they try to come up. Yeah, look at
then they try to come up. Yeah, look at
all this stuff. And then they try to
all this stuff. And then they try to
come up with like ways to make them all
come up with like ways to make them all
play nicely with the same experience
play nicely with the same experience
buffer or stuff like that. I don't want
buffer or stuff like that. I don't want
to do
to do
that. Yeah, I don't want to do that at
that. Yeah, I don't want to do that at
all. I want to go the opposite
all. I want to go the opposite
direction. I want it to be a lot more
direction. I want it to be a lot more
like clean RL and get as like close to
like clean RL and get as like close to
this simplicity as we possibly
can. So like this is clean po and they
can. So like this is clean po and they
only have 286 lines here. I guess 329
only have 286 lines here. I guess 329
counting white space and
stuff and it's like so
stuff and it's like so
simple, but I really want to get closer
simple, but I really want to get closer
and closer to
and closer to
this. Well, of course, you know, we have
this. Well, of course, you know, we have
we have stuff we have to handle in order
we have stuff we have to handle in order
to make it
to make it
fast. But as close as we can get to this
fast. But as close as we can get to this
level of simplicity, the better. Now, I
level of simplicity, the better. Now, I
don't think like this you're literally
don't think like this you're literally
just intended to edit this one file and
just intended to edit this one file and
then this one file is kind of like one
then this one file is kind of like one
environment, one experiment, whatever.
environment, one experiment, whatever.
So, we want a little bit more
So, we want a little bit more
flexibility than that. You know, I'd
flexibility than that. You know, I'd
like to be able to run this uh on
like to be able to run this uh on
different environments and on different
different environments and on different
policies. So instead of just having the
policies. So instead of just having the
environment hardcoded in the policy in
environment hardcoded in the policy in
here, I'd like to be able to load in a
here, I'd like to be able to load in a
different environment and a different
different environment and a different
policy, uh, I would like RNN support. So
policy, uh, I would like RNN support. So
maybe I should compare more to
maybe I should compare more to
this. There's only
375, but I
375, but I
like it bothers me that we have so so
like it bothers me that we have so so
much more code than this. And like I
much more code than this. And like I
know why everything is there but
know why everything is there but
still cuz
like so first of all we we have like
like so first of all we we have like
this eval train split right you don't
this eval train split right you don't
just run the script you run eval and
just run the script you run eval and
then you run train and you run eval and
then you run train and you run eval and
you have run train and that's done that
you have run train and that's done that
way so it's easier to like evaluate
way so it's easier to like evaluate
existing
existing
policies and it's kind of
fine this whole name space thing is
ridiculous. That's 45 lines right
ridiculous. That's 45 lines right
there. We've got all this different
there. We've got all this different
optimizer
config. We've got all this like LSTM
config. We've got all this like LSTM
nonLSTM stuff to support both.
We've got P30, which is still like work
We've got P30, which is still like work
in progress that I need to go back
to. And all these things kind of add up
to. And all these things kind of add up
and just add a bunch of bulk. Now, the
and just add a bunch of bulk. Now, the
one thing I was really proud of lately
one thing I was really proud of lately
is I did fix our profiling. So, our
is I did fix our profiling. So, our
profiling is very light now. You know,
profiling is very light now. You know,
you just have a few lines and you get
you just have a few lines and you get
comprehensive
comprehensive
profiling. So, most of this stuff is not
profiling. So, most of this stuff is not
too much overhead over um over clean RL.
too much overhead over um over clean RL.
And I think once we evaluate Diane and
And I think once we evaluate Diane and
we evaluate P30 and like figure out what
we evaluate P30 and like figure out what
matters there, this will be pretty close
matters there, this will be pretty close
to comparable stuff like this, I can
to comparable stuff like this, I can
definitely crunch up a little bit. If I
definitely crunch up a little bit. If I
try and then like this whole block is
try and then like this whole block is
P30. So, I think
P30. So, I think
like if we once we really know what we
like if we once we really know what we
need to keep and what we don't need to
need to keep and what we don't need to
keep and we kind of just keep the one
keep and we kind of just keep the one
path that we really want, like we can
path that we really want, like we can
cut out a lot of this stuff. A lot of
cut out a lot of this stuff. A lot of
this extra that's been in here is just
this extra that's been in here is just
not really
needed. It's going to be a lot of
needed. It's going to be a lot of
experiments to figure out for sure what
experiments to figure out for sure what
matters and what doesn't, but um we
matters and what doesn't, but um we
should be able to do that.
experience buffer
experience buffer
stuff maybe can compress a little
stuff maybe can compress a little
bit. This is more experience buffer
bit. This is more experience buffer
stuff. We have distributed, we've got
stuff. We have distributed, we've got
logging and now we are at 750 lines of
logging and now we are at 750 lines of
which we can probably delete
which we can probably delete
250 at
250 at
least. And then we have features that
least. And then we have features that
clean RL just doesn't have, right? They
clean RL just doesn't have, right? They
don't have checkpointing, model saving
don't have checkpointing, model saving
and loading
and loading
stuff. Um, we have this eval mode so you
stuff. Um, we have this eval mode so you
can like run
can like run
rollouts and then we have profiling
rollouts and then we have profiling
quite a bit of
quite a bit of
profiling and the dashboard. All this is
profiling and the dashboard. All this is
just to print that local the little
just to print that local the little
local
dashboard. So this type of stuff
dashboard. So this type of stuff
probably there's not much to save. So
probably there's not much to save. So
this is going to be
200ish
lines. Yeah. So, there's like 200 lines
lines. Yeah. So, there's like 200 lines
of profiling at the
bottom and another like almost 200 lines
bottom and another like almost 200 lines
of utils.
of utils.
Okay. Well, I'm not too beat up over
Okay. Well, I'm not too beat up over
those.
Like I don't it doesn't make sense to
Like I don't it doesn't make sense to
have like a line target or anything for
have like a line target or anything for
this. That's kind of just stupid. Um but
this. That's kind of just stupid. Um but
I think that the thing is going to be to
I think that the thing is going to be to
just like put the two files together and
just like put the two files together and
then just try to remove anything that is
then just try to remove anything that is
redundant.
redundant.
Most of the redundant stuff looks like
Most of the redundant stuff looks like
it comes from
it comes from
optional args of like supporting
optional args of like supporting
different settings where really we want
different settings where really we want
to run all the experiments and only
to run all the experiments and only
support the settings we care about. So
support the settings we care about. So
that should get better.
Um and then what about the demo file?
Um and then what about the demo file?
The demo file has WB and Neptune. We do
The demo file has WB and Neptune. We do
need to support both of
need to support both of
those. This policy load stuff can get
those. This policy load stuff can get
simplified. Sweep configs already pretty
simplified. Sweep configs already pretty
simple. Maybe we can do something for
simple. Maybe we can do something for
this. We probably can totally do
this. We probably can totally do
something for this,
right? Yeah, we can to we can totally do
right? Yeah, we can to we can totally do
something for that.
uh carbs will be gone once we have
uh carbs will be gone once we have
evaluated it
thoroughly cuz I'm sure we outperformed
thoroughly cuz I'm sure we outperformed
that. Got this training stuff some
that. Got this training stuff some
little jank injection whatever here
little jank injection whatever here
backend stuff. I think a lot of this
backend stuff. I think a lot of this
like multi selection thing we can
like multi selection thing we can
probably
probably
do much more easily without having all
this like we can probably just
this like we can probably just
dynamically load whichever one you have
dynamically load whichever one you have
in the
in the
config. We have
DDP. Here's the loop.
DDP. Here's the loop.
We have this like jank data collection
We have this like jank data collection
thing on like down sampling the
thing on like down sampling the
trajectory for protein. Whether or not
trajectory for protein. Whether or not
that's useful, we'll have to see
that's useful, we'll have to see
still. Yeah, this down
still. Yeah, this down
sampler DDP. And
sampler DDP. And
then 230 down to 381. So 150 lines of
then 230 down to 381. So 150 lines of
this main
this main
file. Setting up
arg reading configs. this bit
arg reading configs. this bit
here and then calling all the associated
methods.
methods.
Oh, no time like the present.
And now we see all the stuff that we
And now we see all the stuff that we
also import from puffer lip here as
also import from puffer lip here as
well. Right.
Yeah, this is much easier.
And we've got
rich. Now we're no longer calling this
rich. Now we're no longer calling this
externally as if it were like some API.
1473 starting
1473 starting
lines. And this should work already
lines. And this should work already
unless they're name
complex missing four
arguments. So there is a name conflict
arguments. So there is a name conflict
here.
So it
So it
is the fact that we have this wrapped
is the fact that we have this wrapped
trainer is interesting.
As ridiculous as this is, this is like
As ridiculous as this is, this is like
one of my favorite things to do is to
one of my favorite things to do is to
just paste all the code together and
just paste all the code together and
then like see what ends up being
then like see what ends up being
redundant when you have everything next
redundant when you have everything next
to each other. It ends up being
to each other. It ends up being
ridiculously effective, but like I do
ridiculously effective, but like I do
end up with very long files as a result
end up with very long files as a result
of that.
of that.
Um, but like I end up with one file that
Um, but like I end up with one file that
is a third of the length of the 10 files
is a third of the length of the 10 files
you would have written
otherwise. Okay, so there's breakout at
otherwise. Okay, so there's breakout at
3 million steps per second. That is a 26
3 million steps per second. That is a 26
second training
loop. And this already runs.
So, I would like to ideally do this
So, I would like to ideally do this
without introducing any major bugs,
without introducing any major bugs,
which means smaller little refactor hops
which means smaller little refactor hops
than I would normally do.
And for reference, the plan here is I
And for reference, the plan here is I
just wanted to get like the test stream
just wanted to get like the test stream
in this morning. Uh, you know, the whole
in this morning. Uh, you know, the whole
new setup
here and then I will be back for the
here and then I will be back for the
whole rest of the day after breakfast
whole rest of the day after breakfast
working on this.
minus or modulo one I believe one call
minus or modulo one I believe one call
in the mid-after
afternoon so what is there okay here's
afternoon so what is there okay here's
another question right what is there in
another question right what is there in
here that I can cut out that is not
here that I can cut out that is not
related to me supporting like more
related to me supporting like more
options that I have not thoroughly
options that I have not thoroughly
evaluated yet because we know that
evaluated yet because we know that
there's like different advantage
there's like different advantage
functions and stuff like
functions and stuff like
that. But what is there in here that's
that. But what is there in here that's
just like
ridiculous? I mean, the way that I have
ridiculous? I mean, the way that I have
this create
function, man, I really hate to admit
function, man, I really hate to admit
that this should probably just be a
that this should probably just be a
class. There's this thing at the bottom
class. There's this thing at the bottom
that's like a data like this thing is
that's like a data like this thing is
ridiculous here,
right? And yeah, I can get rid of a lot
right? And yeah, I can get rid of a lot
of these, but
still I guess what I was going for here,
still I guess what I was going for here,
right? So easy in clean RL because they
right? So easy in clean RL because they
just have this one function and
just have this one function and
everything is just global. You
everything is just global. You
see like everything is just global. So
see like everything is just global. So
they don't have this
they don't have this
issue. But if you actually figure out
issue. But if you actually figure out
and like try to pass everything that you
and like try to pass everything that you
need for eval and everything you need
need for eval and everything you need
for trains like separately, the
for trains like separately, the
signatures of these get gigantic. So I
signatures of these get gigantic. So I
stuff this into a giant data structure
stuff this into a giant data structure
which then obviously grows and grows and
which then obviously grows and grows and
then like accumulates everything.
Okay, what are options? Option one is
Okay, what are options? Option one is
leave it as
is. Option
is. Option
two, just bite the bullet and convert
two, just bite the bullet and convert
this to a class.
Then each of these things would get
Then each of these things would get
assigned when they're
needed. Option three would be to create
needed. Option three would be to create
this thing
dynamically. So like I can assign stuff
dynamically. So like I can assign stuff
to this after it's
to this after it's
made. That's kind of just like making it
made. That's kind of just like making it
sort of like a dictionary.
The original reason that I didn't want
The original reason that I didn't want
this to be a class was
this to be a class was
what? Was it literally just the
indenting? So you go
indenting? So you go
train or
Other than this,
like most of this is pretty
reasonable. I think that what happened
reasonable. I think that what happened
was before like because we had all the
was before like because we had all the
profiling code
profiling code
indenting I like I thought it was just
indenting I like I thought it was just
getting to be absolutely ridiculous like
getting to be absolutely ridiculous like
you're writing code halfway across the
screen. It probably wasn't a great
screen. It probably wasn't a great
reason to do this
though. A lot of this is also kind of
though. A lot of this is also kind of
left over because
left over because
like this is a language thing, right?
like this is a language thing, right?
Like I know how I would do this in C and
Like I know how I would do this in C and
it would look pretty similar to this
it would look pretty similar to this
except that there would just there'd be
except that there would just there'd be
a strct because that's how you would
a strct because that's how you would
have to do it in C and it would be very
have to do it in C and it would be very
simple, right? Because everything that's
simple, right? Because everything that's
zero would default to zero
and like the actual creation of the
and like the actual creation of the
strct would be
strct would be
smaller. Uh but that's not really how
smaller. Uh but that's not really how
Python works.
I guess technically I could put it as a
I guess technically I could put it as a
data
data
class. I've not liked those in the
past. I mean this is basically a strct,
past. I mean this is basically a strct,
right?
This does not feel good to me
though. You know, I think the reason
though. You know, I think the reason
that I like
that I like
this, the reason I like this in C and
this, the reason I like this in C and
not in
not in
Python is because C is typed, right?
Python is because C is typed, right?
So I would have this function not be a
So I would have this function not be a
part of the data class but then it would
part of the data class but then it would
take the type which is inventory
item. So here it's like this data class
item. So here it's like this data class
is kind
of hang on. Do you even need data class
of hang on. Do you even need data class
like this? What does data class even do?
I thought this was changed.
Yeah. So you don't even need that data
Yeah. So you don't even need that data
class annotator.
Okay.
So, you know, I agonize over like these
So, you know, I agonize over like these
little details like this. This is
little details like this. This is
probably the fifth time I've thought
probably the fifth time I've thought
about this, but it matters a lot.
Half of this is me fighting against like
Half of this is me fighting against like
me wanting to write C in Python, which
me wanting to write C in Python, which
is just not smart. The other half is me
is just not smart. The other half is me
fighting against like doing it the
fighting against like doing it the
really dumb Python
really dumb Python
way. Okay, so what if I just made
way. Okay, so what if I just made
it what if I just took all these things
it what if I just took all these things
that have obvious defaults, right?
that have obvious defaults, right?
So what if I make this thing a class? I
So what if I make this thing a class? I
have all these things that are like
have all these things that are like
obvious
obvious
defaults, all these zeros and
defaults, all these zeros and
things.
Um I can put those up
top. What happens if you have like this
top. What happens if you have like this
be another in an instance of a class?
be another in an instance of a class?
Does that happen? Like does that work?
like
Oh, I think it was because you can just
do Yeah, you can't do this. That's what
do Yeah, you can't do this. That's what
data class gives you,
data class gives you,
right? And we don't need
that. So,
that. So,
um, okay. What would this look like
um, okay. What would this look like
then? A lot of these, this junk, this
then? A lot of these, this junk, this
junk, right, would be
junk, right, would be
at the
top and then we would have an init
function that sets all
this. A lot of these things don't even
this. A lot of these things don't even
necessarily need to be in an init
though. Like this is a global, right?
though. Like this is a global, right?
Like this is a global setting for
Like this is a global setting for
torch. Putting it inside of this
torch. Putting it inside of this
function doesn't do
anything. The seeding stuff. Yeah, cuz
anything. The seeding stuff. Yeah, cuz
there's a seed that you can
set. I don't even know if we need to do
set. I don't even know if we need to do
that though because like realistically
that though because like realistically
you're not getting that same curve back
you're not getting that same curve back
anyways.
maybe
R. I guess it depends on whether you're
R. I guess it depends on whether you're
MC
correctly. Okay. So, I think what I'm
correctly. Okay. So, I think what I'm
going to do, I'm going to go get
going to do, I'm going to go get
breakfast in a minute here.
Um, yeah, like even this losses thing is
Um, yeah, like even this losses thing is
is kind of
is kind of
ridiculous. Okay, I'm going to think
ridiculous. Okay, I'm going to think
about this a little bit over breakfast.
about this a little bit over breakfast.
I think that the main
I think that the main
thing for this is like figuring out what
thing for this is like figuring out what
we do with the structure of this whole
we do with the structure of this whole
training code because everything else
training code because everything else
for the most part, I mean, at least a
for the most part, I mean, at least a
lot of it is just us supporting a ton of
lot of it is just us supporting a ton of
settings that we haven't decided which
settings that we haven't decided which
ones we want to keep.
ones we want to keep.
Um, yeah, I think that over the next
Um, yeah, I think that over the next
couple days, the plan is going to be to
couple days, the plan is going to be to
see if we can really condense this thing
see if we can really condense this thing
down into a nice simple, easy to use uh
down into a nice simple, easy to use uh
single file transcript for Puffer Lib.
single file transcript for Puffer Lib.
If you want to be a part of that and you
If you want to be a part of that and you
want to give feedback on how this thing
want to give feedback on how this thing
should look and what would be the
should look and what would be the
easiest for you to use in Puffer and uh,
easiest for you to use in Puffer and uh,
you know, how hyper RL should work, then
you know, how hyper RL should work, then
you can drop by the streams for that.
you can drop by the streams for that.
I'm going to go get breakfast. I'll be
I'm going to go get breakfast. I'll be
live for pretty much the rest of the day
live for pretty much the rest of the day
outside of one meeting and then all day
outside of one meeting and then all day
tomorrow as well. And pretty much this
tomorrow as well. And pretty much this
is the schedule going forward. I'm back
is the schedule going forward. I'm back
to dev and uh aiming to try to finish up
to dev and uh aiming to try to finish up
the next release over the next few
the next release over the next few
weeks, get something shipped, get a
weeks, get something shipped, get a
whole bunch of stuff written on that as
whole bunch of stuff written on that as
well, which I'll probably also deal on
well, which I'll probably also deal on
stream cuz why not?
stream cuz why not?
And other than that uh yeah I have some
And other than that uh yeah I have some
research ideas for after the release but
research ideas for after the release but
I think the initial goal is just ultra
I think the initial goal is just ultra
high performance really stable hyper
high performance really stable hyper
pram robust uh easy to use version next
pram robust uh easy to use version next
version of puffer lip and I still
version of puffer lip and I still
haven't decided on a version number for
haven't decided on a version number for
that. So thanks for dropping by. I will
that. So thanks for dropping by. I will
be back in probably only like half an
be back in probably only like half an
hour or so.
hour or so.
Uh, if you want to check out all this
Uh, if you want to check out all this
stuff, it's all open source at
stuff, it's all open source at
puffer.ai. You can start on GitHub to
puffer.ai. You can start on GitHub to
really help us out. You can join the
really help us out. You can join the
Discord to get involved with dev. Most
Discord to get involved with dev. Most
of our contributors came in with zero RL
of our contributors came in with zero RL
experience and are now doing really
experience and are now doing really
awesome stuff, really cutting edge RL
awesome stuff, really cutting edge RL
stuff. So, uh, thanks and I will be back
stuff. So, uh, thanks and I will be back
in a bit.
