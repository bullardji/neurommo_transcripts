Kind: captions
Language: en
okay I think this is
okay I think this is
working um I just upgraded this thing so
working um I just upgraded this thing so
I can also mirror this room to
Twitch let
Twitch let
me see how that
works make sure it's live on Twitch
hold on
autoplay yeah okay that looks like it's
autoplay yeah okay that looks like it's
working the
audio Yeah audio is good it's going to
audio Yeah audio is good it's going to
Echo if I leave that up so let me get
Echo if I leave that up so let me get
rid of the infinite
rid of the infinite
mirror
mirror
um I would like to test the chat briefly
um I would like to test the chat briefly
actually let me
actually let me
hold on let me go do that real
quick ah audio
play
play
test ah
test ah
perfect restream chat
perfect restream chat
Works only has a few lines in it but
Works only has a few lines in it but
that's
plenty Okay so
plenty Okay so
what I'm going to do at the
what I'm going to do at the
moment partially just a test stream but
moment partially just a test stream but
also going to try to continue a little
also going to try to continue a little
bit of the dev uh from earlier
today when I left this thing
off we had this super simple little
off we had this super simple little
environment and uh I had it training
environment and uh I had it training
before
before
and uh this is discreet right now or
and uh this is discreet right now or
actually this is continuous but I had it
actually this is continuous but I had it
solved continuous or I had it solved
solved continuous or I had it solved
discreet and now I want to make it solve
discreet and now I want to make it solve
continuous so I added continuous control
continuous so I added continuous control
to puffer lid technically it was only
to puffer lid technically it was only
like 20 lines of code people have been
like 20 lines of code people have been
asking me to do it forever I just didn't
asking me to do it forever I just didn't
want to bother writing the 20 lines of
want to bother writing the 20 lines of
code um now I did it and it technically
code um now I did it and it technically
works but the control uh the control
works but the control uh the control
version does not optimize anywhere near
version does not optimize anywhere near
as well so I tried a few different
as well so I tried a few different
control environments out they're all
control environments out they're all
really bad and really slow I wrote this
really bad and really slow I wrote this
simple one as a test and now we're going
simple one as a test and now we're going
to see if we can solve this really
to see if we can solve this really
really basic
really basic
environment and if anybody happens to
environment and if anybody happens to
watch this who has done continuous
watch this who has done continuous
control in RL cuz almost all the M's I
control in RL cuz almost all the M's I
work with have discreet actions and
work with have discreet actions and
there is any magic sauce I'm missing
there is any magic sauce I'm missing
please let me
please let me
know
so hello andrees Andre ah I wish I could
so hello andrees Andre ah I wish I could
pronounce your name but I have seen you
pronounce your name but I have seen you
around chat looks like it's working I
around chat looks like it's working I
got a little basic overlay for the
got a little basic overlay for the
stream it'll improve over time
stream it'll improve over time
just wanted to do something basic to
just wanted to do something basic to
start with um because I've been enjoying
start with um because I've been enjoying
the streaming so you maybe I'll keep
the streaming so you maybe I'll keep
upgrading stuff this is mainly just a
upgrading stuff this is mainly just a
way to like get people to see my work
way to like get people to see my work
get people to get excited about RL but
get people to get excited about RL but
I've been enjoying
I've been enjoying
it
um
okay
so this is what I had for the continuous
so this is what I had for the continuous
environment
and it doesn't really
and it doesn't really
seem to optimize much at all um I would
seem to optimize much at all um I would
like to see if it's optimizing
like to see if it's optimizing
whatsoever
whatsoever
versus uh not optimizing at all so what
versus uh not optimizing at all so what
we're going to do is we're going to
we're going to do is we're going to
train a baseline
train a baseline
here and then I'm going
here and then I'm going
to open up wand B and see if the
to open up wand B and see if the
training curves are just worse or if
training curves are just worse or if
they are flat
they are flat
that would be a good thing to do
oops interesting so it doesn't look like
oops interesting so it doesn't look like
the training curves are
flat this is actually
flat this is actually
optimizing it's just not optimizing you
optimizing it's just not optimizing you
know
know
remotely as well as it should
be if few things stick out to
me so the first major thing
here wait clip
Frack okay so something is wrong with
Frack okay so something is wrong with
the clip Frack this should not be above
the clip Frack this should not be above
one so we got to look at clip Frack
one so we got to look at clip Frack
that's
that's
nuts and then we got to look at the
nuts and then we got to look at the
entropy
entropy
the entropy is decreasing now I think
the entropy is decreasing now I think
correctly but it's still not where it
correctly but it's still not where it
needs to be so I think they're just some
needs to be so I think they're just some
like weird instabilities with this thing
like weird instabilities with this thing
but the training curve is actually going
but the training curve is actually going
up if we look at it it's just going up
up if we look at it it's just going up
very slowly they should be solved in
very slowly they should be solved in
like 100,000 steps very very
easily we'll let this finish out just to
easily we'll let this finish out just to
be sure and look the entropy is actually
be sure and look the entropy is actually
going down down so you know it is
going down down so you know it is
possible that the entropy scale is just
possible that the entropy scale is just
very different for control tasks but I
very different for control tasks but I
would have to think about why that is it
would have to think about why that is it
could just be a property of the way the
could just be a property of the way the
loss is
constructed and it actually doesn't you
constructed and it actually doesn't you
know it doesn't really get up to where
know it doesn't really get up to where
this should be like 0. n uh way before
this should be like 0. n uh way before
now but it is actually doing something
now but it is actually doing something
reasonable it's just not where it needs
reasonable it's just not where it needs
to be
oh actually wait no no no no this is the
oh actually wait no no no no this is the
this is the discret version isn't it
this is the discret version isn't it
yeah yeah yeah so this is
yeah yeah yeah so this is
the wait now I've confused myself which
the wait now I've confused myself which
version do I which version did I just
train okay discretize is false this is
train okay discretize is false this is
the continuous version
the continuous version
good so now if we eval the Baseline
we'll make
sure oh now it's suddenly much
sure oh now it's suddenly much
better still not good but way
better still not good but way
better so it is definitely learning
better so it is definitely learning
something you can see it's kind of
something you can see it's kind of
Meandering around the target this way
Meandering around the target this way
here it is learning not to go off the
here it is learning not to go off the
screen it gets a very large negative
screen it gets a very large negative
reward if it goes off screen
and it doesn't get to be close to the
and it doesn't get to be close to the
Target but it should be solving the
Target but it should be solving the
environment like instantly it's a very
environment like instantly it's a very
easy environment so entropy is
easy environment so entropy is
decreasing to something more reasonable
decreasing to something more reasonable
that's good um clip Frack is
increasing how are we Computing clip
increasing how are we Computing clip
Frack that it's possible for it to be
Frack that it's possible for it to be
above
above
one I think I have an
idea so clip Frack gets meaned here and
idea so clip Frack gets meaned here and
then num mini
then num mini
batches
so this should not be able to be above
so this should not be able to be above
one
right
right
ratio do
mean experience. Nom mini
mean experience. Nom mini
batches very very
batches very very
weird let's
um okay let's just run some local
train
0.9 eight mini batches
that's very very odd so that's basically
that's very very odd so that's basically
meaning that all the data is
meaning that all the data is
immediately off
policy doesn't make any
sense let's run a a second Baseline for
sense let's run a a second Baseline for
comparison that's going to be the exact
comparison that's going to be the exact
same environment but we're going to do
same environment but we're going to do
the uh the discrete version
okay we're going to do discreet
version and as you can see this one is
version and as you can see this one is
immediately going to be way
better yeah episode return immediately
better yeah episode return immediately
going right up to
going right up to
one episode length is going down to be
one episode length is going down to be
around
around
10 where's here it's still hovering at
10 where's here it's still hovering at
like
like
30 uh here we
30 uh here we
have entripy starts at 5 and goes down
have entripy starts at 5 and goes down
to something reasonable like
to something reasonable like
two oh actually the clip Frack is high
two oh actually the clip Frack is high
in this one as well
in this one as well
so this potentially means I just have
so this potentially means I just have
very bad settings
very bad settings
because this is a ridiculous value for a
because this is a ridiculous value for a
clip Frack I actually don't know how
clip Frack I actually don't know how
it's possible that
um I don't know how it's possible for it
um I don't know how it's possible for it
to be that high so we should definitely
to be that high so we should definitely
check on
check on
that um let's figure that out first cuz
that um let's figure that out first cuz
that looks like a bug to
that looks like a bug to
me opportunity to chase down a more
me opportunity to chase down a more
General puffer lib most likely just an
General puffer lib most likely just an
error in the way I'm scaling it
okay so experience. Nom mini
batches right
here
here
and uh so right here we're adding all of
and uh so right here we're adding all of
these
things uh this is this is quite odd so
things uh this is this is quite odd so
if you look at this we are adding
if you look at this we are adding
together the
loss and we're dividing by the number of
loss and we're dividing by the number of
mini batches
mini batches
but we are not dividing by the number of
but we are not dividing by the number of
update
update
epochs
epochs
so that's not
so that's not
good so we should probably
do uh let's see
do uh let's see
see let's do a total mini
see let's do a total mini
batches times config do update
batches times config do update
epox num mini so we do total mini
epox num mini so we do total mini
batches
so this is actually a uh no
so this is actually a uh no
error this is not an error in puffer
error this is not an error in puffer
it's just a quirk with scaling it
it's just a quirk with scaling it
doesn't harm anything but um you know
doesn't harm anything but um you know
we'll we'll fix it up
we'll we'll fix it up
just for the sake of it so now it should
just for the sake of it so now it should
be 4X lower which would still
be 4X lower which would still
be a ridiculous clip Frack here of
be a ridiculous clip Frack here of
course we have this clip Frack
course we have this clip Frack
decreasing over time but that is because
decreasing over time but that is because
of the anal
of the anal
so let us
so let us
disable this anal learning rate
oops we're going to disable learning
oops we're going to disable learning
rate and
rate and
kneeling because it makes things
kneeling because it makes things
annoying and
annoying and
inconsistent um
entropy very
low let's now look at the the batches
maybe ah these batch sizes are this is
why so we have all these environments
why so we have all these environments
but we have not updated the the batch
but we have not updated the the batch
sizes
sizes
accordingly so let's just just think
of 64 environments
of 64 environments
times 16 steps is
times 16 steps is
1024 uh I think that we should probably
1024 uh I think that we should probably
do
do
4096 and 1024
4096 and 1024
maybe or maybe we just do 20 48 and 20
48 there's no reason to have multiple
48 there's no reason to have multiple
mini batches after all
mini batches after all
right or other way around actually
right or other way around actually
update Epoch should be one and we could
update Epoch should be one and we could
have multiple mini batches if we
have multiple mini batches if we
wanted this should be substantially more
wanted this should be substantially more
stable if slower to train
stable if slower to train
potentially let's see what happens when
potentially let's see what happens when
I do
this okay so the SPs immediately is
this okay so the SPs immediately is
going to shoot
up and it is is not going to optimize
up and it is is not going to optimize
which is
interesting it should be substantially
interesting it should be substantially
easier to optimize now so the fact that
easier to optimize now so the fact that
it is not is
concerning yes
entropy immediately
entropy immediately
crashes clip
crashes clip
Frack let me
Frack let me
see which is very odd
indeed that this would make it crash so
indeed that this would make it crash so
badly I see entropy is immediately
badly I see entropy is immediately
collapsing
collapsing
right yes entropy immediately collapses
so if entropy is immediately collapsing
so if entropy is immediately collapsing
that
that
means potentially
means potentially
oops that the uh the policy is
oops that the uh the policy is
overfitting very
overfitting very
early into
this so let's give it like a bigger
this so let's give it like a bigger
entropy coefficient and see if that
entropy coefficient and see if that
helps whatsoever
yes that does immediately solve the
yes that does immediately solve the
environment though it does not appear
environment though it does not appear
stable in the
solution are we running the continuous
solution are we running the continuous
or the discrete version I
forget the discrete version
okay so it literally it's just a
okay so it literally it's just a
hyperparameter
thing and I didn't bother running a
thing and I didn't bother running a
sweep this is just me messing around for
sweep this is just me messing around for
a few minutes so very easily I'm sure we
a few minutes so very easily I'm sure we
can find stable settings with a
sweep let's make sure that this policy
sweep let's make sure that this policy
actually looks you know reasonable it
actually looks you know reasonable it
doesn't have to be perfect we can always
doesn't have to be perfect we can always
run a
sweep I mean that looks pretty good to
sweep I mean that looks pretty good to
me it doesn't always get at 100% like
me it doesn't always get at 100% like
there it'll overshoot but that's pretty
there it'll overshoot but that's pretty
reasonable
reasonable
right
right
yeah so now we're going to do the exact
yeah so now we're going to do the exact
same thing with the continuous
version and we're going to see if it
version and we're going to see if it
learns anything
interesting it
fails
fails
actions why would it fail oh CU I ran
actions why would it fail oh CU I ran
the eval with the wrong end that's
fine let's see
training
training
ooh well that's interesting
this does not appear as quick to
this does not appear as quick to
optimize does appear more
optimize does appear more
unstable we have a clip Frack of 7 which
unstable we have a clip Frack of 7 which
is incredibly
High we're getting all sorts of
High we're getting all sorts of
different values some of which are
different values some of which are
perfectly solving the environment and
perfectly solving the environment and
some of which are not though it does
some of which are not though it does
look to be
stabilizing and the clip fr is still
stabilizing and the clip fr is still
very high very
very high very
odd let's see what this looks
like it's so close
not
not
quite process is amazing to watch thank
quite process is amazing to watch thank
you for going step by
you for going step by
step I'm going to be able to some I'm
step I'm going to be able to some I'm
going to set some some to not okay well
going to set some some to not okay well
thank you for that I got to make the
thank you for that I got to make the
chat font a little larger I think so I
chat font a little larger I think so I
can see it more easily uh thank you
can see it more easily uh thank you
though yeah I I'm having fun doing this
though yeah I I'm having fun doing this
it really doesn't distract me very much
it really doesn't distract me very much
I actually s get more work done on this
I actually s get more work done on this
stream because like I don't know I don't
stream because like I don't know I don't
I get distracted a lot in my own
I get distracted a lot in my own
thoughts when I'm just working usually I
thoughts when I'm just working usually I
kind of just zone out a lot so it's
kind of just zone out a lot so it's
actually been kind of helpful for me as
actually been kind of helpful for me as
well and it's fun and people get to see
well and it's fun and people get to see
this type of work um I actually don't
this type of work um I actually don't
really enjoy this type of debugging of
really enjoy this type of debugging of
environment so much like the
environment so much like the
experimental side I really enjoy
experimental side I really enjoy
building The highper Sims way more uh
building The highper Sims way more uh
there's going to be a lot of that coming
there's going to be a lot of that coming
up now the thing I'd like to know the
up now the thing I'd like to know the
thing I would like to really understand
thing I would like to really understand
right now though is why it seems like
right now though is why it seems like
it's harder to do continuous M's versus
it's harder to do continuous M's versus
discreet Ms there's really no reason
discreet Ms there's really no reason
right there could be a math reason to be
right there could be a math reason to be
fair there could be a math reason why
fair there could be a math reason why
the continuous objective is harder to
the continuous objective is harder to
optimize but if the objective is good
optimize but if the objective is good
then technically the continuous n gives
then technically the continuous n gives
you strictly more control because you
you strictly more control because you
can learn to like accelerate a little
can learn to like accelerate a little
bit or accelerate a lot whereas the
bit or accelerate a lot whereas the
Creet version only lets you uh
Creet version only lets you uh
accelerate at One
Rate okay but
Rate okay but
like is this the one right
like is this the one right
here yeah so this is the n it actually
here yeah so this is the n it actually
does look like it's very very
close oh interesting this is very weird
close oh interesting this is very weird
so look at this so
this was the one that solved it right
this was the one that solved it right
with one point around one reward right
with one point around one reward right
and the episode length is all the way
and the episode length is all the way
down
down
here at like
here at like
five okay and
five okay and
then here if it's just shy it it looks
then here if it's just shy it it looks
like it
like it
rapidly as soon as you're not fully
rapidly as soon as you're not fully
solving it the episode length is way
solving it the episode length is way
longer so
longer so
even though it looks like it's close
even though it looks like it's close
it's really nowhere
it's really nowhere
near if that makes
near if that makes
sense clip Frack is very very suspicious
sense clip Frack is very very suspicious
here clip Frack is very
here clip Frack is very
suspicious we should rerun the baselines
suspicious we should rerun the baselines
now that we have a kneeling off we
now that we have a kneeling off we
should rerun them both they're very
should rerun them both they're very
quick so we're going to do discretize
true I'm going to run the 500K
you can see the episode length rapidly
you can see the episode length rapidly
decreasing as well as the return
decreasing as well as the return
increasing should be stabilizing
nicely ASAP
nicely ASAP
ASAP hello welcome
ASAP hello welcome
cool to see we have a couple people on
cool to see we have a couple people on
YouTube oh that's bet hi
YouTube oh that's bet hi
bet I am currently adding continuous
bet I am currently adding continuous
control to
control to
Puffer that is what I'm
Puffer that is what I'm
doing B is one of our contributors on
doing B is one of our contributors on
the Pokemon project he has done an
the Pokemon project he has done an
absolutely excellent job I'm frankly
absolutely excellent job I'm frankly
amazed at the amount of progress given
amazed at the amount of progress given
the lack of Prior
the lack of Prior
experience took me a hell of a lot
experience took me a hell of a lot
longer to get useful at stuff
longer to get useful at stuff
and linky is here too
and linky is here too
welcome linky is the other amazing
welcome linky is the other amazing
contributor on the Pokemon project
contributor on the Pokemon project
hopefully we'll have results in that
soon I figured you were both in just
soon I figured you were both in just
Discord hanging out and just both click
Discord hanging out and just both click
the stream you both found it
the stream you both found it
independently that's
funny I just set this up so that I have
funny I just set this up so that I have
it streaming on X YouTube and T twitch
it streaming on X YouTube and T twitch
at the same
time okay so this is the environment the
time okay so this is the environment the
discretized version as you can see it's
discretized version as you can see it's
very nice and consistent not perfect but
very nice and consistent not perfect but
pretty darn good
pretty darn good
right very basic
environment very very basic
environment now if we turn discretize to
environment now if we turn discretize to
be false
be false
and we're going to rerun
training let's actually just grab hold
training let's actually just grab hold
on visualize
on visualize
none and then we'll do this one and this
none and then we'll do this one and this
one yeah
where did my graphs
go I should have both of them open where
go I should have both of them open where
why do I not have both graphs
can you visualize the actions being
can you visualize the actions being
taken at all to see if it's learning
taken at all to see if it's learning
fine control uh the thing is it's not
fine control uh the thing is it's not
really learning control at all properly
really learning control at all properly
yet the the discretized version works
yet the the discretized version works
perfectly the control version uh it
perfectly the control version uh it
doesn't quite solve the task it's
doesn't quite solve the task it's
learning
learning
something but this is literally uh like
something but this is literally uh like
hour two or three maybe invested into
hour two or three maybe invested into
continuous control and Puffer so this is
continuous control and Puffer so this is
still very much new and I don't know if
still very much new and I don't know if
it is bugged or if it is just bad hyper
it is bugged or if it is just bad hyper
prams or what is going on yet that is
prams or what is going on yet that is
what the point of this exercise is um
what the point of this exercise is um
I'd also like to know where the heck my
I'd also like to know where the heck my
other Baseline ran my other Baseline run
other Baseline ran my other Baseline run
went it's very
went it's very
weird
that the other one just
that the other one just
disappeared so I might have to go run
disappeared so I might have to go run
another one of
another one of
those this is let's see I can tell just
those this is let's see I can tell just
by looking at it I'm
sure yeah this is the continuous control
sure yeah this is the continuous control
one for
one for
sure Define continuous control actions
sure Define continuous control actions
are not discrete they're continuous so
are not discrete they're continuous so
actions are sampled from a distribution
actions are sampled from a distribution
rather than being like up down left
rather than being like up down left
right uh the discrete version of this
right uh the discrete version of this
environment is you can press up or down
environment is you can press up or down
and that will set your acceleration to
and that will set your acceleration to
one or negative one uh and then the
one or negative one uh and then the
continuous control version you just give
continuous control version you just give
it a number between negative 1 and one
it a number between negative 1 and one
so it's not something a human could
so it's not something a human could
input with a keyboard it would be more
input with a keyboard it would be more
like a
like a
joystick that's actually would have been
joystick that's actually would have been
the much simpler explanation joystick
the much simpler explanation joystick
versus
keyboard should have gone with that from
keyboard should have gone with that from
the
the
start uh do we have clip Frack being too
start uh do we have clip Frack being too
high
high
still that is what I would like to
know yes clip Frack is incredibly high
know yes clip Frack is incredibly high
this is
bad so I don't know where the other
bad so I don't know where the other
graph went so I'm just going to rerun
it and I'm going to bet that it doesn't
it and I'm going to bet that it doesn't
have as that high of a a clip
have as that high of a a clip
frack and we're going to have to figure
frack and we're going to have to figure
out
out
why the clip Frack is so bad
sh
okay so this is the discrete version in
okay so this is the discrete version in
Orange continuous version is in this
Orange continuous version is in this
pink color fuchsia not a
pink color fuchsia not a
salmon
salmon
um interestingly the discret version is
um interestingly the discret version is
substantially
substantially
faster that's interesting to see I guess
faster that's interesting to see I guess
there's one extra layer in the
there's one extra layer in the
network uh the entropy
network uh the entropy
curves decreases for the discreet
curves decreases for the discreet
one and is stable or increases a bit
one and is stable or increases a bit
with the continuous
with the continuous
one the clip Frack for the discreet is
one the clip Frack for the discreet is
high but
high but
stable and is out of
stable and is out of
control this means that 80% of the data
control this means that 80% of the data
is out of bounds hold on how is that
is out of bounds hold on how is that
even possible didn't I just set the mini
even possible didn't I just set the mini
batches
hold on I have mini batch set
hold on I have mini batch set
to
oh let's set update EPO equal to
oh let's set update EPO equal to
one let me see what happens if I do
one let me see what happens if I do
fully on policy
learning so if I do fully on policy
learning I don't know why continuous
learning I don't know why continuous
should be slower it's the same problem
if I set update Epoch to one this
if I set update Epoch to one this
doesn't work hold on continuous or
doesn't work hold on continuous or
discreet okay dis discreet doesn't work
discreet okay dis discreet doesn't work
with one update Epoch which is
with one update Epoch which is
insane that shouldn't be
insane that shouldn't be
possible the clip for should be zero
possible the clip for should be zero
because that's because math
um so somehow this is only
um so somehow this is only
learning via off policy
updates that doesn't make any sense
updates that doesn't make any sense
whatsoever
so entropy crashes to
so entropy crashes to
zero though not
immediately
immediately
policy why like the metrics look a
policy why like the metrics look a
little spiky but they don't look crazy
bad well there was like a little bit of
bad well there was like a little bit of
learning at the start here and then it
learning at the start here and then it
crashed
right kind of
H entropy
H entropy
loss this is with a substantial entropy
loss this is with a substantial entropy
bonus as
bonus as
well that this is
well that this is
crashing it's very
weird do I want to just run a hyper pram
weird do I want to just run a hyper pram
sweep on
sweep on
this or do I want to just think about
it cannot really think of any
it cannot really think of any
reason
reason
why dropping the update Epoch to
why dropping the update Epoch to
one would screw it
up very
up very
odd what if I drop the mini batch
odd what if I drop the mini batch
size at the same time
suddenly it works
again but if I use 20 48 mini
bash oh wait it
bash oh wait it
does it started to optimize there there
does it started to optimize there there
for a second I saw it and then it
for a second I saw it and then it
crashed
back I'm not going to put this down to
back I'm not going to put this down to
anything fundamental when uh the
anything fundamental when uh the
explanation of General learning
explanation of General learning
instability will suffice I'm just going
instability will suffice I'm just going
to mess with it for a
moment hello
moment hello
Nicholas welcome
okay so entropy low isn't helping what
okay so entropy low isn't helping what
about entropy really high that do
about entropy really high that do
anything this is like higher than you
anything this is like higher than you
would ever set
entropy okay good I actually didn't want
entropy okay good I actually didn't want
that to
work so we'll put it back to what it was
work so we'll put it back to what it was
before it needs like some Jitter or
before it needs like some Jitter or
something to train which is really
something to train which is really
weird
weird
um what if I just massively increase the
um what if I just massively increase the
batch size right like what if I just do
batch size right like what if I just do
8192 so now it's going to end up with
8192 so now it's going to end up with
four mini batches again they're just
four mini batches again they're just
going to be
bigger yep that immediately
bigger yep that immediately
trains that actually immediately trains
trains that actually immediately trains
very very stable which is why what it
very very stable which is why what it
should so that's like RL being
should so that's like RL being
Saye and I bet it's not going to work if
Saye and I bet it's not going to work if
I do
I do
this I hope I'm
wrong
wrong
bizarre it like needs off policy updates
bizarre it like needs off policy updates
to learn
huh
why okay wait what if I do update Epoch
why okay wait what if I do update Epoch
to four now so I put multi it's off
to four now so I put multi it's off
policy but it's sort of a different way
policy but it's sort of a different way
of being off
policy yeah it
learns what on
learns what on
Earth that defies
reason mini batch and batch size
reason mini batch and batch size
matter increase episode
length um well episode length is defined
length um well episode length is defined
by the environment that's defined by
by the environment that's defined by
like when it hits the
like when it hits the
target um the thing that doesn't make
target um the thing that doesn't make
sense here right is that like when you
sense here right is that like when you
set mini batch size smaller than batch
set mini batch size smaller than batch
size your learning goes off policy you
size your learning goes off policy you
start updating on stale
start updating on stale
data so I saw that there was a lot of
data so I saw that there was a lot of
instability with that so I said oh okay
instability with that so I said oh okay
let's just set it to be
let's just set it to be
synchronous let's set the mini batch
synchronous let's set the mini batch
size equal to the batch size but it
size equal to the batch size but it
seems like that prevents it from
seems like that prevents it from
learning so there's like some weird
learning so there's like some weird
Jitter effect happening where it like
Jitter effect happening where it like
needs some Jitter to learn or
needs some Jitter to learn or
something let's go like really big just
something let's go like really big just
for the sake of it like 32
yeah that's what I'm doing
yeah that's what I'm doing
now I might have to run this for longer
now I might have to run this for longer
though
because no learning
progress
progress
64k well I'm going to have to start
64k well I'm going to have to start
increasing this massively if I do that
increasing this massively if I do that
right because like the sample efficiency
right because like the sample efficiency
should go down 64 what is it
should go down 64 what is it
648 no 6 oh
648 no 6 oh
65 five
doesn't look like it's doing
doesn't look like it's doing
anything and you can see right
anything and you can see right
here the entropy is
crashing so when
crashing so when
you when you give it a single mini
you when you give it a single mini
batch entropy crashes
this a bug with this should not
be well yeah I can change update Epoch
be well yeah I can change update Epoch
and make it learn but like why this is a
and make it learn but like why this is a
nonsensical like this is a
nonsensical like this is a
nonsensical thing that we're observing
nonsensical thing that we're observing
here this does not make
here this does not make
sense like you can't just throw your
sense like you can't just throw your
hands up when you see stuff like this
hands up when you see stuff like this
like there's got to be a reason for it
like there's got to be a reason for it
and it can potentially reveal like bugs
and it can potentially reveal like bugs
and and other implementation quirks that
and and other implementation quirks that
are very very difficult to find without
are very very difficult to find without
stuff like this
stuff like this
happening um so you know I'm looking for
happening um so you know I'm looking for
if there's some I just noticed that we
if there's some I just noticed that we
were scaling entropy
weirdly ah well this is interesting
weirdly ah well this is interesting
here so I did change
here so I did change
this I did change this
scale I changed losses.
scale I changed losses.
entropy but this is not the loss that
entropy but this is not the loss that
gets optimized so this doesn't change
gets optimized so this doesn't change
the optimization
the optimization
right yes this is just a reporting scale
right yes this is just a reporting scale
so this did not change
anything the way we add loss
anything the way we add loss
is entropy.
is entropy.
mean so policy
mean so policy
loss which
is poo clipped
here we get entropy coefficient time
here we get entropy coefficient time
entropy loss plus value loss times the
entropy loss plus value loss times the
value function
coefficient I don't see anything that
coefficient I don't see anything that
we're doing weird with entropy it would
we're doing weird with entropy it would
be very surprising if there were cuz
be very surprising if there were cuz
this is based on a very stable uh
implementation now the portion of this
implementation now the portion of this
loss that gets to be
jittered should be this policy gradient
jittered should be this policy gradient
loss more than
anything entropy loss crashing is such a
anything entropy loss crashing is such a
weird
let me set entropy really
let me set entropy really
high let me set entropy like really
high let me set entropy like really
really
really
high and just see because it's possible
high and just see because it's possible
it's substituting this for entropy which
it's substituting this for entropy which
would be I mean weirder things have
would be I mean weirder things have
happened in RL I'd be shocked
but you know weirder things have
but you know weirder things have
happened in
RL so this is now massive
entropy okay so entropy is not
entropy okay so entropy is not
crashing because I added this massive
crashing because I added this massive
massive entropy bonus here
massive entropy bonus here
right it's not really learning
right it's not really learning
anything but entropy is not crashing
either now let's see if we set it to
either now let's see if we set it to
let's just like go down the the rungs
let's just like go down the the rungs
here and let's see like if there's a
here and let's see like if there's a
point at which it learns
oh great we've got Twitter Bots
now
uh blocked that
okay let's keep a blading
okay let's keep a blading
here 25 these are still huge values
here 25 these are still huge values
entropy coefficient is usually like
0.01 yeah yeah you can see in the um if
0.01 yeah yeah you can see in the um if
you look on the on screen chat there's
you look on the on screen chat there's
uh you can see the on screen chat right
uh you can see the on screen chat right
the stream overlay you can see next to
the stream overlay you can see next to
the chatter there's a banner that has
the chatter there's a banner that has
like the YouTube twitch or the uh
like the YouTube twitch or the uh
Twitter the X
icon okay so entropy still not
crashing let's bict this a little bit
uh entry is crashing
uh entry is crashing
here see how much it
crashes yeah that's how the stream
crashes yeah that's how the stream
is set up it's pretty
good this EnV is no I made this en in
good this EnV is no I made this en in
the last few hours
um the code is I'll paste the code to
um the code is I'll paste the code to
you if you want it it's like it's really
you if you want it it's like it's really
dead
dead
simple okay so entropy is not crashing
simple okay so entropy is not crashing
but it's still not learning
here I don't think the m is broken
here I don't think the m is broken
though
though
I really don't think the m is
broken
broken
uh well if I I don't know what you're
uh well if I I don't know what you're
going to do with this because it's not
going to do with this because it's not
bound it's not going to be bound to
bound it's not going to be bound to
stuff but you can look at it if you want
um that's the
client uh uh how do I do
this let me get let me just get the
file and I don't really want to open
file and I don't really want to open
Discord in this I don't think I can drop
Discord in this I don't think I can drop
stuff in
stuff in
chat H screw it I'll just open Discord
it's not easier to just push to dis to
it's not easier to just push to dis to
GitHub though because I have um the repo
GitHub though because I have um the repo
is not in a good State and it's the dev
is not in a good State and it's the dev
Branch I don't want to break it like I
Branch I don't want to break it like I
I've done a ton of stuff with this and I
I've done a ton of stuff with this and I
don't want to break like it'll break
don't want to break like it'll break
snake for instance the way I have the
snake for instance the way I have the
policy set up if I push this and I know
policy set up if I push this and I know
that people are actually looking at
that people are actually looking at
that let
that let
[Music]
[Music]
me uh put this into
here I'll put it in the Poke
General there there's your continuous
file okay so this actually did start to
file okay so this actually did start to
optimize a little bit
optimize a little bit
right not it didn't really do very much
right not it didn't really do very much
but it started to optimize imiz a little
bit very very
bit very very
odd I mean I could also just like try
odd I mean I could also just like try
not to think about it for now
not to think about it for now
but CU this is like one of those cursed
but CU this is like one of those cursed
things that is going to be very
things that is going to be very
difficult to figure out
let's do something more reasonable let's
let's do something more reasonable let's
do
do
16k and we'll do
16k and we'll do
4096 this should be very stable right do
4096 this should be very stable right do
entropy
o5 yeah that's a proper learn curve
o5 yeah that's a proper learn curve
right there
that is a proper learn
that is a proper learn
curve whole thing is
curve whole thing is
solved can very easily reduce this to be
solved can very easily reduce this to be
1 million steps it will still be solved
1 million steps it will still be solved
right less than a
right less than a
minute for the discret version and uh
minute for the discret version and uh
importantly the discrete version has
importantly the discrete version has
been solved with like a variety of
been solved with like a variety of
settings pretty easy to solve it there's
settings pretty easy to solve it there's
this weird thing where you have to have
this weird thing where you have to have
multiple mini batches I have no idea why
multiple mini batches I have no idea why
that is that's incredibly cursed um I'm
that is that's incredibly cursed um I'm
going to have to think about that I'm
going to have to think about that I'm
going to actually want to go test that
going to actually want to go test that
with some other environments as well to
with some other environments as well to
see if that's the case because it really
see if that's the case because it really
should not
be yeah the agent only learns uh I mean
be yeah the agent only learns uh I mean
yeah it only learns when it has some off
yeah it only learns when it has some off
policy data which is bizarre right like
policy data which is bizarre right like
on policy data should be strictly better
on policy data should be strictly better
than off policy data why would you use
than off policy data why would you use
stale data when you have fresh data
stale data when you have fresh data
right same amount of data fresh versus
right same amount of data fresh versus
stale you want fresh data but it's not
stale you want fresh data but it's not
learning very weird and it solves it
learning very weird and it solves it
perfectly when you have you know a bit
perfectly when you have you know a bit
of off policy
of off policy
data at least in the discret case now if
data at least in the discret case now if
we go to the continuous case that is a
we go to the continuous case that is a
different
different
story um
and that is the goal today is to figure
and that is the goal today is to figure
out how to get this to
out how to get this to
work maybe all the agents collecting the
work maybe all the agents collecting the
data are too
similar I didn't do any
similar I didn't do any
seating and they're all on the same
seating and they're all on the same
process so I would think that the ties
process so I would think that the ties
would be
would be
broken I did kind of consider that let
broken I did kind of consider that let
me you know what that's a good point let
me you know what that's a good point let
me just go double check on on that I
me just go double check on on that I
think we're going to be
fine that would be a really weird
fine that would be a really weird
situation technically technically
possible let's go
look nope as you can
look nope as you can
see 64x 6 so 64 environments
see 64x 6 so 64 environments
observations only have six dimensions in
observations only have six dimensions in
them you can see all the data is very
them you can see all the data is very
different this is randomly generated
different this is randomly generated
data it's as diverse as it could
data it's as diverse as it could
possibly
be and I didn't do any
be and I didn't do any
seating
seating
again so good thought but not in this
case let's take off discretization and
case let's take off discretization and
see what
happens
oo la la that
actually that looks
actually that looks
good not quite as good
good not quite as good
actually no that's nice and stable now
right actually is that
better that might be
better that might be
better episode length is really
long episode length is really
long episode length is really
long so something
long so something
weird is it the mini batch or batch that
weird is it the mini batch or batch that
the updates happen
the updates happen
from the loss is C the law stop backward
from the loss is C the law stop backward
in the model update is done per mini
in the model update is done per mini
batch up to as many mini batches fit in
batch up to as many mini batches fit in
the batch and for as many epochs as
specified we're going to rerun this with
specified we're going to rerun this with
tracking on I didn't expect that to
work so now we have what looks like very
work so now we have what looks like very
good consistent episode return out of
good consistent episode return out of
the continuous case
the continuous case
but the episode length is very weird it
but the episode length is very weird it
looks way too
long I'm interested to see what the
long I'm interested to see what the
policy looks
like so this is actually a little bit
like so this is actually a little bit
higher than um the discret
higher than um the discret
case I'm wondering if it managed to get
case I'm wondering if it managed to get
really close to
really close to
the it might have actually figured out
the it might have actually figured out
how to get really close to the Target
how to get really close to the Target
and then just hover there we'll
and then just hover there we'll
see that is actually yeah that's
see that is actually yeah that's
definitely better
definitely better
than in terms of return that is better
than in terms of return that is better
than the discreet which it should be you
than the discreet which it should be you
have more fine grain control with the
have more fine grain control with the
continuous
case since we have a a few people
case since we have a a few people
watching this um if you have not starred
watching this um if you have not starred
puffer lib on GitHub please do so it
puffer lib on GitHub please do so it
helps me out a whole
helps me out a whole
ton working on this fulltime now and
ton working on this fulltime now and
it's really the only thing I ask all
it's really the only thing I ask all
this stuff is free and open
source forgot to set it as the
Baseline we'll retrain it
Baseline we'll retrain it
would the mini batch scenario be caused
would the mini batch scenario be caused
by the difference of data between the
by the difference of data between the
mini
batches I have no
batches I have no
idea
idea
um yeah I've got I don't know why it
happens it's somehow jittering the
happens it's somehow jittering the
policy in a way that makes it learn that
policy in a way that makes it learn that
makes no sense I've never seen that ever
makes no sense I've never seen that ever
throughout all of RL I've seen like a
throughout all of RL I've seen like a
couple updates do better than one update
couple updates do better than one update
before but I've never seen it just
before but I've never seen it just
straight up refuse to learn anything
straight up refuse to learn anything
without multiple
updates RL is still surprising
updates RL is still surprising
me seven eight years later however long
me seven eight years later however long
it's been
let's see what this
is very weird
so it's getting good reward by doing
this it's getting good reward by doing
this it's getting good reward by doing
this whatever it is it thinks it's doing
this whatever it is it thinks it's doing
a better job than the original policy by
a better job than the original policy by
doing
this e
okay go mess with the
okay go mess with the
environment
environment
because it looks like it's being
weird need to change the
weird need to change the
rewards yeah but the thing
is if the if it's not reaching the goal
is if the if it's not reaching the goal
on purpose which it appears to not be
on purpose which it appears to not be
because this gets higher reward than the
because this gets higher reward than the
policy that just goes straight to the
policy that just goes straight to the
goal then I have the rewards wrong
somehow or the hyper
parameters
well man
well man
man it's so weird we're always like
man it's so weird we're always like
logging the wrong
metrics let's not let me just try one
metrics let's not let me just try one
other
thing discount factors
thing discount factors
0.95 let's give it Goldfish Memory
now it should not care about hovering
around you want the episode return to be
around you want the episode return to be
around
around
1.05
1.05
is I
think may or may not be
solved it's not associated with two
solved it's not associated with two
consecutive there's not two consecutive
consecutive there's not two consecutive
0.9 rewards it only gets
0.9 rewards it only gets
01 um at
01 um at
most for
most for
getting close to the goal and it gets
getting close to the goal and it gets
one whole point for hitting the goal but
one whole point for hitting the goal but
I think that with the discount Factor
I think that with the discount Factor
before it might have just been learning
before it might have just been learning
to jiggle around near the goal and keep
to jiggle around near the goal and keep
farming that reward for a long
farming that reward for a long
time let's
time let's
see this should demonstrate fairly
conclusively still jiggling
oh no wait it gets it goes there it
oh no wait it gets it goes there it
might just be afraid of the edge of the
might just be afraid of the edge of the
map no it's definitely
jiggling yes a few Jiggles does
okay let's just mess with the rewards a
okay let's just mess with the rewards a
little bit I think the bot's just
little bit I think the bot's just
smarter than
me that has other Pro you know what fine
me that has other Pro you know what fine
I'll do that that may have other
I'll do that that may have other
unintended consequences though because
unintended consequences though because
when you put really big numbers in the
when you put really big numbers in the
reward to destabilizes
reward to destabilizes
learning but
fine yeah I can add a penalty for
fine yeah I can add a penalty for
episode length
you don't know it's an easy solve until
you don't know it's an easy solve until
you look at the
you look at the
policy this right now is if it doesn't
policy this right now is if it doesn't
have five reward it means it's not
have five reward it means it's not
solving it
consistently though the episode look
consistently though the episode look
does the episode length does look much
better h
better h
you were right that's
funny I was concerned about putting a
funny I was concerned about putting a
reward as high as five I was going to
reward as high as five I was going to
drop down the small rewards more looks
drop down the small rewards more looks
like that
works it's kind of difficult ult to
works it's kind of difficult ult to
think about how I would add in
penalty I'd have to do like a quadratic
thing
thing
okay so let's do
okay so let's do
1.0 but let's
do we'll
do we'll
do reward minus equ ALS 0.01 * self.
do reward minus equ ALS 0.01 * self.
tick
tick
squared
right that suggested lean key will not
right that suggested lean key will not
work length penalty might work
I think it's running into the wall right
I think it's running into the wall right
now is my
guess I'm thinking I'm guessing it's
guess I'm thinking I'm guessing it's
suiciding right now to avoid get
suiciding right now to avoid get
um bigger
reward I guess that's called demonetized
reward I guess that's called demonetized
on
on
YouTube I don't think you're allowed to
YouTube I don't think you're allowed to
say that these days
yep I'm right look it's just running off
yep I'm right look it's just running off
the screen to avoid the big negative
the screen to avoid the big negative
reward RL agents are
reward RL agents are
smart the problem is that they're smart
smart the problem is that they're smart
in a way that they can't tell
you and humans are really stupid
yeah not allowed to say that on YouTube
yeah not allowed to say that on YouTube
anymore that's funny though I used to
anymore that's funny though I used to
just be what we'd call the exercise
just be what we'd call the exercise
where you run from one line to the other
where you run from one line to the other
right
uh yeah I think this is screwing up
uh yeah I think this is screwing up
learning completely not going to
lie rewards pretty much stuck
it shouldn't be that negative
though
though
wait
wait
ah did I mess something
ah did I mess something
up self.
up self.
Tick this yeah I did mess something up
Tick this yeah I did mess something up
this doesn't need to be
this doesn't need to be
squared no reason to square that it's
squared no reason to square that it's
already it's already
already it's already
increasing no it's just I might have
increasing no it's just I might have
done I think the squar is too uh the
done I think the squar is too uh the
quadratic is too
aggressive how is it even getting
-2 and that's so Jank
okay so that doesn't look is good to me
okay so that doesn't look is good to me
but we will see it's possible that the
but we will see it's possible that the
rewards are just scaled
differently oh yeah the rewards are just
differently oh yeah the rewards are just
scaled differently this is
scaled differently this is
fine it's not really any better than the
fine it's not really any better than the
other one though he likes to jiggle even
other one though he likes to jiggle even
a little bit
more jiggle
agent I think we can just get rid of
agent I think we can just get rid of
this time penalty
this time penalty
yeah to 01 that's what I was going to
yeah to 01 that's what I was going to
say and we're going to do 05 like this
say and we're going to do 05 like this
cut it a whole
bunch and then let's see if it goes back
to reasonable
to reasonable
again we're looking for very close to 10
again we're looking for very close to 10
here
I also shouldn't be waiting for this
I also shouldn't be waiting for this
thing to train for this long one I'm
thing to train for this long one I'm
running this locally on my desktop which
running this locally on my desktop which
is a slow desktop and uh two I haven't
is a slow desktop and uh two I haven't
bothered with like VEC or any form of
bothered with like VEC or any form of
optimization so this 20K is just like if
optimization so this 20K is just like if
you if you just do it in the most brain
you if you just do it in the most brain
dead POS way possible
20k that's
20k that's
fun for
good
enough not
really man why does it do
really man why does it do
this stupid jiggle
thing I have one other thing to
thing I have one other thing to
try for
one o1 is to the point where it like
one o1 is to the point where it like
almost won't even see
it interesting well I guess this makes
it interesting well I guess this makes
sense this not going to randomly solve
sense this not going to randomly solve
it you might actually be right let's
see I'd be somewhat
surprised actually looks pretty good
[Music]
[Music]
it's not really learning it quick enough
it's not really learning it quick enough
though what I'd
feared yeah
so it was learning but it wasn't
so it was learning but it wasn't
learning fast
enough yeah what did we have was it 02
enough yeah what did we have was it 02
or
or
something when we had reward
something when we had reward
five it was like this
you know let's stop being stupid here
you know let's stop being stupid here
um let's just
do score minus
one
one
info or
info or
1.0 or just
1.0 or just
one and then hold on
equal
equal
[Music]
zero and one actually
zero and one actually
no wait it should be
no wait it should be
zero yeah this will give you the
zero yeah this will give you the
completion
right it was O it was 01 are you
sure this will get us the completion
sure this will get us the completion
rate
anyways so now instead of having to
anyways so now instead of having to
stare at return and length which don't
stare at return and length which don't
really mean anything we can just see how
really mean anything we can just see how
many of the like what percentage of the
many of the like what percentage of the
time it solves the game
about 90 91
about 90 91
92 O2 is what it was I checked the video
92 O2 is what it was I checked the video
thank
you so this solves it like 90% of the
you so this solves it like 90% of the
time
cool and now we try the uh the discret
version and let's see
we try the discrete
version and see how it does by
version and see how it does by
comparison
that does look a little bit more stable
that does look a little bit more stable
doesn't
doesn't
it
95 96%
so this is you saw the continuous one
so this is you saw the continuous one
now you'll get to see the discrete
now you'll get to see the discrete
one oop
oop which looks way better right
oop which looks way better right
actually you know we have a very easy
actually you know we have a very easy
way to
way to
determine whether
determine whether
um this is a property of the algorithm
um this is a property of the algorithm
or the
or the
environment I don't know why I didn't
environment I don't know why I didn't
think think of this
earlier
so we're just going to treat the discret
so we're just going to treat the discret
as a The Continuous as a discrete
as a The Continuous as a discrete
right so this will tell us basically
right so this will tell us basically
whether it is the optimization algorithm
whether it is the optimization algorithm
being
being
Jank or the
Jank or the
um uh the optimization algorithm or just
um uh the optimization algorithm or just
the
the
environment this will tell
us now mind you this is not
us now mind you this is not
hyperparameter tuned
okay so it's definitely the
okay so it's definitely the
algorithm definitely the algorithm is
algorithm definitely the algorithm is
weird not
weird not
broken but
weird no there's no different in
weird no there's no different in
processing of continuous
processing of continuous
State
State
um it's just the way the loss is
um it's just the way the loss is
constructed and works out as
all
yeah it represents it as a mean and a
yeah it represents it as a mean and a
variance
I mean we could hyperparameter tune both
I mean we could hyperparameter tune both
right it would probably solve it in both
right it would probably solve it in both
cases let's just go run uh one more so
cases let's just go run uh one more so
we have a
Baseline and we'll make a little video
Baseline and we'll make a little video
of it or something
continuous control support coming to a
continuous control support coming to a
puffer lib near
you coming to a puffer lib near you
let's do 15 FPS on this right
and wait
and wait
100 this only needs to
100 this only needs to
be 10 seconds
right
150 let's try this
what cannot handle this data type
really
couple my bed
uh return frame not
action okay give me my Baseline gift
action okay give me my Baseline gift
please
okay and we should have a gift
okay and we should have a gift
in buffer
in buffer
tank there's our gift
sh
interesting I would challenge that but
interesting I would challenge that but
depends what Chris is
doing
e e
this is technically
this is technically
whoops technically a bad time to post
whoops technically a bad time to post
stuff but you know I got plenty of stuff
stuff but you know I got plenty of stuff
to
to
post so we'll just keep adding
post so we'll just keep adding
stuff nope wrong
stuff nope wrong
one this one
this Artic this article actually did
this Artic this article actually did
pretty
pretty
well that's
funny e
cool good Twitter
cool good Twitter
day very nice Twitter
day very nice Twitter
day that helps me out a lot with uh the
day that helps me out a lot with uh the
exposure for
exposure for
puffer puffer's gotten a decent chunk of
puffer puffer's gotten a decent chunk of
stars as well today
stars as well today
look at that back on the exponential
up this
up this
awesome all right we so we have basic
awesome all right we so we have basic
continuous control
continuous control
implemented um I'm going to have to
implemented um I'm going to have to
clean this up tomorrow it's already
clean this up tomorrow it's already
754 so I'm probably going to go to sleep
754 so I'm probably going to go to sleep
in a bit I would like to get some idea
in a bit I would like to get some idea
for projects
for projects
first would like to get some idea for
first would like to get some idea for
uh for projects whoops let me me fix
that hold
on
on
uh this darn
uh this darn
thing yeah
thing yeah
so I've had a bunch of ideas on stuff to
so I've had a bunch of ideas on stuff to
do next I want to do more Sims Sims are
do next I want to do more Sims Sims are
fun Sims are really high impact for the
fun Sims are really high impact for the
field RL really really needs more like
field RL really really needs more like
good high quality
good high quality
Sims let me go see if that guy did
Tetris did you do did he post Tetris
huh that's
huh that's
fun I'm not sure what he's
fun I'm not sure what he's
doing
doing
Tetris and drawing
canvas I mean this is like RL or
canvas I mean this is like RL or
something playing it
something playing it
right I don't know is Tetris a good end
right I don't know is Tetris a good end
for
RL I mean it's like a fine really simple
RL I mean it's like a fine really simple
test end
right not particularly
hard environment prototype done
well we'll see whether
um oh he's trying to get the the RL to
um oh he's trying to get the the RL to
match the pixels that's
funny we could probably make like a
funny we could probably make like a
Tetris end really quick I don't know if
Tetris end really quick I don't know if
that's worth the time that would still
that's worth the time that would still
probably take you know a day to
probably take you know a day to
implement plus a day to polish something
implement plus a day to polish something
like
like
that and I could get it to be reasonably
that and I could get it to be reasonably
fast yeah I mean I could get it to be
fast yeah I mean I could get it to be
like a million steps per second I'm sure
like a million steps per second I'm sure
um I don't know if that's worth it
though snake was a good one because it's
though snake was a good one because it's
single agent or
single agent or
multi-agent one of the ideas I've been
multi-agent one of the ideas I've been
toying with is
toying with is
um some sort of like really strip down
um some sort of like really strip down
basic
MOA but I don't know how much you like a
MOA but I don't know how much you like a
MOA is a really complicated game I don't
MOA is a really complicated game I don't
know how much you can strip down a MOA
know how much you can strip down a MOA
and still have it be you know
and still have it be you know
meaningful like it would still be a
meaningful like it would still be a
decent chunk of code I'd have to
decent chunk of code I'd have to
implement creep
spawning creep AI which is path thing
spawning creep AI which is path thing
continuous pathing it's kind of a lot of
work h
simple coordination
environment Tower Defense isn't really a
environment Tower Defense isn't really a
strip down mooba right CU Tower Defense
strip down mooba right CU Tower Defense
like the player is usually placing the
like the player is usually placing the
towers right and then not actually doing
towers right and then not actually doing
stuff simple coordination environment um
um
um
yeah I mean I have the pixel EnV with a
yeah I mean I have the pixel EnV with a
grid
environment agents have to take turns to
environment agents have to take turns to
clean up
clean up
pool let's I mean I have the
pool let's I mean I have the
uh let me see if I can run
it it's in Ocean so technically
grid oops tired
um this is around my bedtime so I've got
um this is around my bedtime so I've got
to go sleep in a
bit I get up at 6 to run sh and I got to
bit I get up at 6 to run sh and I got to
do
do
nine I think I'm trying to do 9 and a
nine I think I'm trying to do 9 and a
half miles
tomorrow is continuous
No it should have an is
continuous he's continuous right here oh
continuous he's continuous right here oh
cuz it's not loaded it's fine
cuz it's not loaded it's fine
so
here I have this environment right which
here I have this environment right which
is just like each agent is a pixel and
is just like each agent is a pixel and
you can specify different like different
you can specify different like different
things that they've got to do that's
things that they've got to do that's
like a decent Little Engine I could
like a decent Little Engine I could
clean that up pretty
nicely let
nicely let
[Music]
me yeah so I mean I was thinking I could
me yeah so I mean I was thinking I could
do something with that like that's kind
do something with that like that's kind
of the simplest like the simplest it
of the simplest like the simplest it
gets is a pixel en like that um but I
gets is a pixel en like that um but I
wasn't sure if I wanted to make that n
wasn't sure if I wanted to make that n
discreete continuous or like support
discreete continuous or like support
both right so you could potentially do
both right so you could potentially do
continuous and discret with
continuous and discret with
it that would be a good project having
it that would be a good project having
just like a really simple particle end
just like a really simple particle end
for testing basic stuff
for testing basic stuff
right where I can have like yep po
right where I can have like yep po
solves all these tasks
solves all these tasks
they're it'd be kind of cool to have
they're it'd be kind of cool to have
like a baseline thing that where like
like a baseline thing that where like
all the tasks are solved but like it's
all the tasks are solved but like it's
fast so the tasks are actually
fast so the tasks are actually
non-trivial like the tasks are things
non-trivial like the tasks are things
that a PhD student might have spent
that a PhD student might have spent
three months on like a couple years ago
three months on like a couple years ago
and then it's just solved in five
and then it's just solved in five
minutes because PO is fast with Puffer
minutes because PO is fast with Puffer
that kind of appeals to
me and that would be a really easy
me and that would be a really easy
setting to like start getting some ideas
setting to like start getting some ideas
of what do with continuous as
of what do with continuous as
well let me make the grid Ms larger so
well let me make the grid Ms larger so
you can actually get a proper idea for
you can actually get a proper idea for
it um one
it um one
sec one
second uh def roll
out
out
okay th000
okay th000
and
and
yeah let's just make the grid a proper
size okay so this is way better right
this is now I think what thousand agents
this is now I think what thousand agents
512 agents whatever I said it
was and you can train these guys to do
was and you can train these guys to do
some
some
stuff I can I train them in real time
stuff I can I train them in real time
let me look what's my config for
grid 125 million probably can't train
grid 125 million probably can't train
these in real
these in real
time uh I don't think I needed it to be
time uh I don't think I needed it to be
that much though did I and I just do
actually you know what I can do I know
actually you know what I can do I know
what I can do I can just patch it real
quick does this work
yeah I forget what I train these guys to
yeah I forget what I train these guys to
even do
okay that's kind of gross that that's
okay that's kind of gross that that's
how that
works you can't save policies
works you can't save policies
properly
properly
um well whatever you can train them to
um well whatever you can train them to
do a couple different things like you
do a couple different things like you
can train them to spread out you can
can train them to spread out you can
train them to like form a ring stuff
train them to like form a ring stuff
like
like
that maybe I have the vid uh do I have
that maybe I have the vid uh do I have
the videos on like my my ex
the videos on like my my ex
account let me
account let me
see I'm actually kind of trying to
see I'm actually kind of trying to
remember what I even did with this en
remember what I even did with this en
it's only been a couple weeks since I
it's only been a couple weeks since I
made
made
it I've been posting way too much
it I've been posting way too much
stuff but it's
stuff but it's
good so this is the snake en right this
good so this is the snake en right this
is playing snake there a lot of stuff on
is playing snake there a lot of stuff on
the Twitter this is snake
Dev snake Dev
did the grid before this didn't
I okay yeah
I okay yeah
here
here
so grid
so grid
EnV this is the same grid environment
EnV this is the same grid environment
you can render it with puffer fish as
you can render it with puffer fish as
well there's just a puffer fish render
well there's just a puffer fish render
mode because why
mode because why
not oh here's a good one yeah this is a
not oh here's a good one yeah this is a
cool demo yeah right here so you see
this I train them to spread apart and
this I train them to spread apart and
there's like this weird coordination
there's like this weird coordination
thing that happens where they end up
thing that happens where they end up
like spreading out into these patches in
like spreading out into these patches in
this really cool
way and then some of them end up
way and then some of them end up
floating around like
floating around like
this you can do it like this if you
this you can do it like this if you
train it more
train it more
you get like this like cool Arrow shape
pattern and
pattern and
then uh you also like you can also get
then uh you also like you can also get
like with different rewards you can get
like with different rewards you can get
them to spread out more
evenly so I could do something with this
evenly so I could do something with this
grid
grid
environment I have to think about how
environment I have to think about how
I'd want to do it
yeah flocking flocking type stuff you
yeah flocking flocking type stuff you
can totally do I don't want to do heavy
can totally do I don't want to do heavy
physic Sim I could do very light physic
physic Sim I could do very light physic
Sim with just like you know acceleration
Sim with just like you know acceleration
velocity I'd have to think about what
velocity I'd have to think about what
the observations would be though if I
the observations would be though if I
did that the observations get a little
did that the observations get a little
fancier that might be a fun thing to do
fancier that might be a fun thing to do
tomorrow though is to like figure out
tomorrow though is to like figure out
how to build a uh a decent little high
how to build a uh a decent little high
perf continuous engine based on the
perf continuous engine based on the
stuff that I've done
stuff that I've done
already do you like a continuous grid
already do you like a continuous grid
version technically if I could figure it
out continuous is really well suited to
out continuous is really well suited to
entity based networks which can be very
entity based networks which can be very
efficient reminds me of entity
gem h
well maybe I'll stream that
well maybe I'll stream that
tomorrow the uh the streams are kind of
tomorrow the uh the streams are kind of
impromptu whenever I have time or feel
impromptu whenever I have time or feel
like it but uh normally I end up running
like it but uh normally I end up running
and lifting for the first few hours of
and lifting for the first few hours of
uh my days and then I'm back I'm on like
uh my days and then I'm back I'm on like
10 11 something like that depending when
10 11 something like that depending when
I finish stuff sometimes I do some work
I finish stuff sometimes I do some work
from there first but yeah there's going
from there first but yeah there's going
to be a fair bit of streaming on on this
to be a fair bit of streaming on on this
soon um
soon um
yeah this would be a good thing to
yeah this would be a good thing to
do I might also just spend some time
do I might also just spend some time
cleaning up the new code base like the
cleaning up the new code base like the
new continuous Integrations tomorrow
new continuous Integrations tomorrow
since I have this all locally for
now I'm already thinking about like that
now I'm already thinking about like that
continuous engine and how I would do it
continuous engine and how I would do it
so like cuz the grid environments are
so like cuz the grid environments are
really really computationally efficient
really really computationally efficient
at small scale but when you want to do
at small scale but when you want to do
like bigger observation Windows they
like bigger observation Windows they
stop being so
efficient but the thing is I don't know
efficient but the thing is I don't know
how you would get
how you would get
like I don't know what an efficient
like I don't know what an efficient
algorithm would be to find all nearby
algorithm would be to find all nearby
agents because that's what you need for
agents because that's what you need for
your observations is like old nearby
your observations is like old nearby
agents and that's kind of
hard h
that's nice this was at
that's nice this was at
yesterday the growth has just been great
yesterday the growth has just been great
it's a really good motivation to keep
it's a really good motivation to keep
doing this stuff you know since
doing this stuff you know since
graduating there's no point in doing
graduating there's no point in doing
this stuff if people don't see it and
this stuff if people don't see it and
like you know want to use it so it's
like you know want to use it so it's
it's been really good to see the growth
it's been really good to see the growth
on this
and it does seem like people like the
and it does seem like people like the
articles I mean this is a really click
articles I mean this is a really click
baity title but you know
whatever okay I'm gon to call it for now
whatever okay I'm gon to call it for now
I got to get some sleep um I'm going to
I got to get some sleep um I'm going to
think about that engine a bit I'm going
think about that engine a bit I'm going
to see if I can come back back with some
to see if I can come back back with some
ideas yeah I think it would be dumb to
ideas yeah I think it would be dumb to
try to attempt something like a MOBA or
try to attempt something like a MOBA or
whatever and think I'm going to have
whatever and think I'm going to have
continuous simulation before I have like
continuous simulation before I have like
a little engine type thing that can
a little engine type thing that can
handle grid environments so I'm going to
handle grid environments so I'm going to
go think about that uh good night all
go think about that uh good night all
and we'll be back soon

Kind: captions
Language: en
okay I think this is
okay I think this is
working um I just upgraded this thing so
working um I just upgraded this thing so
I can also mirror this room to
Twitch let
Twitch let
me see how that
works make sure it's live on Twitch
hold on
autoplay yeah okay that looks like it's
autoplay yeah okay that looks like it's
working the
audio Yeah audio is good it's going to
audio Yeah audio is good it's going to
Echo if I leave that up so let me get
Echo if I leave that up so let me get
rid of the infinite
rid of the infinite
mirror
mirror
um I would like to test the chat briefly
um I would like to test the chat briefly
actually let me
actually let me
hold on let me go do that real
quick ah audio
play
play
test ah
test ah
perfect restream chat
perfect restream chat
Works only has a few lines in it but
Works only has a few lines in it but
that's
plenty Okay so
plenty Okay so
what I'm going to do at the
what I'm going to do at the
moment partially just a test stream but
moment partially just a test stream but
also going to try to continue a little
also going to try to continue a little
bit of the dev uh from earlier
today when I left this thing
off we had this super simple little
off we had this super simple little
environment and uh I had it training
environment and uh I had it training
before
before
and uh this is discreet right now or
and uh this is discreet right now or
actually this is continuous but I had it
actually this is continuous but I had it
solved continuous or I had it solved
solved continuous or I had it solved
discreet and now I want to make it solve
discreet and now I want to make it solve
continuous so I added continuous control
continuous so I added continuous control
to puffer lid technically it was only
to puffer lid technically it was only
like 20 lines of code people have been
like 20 lines of code people have been
asking me to do it forever I just didn't
asking me to do it forever I just didn't
want to bother writing the 20 lines of
want to bother writing the 20 lines of
code um now I did it and it technically
code um now I did it and it technically
works but the control uh the control
works but the control uh the control
version does not optimize anywhere near
version does not optimize anywhere near
as well so I tried a few different
as well so I tried a few different
control environments out they're all
control environments out they're all
really bad and really slow I wrote this
really bad and really slow I wrote this
simple one as a test and now we're going
simple one as a test and now we're going
to see if we can solve this really
to see if we can solve this really
really basic
really basic
environment and if anybody happens to
environment and if anybody happens to
watch this who has done continuous
watch this who has done continuous
control in RL cuz almost all the M's I
control in RL cuz almost all the M's I
work with have discreet actions and
work with have discreet actions and
there is any magic sauce I'm missing
there is any magic sauce I'm missing
please let me
please let me
know
so hello andrees Andre ah I wish I could
so hello andrees Andre ah I wish I could
pronounce your name but I have seen you
pronounce your name but I have seen you
around chat looks like it's working I
around chat looks like it's working I
got a little basic overlay for the
got a little basic overlay for the
stream it'll improve over time
stream it'll improve over time
just wanted to do something basic to
just wanted to do something basic to
start with um because I've been enjoying
start with um because I've been enjoying
the streaming so you maybe I'll keep
the streaming so you maybe I'll keep
upgrading stuff this is mainly just a
upgrading stuff this is mainly just a
way to like get people to see my work
way to like get people to see my work
get people to get excited about RL but
get people to get excited about RL but
I've been enjoying
I've been enjoying
it
um
okay
so this is what I had for the continuous
so this is what I had for the continuous
environment
and it doesn't really
and it doesn't really
seem to optimize much at all um I would
seem to optimize much at all um I would
like to see if it's optimizing
like to see if it's optimizing
whatsoever
whatsoever
versus uh not optimizing at all so what
versus uh not optimizing at all so what
we're going to do is we're going to
we're going to do is we're going to
train a baseline
train a baseline
here and then I'm going
here and then I'm going
to open up wand B and see if the
to open up wand B and see if the
training curves are just worse or if
training curves are just worse or if
they are flat
they are flat
that would be a good thing to do
oops interesting so it doesn't look like
oops interesting so it doesn't look like
the training curves are
flat this is actually
flat this is actually
optimizing it's just not optimizing you
optimizing it's just not optimizing you
know
know
remotely as well as it should
be if few things stick out to
me so the first major thing
here wait clip
Frack okay so something is wrong with
Frack okay so something is wrong with
the clip Frack this should not be above
the clip Frack this should not be above
one so we got to look at clip Frack
one so we got to look at clip Frack
that's
that's
nuts and then we got to look at the
nuts and then we got to look at the
entropy
entropy
the entropy is decreasing now I think
the entropy is decreasing now I think
correctly but it's still not where it
correctly but it's still not where it
needs to be so I think they're just some
needs to be so I think they're just some
like weird instabilities with this thing
like weird instabilities with this thing
but the training curve is actually going
but the training curve is actually going
up if we look at it it's just going up
up if we look at it it's just going up
very slowly they should be solved in
very slowly they should be solved in
like 100,000 steps very very
easily we'll let this finish out just to
easily we'll let this finish out just to
be sure and look the entropy is actually
be sure and look the entropy is actually
going down down so you know it is
going down down so you know it is
possible that the entropy scale is just
possible that the entropy scale is just
very different for control tasks but I
very different for control tasks but I
would have to think about why that is it
would have to think about why that is it
could just be a property of the way the
could just be a property of the way the
loss is
constructed and it actually doesn't you
constructed and it actually doesn't you
know it doesn't really get up to where
know it doesn't really get up to where
this should be like 0. n uh way before
this should be like 0. n uh way before
now but it is actually doing something
now but it is actually doing something
reasonable it's just not where it needs
reasonable it's just not where it needs
to be
oh actually wait no no no no this is the
oh actually wait no no no no this is the
this is the discret version isn't it
this is the discret version isn't it
yeah yeah yeah so this is
yeah yeah yeah so this is
the wait now I've confused myself which
the wait now I've confused myself which
version do I which version did I just
train okay discretize is false this is
train okay discretize is false this is
the continuous version
the continuous version
good so now if we eval the Baseline
we'll make
sure oh now it's suddenly much
sure oh now it's suddenly much
better still not good but way
better still not good but way
better so it is definitely learning
better so it is definitely learning
something you can see it's kind of
something you can see it's kind of
Meandering around the target this way
Meandering around the target this way
here it is learning not to go off the
here it is learning not to go off the
screen it gets a very large negative
screen it gets a very large negative
reward if it goes off screen
and it doesn't get to be close to the
and it doesn't get to be close to the
Target but it should be solving the
Target but it should be solving the
environment like instantly it's a very
environment like instantly it's a very
easy environment so entropy is
easy environment so entropy is
decreasing to something more reasonable
decreasing to something more reasonable
that's good um clip Frack is
increasing how are we Computing clip
increasing how are we Computing clip
Frack that it's possible for it to be
Frack that it's possible for it to be
above
above
one I think I have an
idea so clip Frack gets meaned here and
idea so clip Frack gets meaned here and
then num mini
then num mini
batches
so this should not be able to be above
so this should not be able to be above
one
right
right
ratio do
mean experience. Nom mini
mean experience. Nom mini
batches very very
batches very very
weird let's
um okay let's just run some local
train
0.9 eight mini batches
that's very very odd so that's basically
that's very very odd so that's basically
meaning that all the data is
meaning that all the data is
immediately off
policy doesn't make any
sense let's run a a second Baseline for
sense let's run a a second Baseline for
comparison that's going to be the exact
comparison that's going to be the exact
same environment but we're going to do
same environment but we're going to do
the uh the discrete version
okay we're going to do discreet
version and as you can see this one is
version and as you can see this one is
immediately going to be way
better yeah episode return immediately
better yeah episode return immediately
going right up to
going right up to
one episode length is going down to be
one episode length is going down to be
around
around
10 where's here it's still hovering at
10 where's here it's still hovering at
like
like
30 uh here we
30 uh here we
have entripy starts at 5 and goes down
have entripy starts at 5 and goes down
to something reasonable like
to something reasonable like
two oh actually the clip Frack is high
two oh actually the clip Frack is high
in this one as well
in this one as well
so this potentially means I just have
so this potentially means I just have
very bad settings
very bad settings
because this is a ridiculous value for a
because this is a ridiculous value for a
clip Frack I actually don't know how
clip Frack I actually don't know how
it's possible that
um I don't know how it's possible for it
um I don't know how it's possible for it
to be that high so we should definitely
to be that high so we should definitely
check on
check on
that um let's figure that out first cuz
that um let's figure that out first cuz
that looks like a bug to
that looks like a bug to
me opportunity to chase down a more
me opportunity to chase down a more
General puffer lib most likely just an
General puffer lib most likely just an
error in the way I'm scaling it
okay so experience. Nom mini
batches right
here
here
and uh so right here we're adding all of
and uh so right here we're adding all of
these
things uh this is this is quite odd so
things uh this is this is quite odd so
if you look at this we are adding
if you look at this we are adding
together the
loss and we're dividing by the number of
loss and we're dividing by the number of
mini batches
mini batches
but we are not dividing by the number of
but we are not dividing by the number of
update
update
epochs
epochs
so that's not
so that's not
good so we should probably
do uh let's see
do uh let's see
see let's do a total mini
see let's do a total mini
batches times config do update
batches times config do update
epox num mini so we do total mini
epox num mini so we do total mini
batches
so this is actually a uh no
so this is actually a uh no
error this is not an error in puffer
error this is not an error in puffer
it's just a quirk with scaling it
it's just a quirk with scaling it
doesn't harm anything but um you know
doesn't harm anything but um you know
we'll we'll fix it up
we'll we'll fix it up
just for the sake of it so now it should
just for the sake of it so now it should
be 4X lower which would still
be 4X lower which would still
be a ridiculous clip Frack here of
be a ridiculous clip Frack here of
course we have this clip Frack
course we have this clip Frack
decreasing over time but that is because
decreasing over time but that is because
of the anal
of the anal
so let us
so let us
disable this anal learning rate
oops we're going to disable learning
oops we're going to disable learning
rate and
rate and
kneeling because it makes things
kneeling because it makes things
annoying and
annoying and
inconsistent um
entropy very
low let's now look at the the batches
maybe ah these batch sizes are this is
why so we have all these environments
why so we have all these environments
but we have not updated the the batch
but we have not updated the the batch
sizes
sizes
accordingly so let's just just think
of 64 environments
of 64 environments
times 16 steps is
times 16 steps is
1024 uh I think that we should probably
1024 uh I think that we should probably
do
do
4096 and 1024
4096 and 1024
maybe or maybe we just do 20 48 and 20
48 there's no reason to have multiple
48 there's no reason to have multiple
mini batches after all
mini batches after all
right or other way around actually
right or other way around actually
update Epoch should be one and we could
update Epoch should be one and we could
have multiple mini batches if we
have multiple mini batches if we
wanted this should be substantially more
wanted this should be substantially more
stable if slower to train
stable if slower to train
potentially let's see what happens when
potentially let's see what happens when
I do
this okay so the SPs immediately is
this okay so the SPs immediately is
going to shoot
up and it is is not going to optimize
up and it is is not going to optimize
which is
interesting it should be substantially
interesting it should be substantially
easier to optimize now so the fact that
easier to optimize now so the fact that
it is not is
concerning yes
entropy immediately
entropy immediately
crashes clip
crashes clip
Frack let me
Frack let me
see which is very odd
indeed that this would make it crash so
indeed that this would make it crash so
badly I see entropy is immediately
badly I see entropy is immediately
collapsing
collapsing
right yes entropy immediately collapses
so if entropy is immediately collapsing
so if entropy is immediately collapsing
that
that
means potentially
means potentially
oops that the uh the policy is
oops that the uh the policy is
overfitting very
overfitting very
early into
this so let's give it like a bigger
this so let's give it like a bigger
entropy coefficient and see if that
entropy coefficient and see if that
helps whatsoever
yes that does immediately solve the
yes that does immediately solve the
environment though it does not appear
environment though it does not appear
stable in the
solution are we running the continuous
solution are we running the continuous
or the discrete version I
forget the discrete version
okay so it literally it's just a
okay so it literally it's just a
hyperparameter
thing and I didn't bother running a
thing and I didn't bother running a
sweep this is just me messing around for
sweep this is just me messing around for
a few minutes so very easily I'm sure we
a few minutes so very easily I'm sure we
can find stable settings with a
sweep let's make sure that this policy
sweep let's make sure that this policy
actually looks you know reasonable it
actually looks you know reasonable it
doesn't have to be perfect we can always
doesn't have to be perfect we can always
run a
sweep I mean that looks pretty good to
sweep I mean that looks pretty good to
me it doesn't always get at 100% like
me it doesn't always get at 100% like
there it'll overshoot but that's pretty
there it'll overshoot but that's pretty
reasonable
reasonable
right
right
yeah so now we're going to do the exact
yeah so now we're going to do the exact
same thing with the continuous
version and we're going to see if it
version and we're going to see if it
learns anything
interesting it
fails
fails
actions why would it fail oh CU I ran
actions why would it fail oh CU I ran
the eval with the wrong end that's
fine let's see
training
training
ooh well that's interesting
this does not appear as quick to
this does not appear as quick to
optimize does appear more
optimize does appear more
unstable we have a clip Frack of 7 which
unstable we have a clip Frack of 7 which
is incredibly
High we're getting all sorts of
High we're getting all sorts of
different values some of which are
different values some of which are
perfectly solving the environment and
perfectly solving the environment and
some of which are not though it does
some of which are not though it does
look to be
stabilizing and the clip fr is still
stabilizing and the clip fr is still
very high very
very high very
odd let's see what this looks
like it's so close
not
not
quite process is amazing to watch thank
quite process is amazing to watch thank
you for going step by
you for going step by
step I'm going to be able to some I'm
step I'm going to be able to some I'm
going to set some some to not okay well
going to set some some to not okay well
thank you for that I got to make the
thank you for that I got to make the
chat font a little larger I think so I
chat font a little larger I think so I
can see it more easily uh thank you
can see it more easily uh thank you
though yeah I I'm having fun doing this
though yeah I I'm having fun doing this
it really doesn't distract me very much
it really doesn't distract me very much
I actually s get more work done on this
I actually s get more work done on this
stream because like I don't know I don't
stream because like I don't know I don't
I get distracted a lot in my own
I get distracted a lot in my own
thoughts when I'm just working usually I
thoughts when I'm just working usually I
kind of just zone out a lot so it's
kind of just zone out a lot so it's
actually been kind of helpful for me as
actually been kind of helpful for me as
well and it's fun and people get to see
well and it's fun and people get to see
this type of work um I actually don't
this type of work um I actually don't
really enjoy this type of debugging of
really enjoy this type of debugging of
environment so much like the
environment so much like the
experimental side I really enjoy
experimental side I really enjoy
building The highper Sims way more uh
building The highper Sims way more uh
there's going to be a lot of that coming
there's going to be a lot of that coming
up now the thing I'd like to know the
up now the thing I'd like to know the
thing I would like to really understand
thing I would like to really understand
right now though is why it seems like
right now though is why it seems like
it's harder to do continuous M's versus
it's harder to do continuous M's versus
discreet Ms there's really no reason
discreet Ms there's really no reason
right there could be a math reason to be
right there could be a math reason to be
fair there could be a math reason why
fair there could be a math reason why
the continuous objective is harder to
the continuous objective is harder to
optimize but if the objective is good
optimize but if the objective is good
then technically the continuous n gives
then technically the continuous n gives
you strictly more control because you
you strictly more control because you
can learn to like accelerate a little
can learn to like accelerate a little
bit or accelerate a lot whereas the
bit or accelerate a lot whereas the
Creet version only lets you uh
Creet version only lets you uh
accelerate at One
Rate okay but
Rate okay but
like is this the one right
like is this the one right
here yeah so this is the n it actually
here yeah so this is the n it actually
does look like it's very very
close oh interesting this is very weird
close oh interesting this is very weird
so look at this so
this was the one that solved it right
this was the one that solved it right
with one point around one reward right
with one point around one reward right
and the episode length is all the way
and the episode length is all the way
down
down
here at like
here at like
five okay and
five okay and
then here if it's just shy it it looks
then here if it's just shy it it looks
like it
like it
rapidly as soon as you're not fully
rapidly as soon as you're not fully
solving it the episode length is way
solving it the episode length is way
longer so
longer so
even though it looks like it's close
even though it looks like it's close
it's really nowhere
it's really nowhere
near if that makes
near if that makes
sense clip Frack is very very suspicious
sense clip Frack is very very suspicious
here clip Frack is very
here clip Frack is very
suspicious we should rerun the baselines
suspicious we should rerun the baselines
now that we have a kneeling off we
now that we have a kneeling off we
should rerun them both they're very
should rerun them both they're very
quick so we're going to do discretize
true I'm going to run the 500K
you can see the episode length rapidly
you can see the episode length rapidly
decreasing as well as the return
decreasing as well as the return
increasing should be stabilizing
nicely ASAP
nicely ASAP
ASAP hello welcome
ASAP hello welcome
cool to see we have a couple people on
cool to see we have a couple people on
YouTube oh that's bet hi
YouTube oh that's bet hi
bet I am currently adding continuous
bet I am currently adding continuous
control to
control to
Puffer that is what I'm
Puffer that is what I'm
doing B is one of our contributors on
doing B is one of our contributors on
the Pokemon project he has done an
the Pokemon project he has done an
absolutely excellent job I'm frankly
absolutely excellent job I'm frankly
amazed at the amount of progress given
amazed at the amount of progress given
the lack of Prior
the lack of Prior
experience took me a hell of a lot
experience took me a hell of a lot
longer to get useful at stuff
longer to get useful at stuff
and linky is here too
and linky is here too
welcome linky is the other amazing
welcome linky is the other amazing
contributor on the Pokemon project
contributor on the Pokemon project
hopefully we'll have results in that
soon I figured you were both in just
soon I figured you were both in just
Discord hanging out and just both click
Discord hanging out and just both click
the stream you both found it
the stream you both found it
independently that's
funny I just set this up so that I have
funny I just set this up so that I have
it streaming on X YouTube and T twitch
it streaming on X YouTube and T twitch
at the same
time okay so this is the environment the
time okay so this is the environment the
discretized version as you can see it's
discretized version as you can see it's
very nice and consistent not perfect but
very nice and consistent not perfect but
pretty darn good
pretty darn good
right very basic
environment very very basic
environment now if we turn discretize to
environment now if we turn discretize to
be false
be false
and we're going to rerun
training let's actually just grab hold
training let's actually just grab hold
on visualize
on visualize
none and then we'll do this one and this
none and then we'll do this one and this
one yeah
where did my graphs
go I should have both of them open where
go I should have both of them open where
why do I not have both graphs
can you visualize the actions being
can you visualize the actions being
taken at all to see if it's learning
taken at all to see if it's learning
fine control uh the thing is it's not
fine control uh the thing is it's not
really learning control at all properly
really learning control at all properly
yet the the discretized version works
yet the the discretized version works
perfectly the control version uh it
perfectly the control version uh it
doesn't quite solve the task it's
doesn't quite solve the task it's
learning
learning
something but this is literally uh like
something but this is literally uh like
hour two or three maybe invested into
hour two or three maybe invested into
continuous control and Puffer so this is
continuous control and Puffer so this is
still very much new and I don't know if
still very much new and I don't know if
it is bugged or if it is just bad hyper
it is bugged or if it is just bad hyper
prams or what is going on yet that is
prams or what is going on yet that is
what the point of this exercise is um
what the point of this exercise is um
I'd also like to know where the heck my
I'd also like to know where the heck my
other Baseline ran my other Baseline run
other Baseline ran my other Baseline run
went it's very
went it's very
weird
that the other one just
that the other one just
disappeared so I might have to go run
disappeared so I might have to go run
another one of
another one of
those this is let's see I can tell just
those this is let's see I can tell just
by looking at it I'm
sure yeah this is the continuous control
sure yeah this is the continuous control
one for
one for
sure Define continuous control actions
sure Define continuous control actions
are not discrete they're continuous so
are not discrete they're continuous so
actions are sampled from a distribution
actions are sampled from a distribution
rather than being like up down left
rather than being like up down left
right uh the discrete version of this
right uh the discrete version of this
environment is you can press up or down
environment is you can press up or down
and that will set your acceleration to
and that will set your acceleration to
one or negative one uh and then the
one or negative one uh and then the
continuous control version you just give
continuous control version you just give
it a number between negative 1 and one
it a number between negative 1 and one
so it's not something a human could
so it's not something a human could
input with a keyboard it would be more
input with a keyboard it would be more
like a
like a
joystick that's actually would have been
joystick that's actually would have been
the much simpler explanation joystick
the much simpler explanation joystick
versus
keyboard should have gone with that from
keyboard should have gone with that from
the
the
start uh do we have clip Frack being too
start uh do we have clip Frack being too
high
high
still that is what I would like to
know yes clip Frack is incredibly high
know yes clip Frack is incredibly high
this is
bad so I don't know where the other
bad so I don't know where the other
graph went so I'm just going to rerun
it and I'm going to bet that it doesn't
it and I'm going to bet that it doesn't
have as that high of a a clip
have as that high of a a clip
frack and we're going to have to figure
frack and we're going to have to figure
out
out
why the clip Frack is so bad
sh
okay so this is the discrete version in
okay so this is the discrete version in
Orange continuous version is in this
Orange continuous version is in this
pink color fuchsia not a
pink color fuchsia not a
salmon
salmon
um interestingly the discret version is
um interestingly the discret version is
substantially
substantially
faster that's interesting to see I guess
faster that's interesting to see I guess
there's one extra layer in the
there's one extra layer in the
network uh the entropy
network uh the entropy
curves decreases for the discreet
curves decreases for the discreet
one and is stable or increases a bit
one and is stable or increases a bit
with the continuous
with the continuous
one the clip Frack for the discreet is
one the clip Frack for the discreet is
high but
high but
stable and is out of
stable and is out of
control this means that 80% of the data
control this means that 80% of the data
is out of bounds hold on how is that
is out of bounds hold on how is that
even possible didn't I just set the mini
even possible didn't I just set the mini
batches
hold on I have mini batch set
hold on I have mini batch set
to
oh let's set update EPO equal to
oh let's set update EPO equal to
one let me see what happens if I do
one let me see what happens if I do
fully on policy
learning so if I do fully on policy
learning I don't know why continuous
learning I don't know why continuous
should be slower it's the same problem
if I set update Epoch to one this
if I set update Epoch to one this
doesn't work hold on continuous or
doesn't work hold on continuous or
discreet okay dis discreet doesn't work
discreet okay dis discreet doesn't work
with one update Epoch which is
with one update Epoch which is
insane that shouldn't be
insane that shouldn't be
possible the clip for should be zero
possible the clip for should be zero
because that's because math
um so somehow this is only
um so somehow this is only
learning via off policy
updates that doesn't make any sense
updates that doesn't make any sense
whatsoever
so entropy crashes to
so entropy crashes to
zero though not
immediately
immediately
policy why like the metrics look a
policy why like the metrics look a
little spiky but they don't look crazy
bad well there was like a little bit of
bad well there was like a little bit of
learning at the start here and then it
learning at the start here and then it
crashed
right kind of
H entropy
H entropy
loss this is with a substantial entropy
loss this is with a substantial entropy
bonus as
bonus as
well that this is
well that this is
crashing it's very
weird do I want to just run a hyper pram
weird do I want to just run a hyper pram
sweep on
sweep on
this or do I want to just think about
it cannot really think of any
it cannot really think of any
reason
reason
why dropping the update Epoch to
why dropping the update Epoch to
one would screw it
up very
up very
odd what if I drop the mini batch
odd what if I drop the mini batch
size at the same time
suddenly it works
again but if I use 20 48 mini
bash oh wait it
bash oh wait it
does it started to optimize there there
does it started to optimize there there
for a second I saw it and then it
for a second I saw it and then it
crashed
back I'm not going to put this down to
back I'm not going to put this down to
anything fundamental when uh the
anything fundamental when uh the
explanation of General learning
explanation of General learning
instability will suffice I'm just going
instability will suffice I'm just going
to mess with it for a
moment hello
moment hello
Nicholas welcome
okay so entropy low isn't helping what
okay so entropy low isn't helping what
about entropy really high that do
about entropy really high that do
anything this is like higher than you
anything this is like higher than you
would ever set
entropy okay good I actually didn't want
entropy okay good I actually didn't want
that to
work so we'll put it back to what it was
work so we'll put it back to what it was
before it needs like some Jitter or
before it needs like some Jitter or
something to train which is really
something to train which is really
weird
weird
um what if I just massively increase the
um what if I just massively increase the
batch size right like what if I just do
batch size right like what if I just do
8192 so now it's going to end up with
8192 so now it's going to end up with
four mini batches again they're just
four mini batches again they're just
going to be
bigger yep that immediately
bigger yep that immediately
trains that actually immediately trains
trains that actually immediately trains
very very stable which is why what it
very very stable which is why what it
should so that's like RL being
should so that's like RL being
Saye and I bet it's not going to work if
Saye and I bet it's not going to work if
I do
I do
this I hope I'm
wrong
wrong
bizarre it like needs off policy updates
bizarre it like needs off policy updates
to learn
huh
why okay wait what if I do update Epoch
why okay wait what if I do update Epoch
to four now so I put multi it's off
to four now so I put multi it's off
policy but it's sort of a different way
policy but it's sort of a different way
of being off
policy yeah it
learns what on
learns what on
Earth that defies
reason mini batch and batch size
reason mini batch and batch size
matter increase episode
length um well episode length is defined
length um well episode length is defined
by the environment that's defined by
by the environment that's defined by
like when it hits the
like when it hits the
target um the thing that doesn't make
target um the thing that doesn't make
sense here right is that like when you
sense here right is that like when you
set mini batch size smaller than batch
set mini batch size smaller than batch
size your learning goes off policy you
size your learning goes off policy you
start updating on stale
start updating on stale
data so I saw that there was a lot of
data so I saw that there was a lot of
instability with that so I said oh okay
instability with that so I said oh okay
let's just set it to be
let's just set it to be
synchronous let's set the mini batch
synchronous let's set the mini batch
size equal to the batch size but it
size equal to the batch size but it
seems like that prevents it from
seems like that prevents it from
learning so there's like some weird
learning so there's like some weird
Jitter effect happening where it like
Jitter effect happening where it like
needs some Jitter to learn or
needs some Jitter to learn or
something let's go like really big just
something let's go like really big just
for the sake of it like 32
yeah that's what I'm doing
yeah that's what I'm doing
now I might have to run this for longer
now I might have to run this for longer
though
because no learning
progress
progress
64k well I'm going to have to start
64k well I'm going to have to start
increasing this massively if I do that
increasing this massively if I do that
right because like the sample efficiency
right because like the sample efficiency
should go down 64 what is it
should go down 64 what is it
648 no 6 oh
648 no 6 oh
65 five
doesn't look like it's doing
doesn't look like it's doing
anything and you can see right
anything and you can see right
here the entropy is
crashing so when
crashing so when
you when you give it a single mini
you when you give it a single mini
batch entropy crashes
this a bug with this should not
be well yeah I can change update Epoch
be well yeah I can change update Epoch
and make it learn but like why this is a
and make it learn but like why this is a
nonsensical like this is a
nonsensical like this is a
nonsensical thing that we're observing
nonsensical thing that we're observing
here this does not make
here this does not make
sense like you can't just throw your
sense like you can't just throw your
hands up when you see stuff like this
hands up when you see stuff like this
like there's got to be a reason for it
like there's got to be a reason for it
and it can potentially reveal like bugs
and it can potentially reveal like bugs
and and other implementation quirks that
and and other implementation quirks that
are very very difficult to find without
are very very difficult to find without
stuff like this
stuff like this
happening um so you know I'm looking for
happening um so you know I'm looking for
if there's some I just noticed that we
if there's some I just noticed that we
were scaling entropy
weirdly ah well this is interesting
weirdly ah well this is interesting
here so I did change
here so I did change
this I did change this
scale I changed losses.
scale I changed losses.
entropy but this is not the loss that
entropy but this is not the loss that
gets optimized so this doesn't change
gets optimized so this doesn't change
the optimization
the optimization
right yes this is just a reporting scale
right yes this is just a reporting scale
so this did not change
anything the way we add loss
anything the way we add loss
is entropy.
is entropy.
mean so policy
mean so policy
loss which
is poo clipped
here we get entropy coefficient time
here we get entropy coefficient time
entropy loss plus value loss times the
entropy loss plus value loss times the
value function
coefficient I don't see anything that
coefficient I don't see anything that
we're doing weird with entropy it would
we're doing weird with entropy it would
be very surprising if there were cuz
be very surprising if there were cuz
this is based on a very stable uh
implementation now the portion of this
implementation now the portion of this
loss that gets to be
jittered should be this policy gradient
jittered should be this policy gradient
loss more than
anything entropy loss crashing is such a
anything entropy loss crashing is such a
weird
let me set entropy really
let me set entropy really
high let me set entropy like really
high let me set entropy like really
really
really
high and just see because it's possible
high and just see because it's possible
it's substituting this for entropy which
it's substituting this for entropy which
would be I mean weirder things have
would be I mean weirder things have
happened in RL I'd be shocked
but you know weirder things have
but you know weirder things have
happened in
RL so this is now massive
entropy okay so entropy is not
entropy okay so entropy is not
crashing because I added this massive
crashing because I added this massive
massive entropy bonus here
massive entropy bonus here
right it's not really learning
right it's not really learning
anything but entropy is not crashing
either now let's see if we set it to
either now let's see if we set it to
let's just like go down the the rungs
let's just like go down the the rungs
here and let's see like if there's a
here and let's see like if there's a
point at which it learns
oh great we've got Twitter Bots
now
uh blocked that
okay let's keep a blading
okay let's keep a blading
here 25 these are still huge values
here 25 these are still huge values
entropy coefficient is usually like
0.01 yeah yeah you can see in the um if
0.01 yeah yeah you can see in the um if
you look on the on screen chat there's
you look on the on screen chat there's
uh you can see the on screen chat right
uh you can see the on screen chat right
the stream overlay you can see next to
the stream overlay you can see next to
the chatter there's a banner that has
the chatter there's a banner that has
like the YouTube twitch or the uh
like the YouTube twitch or the uh
Twitter the X
icon okay so entropy still not
crashing let's bict this a little bit
uh entry is crashing
uh entry is crashing
here see how much it
crashes yeah that's how the stream
crashes yeah that's how the stream
is set up it's pretty
good this EnV is no I made this en in
good this EnV is no I made this en in
the last few hours
um the code is I'll paste the code to
um the code is I'll paste the code to
you if you want it it's like it's really
you if you want it it's like it's really
dead
dead
simple okay so entropy is not crashing
simple okay so entropy is not crashing
but it's still not learning
here I don't think the m is broken
here I don't think the m is broken
though
though
I really don't think the m is
broken
broken
uh well if I I don't know what you're
uh well if I I don't know what you're
going to do with this because it's not
going to do with this because it's not
bound it's not going to be bound to
bound it's not going to be bound to
stuff but you can look at it if you want
um that's the
client uh uh how do I do
this let me get let me just get the
file and I don't really want to open
file and I don't really want to open
Discord in this I don't think I can drop
Discord in this I don't think I can drop
stuff in
stuff in
chat H screw it I'll just open Discord
it's not easier to just push to dis to
it's not easier to just push to dis to
GitHub though because I have um the repo
GitHub though because I have um the repo
is not in a good State and it's the dev
is not in a good State and it's the dev
Branch I don't want to break it like I
Branch I don't want to break it like I
I've done a ton of stuff with this and I
I've done a ton of stuff with this and I
don't want to break like it'll break
don't want to break like it'll break
snake for instance the way I have the
snake for instance the way I have the
policy set up if I push this and I know
policy set up if I push this and I know
that people are actually looking at
that people are actually looking at
that let
that let
[Music]
[Music]
me uh put this into
here I'll put it in the Poke
General there there's your continuous
file okay so this actually did start to
file okay so this actually did start to
optimize a little bit
optimize a little bit
right not it didn't really do very much
right not it didn't really do very much
but it started to optimize imiz a little
bit very very
bit very very
odd I mean I could also just like try
odd I mean I could also just like try
not to think about it for now
not to think about it for now
but CU this is like one of those cursed
but CU this is like one of those cursed
things that is going to be very
things that is going to be very
difficult to figure out
let's do something more reasonable let's
let's do something more reasonable let's
do
do
16k and we'll do
16k and we'll do
4096 this should be very stable right do
4096 this should be very stable right do
entropy
o5 yeah that's a proper learn curve
o5 yeah that's a proper learn curve
right there
that is a proper learn
that is a proper learn
curve whole thing is
curve whole thing is
solved can very easily reduce this to be
solved can very easily reduce this to be
1 million steps it will still be solved
1 million steps it will still be solved
right less than a
right less than a
minute for the discret version and uh
minute for the discret version and uh
importantly the discrete version has
importantly the discrete version has
been solved with like a variety of
been solved with like a variety of
settings pretty easy to solve it there's
settings pretty easy to solve it there's
this weird thing where you have to have
this weird thing where you have to have
multiple mini batches I have no idea why
multiple mini batches I have no idea why
that is that's incredibly cursed um I'm
that is that's incredibly cursed um I'm
going to have to think about that I'm
going to have to think about that I'm
going to actually want to go test that
going to actually want to go test that
with some other environments as well to
with some other environments as well to
see if that's the case because it really
see if that's the case because it really
should not
be yeah the agent only learns uh I mean
be yeah the agent only learns uh I mean
yeah it only learns when it has some off
yeah it only learns when it has some off
policy data which is bizarre right like
policy data which is bizarre right like
on policy data should be strictly better
on policy data should be strictly better
than off policy data why would you use
than off policy data why would you use
stale data when you have fresh data
stale data when you have fresh data
right same amount of data fresh versus
right same amount of data fresh versus
stale you want fresh data but it's not
stale you want fresh data but it's not
learning very weird and it solves it
learning very weird and it solves it
perfectly when you have you know a bit
perfectly when you have you know a bit
of off policy
of off policy
data at least in the discret case now if
data at least in the discret case now if
we go to the continuous case that is a
we go to the continuous case that is a
different
different
story um
and that is the goal today is to figure
and that is the goal today is to figure
out how to get this to
out how to get this to
work maybe all the agents collecting the
work maybe all the agents collecting the
data are too
similar I didn't do any
similar I didn't do any
seating and they're all on the same
seating and they're all on the same
process so I would think that the ties
process so I would think that the ties
would be
would be
broken I did kind of consider that let
broken I did kind of consider that let
me you know what that's a good point let
me you know what that's a good point let
me just go double check on on that I
me just go double check on on that I
think we're going to be
fine that would be a really weird
fine that would be a really weird
situation technically technically
possible let's go
look nope as you can
look nope as you can
see 64x 6 so 64 environments
see 64x 6 so 64 environments
observations only have six dimensions in
observations only have six dimensions in
them you can see all the data is very
them you can see all the data is very
different this is randomly generated
different this is randomly generated
data it's as diverse as it could
data it's as diverse as it could
possibly
be and I didn't do any
be and I didn't do any
seating
seating
again so good thought but not in this
case let's take off discretization and
case let's take off discretization and
see what
happens
oo la la that
actually that looks
actually that looks
good not quite as good
good not quite as good
actually no that's nice and stable now
right actually is that
better that might be
better that might be
better episode length is really
long episode length is really
long episode length is really
long so something
long so something
weird is it the mini batch or batch that
weird is it the mini batch or batch that
the updates happen
the updates happen
from the loss is C the law stop backward
from the loss is C the law stop backward
in the model update is done per mini
in the model update is done per mini
batch up to as many mini batches fit in
batch up to as many mini batches fit in
the batch and for as many epochs as
specified we're going to rerun this with
specified we're going to rerun this with
tracking on I didn't expect that to
work so now we have what looks like very
work so now we have what looks like very
good consistent episode return out of
good consistent episode return out of
the continuous case
the continuous case
but the episode length is very weird it
but the episode length is very weird it
looks way too
long I'm interested to see what the
long I'm interested to see what the
policy looks
like so this is actually a little bit
like so this is actually a little bit
higher than um the discret
higher than um the discret
case I'm wondering if it managed to get
case I'm wondering if it managed to get
really close to
really close to
the it might have actually figured out
the it might have actually figured out
how to get really close to the Target
how to get really close to the Target
and then just hover there we'll
and then just hover there we'll
see that is actually yeah that's
see that is actually yeah that's
definitely better
definitely better
than in terms of return that is better
than in terms of return that is better
than the discreet which it should be you
than the discreet which it should be you
have more fine grain control with the
have more fine grain control with the
continuous
case since we have a a few people
case since we have a a few people
watching this um if you have not starred
watching this um if you have not starred
puffer lib on GitHub please do so it
puffer lib on GitHub please do so it
helps me out a whole
helps me out a whole
ton working on this fulltime now and
ton working on this fulltime now and
it's really the only thing I ask all
it's really the only thing I ask all
this stuff is free and open
source forgot to set it as the
Baseline we'll retrain it
Baseline we'll retrain it
would the mini batch scenario be caused
would the mini batch scenario be caused
by the difference of data between the
by the difference of data between the
mini
batches I have no
batches I have no
idea
idea
um yeah I've got I don't know why it
happens it's somehow jittering the
happens it's somehow jittering the
policy in a way that makes it learn that
policy in a way that makes it learn that
makes no sense I've never seen that ever
makes no sense I've never seen that ever
throughout all of RL I've seen like a
throughout all of RL I've seen like a
couple updates do better than one update
couple updates do better than one update
before but I've never seen it just
before but I've never seen it just
straight up refuse to learn anything
straight up refuse to learn anything
without multiple
updates RL is still surprising
updates RL is still surprising
me seven eight years later however long
me seven eight years later however long
it's been
let's see what this
is very weird
so it's getting good reward by doing
this it's getting good reward by doing
this it's getting good reward by doing
this whatever it is it thinks it's doing
this whatever it is it thinks it's doing
a better job than the original policy by
a better job than the original policy by
doing
this e
okay go mess with the
okay go mess with the
environment
environment
because it looks like it's being
weird need to change the
weird need to change the
rewards yeah but the thing
is if the if it's not reaching the goal
is if the if it's not reaching the goal
on purpose which it appears to not be
on purpose which it appears to not be
because this gets higher reward than the
because this gets higher reward than the
policy that just goes straight to the
policy that just goes straight to the
goal then I have the rewards wrong
somehow or the hyper
parameters
well man
well man
man it's so weird we're always like
man it's so weird we're always like
logging the wrong
metrics let's not let me just try one
metrics let's not let me just try one
other
thing discount factors
thing discount factors
0.95 let's give it Goldfish Memory
now it should not care about hovering
around you want the episode return to be
around you want the episode return to be
around
around
1.05
1.05
is I
think may or may not be
solved it's not associated with two
solved it's not associated with two
consecutive there's not two consecutive
consecutive there's not two consecutive
0.9 rewards it only gets
0.9 rewards it only gets
01 um at
01 um at
most for
most for
getting close to the goal and it gets
getting close to the goal and it gets
one whole point for hitting the goal but
one whole point for hitting the goal but
I think that with the discount Factor
I think that with the discount Factor
before it might have just been learning
before it might have just been learning
to jiggle around near the goal and keep
to jiggle around near the goal and keep
farming that reward for a long
farming that reward for a long
time let's
time let's
see this should demonstrate fairly
conclusively still jiggling
oh no wait it gets it goes there it
oh no wait it gets it goes there it
might just be afraid of the edge of the
might just be afraid of the edge of the
map no it's definitely
jiggling yes a few Jiggles does
okay let's just mess with the rewards a
okay let's just mess with the rewards a
little bit I think the bot's just
little bit I think the bot's just
smarter than
me that has other Pro you know what fine
me that has other Pro you know what fine
I'll do that that may have other
I'll do that that may have other
unintended consequences though because
unintended consequences though because
when you put really big numbers in the
when you put really big numbers in the
reward to destabilizes
reward to destabilizes
learning but
fine yeah I can add a penalty for
fine yeah I can add a penalty for
episode length
you don't know it's an easy solve until
you don't know it's an easy solve until
you look at the
you look at the
policy this right now is if it doesn't
policy this right now is if it doesn't
have five reward it means it's not
have five reward it means it's not
solving it
consistently though the episode look
consistently though the episode look
does the episode length does look much
better h
better h
you were right that's
funny I was concerned about putting a
funny I was concerned about putting a
reward as high as five I was going to
reward as high as five I was going to
drop down the small rewards more looks
drop down the small rewards more looks
like that
works it's kind of difficult ult to
works it's kind of difficult ult to
think about how I would add in
penalty I'd have to do like a quadratic
thing
thing
okay so let's do
okay so let's do
1.0 but let's
do we'll
do we'll
do reward minus equ ALS 0.01 * self.
do reward minus equ ALS 0.01 * self.
tick
tick
squared
right that suggested lean key will not
right that suggested lean key will not
work length penalty might work
I think it's running into the wall right
I think it's running into the wall right
now is my
guess I'm thinking I'm guessing it's
guess I'm thinking I'm guessing it's
suiciding right now to avoid get
suiciding right now to avoid get
um bigger
reward I guess that's called demonetized
reward I guess that's called demonetized
on
on
YouTube I don't think you're allowed to
YouTube I don't think you're allowed to
say that these days
yep I'm right look it's just running off
yep I'm right look it's just running off
the screen to avoid the big negative
the screen to avoid the big negative
reward RL agents are
reward RL agents are
smart the problem is that they're smart
smart the problem is that they're smart
in a way that they can't tell
you and humans are really stupid
yeah not allowed to say that on YouTube
yeah not allowed to say that on YouTube
anymore that's funny though I used to
anymore that's funny though I used to
just be what we'd call the exercise
just be what we'd call the exercise
where you run from one line to the other
where you run from one line to the other
right
uh yeah I think this is screwing up
uh yeah I think this is screwing up
learning completely not going to
lie rewards pretty much stuck
it shouldn't be that negative
though
though
wait
wait
ah did I mess something
ah did I mess something
up self.
up self.
Tick this yeah I did mess something up
Tick this yeah I did mess something up
this doesn't need to be
this doesn't need to be
squared no reason to square that it's
squared no reason to square that it's
already it's already
already it's already
increasing no it's just I might have
increasing no it's just I might have
done I think the squar is too uh the
done I think the squar is too uh the
quadratic is too
aggressive how is it even getting
-2 and that's so Jank
okay so that doesn't look is good to me
okay so that doesn't look is good to me
but we will see it's possible that the
but we will see it's possible that the
rewards are just scaled
differently oh yeah the rewards are just
differently oh yeah the rewards are just
scaled differently this is
scaled differently this is
fine it's not really any better than the
fine it's not really any better than the
other one though he likes to jiggle even
other one though he likes to jiggle even
a little bit
more jiggle
agent I think we can just get rid of
agent I think we can just get rid of
this time penalty
this time penalty
yeah to 01 that's what I was going to
yeah to 01 that's what I was going to
say and we're going to do 05 like this
say and we're going to do 05 like this
cut it a whole
bunch and then let's see if it goes back
to reasonable
to reasonable
again we're looking for very close to 10
again we're looking for very close to 10
here
I also shouldn't be waiting for this
I also shouldn't be waiting for this
thing to train for this long one I'm
thing to train for this long one I'm
running this locally on my desktop which
running this locally on my desktop which
is a slow desktop and uh two I haven't
is a slow desktop and uh two I haven't
bothered with like VEC or any form of
bothered with like VEC or any form of
optimization so this 20K is just like if
optimization so this 20K is just like if
you if you just do it in the most brain
you if you just do it in the most brain
dead POS way possible
20k that's
20k that's
fun for
good
enough not
really man why does it do
really man why does it do
this stupid jiggle
thing I have one other thing to
thing I have one other thing to
try for
one o1 is to the point where it like
one o1 is to the point where it like
almost won't even see
it interesting well I guess this makes
it interesting well I guess this makes
sense this not going to randomly solve
sense this not going to randomly solve
it you might actually be right let's
see I'd be somewhat
surprised actually looks pretty good
[Music]
[Music]
it's not really learning it quick enough
it's not really learning it quick enough
though what I'd
feared yeah
so it was learning but it wasn't
so it was learning but it wasn't
learning fast
enough yeah what did we have was it 02
enough yeah what did we have was it 02
or
or
something when we had reward
something when we had reward
five it was like this
you know let's stop being stupid here
you know let's stop being stupid here
um let's just
do score minus
one
one
info or
info or
1.0 or just
1.0 or just
one and then hold on
equal
equal
[Music]
zero and one actually
zero and one actually
no wait it should be
no wait it should be
zero yeah this will give you the
zero yeah this will give you the
completion
right it was O it was 01 are you
sure this will get us the completion
sure this will get us the completion
rate
anyways so now instead of having to
anyways so now instead of having to
stare at return and length which don't
stare at return and length which don't
really mean anything we can just see how
really mean anything we can just see how
many of the like what percentage of the
many of the like what percentage of the
time it solves the game
about 90 91
about 90 91
92 O2 is what it was I checked the video
92 O2 is what it was I checked the video
thank
you so this solves it like 90% of the
you so this solves it like 90% of the
time
cool and now we try the uh the discret
version and let's see
we try the discrete
version and see how it does by
version and see how it does by
comparison
that does look a little bit more stable
that does look a little bit more stable
doesn't
doesn't
it
95 96%
so this is you saw the continuous one
so this is you saw the continuous one
now you'll get to see the discrete
now you'll get to see the discrete
one oop
oop which looks way better right
oop which looks way better right
actually you know we have a very easy
actually you know we have a very easy
way to
way to
determine whether
determine whether
um this is a property of the algorithm
um this is a property of the algorithm
or the
or the
environment I don't know why I didn't
environment I don't know why I didn't
think think of this
earlier
so we're just going to treat the discret
so we're just going to treat the discret
as a The Continuous as a discrete
as a The Continuous as a discrete
right so this will tell us basically
right so this will tell us basically
whether it is the optimization algorithm
whether it is the optimization algorithm
being
being
Jank or the
Jank or the
um uh the optimization algorithm or just
um uh the optimization algorithm or just
the
the
environment this will tell
us now mind you this is not
us now mind you this is not
hyperparameter tuned
okay so it's definitely the
okay so it's definitely the
algorithm definitely the algorithm is
algorithm definitely the algorithm is
weird not
weird not
broken but
weird no there's no different in
weird no there's no different in
processing of continuous
processing of continuous
State
State
um it's just the way the loss is
um it's just the way the loss is
constructed and works out as
all
yeah it represents it as a mean and a
yeah it represents it as a mean and a
variance
I mean we could hyperparameter tune both
I mean we could hyperparameter tune both
right it would probably solve it in both
right it would probably solve it in both
cases let's just go run uh one more so
cases let's just go run uh one more so
we have a
Baseline and we'll make a little video
Baseline and we'll make a little video
of it or something
continuous control support coming to a
continuous control support coming to a
puffer lib near
you coming to a puffer lib near you
let's do 15 FPS on this right
and wait
and wait
100 this only needs to
100 this only needs to
be 10 seconds
right
150 let's try this
what cannot handle this data type
really
couple my bed
uh return frame not
action okay give me my Baseline gift
action okay give me my Baseline gift
please
okay and we should have a gift
okay and we should have a gift
in buffer
in buffer
tank there's our gift
sh
interesting I would challenge that but
interesting I would challenge that but
depends what Chris is
doing
e e
this is technically
this is technically
whoops technically a bad time to post
whoops technically a bad time to post
stuff but you know I got plenty of stuff
stuff but you know I got plenty of stuff
to
to
post so we'll just keep adding
post so we'll just keep adding
stuff nope wrong
stuff nope wrong
one this one
this Artic this article actually did
this Artic this article actually did
pretty
pretty
well that's
funny e
cool good Twitter
cool good Twitter
day very nice Twitter
day very nice Twitter
day that helps me out a lot with uh the
day that helps me out a lot with uh the
exposure for
exposure for
puffer puffer's gotten a decent chunk of
puffer puffer's gotten a decent chunk of
stars as well today
stars as well today
look at that back on the exponential
up this
up this
awesome all right we so we have basic
awesome all right we so we have basic
continuous control
continuous control
implemented um I'm going to have to
implemented um I'm going to have to
clean this up tomorrow it's already
clean this up tomorrow it's already
754 so I'm probably going to go to sleep
754 so I'm probably going to go to sleep
in a bit I would like to get some idea
in a bit I would like to get some idea
for projects
for projects
first would like to get some idea for
first would like to get some idea for
uh for projects whoops let me me fix
that hold
on
on
uh this darn
uh this darn
thing yeah
thing yeah
so I've had a bunch of ideas on stuff to
so I've had a bunch of ideas on stuff to
do next I want to do more Sims Sims are
do next I want to do more Sims Sims are
fun Sims are really high impact for the
fun Sims are really high impact for the
field RL really really needs more like
field RL really really needs more like
good high quality
good high quality
Sims let me go see if that guy did
Tetris did you do did he post Tetris
huh that's
huh that's
fun I'm not sure what he's
fun I'm not sure what he's
doing
doing
Tetris and drawing
canvas I mean this is like RL or
canvas I mean this is like RL or
something playing it
something playing it
right I don't know is Tetris a good end
right I don't know is Tetris a good end
for
RL I mean it's like a fine really simple
RL I mean it's like a fine really simple
test end
right not particularly
hard environment prototype done
well we'll see whether
um oh he's trying to get the the RL to
um oh he's trying to get the the RL to
match the pixels that's
funny we could probably make like a
funny we could probably make like a
Tetris end really quick I don't know if
Tetris end really quick I don't know if
that's worth the time that would still
that's worth the time that would still
probably take you know a day to
probably take you know a day to
implement plus a day to polish something
implement plus a day to polish something
like
like
that and I could get it to be reasonably
that and I could get it to be reasonably
fast yeah I mean I could get it to be
fast yeah I mean I could get it to be
like a million steps per second I'm sure
like a million steps per second I'm sure
um I don't know if that's worth it
though snake was a good one because it's
though snake was a good one because it's
single agent or
single agent or
multi-agent one of the ideas I've been
multi-agent one of the ideas I've been
toying with is
toying with is
um some sort of like really strip down
um some sort of like really strip down
basic
MOA but I don't know how much you like a
MOA but I don't know how much you like a
MOA is a really complicated game I don't
MOA is a really complicated game I don't
know how much you can strip down a MOA
know how much you can strip down a MOA
and still have it be you know
and still have it be you know
meaningful like it would still be a
meaningful like it would still be a
decent chunk of code I'd have to
decent chunk of code I'd have to
implement creep
spawning creep AI which is path thing
spawning creep AI which is path thing
continuous pathing it's kind of a lot of
work h
simple coordination
environment Tower Defense isn't really a
environment Tower Defense isn't really a
strip down mooba right CU Tower Defense
strip down mooba right CU Tower Defense
like the player is usually placing the
like the player is usually placing the
towers right and then not actually doing
towers right and then not actually doing
stuff simple coordination environment um
um
um
yeah I mean I have the pixel EnV with a
yeah I mean I have the pixel EnV with a
grid
environment agents have to take turns to
environment agents have to take turns to
clean up
clean up
pool let's I mean I have the
pool let's I mean I have the
uh let me see if I can run
it it's in Ocean so technically
grid oops tired
um this is around my bedtime so I've got
um this is around my bedtime so I've got
to go sleep in a
bit I get up at 6 to run sh and I got to
bit I get up at 6 to run sh and I got to
do
do
nine I think I'm trying to do 9 and a
nine I think I'm trying to do 9 and a
half miles
tomorrow is continuous
No it should have an is
continuous he's continuous right here oh
continuous he's continuous right here oh
cuz it's not loaded it's fine
cuz it's not loaded it's fine
so
here I have this environment right which
here I have this environment right which
is just like each agent is a pixel and
is just like each agent is a pixel and
you can specify different like different
you can specify different like different
things that they've got to do that's
things that they've got to do that's
like a decent Little Engine I could
like a decent Little Engine I could
clean that up pretty
nicely let
nicely let
[Music]
me yeah so I mean I was thinking I could
me yeah so I mean I was thinking I could
do something with that like that's kind
do something with that like that's kind
of the simplest like the simplest it
of the simplest like the simplest it
gets is a pixel en like that um but I
gets is a pixel en like that um but I
wasn't sure if I wanted to make that n
wasn't sure if I wanted to make that n
discreete continuous or like support
discreete continuous or like support
both right so you could potentially do
both right so you could potentially do
continuous and discret with
continuous and discret with
it that would be a good project having
it that would be a good project having
just like a really simple particle end
just like a really simple particle end
for testing basic stuff
for testing basic stuff
right where I can have like yep po
right where I can have like yep po
solves all these tasks
solves all these tasks
they're it'd be kind of cool to have
they're it'd be kind of cool to have
like a baseline thing that where like
like a baseline thing that where like
all the tasks are solved but like it's
all the tasks are solved but like it's
fast so the tasks are actually
fast so the tasks are actually
non-trivial like the tasks are things
non-trivial like the tasks are things
that a PhD student might have spent
that a PhD student might have spent
three months on like a couple years ago
three months on like a couple years ago
and then it's just solved in five
and then it's just solved in five
minutes because PO is fast with Puffer
minutes because PO is fast with Puffer
that kind of appeals to
me and that would be a really easy
me and that would be a really easy
setting to like start getting some ideas
setting to like start getting some ideas
of what do with continuous as
of what do with continuous as
well let me make the grid Ms larger so
well let me make the grid Ms larger so
you can actually get a proper idea for
you can actually get a proper idea for
it um one
it um one
sec one
second uh def roll
out
out
okay th000
okay th000
and
and
yeah let's just make the grid a proper
size okay so this is way better right
this is now I think what thousand agents
this is now I think what thousand agents
512 agents whatever I said it
was and you can train these guys to do
was and you can train these guys to do
some
some
stuff I can I train them in real time
stuff I can I train them in real time
let me look what's my config for
grid 125 million probably can't train
grid 125 million probably can't train
these in real
these in real
time uh I don't think I needed it to be
time uh I don't think I needed it to be
that much though did I and I just do
actually you know what I can do I know
actually you know what I can do I know
what I can do I can just patch it real
quick does this work
yeah I forget what I train these guys to
yeah I forget what I train these guys to
even do
okay that's kind of gross that that's
okay that's kind of gross that that's
how that
works you can't save policies
works you can't save policies
properly
properly
um well whatever you can train them to
um well whatever you can train them to
do a couple different things like you
do a couple different things like you
can train them to spread out you can
can train them to spread out you can
train them to like form a ring stuff
train them to like form a ring stuff
like
like
that maybe I have the vid uh do I have
that maybe I have the vid uh do I have
the videos on like my my ex
the videos on like my my ex
account let me
account let me
see I'm actually kind of trying to
see I'm actually kind of trying to
remember what I even did with this en
remember what I even did with this en
it's only been a couple weeks since I
it's only been a couple weeks since I
made
made
it I've been posting way too much
it I've been posting way too much
stuff but it's
stuff but it's
good so this is the snake en right this
good so this is the snake en right this
is playing snake there a lot of stuff on
is playing snake there a lot of stuff on
the Twitter this is snake
Dev snake Dev
did the grid before this didn't
I okay yeah
I okay yeah
here
here
so grid
so grid
EnV this is the same grid environment
EnV this is the same grid environment
you can render it with puffer fish as
you can render it with puffer fish as
well there's just a puffer fish render
well there's just a puffer fish render
mode because why
mode because why
not oh here's a good one yeah this is a
not oh here's a good one yeah this is a
cool demo yeah right here so you see
this I train them to spread apart and
this I train them to spread apart and
there's like this weird coordination
there's like this weird coordination
thing that happens where they end up
thing that happens where they end up
like spreading out into these patches in
like spreading out into these patches in
this really cool
way and then some of them end up
way and then some of them end up
floating around like
floating around like
this you can do it like this if you
this you can do it like this if you
train it more
train it more
you get like this like cool Arrow shape
pattern and
pattern and
then uh you also like you can also get
then uh you also like you can also get
like with different rewards you can get
like with different rewards you can get
them to spread out more
evenly so I could do something with this
evenly so I could do something with this
grid
grid
environment I have to think about how
environment I have to think about how
I'd want to do it
yeah flocking flocking type stuff you
yeah flocking flocking type stuff you
can totally do I don't want to do heavy
can totally do I don't want to do heavy
physic Sim I could do very light physic
physic Sim I could do very light physic
Sim with just like you know acceleration
Sim with just like you know acceleration
velocity I'd have to think about what
velocity I'd have to think about what
the observations would be though if I
the observations would be though if I
did that the observations get a little
did that the observations get a little
fancier that might be a fun thing to do
fancier that might be a fun thing to do
tomorrow though is to like figure out
tomorrow though is to like figure out
how to build a uh a decent little high
how to build a uh a decent little high
perf continuous engine based on the
perf continuous engine based on the
stuff that I've done
stuff that I've done
already do you like a continuous grid
already do you like a continuous grid
version technically if I could figure it
out continuous is really well suited to
out continuous is really well suited to
entity based networks which can be very
entity based networks which can be very
efficient reminds me of entity
gem h
well maybe I'll stream that
well maybe I'll stream that
tomorrow the uh the streams are kind of
tomorrow the uh the streams are kind of
impromptu whenever I have time or feel
impromptu whenever I have time or feel
like it but uh normally I end up running
like it but uh normally I end up running
and lifting for the first few hours of
and lifting for the first few hours of
uh my days and then I'm back I'm on like
uh my days and then I'm back I'm on like
10 11 something like that depending when
10 11 something like that depending when
I finish stuff sometimes I do some work
I finish stuff sometimes I do some work
from there first but yeah there's going
from there first but yeah there's going
to be a fair bit of streaming on on this
to be a fair bit of streaming on on this
soon um
soon um
yeah this would be a good thing to
yeah this would be a good thing to
do I might also just spend some time
do I might also just spend some time
cleaning up the new code base like the
cleaning up the new code base like the
new continuous Integrations tomorrow
new continuous Integrations tomorrow
since I have this all locally for
now I'm already thinking about like that
now I'm already thinking about like that
continuous engine and how I would do it
continuous engine and how I would do it
so like cuz the grid environments are
so like cuz the grid environments are
really really computationally efficient
really really computationally efficient
at small scale but when you want to do
at small scale but when you want to do
like bigger observation Windows they
like bigger observation Windows they
stop being so
efficient but the thing is I don't know
efficient but the thing is I don't know
how you would get
how you would get
like I don't know what an efficient
like I don't know what an efficient
algorithm would be to find all nearby
algorithm would be to find all nearby
agents because that's what you need for
agents because that's what you need for
your observations is like old nearby
your observations is like old nearby
agents and that's kind of
hard h
that's nice this was at
that's nice this was at
yesterday the growth has just been great
yesterday the growth has just been great
it's a really good motivation to keep
it's a really good motivation to keep
doing this stuff you know since
doing this stuff you know since
graduating there's no point in doing
graduating there's no point in doing
this stuff if people don't see it and
this stuff if people don't see it and
like you know want to use it so it's
like you know want to use it so it's
it's been really good to see the growth
it's been really good to see the growth
on this
and it does seem like people like the
and it does seem like people like the
articles I mean this is a really click
articles I mean this is a really click
baity title but you know
whatever okay I'm gon to call it for now
whatever okay I'm gon to call it for now
I got to get some sleep um I'm going to
I got to get some sleep um I'm going to
think about that engine a bit I'm going
think about that engine a bit I'm going
to see if I can come back back with some
to see if I can come back back with some
ideas yeah I think it would be dumb to
ideas yeah I think it would be dumb to
try to attempt something like a MOBA or
try to attempt something like a MOBA or
whatever and think I'm going to have
whatever and think I'm going to have
continuous simulation before I have like
continuous simulation before I have like
a little engine type thing that can
a little engine type thing that can
handle grid environments so I'm going to
handle grid environments so I'm going to
go think about that uh good night all
go think about that uh good night all
and we'll be back soon
