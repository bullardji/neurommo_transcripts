Kind: captions
Language: en
Okay.
Okay.
Hi, we're live just for a short bit
Hi, we're live just for a short bit
right
right
now. I have to deal with admin stuff all
now. I have to deal with admin stuff all
day because I am going away for the
day because I am going away for the
weekend. That means no all day Saturday
weekend. That means no all day Saturday
devst stream, which sucks. Very much
devst stream, which sucks. Very much
like to be doing an all day Saturday dev
like to be doing an all day Saturday dev
stream instead of whatever the hell I'm
stream instead of whatever the hell I'm
going to be doing. But, uh, you know,
going to be doing. But, uh, you know,
there's some stuff that has to be taken
there's some stuff that has to be taken
care of, so no big deal. Um, all I want
care of, so no big deal. Um, all I want
to do right now is not really do any
to do right now is not really do any
real dev. Just check a couple of
real dev. Just check a couple of
experiments, figure out some good
experiments, figure out some good
experiments to run, set them up on a few
experiments to run, set them up on a few
machines, and call it a day. That's
it. So, um, I have it right
it. So, um, I have it right
here. So, this is pretty cool. We have
here. So, this is pretty cool. We have
soda on neural MMO with the latest
soda on neural MMO with the latest
experiment. Um, right
experiment. Um, right
here you can see this is
here you can see this is
4.5. So if we go back to 4.5
4.5. So if we go back to 4.5
here, this is 43 billion steps. So this
here, this is 43 billion steps. So this
run is more than 2x better than this run
run is more than 2x better than this run
just because I fixed some seating stuff.
just because I fixed some seating stuff.
And uh if you kind of draw this line
And uh if you kind of draw this line
up, it's getting pretty shallow, but you
up, it's getting pretty shallow, but you
think that this would get to five or so,
think that this would get to five or so,
right? This is probably going to get to
right? This is probably going to get to
around
around
five if it uh
five if it uh
finishes. So, soda at five. Pretty damn
finishes. So, soda at five. Pretty damn
good. That is a quarter of the way to
good. That is a quarter of the way to
solve. So, we've gone from a tenth up to
solve. So, we've gone from a tenth up to
a quarter in uh the last couple of
a quarter in uh the last couple of
weeks, which is very, very nice. Uh I
weeks, which is very, very nice. Uh I
don't think that these policies are
don't think that these policies are
going to be they're not quite to the
going to be they're not quite to the
point where they're going to look really
point where they're going to look really
good if you're watching them. That's
good if you're watching them. That's
probably, if I had to guess, somewhere
probably, if I had to guess, somewhere
around 8 to 10. So, long way off, but
around 8 to 10. So, long way off, but
it's definitely a start.
it's definitely a start.
So,
So,
um I'm trying to think what experiments
um I'm trying to think what experiments
I can
I can
run
run
because we kind of have everything log
because we kind of have everything log
linear right
linear right
now is not
ideal. Maybe we look at loss real
quick. Okay, Kale's
quick. Okay, Kale's
flat clip bracket stable.
Entropy is
stable. This is very spiky
stable. This is very spiky
actually. Gradient
actually. Gradient
variance
variance
KL. Okay, there's a small KL gap.
KL. Okay, there's a small KL gap.
value loss very
low. I think at least one of these is
low. I think at least one of these is
worth just running another
worth just running another
hyperparameter
hyperparameter
sweep. I think I'd probably get two
sweep. I think I'd probably get two
experiments to
run. Plus, when this one this one has
run. Plus, when this one this one has
like another 24 hoursish on it, then
like another 24 hoursish on it, then
when this one finishes, I get to run
when this one finishes, I get to run
something else.
Um, the real question is how much is
Um, the real question is how much is
left in hyper pram
sweeps. Sweep those
sweeps. Sweep those
hypers. Oh
hypers. Oh
yeah. Well, I mean, they've made a huge
yeah. Well, I mean, they've made a huge
difference everywhere else. It's just
difference everywhere else. It's just
harder to do here because from my
harder to do here because from my
experience, you can't just do even a one
experience, you can't just do even a one
billion step hyperparam sweep. That's
billion step hyperparam sweep. That's
already insane to talk about a 1 billion
already insane to talk about a 1 billion
step per experiment hyperparam sweep,
step per experiment hyperparam sweep,
but that's not even good enough. You
but that's not even good enough. You
kind of have to do like five or 10
kind of have to do like five or 10
billion hyperpar sweep. So, I can
billion hyperpar sweep. So, I can
do, you know, you only get a few
do, you know, you only get a few
experiments a day like
that. So, I think one of these machines
that. So, I think one of these machines
is just going to be a longunning job
is just going to be a longunning job
that hopefully doesn't
that hopefully doesn't
crash.
crash.
Um, seeing what we can get better out of
Um, seeing what we can get better out of
this, maybe like a 10
this, maybe like a 10
billion. Can you estimate the curve?
billion. Can you estimate the curve?
Nope, you can't. This is why it's so
Nope, you can't. This is why it's so
important the puffer is fast because if
important the puffer is fast because if
we were stuck doing that, we would we'd
we were stuck doing that, we would we'd
be nowhere right now. And I can prove it
be nowhere right now. And I can prove it
to you.
So this is the result of uh we have like
So this is the result of uh we have like
this 1 billion sweep here and you can
this 1 billion sweep here and you can
see like stuff up here has like really
see like stuff up here has like really
really steep slope but it's not actually
really steep slope but it's not actually
predictive of where it's going to
predictive of where it's going to
converge. Like these things just level
converge. Like these things just level
out early. And I have some other runs
out early. And I have some other runs
here somewhere where I even ran some of
here somewhere where I even ran some of
these for a little
these for a little
longer. Oh yeah, there you go.
longer. Oh yeah, there you go.
So, you know, we have all sorts of
So, you know, we have all sorts of
different runs here. Some of these look
different runs here. Some of these look
really good even, but um they all tend
really good even, but um they all tend
to level out if you just run them
longer here. This is one of them
right.
Yeah, this was PSGD.
Now, you know, I do wonder if there was
Now, you know, I do wonder if there was
something to it here, though, with
the like some annealing factor here.
Try just fitting a
spline. I mean, you can kind of see from
spline. I mean, you can kind of see from
these though, right?
these though, right?
Like you end up getting like shapes like
Like you end up getting like shapes like
this and
this and
this where this one looked really good
this where this one looked really good
and then it levels off. I think I have
and then it levels off. I think I have
some of these that I ran for longer as
some of these that I ran for longer as
well. Actually, it might be this right
well. Actually, it might be this right
here. Let me see.
Yeah. So, here you go. If I zoom it to
Yeah. So, here you go. If I zoom it to
here. So, this was me taking one of the
here. So, this was me taking one of the
better runs, right? This one looks
better runs, right? This one looks
really good. This one's way above all my
really good. This one's way above all my
other ones. And it levels off and it
other ones. And it levels off and it
kind of intersects with them around 5
billion. Maybe five billion steps is
billion. Maybe five billion steps is
going to be enough.
Need more hardware. Well, we have some
Need more hardware. Well, we have some
hardware. I haven't been like doing
hardware. I haven't been like doing
distributed sweeps or anything
yet. We just got our first 5090 box
yet. We just got our first 5090 box
in. And I'm actually the trip I'm taking
in. And I'm actually the trip I'm taking
this weekend is to tour the new facility
this weekend is to tour the new facility
that uh we're going to have ready in
that uh we're going to have ready in
about a month. So, we're going to be
about a month. So, we're going to be
able to start purchasing more hardware.
able to start purchasing more hardware.
The existing hardware that we move there
The existing hardware that we move there
is going to be way more stable, have way
is going to be way more stable, have way
more consistent power, hopefully more
more consistent power, hopefully more
consistent internet.
Well, I don't I don't know how much
Well, I don't I don't know how much
you've been around here, but the if you
you've been around here, but the if you
see like how much we're already
see like how much we're already
running, even if I'm running the sweep
running, even if I'm running the sweep
on one GPU, this runs like at least 100
on one GPU, this runs like at least 100
times faster than anything comparable in
times faster than anything comparable in
academia. So, my one GPU may as well be
academia. So, my one GPU may as well be
100 GPUs, right, for this sweep. And
100 GPUs, right, for this sweep. And
actually we have 10 GPUs right now. So
actually we have 10 GPUs right now. So
we may as well have a thousand GPUs for
we may as well have a thousand GPUs for
research, right? That's kind of the key
research, right? That's kind of the key
with all of
with all of
this. This x-axis here on this whole
this. This x-axis here on this whole
graph for the full run here, this is 100
graph for the full run here, this is 100
billion steps. This is equal to this
billion steps. This is equal to this
thing playing 2,000 years worth of
thing playing 2,000 years worth of
games. So this plot here, like including
games. So this plot here, like including
all these, has like probably 8,000 years
all these, has like probably 8,000 years
worth of games played on it.
worth of games played on it.
No more. 10,000 years worth of games
No more. 10,000 years worth of games
played on it. It's kind of crazy.
I think we just run a few quick tests on
I think we just run a few quick tests on
this and make sure we don't OM on the
this and make sure we don't OM on the
biggest settings. We launched like a
biggest settings. We launched like a
really nice five bill hyper pram
sweep. Does that make sense? So that's
sweep. Does that make sense? So that's
like right here on the
like right here on the
graph. Right
graph. Right
here. Yeah. X is slow. The Twitch and
here. Yeah. X is slow. The Twitch and
YouTube ones are faster. I'm live there
YouTube ones are faster. I'm live there
as well.
X is the best for the notifications
X is the best for the notifications
though. So you also post stuff
there. It's a lot more likely to be
there. It's a lot more likely to be
predicted by
predicted by
Isn't
Isn't
it? And look at this
it? And look at this
thing. It literally your previous soda
thing. It literally your previous soda
run
run
here. It intersects all the way out here
here. It intersects all the way out here
at 30. What's this? 25
at 30. What's this? 25
bill. That's
bill. That's
crazy. Can't do a 25 bill hyperpar
crazy. Can't do a 25 bill hyperpar
sweep.
It's like a day per
It's like a day per
experiment
almost 16
hours. 10's pushing
hours. 10's pushing
it. I think five is going to be what we
it. I think five is going to be what we
want. Kind of the best we can
do. How good do you think we can do in
do. How good do you think we can do in
five? I think
five? I think
optimistically we can probably get three
optimistically we can probably get three
by
five. That should be high
five. That should be high
enough. Three is non-trivial performance
enough. Three is non-trivial performance
on the test.
Uh Jay's bar is 5341. It's the same as
Uh Jay's bar is 5341. It's the same as
my X
handle. So, we're going to try
this. What else do we try, though?
I wouldn't be surprised if after this
I wouldn't be surprised if after this
it's
it's
like data and architecture
honestly. What about cosine and
honestly. What about cosine and
kneeling? We don't have that on, do
kneeling? We don't have that on, do
we?
Welcome. We don't have cosine and
Welcome. We don't have cosine and
kneeling on cuz I messed up the
kneeling on cuz I messed up the
implementation,
right? Or do
right? Or do
we? We might have it on. Hang on. I
we? We might have it on. Hang on. I
actually don't
know. Okay, we can't commit this is
know. Okay, we can't commit this is
because I have this a mess.
No, we do have it
No, we do have it
on
data.sculer.step. Did I implement this
data.sculer.step. Did I implement this
thing
correctly? Yes, it is because it's wraps
correctly? Yes, it is because it's wraps
the
the
optimizer. So, we do have cosine nailing
optimizer. So, we do have cosine nailing
on already. So, that's fine.
on already. So, that's fine.
So, we just
So, we just
do one machine hyper sweep. What else
do one machine hyper sweep. What else
can I run that would be
good? I could massively scale the
network. That seems wrong to me.
Scaling the network just gave me
Scaling the network just gave me
this. It's
not It's not going to solve the
not It's not going to solve the
task. Weight
task. Weight
decay. Omega. Does
decay. Omega. Does
this Okay, here. Question for you. I'm
this Okay, here. Question for you. I'm
gonna run a hyperparameter sweep on this
gonna run a hyperparameter sweep on this
because this what like look I I have to
because this what like look I I have to
just express to you how ridiculous this
just express to you how ridiculous this
task is.
task is.
Okay, so this is like I don't even know
Okay, so this is like I don't even know
experiments. These are 1 billion steps
experiments. These are 1 billion steps
each. I'm going to run an experiment a
each. I'm going to run an experiment a
sweep where each run is five billion
sweep where each run is five billion
steps. So these are
steps. So these are
chunky. If there's more if there are
chunky. If there's more if there are
more
more
techniques, you would hope that they're
techniques, you would hope that they're
stable enough that you could get
stable enough that you could get
something out of them just sweeping that
something out of them just sweeping that
one parameter with the optimals. If I
one parameter with the optimals. If I
have to sweep the [ __ ] weight decay
have to sweep the [ __ ] weight decay
or whatever a new technique and then
or whatever a new technique and then
reweep all the other parameters for it
reweep all the other parameters for it
to work, then that's kind of
to work, then that's kind of
ass. Also, a lot of these are PSGD.
If you get like any indication that PSGD
If you get like any indication that PSGD
is likely to be good on neural MMO, I
is likely to be good on neural MMO, I
will be more than happy to run that
will be more than happy to run that
experiment. But what happened with PSGD
experiment. But what happened with PSGD
so far is it starts off really good
so far is it starts off really good
early and then it actually levels out
early and then it actually levels out
and it's worse than muon without even
and it's worse than muon without even
fully optimized muon
performance. This is the current. We
performance. This is the current. We
beat soda by a factor of two in terms of
beat soda by a factor of two in terms of
time taken.
time taken.
I just fixed all the random
I just fixed all the random
seating. But by the way, this one
seating. But by the way, this one
literally it doesn't learn anything for
literally it doesn't learn anything for
five billion steps and then it takes
five billion steps and then it takes
off. That's how crazy this stuff
off. That's how crazy this stuff
is. So we're at
is. So we're at
4.8ish after 65 billion steps is
4.8ish after 65 billion steps is
currently
currently
soda. This will probably be five at 100
soda. This will probably be five at 100
bill. The curves are quite stable.
It could just make the net dramatically
It could just make the net dramatically
bigger. I really
could. What do we think we would get out
could. What do we think we would get out
of it?
I still think the best case scenario of
I still think the best case scenario of
that is that it gets like
six. Well, what do I think the best case
six. Well, what do I think the best case
is out of the hyper pram
sweep? Do I really think the hyper pram
sweep? Do I really think the hyper pram
sweep is going to make that big a
sweep is going to make that big a
difference? Kind of.
difference? Kind of.
Yeah, I kind of
Yeah, I kind of
do. Let me go check this
do. Let me go check this
experiment. See what I ran this
with. So this
is Oops.
Um, well, this is still running even
Um, well, this is still running even
though the driver is cracked. So, that's
though the driver is cracked. So, that's
cool.
You know, I could actually see the hyper
You know, I could actually see the hyper
pram sweep making a big difference. Are
pram sweep making a big difference. Are
you using heavy ball? Yeah, this is
you using heavy ball? Yeah, this is
heavy ball. Mulan.
We do a restricted set
sweep. 4 m
two. It's pretty
two. It's pretty
good. Okay, I think I know what I'm
good. Okay, I think I know what I'm
going to
do. This is already master.
[Music]
What's this damn machine called fault?
How do I forget my own SSH
password? There we go.
Do you ever think you'll work in
industry? I mean, what does this count
as,
as,
right? This is I mean, this is a
right? This is I mean, this is a
startup where we offer priority service
startup where we offer priority service
to companies in industry that want to do
to companies in industry that want to do
RL and have an easier time of it, make
RL and have an easier time of it, make
stuff go faster, get their SIMs running
stuff go faster, get their SIMs running
better, apply all of our latest tools,
better, apply all of our latest tools,
get custom tools made,
get custom tools made,
right? So, if you mean, do you think
right? So, if you mean, do you think
I'll take a job at big tech? Probably
I'll take a job at big tech? Probably
not. You think I will like get closer to
not. You think I will like get closer to
a bunch of industry problems over time?
a bunch of industry problems over time?
Absolutely.
Yeah, I'm really specialized to
Yeah, I'm really specialized to
like I'm pretty damn good at making like
like I'm pretty damn good at making like
m mediumsized projects. very very simple
m mediumsized projects. very very simple
and compact and
and compact and
efficient. That's kind of where I'm
efficient. That's kind of where I'm
happiest,
happiest,
right? Cuz when you get into really big
right? Cuz when you get into really big
size projects, your impact as an IC goes
size projects, your impact as an IC goes
way down and it just becomes a
way down and it just becomes a
management ordeal of total
management ordeal of total
mess. I like to have projects that are
mess. I like to have projects that are
still a size where I can like get there
still a size where I can like get there
and really mess with the code myself.
L there's a bug in heavy ball. Look,
L there's a bug in heavy ball. Look,
Omid, just
like either run some stuff on
like either run some stuff on
Neuralarmmo or if you have some
Neuralarmmo or if you have some
promising initial stuff, I can run stuff
promising initial stuff, I can run stuff
on it,
on it,
right? Was about to kill
right? Was about to kill
me, man. She's cutting into your Twitch
me, man. She's cutting into your Twitch
dev stream random Thursday night
dev stream random Thursday night
whatever shenanigans.
So, let's see what we're going to
sweep. See what we are going to
sweep. You don't want to screw this
sweep. You don't want to screw this
up. I'm sweeping hidden
up. I'm sweeping hidden
size. Not sweeping numms
m sweeping total time
m sweeping total time
steps. We can sweep batch
size of this.
So this batch size can now be like
So this batch size can now be like
ridiculous this mini batch
ridiculous this mini batch
size because
size because
um we have gradient accumulation. So now
um we have gradient accumulation. So now
it cannot OM on us. Learning rate gets
it cannot OM on us. Learning rate gets
swept. Entropy gets swept. Gamma gets
swept. Entropy gets swept. Gamma gets
swept. Lambda gets
swept. Lambda gets
swept. Update epox doesn't get swept.
swept. Update epox doesn't get swept.
Screw that. It's going to stay at one.
Screw that. It's going to stay at one.
Value function coefficient can get
Value function coefficient can get
swept. Gradient can get
swept. Gradient can get
swept. BPT
swept. BPT
horizon go up to
horizon go up to
and get
swept. Adam beta
swept. Adam beta
1. This can still get
1. This can still get
swept. Adam epsilon can still get swept.
swept. Adam epsilon can still get swept.
Okay.
Don't need any of this
stuff. And then the only thing we need
stuff. And then the only thing we need
in
in
uh
three. Do we want to sweep the reward
three. Do we want to sweep the reward
coefficients? That's too much,
coefficients? That's too much,
right?
Think we just do
Think we just do
this total time
this total time
steps
steps
away. M goes
away. And now we're sweeping all the
away. And now we're sweeping all the
stuff that matters. We should be at
stuff that matters. We should be at
least. And then this has got to be five
least. And then this has got to be five
bill.
Bill with a
Bill with a
B. Freaking crazy to think
B. Freaking crazy to think
about. I want to OM this entire box.
That's so
fun. This is all
fun. This is all
good. Then we'll have to hope that this
good. Then we'll have to hope that this
is reasonable.
Holy hell. How do I have 1.6 terabytes
Holy hell. How do I have 1.6 terabytes
used?
We also have to make sure we don't
We also have to make sure we don't
forget to rebuild.
gigs per
experiment. 500
megs. I always forget the bloody command
megs. I always forget the bloody command
for
this overlay.
There we
go. Yeah. So that's insane.
I got to fix that. There's something
I got to fix that. There's something
wrong with the uh the model save and
wrong with the uh the model save and
checkpointing. I'm going to just adjust
checkpointing. I'm going to just adjust
the interval so we don't
OM. That's terrible on the hard drive as
OM. That's terrible on the hard drive as
well.
Okay, so there's 10k checkpoint
Okay, so there's 10k checkpoint
interval. Now, now the only thing I got
interval. Now, now the only thing I got
to remember to do and not screw up
to remember to do and not screw up
here, I remember this on the other
here, I remember this on the other
machine too. If I run something
there. Okay. So this is compiling the
there. Okay. So this is compiling the
new
new
version of the neural MMO
version of the neural MMO
binding. This is with the new Python C
binding. This is with the new Python C
API binding code. So if you look there,
API binding code. So if you look there,
it's not actually compiling any Syon for
it's not actually compiling any Syon for
neural MMO. This just C
neural MMO. This just C
Python right here. This is no
Python right here. This is no
Syon. So that'll be pretty nice.
Is this thing still
running?
running?
4.3. Hang on. What's still
4.3. Hang on. What's still
running? I mean, that's basically
running? I mean, that's basically
finished, but what the hell is it?
There must be another run that I'm not
There must be another run that I'm not
visualizing
here. It's like a 4.3
Weird. Well, it's not a soda run, so we
Weird. Well, it's not a soda run, so we
don't
care. This thing go
Yeah, not a soda run
Yeah, not a soda run
though. It's
decent. Not a soda run
decent. Not a soda run
though. Hang
on. All
right.
Um, this was the random seated run.
Um, this was the random seated run.
Okay. Are you using 204 2204?
Okay. Are you using 204 2204?
Uh, so our older containers are
Uh, so our older containers are
2204 and our newer containers are going
2204 and our newer containers are going
to be
to be
2404. I just started one of these
2404. I just started one of these
because we need drivers for90s now.
because we need drivers for90s now.
There are a bunch of annoying things
There are a bunch of annoying things
with 2404 though that need to be
with 2404 though that need to be
handled. So I don't recommend that until
handled. So I don't recommend that until
we uh we update our nice containers so
we uh we update our nice containers so
that you don't have to deal with it.
that you don't have to deal with it.
2204 is fine unless you have a
5090. Just making sure everything is
5090. Just making sure everything is
correct because if I screw this run up,
correct because if I screw this run up,
this is like a big
run. I highly doubt we run out
run. I highly doubt we run out
of anything on this.
of anything on this.
The one thing that really annoys me,
The one thing that really annoys me,
I'll say, with 2404, which we're going
I'll say, with 2404, which we're going
to patch in our container,
to patch in our container,
um, they adopted a new Python pep, which
um, they adopted a new Python pep, which
is like literally the dumbest thing I've
is like literally the dumbest thing I've
ever seen Python do. And that's saying
ever seen Python do. And that's saying
something where they basically don't let
something where they basically don't let
you install pip packages outside of a
you install pip packages outside of a
virtual M by default which is
virtual M by default which is
like if you need if you use virtual MS
like if you need if you use virtual MS
inside of Docker containers like please
inside of Docker containers like please
seek mental
seek mental
help. So I don't know what the hell
help. So I don't know what the hell
they're doing because it's
they're doing because it's
like so we're going to work around that.
Isn't something horribly wrong
here? Something's horribly wrong here.
I tested this and it worked.
Why do you find docker containers
Why do you find docker containers
useful using nountu service main dev? Is
useful using nountu service main dev? Is
there an additional benefit using the
there an additional benefit using the
docker? Absolutely there is.
docker? Absolutely there is.
So you kind of use one of two things,
So you kind of use one of two things,
right? use like a virtual M or a cond or
right? use like a virtual M or a cond or
whatever or you use a
whatever or you use a
container virtual M every time you want
container virtual M every time you want
a new one you have to rebuild the whole
a new one you have to rebuild the whole
damn
damn
thing and reinstall everything and it's
thing and reinstall everything and it's
a
a
pain and also everything's not even
pain and also everything's not even
guaranteed to work in that because you
guaranteed to work in that because you
have to have correct system
have to have correct system
packages in a Docker container I get the
packages in a Docker container I get the
same dev environment every time if I
same dev environment every time if I
want a brand new clean dev environment
want a brand new clean dev environment
where everything is guaranteed to work.
where everything is guaranteed to work.
It takes me 10 seconds. I run one
It takes me 10 seconds. I run one
command and I have a fresh development
command and I have a fresh development
environment in 10 seconds. And I have
environment in 10 seconds. And I have
the exact same development environment
the exact same development environment
locally as I have on our
locally as I have on our
servers. It's very very easy that way.
servers. It's very very easy that way.
Everybody can have their own as well. I
Everybody can have their own as well. I
can let I just have it so that when
can let I just have it so that when
people log into our servers, you just
people log into our servers, you just
get booted into your
get booted into your
container. And it's the same exact
container. And it's the same exact
development environment as if you use
development environment as if you use
your container at
your container at
home. So it's very very nice for
home. So it's very very nice for
that. Very quick quick to set up, you
that. Very quick quick to set up, you
know, reproducible dev environment.
I think this is actually
working. Well, this metric's
working. Well, this metric's
working. See
It's a log.
This line
This line
disappeared. I see it.
I don't know how that
I don't know how that
happened. Did I not commit it?
a
a
reward. That's
why. Yeah, this is why only the returns
why. Yeah, this is why only the returns
are
wrong. Only the returns are wrong.
I thought that uh we had
like doesn't seem to get zeroed
like doesn't seem to get zeroed
correctly.
How concerned am I about this?
moderately concerned.
Oh, because this is reward and not
Oh, because this is reward and not
return. Yeah, this is reward, not
return. Yeah, this is reward, not
return.
return.
Okay. Yeah, this is correct. This should
Okay. Yeah, this is correct. This should
fix
fix
it. We'll double check real quick.
Whatever. Broken ass
Whatever. Broken ass
driver. Just push it.
Now we should no longer see metric
Now we should no longer see metric
stacking up
stupidly. It wouldn't have hurt anything
stupidly. It wouldn't have hurt anything
until it overflowed,
until it overflowed,
but better not risk
but better not risk
it. I don't even know if it would have
it. I don't even know if it would have
overflowed in the time of the
overflowed in the time of the
experiment, but probably not. Still
experiment, but probably not. Still
better not to screw with it.
better not to screw with it.
Yeah, now that's actually
correct. Yeah, those metrics look
good. Okay, we leave this one
good. Okay, we leave this one
be and then we go run the second
be and then we go run the second
experiment, which
experiment, which
is is it box four the one I use?
I
don't this my
job. Yeah, this is my job. It's just
job. Yeah, this is my job. It's just
stuck. That's fine.
This is going to be kind of
crazy. Big
model.
Instantly this
Instantly this
works. We will see
works. We will see
though. We will see.
37 million
37 million
per. I've not trained a model this big
per. I've not trained a model this big
in
in
years. And I know that's a crazy thing
years. And I know that's a crazy thing
to say because 37 mil is lower than uh
to say because 37 mil is lower than uh
what I was training in like
what I was training in like
20 17 or whatever, one of my first
20 17 or whatever, one of my first
projects, but it's very big for
projects, but it's very big for
RL. And to keep in mind the X-axis is so
RL. And to keep in mind the X-axis is so
much
much
longer in RL.
If this OOMs, we do have outs. As long
If this OOMs, we do have outs. As long
as it doesn't OM on the forward
as it doesn't OM on the forward
pass. If it OOMs in the backward pass,
pass. If it OOMs in the backward pass,
we have gradient accumulation to fall
we have gradient accumulation to fall
back
back
on. Cuz I do want to get some sleep
on. Cuz I do want to get some sleep
tonight. So, I just want to The goal is
tonight. So, I just want to The goal is
just to get this run going and go to
just to get this run going and go to
sleep.
sleep.
I guess technically I could run
I guess technically I could run
something on my personal box as well
something on my personal box as well
since I'm not going to be
here. I can also still use I could use
here. I can also still use I could use
this the dev box as well over the
this the dev box as well over the
weekend. Might be nice to have
one. Okay,
one. Okay,
so that forward time is
so that forward time is
nuts. Holy, look at
that. It shouldn't be that skewed,
that. It shouldn't be that skewed,
actually.
see anything weird in
here? That's actually kind of sketchy
here? That's actually kind of sketchy
that it's that
that it's that
skewed. Oh, it's the mini batch
skewed. Oh, it's the mini batch
size, you know. That's it. We can get
size, you know. That's it. We can get
this faster.
What is the accumulation
size faster? Can we make this
So somehow this balances out the compute
So somehow this balances out the compute
but it doesn't make it
but it doesn't make it
faster. Seems
weird. There's a more reasonable number
weird. There's a more reasonable number
though.
though.
97% GPU
97% GPU
set. That's something you don't see in
set. That's something you don't see in
RL
often. 181 hours for this whole
thing. It's a little
thing. It's a little
crazy. Oh, the value loss is screwed
crazy. Oh, the value loss is screwed
already. How's that happen?
Doesn't make much
sense. If I do this, is it not screwed?
Interesting. Doesn't blow
up. Unless it's blowing up now.
There it goes.
Watch this for a bit. Make sure it
Watch this for a bit. Make sure it
doesn't blow
up. Let me go uh blast the optimizer,
guys, because this not supposed to It
guys, because this not supposed to It
still [ __ ] blows
still [ __ ] blows
up. It still blows
up. It still blows
up. The
heck? Not supposed to happen.
Can I get away with half of that
size? Why is the thing suddenly blow up?
size? Why is the thing suddenly blow up?
Has never blown up before.
This
This
is better looking,
right? Nope. Still blows
right? Nope. Still blows
up. Am I like screwing up? like is it
up. Am I like screwing up? like is it
still not stable with
512? Let's see what
512? Let's see what
was the heck is going on
here. Now these are all
stable. This is like some small value,
right? See if this blows up.
Yeah, I literally can't train a bigger
Yeah, I literally can't train a bigger
model. That's
model. That's
weird. That's very
weird. That's
weird. That's
stable. You go over 512, it blows up.
It's bizaro.
Maybe it's cuz this thing is
bottlenecking. What's this map 2D
bottlenecking. What's this map 2D
output?
I owned myself with this stupid
I owned myself with this stupid
architecture. I swear.
That'll do it.
if this is stable.
So
So
recompile. So this is going to get rid
recompile. So this is going to get rid
of the uh 128 bottleneck on the most
of the uh 128 bottleneck on the most
important chunk of
observations. 128 might just be too
observations. 128 might just be too
small.
There's also just probably a lot of
There's also just probably a lot of
stuff modeled poorly in that network.
We'll see if this is
We'll see if this is
stable. Doesn't take too big of a hit.
That looks stable
That looks stable
enough. Whether it makes a difference,
enough. Whether it makes a difference,
we will see.
we will see.
But uh this could very
But uh this could very
well the
difference. Give this some experiments.
Okay, we are
Okay, we are
set. We have experiments
set. We have experiments
running. Hopefully they are
running. Hopefully they are
stable. Check the discboard real quick.
Doesn't look like anything super
Doesn't look like anything super
urgent, but so here's the
urgent, but so here's the
plan. I am traveling
plan. I am traveling
tomorrow. I'm traveling back on
tomorrow. I'm traveling back on
Monday. Won't be able to stream, but
Monday. Won't be able to stream, but
we'll answer stuff on the
we'll answer stuff on the
Discord. I still will get some work in
Discord. I still will get some work in
on
on
Saturday. So, we'll see if I can
Saturday. So, we'll see if I can
find a cool thing to do there to about
find a cool thing to do there to about
when I get back. I have a couple ideas
when I get back. I have a couple ideas
for stuff I've wanted a day to work on.
Um, other than
that, experiments are running. New infra
that, experiments are running. New infra
bindings and bindings to Python are
bindings and bindings to Python are
really, really
really, really
nice. Muan's been doing great.
nice. Muan's been doing great.
only hyperp finicky one is neural MMO
only hyperp finicky one is neural MMO
which is by far the hardest problem but
which is by far the hardest problem but
the curves are
the curves are
clean and the network is probably
clean and the network is probably
there's some room for
improvement there's some still more
improvement there's some still more
algorithm side stuff to do quite a bit
algorithm side stuff to do quite a bit
of
it we'll have to get to that
it we'll have to get to that
soon likely next week I have two weeks
soon likely next week I have two weeks
coming up where I'm going to have
coming up where I'm going to have
basically nothing to do other than just
basically nothing to do other than just
stream dev all
stream dev all
which will be very
which will be very
nice and uh yeah we will go from
nice and uh yeah we will go from
there. So thanks to folks watching I'll
there. So thanks to folks watching I'll
be back in a few days and if you're
be back in a few days and if you're
interested in my work generally or
interested in my work generally or
trying to get into
trying to get into
RLP.ai it's all open source start the
RLP.ai it's all open source start the
repo to help us out. We would love to
repo to help us out. We would love to
hit 2K pretty soon and join the Discord
hit 2K pretty soon and join the Discord
to get involved and follow me on X for
to get involved and follow me on X for
more RL content.

Kind: captions
Language: en
Okay.
Okay.
Hi, we're live just for a short bit
Hi, we're live just for a short bit
right
right
now. I have to deal with admin stuff all
now. I have to deal with admin stuff all
day because I am going away for the
day because I am going away for the
weekend. That means no all day Saturday
weekend. That means no all day Saturday
devst stream, which sucks. Very much
devst stream, which sucks. Very much
like to be doing an all day Saturday dev
like to be doing an all day Saturday dev
stream instead of whatever the hell I'm
stream instead of whatever the hell I'm
going to be doing. But, uh, you know,
going to be doing. But, uh, you know,
there's some stuff that has to be taken
there's some stuff that has to be taken
care of, so no big deal. Um, all I want
care of, so no big deal. Um, all I want
to do right now is not really do any
to do right now is not really do any
real dev. Just check a couple of
real dev. Just check a couple of
experiments, figure out some good
experiments, figure out some good
experiments to run, set them up on a few
experiments to run, set them up on a few
machines, and call it a day. That's
it. So, um, I have it right
it. So, um, I have it right
here. So, this is pretty cool. We have
here. So, this is pretty cool. We have
soda on neural MMO with the latest
soda on neural MMO with the latest
experiment. Um, right
experiment. Um, right
here you can see this is
here you can see this is
4.5. So if we go back to 4.5
4.5. So if we go back to 4.5
here, this is 43 billion steps. So this
here, this is 43 billion steps. So this
run is more than 2x better than this run
run is more than 2x better than this run
just because I fixed some seating stuff.
just because I fixed some seating stuff.
And uh if you kind of draw this line
And uh if you kind of draw this line
up, it's getting pretty shallow, but you
up, it's getting pretty shallow, but you
think that this would get to five or so,
think that this would get to five or so,
right? This is probably going to get to
right? This is probably going to get to
around
around
five if it uh
five if it uh
finishes. So, soda at five. Pretty damn
finishes. So, soda at five. Pretty damn
good. That is a quarter of the way to
good. That is a quarter of the way to
solve. So, we've gone from a tenth up to
solve. So, we've gone from a tenth up to
a quarter in uh the last couple of
a quarter in uh the last couple of
weeks, which is very, very nice. Uh I
weeks, which is very, very nice. Uh I
don't think that these policies are
don't think that these policies are
going to be they're not quite to the
going to be they're not quite to the
point where they're going to look really
point where they're going to look really
good if you're watching them. That's
good if you're watching them. That's
probably, if I had to guess, somewhere
probably, if I had to guess, somewhere
around 8 to 10. So, long way off, but
around 8 to 10. So, long way off, but
it's definitely a start.
it's definitely a start.
So,
So,
um I'm trying to think what experiments
um I'm trying to think what experiments
I can
I can
run
run
because we kind of have everything log
because we kind of have everything log
linear right
linear right
now is not
ideal. Maybe we look at loss real
quick. Okay, Kale's
quick. Okay, Kale's
flat clip bracket stable.
Entropy is
stable. This is very spiky
stable. This is very spiky
actually. Gradient
actually. Gradient
variance
variance
KL. Okay, there's a small KL gap.
KL. Okay, there's a small KL gap.
value loss very
low. I think at least one of these is
low. I think at least one of these is
worth just running another
worth just running another
hyperparameter
hyperparameter
sweep. I think I'd probably get two
sweep. I think I'd probably get two
experiments to
run. Plus, when this one this one has
run. Plus, when this one this one has
like another 24 hoursish on it, then
like another 24 hoursish on it, then
when this one finishes, I get to run
when this one finishes, I get to run
something else.
Um, the real question is how much is
Um, the real question is how much is
left in hyper pram
sweeps. Sweep those
sweeps. Sweep those
hypers. Oh
hypers. Oh
yeah. Well, I mean, they've made a huge
yeah. Well, I mean, they've made a huge
difference everywhere else. It's just
difference everywhere else. It's just
harder to do here because from my
harder to do here because from my
experience, you can't just do even a one
experience, you can't just do even a one
billion step hyperparam sweep. That's
billion step hyperparam sweep. That's
already insane to talk about a 1 billion
already insane to talk about a 1 billion
step per experiment hyperparam sweep,
step per experiment hyperparam sweep,
but that's not even good enough. You
but that's not even good enough. You
kind of have to do like five or 10
kind of have to do like five or 10
billion hyperpar sweep. So, I can
billion hyperpar sweep. So, I can
do, you know, you only get a few
do, you know, you only get a few
experiments a day like
that. So, I think one of these machines
that. So, I think one of these machines
is just going to be a longunning job
is just going to be a longunning job
that hopefully doesn't
that hopefully doesn't
crash.
crash.
Um, seeing what we can get better out of
Um, seeing what we can get better out of
this, maybe like a 10
this, maybe like a 10
billion. Can you estimate the curve?
billion. Can you estimate the curve?
Nope, you can't. This is why it's so
Nope, you can't. This is why it's so
important the puffer is fast because if
important the puffer is fast because if
we were stuck doing that, we would we'd
we were stuck doing that, we would we'd
be nowhere right now. And I can prove it
be nowhere right now. And I can prove it
to you.
So this is the result of uh we have like
So this is the result of uh we have like
this 1 billion sweep here and you can
this 1 billion sweep here and you can
see like stuff up here has like really
see like stuff up here has like really
really steep slope but it's not actually
really steep slope but it's not actually
predictive of where it's going to
predictive of where it's going to
converge. Like these things just level
converge. Like these things just level
out early. And I have some other runs
out early. And I have some other runs
here somewhere where I even ran some of
here somewhere where I even ran some of
these for a little
these for a little
longer. Oh yeah, there you go.
longer. Oh yeah, there you go.
So, you know, we have all sorts of
So, you know, we have all sorts of
different runs here. Some of these look
different runs here. Some of these look
really good even, but um they all tend
really good even, but um they all tend
to level out if you just run them
longer here. This is one of them
right.
Yeah, this was PSGD.
Now, you know, I do wonder if there was
Now, you know, I do wonder if there was
something to it here, though, with
the like some annealing factor here.
Try just fitting a
spline. I mean, you can kind of see from
spline. I mean, you can kind of see from
these though, right?
these though, right?
Like you end up getting like shapes like
Like you end up getting like shapes like
this and
this and
this where this one looked really good
this where this one looked really good
and then it levels off. I think I have
and then it levels off. I think I have
some of these that I ran for longer as
some of these that I ran for longer as
well. Actually, it might be this right
well. Actually, it might be this right
here. Let me see.
Yeah. So, here you go. If I zoom it to
Yeah. So, here you go. If I zoom it to
here. So, this was me taking one of the
here. So, this was me taking one of the
better runs, right? This one looks
better runs, right? This one looks
really good. This one's way above all my
really good. This one's way above all my
other ones. And it levels off and it
other ones. And it levels off and it
kind of intersects with them around 5
billion. Maybe five billion steps is
billion. Maybe five billion steps is
going to be enough.
Need more hardware. Well, we have some
Need more hardware. Well, we have some
hardware. I haven't been like doing
hardware. I haven't been like doing
distributed sweeps or anything
yet. We just got our first 5090 box
yet. We just got our first 5090 box
in. And I'm actually the trip I'm taking
in. And I'm actually the trip I'm taking
this weekend is to tour the new facility
this weekend is to tour the new facility
that uh we're going to have ready in
that uh we're going to have ready in
about a month. So, we're going to be
about a month. So, we're going to be
able to start purchasing more hardware.
able to start purchasing more hardware.
The existing hardware that we move there
The existing hardware that we move there
is going to be way more stable, have way
is going to be way more stable, have way
more consistent power, hopefully more
more consistent power, hopefully more
consistent internet.
Well, I don't I don't know how much
Well, I don't I don't know how much
you've been around here, but the if you
you've been around here, but the if you
see like how much we're already
see like how much we're already
running, even if I'm running the sweep
running, even if I'm running the sweep
on one GPU, this runs like at least 100
on one GPU, this runs like at least 100
times faster than anything comparable in
times faster than anything comparable in
academia. So, my one GPU may as well be
academia. So, my one GPU may as well be
100 GPUs, right, for this sweep. And
100 GPUs, right, for this sweep. And
actually we have 10 GPUs right now. So
actually we have 10 GPUs right now. So
we may as well have a thousand GPUs for
we may as well have a thousand GPUs for
research, right? That's kind of the key
research, right? That's kind of the key
with all of
with all of
this. This x-axis here on this whole
this. This x-axis here on this whole
graph for the full run here, this is 100
graph for the full run here, this is 100
billion steps. This is equal to this
billion steps. This is equal to this
thing playing 2,000 years worth of
thing playing 2,000 years worth of
games. So this plot here, like including
games. So this plot here, like including
all these, has like probably 8,000 years
all these, has like probably 8,000 years
worth of games played on it.
worth of games played on it.
No more. 10,000 years worth of games
No more. 10,000 years worth of games
played on it. It's kind of crazy.
I think we just run a few quick tests on
I think we just run a few quick tests on
this and make sure we don't OM on the
this and make sure we don't OM on the
biggest settings. We launched like a
biggest settings. We launched like a
really nice five bill hyper pram
sweep. Does that make sense? So that's
sweep. Does that make sense? So that's
like right here on the
like right here on the
graph. Right
graph. Right
here. Yeah. X is slow. The Twitch and
here. Yeah. X is slow. The Twitch and
YouTube ones are faster. I'm live there
YouTube ones are faster. I'm live there
as well.
X is the best for the notifications
X is the best for the notifications
though. So you also post stuff
there. It's a lot more likely to be
there. It's a lot more likely to be
predicted by
predicted by
Isn't
Isn't
it? And look at this
it? And look at this
thing. It literally your previous soda
thing. It literally your previous soda
run
run
here. It intersects all the way out here
here. It intersects all the way out here
at 30. What's this? 25
at 30. What's this? 25
bill. That's
bill. That's
crazy. Can't do a 25 bill hyperpar
crazy. Can't do a 25 bill hyperpar
sweep.
It's like a day per
It's like a day per
experiment
almost 16
hours. 10's pushing
hours. 10's pushing
it. I think five is going to be what we
it. I think five is going to be what we
want. Kind of the best we can
do. How good do you think we can do in
do. How good do you think we can do in
five? I think
five? I think
optimistically we can probably get three
optimistically we can probably get three
by
five. That should be high
five. That should be high
enough. Three is non-trivial performance
enough. Three is non-trivial performance
on the test.
Uh Jay's bar is 5341. It's the same as
Uh Jay's bar is 5341. It's the same as
my X
handle. So, we're going to try
this. What else do we try, though?
I wouldn't be surprised if after this
I wouldn't be surprised if after this
it's
it's
like data and architecture
honestly. What about cosine and
honestly. What about cosine and
kneeling? We don't have that on, do
kneeling? We don't have that on, do
we?
Welcome. We don't have cosine and
Welcome. We don't have cosine and
kneeling on cuz I messed up the
kneeling on cuz I messed up the
implementation,
right? Or do
right? Or do
we? We might have it on. Hang on. I
we? We might have it on. Hang on. I
actually don't
know. Okay, we can't commit this is
know. Okay, we can't commit this is
because I have this a mess.
No, we do have it
No, we do have it
on
data.sculer.step. Did I implement this
data.sculer.step. Did I implement this
thing
correctly? Yes, it is because it's wraps
correctly? Yes, it is because it's wraps
the
the
optimizer. So, we do have cosine nailing
optimizer. So, we do have cosine nailing
on already. So, that's fine.
on already. So, that's fine.
So, we just
So, we just
do one machine hyper sweep. What else
do one machine hyper sweep. What else
can I run that would be
good? I could massively scale the
network. That seems wrong to me.
Scaling the network just gave me
Scaling the network just gave me
this. It's
not It's not going to solve the
not It's not going to solve the
task. Weight
task. Weight
decay. Omega. Does
decay. Omega. Does
this Okay, here. Question for you. I'm
this Okay, here. Question for you. I'm
gonna run a hyperparameter sweep on this
gonna run a hyperparameter sweep on this
because this what like look I I have to
because this what like look I I have to
just express to you how ridiculous this
just express to you how ridiculous this
task is.
task is.
Okay, so this is like I don't even know
Okay, so this is like I don't even know
experiments. These are 1 billion steps
experiments. These are 1 billion steps
each. I'm going to run an experiment a
each. I'm going to run an experiment a
sweep where each run is five billion
sweep where each run is five billion
steps. So these are
steps. So these are
chunky. If there's more if there are
chunky. If there's more if there are
more
more
techniques, you would hope that they're
techniques, you would hope that they're
stable enough that you could get
stable enough that you could get
something out of them just sweeping that
something out of them just sweeping that
one parameter with the optimals. If I
one parameter with the optimals. If I
have to sweep the [ __ ] weight decay
have to sweep the [ __ ] weight decay
or whatever a new technique and then
or whatever a new technique and then
reweep all the other parameters for it
reweep all the other parameters for it
to work, then that's kind of
to work, then that's kind of
ass. Also, a lot of these are PSGD.
If you get like any indication that PSGD
If you get like any indication that PSGD
is likely to be good on neural MMO, I
is likely to be good on neural MMO, I
will be more than happy to run that
will be more than happy to run that
experiment. But what happened with PSGD
experiment. But what happened with PSGD
so far is it starts off really good
so far is it starts off really good
early and then it actually levels out
early and then it actually levels out
and it's worse than muon without even
and it's worse than muon without even
fully optimized muon
performance. This is the current. We
performance. This is the current. We
beat soda by a factor of two in terms of
beat soda by a factor of two in terms of
time taken.
time taken.
I just fixed all the random
I just fixed all the random
seating. But by the way, this one
seating. But by the way, this one
literally it doesn't learn anything for
literally it doesn't learn anything for
five billion steps and then it takes
five billion steps and then it takes
off. That's how crazy this stuff
off. That's how crazy this stuff
is. So we're at
is. So we're at
4.8ish after 65 billion steps is
4.8ish after 65 billion steps is
currently
currently
soda. This will probably be five at 100
soda. This will probably be five at 100
bill. The curves are quite stable.
It could just make the net dramatically
It could just make the net dramatically
bigger. I really
could. What do we think we would get out
could. What do we think we would get out
of it?
I still think the best case scenario of
I still think the best case scenario of
that is that it gets like
six. Well, what do I think the best case
six. Well, what do I think the best case
is out of the hyper pram
sweep? Do I really think the hyper pram
sweep? Do I really think the hyper pram
sweep is going to make that big a
sweep is going to make that big a
difference? Kind of.
difference? Kind of.
Yeah, I kind of
Yeah, I kind of
do. Let me go check this
do. Let me go check this
experiment. See what I ran this
with. So this
is Oops.
Um, well, this is still running even
Um, well, this is still running even
though the driver is cracked. So, that's
though the driver is cracked. So, that's
cool.
You know, I could actually see the hyper
You know, I could actually see the hyper
pram sweep making a big difference. Are
pram sweep making a big difference. Are
you using heavy ball? Yeah, this is
you using heavy ball? Yeah, this is
heavy ball. Mulan.
We do a restricted set
sweep. 4 m
two. It's pretty
two. It's pretty
good. Okay, I think I know what I'm
good. Okay, I think I know what I'm
going to
do. This is already master.
[Music]
What's this damn machine called fault?
How do I forget my own SSH
password? There we go.
Do you ever think you'll work in
industry? I mean, what does this count
as,
as,
right? This is I mean, this is a
right? This is I mean, this is a
startup where we offer priority service
startup where we offer priority service
to companies in industry that want to do
to companies in industry that want to do
RL and have an easier time of it, make
RL and have an easier time of it, make
stuff go faster, get their SIMs running
stuff go faster, get their SIMs running
better, apply all of our latest tools,
better, apply all of our latest tools,
get custom tools made,
get custom tools made,
right? So, if you mean, do you think
right? So, if you mean, do you think
I'll take a job at big tech? Probably
I'll take a job at big tech? Probably
not. You think I will like get closer to
not. You think I will like get closer to
a bunch of industry problems over time?
a bunch of industry problems over time?
Absolutely.
Yeah, I'm really specialized to
Yeah, I'm really specialized to
like I'm pretty damn good at making like
like I'm pretty damn good at making like
m mediumsized projects. very very simple
m mediumsized projects. very very simple
and compact and
and compact and
efficient. That's kind of where I'm
efficient. That's kind of where I'm
happiest,
happiest,
right? Cuz when you get into really big
right? Cuz when you get into really big
size projects, your impact as an IC goes
size projects, your impact as an IC goes
way down and it just becomes a
way down and it just becomes a
management ordeal of total
management ordeal of total
mess. I like to have projects that are
mess. I like to have projects that are
still a size where I can like get there
still a size where I can like get there
and really mess with the code myself.
L there's a bug in heavy ball. Look,
L there's a bug in heavy ball. Look,
Omid, just
like either run some stuff on
like either run some stuff on
Neuralarmmo or if you have some
Neuralarmmo or if you have some
promising initial stuff, I can run stuff
promising initial stuff, I can run stuff
on it,
on it,
right? Was about to kill
right? Was about to kill
me, man. She's cutting into your Twitch
me, man. She's cutting into your Twitch
dev stream random Thursday night
dev stream random Thursday night
whatever shenanigans.
So, let's see what we're going to
sweep. See what we are going to
sweep. You don't want to screw this
sweep. You don't want to screw this
up. I'm sweeping hidden
up. I'm sweeping hidden
size. Not sweeping numms
m sweeping total time
m sweeping total time
steps. We can sweep batch
size of this.
So this batch size can now be like
So this batch size can now be like
ridiculous this mini batch
ridiculous this mini batch
size because
size because
um we have gradient accumulation. So now
um we have gradient accumulation. So now
it cannot OM on us. Learning rate gets
it cannot OM on us. Learning rate gets
swept. Entropy gets swept. Gamma gets
swept. Entropy gets swept. Gamma gets
swept. Lambda gets
swept. Lambda gets
swept. Update epox doesn't get swept.
swept. Update epox doesn't get swept.
Screw that. It's going to stay at one.
Screw that. It's going to stay at one.
Value function coefficient can get
Value function coefficient can get
swept. Gradient can get
swept. Gradient can get
swept. BPT
swept. BPT
horizon go up to
horizon go up to
and get
swept. Adam beta
swept. Adam beta
1. This can still get
1. This can still get
swept. Adam epsilon can still get swept.
swept. Adam epsilon can still get swept.
Okay.
Don't need any of this
stuff. And then the only thing we need
stuff. And then the only thing we need
in
in
uh
three. Do we want to sweep the reward
three. Do we want to sweep the reward
coefficients? That's too much,
coefficients? That's too much,
right?
Think we just do
Think we just do
this total time
this total time
steps
steps
away. M goes
away. And now we're sweeping all the
away. And now we're sweeping all the
stuff that matters. We should be at
stuff that matters. We should be at
least. And then this has got to be five
least. And then this has got to be five
bill.
Bill with a
Bill with a
B. Freaking crazy to think
B. Freaking crazy to think
about. I want to OM this entire box.
That's so
fun. This is all
fun. This is all
good. Then we'll have to hope that this
good. Then we'll have to hope that this
is reasonable.
Holy hell. How do I have 1.6 terabytes
Holy hell. How do I have 1.6 terabytes
used?
We also have to make sure we don't
We also have to make sure we don't
forget to rebuild.
gigs per
experiment. 500
megs. I always forget the bloody command
megs. I always forget the bloody command
for
this overlay.
There we
go. Yeah. So that's insane.
I got to fix that. There's something
I got to fix that. There's something
wrong with the uh the model save and
wrong with the uh the model save and
checkpointing. I'm going to just adjust
checkpointing. I'm going to just adjust
the interval so we don't
OM. That's terrible on the hard drive as
OM. That's terrible on the hard drive as
well.
Okay, so there's 10k checkpoint
Okay, so there's 10k checkpoint
interval. Now, now the only thing I got
interval. Now, now the only thing I got
to remember to do and not screw up
to remember to do and not screw up
here, I remember this on the other
here, I remember this on the other
machine too. If I run something
there. Okay. So this is compiling the
there. Okay. So this is compiling the
new
new
version of the neural MMO
version of the neural MMO
binding. This is with the new Python C
binding. This is with the new Python C
API binding code. So if you look there,
API binding code. So if you look there,
it's not actually compiling any Syon for
it's not actually compiling any Syon for
neural MMO. This just C
neural MMO. This just C
Python right here. This is no
Python right here. This is no
Syon. So that'll be pretty nice.
Is this thing still
running?
running?
4.3. Hang on. What's still
4.3. Hang on. What's still
running? I mean, that's basically
running? I mean, that's basically
finished, but what the hell is it?
There must be another run that I'm not
There must be another run that I'm not
visualizing
here. It's like a 4.3
Weird. Well, it's not a soda run, so we
Weird. Well, it's not a soda run, so we
don't
care. This thing go
Yeah, not a soda run
Yeah, not a soda run
though. It's
decent. Not a soda run
decent. Not a soda run
though. Hang
on. All
right.
Um, this was the random seated run.
Um, this was the random seated run.
Okay. Are you using 204 2204?
Okay. Are you using 204 2204?
Uh, so our older containers are
Uh, so our older containers are
2204 and our newer containers are going
2204 and our newer containers are going
to be
to be
2404. I just started one of these
2404. I just started one of these
because we need drivers for90s now.
because we need drivers for90s now.
There are a bunch of annoying things
There are a bunch of annoying things
with 2404 though that need to be
with 2404 though that need to be
handled. So I don't recommend that until
handled. So I don't recommend that until
we uh we update our nice containers so
we uh we update our nice containers so
that you don't have to deal with it.
that you don't have to deal with it.
2204 is fine unless you have a
5090. Just making sure everything is
5090. Just making sure everything is
correct because if I screw this run up,
correct because if I screw this run up,
this is like a big
run. I highly doubt we run out
run. I highly doubt we run out
of anything on this.
of anything on this.
The one thing that really annoys me,
The one thing that really annoys me,
I'll say, with 2404, which we're going
I'll say, with 2404, which we're going
to patch in our container,
to patch in our container,
um, they adopted a new Python pep, which
um, they adopted a new Python pep, which
is like literally the dumbest thing I've
is like literally the dumbest thing I've
ever seen Python do. And that's saying
ever seen Python do. And that's saying
something where they basically don't let
something where they basically don't let
you install pip packages outside of a
you install pip packages outside of a
virtual M by default which is
virtual M by default which is
like if you need if you use virtual MS
like if you need if you use virtual MS
inside of Docker containers like please
inside of Docker containers like please
seek mental
seek mental
help. So I don't know what the hell
help. So I don't know what the hell
they're doing because it's
they're doing because it's
like so we're going to work around that.
Isn't something horribly wrong
here? Something's horribly wrong here.
I tested this and it worked.
Why do you find docker containers
Why do you find docker containers
useful using nountu service main dev? Is
useful using nountu service main dev? Is
there an additional benefit using the
there an additional benefit using the
docker? Absolutely there is.
docker? Absolutely there is.
So you kind of use one of two things,
So you kind of use one of two things,
right? use like a virtual M or a cond or
right? use like a virtual M or a cond or
whatever or you use a
whatever or you use a
container virtual M every time you want
container virtual M every time you want
a new one you have to rebuild the whole
a new one you have to rebuild the whole
damn
damn
thing and reinstall everything and it's
thing and reinstall everything and it's
a
a
pain and also everything's not even
pain and also everything's not even
guaranteed to work in that because you
guaranteed to work in that because you
have to have correct system
have to have correct system
packages in a Docker container I get the
packages in a Docker container I get the
same dev environment every time if I
same dev environment every time if I
want a brand new clean dev environment
want a brand new clean dev environment
where everything is guaranteed to work.
where everything is guaranteed to work.
It takes me 10 seconds. I run one
It takes me 10 seconds. I run one
command and I have a fresh development
command and I have a fresh development
environment in 10 seconds. And I have
environment in 10 seconds. And I have
the exact same development environment
the exact same development environment
locally as I have on our
locally as I have on our
servers. It's very very easy that way.
servers. It's very very easy that way.
Everybody can have their own as well. I
Everybody can have their own as well. I
can let I just have it so that when
can let I just have it so that when
people log into our servers, you just
people log into our servers, you just
get booted into your
get booted into your
container. And it's the same exact
container. And it's the same exact
development environment as if you use
development environment as if you use
your container at
your container at
home. So it's very very nice for
home. So it's very very nice for
that. Very quick quick to set up, you
that. Very quick quick to set up, you
know, reproducible dev environment.
I think this is actually
working. Well, this metric's
working. Well, this metric's
working. See
It's a log.
This line
This line
disappeared. I see it.
I don't know how that
I don't know how that
happened. Did I not commit it?
a
a
reward. That's
why. Yeah, this is why only the returns
why. Yeah, this is why only the returns
are
wrong. Only the returns are wrong.
I thought that uh we had
like doesn't seem to get zeroed
like doesn't seem to get zeroed
correctly.
How concerned am I about this?
moderately concerned.
Oh, because this is reward and not
Oh, because this is reward and not
return. Yeah, this is reward, not
return. Yeah, this is reward, not
return.
return.
Okay. Yeah, this is correct. This should
Okay. Yeah, this is correct. This should
fix
fix
it. We'll double check real quick.
Whatever. Broken ass
Whatever. Broken ass
driver. Just push it.
Now we should no longer see metric
Now we should no longer see metric
stacking up
stupidly. It wouldn't have hurt anything
stupidly. It wouldn't have hurt anything
until it overflowed,
until it overflowed,
but better not risk
but better not risk
it. I don't even know if it would have
it. I don't even know if it would have
overflowed in the time of the
overflowed in the time of the
experiment, but probably not. Still
experiment, but probably not. Still
better not to screw with it.
better not to screw with it.
Yeah, now that's actually
correct. Yeah, those metrics look
good. Okay, we leave this one
good. Okay, we leave this one
be and then we go run the second
be and then we go run the second
experiment, which
experiment, which
is is it box four the one I use?
I
don't this my
job. Yeah, this is my job. It's just
job. Yeah, this is my job. It's just
stuck. That's fine.
This is going to be kind of
crazy. Big
model.
Instantly this
Instantly this
works. We will see
works. We will see
though. We will see.
37 million
37 million
per. I've not trained a model this big
per. I've not trained a model this big
in
in
years. And I know that's a crazy thing
years. And I know that's a crazy thing
to say because 37 mil is lower than uh
to say because 37 mil is lower than uh
what I was training in like
what I was training in like
20 17 or whatever, one of my first
20 17 or whatever, one of my first
projects, but it's very big for
projects, but it's very big for
RL. And to keep in mind the X-axis is so
RL. And to keep in mind the X-axis is so
much
much
longer in RL.
If this OOMs, we do have outs. As long
If this OOMs, we do have outs. As long
as it doesn't OM on the forward
as it doesn't OM on the forward
pass. If it OOMs in the backward pass,
pass. If it OOMs in the backward pass,
we have gradient accumulation to fall
we have gradient accumulation to fall
back
back
on. Cuz I do want to get some sleep
on. Cuz I do want to get some sleep
tonight. So, I just want to The goal is
tonight. So, I just want to The goal is
just to get this run going and go to
just to get this run going and go to
sleep.
sleep.
I guess technically I could run
I guess technically I could run
something on my personal box as well
something on my personal box as well
since I'm not going to be
here. I can also still use I could use
here. I can also still use I could use
this the dev box as well over the
this the dev box as well over the
weekend. Might be nice to have
one. Okay,
one. Okay,
so that forward time is
so that forward time is
nuts. Holy, look at
that. It shouldn't be that skewed,
that. It shouldn't be that skewed,
actually.
see anything weird in
here? That's actually kind of sketchy
here? That's actually kind of sketchy
that it's that
that it's that
skewed. Oh, it's the mini batch
skewed. Oh, it's the mini batch
size, you know. That's it. We can get
size, you know. That's it. We can get
this faster.
What is the accumulation
size faster? Can we make this
So somehow this balances out the compute
So somehow this balances out the compute
but it doesn't make it
but it doesn't make it
faster. Seems
weird. There's a more reasonable number
weird. There's a more reasonable number
though.
though.
97% GPU
97% GPU
set. That's something you don't see in
set. That's something you don't see in
RL
often. 181 hours for this whole
thing. It's a little
thing. It's a little
crazy. Oh, the value loss is screwed
crazy. Oh, the value loss is screwed
already. How's that happen?
Doesn't make much
sense. If I do this, is it not screwed?
Interesting. Doesn't blow
up. Unless it's blowing up now.
There it goes.
Watch this for a bit. Make sure it
Watch this for a bit. Make sure it
doesn't blow
up. Let me go uh blast the optimizer,
guys, because this not supposed to It
guys, because this not supposed to It
still [ __ ] blows
still [ __ ] blows
up. It still blows
up. It still blows
up. The
heck? Not supposed to happen.
Can I get away with half of that
size? Why is the thing suddenly blow up?
size? Why is the thing suddenly blow up?
Has never blown up before.
This
This
is better looking,
right? Nope. Still blows
right? Nope. Still blows
up. Am I like screwing up? like is it
up. Am I like screwing up? like is it
still not stable with
512? Let's see what
512? Let's see what
was the heck is going on
here. Now these are all
stable. This is like some small value,
right? See if this blows up.
Yeah, I literally can't train a bigger
Yeah, I literally can't train a bigger
model. That's
model. That's
weird. That's very
weird. That's
weird. That's
stable. You go over 512, it blows up.
It's bizaro.
Maybe it's cuz this thing is
bottlenecking. What's this map 2D
bottlenecking. What's this map 2D
output?
I owned myself with this stupid
I owned myself with this stupid
architecture. I swear.
That'll do it.
if this is stable.
So
So
recompile. So this is going to get rid
recompile. So this is going to get rid
of the uh 128 bottleneck on the most
of the uh 128 bottleneck on the most
important chunk of
observations. 128 might just be too
observations. 128 might just be too
small.
There's also just probably a lot of
There's also just probably a lot of
stuff modeled poorly in that network.
We'll see if this is
We'll see if this is
stable. Doesn't take too big of a hit.
That looks stable
That looks stable
enough. Whether it makes a difference,
enough. Whether it makes a difference,
we will see.
we will see.
But uh this could very
But uh this could very
well the
difference. Give this some experiments.
Okay, we are
Okay, we are
set. We have experiments
set. We have experiments
running. Hopefully they are
running. Hopefully they are
stable. Check the discboard real quick.
Doesn't look like anything super
Doesn't look like anything super
urgent, but so here's the
urgent, but so here's the
plan. I am traveling
plan. I am traveling
tomorrow. I'm traveling back on
tomorrow. I'm traveling back on
Monday. Won't be able to stream, but
Monday. Won't be able to stream, but
we'll answer stuff on the
we'll answer stuff on the
Discord. I still will get some work in
Discord. I still will get some work in
on
on
Saturday. So, we'll see if I can
Saturday. So, we'll see if I can
find a cool thing to do there to about
find a cool thing to do there to about
when I get back. I have a couple ideas
when I get back. I have a couple ideas
for stuff I've wanted a day to work on.
Um, other than
that, experiments are running. New infra
that, experiments are running. New infra
bindings and bindings to Python are
bindings and bindings to Python are
really, really
really, really
nice. Muan's been doing great.
nice. Muan's been doing great.
only hyperp finicky one is neural MMO
only hyperp finicky one is neural MMO
which is by far the hardest problem but
which is by far the hardest problem but
the curves are
the curves are
clean and the network is probably
clean and the network is probably
there's some room for
improvement there's some still more
improvement there's some still more
algorithm side stuff to do quite a bit
algorithm side stuff to do quite a bit
of
it we'll have to get to that
it we'll have to get to that
soon likely next week I have two weeks
soon likely next week I have two weeks
coming up where I'm going to have
coming up where I'm going to have
basically nothing to do other than just
basically nothing to do other than just
stream dev all
stream dev all
which will be very
which will be very
nice and uh yeah we will go from
nice and uh yeah we will go from
there. So thanks to folks watching I'll
there. So thanks to folks watching I'll
be back in a few days and if you're
be back in a few days and if you're
interested in my work generally or
interested in my work generally or
trying to get into
trying to get into
RLP.ai it's all open source start the
RLP.ai it's all open source start the
repo to help us out. We would love to
repo to help us out. We would love to
hit 2K pretty soon and join the Discord
hit 2K pretty soon and join the Discord
to get involved and follow me on X for
to get involved and follow me on X for
more RL content.
