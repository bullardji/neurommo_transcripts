Kind: captions
Language: en
Hello,
Hello,
we are back live.
we are back live.
Hi.
I am late today once again
I am late today once again
with a good reason for the most part.
with a good reason for the most part.
I actually got up pretty early this
I actually got up pretty early this
morning.
morning.
I started working on a new article for
I started working on a new article for
you all.
you all.
I think it's one that people will really
I think it's one that people will really
like, but it's going to take quite a bit
like, but it's going to take quite a bit
more work.
more work.
I literally just wrote the intro
I literally just wrote the intro
sections today.
Hopefully that'll be out within the next
Hopefully that'll be out within the next
couple of weeks. See?
couple of weeks. See?
So, what are we going to do today?
today.
First of all, we have this nice sweep
First of all, we have this nice sweep
result where we've solved 2048 pretty
result where we've solved 2048 pretty
well, apparently.
well, apparently.
But what we're going to do today is
But what we're going to do today is
we're going to work on the drone sim for
we're going to work on the drone sim for
a bit.
a bit.
That's like the main plan.
Specifically,
I think we're just going to formulate
I think we're just going to formulate
the uh the drone
the uh the drone
objective as go to point and don't
objective as go to point and don't
collide
collide
and like most things will be some
and like most things will be some
combination of go to point and don't
combination of go to point and don't
collide for this them specifically
take a quick look at the current thing
this is what we have All right,
got a model.
Got to mess with these reward functions.
Got to mess with these reward functions.
So,
most of these are not that bad.
most of these are not that bad.
I think the only thing that really needs
I think the only thing that really needs
to change is
the orbit one.
Probably the orbit one.
I need to generate points on a sphere.
What's a good number of8 Eight
any I think like four.
What's the easiest way to do this? So I
What's the easiest way to do this? So I
want to generate points
want to generate points
on a sphere.
This is going to be some obnoxious
This is going to be some obnoxious
function actually, isn't it?
I don't know. Let's do
All right.
This is the type of thing though that's
This is the type of thing though that's
done very quickly in a shader.
See
if I can get a reasonable function.
Okay. So you get the cartisian
Okay. So you get the cartisian
coordinates
coordinates
from the conversion to spherical. I
from the conversion to spherical. I
don't know why you do it angular, but
don't know why you do it angular, but
sure.
M rings.
That's like super obnoxious.
Should be able to do it
Should be able to do it
as a pure function of time.
Oh yeah, I also I forgot that I posted
Oh yeah, I also I forgot that I posted
uh the trailer to YouTube
of the neural MMO channel.
We have this one which is posted.
Why is it CCD?
Why is it CCD?
Welcome to the boot. Oh, that's close
Welcome to the boot. Oh, that's close
captions.
Okay. So, they both have I don't know
Okay. So, they both have I don't know
some small number of views.
some small number of views.
Well, the guys I'm on these posted um I
Well, the guys I'm on these posted um I
forget what 12. Okay. 13 hours ago.
forget what 12. Okay. 13 hours ago.
Cool. Trailers are up.
Yeah, I think regardless of how I do
Yeah, I think regardless of how I do
this, it's going to be annoying,
this, it's going to be annoying,
but we'll just start on
I really don't like this type of Well,
I really don't like this type of Well,
to be fair, if I as long as I get it, I
to be fair, if I as long as I get it, I
can verify that this is correct
can verify that this is correct
separately, I guess, and then I can do
separately, I guess, and then I can do
the RL. So, normally I'm very adverse to
the RL. So, normally I'm very adverse to
doing anything remotely janky because
doing anything remotely janky because
then RL makes it way worse.
then RL makes it way worse.
Thanks for sending over some drone kit.
Thanks for sending over some drone kit.
Of course, Ben, have you gotten any more
Of course, Ben, have you gotten any more
of it?
of it?
They should all be there somewhat soon.
Heck yeah, man.
Heck yeah, man.
I'm still working on the drone stuff. I
I'm still working on the drone stuff. I
realized that we can do a lot of demos
realized that we can do a lot of demos
just as a function of like go to
just as a function of like go to
position but with just like different
position but with just like different
versions of that basically. So, I'm
versions of that basically. So, I'm
working on that right
Okay.
Kind of need the index, don't you?
super annoying. Works
Well,
Well,
let's just say for now
let's just say for now
going to do
is so incredibly jank.
Arrow and Omega
Arrow and Omega
Radius.
Fine.
Fine.
Guess that's spiral to cartisian.
Guess that's spiral to cartisian.
Maybe something like this is not
Maybe something like this is not
terrible.
All we have to do is set a uh a per
All we have to do is set a uh a per
drone target, right?
So, we just do
Move this to here.
You know, this is actually not going to
You know, this is actually not going to
be bad.
be bad.
I could use a little bit of just chill
I could use a little bit of just chill
work like this for a bit.
work like this for a bit.
The only mildly annoying thing is the um
The only mildly annoying thing is the um
the sphere math.
I think if we're clever here, I can
I think if we're clever here, I can
probably uh come up with a whole bunch
probably uh come up with a whole bunch
of
of
cool demos just based on this one simple
cool demos just based on this one simple
thing.
Okay. So, in reset,
this needs to move
this needs to move
up to here.
Now all the agents have different
Now all the agents have different
targets.
We can do update target.
Now, this is actually going to be the
Now, this is actually going to be the
same exact thing as before, just way
same exact thing as before, just way
easier,
easier,
right?
Okay. Solid.
What are you using that auto complete.
What are you using that auto complete.
Is this just now
Okay. Okay. So for idle targets
can probably do like um
can probably do like um
where's the sphere velocity thing?
this thing right
think how we're going to synchronize
think how we're going to synchronize
this for
for everything.
Do we do it based on the initial?
Do we do it based on the initial?
Hope it doesn't diverge.
Oh, I don't like that.
Leave it like this for now.
Oh yeah. Is it Was it It's
bit. So yeah, this works.
bit. So yeah, this works.
This here works.
And what else did we have? We had
And what else did we have? We had
follow.
follow.
This was the one that I didn't know how
This was the one that I didn't know how
to do cleanly.
This is technically like a move target I
This is technically like a move target I
guess,
guess,
right?
right?
This can be move target
and then this one can be
This is going to collapse them all to
This is going to collapse them all to
one target for now.
one target for now.
Okay.
Now we have something like this.
have to do
going to be distance reward.
This gives us position target.
Uh yeah, not this at all though. I wish
Uh yeah, not this at all though. I wish
I could disable multi-line.
And then what was the reward I came up
And then what was the reward I came up
with? Yeah, negative.
with? Yeah, negative.
So we just do reward plus
So we just do reward plus
float
negative distance over max distance.
negative distance over max distance.
So
your distance reward
your distance reward
times density.
So I believe this is going to one minus
Okay, cool. So, compute reward.
Okay, cool. So, compute reward.
Now, all this needs doesn't need decks
Now, all this needs doesn't need decks
anymore. So, that's cool.
Hey, Major.
Hey, Major.
Daily grind continues as per usual.
Speaking of which, we have the daily
Speaking of which, we have the daily
grind of fly killing because I had some
grind of fly killing because I had some
maintenance work and I see three flies
maintenance work and I see three flies
that I may as well just kill now while
that I may as well just kill now while
that's easy to do. So,
One
- 3
- 4.
I actually have thought about doing an
I actually have thought about doing an
RL trained laser turret in moments of
RL trained laser turret in moments of
frustration.
Seems like a lot of work and I don't
Seems like a lot of work and I don't
think I'd be able to actually sell them
think I'd be able to actually sell them
for any reasonable amount of money.
for any reasonable amount of money.
You'd probably just get sued for
You'd probably just get sued for
blinding people with them.
blinding people with them.
That's my guess.
I would very much like to just back the
I would very much like to just back the
damn things though.
Yeah, I've been working on uh one of the
Yeah, I've been working on uh one of the
things I've been working on here is
things I've been working on here is
trying to figure out how we can just
trying to figure out how we can just
reduce the number of stuff that gets in.
reduce the number of stuff that gets in.
It is a farm and lots of just bugs and
It is a farm and lots of just bugs and
things get in. And man, it's like you
things get in. And man, it's like you
think, oh yeah, it's no big deal. You
think, oh yeah, it's no big deal. You
deal with a bug once in a while. But the
deal with a bug once in a while. But the
thing is, when you have stuff that like
thing is, when you have stuff that like
lands on you once in a while, right, and
lands on you once in a while, right, and
you look and oh shoot, it's a bug, like
you look and oh shoot, it's a bug, like
every single time something slightly
every single time something slightly
itches,
itches,
you will think, "Oh, it's a bug." And it
you will think, "Oh, it's a bug." And it
will drive you insane.
Incredibly annoying. Yeah.
Incredibly annoying. Yeah.
And actually, it's so buggy outside. I
And actually, it's so buggy outside. I
stopped running outside. Well, first of
stopped running outside. Well, first of
all, it's stupid hot here and I'm going
all, it's stupid hot here and I'm going
to be in California in a few weeks. I'll
to be in California in a few weeks. I'll
be able to run there anyways. But other
be able to run there anyways. But other
than that, like literally I went for a
than that, like literally I went for a
run for I think an hour and five minutes
run for I think an hour and five minutes
and I had like four or five golf balls
and I had like four or five golf balls
sized welts on my back by the end of it
sized welts on my back by the end of it
from just like big horse flies just
from just like big horse flies just
taking chunks out of me. You literally
taking chunks out of me. You literally
like rip like a horsefly off of you.
like rip like a horsefly off of you.
this mid run. It's horrible.
So, I've been Can you even see that
So, I've been Can you even see that
here? Yeah, you can probably see in the
here? Yeah, you can probably see in the
background. I got the bike and I've got
background. I got the bike and I've got
the URG.
the URG.
I think you should make some from
I think you should make some from
scratch tutorial videos for some DMs,
scratch tutorial videos for some DMs,
integrating them, designing reward
integrating them, designing reward
terminal conditions, adjusting
terminal conditions, adjusting
parameters, bugs, and sweeping
parameters, bugs, and sweeping
hyperparams because the articles are
hyperparams because the articles are
cool, but videos are always better and
cool, but videos are always better and
more appreciated. I'm actually going to
more appreciated. I'm actually going to
take that quote. I'm going to put it
take that quote. I'm going to put it
into the article that I'm working on
into the article that I'm working on
at the bottom right here. So, I remember
at the bottom right here. So, I remember
this. So, here's the issue with the
this. So, here's the issue with the
videos, right? Making good video
videos, right? Making good video
tutorials
tutorials
takes an utterly stupid amount of time.
takes an utterly stupid amount of time.
Like, a truly ludicrous amount of time.
Like the iceberg video that I published.
Like the iceberg video that I published.
But I would want to publish something at
But I would want to publish something at
least if I'm going to release videos,
least if I'm going to release videos,
right? I'd want to release something
right? I'd want to release something
that's as high quality as my iceberg
that's as high quality as my iceberg
video.
This was like this took me two weeks of
This was like this took me two weeks of
work. Language. This is like the highest
work. Language. This is like the highest
quality thing I could put out. All
quality thing I could put out. All
right. I put the tux on. I did all this
right. I put the tux on. I did all this
editing. I probably could have made the
editing. I probably could have made the
editing better if I just hired an editor
editing better if I just hired an editor
instead of doing it myself. We'll do
instead of doing it myself. We'll do
that in the future. But, you know, I
that in the future. But, you know, I
could have spent it would probably cost
could have spent it would probably cost
me, you know, a few thousand dollars at
me, you know, a few thousand dollars at
least to get a competent editor for
least to get a competent editor for
something this length.
something this length.
Uh, and this thing got over the last
Uh, and this thing got over the last
several months 3,500 views.
That's like simply not worth it.
That's like simply not worth it.
The articles on the other hand
The articles on the other hand
occasionally they take a lot less time
occasionally they take a lot less time
first of all and they occasionally do
first of all and they occasionally do
quite well. So this one that I wrote
quite well. So this one that I wrote
here, right, this has gotten 100k views.
here, right, this has gotten 100k views.
This is actually like this is a
This is actually like this is a
worthwhile investment of of my time to
worthwhile investment of of my time to
do stuff like this.
I am actually working on a much more in
I am actually working on a much more in
detailed article though. Much more in
detailed article though. Much more in
detailed article.
detailed article.
You'll get this in maybe a few weeks.
That one will take quite a bit longer to
That one will take quite a bit longer to
write, but nowhere near as long it was
write, but nowhere near as long it was
it would take to make a video.
a lot of value
doing for gamedev but you know
doing for gamedev but you know
a lot of yeah it's just like
if I were getting if people were
if I were getting if people were
actually like go like using them I would
actually like go like using them I would
do it. Um, but I can't like justify
do it. Um, but I can't like justify
taking two weeks
taking two weeks
to make like a tutorial of that form for
to make like a tutorial of that form for
people to not watch it when I also have
people to not watch it when I also have
a business to build.
a business to build.
And like I'm doing this double time
And like I'm doing this double time
basically as is. Not always double time,
basically as is. Not always double time,
not consistent, but very often working
not consistent, but very often working
double time.
I pretty much work double time until my
I pretty much work double time until my
I burn myself out and then I work normal
I burn myself out and then I work normal
hours for a week or two and then I do it
hours for a week or two and then I do it
again.
See the thing is like I literally did
See the thing is like I literally did
stuff like that before as well. The
stuff like that before as well. The
thing like when puffer when I did like
thing like when puffer when I did like
puffer 10
puffer 10
if you will check on the YouTube
I did like a seminar I did uh here
This is like a full walkthrough of the
This is like a full walkthrough of the
library. Didn't like nobody saw this.
library. Didn't like nobody saw this.
I' like I tried a few different
I' like I tried a few different
experiments and it just didn't catch on
experiments and it just didn't catch on
at all.
at all.
Really, the thing that has been best on
Really, the thing that has been best on
YouTube has just been the consistent
YouTube has just been the consistent
like people getting involved from the
like people getting involved from the
live streams.
And this was on a channel that's already
And this was on a channel that's already
had, you know, a couple thousand
had, you know, a couple thousand
subscribers on it as well because my uh
subscribers on it as well because my uh
my thesis defense video did very very
my thesis defense video did very very
well.
well.
But the uh the YouTube algorithm is
But the uh the YouTube algorithm is
super super fiddly and it's just like so
super super fiddly and it's just like so
uncertain if like technical content like
uncertain if like technical content like
this actually gets seen.
It was pretty rough. It's pretty rough
It was pretty rough. It's pretty rough
overall.
I also and I also don't enjoy it at all.
I also and I also don't enjoy it at all.
Like I like producing videos is like
Like I like producing videos is like
horrendously mind-numbing
horrendously mind-numbing
like time consuming boring work as well.
So, I basically have to torture myself
So, I basically have to torture myself
for like a few weeks to make a video,
for like a few weeks to make a video,
like a a long form video like
I know how we can do this.
I know how we can do this.
We can do it.
How about running streams and clipping
How about running streams and clipping
them and p pushing them
them and p pushing them
always general purpose and mostly mixed
always general purpose and mostly mixed
recreational programming way.
I might run some sort of tutorial on it.
I might run some sort of tutorial.
You do realize like for that type of
You do realize like for that type of
content, it's not as easy as like I just
content, it's not as easy as like I just
turn the stream on and like do a thing
turn the stream on and like do a thing
for 30 minutes and then clip. Like
for 30 minutes and then clip. Like
the quality of that is going to be like
the quality of that is going to be like
way way way lower versus something
way way way lower versus something
prepared.
That's super annoying.
There will be some more educational
There will be some more educational
content though. There will be
I have to figure out how to space it out
I have to figure out how to space it out
and like where to allocate the effort
and like where to allocate the effort
because you know my main thing is not
because you know my main thing is not
educational content. It's kind of just
educational content. It's kind of just
been like a recent thing that um Tuffer
been like a recent thing that um Tuffer
has become so like relatively so much
has become so like relatively so much
easier to use than everything else in RL
easier to use than everything else in RL
that we're getting like lots of new
that we're getting like lots of new
people which is awesome and many of them
people which is awesome and many of them
have actually gone on to be productive
have actually gone on to be productive
contributors to the research. uh it does
contributors to the research. uh it does
require me to rethink a few things as to
require me to rethink a few things as to
how they're framed because like when I
how they're framed because like when I
started Puffer Lib the initial audience
started Puffer Lib the initial audience
was RLP PhD and then it went down to
was RLP PhD and then it went down to
like you know ML PhD
like you know ML PhD
right and then it went down to like AI
right and then it went down to like AI
engineers and now we're at the point
engineers and now we're at the point
where we have literally brand new
where we have literally brand new
programmers doing this stuff it's like
programmers doing this stuff it's like
ah crap okay I didn't position this for
ah crap okay I didn't position this for
any of I didn't position this for that
any of I didn't position this for that
at all I have to figure out How to do
at all I have to figure out How to do
that?
that?
Implementation of N forX
Implementation of N forX
improving rewards network design
network
parts.
parts.
So like I can do that, right? But here's
So like I can do that, right? But here's
the thing. Here's the thing that's just
the thing. Here's the thing that's just
jank about that, right? If I did that as
jank about that, right? If I did that as
a prepared video,
a prepared video,
I could do that entire thing in like a
I could do that entire thing in like a
one hour lecture
one hour lecture
and like live with all the demos. I
and like live with all the demos. I
could do that whole thing in like a
could do that whole thing in like a
really good one hour lecture.
really good one hour lecture.
It would take me like
It would take me like
probably close to a month to make that
probably close to a month to make that
video.
video.
If I do it as a series of live streams,
If I do it as a series of live streams,
it's going to be like
It's not going to give you thorough
It's not going to give you thorough
coverage because like you're not going
coverage because like you're not going
to see all those different things in the
to see all those different things in the
context of several different examples
context of several different examples
and it's going to be like you know many
and it's going to be like you know many
hours
and people don't watch many hour videos.
and people don't watch many hour videos.
Turns out
I have been trying to clip some of the
I have been trying to clip some of the
educational like tips and things um and
educational like tips and things um and
start uploading like short little clips.
start uploading like short little clips.
It's a little tricky to do, but I've
It's a little tricky to do, but I've
been trying to figure that out, how to
been trying to figure that out, how to
do it more efficiently.
Like really, the main jam around here
Like really, the main jam around here
is improving the research. I have to
is improving the research. I have to
figure out how to still make that the
figure out how to still make that the
focus, right?
Okay. So, this map did not map like
Well, this is cool.
This is a good algorithm.
This is a good algorithm.
How the heck does this work?
Some sort of like serious
Some sort of like serious
Fibonacci number. That's weird.
Fibonacci number. That's weird.
Cool.
Some people watch actually watch them. I
Some people watch actually watch them. I
do.
do.
I watch long form stuff too. Very few
I watch long form stuff too. Very few
do.
Carpathia stuff of course.
I I interned in uh in Fe's lab I think
I I interned in uh in Fe's lab I think
in like 2014 or something when he was
in like 2014 or something when he was
still a student there.
He's a funny guy.
Yeah. Honestly, the probably the best
Yeah. Honestly, the probably the best
way to motivate me to uh make tutorials
way to motivate me to uh make tutorials
is to make bad tutorials.
So, we'll see how that goes. Um,
So, we'll see how that goes. Um,
let's see how this article that I'm
let's see how this article that I'm
working on goes first because like this
working on goes first because like this
should be a pretty good comprehensive
should be a pretty good comprehensive
article.
Actually, grab
Actually, grab
this stuff. Well,
this stuff. Well,
as references for like the type of stuff
as references for like the type of stuff
that people are interested in.
This
This
obviously that's not going in the
obviously that's not going in the
article. I'll use that to write stuff
article. I'll use that to write stuff
based on it.
Also, everybody wants more content.
Also, everybody wants more content.
Nobody wants to feed the puffer a star.
Nobody wants to feed the puffer a star.
Go star the repo. It's literally free.
Go star the repo. It's literally free.
Takes 5 seconds. Did the puffer a star?
Takes 5 seconds. Did the puffer a star?
He's hungry.
I opened a PR for the drone and
I opened a PR for the drone and
simple
simple
realistic motor. Okay, I will have to
realistic motor. Okay, I will have to
look at that in more detail. Major, let
look at that in more detail. Major, let
me I want to finish this thing right now
me I want to finish this thing right now
while I still like before I run out of
while I still like before I run out of
steam. I've already done a bunch of
steam. I've already done a bunch of
stuff this morning. Um, I want to have
stuff this morning. Um, I want to have
this environment done today so we have
this environment done today so we have
like a standalone second drone
like a standalone second drone
environment.
environment.
And then we're going to probably figure
And then we're going to probably figure
out a way to like pull out the drone so
out a way to like pull out the drone so
that the drone can just be the
that the drone can just be the
standalone thing and we can like do all
standalone thing and we can like do all
the physics tests including motor lag.
the physics tests including motor lag.
I will definitely incorporate that
I will definitely incorporate that
though if that is a a reasonable thing
though if that is a a reasonable thing
to model it.
Man,
Man,
I will say I'm very happy about the uh
I will say I'm very happy about the uh
the reason that I started writing this
the reason that I started writing this
article in the first place is that the
article in the first place is that the
last one did very well. So, if you want
last one did very well. So, if you want
me to write more articles or you want me
me to write more articles or you want me
to do more of a thing, you know, go post
to do more of a thing, you know, go post
and support the current thing because
and support the current thing because
that all helps.
The article,
The article,
this one,
this one,
the new article is literally just an
the new article is literally just an
introduction section. It doesn't have
introduction section. It doesn't have
any content in it yet.
any content in it yet.
I might like I might write on it on
I might like I might write on it on
stream uh either tomorrow or over the
stream uh either tomorrow or over the
next bit of the week. We'll see.
next bit of the week. We'll see.
when I'm like sick of coding stuff, I'll
when I'm like sick of coding stuff, I'll
write on things.
write on things.
We'll share code walk through.
We'll share code walk through.
Uh it's more of a how to learn RL thing
Uh it's more of a how to learn RL thing
in general. So, it's going to point you
in general. So, it's going to point you
to a lot of other resources.
to a lot of other resources.
The code that seems like stuff that's
The code that seems like stuff that's
like more for the docs.
Like it looks like you want like an
Like it looks like you want like an
expanded upon version of
expanded upon version of
of like this tutorial or whatever.
Expanded version of this tutorial.
I probably should add like a sweeps
I probably should add like a sweeps
thing to this. I could do that.
adding sweeps,
adding sweeps,
improving rewards.
Improving rewards I will talk about in
Improving rewards I will talk about in
the article. Network design I can
the article. Network design I can
probably talk about in the article.
Talk about sweeps in general for sure
Talk about sweeps in general for sure
and like common bugs.
The article will direct you on how to
The article will direct you on how to
like implement things and it will have
like implement things and it will have
you build things but it's not going to
you build things but it's not going to
directly be like this piece of code read
directly be like this piece of code read
now this piece of code read this etc
now this piece of code read this etc
etc.
All right, let me code my sphere. I got
All right, let me code my sphere. I got
to code my sphere.
to code my sphere.
Otherwise, we won't have drone things
Otherwise, we won't have drone things
Done.
You're also more than free to ask
You're also more than free to ask
questions here, Shadow, while um I'm
questions here, Shadow, while um I'm
working on stuff. That's kind of the
working on stuff. That's kind of the
point of the stream.
I'm Red Zep. Okay. You cannot people
I'm Red Zep. Okay. You cannot people
cannot possibly expect me to remember
cannot possibly expect me to remember
when they have different usernames. So,
when they have different usernames. So,
if I get confused, just remind me.
if I get confused, just remind me.
I have like a bunch of people on here
I have like a bunch of people on here
and then some people have like three or
and then some people have like three or
four different usernames on all the
four different usernames on all the
platforms.
platforms.
What are you trying to do? You trying to
What are you trying to do? You trying to
confuse me?
Oh yeah,
curriculum learning IRL.
The curriculum learning goal at the
The curriculum learning goal at the
moment,
it's to grow the puffer business so I
it's to grow the puffer business so I
can get back to doing real research.
far beyond many frameworks beat with the
far beyond many frameworks beat with the
simplicity. I mean, that's the goal.
simplicity. I mean, that's the goal.
It's simpler.
It's simpler.
It's simpler than everything, but Clean
It's simpler than everything, but Clean
RL, Clean RL is still kind of the best
RL, Clean RL is still kind of the best
for that. Um, but it is like a thousand
for that. Um, but it is like a thousand
times faster.
times faster.
It's not It's not that much more than
It's not It's not that much more than
Clean RL either. Especially some of the
Clean RL either. Especially some of the
recent Clean RL stuff where they like
recent Clean RL stuff where they like
import and use. Like some of the newer
import and use. Like some of the newer
Clean RL stuff actually imports garbage
Clean RL stuff actually imports garbage
from SP3.
from SP3.
Like the original Clean RL stuff that
Like the original Clean RL stuff that
Costa built is the best.
Costa built is the best.
Uh and like all the like the newer
Uh and like all the like the newer
stuff, it's just nah. Nobody nobody does
stuff, it's just nah. Nobody nobody does
anything like reasonably. It's such a
anything like reasonably. It's such a
pain.
Have you read the uh the quick the quick
Have you read the uh the quick the quick
start guide though? Shadow or Reds?
The quick start guide has a lot of good
The quick start guide has a lot of good
stuff in it.
The article I'm working on is going to
The article I'm working on is going to
basically be a very updated version of
basically be a very updated version of
that. Uh, pretty much all the advice
that. Uh, pretty much all the advice
that I give in there is still good.
that I give in there is still good.
So, it's just going to be like a bigger,
So, it's just going to be like a bigger,
more updated version of that that covers
more updated version of that that covers
more stuff.
But pretty much by the time like if
But pretty much by the time like if
you've built five environments, by like
you've built five environments, by like
environment number five, you're going to
environment number five, you're going to
be pretty good at this stuff.
[Music]
Big bold.
Ah.
Currently
training an agent to solve a very
training an agent to solve a very
complex robotic operation with long
complex robotic operation with long
horizon.
horizon.
Fortunately using Isaac lab skl, but
Fortunately using Isaac lab skl, but
we're considering integrating puffer
we're considering integrating puffer
liib for your model benchmarks. Issue is
liib for your model benchmarks. Issue is
developing the end and fixing the bugs
developing the end and fixing the bugs
taking some time. Yeah, Isaac will do
taking some time. Yeah, Isaac will do
that. I had to do some stuff with Isaac
that. I had to do some stuff with Isaac
Jim for a client. It was a pain. I don't
Jim for a client. It was a pain. I don't
know if you've seen in the last few
know if you've seen in the last few
days, we actually have Puffer Live
days, we actually have Puffer Live
working with Manny Scale. I can push
working with Manny Scale. I can push
some of this stuff if you want. Um, we
some of this stuff if you want. Um, we
will have it pushed anyways in a bit.
will have it pushed anyways in a bit.
Uh, that mostly just works. The only
Uh, that mostly just works. The only
thing is that the defaults that people
thing is that the defaults that people
use in robotics are moderately insane
use in robotics are moderately insane
for all their algorithms. So like
for all their algorithms. So like
pretty much it's going to take us quite
pretty much it's going to take us quite
a bit of optimization to make it as fast
a bit of optimization to make it as fast
or faster than the existing stuff in
or faster than the existing stuff in
that space. specifically because like
that space. specifically because like
the combination of insane reward
the combination of insane reward
functions and like weird model
functions and like weird model
architectures
architectures
and like weird hyperp combines to be
and like weird hyperp combines to be
this very locally optimal thing and you
this very locally optimal thing and you
kind of have to reoptimize everything in
kind of have to reoptimize everything in
order to like really beat it and uh
order to like really beat it and uh
that's just like kind of complicated
that's just like kind of complicated
like I have to set up a big sweep
like I have to set up a big sweep
basically to do that. So, that is in the
basically to do that. So, that is in the
cards and I was working on that earlier.
cards and I was working on that earlier.
That's this week. I kind of just got
That's this week. I kind of just got
bored. So, I wanted to do some of the
bored. So, I wanted to do some of the
drone stuff uh yesterday and today
they're not better than Isaac Lab. Isaac
they're not better than Isaac Lab. Isaac
Jim was just a student work.
They're not that better than Isaac lab.
How's the code? Like some of the
How's the code? Like some of the
packages that we had to work with in
packages that we had to work with in
Isaac gym were just awful. And from what
Isaac gym were just awful. And from what
I've seen, even like Isaac Sim, they
I've seen, even like Isaac Sim, they
still use the same packages. Like people
still use the same packages. Like people
like load, maybe this is humanoid
like load, maybe this is humanoid
specific, but they have like motion lib
specific, but they have like motion lib
and pose lib and like all these other
and pose lib and like all these other
just janky like an old horribly
just janky like an old horribly
overabstracted uh grad student code
overabstracted uh grad student code
libraries.
So Manny was at least like relatively
So Manny was at least like relatively
easier to get stuff set up and working.
Isaac Jim is better develop from
Isaac Jim is better develop from
scratch. Isaac lab.
scratch. Isaac lab.
Isaac can better develop from scratch.
Isaac can better develop from scratch.
Isaac lab. Finally.
Isaac lab. Finally.
Very similar to Manny's skill. slightly
Very similar to Manny's skill. slightly
more complex with more trying to relying
more complex with more trying to relying
on this. Yeah.
on this. Yeah.
So, I mean,
So, I mean,
robotics is an area that I don't really
robotics is an area that I don't really
intend to get super deep into quite soon
intend to get super deep into quite soon
unless it would basically it would take
unless it would basically it would take
a company being really really interested
a company being really really interested
in wanting to work with us uh to bring
in wanting to work with us uh to bring
our type of tech to robotics, then I
our type of tech to robotics, then I
would do it. But like it's not like a a
would do it. But like it's not like a a
short side project level of an effort,
short side project level of an effort,
right? Like I pretty much have to rip
right? Like I pretty much have to rip
apart the really overly abstracted way
apart the really overly abstracted way
that a lot of stuff is done in robotics
that a lot of stuff is done in robotics
and distill it down and simplify it and
and distill it down and simplify it and
then find all the things making stuff
then find all the things making stuff
slow and janky, right? That I'm sure are
slow and janky, right? That I'm sure are
there. It's the same thing I would I did
there. It's the same thing I would I did
with the rest of RL. I'd have to bring
with the rest of RL. I'd have to bring
over to robotics.
I basically I would it would have to be
I basically I would it would have to be
like a company would want to would have
like a company would want to would have
to want like a big contract for us to go
to want like a big contract for us to go
do that because otherwise it's a huge
do that because otherwise it's a huge
huge time investment that takes me off
huge time investment that takes me off
of a lot of the stuff I'm doing outside
of a lot of the stuff I'm doing outside
of
like the main thing I'm doing outside of
like the main thing I'm doing outside of
this stream now is basically
this stream now is basically
looking for pro like valuable problems
looking for pro like valuable problems
in industry to throw this stuff on. Um,
in industry to throw this stuff on. Um,
both because that's going to like really
both because that's going to like really
help us benchmark and test puffer, but
help us benchmark and test puffer, but
also uh you know that solves the that
also uh you know that solves the that
will solve the revenue
will solve the revenue
uh the revenue problem. So that'll like
uh the revenue problem. So that'll like
let us grow way more than we are at the
let us grow way more than we are at the
moment.
moment.
Reach out to you in the next three
Reach out to you in the next three
months. Would you be up for 12 months
months. Would you be up for 12 months
guaranteed collaboration?
guaranteed collaboration?
Yeah, I'd have to know more. Right. Um,
Yeah, I'd have to know more. Right. Um,
I don't know if you're at a company or a
I don't know if you're at a company or a
lab or what because we do some level of
lab or what because we do some level of
free support for laboratories. And then
free support for laboratories. And then
for companies, we do uh we do paid
for companies, we do uh we do paid
contracts
the company. Yeah, if you guys are
the company. Yeah, if you guys are
interested in something like that, we
interested in something like that, we
could definitely do that. And robotics
could definitely do that. And robotics
is one of the things that I've looked
is one of the things that I've looked
into that it like from what I've dealt
into that it like from what I've dealt
with it feels like it should be very
with it feels like it should be very
doable uh to bring like the puffer level
doable uh to bring like the puffer level
of advancements over to robotics. It's
of advancements over to robotics. It's
just like a fair bit more work than I'd
just like a fair bit more work than I'd
want to do as a side project outside of
want to do as a side project outside of
a contract.
a contract.
Yeah.
Yeah. We do two things at the moment,
Yeah. We do two things at the moment,
right? We do like smaller jobs that are
right? We do like smaller jobs that are
just like support extended support and
just like support extended support and
features and then we do larger things
features and then we do larger things
that are more like um
that are more like um
like fixed deliverables like hey we want
like fixed deliverables like hey we want
X built it's worth Y to us.
Help us do that.
Shadow, can I ask if it's humanoids or
Shadow, can I ask if it's humanoids or
if it's more like industrial?
if it's more like industrial?
Is it like industrial like armbbased
Is it like industrial like armbbased
stuff or is it humanoids?
Arm base. Okay, that's actually way
Arm base. Okay, that's actually way
better. But like industrial robotics, if
better. But like industrial robotics, if
I had to like do something in robotics
I had to like do something in robotics
and pick an entry point, that's the type
and pick an entry point, that's the type
of thing we'd be way more excited about
of thing we'd be way more excited about
because I think that's actually going to
because I think that's actually going to
have way higher impact than humanoids in
have way higher impact than humanoids in
the long term. Even if in the short term
the long term. Even if in the short term
we see like super hype all like tons of
we see like super hype all like tons of
companies buying humanoids yada yada I
companies buying humanoids yada yada I
think that folks will eventually realize
think that folks will eventually realize
that it's like woefully impractical to
that it's like woefully impractical to
have this one-sizefits-all but like
have this one-sizefits-all but like
really slow and expensive solution for
really slow and expensive solution for
everything. Um
I personally I would love to see like
I personally I would love to see like
industrial robotics like the arms moving
industrial robotics like the arms moving
at five times the pace that they
at five times the pace that they
currently move.
humanoids. Yeah, man. It's like
I kind of see why there's the appeal to
I kind of see why there's the appeal to
it, but like
it, but like
I don't think humanoid robots gets us
I don't think humanoid robots gets us
like sci-fi era awesome tech everywhere.
like sci-fi era awesome tech everywhere.
You know, that's kind of the way I look
You know, that's kind of the way I look
at a lot of stuff. Humanoids is like
at a lot of stuff. Humanoids is like
it's faster horses. You're basically
it's faster horses. You're basically
you're replacing human workers with
you're replacing human workers with
something that's going to be maybe about
something that's going to be maybe about
as effective as a human worker. Like
as effective as a human worker. Like
eh
exactly what we're doing.
exactly what we're doing.
Be happy to chat. Long horizon multitask
Be happy to chat. Long horizon multitask
optimize policies.
optimize policies.
I've actually been thinking about stuff
I've actually been thinking about stuff
like that and how you solve. So
like that and how you solve. So
basically, I could solve your long
basically, I could solve your long
horizon problem pretty much out of the
horizon problem pretty much out of the
box if your Sims were fast enough.
box if your Sims were fast enough.
That's the key annoyance at the moment.
That's the key annoyance at the moment.
Um,
Um,
so I've been thinking of like if there's
so I've been thinking of like if there's
a way to do like super low fidelity,
a way to do like super low fidelity,
very domain randomized, and then like
very domain randomized, and then like
fine-tune up to faster or like to
fine-tune up to faster or like to
slower, higher precision.
slower, higher precision.
There are a lot of knobs that need to be
There are a lot of knobs that need to be
messed with. The Sims are just really
messed with. The Sims are just really
slow right now.
I think that's the main annoyance.
I think that's the main annoyance.
It really doesn't feel to me like from
It really doesn't feel to me like from
first principles either that like
first principles either that like
you know if you can run a humanoid at
you know if you can run a humanoid at
10,000 steps per second statebased can
10,000 steps per second statebased can
only run an arm at like 40,000 steps per
only run an arm at like 40,000 steps per
second with the same settings. It seems
second with the same settings. It seems
like just like a six degree of freedom
like just like a six degree of freedom
arm. It seems to me like you should be
arm. It seems to me like you should be
able to run it at least in like hundreds
able to run it at least in like hundreds
of thousands with reasonable fidelity.
of thousands with reasonable fidelity.
and like current Sims just aren't doing
and like current Sims just aren't doing
it. I could be wrong, but just like
it. I could be wrong, but just like
based on what I know about the problem,
based on what I know about the problem,
given that they're not even doing like
given that they're not even doing like
they're not even doing like gel sensors
they're not even doing like gel sensors
or anything like that, it stuff should
or anything like that, it stuff should
be a lot faster than it is.
Like, oh, it's built on physics and
Like, oh, it's built on physics and
physics is fast, therefore our thing
physics is fast, therefore our thing
must be fast is not not really it.
must be fast is not not really it.
You know,
we're just two AI engineers and a plus
we're just two AI engineers and a plus
years of RL experience. Once we have a
years of RL experience. Once we have a
simple bug-free end, get to the level of
simple bug-free end, get to the level of
first real robot deployment, I'm going
first real robot deployment, I'm going
to call you. Sounds good.
to call you. Sounds good.
Yeah, man. Good luck with that. Robotics
Yeah, man. Good luck with that. Robotics
is hot at the moment, but it's also it's
is hot at the moment, but it's also it's
it's a tough problem in the sense that
it's a tough problem in the sense that
like all the Sims and tools are really
like all the Sims and tools are really
big and bloated. This is kind of the
big and bloated. This is kind of the
problem I had to solve with RL in
problem I had to solve with RL in
general, right? Like just stuff like
general, right? Like just stuff like
RLIB and SP3
RLIB and SP3
um and like Gym and Gymnasium with their
um and like Gym and Gymnasium with their
vectorzation and rappers and things.
vectorzation and rappers and things.
Everything was bloated and slow
Everything was bloated and slow
and you just had to like cut off all the
and you just had to like cut off all the
fat and it just took forever. But you
fat and it just took forever. But you
got we got to a point eventually where
got we got to a point eventually where
stuff is just good now.
For me, I've been working in RL since
For me, I've been working in RL since
well, I started neural MMO I believe in
well, I started neural MMO I believe in
20 2018, maybe 2017 or 2018.
That's when I started doing RL.
Okay. Why is the observation out of
Okay. Why is the observation out of
bounds here?
Fake
this change
one.
one.
9 13
How's this stuff out of bounds?
What I messed up here?
What I messed up here?
Says 31.
Funny.
RL lib kills me. I don't Yeah,
RL lib kills me. I don't Yeah,
the thing is
the thing is
the devs actually really tried hard with
the devs actually really tried hard with
that and like I know some of them.
that and like I know some of them.
It's just
It's just
I actually I got a message I think like
I actually I got a message I think like
from a random engineer not realizing
from a random engineer not realizing
like all the stuff I've done trying to
like all the stuff I've done trying to
hire me for like RL lib. I don't
It's like it's just not how you build
It's like it's just not how you build
for RL. You don't build a super heavy
for RL. You don't build a super heavy
fang style
fang style
product or a field where everything is
product or a field where everything is
cursed and breaks constantly. You build
cursed and breaks constantly. You build
the simplest, most compact possible
the simplest, most compact possible
thing, the smallest number of moving
thing, the smallest number of moving
parts. That's how you build it.
I've tried to help him a few different
I've tried to help him a few different
times as well, but
I don't know.
What the heck did I break? What did I
What the heck did I break? What did I
break here, man? This is simple.
break here, man? This is simple.
It's very simple. What did I break?
Welcome Jai.
Hey, Tyloian. Welcome.
Hey, Tyloian. Welcome.
Luck on runs.
We have one cool experiment. So, this is
We have one cool experiment. So, this is
a couple cool things. This is 2048. It
a couple cool things. This is 2048. It
looks like we've gotten some solves out
looks like we've gotten some solves out
of this.
of this.
And um we also have a pretty promising
And um we also have a pretty promising
neural MMO run over here. Very promising
neural MMO run over here. Very promising
actually.
actually.
So this is the current one and then this
So this is the current one and then this
is the uh the soda
is the uh the soda
from before.
from before.
So this is the uh the run that I wrote
So this is the uh the run that I wrote
my article about and this is the new
my article about and this is the new
run. So basically, if it gets the same
run. So basically, if it gets the same
sort of curvature, which it looks like
sort of curvature, which it looks like
it might start to be getting, then it
it might start to be getting, then it
should be state-of-the-art. We'll see.
should be state-of-the-art. We'll see.
Y'all with Muan.
If anybody wants to figure out how PSGD,
If anybody wants to figure out how PSGD,
like how to set up PSGD and have it
like how to set up PSGD and have it
actually work, uh, I'm open to trying
actually work, uh, I'm open to trying
other stuff as well. Like I can set up a
other stuff as well. Like I can set up a
big run like this, but some basically
big run like this, but some basically
you'd have to actually set it up so it's
you'd have to actually set it up so it's
not going to just crash instantly. We
not going to just crash instantly. We
don't want to do this.
This isund
This isund
something very odd is happening that
something very odd is happening that
this is out of bounds then, right?
should not be out of bounds.
Oh, plus task.
Hello study.
Welcome.
Oh, wait. This is out of bounds.
I'm dumb.
I'm dumb.
Yeah, I I have an off by one.
Yeah, I I have an off by one.
That's all it is.
Started ML like one month ago. Welcome
Started ML like one month ago. Welcome
to the space. There's lots of cool stuff
to the space. There's lots of cool stuff
you can do in here.
you can do in here.
Not good with the basics.
Not good with the basics.
I have uh references for new ML people
I have uh references for new ML people
that I always suggest.
The S231N is probably the best like
The S231N is probably the best like
one-stop shop overall deep learning
one-stop shop overall deep learning
reference. The lectures with either
reference. The lectures with either
Carpathy or Justin Johnson. Either of
Carpathy or Justin Johnson. Either of
those are good.
Do you think I should go further? It
Do you think I should go further? It
really depends on your level of
really depends on your level of
background and especially like how good
background and especially like how good
of a programmer you are. How's your
of a programmer you are. How's your
math? What areas are interesting to you?
math? What areas are interesting to you?
Like what do you want to do, right?
Like what do you want to do, right?
I have my quick start guide for RL on
I have my quick start guide for RL on
the uh the website puffer.ai. It's also
the uh the website puffer.ai. It's also
on X.
Okay. So if this works,
this is orbit.
Super super cool you live stream this. I
Super super cool you live stream this. I
wish more people did. Yeah, it's been
wish more people did. Yeah, it's been
fun. I uh I like live streaming all the
fun. I uh I like live streaming all the
work.
It's been great for the project as well.
It's been great for the project as well.
We've had like several people from the
We've had like several people from the
live stream come and just say, "Hey, you
live stream come and just say, "Hey, you
know, I want to start building some
know, I want to start building some
stuff." And uh you know, many have been
stuff." And uh you know, many have been
very successful at it even without AI
very successful at it even without AI
experience.
experience.
Thinking of being a quant analyst,
Thinking of being a quant analyst,
I don't think they even do any like
I don't think they even do any like
super crazy
super crazy
I don't think they even really do any
I don't think they even really do any
crazy stuff with ML.
crazy stuff with ML.
I think a lot of it's like pretty basic
I think a lot of it's like pretty basic
models that they use and it's a lot more
models that they use and it's a lot more
just about getting data that other
just about getting data that other
people don't have.
Where's the implementation of trajectory
Where's the implementation of trajectory
segment filtering? Yes, it's included
here.
So if you look at pufferl
So if you look at pufferl
where all the code is right
you can see here
you can see here
hang on
right Here you can see that we're not
right Here you can see that we're not
just iterating over the batch, right?
just iterating over the batch, right?
We're actually sampling and we're
We're actually sampling and we're
sampling based on these pryo probs. This
sampling based on these pryo probs. This
is prioritized experience replay using
is prioritized experience replay using
the advantage function uh as the metric.
the advantage function uh as the metric.
So it throws away low advantage segments
low or high. I believe it is
low or high. I believe it is
Like
Like
it throws away like things that are
it throws away like things that are
uninformative. Basically low absolute
uninformative. Basically low absolute
value.
All included.
You help me to understand what project
You help me to understand what project
you're doing right now.
you're doing right now.
Uh, I'm kind of in the middle of a
Uh, I'm kind of in the middle of a
couple different things, but pretty much
couple different things, but pretty much
we have this drone sim. I guess I can
we have this drone sim. I guess I can
show this one. This one's a lot like
show this one. This one's a lot like
this one's in a good spot. So, this is a
this one's in a good spot. So, this is a
drone. It flies through rings. This is a
drone. It flies through rings. This is a
sim. I'm building a sim in which you
sim. I'm building a sim in which you
have a whole bunch of drones and you can
have a whole bunch of drones and you can
kind of command them to do different
kind of command them to do different
things.
things.
And then we're going to reinforcement
And then we're going to reinforcement
learn the drones to be able to do that.
learn the drones to be able to do that.
Doing it for full. No, it's over
Doing it for full. No, it's over
trajectory segments.
trajectory segments.
It's segments of length of BPTT horizon.
That's how we do that.
Okay. So, I we pretty much have the full
Okay. So, I we pretty much have the full
sim except for the fact that for some
sim except for the fact that for some
reason I still have this math wrong on
reason I still have this math wrong on
the circle somehow.
Where? Where did it go?
I do this wrong.
The radius of 8<unk>
*<unk> 5 - 1
And then your sample
And then your sample
1 minus
1 minus
x over the num agents
x over the num agents
* 2 * the radius
probably r is what happened.
Just going to guess that that's what I
Just going to guess that that's what I
messed up.
Huh?
Huh?
Yeah. Why is this not
Yeah. Why is this not
Why is this doing this?
Can't understand what you're doing.
Can't understand what you're doing.
I would suggest
I would suggest
we have some good resources right here.
If you check on puffer.ai,
we have uh there's this quick start
we have uh there's this quick start
guide.
guide.
This gives you a lot of the basics of RL
This gives you a lot of the basics of RL
and a lot of the intuition for stuff.
and a lot of the intuition for stuff.
And also I these some of these need to
And also I these some of these need to
be reformatted at the top. But yeah,
be reformatted at the top. But yeah,
we also have the uh the docs for this
we also have the uh the docs for this
whole project
whole project
and like tons of examples.
and like tons of examples.
I'm building a I'm building a simulator
I'm building a I'm building a simulator
right now for
right now for
essentially for a swarm of drones to
essentially for a swarm of drones to
behave in a certain way and then I'm
behave in a certain way and then I'm
going to run reinforcement learning to
going to run reinforcement learning to
make the drones actually learn to do
make the drones actually learn to do
that
that
with puffer lab.
Apply each point.
Apply each point.
Okay.
You build puffer. Yes,
is my main Perfect.
Okay, this could be it technically.
We need more drones to tell.
There we go. That's a sphere.
There we go. That's a sphere.
Yeah, that's a sphere, right?
Yeah, that's a sphere, right?
We're good.
Let's do some basic thing first with
Let's do some basic thing first with
this. See if we can get it to Turn.
What code editor am I using? Uh, Neoim.
Okay,
Okay,
training is stable. So, I guess I didn't
training is stable. So, I guess I didn't
horribly break everything in this latest
horribly break everything in this latest
change.
change.
See whether it does anything.
article really did very well. I only
article really did very well. I only
have one other article with 100,000
have one other article with 100,000
views and it was kind of like a
views and it was kind of like a
loweffort batty article.
loweffort batty article.
So, this is kind of nice to see a actual
So, this is kind of nice to see a actual
technical uh article do this well.
What do you do for a living? This
What do you do for a living? This
I do reinforcement learning work
I do reinforcement learning work
full-time.
Hey Anick,
Hey Anick,
thanks for the shout out. Appreciate if
thanks for the shout out. Appreciate if
you missed it. I pushed a small change
you missed it. I pushed a small change
on GitHub to make it interactable.
on GitHub to make it interactable.
Article's going wild. Many views on
Article's going wild. Many views on
Puff. Yeah, it's very good. Did you see
Puff. Yeah, it's very good. Did you see
the latest sweep that I did, Yanick?
the latest sweep that I did, Yanick?
You will uh you will appreciate this for
You will uh you will appreciate this for
sure.
So, this is 600 million steps and this
So, this is 600 million steps and this
is 2048.
is 2048.
So, uh, we found some good parameters.
So, uh, we found some good parameters.
Apparently,
Neptune is so slow.
Neptune is so slow.
They advertise it's like the fastest or
They advertise it's like the fastest or
whatever, but it's really not.
Whole thing's frozen.
Okay. Well, this worked.
There you go. Three minutes.
So, 3 minutes to solve 2048.
So, it looks like they don't all know
So, it looks like they don't all know
exactly where they're supposed to go.
exactly where they're supposed to go.
It's pretty close.
It's pretty close.
Interesting. If it continues to solve
Interesting. If it continues to solve
based on the curves, it looked like it
based on the curves, it looked like it
it looks like it should.
I will grab those hypers later and we
I will grab those hypers later and we
can play around with it.
can play around with it.
Or I could link if you want to play
Or I could link if you want to play
around with it. I can link you this
here. I put the sweep in the dev chat.
here. I put the sweep in the dev chat.
See if that link works.
Each drone have its own target point.
Each drone have its own target point.
Now it does. Yes.
Okay, this should make it substantially
Okay, this should make it substantially
easier to learn.
easier to learn.
Got 470 before.
Yeah, we can far. We can push the ends.
Yeah, we can far. We can push the ends.
I think it's a quite good environment
I think it's a quite good environment
actually.
actually.
There really aren't that many things
There really aren't that many things
that take that many steps to learn like
that take that many steps to learn like
on the uh like the game environments
and the episodes are not like crazy long
and the episodes are not like crazy long
either.
It's a good environment.
It's a good environment.
Thank you for the contribution.
10x improvement.
10x improvement.
Yeah, I this is what we've sort of seen
Yeah, I this is what we've sort of seen
with a lot of my work, right?
Sweeps are kind of just ridiculously
Sweeps are kind of just ridiculously
overpowered. Oh, yeah. This is also with
overpowered. Oh, yeah. This is also with
a simpler and smaller model than uh the
a simpler and smaller model than uh the
one that you used. So
it's pretty crazy.
Uh this got 470 before, did it not?
Uh this got 470 before, did it not?
Hang on. Let me go get the I closed the
Hang on. Let me go get the I closed the
tab because Neptune was crashing stuff.
Uh, it's very similar.
So, I guess we'll see whether this helps
So, I guess we'll see whether this helps
it stay stable and keep learning or not.
it stay stable and keep learning or not.
All I did was uh this experiment is I
All I did was uh this experiment is I
relativized the observations. Actually,
relativized the observations. Actually,
you know what I should do? Every time I
you know what I should do? Every time I
think of a thing that's like a basic
think of a thing that's like a basic
trick that I want to talk about,
trick that I want to talk about,
I'm going to just put it into the bottom
I'm going to just put it into the bottom
as a note.
That'll make the article way better.
Okay, so this looks maybe a little
Okay, so this looks maybe a little
better.
better.
Uh, still kind of crashing a bit though.
Well, it still ended up better, right?
Yeah, it still ended up a little tiny
Yeah, it still ended up a little tiny
bit better.
bit better.
I guess what you would expect.
I guess what you would expect.
Here's drone sphere.
Okay. So next what we can do
we train them for all the tasks
we train them for all the tasks
simultaneously.
That means I get to delete
I get to delete four
I get to delete four
dimensions
dimensions
from the obace.
So that is
So that is
20.
20.
Wait, am I stupid?
27.
27.
Yeah.
Yeah.
Or I cannot add
Seven.
Seven.
Okay.
Now
we rebuild this and we see if we can do
we rebuild this and we see if we can do
all four tasks simultaneously.
So, this is actually a fair bit easier
So, this is actually a fair bit easier
because you really don't even need to
because you really don't even need to
know what task you're doing in order to
know what task you're doing in order to
do this. You just need to know where the
do this. You just need to know where the
target is. But, let it be known that we
target is. But, let it be known that we
actually had a version of this working
actually had a version of this working
pretty well even without that. So like
pretty well even without that. So like
task conditional RL kind of just works
task conditional RL kind of just works
which is crazy because that's not a like
which is crazy because that's not a like
that's not a thing at all that used to
that's not a thing at all that used to
Dark.
Actually,
if task conditional RL works now, yeah,
if task conditional RL works now, yeah,
there's some crazy demos we can throw
there's some crazy demos we can throw
together from
I have the score normalized such that or
I have the score normalized such that or
the perf normalized especially such that
the perf normalized especially such that
I think one is ideal like it's working
I think one is ideal like it's working
perfectly but I don't think you can
perfectly but I don't think you can
actually get one.
So hopefully this should be like
So hopefully this should be like
reasonably good behavior. here.
Okay. So this is orbit. Yeah.
Idle
follow.
Oh yeah, this is working. And they're
Oh yeah, this is working. And they're
trying not to crash as well.
obviously we have to fix these drone
obviously we have to fix these drone
trails and stuff
like 20 as Well,
way better. And I we'll fix this.
way better. And I we'll fix this.
Actually, we'll do this next. We'll just
Actually, we'll do this next. We'll just
fix this next. And then we'll add in the
fix this next. And then we'll add in the
rest of the tasks and then we will be
rest of the tasks and then we will be
pretty well set. Like we'll have an
pretty well set. Like we'll have an
awesome drone sim that works with RL in
awesome drone sim that works with RL in
like day and a half of like pretty lazy
like day and a half of like pretty lazy
work.
work.
All right. I'd be right back.
I forgot my daily deadlift.
Okay,
back to
Let's do
we'll do the two component reward. In
we'll do the two component reward. In
fact,
all sore today and I don't know why
all sore today and I don't know why
a bunch of pull-ups and like some pearls
a bunch of pull-ups and like some pearls
yesterday anything else
weird
Oh, I guess then this does get
Oh, I guess then this does get
does get updated, huh?
does get updated, huh?
Yeah, you can do
when I'm assessing a new area of work, I
when I'm assessing a new area of work, I
always look for wrong fundamental
always look for wrong fundamental
assumptions. Why puffer will win?
assumptions. Why puffer will win?
Pretty much what we do.
I mean,
I mean,
I kind of have a probably not as great
I kind of have a probably not as great
of an outlook on it in how I get to that
of an outlook on it in how I get to that
conclusion, which is like I kind of
conclusion, which is like I kind of
every I kind of assume everything is
every I kind of assume everything is
done in the stupidest and most
done in the stupidest and most
incompetent way possible until proven
incompetent way possible until proven
otherwise.
otherwise.
And like when I see a few things done
And like when I see a few things done
incompetently, I look for other things
incompetently, I look for other things
done incompetently.
This is solid.
Okay, we do actually need this stuff as
Okay, we do actually need this stuff as
well, but
well, but
it can go into compute
it can go into compute
board.
episode return.
Okay. Episode length
Okay. Episode length
or
get absor.
get absor.
Yeah.
Now, the only thing I have to do besides
Now, the only thing I have to do besides
this, making sure that I I didn't pass
this, making sure that I I didn't pass
anything else up.
Decision reward, target reward, and
Decision reward, target reward, and
that's it.
I could do the absolute reward.
I may as well let it see the
May as well let it see, right? Let there
May as well let it see, right? Let there
be light.
H numbers.
Definitely better.
reward like this.
And we also wanted to fix the trails,
And we also wanted to fix the trails,
right?
little awkward
and probably do something like
maybe I can do something like this.
Not quite.
really. I would think that this would do
really. I would think that this would do
it. Now.
Oh, hang on. I think it just indexed
Oh, hang on. I think it just indexed
wrong somehow.
This is it here, isn't it?
thought this would be it.
thought this would be it.
Really good references in your quick
Really good references in your quick
start blog. Thank you. I am working on
start blog. Thank you. I am working on
another one. I've started on like
another one. I've started on like
another educational article. It's going
another educational article. It's going
to be much longer.
to be much longer.
Uh, and it's going to take me quite a
Uh, and it's going to take me quite a
bit of work.
I'm just kind of doing it bit by bit,
I'm just kind of doing it bit by bit,
but
but
I'm working on that.
Costa is
Costa is
I think Costa is like the only person
I think Costa is like the only person
the only other person in Arl where I'd
the only other person in Arl where I'd
like I have literally nothing negative
like I have literally nothing negative
to say about Costa at all. Costa is just
to say about Costa at all. Costa is just
awesome.
Like it's one of these things where I
Like it's one of these things where I
don't think the field realizes how
don't think the field realizes how
screwed reinforcement learning would be
screwed reinforcement learning would be
without Costa.
without Costa.
Like including all the stuff I do. Like
Like including all the stuff I do. Like
we would just be beyond screwed.
How could this happen?
The heck is going on with this thing?
It said it follows the drone.
Count to zero.
Really
for one frame.
Why does this guy have both trails and
Why does this guy have both trails and
this other one doesn't have any?
this other one doesn't have any?
Oh, this needs to be zero.
Oh, this needs to be zero.
Now they both get trails.
That was stupid right thing.
When it's out of bounds, you reset the
When it's out of bounds, you reset the
agent and terminals is set to one.
Okay.
And then you call render.
doesn't draw the trail.
very weird that this thing does this.
very weird that this thing does this.
How does the trail jump on reset like
How does the trail jump on reset like
this?
It's like the frame after they reset or
It's like the frame after they reset or
whatever, right?
Okay. So, this is just not doing
Okay. So, this is just not doing
anything I guess.
Oh,
Oh,
you are stupid is why.
Actually, shouldn't it just be
just this
Okay, they still zap though like this.
Okay, they still zap though like this.
Why this is out?
Okay. So, this is still
still doing this weird zappy
That's
So, this is getting cold.
Very
silly bug to get stuck on for this long.
Is it just drawing it somewhere else and
Is it just drawing it somewhere else and
I'm just dumb?
No,
No,
this is where it's drawing it.
very odd.
Okay, this is the expected behavior.
Okay. Okay. So, you can actually see
Okay. Okay. So, you can actually see
that it is wrapping around and screwing
that it is wrapping around and screwing
it
This terminated condition does work.
This terminated condition does work.
The heck is wrong?
Hello,
Hello,
your potato.
Uh, this is a live reinforcement
Uh, this is a live reinforcement
learning dev. I'm currently working on a
learning dev. I'm currently working on a
drone simulator.
drone simulator.
Show you a different version.
Okay, apparently I don't have it. I can
Okay, apparently I don't have it. I can
show you this version at least.
show you this version at least.
So, we have a couple different drone
So, we have a couple different drone
simulators and I'm currently working on
simulators and I'm currently working on
a version that has a ton of different
a version that has a ton of different
drones that can like fly in a sphere or
drones that can like fly in a sphere or
hover or like do a few different things
hover or like do a few different things
and we're training them with
and we're training them with
reinforcement learning.
reinforcement learning.
That is currently what is going on.
You can watch some of these live in your
You can watch some of these live in your
browser at puffer.ai.
You have all sorts of games and
You have all sorts of games and
simulators and other things.
This is a trained agent playing it in
This is a trained agent playing it in
your browser.
your browser.
This is a trained agent that plays in
This is a trained agent that plays in
your browser.
We have lots of different things in
We have lots of different things in
here.
I'm currently just trying to figure out
I'm currently just trying to figure out
why these uh trails on these drones are
why these uh trails on these drones are
not rendering correctly.
not rendering correctly.
Stuck on a very basic thing at the
Stuck on a very basic thing at the
moment.
Yeah. See, it like it zaps and like
Yeah. See, it like it zaps and like
follows them for some reason.
It's like an off by one or some weird
It's like an off by one or some weird
thing.
thing.
I honestly don't know why this is doing
I honestly don't know why this is doing
this.
We can just re
We can just re
do how the trail works a little. So you
do how the trail works a little. So you
get the position.
Oh, I see.
that. Well, that wasn't it, but
that. Well, that wasn't it, but
hang on. It's something like this.
See what their original indexing was.
I forgot how the indexing was done
I forgot how the indexing was done
originally.
originally.
Probably just in
plus I -1. How does this make sense?
Increment the trail length.
I see. Yeah, this wasn't designed to be
I see. Yeah, this wasn't designed to be
used this way. Okay. So, we have to
used this way. Okay. So, we have to
redesign a little bit.
two variables ever different?
No, they're not right.
Well, they are in the sense that um
I see no the original is actually
I see no the original is actually
correct.
correct.
Do like this
Do like this
up to this cap.
And it should be that you count
And it should be that you count
backwards.
But instead of subtracting J.
Okay. So, the intensity is backwards.
Somehow this breaks it.
Just not by one now I believe. Think how
Just not by one now I believe. Think how
we do this
we do this
back. Okay.
I hate when I get stuck on silly things
I hate when I get stuck on silly things
like this.
like this.
It's just like it needs to be done, but
It's just like it needs to be done, but
I'm stuck for some dumb reason.
like incredibly incredibly basic as
like incredibly incredibly basic as
well.
well.
Literally just a ring buffer.
This is really the simplest way to do it
This is really the simplest way to do it
as well, isn't it?
Hey man, I'm not from a coding
Hey man, I'm not from a coding
background. Should I learn coding?
I mean, if you want to, right? I don't
I mean, if you want to, right? I don't
know. It's your life, man.
What the heck?
I'm sure I just have the like the modulo
I'm sure I just have the like the modulo
arithmetic screwed up in some dumb way.
I'm 19. All this looks too flashy.
If you want to see some cool demos,
If you want to see some cool demos,
there's some stuff on puffer.ai.
there's some stuff on puffer.ai.
some of the agents that we've got.
Thank you for the reminder for folks.
Thank you for the reminder for folks.
Linky, do star the puffer all open
Linky, do star the puffer all open
source code. It's on GitHub. Find the
source code. It's on GitHub. Find the
link at puffer.ai.
link at puffer.ai.
The repo helps us out a lot.
give up. Going to just debug it like
give up. Going to just debug it like
this.
Yeah.
How are we seging?
What?
Okay.
I got silence for dropping a link.
I don't have anything on that does that.
I don't have anything on that does that.
It just does it automatically.
Oh, this is weird.
Yeah, these numbers are way too big,
Yeah, these numbers are way too big,
aren't they?
Okay, it was literally an off by one.
That was annoying, but whatever. We got
That was annoying, but whatever. We got
it.
Okay,
Okay,
we are ready.
Train a model on this.
See how this looks.
See how this looks.
Lab the new rewards in. You'd be able to
Lab the new rewards in. You'd be able to
have this cleaned up for today.
Rain this now.
How this goes.
The article got more than twice as many
The article got more than twice as many
views as the release that literally
views as the release that literally
rewrites reinforcement learning.
rewrites reinforcement learning.
Crazy.
love the new video today.
love the new video today.
Oh, the trailer that I put online.
Yeah, I realized that I had not I hadn't
Yeah, I realized that I had not I hadn't
put our release trailer from X onto uh
put our release trailer from X onto uh
onto YouTube. So, I uploaded as as a uh
onto YouTube. So, I uploaded as as a uh
I uploaded the 1080p one and then I also
I uploaded the 1080p one and then I also
uploaded the shorts one.
Oh, that's hilarious.
Community note, not an operating system.
Don't underestimate the power of
Don't underestimate the power of
Schwarz. Yeah, I've uploaded a few small
Schwarz. Yeah, I've uploaded a few small
things and they do well. It's funny. Oh,
things and they do well. It's funny. Oh,
hey Arin. Yes, now I remember. Compan
hey Arin. Yes, now I remember. Compan
things. I saw it naturally in YouTube
things. I saw it naturally in YouTube
reals.
reals.
That's the algorithm.
Okay. So, can we do eval?
Okay. So, can we do eval?
Have it look decent now.
Oh, yeah. Look at that.
following this ball Now,
me to create a channel. My friend, I'm
me to create a channel. My friend, I'm
preparing a review paper on machine
preparing a review paper on machine
learning force fields. Very cool.
As you can see on the uh the channel, I
As you can see on the uh the channel, I
don't really post a ton of like videos.
don't really post a ton of like videos.
They're a ton of work. I have uh I have
They're a ton of work. I have uh I have
like 400 something live streams though
like 400 something live streams though
on the channel so far. And um
on the channel so far. And um
I also I mean I write articles. I post
I also I mean I write articles. I post
those on X
fighting start discussing a lot of RL
fighting start discussing a lot of RL
and chemistry. Absolutely.
You account for the turbulence caused by
You account for the turbulence caused by
other drones in the area.
other drones in the area.
No, that should be accounted for by just
No, that should be accounted for by just
telling them not to slam into each other
telling them not to slam into each other
or get too
What RL methods are the drones using
What RL methods are the drones using
currently? It's the main trainer in Papa
currently? It's the main trainer in Papa
Lip, which is not exactly PO. It's quite
Lip, which is not exactly PO. It's quite
a bit better, but it's based on it.
Oops.
One second, folks. Right back.
Okay.
Okay.
Add the uh the task for them to form a
Add the uh the task for them to form a
line, I guess.
One
us.
target.
target.
I see.
But I do need to figure this last thing
But I do need to figure this last thing
out, which is I need to figure out a
out, which is I need to figure out a
separate way to set the target and then
separate way to set the target and then
uh move the target, I guess.
Where is this?
Okay. So this is random position.
target. Idle
target. Idle
target
hover.
Okay, so this works.
Okay, so this works.
This is just going to be set target
This is just going to be set target
orbit.
Follow
go to the first agent or whatever.
dinner soon.
dinner soon.
Going to end first.
Got the target and the line
Got the target and the line
update function.
The only ones that need update
The only ones that need update
we have idle
we have idle
Follow.
What are you fixing now? I'm making I'm
What are you fixing now? I'm making I'm
just adding a bunch of tasks. The goal
just adding a bunch of tasks. The goal
is you're going to have like a whole
is you're going to have like a whole
bunch of different tasks that the drones
bunch of different tasks that the drones
can do and now uh or like commands they
can do and now uh or like commands they
can follow and uh I'm adding that
Don't need this.
What was your school experience like?
What was your school experience like?
What were the biggest rewards and
What were the biggest rewards and
takeaways?
Uh like undergrad or PhD or everything.
I'm usually I'm pretty negative for the
I'm usually I'm pretty negative for the
most part. uh overall on like
most part. uh overall on like
traditional coursework to learn stuff.
traditional coursework to learn stuff.
I guess it's more like the vast majority
I guess it's more like the vast majority
of the courses are not well taught. Some
of the courses are not well taught. Some
are. The ones that are good are very
are. The ones that are good are very
good, but the majority are just kind of
good, but the majority are just kind of
a waste of time.
a waste of time.
Um
Um
for PhD, it's not really school in the
for PhD, it's not really school in the
same way. At least not in CS. like you
same way. At least not in CS. like you
take to a total of four courses that
take to a total of four courses that
aren't really relevant or helpful in any
aren't really relevant or helpful in any
way to what you're doing. There really
way to what you're doing. There really
isn't course work that you can do that's
isn't course work that you can do that's
going to be relevant to the research.
going to be relevant to the research.
It's kind of just up to you to like
It's kind of just up to you to like
teach yourself and figure it out.
Couple of the intro courses in undergrad
Couple of the intro courses in undergrad
were good. I had one really good ML
were good. I had one really good ML
course. I had like a couple decent
course. I had like a couple decent
miscellaneous other ones and other than
miscellaneous other ones and other than
that, I mean, I spent like half of my
that, I mean, I spent like half of my
time in undergrad just doing research.
time in undergrad just doing research.
Like I was pretty much doing full-time
Like I was pretty much doing full-time
AI research starting sophomore year, a
AI research starting sophomore year, a
little earlier.
A little earlier actually.
Think if there's anything else like
Think if there's anything else like
super interesting
takeaways.
takeaways.
A lot of the stuff has just been you
A lot of the stuff has just been you
need to spend a ludicrous amount of time
need to spend a ludicrous amount of time
learning the thing and like use the
learning the thing and like use the
materials that are good to learn, but
materials that are good to learn, but
very often it's just going to be you
very often it's just going to be you
have to figure stuff out and it's going
have to figure stuff out and it's going
to be slow and it's going to be a grind
to be slow and it's going to be a grind
because there just isn't material out
because there just isn't material out
there that you can use to like be taught
there that you can use to like be taught
it. Basically, you have to learn it
it. Basically, you have to learn it
yourself.
I mean, it literally took me like I
I mean, it literally took me like I
think it took me well over a thousand
think it took me well over a thousand
hours to figure out the basics of neural
hours to figure out the basics of neural
nets because there were just zero good
nets because there were just zero good
resources back then at all.
resources back then at all.
That was even a little before undergrad
That was even a little before undergrad
to be fair.
But yeah, like when I took the uh the
But yeah, like when I took the uh the
main Stanford ML course, it was
main Stanford ML course, it was
completely irrelevant and it didn't even
completely irrelevant and it didn't even
touch on neural nets at all. Um
I think if anything else
I think if anything else
I don't know if you have other
I don't know if you have other
specifics, I can answer stuff.
learning takes time. Well, it's like
learning takes time. Well, it's like
a lot of the coursework isn't even going
a lot of the coursework isn't even going
to help you. Like take RL specifically.
to help you. Like take RL specifically.
You can perfectly, you can go take an RL
You can perfectly, you can go take an RL
course and understand everything
course and understand everything
perfectly and get a 100red in the course
perfectly and get a 100red in the course
and have absolutely no idea what you're
and have absolutely no idea what you're
doing.
Like I literally have people that spend
Like I literally have people that spend
a few days going through some of the
a few days going through some of the
stuff that I've done and they have a
stuff that I've done and they have a
better understanding than if you go read
better understanding than if you go read
the entire Sutton and Bardau book.
I don't know. Like academia has a way of
I don't know. Like academia has a way of
teaching stuff and a language by which
teaching stuff and a language by which
they teach stuff. They kind of just like
they teach stuff. They kind of just like
to beat you over the head with math
to beat you over the head with math
until you like get bored and stop, I
until you like get bored and stop, I
guess.
guess.
But like they'll do it even if it has no
But like they'll do it even if it has no
practical application or it's like not
practical application or it's like not
even fully correct. They'll just do it
even fully correct. They'll just do it
anyways.
I don't know. This has been one of the
I don't know. This has been one of the
things I've been pretty good at, right?
things I've been pretty good at, right?
Is like identifying gaps in the way that
Is like identifying gaps in the way that
things are done and then just doing it a
things are done and then just doing it a
completely different way.
I got into my CS masters and I have gaps
I got into my CS masters and I have gaps
in math only fill them after I finish
in math only fill them after I finish
grad. My trying to do it along courses
grad. My trying to do it along courses
research is much honestly most of the
research is much honestly most of the
math in RL is like wrong.
math in RL is like wrong.
Most of the RL math is just wrong.
There are very small bits of math that
There are very small bits of math that
actually matter.
like the whole basis of a lot of stuff
like the whole basis of a lot of stuff
it's like all derived from tabular
it's like all derived from tabular
Q-learning on MDPs
Q-learning on MDPs
and it's just a mess. Yes.
Please mention what needs to be changed.
Please mention what needs to be changed.
I'm working on an article that will
I'm working on an article that will
cover a lot of it. Um, it's mainly like
cover a lot of it. Um, it's mainly like
they do 10 times too much math and 10
they do 10 times too much math and 10
times too little engineering.
Like they don't care about solving the
Like they don't care about solving the
problem. They care about doing a bunch
problem. They care about doing a bunch
of math. It's weird. like they care
of math. It's weird. like they care
about writing fancy algorithms and like
about writing fancy algorithms and like
running their experiments and like
running their experiments and like
saying a better than b even though
saying a better than b even though
statistically it makes no sense. It's
statistically it makes no sense. It's
like there's like a very cookie cutter
like there's like a very cookie cutter
way that stuff is done
way that stuff is done
and that worked up to a point and then
and that worked up to a point and then
when it was time to actually like make
when it was time to actually like make
all this stuff fast enough so that that
all this stuff fast enough so that that
approach could continue to be useful,
approach could continue to be useful,
everybody kind of just threw up their
everybody kind of just threw up their
hands, didn't do it, and let the field
hands, didn't do it, and let the field
die.
die.
I'm not even remotely exaggerating.
RL is a field where understanding a
RL is a field where understanding a
little bit about the history of like how
little bit about the history of like how
stuff has developed over the last few
stuff has developed over the last few
years will do you a lot more good than
years will do you a lot more good than
like understanding 20 algorithm.
like understanding 20 algorithm.
This is a generic question. I'm a
This is a generic question. I'm a
third-year undergrad and ideally you
third-year undergrad and ideally you
want to be some kind of ML research or
want to be some kind of ML research or
applied scientist. Pretty comfortable
applied scientist. Pretty comfortable
with understanding the latest
with understanding the latest
developments in LMS and based models.
developments in LMS and based models.
Okay, that's a lot of math. So, you're
Okay, that's a lot of math. So, you're
probably set there. Minus RL. If you
probably set there. Minus RL. If you
were me, what would you focus on right
were me, what would you focus on right
now? I don't know what I should do to
now? I don't know what I should do to
achieve my goals.
achieve my goals.
Research engineer or applied scientist?
Research engineer or applied scientist?
Yeah. So, research engineer is a little
Yeah. So, research engineer is a little
bit trickier because it's usually like
bit trickier because it's usually like
they kind of just grab people out of
they kind of just grab people out of
masters or whatever. um for re like for
masters or whatever. um for re like for
ML research and then also qualifies you
ML research and then also qualifies you
for research engineer positions doing a
for research engineer positions doing a
bit of your own research is probably
bit of your own research is probably
good publishing something is probably
good publishing something is probably
good. Um, so getting to the point that
good. Um, so getting to the point that
you can function autonomously like that
you can function autonomously like that
is good. And then on the engineering
is good. And then on the engineering
side, just like if you want to go that
side, just like if you want to go that
route, then just do the exact same
route, then just do the exact same
thing, but do it with an engineering
thing, but do it with an engineering
heavy approach, right?
heavy approach, right?
like focus on doing stuff that is
like focus on doing stuff that is
engineering intensive and also produces
engineering intensive and also produces
a cool result that you can publish
a cool result that you can publish
instead of like
instead of like
the traditional one which is the
the traditional one which is the
traditional science thing where like
traditional science thing where like
scientists can't write code at all.
I don't know. That's the vague general
I don't know. That's the vague general
advice I have today.
appreciate it a lot. Yeah, you can look
appreciate it a lot. Yeah, you can look
at like my RL specific thing. There's a
at like my RL specific thing. There's a
quick start guide on puffer.ai. It has a
quick start guide on puffer.ai. It has a
lot of good reference material.
I mean, my path was pretty much that I
I mean, my path was pretty much that I
started research really early on. I
started research really early on. I
didn't really have a specific topic of
didn't really have a specific topic of
interest. So I started doing some
interest. So I started doing some
natural language processing because that
natural language processing because that
was the lab that was there and then I
was the lab that was there and then I
went and I did some computer vision. I
went and I did some computer vision. I
managed to publish one thing in natural
managed to publish one thing in natural
language processing. Put a couple just
language processing. Put a couple just
archive manuscripts out on vision stuff
archive manuscripts out on vision stuff
and then I came up with the idea for
and then I came up with the idea for
neural MMO and I learned the RL and all
neural MMO and I learned the RL and all
the stuff around it to make that happen.
the stuff around it to make that happen.
I did that for my whole PhD and then in
I did that for my whole PhD and then in
the last year year and a half I started
the last year year and a half I started
doing puffer and the goal here is to use
doing puffer and the goal here is to use
all the knowledge I gained about RL to
all the knowledge I gained about RL to
make RL a faster ser more stable field
make RL a faster ser more stable field
because I saw that as a gap
a lot of science is a lot more cookie
a lot of science is a lot more cookie
cutter than the path that I've taken
cutter than the path that I've taken
uh the path that I've taken is like the
uh the path that I've taken is like the
very high variance path
very high variance path
where you're kind of just going to get
where you're kind of just going to get
stomped a lot of the time because
stomped a lot of the time because
researchers don't like it when you do
researchers don't like it when you do
work this way. Uh but you're also going
work this way. Uh but you're also going
to be able to solve problems that nobody
to be able to solve problems that nobody
else can.
So that's the that's what I can speak
So that's the that's what I can speak
to.
all very impressive. Oh, thank you. It's
all very impressive. Oh, thank you. It's
most of what I do, so I would hope it
most of what I do, so I would hope it
is.
Hey, what's going on? Can I get a quick
Hey, what's going on? Can I get a quick
overview? Uh, this is reinforcement
overview? Uh, this is reinforcement
learning dev. I stream all of my
learning dev. I stream all of my
research. I'm currently working on a
research. I'm currently working on a
drone environment where you can send
drone environment where you can send
commands to make drones go in uh arrange
commands to make drones go in uh arrange
themselves in a variety of patterns and
themselves in a variety of patterns and
follow each other and do stuff like
follow each other and do stuff like
that.
that.
If you want to check out some cool
If you want to check out some cool
demos, they're all on puffer.ai. You
demos, they're all on puffer.ai. You
have agents that play games and like do
have agents that play games and like do
other fun stuff all in your browser.
Any
advice on YouTube versus Twitch
advice on YouTube versus Twitch
streaming? Free automation tool? I
streaming? Free automation tool? I
stream on both. I just do it through
stream on both. I just do it through
reream.
reream.
And I don't know what you mean for free
And I don't know what you mean for free
automation tools
specifically.
So, Congo,
how to make the posts get automated.
how to make the posts get automated.
Message everything externally.
Do you mean how to make the post get
Do you mean how to make the post get
automated?
like
post
post
it just like YouTube just shows up.
it just like YouTube just shows up.
YouTube will just record your VODs
YouTube will just record your VODs
automatically for you. You don't have to
automatically for you. You don't have to
do anything.
do anything.
Twitch will record them, but it won't
Twitch will record them, but it won't
store them forever. That's just Twitch
store them forever. That's just Twitch
being Twitch. Nothing you do about that.
being Twitch. Nothing you do about that.
YouTube is really going to be your main
YouTube is really going to be your main
archive. Uh X will store I don't know
archive. Uh X will store I don't know
how many. I think X has a cap, but it'll
how many. I think X has a cap, but it'll
store the last many. Um,
store the last many. Um,
X automatically posts your stream when
X automatically posts your stream when
you stream YouTube. It automatically
you stream YouTube. It automatically
shows up in the live tab and it gets
shows up in the live tab and it gets
recommended to people. Same for Twitch.
recommended to people. Same for Twitch.
You really don't need any like extra
You really don't need any like extra
tools. You do need something like Reream
tools. You do need something like Reream
to make it a little easier to stream
to make it a little easier to stream
simultaneously to many services.
Oh yeah, this is going to be really
Oh yeah, this is going to be really
good.
Thanks a lot. How would you learn RL
Thanks a lot. How would you learn RL
teach RL to beginner researchers? The uh
teach RL to beginner researchers? The uh
I'm making another one of these, but the
I'm making another one of these, but the
quick start guide on my website is very
quick start guide on my website is very
good.
Like that's literally it. Do that. Start
Like that's literally it. Do that. Start
building environments.
building environments.
If you already know how to program, you
If you already know how to program, you
can literally start doing RL over a
can literally start doing RL over a
weekend. If you don't know how to
weekend. If you don't know how to
program, well, then that's the hard
program, well, then that's the hard
part, right?
We'll add one more task.
What are you working on here? Um
here. So you can see that there are all
here. So you can see that there are all
sorts of different configurations.
sorts of different configurations.
Some are stationary, some are mobile.
Some are stationary, some are mobile.
Uh, and I'm going to I'm defining a
Uh, and I'm going to I'm defining a
bunch of these and I'm going to
bunch of these and I'm going to
reinforcement learn these drones such
reinforcement learn these drones such
that they can uh do any of those
that they can uh do any of those
patterns. They can arrange themselves in
patterns. They can arrange themselves in
any of those patterns.
Almost done as well.
You
Uh, almost
Uh, almost
white.
Okay. So almost
make it better later. I want to at least
make it better later. I want to at least
get it to run.
What's your recommended way of
What's your recommended way of
understanding a given environment?
understanding a given environment?
Know in it step and a reset function.
Know in it step and a reset function.
Well, understanding like one of the
Well, understanding like one of the
puffer environments, you can mostly read
puffer environments, you can mostly read
it from top to bottom.
it from top to bottom.
Um,
Um,
like these are like except for some of
like these are like except for some of
the messier ones, they're mostly written
the messier ones, they're mostly written
in as simple as possible basic C. But
in as simple as possible basic C. But
like go watch it. If it's playable, play
like go watch it. If it's playable, play
it a little bit.
If it's playable, play it a little bit.
If it's playable, play it a little bit.
That helps a lot.
Still not arranged correctly.
try this. Um,
try this. Um,
yeah, mostly it's like playing the
yeah, mostly it's like playing the
environment. The way you design rewards
environment. The way you design rewards
is less even to do. There are a couple
is less even to do. There are a couple
RL specific things you need to know, but
RL specific things you need to know, but
like the biggest thing honestly is just
like the biggest thing honestly is just
knowing what information the agent needs
knowing what information the agent needs
to solve the task and like what signal
to solve the task and like what signal
makes sense
makes sense
to actually tell you how to solve the
to actually tell you how to solve the
task. It's like not even RL specific,
task. It's like not even RL specific,
right? It's just like basic first
right? It's just like basic first
principles reasoning
wrong here. It's Sixide by 8
wrong here. It's Sixide by 8
and 8
and 8
0 to 7.
from the ML side where is the
from the ML side where is the
observation space, action space and
observation space, action space and
reward stuff. So the actual shape of it
reward stuff. So the actual shape of it
is in the Python file
is in the Python file
um
um
and that gets passed in as just a
and that gets passed in as just a
pointer. So you just have a pointer to
pointer. So you just have a pointer to
the observations
the observations
and then usually most ends have like a
and then usually most ends have like a
compute observation
compute observation
function or it'll be inlined
function or it'll be inlined
inside of the step function and then
inside of the step function and then
reward similarly either there's either
reward similarly either there's either
going to be a function or it'll be
going to be a function or it'll be
inlined in the step function.
Okay, this is I think this is correct.
Okay, this is I think this is correct.
Good.
Let's see if this thing learns.
Roer color.
Okay, so this is now trained on I
Okay, so this is now trained on I
believe seven or eight tasks.
believe seven or eight tasks.
See,
See,
seven tasks.
seven tasks.
One of them is just do like it's like an
One of them is just do like it's like an
idle task.
idle task.
One of them is to hover in place. One of
One of them is to hover in place. One of
them is to be in this like spherical
them is to be in this like spherical
orbit thing.
orbit thing.
There's a follow task where you have to
There's a follow task where you have to
follow a single target. There's a line
follow a single target. There's a line
task where they all have to put
task where they all have to put
themselves into a line. Congo task where
themselves into a line. Congo task where
they got to follow each other. There's a
they got to follow each other. There's a
plane task.
Should be able to do some stuff with
Should be able to do some stuff with
this.
And that's a decent policy in like
And that's a decent policy in like
literally 30 seconds as well. He'll get
literally 30 seconds as well. He'll get
better, but this is a very good start, I
better, but this is a very good start, I
would say.
This looks very fun. How do I get
This looks very fun. How do I get
involved? It's all open source
involved? It's all open source
puffer.ai.
Wait till you see this result as soon as
Wait till you see this result as soon as
this thing is trained.
this thing is trained.
These are all the ends. Uh most of these
These are all the ends. Uh most of these
are made by contributors. Some of them
are made by contributors. Some of them
are made by me.
are made by me.
There is uh documentation on how to get
There is uh documentation on how to get
started. We suggest that most new
started. We suggest that most new
contributors start by going through the
contributors start by going through the
quick start guide on the blog here.
quick start guide on the blog here.
And then you're going to want to write
And then you're going to want to write
an environment.
Typically, like you look for something
Typically, like you look for something
that's fun that you can do in maybe a
that's fun that you can do in maybe a
few hundred lines of code, not a massive
few hundred lines of code, not a massive
project. People have come up with all
project. People have come up with all
sorts of stuff. We like things that are
sorts of stuff. We like things that are
interesting, like interesting challenges
interesting, like interesting challenges
for RL in a new way. We also like things
for RL in a new way. We also like things
that are just cool and interesting. Like
that are just cool and interesting. Like
here, Tetris ended up being really cool
here, Tetris ended up being really cool
to watch. Just Tetris, but like look how
to watch. Just Tetris, but like look how
cool it is to watch the AI play it.
cool it is to watch the AI play it.
Like mesmerizing, right?
We had somebody submit 2048 and uh you
We had somebody submit 2048 and uh you
know, completely counterintuitively,
know, completely counterintuitively,
this ended up being actually a very
this ended up being actually a very
useful environment for research.
useful environment for research.
As it turns out, it's actually kind of
As it turns out, it's actually kind of
hard.
There tons of things in here.
I don't know what that is
type of Polish dance. What?
Is this sick? Happy I stumbled across
Is this sick? Happy I stumbled across
you. Thank you. Here, let me show you
you. Thank you. Here, let me show you
this thing real quick
this thing real quick
because we just trained this model.
because we just trained this model.
Okay, so if I hold tab, this will show
Okay, so if I hold tab, this will show
you the target objectives. They do a
you the target objectives. They do a
pretty decent job of uh going to these
pretty decent job of uh going to these
targets.
targets.
And if we sort of change up the tasks,
And if we sort of change up the tasks,
so this is just a do whatever task,
so this is just a do whatever task,
don't collide.
don't collide.
We've got a hover task which is stay in
We've got a hover task which is stay in
place.
place.
Orbit follow the single dot. Got this
Orbit follow the single dot. Got this
line task.
Arrange themselves in a line. Got this
Arrange themselves in a line. Got this
congo task.
I need to make it so it doesn't reset so
I need to make it so it doesn't reset so
frequently so you can actually see. They
frequently so you can actually see. They
are doing a congo though. You can kind
are doing a congo though. You can kind
of see it.
of see it.
It could be a little better, but not bad
It could be a little better, but not bad
for a first result plane.
That was quick. Yeah. So, this is the
That was quick. Yeah. So, this is the
thing with Puffer, right? It's literally
thing with Puffer, right? It's literally
a thousand times faster than everything
a thousand times faster than everything
that else that is out there in
that else that is out there in
reinforcement learning. You can
reinforcement learning. You can
literally train superhuman models in
literally train superhuman models in
seconds.
Like this pong agent here, you know how
Like this pong agent here, you know how
long it takes to train this pong agent?
long it takes to train this pong agent?
Okay, so this is something that would
Okay, so this is something that would
take like hours or days uh before puffer
take like hours or days uh before puffer
lib. This is how long it takes to train
lib. This is how long it takes to train
Pong.
Okay, it's done.
And if I will have to convince you.
There you go. There's your agent that
There you go. There's your agent that
plays pong. You're the blue one,
plays pong. You're the blue one,
obviously.
So yeah, this is what I do all day. This
So yeah, this is what I do all day. This
is all open source. We do our own RL
is all open source. We do our own RL
research on the algorithms. We do our
research on the algorithms. We do our
own crazy infrastructure to make
own crazy infrastructure to make
everything fast. We write tons of
everything fast. We write tons of
environments for use in research and
environments for use in research and
applications.
applications.
Uh yeah, this is this is the main thing.
Uh yeah, this is this is the main thing.
What did you optimize so well? We tore
What did you optimize so well? We tore
out and rewrote the whole stack. The
out and rewrote the whole stack. The
result is actually pretty concise. like
result is actually pretty concise. like
our code is actually a lot simpler than
our code is actually a lot simpler than
the other things out there as well even
the other things out there as well even
though it's this fast but the
though it's this fast but the
environments are in C very simple C but
environments are in C very simple C but
it's C uh they write observations
it's C uh they write observations
directly into shared memory so like you
directly into shared memory so like you
can have thousands of environments and
can have thousands of environments and
all the data is immediately available on
all the data is immediately available on
the main process without redundant
the main process without redundant
copies
copies
trainers optimized for super large
trainers optimized for super large
batches which is not usual we optimize
batches which is not usual we optimize
the heck out of a lot of the overhead on
the heck out of a lot of the overhead on
the trainer as well
the trainer as well
we
we
And we made some fundamental algorithm
And we made some fundamental algorithm
improvements that let you do that more
improvements that let you do that more
effectively.
effectively.
The mix of a lot of things.
This is what I think this is the first
This is what I think this is the first
environment that I did in pure state is
environment that I did in pure state is
this snake environment. It's maybe 300
this snake environment. It's maybe 300
linesish of code. very very simple
linesish of code. very very simple
environment but cool each snake is an
environment but cool each snake is an
agent.
agent.
What batch sizes are we talking about?
What batch sizes are we talking about?
So I think our most common training
So I think our most common training
setting at this point is 8192
setting at this point is 8192
environments or agents. So if you have a
environments or agents. So if you have a
multi- aent environment you count total
multi- aent environment you count total
number of agents. 8192 agents and a
number of agents. 8192 agents and a
batch size of about 500,000. and our
batch size of about 500,000. and our
biggest experiments. If you haven't seen
biggest experiments. If you haven't seen
this article, this is this is a pretty
this article, this is this is a pretty
cool article.
cool article.
So this one here, we did RL on a pabyte
So this one here, we did RL on a pabyte
of data. So uh it was 640 billion steps
of data. So uh it was 640 billion steps
or 640 billion observations. And this
or 640 billion observations. And this
one used a batch size of 3 million.
one used a batch size of 3 million.
You deploy a neural net for each trained
You deploy a neural net for each trained
agent. What's the data format of the
agent. What's the data format of the
policy when you save it? It is the same
policy when you save it? It is the same
neural network executed independently.
neural network executed independently.
So they're not the same agent. They are
So they're not the same agent. They are
completely independent of each other. Uh
completely independent of each other. Uh
but they share the same logic.
That is our standard setting.
And my PhD is in multi-agent RL. There
And my PhD is in multi-agent RL. There
are a lot of other things you can do.
are a lot of other things you can do.
Some of them make sense, but mostly it's
Some of them make sense, but mostly it's
kind of best to just do it this way.
This
This
not log in this.
not log in this.
Oh, yes.
Probably needs to be swept. Batch size 3
Probably needs to be swept. Batch size 3
million. I'm going to go read up.
million. I'm going to go read up.
Yeah, we have some pretty cool stuff. I
Yeah, we have some pretty cool stuff. I
think the best agent Very nice work,
think the best agent Very nice work,
Kingpuffer. Thank you. The best agent
Kingpuffer. Thank you. The best agent
that we have is the uh so the one
that we have is the uh so the one
pedabyte agent is available on the
pedabyte agent is available on the
website.
website.
It plays neural MMO 3. Takes a second to
It plays neural MMO 3. Takes a second to
load in because now it's loading a
load in because now it's loading a
neural net and stuff. Um
neural net and stuff. Um
so this is a big game. Oops.
so this is a big game. Oops.
I think I hit escape by mistake. Escape
I think I hit escape by mistake. Escape
is mapped to uh
is mapped to uh
undo. Hang on.
Did we break it?
Did we break it?
When does tab break it?
When does tab break it?
Oh, that's obnoxious.
You should be able to zoom out on the
You should be able to zoom out on the
map.
I didn't even push an update to this
I didn't even push an update to this
thing recently.
thing recently.
Well, apparently I can't zoom out to
Well, apparently I can't zoom out to
show you how big the map is, but the
show you how big the map is, but the
trailer for that is on X. Actually, you
trailer for that is on X. Actually, you
know what? No, I totally can because I
know what? No, I totally can because I
have it locally.
Neural MMO policy is only 3 million
Neural MMO policy is only 3 million
parameters. All right, this is the map.
parameters. All right, this is the map.
It's not actually fractal, but we It's I
It's not actually fractal, but we It's I
left it this way because we do actually
left it this way because we do actually
train on multiple maps at the same time,
train on multiple maps at the same time,
so it makes sense.
so it makes sense.
So, it's like this big MMO.
And
And
if you watch the agent, you'll see that
if you watch the agent, you'll see that
it's capable of using tools. It gets
it's capable of using tools. It gets
equipment. It knows how to put stuff on.
equipment. It knows how to put stuff on.
It knows how to fight. It knows how to
It knows how to fight. It knows how to
kite enemies. Sometimes it even knows
kite enemies. Sometimes it even knows
how to sell and buy items on this
how to sell and buy items on this
marketplace.
like a 3.4 million parameter-ish
like a 3.4 million parameter-ish
network.
This is our best agent. I would say
This is our best agent. I would say
I wrote an article about this. I
I wrote an article about this. I
subjectively consider this result to be
subjectively consider this result to be
better than emergent tool use and
better than emergent tool use and
capture the flag, but uh nowhere near as
capture the flag, but uh nowhere near as
good as something like Alpha Star and
good as something like Alpha Star and
Dota
Dota
based on my own subjective opinion. So
based on my own subjective opinion. So
deal with it.
Option space there is huge.
Option space there is huge.
in neural MMO. Yeah, you'd think so. But
in neural MMO. Yeah, you'd think so. But
guess what? I have the action space
guess what? I have the action space
mapped to something like a discrete of
mapped to something like a discrete of
26.
26.
That's part of energy design.
There are some tricks that we have.
It's a bit ry. I mean, I'd hope it's
It's a bit ry. I mean, I'd hope it's
cool. I've literally neural MMO was the
cool. I've literally neural MMO was the
topic of my entire PhD and two years
topic of my entire PhD and two years
worth of research before that.
I'd hope it's cool.
Yeah, thank you. We're not done with it
Yeah, thank you. We're not done with it
either. I literally have um I have an
either. I literally have um I have an
experiment going right now.
It's doing another one pabyte experiment
It's doing another one pabyte experiment
at the moment.
This is approximately
This is approximately
uh 350 terabytes. No wait is it 350?
uh 350 terabytes. No wait is it 350?
Yeah, 350 terabytes into training and
Yeah, 350 terabytes into training and
currently it is doing
currently it is doing
pretty dang well.
pretty dang well.
Can you say what hardware you're running
Can you say what hardware you're running
this on?
this on?
You see right behind me,
You see right behind me,
you see the white boxes up on the
you see the white boxes up on the
shelves? Those are tiny boxes. There's
shelves? Those are tiny boxes. There's
six GPUs a piece, six 4090s.
six GPUs a piece, six 4090s.
And uh we ran these experiments. Just
And uh we ran these experiments. Just
need one of those boxes to run an
need one of those boxes to run an
experiment like this for maybe three
experiment like this for maybe three
days, three to four days.
You don't need a crazy amount of
You don't need a crazy amount of
hardware. You need a little bit of
hardware. You need a little bit of
hardware, not a crazy amount.
hardware, not a crazy amount.
This is the only thing in Puffer that
This is the only thing in Puffer that
requires a multiGPU machine as well.
requires a multiGPU machine as well.
Nothing else requires multiGPU.
Nothing else requires multiGPU.
Everything else you can train at home on
Everything else you can train at home on
like a single 4090
like a single 4090
3080 or whatever if you have one. It'll
3080 or whatever if you have one. It'll
just take long, right?
just take long, right?
You're never going to be out of memory
You're never going to be out of memory
for the most part.
Okay, let me get this stuff configured.
Okay, let me get this stuff configured.
I got to go to dinner soonish. I want to
I got to go to dinner soonish. I want to
make sure that we get a sweep going on
make sure that we get a sweep going on
this
read up on the details. This is awesome.
read up on the details. This is awesome.
Thanks. Hey, I hope you enjoy. We're
Thanks. Hey, I hope you enjoy. We're
always looking for new contributors. So,
always looking for new contributors. So,
if you want to get involved with
if you want to get involved with
research, be very happy for the help.
Yep.
stream every day. I do not stream seven
stream every day. I do not stream seven
days a week. I do occasionally rest. Uh
days a week. I do occasionally rest. Uh
I mostly stream at the moment on
I mostly stream at the moment on
reasonable hours Eastern time subject to
reasonable hours Eastern time subject to
other meetings and stuff that I have to
other meetings and stuff that I have to
take. So, most of the day EST,
take. So, most of the day EST,
sometimes in the evenings, depends how,
sometimes in the evenings, depends how,
you know, depends how I'm feeling.
you know, depends how I'm feeling.
Sometimes I work late as well. Uh,
Sometimes I work late as well. Uh,
usually stream like Monday through
usually stream like Monday through
Saturday.
Saturday.
Now, the thing is I am going in uh in
Now, the thing is I am going in uh in
like a week. I'm going to Palo Alto. So,
like a week. I'm going to Palo Alto. So,
I'll be on Pacific for a bit and I'll
I'll be on Pacific for a bit and I'll
probably be having a lot of like
probably be having a lot of like
business meetings to deal with because
business meetings to deal with because
that's the point of being there right by
that's the point of being there right by
SF. All sorts of meetings. Then I'm
SF. All sorts of meetings. Then I'm
going to RLC. So, I will be at RLC in
going to RLC. So, I will be at RLC in
person for uh presenting Puffer Lib
person for uh presenting Puffer Lib
Puffer Lib 2, which is old at this
Puffer Lib 2, which is old at this
point, but that's the paper that got
point, but that's the paper that got
accepted. And then I'll be back in Po
accepted. And then I'll be back in Po
Alto for a few weeks and then I'll be
Alto for a few weeks and then I'll be
back here for quite a while.
Oh, it's not super consistent when, but
Oh, it's not super consistent when, but
the number of hours is quite cons. That
the number of hours is quite cons. That
makes sense.
Congrats
on all the W's. Thank you.
Well,
Well,
we could still use uh some larger
we could still use uh some larger
contracts, right?
contracts, right?
We have a
We have a
slightly profitable private RL lab.
slightly profitable private RL lab.
Ideally, we could have a very profitable
Ideally, we could have a very profitable
private RL lab and then we can fund way
private RL lab and then we can fund way
more research.
That is the ideal.
Make that happen for sure. I hope so as
Make that happen for sure. I hope so as
well. I think we should be good.
I pretty much just need to be spending
I pretty much just need to be spending
uh a decent chunk of time looking for
uh a decent chunk of time looking for
good applications where we can really uh
good applications where we can really uh
solve people's problems with RL.
solve people's problems with RL.
Sort of been doing that passively over
Sort of been doing that passively over
the last weeks since the release.
Find a couple of those and we should
Find a couple of those and we should
get back to doing more research.
UK.
So this works. Yeah.
Have you looked at chip optimization
Have you looked at chip optimization
with RL? Planning to give that a go
with RL? Planning to give that a go
soon.
It's a much harder problem because it's
It's a much harder problem because it's
a placement problem. You kind of just
a placement problem. You kind of just
have to zero shot output the entire
have to zero shot output the entire
chip.
chip.
We do have some good RL stuff, so it's
We do have some good RL stuff, so it's
possible we could do something there.
possible we could do something there.
I've sort of thought about it. It's not
I've sort of thought about it. It's not
anywhere near as easy of an application
anywhere near as easy of an application
for initial entry point into industry.
for initial entry point into industry.
Um, we actually almost got a client in
Um, we actually almost got a client in
that space quite a while ago just on
that space quite a while ago just on
like the general RL tech that we were
like the general RL tech that we were
doing.
need a high-speed simulator is a big
need a high-speed simulator is a big
barrier. Yep. Are there workarounds that
barrier. Yep. Are there workarounds that
you could invent? Yes, there very much
you could invent? Yes, there very much
are. And that is the uh the subject of
are. And that is the uh the subject of
quite a bit of research. I think we are
quite a bit of research. I think we are
better positioned than anybody else to
better positioned than anybody else to
do that research. But the thing is like
do that research. But the thing is like
we kind of already have a bunch of
we kind of already have a bunch of
valuable tech. So my plan for the time
valuable tech. So my plan for the time
being is to find useful areas where we
being is to find useful areas where we
can build fast simulators. Uh make the
can build fast simulators. Uh make the
company much more profitable doing a
company much more profitable doing a
couple of those things and then invest
couple of those things and then invest
that to do the research to make RL work
that to do the research to make RL work
in other areas. Right? That seems the
in other areas. Right? That seems the
most sensible course to me.
most sensible course to me.
Can we just appreciate that this thing
Can we just appreciate that this thing
is running at 4 million steps per
is running at 4 million steps per
second? By the way,
thing is running like an overnight the
thing is running like an overnight the
equivalent of like an overnight
equivalent of like an overnight
experiment from my PhD every two
experiment from my PhD every two
seconds.
seconds.
All right, we'll leave this here and
All right, we'll leave this here and
then this will uh run us a nice hyper
then this will uh run us a nice hyper
pram sweep.
He should be good shape with that.
What else do I want to do on this? I may
What else do I want to do on this? I may
as well just clean it up for a little
as well just clean it up for a little
bit right now before I have to head for
bit right now before I have to head for
dinner. I'm going to head out just a
dinner. I'm going to head out just a
little bit early, I think, as well. My
little bit early, I think, as well. My
uh my family is visiting. They just got
uh my family is visiting. They just got
here. Um, but let me real quick I just
here. Um, but let me real quick I just
want to rename it real
Hey yay.
I'm back. How much of the drone code
I'm back. How much of the drone code
have you written by yourself? How much
have you written by yourself? How much
of it is off this shelf? Such a huge
of it is off this shelf? Such a huge
space. We have two undergrads who are
space. We have two undergrads who are
helping with the drone stuff. Uh they
helping with the drone stuff. Uh they
wrote I will show you their sim.
wrote I will show you their sim.
None of it's off the shelf though,
None of it's off the shelf though,
that's for sure.
So Finn and Sam, who are in the Discord,
So Finn and Sam, who are in the Discord,
wrote this.
wrote this.
I helped a little bit with some of the
I helped a little bit with some of the
learning, but they wrote this.
trained with Puffer Lib.
trained with Puffer Lib.
And then in the last like day and a
And then in the last like day and a
half, I modified this. I made a version
half, I modified this. I made a version
of it that has supports a bunch of
of it that has supports a bunch of
drones. And then I instead of having
drones. And then I instead of having
ring targets, I have a configuration
ring targets, I have a configuration
that's essentially just like tells the
that's essentially just like tells the
drone to follow an instruction. There's
drone to follow an instruction. There's
Finn. Finn's one of the authors of this.
You'll see, Larry, that um like a lot of
You'll see, Larry, that um like a lot of
the stuff in Puffer Lib, it's like these
the stuff in Puffer Lib, it's like these
crazy things, but it ends up just being
crazy things, but it ends up just being
a few hundred lines of code with the way
a few hundred lines of code with the way
we build everything.
we build everything.
Like the more complicated stuff ends up
Like the more complicated stuff ends up
being a few thousand lines of code. But
being a few thousand lines of code. But
I think all of neural MMO 3, this whole
I think all of neural MMO 3, this whole
project here is under 3,000 lines.
No, it's the exact opposite. None of it
No, it's the exact opposite. None of it
is abstracted. That's why it's short.
This is why you like you see me writing
This is why you like you see me writing
like uh almost no dependencies C.
Oh, whoops.
Environments and C. I have some practice
Environments and C. I have some practice
to do. I'm a physics grad. Oh, yeah.
to do. I'm a physics grad. Oh, yeah.
Perfect. You'll be well positioned then.
Perfect. You'll be well positioned then.
That's actually super useful cuz that's
That's actually super useful cuz that's
like one of the things I'm very bad at
like one of the things I'm very bad at
and I love having people around who are
and I love having people around who are
good at that.
We keep the C really simple though, like
We keep the C really simple though, like
really really simple.
We actually have brand new programmers
We actually have brand new programmers
who uh who have gotten into Puffer Lab
who uh who have gotten into Puffer Lab
and have been just fine.
Like this is the entire source code
Like this is the entire source code
right here is this 800 line file. And
right here is this 800 line file. And
I'm actually embarrassed that this is
I'm actually embarrassed that this is
800 lines. Like it should not be 800
800 lines. Like it should not be 800
lines. So I'll have to go figure out
lines. So I'll have to go figure out
what the heck redundant stuff I have in
what the heck redundant stuff I have in
here.
Okay, there we go. Still works. Commit
Okay, there we go. Still works. Commit
this.
trying to solve a fiber optic path
trying to solve a fiber optic path
finding algorithm at the moment.
finding algorithm at the moment.
Cool.
The name of the game with RL is like
The name of the game with RL is like
fast
fast
as fast simulation as you possibly can
as fast simulation as you possibly can
for interactive processes, right?
for interactive processes, right?
So if you have a problem that can be
So if you have a problem that can be
formulated as an interactive process,
formulated as an interactive process,
you can write a fast sim for it. RL is
you can write a fast sim for it. RL is
usually a good fit. There are a few
usually a good fit. There are a few
exceptions. Stuff that relies a ton on
exceptions. Stuff that relies a ton on
like language is not great. Vision is
like language is not great. Vision is
better, but still not amazing, mainly
better, but still not amazing, mainly
just because it makes the Sim slow. Um,
just because it makes the Sim slow. Um,
but other than that, yeah, you can solve
but other than that, yeah, you can solve
like a lot of really unintuitive
like a lot of really unintuitive
problems really, really fast with this
problems really, really fast with this
stuff.
Do you think pathf finding could be an
Do you think pathf finding could be an
RL problem? Uh, you could turn it into
RL problem? Uh, you could turn it into
one.
one.
Yeah, you could definitely turn it into
Yeah, you could definitely turn it into
one. I mean, we have um
one. I mean, we have um
well, it actually takes a second to
well, it actually takes a second to
train an agent to do our mazes.
train an agent to do our mazes.
Let me see if I can find the graphic of
Let me see if I can find the graphic of
our mazes.
our mazes.
It was in the one of the articles.
It was in the one of the articles.
We have the best maze solving RL agent
We have the best maze solving RL agent
that doesn't like hack it with other
that doesn't like hack it with other
stuff.
Yeah. So, here's our maze solving agent.
You kind of need to be familiar with RL
You kind of need to be familiar with RL
stuff to know how impressive this is.
stuff to know how impressive this is.
Um, this maze right here, like that tiny
Um, this maze right here, like that tiny
one. Yeah, this that's about as big as
one. Yeah, this that's about as big as
the mazes usually get in RL. And even
the mazes usually get in RL. And even
that doesn't really work. And people
that doesn't really work. And people
like hack the algorithm to force it to
like hack the algorithm to force it to
work. So, this is what we got just out
work. So, this is what we got just out
of the box without really doing anything
of the box without really doing anything
special, just running our algorithm.
cominatorial optimizations on graphs in
cominatorial optimizations on graphs in
the dev channel. You can definitely try
the dev channel. You can definitely try
it.
Yeah, you can definitely try it.
It's like kind of a decent approach for
It's like kind of a decent approach for
stuff where verifying the problem is
stuff where verifying the problem is
really fast,
really fast,
but like can't even really get good data
but like can't even really get good data
on the problem because generating the
on the problem because generating the
data is super slow.
The heck is this?
RG puffer.
See, I'll check this and then I got to
See, I'll check this and then I got to
run.
Oh, wait. in the VC do you mean or what
we have this weird case where some
we have this weird case where some
networks subsidized like free to build
networks subsidized like free to build
so some of the edges in the nodes are
so some of the edges in the nodes are
free mitations limit that's fun
I I don't know who this is just chilling
I I don't know who this is just chilling
in the VC if that's what you meant
in the VC if that's what you meant
I do have to run and uh I got to run for
I do have to run and uh I got to run for
in there.
Okay. So, for the folks watching here,
Okay. So, for the folks watching here,
thank you for tuning in today.
thank you for tuning in today.
Probably won't be back after dinner.
Probably won't be back after dinner.
We'll see. My family is here. Uh they're
We'll see. My family is here. Uh they're
visiting.
I will be back in the morning. So if
I will be back in the morning. So if
you're interested in all this stuff,
you're interested in all this stuff,
puffer.ai for all the things,
puffer.ai for all the things,
lots of cool projects built by
lots of cool projects built by
contributors here. If you want to help
contributors here. If you want to help
me out for free, literally free in 5
me out for free, literally free in 5
seconds, just star the repo. Feed the
seconds, just star the repo. Feed the
puffer. It really helps. Like actually
puffer. It really helps. Like actually
starring the repo really helps. And uh
starring the repo really helps. And uh
other than that, yeah, join the Discord.
other than that, yeah, join the Discord.
You can follow me on X for more and all
You can follow me on X for more and all
that. And I will be back tomorrow. More
that. And I will be back tomorrow. More
reinforcement learning.

Kind: captions
Language: en
Hello,
Hello,
we are back live.
we are back live.
Hi.
I am late today once again
I am late today once again
with a good reason for the most part.
with a good reason for the most part.
I actually got up pretty early this
I actually got up pretty early this
morning.
morning.
I started working on a new article for
I started working on a new article for
you all.
you all.
I think it's one that people will really
I think it's one that people will really
like, but it's going to take quite a bit
like, but it's going to take quite a bit
more work.
more work.
I literally just wrote the intro
I literally just wrote the intro
sections today.
Hopefully that'll be out within the next
Hopefully that'll be out within the next
couple of weeks. See?
couple of weeks. See?
So, what are we going to do today?
today.
First of all, we have this nice sweep
First of all, we have this nice sweep
result where we've solved 2048 pretty
result where we've solved 2048 pretty
well, apparently.
well, apparently.
But what we're going to do today is
But what we're going to do today is
we're going to work on the drone sim for
we're going to work on the drone sim for
a bit.
a bit.
That's like the main plan.
Specifically,
I think we're just going to formulate
I think we're just going to formulate
the uh the drone
the uh the drone
objective as go to point and don't
objective as go to point and don't
collide
collide
and like most things will be some
and like most things will be some
combination of go to point and don't
combination of go to point and don't
collide for this them specifically
take a quick look at the current thing
this is what we have All right,
got a model.
Got to mess with these reward functions.
Got to mess with these reward functions.
So,
most of these are not that bad.
most of these are not that bad.
I think the only thing that really needs
I think the only thing that really needs
to change is
the orbit one.
Probably the orbit one.
I need to generate points on a sphere.
What's a good number of8 Eight
any I think like four.
What's the easiest way to do this? So I
What's the easiest way to do this? So I
want to generate points
want to generate points
on a sphere.
This is going to be some obnoxious
This is going to be some obnoxious
function actually, isn't it?
I don't know. Let's do
All right.
This is the type of thing though that's
This is the type of thing though that's
done very quickly in a shader.
See
if I can get a reasonable function.
Okay. So you get the cartisian
Okay. So you get the cartisian
coordinates
coordinates
from the conversion to spherical. I
from the conversion to spherical. I
don't know why you do it angular, but
don't know why you do it angular, but
sure.
M rings.
That's like super obnoxious.
Should be able to do it
Should be able to do it
as a pure function of time.
Oh yeah, I also I forgot that I posted
Oh yeah, I also I forgot that I posted
uh the trailer to YouTube
of the neural MMO channel.
We have this one which is posted.
Why is it CCD?
Why is it CCD?
Welcome to the boot. Oh, that's close
Welcome to the boot. Oh, that's close
captions.
Okay. So, they both have I don't know
Okay. So, they both have I don't know
some small number of views.
some small number of views.
Well, the guys I'm on these posted um I
Well, the guys I'm on these posted um I
forget what 12. Okay. 13 hours ago.
forget what 12. Okay. 13 hours ago.
Cool. Trailers are up.
Yeah, I think regardless of how I do
Yeah, I think regardless of how I do
this, it's going to be annoying,
this, it's going to be annoying,
but we'll just start on
I really don't like this type of Well,
I really don't like this type of Well,
to be fair, if I as long as I get it, I
to be fair, if I as long as I get it, I
can verify that this is correct
can verify that this is correct
separately, I guess, and then I can do
separately, I guess, and then I can do
the RL. So, normally I'm very adverse to
the RL. So, normally I'm very adverse to
doing anything remotely janky because
doing anything remotely janky because
then RL makes it way worse.
then RL makes it way worse.
Thanks for sending over some drone kit.
Thanks for sending over some drone kit.
Of course, Ben, have you gotten any more
Of course, Ben, have you gotten any more
of it?
of it?
They should all be there somewhat soon.
Heck yeah, man.
Heck yeah, man.
I'm still working on the drone stuff. I
I'm still working on the drone stuff. I
realized that we can do a lot of demos
realized that we can do a lot of demos
just as a function of like go to
just as a function of like go to
position but with just like different
position but with just like different
versions of that basically. So, I'm
versions of that basically. So, I'm
working on that right
Okay.
Kind of need the index, don't you?
super annoying. Works
Well,
Well,
let's just say for now
let's just say for now
going to do
is so incredibly jank.
Arrow and Omega
Arrow and Omega
Radius.
Fine.
Fine.
Guess that's spiral to cartisian.
Guess that's spiral to cartisian.
Maybe something like this is not
Maybe something like this is not
terrible.
All we have to do is set a uh a per
All we have to do is set a uh a per
drone target, right?
So, we just do
Move this to here.
You know, this is actually not going to
You know, this is actually not going to
be bad.
be bad.
I could use a little bit of just chill
I could use a little bit of just chill
work like this for a bit.
work like this for a bit.
The only mildly annoying thing is the um
The only mildly annoying thing is the um
the sphere math.
I think if we're clever here, I can
I think if we're clever here, I can
probably uh come up with a whole bunch
probably uh come up with a whole bunch
of
of
cool demos just based on this one simple
cool demos just based on this one simple
thing.
Okay. So, in reset,
this needs to move
this needs to move
up to here.
Now all the agents have different
Now all the agents have different
targets.
We can do update target.
Now, this is actually going to be the
Now, this is actually going to be the
same exact thing as before, just way
same exact thing as before, just way
easier,
easier,
right?
Okay. Solid.
What are you using that auto complete.
What are you using that auto complete.
Is this just now
Okay. Okay. So for idle targets
can probably do like um
can probably do like um
where's the sphere velocity thing?
this thing right
think how we're going to synchronize
think how we're going to synchronize
this for
for everything.
Do we do it based on the initial?
Do we do it based on the initial?
Hope it doesn't diverge.
Oh, I don't like that.
Leave it like this for now.
Oh yeah. Is it Was it It's
bit. So yeah, this works.
bit. So yeah, this works.
This here works.
And what else did we have? We had
And what else did we have? We had
follow.
follow.
This was the one that I didn't know how
This was the one that I didn't know how
to do cleanly.
This is technically like a move target I
This is technically like a move target I
guess,
guess,
right?
right?
This can be move target
and then this one can be
This is going to collapse them all to
This is going to collapse them all to
one target for now.
one target for now.
Okay.
Now we have something like this.
have to do
going to be distance reward.
This gives us position target.
Uh yeah, not this at all though. I wish
Uh yeah, not this at all though. I wish
I could disable multi-line.
And then what was the reward I came up
And then what was the reward I came up
with? Yeah, negative.
with? Yeah, negative.
So we just do reward plus
So we just do reward plus
float
negative distance over max distance.
negative distance over max distance.
So
your distance reward
your distance reward
times density.
So I believe this is going to one minus
Okay, cool. So, compute reward.
Okay, cool. So, compute reward.
Now, all this needs doesn't need decks
Now, all this needs doesn't need decks
anymore. So, that's cool.
Hey, Major.
Hey, Major.
Daily grind continues as per usual.
Speaking of which, we have the daily
Speaking of which, we have the daily
grind of fly killing because I had some
grind of fly killing because I had some
maintenance work and I see three flies
maintenance work and I see three flies
that I may as well just kill now while
that I may as well just kill now while
that's easy to do. So,
One
- 3
- 4.
I actually have thought about doing an
I actually have thought about doing an
RL trained laser turret in moments of
RL trained laser turret in moments of
frustration.
Seems like a lot of work and I don't
Seems like a lot of work and I don't
think I'd be able to actually sell them
think I'd be able to actually sell them
for any reasonable amount of money.
for any reasonable amount of money.
You'd probably just get sued for
You'd probably just get sued for
blinding people with them.
blinding people with them.
That's my guess.
I would very much like to just back the
I would very much like to just back the
damn things though.
Yeah, I've been working on uh one of the
Yeah, I've been working on uh one of the
things I've been working on here is
things I've been working on here is
trying to figure out how we can just
trying to figure out how we can just
reduce the number of stuff that gets in.
reduce the number of stuff that gets in.
It is a farm and lots of just bugs and
It is a farm and lots of just bugs and
things get in. And man, it's like you
things get in. And man, it's like you
think, oh yeah, it's no big deal. You
think, oh yeah, it's no big deal. You
deal with a bug once in a while. But the
deal with a bug once in a while. But the
thing is, when you have stuff that like
thing is, when you have stuff that like
lands on you once in a while, right, and
lands on you once in a while, right, and
you look and oh shoot, it's a bug, like
you look and oh shoot, it's a bug, like
every single time something slightly
every single time something slightly
itches,
itches,
you will think, "Oh, it's a bug." And it
you will think, "Oh, it's a bug." And it
will drive you insane.
Incredibly annoying. Yeah.
Incredibly annoying. Yeah.
And actually, it's so buggy outside. I
And actually, it's so buggy outside. I
stopped running outside. Well, first of
stopped running outside. Well, first of
all, it's stupid hot here and I'm going
all, it's stupid hot here and I'm going
to be in California in a few weeks. I'll
to be in California in a few weeks. I'll
be able to run there anyways. But other
be able to run there anyways. But other
than that, like literally I went for a
than that, like literally I went for a
run for I think an hour and five minutes
run for I think an hour and five minutes
and I had like four or five golf balls
and I had like four or five golf balls
sized welts on my back by the end of it
sized welts on my back by the end of it
from just like big horse flies just
from just like big horse flies just
taking chunks out of me. You literally
taking chunks out of me. You literally
like rip like a horsefly off of you.
like rip like a horsefly off of you.
this mid run. It's horrible.
So, I've been Can you even see that
So, I've been Can you even see that
here? Yeah, you can probably see in the
here? Yeah, you can probably see in the
background. I got the bike and I've got
background. I got the bike and I've got
the URG.
the URG.
I think you should make some from
I think you should make some from
scratch tutorial videos for some DMs,
scratch tutorial videos for some DMs,
integrating them, designing reward
integrating them, designing reward
terminal conditions, adjusting
terminal conditions, adjusting
parameters, bugs, and sweeping
parameters, bugs, and sweeping
hyperparams because the articles are
hyperparams because the articles are
cool, but videos are always better and
cool, but videos are always better and
more appreciated. I'm actually going to
more appreciated. I'm actually going to
take that quote. I'm going to put it
take that quote. I'm going to put it
into the article that I'm working on
into the article that I'm working on
at the bottom right here. So, I remember
at the bottom right here. So, I remember
this. So, here's the issue with the
this. So, here's the issue with the
videos, right? Making good video
videos, right? Making good video
tutorials
tutorials
takes an utterly stupid amount of time.
takes an utterly stupid amount of time.
Like, a truly ludicrous amount of time.
Like the iceberg video that I published.
Like the iceberg video that I published.
But I would want to publish something at
But I would want to publish something at
least if I'm going to release videos,
least if I'm going to release videos,
right? I'd want to release something
right? I'd want to release something
that's as high quality as my iceberg
that's as high quality as my iceberg
video.
This was like this took me two weeks of
This was like this took me two weeks of
work. Language. This is like the highest
work. Language. This is like the highest
quality thing I could put out. All
quality thing I could put out. All
right. I put the tux on. I did all this
right. I put the tux on. I did all this
editing. I probably could have made the
editing. I probably could have made the
editing better if I just hired an editor
editing better if I just hired an editor
instead of doing it myself. We'll do
instead of doing it myself. We'll do
that in the future. But, you know, I
that in the future. But, you know, I
could have spent it would probably cost
could have spent it would probably cost
me, you know, a few thousand dollars at
me, you know, a few thousand dollars at
least to get a competent editor for
least to get a competent editor for
something this length.
something this length.
Uh, and this thing got over the last
Uh, and this thing got over the last
several months 3,500 views.
That's like simply not worth it.
That's like simply not worth it.
The articles on the other hand
The articles on the other hand
occasionally they take a lot less time
occasionally they take a lot less time
first of all and they occasionally do
first of all and they occasionally do
quite well. So this one that I wrote
quite well. So this one that I wrote
here, right, this has gotten 100k views.
here, right, this has gotten 100k views.
This is actually like this is a
This is actually like this is a
worthwhile investment of of my time to
worthwhile investment of of my time to
do stuff like this.
I am actually working on a much more in
I am actually working on a much more in
detailed article though. Much more in
detailed article though. Much more in
detailed article.
detailed article.
You'll get this in maybe a few weeks.
That one will take quite a bit longer to
That one will take quite a bit longer to
write, but nowhere near as long it was
write, but nowhere near as long it was
it would take to make a video.
a lot of value
doing for gamedev but you know
doing for gamedev but you know
a lot of yeah it's just like
if I were getting if people were
if I were getting if people were
actually like go like using them I would
actually like go like using them I would
do it. Um, but I can't like justify
do it. Um, but I can't like justify
taking two weeks
taking two weeks
to make like a tutorial of that form for
to make like a tutorial of that form for
people to not watch it when I also have
people to not watch it when I also have
a business to build.
a business to build.
And like I'm doing this double time
And like I'm doing this double time
basically as is. Not always double time,
basically as is. Not always double time,
not consistent, but very often working
not consistent, but very often working
double time.
I pretty much work double time until my
I pretty much work double time until my
I burn myself out and then I work normal
I burn myself out and then I work normal
hours for a week or two and then I do it
hours for a week or two and then I do it
again.
See the thing is like I literally did
See the thing is like I literally did
stuff like that before as well. The
stuff like that before as well. The
thing like when puffer when I did like
thing like when puffer when I did like
puffer 10
puffer 10
if you will check on the YouTube
I did like a seminar I did uh here
This is like a full walkthrough of the
This is like a full walkthrough of the
library. Didn't like nobody saw this.
library. Didn't like nobody saw this.
I' like I tried a few different
I' like I tried a few different
experiments and it just didn't catch on
experiments and it just didn't catch on
at all.
at all.
Really, the thing that has been best on
Really, the thing that has been best on
YouTube has just been the consistent
YouTube has just been the consistent
like people getting involved from the
like people getting involved from the
live streams.
And this was on a channel that's already
And this was on a channel that's already
had, you know, a couple thousand
had, you know, a couple thousand
subscribers on it as well because my uh
subscribers on it as well because my uh
my thesis defense video did very very
my thesis defense video did very very
well.
well.
But the uh the YouTube algorithm is
But the uh the YouTube algorithm is
super super fiddly and it's just like so
super super fiddly and it's just like so
uncertain if like technical content like
uncertain if like technical content like
this actually gets seen.
It was pretty rough. It's pretty rough
It was pretty rough. It's pretty rough
overall.
I also and I also don't enjoy it at all.
I also and I also don't enjoy it at all.
Like I like producing videos is like
Like I like producing videos is like
horrendously mind-numbing
horrendously mind-numbing
like time consuming boring work as well.
So, I basically have to torture myself
So, I basically have to torture myself
for like a few weeks to make a video,
for like a few weeks to make a video,
like a a long form video like
I know how we can do this.
I know how we can do this.
We can do it.
How about running streams and clipping
How about running streams and clipping
them and p pushing them
them and p pushing them
always general purpose and mostly mixed
always general purpose and mostly mixed
recreational programming way.
I might run some sort of tutorial on it.
I might run some sort of tutorial.
You do realize like for that type of
You do realize like for that type of
content, it's not as easy as like I just
content, it's not as easy as like I just
turn the stream on and like do a thing
turn the stream on and like do a thing
for 30 minutes and then clip. Like
for 30 minutes and then clip. Like
the quality of that is going to be like
the quality of that is going to be like
way way way lower versus something
way way way lower versus something
prepared.
That's super annoying.
There will be some more educational
There will be some more educational
content though. There will be
I have to figure out how to space it out
I have to figure out how to space it out
and like where to allocate the effort
and like where to allocate the effort
because you know my main thing is not
because you know my main thing is not
educational content. It's kind of just
educational content. It's kind of just
been like a recent thing that um Tuffer
been like a recent thing that um Tuffer
has become so like relatively so much
has become so like relatively so much
easier to use than everything else in RL
easier to use than everything else in RL
that we're getting like lots of new
that we're getting like lots of new
people which is awesome and many of them
people which is awesome and many of them
have actually gone on to be productive
have actually gone on to be productive
contributors to the research. uh it does
contributors to the research. uh it does
require me to rethink a few things as to
require me to rethink a few things as to
how they're framed because like when I
how they're framed because like when I
started Puffer Lib the initial audience
started Puffer Lib the initial audience
was RLP PhD and then it went down to
was RLP PhD and then it went down to
like you know ML PhD
like you know ML PhD
right and then it went down to like AI
right and then it went down to like AI
engineers and now we're at the point
engineers and now we're at the point
where we have literally brand new
where we have literally brand new
programmers doing this stuff it's like
programmers doing this stuff it's like
ah crap okay I didn't position this for
ah crap okay I didn't position this for
any of I didn't position this for that
any of I didn't position this for that
at all I have to figure out How to do
at all I have to figure out How to do
that?
that?
Implementation of N forX
Implementation of N forX
improving rewards network design
network
parts.
parts.
So like I can do that, right? But here's
So like I can do that, right? But here's
the thing. Here's the thing that's just
the thing. Here's the thing that's just
jank about that, right? If I did that as
jank about that, right? If I did that as
a prepared video,
a prepared video,
I could do that entire thing in like a
I could do that entire thing in like a
one hour lecture
one hour lecture
and like live with all the demos. I
and like live with all the demos. I
could do that whole thing in like a
could do that whole thing in like a
really good one hour lecture.
really good one hour lecture.
It would take me like
It would take me like
probably close to a month to make that
probably close to a month to make that
video.
video.
If I do it as a series of live streams,
If I do it as a series of live streams,
it's going to be like
It's not going to give you thorough
It's not going to give you thorough
coverage because like you're not going
coverage because like you're not going
to see all those different things in the
to see all those different things in the
context of several different examples
context of several different examples
and it's going to be like you know many
and it's going to be like you know many
hours
and people don't watch many hour videos.
and people don't watch many hour videos.
Turns out
I have been trying to clip some of the
I have been trying to clip some of the
educational like tips and things um and
educational like tips and things um and
start uploading like short little clips.
start uploading like short little clips.
It's a little tricky to do, but I've
It's a little tricky to do, but I've
been trying to figure that out, how to
been trying to figure that out, how to
do it more efficiently.
Like really, the main jam around here
Like really, the main jam around here
is improving the research. I have to
is improving the research. I have to
figure out how to still make that the
figure out how to still make that the
focus, right?
Okay. So, this map did not map like
Well, this is cool.
This is a good algorithm.
This is a good algorithm.
How the heck does this work?
Some sort of like serious
Some sort of like serious
Fibonacci number. That's weird.
Fibonacci number. That's weird.
Cool.
Some people watch actually watch them. I
Some people watch actually watch them. I
do.
do.
I watch long form stuff too. Very few
I watch long form stuff too. Very few
do.
Carpathia stuff of course.
I I interned in uh in Fe's lab I think
I I interned in uh in Fe's lab I think
in like 2014 or something when he was
in like 2014 or something when he was
still a student there.
He's a funny guy.
Yeah. Honestly, the probably the best
Yeah. Honestly, the probably the best
way to motivate me to uh make tutorials
way to motivate me to uh make tutorials
is to make bad tutorials.
So, we'll see how that goes. Um,
So, we'll see how that goes. Um,
let's see how this article that I'm
let's see how this article that I'm
working on goes first because like this
working on goes first because like this
should be a pretty good comprehensive
should be a pretty good comprehensive
article.
Actually, grab
Actually, grab
this stuff. Well,
this stuff. Well,
as references for like the type of stuff
as references for like the type of stuff
that people are interested in.
This
This
obviously that's not going in the
obviously that's not going in the
article. I'll use that to write stuff
article. I'll use that to write stuff
based on it.
Also, everybody wants more content.
Also, everybody wants more content.
Nobody wants to feed the puffer a star.
Nobody wants to feed the puffer a star.
Go star the repo. It's literally free.
Go star the repo. It's literally free.
Takes 5 seconds. Did the puffer a star?
Takes 5 seconds. Did the puffer a star?
He's hungry.
I opened a PR for the drone and
I opened a PR for the drone and
simple
simple
realistic motor. Okay, I will have to
realistic motor. Okay, I will have to
look at that in more detail. Major, let
look at that in more detail. Major, let
me I want to finish this thing right now
me I want to finish this thing right now
while I still like before I run out of
while I still like before I run out of
steam. I've already done a bunch of
steam. I've already done a bunch of
stuff this morning. Um, I want to have
stuff this morning. Um, I want to have
this environment done today so we have
this environment done today so we have
like a standalone second drone
like a standalone second drone
environment.
environment.
And then we're going to probably figure
And then we're going to probably figure
out a way to like pull out the drone so
out a way to like pull out the drone so
that the drone can just be the
that the drone can just be the
standalone thing and we can like do all
standalone thing and we can like do all
the physics tests including motor lag.
the physics tests including motor lag.
I will definitely incorporate that
I will definitely incorporate that
though if that is a a reasonable thing
though if that is a a reasonable thing
to model it.
Man,
Man,
I will say I'm very happy about the uh
I will say I'm very happy about the uh
the reason that I started writing this
the reason that I started writing this
article in the first place is that the
article in the first place is that the
last one did very well. So, if you want
last one did very well. So, if you want
me to write more articles or you want me
me to write more articles or you want me
to do more of a thing, you know, go post
to do more of a thing, you know, go post
and support the current thing because
and support the current thing because
that all helps.
The article,
The article,
this one,
this one,
the new article is literally just an
the new article is literally just an
introduction section. It doesn't have
introduction section. It doesn't have
any content in it yet.
any content in it yet.
I might like I might write on it on
I might like I might write on it on
stream uh either tomorrow or over the
stream uh either tomorrow or over the
next bit of the week. We'll see.
next bit of the week. We'll see.
when I'm like sick of coding stuff, I'll
when I'm like sick of coding stuff, I'll
write on things.
write on things.
We'll share code walk through.
We'll share code walk through.
Uh it's more of a how to learn RL thing
Uh it's more of a how to learn RL thing
in general. So, it's going to point you
in general. So, it's going to point you
to a lot of other resources.
to a lot of other resources.
The code that seems like stuff that's
The code that seems like stuff that's
like more for the docs.
Like it looks like you want like an
Like it looks like you want like an
expanded upon version of
expanded upon version of
of like this tutorial or whatever.
Expanded version of this tutorial.
I probably should add like a sweeps
I probably should add like a sweeps
thing to this. I could do that.
adding sweeps,
adding sweeps,
improving rewards.
Improving rewards I will talk about in
Improving rewards I will talk about in
the article. Network design I can
the article. Network design I can
probably talk about in the article.
Talk about sweeps in general for sure
Talk about sweeps in general for sure
and like common bugs.
The article will direct you on how to
The article will direct you on how to
like implement things and it will have
like implement things and it will have
you build things but it's not going to
you build things but it's not going to
directly be like this piece of code read
directly be like this piece of code read
now this piece of code read this etc
now this piece of code read this etc
etc.
All right, let me code my sphere. I got
All right, let me code my sphere. I got
to code my sphere.
to code my sphere.
Otherwise, we won't have drone things
Otherwise, we won't have drone things
Done.
You're also more than free to ask
You're also more than free to ask
questions here, Shadow, while um I'm
questions here, Shadow, while um I'm
working on stuff. That's kind of the
working on stuff. That's kind of the
point of the stream.
I'm Red Zep. Okay. You cannot people
I'm Red Zep. Okay. You cannot people
cannot possibly expect me to remember
cannot possibly expect me to remember
when they have different usernames. So,
when they have different usernames. So,
if I get confused, just remind me.
if I get confused, just remind me.
I have like a bunch of people on here
I have like a bunch of people on here
and then some people have like three or
and then some people have like three or
four different usernames on all the
four different usernames on all the
platforms.
platforms.
What are you trying to do? You trying to
What are you trying to do? You trying to
confuse me?
Oh yeah,
curriculum learning IRL.
The curriculum learning goal at the
The curriculum learning goal at the
moment,
it's to grow the puffer business so I
it's to grow the puffer business so I
can get back to doing real research.
far beyond many frameworks beat with the
far beyond many frameworks beat with the
simplicity. I mean, that's the goal.
simplicity. I mean, that's the goal.
It's simpler.
It's simpler.
It's simpler than everything, but Clean
It's simpler than everything, but Clean
RL, Clean RL is still kind of the best
RL, Clean RL is still kind of the best
for that. Um, but it is like a thousand
for that. Um, but it is like a thousand
times faster.
times faster.
It's not It's not that much more than
It's not It's not that much more than
Clean RL either. Especially some of the
Clean RL either. Especially some of the
recent Clean RL stuff where they like
recent Clean RL stuff where they like
import and use. Like some of the newer
import and use. Like some of the newer
Clean RL stuff actually imports garbage
Clean RL stuff actually imports garbage
from SP3.
from SP3.
Like the original Clean RL stuff that
Like the original Clean RL stuff that
Costa built is the best.
Costa built is the best.
Uh and like all the like the newer
Uh and like all the like the newer
stuff, it's just nah. Nobody nobody does
stuff, it's just nah. Nobody nobody does
anything like reasonably. It's such a
anything like reasonably. It's such a
pain.
Have you read the uh the quick the quick
Have you read the uh the quick the quick
start guide though? Shadow or Reds?
The quick start guide has a lot of good
The quick start guide has a lot of good
stuff in it.
The article I'm working on is going to
The article I'm working on is going to
basically be a very updated version of
basically be a very updated version of
that. Uh, pretty much all the advice
that. Uh, pretty much all the advice
that I give in there is still good.
that I give in there is still good.
So, it's just going to be like a bigger,
So, it's just going to be like a bigger,
more updated version of that that covers
more updated version of that that covers
more stuff.
But pretty much by the time like if
But pretty much by the time like if
you've built five environments, by like
you've built five environments, by like
environment number five, you're going to
environment number five, you're going to
be pretty good at this stuff.
[Music]
Big bold.
Ah.
Currently
training an agent to solve a very
training an agent to solve a very
complex robotic operation with long
complex robotic operation with long
horizon.
horizon.
Fortunately using Isaac lab skl, but
Fortunately using Isaac lab skl, but
we're considering integrating puffer
we're considering integrating puffer
liib for your model benchmarks. Issue is
liib for your model benchmarks. Issue is
developing the end and fixing the bugs
developing the end and fixing the bugs
taking some time. Yeah, Isaac will do
taking some time. Yeah, Isaac will do
that. I had to do some stuff with Isaac
that. I had to do some stuff with Isaac
Jim for a client. It was a pain. I don't
Jim for a client. It was a pain. I don't
know if you've seen in the last few
know if you've seen in the last few
days, we actually have Puffer Live
days, we actually have Puffer Live
working with Manny Scale. I can push
working with Manny Scale. I can push
some of this stuff if you want. Um, we
some of this stuff if you want. Um, we
will have it pushed anyways in a bit.
will have it pushed anyways in a bit.
Uh, that mostly just works. The only
Uh, that mostly just works. The only
thing is that the defaults that people
thing is that the defaults that people
use in robotics are moderately insane
use in robotics are moderately insane
for all their algorithms. So like
for all their algorithms. So like
pretty much it's going to take us quite
pretty much it's going to take us quite
a bit of optimization to make it as fast
a bit of optimization to make it as fast
or faster than the existing stuff in
or faster than the existing stuff in
that space. specifically because like
that space. specifically because like
the combination of insane reward
the combination of insane reward
functions and like weird model
functions and like weird model
architectures
architectures
and like weird hyperp combines to be
and like weird hyperp combines to be
this very locally optimal thing and you
this very locally optimal thing and you
kind of have to reoptimize everything in
kind of have to reoptimize everything in
order to like really beat it and uh
order to like really beat it and uh
that's just like kind of complicated
that's just like kind of complicated
like I have to set up a big sweep
like I have to set up a big sweep
basically to do that. So, that is in the
basically to do that. So, that is in the
cards and I was working on that earlier.
cards and I was working on that earlier.
That's this week. I kind of just got
That's this week. I kind of just got
bored. So, I wanted to do some of the
bored. So, I wanted to do some of the
drone stuff uh yesterday and today
they're not better than Isaac Lab. Isaac
they're not better than Isaac Lab. Isaac
Jim was just a student work.
They're not that better than Isaac lab.
How's the code? Like some of the
How's the code? Like some of the
packages that we had to work with in
packages that we had to work with in
Isaac gym were just awful. And from what
Isaac gym were just awful. And from what
I've seen, even like Isaac Sim, they
I've seen, even like Isaac Sim, they
still use the same packages. Like people
still use the same packages. Like people
like load, maybe this is humanoid
like load, maybe this is humanoid
specific, but they have like motion lib
specific, but they have like motion lib
and pose lib and like all these other
and pose lib and like all these other
just janky like an old horribly
just janky like an old horribly
overabstracted uh grad student code
overabstracted uh grad student code
libraries.
So Manny was at least like relatively
So Manny was at least like relatively
easier to get stuff set up and working.
Isaac Jim is better develop from
Isaac Jim is better develop from
scratch. Isaac lab.
scratch. Isaac lab.
Isaac can better develop from scratch.
Isaac can better develop from scratch.
Isaac lab. Finally.
Isaac lab. Finally.
Very similar to Manny's skill. slightly
Very similar to Manny's skill. slightly
more complex with more trying to relying
more complex with more trying to relying
on this. Yeah.
on this. Yeah.
So, I mean,
So, I mean,
robotics is an area that I don't really
robotics is an area that I don't really
intend to get super deep into quite soon
intend to get super deep into quite soon
unless it would basically it would take
unless it would basically it would take
a company being really really interested
a company being really really interested
in wanting to work with us uh to bring
in wanting to work with us uh to bring
our type of tech to robotics, then I
our type of tech to robotics, then I
would do it. But like it's not like a a
would do it. But like it's not like a a
short side project level of an effort,
short side project level of an effort,
right? Like I pretty much have to rip
right? Like I pretty much have to rip
apart the really overly abstracted way
apart the really overly abstracted way
that a lot of stuff is done in robotics
that a lot of stuff is done in robotics
and distill it down and simplify it and
and distill it down and simplify it and
then find all the things making stuff
then find all the things making stuff
slow and janky, right? That I'm sure are
slow and janky, right? That I'm sure are
there. It's the same thing I would I did
there. It's the same thing I would I did
with the rest of RL. I'd have to bring
with the rest of RL. I'd have to bring
over to robotics.
I basically I would it would have to be
I basically I would it would have to be
like a company would want to would have
like a company would want to would have
to want like a big contract for us to go
to want like a big contract for us to go
do that because otherwise it's a huge
do that because otherwise it's a huge
huge time investment that takes me off
huge time investment that takes me off
of a lot of the stuff I'm doing outside
of a lot of the stuff I'm doing outside
of
like the main thing I'm doing outside of
like the main thing I'm doing outside of
this stream now is basically
this stream now is basically
looking for pro like valuable problems
looking for pro like valuable problems
in industry to throw this stuff on. Um,
in industry to throw this stuff on. Um,
both because that's going to like really
both because that's going to like really
help us benchmark and test puffer, but
help us benchmark and test puffer, but
also uh you know that solves the that
also uh you know that solves the that
will solve the revenue
will solve the revenue
uh the revenue problem. So that'll like
uh the revenue problem. So that'll like
let us grow way more than we are at the
let us grow way more than we are at the
moment.
moment.
Reach out to you in the next three
Reach out to you in the next three
months. Would you be up for 12 months
months. Would you be up for 12 months
guaranteed collaboration?
guaranteed collaboration?
Yeah, I'd have to know more. Right. Um,
Yeah, I'd have to know more. Right. Um,
I don't know if you're at a company or a
I don't know if you're at a company or a
lab or what because we do some level of
lab or what because we do some level of
free support for laboratories. And then
free support for laboratories. And then
for companies, we do uh we do paid
for companies, we do uh we do paid
contracts
the company. Yeah, if you guys are
the company. Yeah, if you guys are
interested in something like that, we
interested in something like that, we
could definitely do that. And robotics
could definitely do that. And robotics
is one of the things that I've looked
is one of the things that I've looked
into that it like from what I've dealt
into that it like from what I've dealt
with it feels like it should be very
with it feels like it should be very
doable uh to bring like the puffer level
doable uh to bring like the puffer level
of advancements over to robotics. It's
of advancements over to robotics. It's
just like a fair bit more work than I'd
just like a fair bit more work than I'd
want to do as a side project outside of
want to do as a side project outside of
a contract.
a contract.
Yeah.
Yeah. We do two things at the moment,
Yeah. We do two things at the moment,
right? We do like smaller jobs that are
right? We do like smaller jobs that are
just like support extended support and
just like support extended support and
features and then we do larger things
features and then we do larger things
that are more like um
that are more like um
like fixed deliverables like hey we want
like fixed deliverables like hey we want
X built it's worth Y to us.
Help us do that.
Shadow, can I ask if it's humanoids or
Shadow, can I ask if it's humanoids or
if it's more like industrial?
if it's more like industrial?
Is it like industrial like armbbased
Is it like industrial like armbbased
stuff or is it humanoids?
Arm base. Okay, that's actually way
Arm base. Okay, that's actually way
better. But like industrial robotics, if
better. But like industrial robotics, if
I had to like do something in robotics
I had to like do something in robotics
and pick an entry point, that's the type
and pick an entry point, that's the type
of thing we'd be way more excited about
of thing we'd be way more excited about
because I think that's actually going to
because I think that's actually going to
have way higher impact than humanoids in
have way higher impact than humanoids in
the long term. Even if in the short term
the long term. Even if in the short term
we see like super hype all like tons of
we see like super hype all like tons of
companies buying humanoids yada yada I
companies buying humanoids yada yada I
think that folks will eventually realize
think that folks will eventually realize
that it's like woefully impractical to
that it's like woefully impractical to
have this one-sizefits-all but like
have this one-sizefits-all but like
really slow and expensive solution for
really slow and expensive solution for
everything. Um
I personally I would love to see like
I personally I would love to see like
industrial robotics like the arms moving
industrial robotics like the arms moving
at five times the pace that they
at five times the pace that they
currently move.
humanoids. Yeah, man. It's like
I kind of see why there's the appeal to
I kind of see why there's the appeal to
it, but like
it, but like
I don't think humanoid robots gets us
I don't think humanoid robots gets us
like sci-fi era awesome tech everywhere.
like sci-fi era awesome tech everywhere.
You know, that's kind of the way I look
You know, that's kind of the way I look
at a lot of stuff. Humanoids is like
at a lot of stuff. Humanoids is like
it's faster horses. You're basically
it's faster horses. You're basically
you're replacing human workers with
you're replacing human workers with
something that's going to be maybe about
something that's going to be maybe about
as effective as a human worker. Like
as effective as a human worker. Like
eh
exactly what we're doing.
exactly what we're doing.
Be happy to chat. Long horizon multitask
Be happy to chat. Long horizon multitask
optimize policies.
optimize policies.
I've actually been thinking about stuff
I've actually been thinking about stuff
like that and how you solve. So
like that and how you solve. So
basically, I could solve your long
basically, I could solve your long
horizon problem pretty much out of the
horizon problem pretty much out of the
box if your Sims were fast enough.
box if your Sims were fast enough.
That's the key annoyance at the moment.
That's the key annoyance at the moment.
Um,
Um,
so I've been thinking of like if there's
so I've been thinking of like if there's
a way to do like super low fidelity,
a way to do like super low fidelity,
very domain randomized, and then like
very domain randomized, and then like
fine-tune up to faster or like to
fine-tune up to faster or like to
slower, higher precision.
slower, higher precision.
There are a lot of knobs that need to be
There are a lot of knobs that need to be
messed with. The Sims are just really
messed with. The Sims are just really
slow right now.
I think that's the main annoyance.
I think that's the main annoyance.
It really doesn't feel to me like from
It really doesn't feel to me like from
first principles either that like
first principles either that like
you know if you can run a humanoid at
you know if you can run a humanoid at
10,000 steps per second statebased can
10,000 steps per second statebased can
only run an arm at like 40,000 steps per
only run an arm at like 40,000 steps per
second with the same settings. It seems
second with the same settings. It seems
like just like a six degree of freedom
like just like a six degree of freedom
arm. It seems to me like you should be
arm. It seems to me like you should be
able to run it at least in like hundreds
able to run it at least in like hundreds
of thousands with reasonable fidelity.
of thousands with reasonable fidelity.
and like current Sims just aren't doing
and like current Sims just aren't doing
it. I could be wrong, but just like
it. I could be wrong, but just like
based on what I know about the problem,
based on what I know about the problem,
given that they're not even doing like
given that they're not even doing like
they're not even doing like gel sensors
they're not even doing like gel sensors
or anything like that, it stuff should
or anything like that, it stuff should
be a lot faster than it is.
Like, oh, it's built on physics and
Like, oh, it's built on physics and
physics is fast, therefore our thing
physics is fast, therefore our thing
must be fast is not not really it.
must be fast is not not really it.
You know,
we're just two AI engineers and a plus
we're just two AI engineers and a plus
years of RL experience. Once we have a
years of RL experience. Once we have a
simple bug-free end, get to the level of
simple bug-free end, get to the level of
first real robot deployment, I'm going
first real robot deployment, I'm going
to call you. Sounds good.
to call you. Sounds good.
Yeah, man. Good luck with that. Robotics
Yeah, man. Good luck with that. Robotics
is hot at the moment, but it's also it's
is hot at the moment, but it's also it's
it's a tough problem in the sense that
it's a tough problem in the sense that
like all the Sims and tools are really
like all the Sims and tools are really
big and bloated. This is kind of the
big and bloated. This is kind of the
problem I had to solve with RL in
problem I had to solve with RL in
general, right? Like just stuff like
general, right? Like just stuff like
RLIB and SP3
RLIB and SP3
um and like Gym and Gymnasium with their
um and like Gym and Gymnasium with their
vectorzation and rappers and things.
vectorzation and rappers and things.
Everything was bloated and slow
Everything was bloated and slow
and you just had to like cut off all the
and you just had to like cut off all the
fat and it just took forever. But you
fat and it just took forever. But you
got we got to a point eventually where
got we got to a point eventually where
stuff is just good now.
For me, I've been working in RL since
For me, I've been working in RL since
well, I started neural MMO I believe in
well, I started neural MMO I believe in
20 2018, maybe 2017 or 2018.
That's when I started doing RL.
Okay. Why is the observation out of
Okay. Why is the observation out of
bounds here?
Fake
this change
one.
one.
9 13
How's this stuff out of bounds?
What I messed up here?
What I messed up here?
Says 31.
Funny.
RL lib kills me. I don't Yeah,
RL lib kills me. I don't Yeah,
the thing is
the thing is
the devs actually really tried hard with
the devs actually really tried hard with
that and like I know some of them.
that and like I know some of them.
It's just
It's just
I actually I got a message I think like
I actually I got a message I think like
from a random engineer not realizing
from a random engineer not realizing
like all the stuff I've done trying to
like all the stuff I've done trying to
hire me for like RL lib. I don't
It's like it's just not how you build
It's like it's just not how you build
for RL. You don't build a super heavy
for RL. You don't build a super heavy
fang style
fang style
product or a field where everything is
product or a field where everything is
cursed and breaks constantly. You build
cursed and breaks constantly. You build
the simplest, most compact possible
the simplest, most compact possible
thing, the smallest number of moving
thing, the smallest number of moving
parts. That's how you build it.
I've tried to help him a few different
I've tried to help him a few different
times as well, but
I don't know.
What the heck did I break? What did I
What the heck did I break? What did I
break here, man? This is simple.
break here, man? This is simple.
It's very simple. What did I break?
Welcome Jai.
Hey, Tyloian. Welcome.
Hey, Tyloian. Welcome.
Luck on runs.
We have one cool experiment. So, this is
We have one cool experiment. So, this is
a couple cool things. This is 2048. It
a couple cool things. This is 2048. It
looks like we've gotten some solves out
looks like we've gotten some solves out
of this.
of this.
And um we also have a pretty promising
And um we also have a pretty promising
neural MMO run over here. Very promising
neural MMO run over here. Very promising
actually.
actually.
So this is the current one and then this
So this is the current one and then this
is the uh the soda
is the uh the soda
from before.
from before.
So this is the uh the run that I wrote
So this is the uh the run that I wrote
my article about and this is the new
my article about and this is the new
run. So basically, if it gets the same
run. So basically, if it gets the same
sort of curvature, which it looks like
sort of curvature, which it looks like
it might start to be getting, then it
it might start to be getting, then it
should be state-of-the-art. We'll see.
should be state-of-the-art. We'll see.
Y'all with Muan.
If anybody wants to figure out how PSGD,
If anybody wants to figure out how PSGD,
like how to set up PSGD and have it
like how to set up PSGD and have it
actually work, uh, I'm open to trying
actually work, uh, I'm open to trying
other stuff as well. Like I can set up a
other stuff as well. Like I can set up a
big run like this, but some basically
big run like this, but some basically
you'd have to actually set it up so it's
you'd have to actually set it up so it's
not going to just crash instantly. We
not going to just crash instantly. We
don't want to do this.
This isund
This isund
something very odd is happening that
something very odd is happening that
this is out of bounds then, right?
should not be out of bounds.
Oh, plus task.
Hello study.
Welcome.
Oh, wait. This is out of bounds.
I'm dumb.
I'm dumb.
Yeah, I I have an off by one.
Yeah, I I have an off by one.
That's all it is.
Started ML like one month ago. Welcome
Started ML like one month ago. Welcome
to the space. There's lots of cool stuff
to the space. There's lots of cool stuff
you can do in here.
you can do in here.
Not good with the basics.
Not good with the basics.
I have uh references for new ML people
I have uh references for new ML people
that I always suggest.
The S231N is probably the best like
The S231N is probably the best like
one-stop shop overall deep learning
one-stop shop overall deep learning
reference. The lectures with either
reference. The lectures with either
Carpathy or Justin Johnson. Either of
Carpathy or Justin Johnson. Either of
those are good.
Do you think I should go further? It
Do you think I should go further? It
really depends on your level of
really depends on your level of
background and especially like how good
background and especially like how good
of a programmer you are. How's your
of a programmer you are. How's your
math? What areas are interesting to you?
math? What areas are interesting to you?
Like what do you want to do, right?
Like what do you want to do, right?
I have my quick start guide for RL on
I have my quick start guide for RL on
the uh the website puffer.ai. It's also
the uh the website puffer.ai. It's also
on X.
Okay. So if this works,
this is orbit.
Super super cool you live stream this. I
Super super cool you live stream this. I
wish more people did. Yeah, it's been
wish more people did. Yeah, it's been
fun. I uh I like live streaming all the
fun. I uh I like live streaming all the
work.
It's been great for the project as well.
It's been great for the project as well.
We've had like several people from the
We've had like several people from the
live stream come and just say, "Hey, you
live stream come and just say, "Hey, you
know, I want to start building some
know, I want to start building some
stuff." And uh you know, many have been
stuff." And uh you know, many have been
very successful at it even without AI
very successful at it even without AI
experience.
experience.
Thinking of being a quant analyst,
Thinking of being a quant analyst,
I don't think they even do any like
I don't think they even do any like
super crazy
super crazy
I don't think they even really do any
I don't think they even really do any
crazy stuff with ML.
crazy stuff with ML.
I think a lot of it's like pretty basic
I think a lot of it's like pretty basic
models that they use and it's a lot more
models that they use and it's a lot more
just about getting data that other
just about getting data that other
people don't have.
Where's the implementation of trajectory
Where's the implementation of trajectory
segment filtering? Yes, it's included
here.
So if you look at pufferl
So if you look at pufferl
where all the code is right
you can see here
you can see here
hang on
right Here you can see that we're not
right Here you can see that we're not
just iterating over the batch, right?
just iterating over the batch, right?
We're actually sampling and we're
We're actually sampling and we're
sampling based on these pryo probs. This
sampling based on these pryo probs. This
is prioritized experience replay using
is prioritized experience replay using
the advantage function uh as the metric.
the advantage function uh as the metric.
So it throws away low advantage segments
low or high. I believe it is
low or high. I believe it is
Like
Like
it throws away like things that are
it throws away like things that are
uninformative. Basically low absolute
uninformative. Basically low absolute
value.
All included.
You help me to understand what project
You help me to understand what project
you're doing right now.
you're doing right now.
Uh, I'm kind of in the middle of a
Uh, I'm kind of in the middle of a
couple different things, but pretty much
couple different things, but pretty much
we have this drone sim. I guess I can
we have this drone sim. I guess I can
show this one. This one's a lot like
show this one. This one's a lot like
this one's in a good spot. So, this is a
this one's in a good spot. So, this is a
drone. It flies through rings. This is a
drone. It flies through rings. This is a
sim. I'm building a sim in which you
sim. I'm building a sim in which you
have a whole bunch of drones and you can
have a whole bunch of drones and you can
kind of command them to do different
kind of command them to do different
things.
things.
And then we're going to reinforcement
And then we're going to reinforcement
learn the drones to be able to do that.
learn the drones to be able to do that.
Doing it for full. No, it's over
Doing it for full. No, it's over
trajectory segments.
trajectory segments.
It's segments of length of BPTT horizon.
That's how we do that.
Okay. So, I we pretty much have the full
Okay. So, I we pretty much have the full
sim except for the fact that for some
sim except for the fact that for some
reason I still have this math wrong on
reason I still have this math wrong on
the circle somehow.
Where? Where did it go?
I do this wrong.
The radius of 8<unk>
*<unk> 5 - 1
And then your sample
And then your sample
1 minus
1 minus
x over the num agents
x over the num agents
* 2 * the radius
probably r is what happened.
Just going to guess that that's what I
Just going to guess that that's what I
messed up.
Huh?
Huh?
Yeah. Why is this not
Yeah. Why is this not
Why is this doing this?
Can't understand what you're doing.
Can't understand what you're doing.
I would suggest
I would suggest
we have some good resources right here.
If you check on puffer.ai,
we have uh there's this quick start
we have uh there's this quick start
guide.
guide.
This gives you a lot of the basics of RL
This gives you a lot of the basics of RL
and a lot of the intuition for stuff.
and a lot of the intuition for stuff.
And also I these some of these need to
And also I these some of these need to
be reformatted at the top. But yeah,
be reformatted at the top. But yeah,
we also have the uh the docs for this
we also have the uh the docs for this
whole project
whole project
and like tons of examples.
and like tons of examples.
I'm building a I'm building a simulator
I'm building a I'm building a simulator
right now for
right now for
essentially for a swarm of drones to
essentially for a swarm of drones to
behave in a certain way and then I'm
behave in a certain way and then I'm
going to run reinforcement learning to
going to run reinforcement learning to
make the drones actually learn to do
make the drones actually learn to do
that
that
with puffer lab.
Apply each point.
Apply each point.
Okay.
You build puffer. Yes,
is my main Perfect.
Okay, this could be it technically.
We need more drones to tell.
There we go. That's a sphere.
There we go. That's a sphere.
Yeah, that's a sphere, right?
Yeah, that's a sphere, right?
We're good.
Let's do some basic thing first with
Let's do some basic thing first with
this. See if we can get it to Turn.
What code editor am I using? Uh, Neoim.
Okay,
Okay,
training is stable. So, I guess I didn't
training is stable. So, I guess I didn't
horribly break everything in this latest
horribly break everything in this latest
change.
change.
See whether it does anything.
article really did very well. I only
article really did very well. I only
have one other article with 100,000
have one other article with 100,000
views and it was kind of like a
views and it was kind of like a
loweffort batty article.
loweffort batty article.
So, this is kind of nice to see a actual
So, this is kind of nice to see a actual
technical uh article do this well.
What do you do for a living? This
What do you do for a living? This
I do reinforcement learning work
I do reinforcement learning work
full-time.
Hey Anick,
Hey Anick,
thanks for the shout out. Appreciate if
thanks for the shout out. Appreciate if
you missed it. I pushed a small change
you missed it. I pushed a small change
on GitHub to make it interactable.
on GitHub to make it interactable.
Article's going wild. Many views on
Article's going wild. Many views on
Puff. Yeah, it's very good. Did you see
Puff. Yeah, it's very good. Did you see
the latest sweep that I did, Yanick?
the latest sweep that I did, Yanick?
You will uh you will appreciate this for
You will uh you will appreciate this for
sure.
So, this is 600 million steps and this
So, this is 600 million steps and this
is 2048.
is 2048.
So, uh, we found some good parameters.
So, uh, we found some good parameters.
Apparently,
Neptune is so slow.
Neptune is so slow.
They advertise it's like the fastest or
They advertise it's like the fastest or
whatever, but it's really not.
Whole thing's frozen.
Okay. Well, this worked.
There you go. Three minutes.
So, 3 minutes to solve 2048.
So, it looks like they don't all know
So, it looks like they don't all know
exactly where they're supposed to go.
exactly where they're supposed to go.
It's pretty close.
It's pretty close.
Interesting. If it continues to solve
Interesting. If it continues to solve
based on the curves, it looked like it
based on the curves, it looked like it
it looks like it should.
I will grab those hypers later and we
I will grab those hypers later and we
can play around with it.
can play around with it.
Or I could link if you want to play
Or I could link if you want to play
around with it. I can link you this
here. I put the sweep in the dev chat.
here. I put the sweep in the dev chat.
See if that link works.
Each drone have its own target point.
Each drone have its own target point.
Now it does. Yes.
Okay, this should make it substantially
Okay, this should make it substantially
easier to learn.
easier to learn.
Got 470 before.
Yeah, we can far. We can push the ends.
Yeah, we can far. We can push the ends.
I think it's a quite good environment
I think it's a quite good environment
actually.
actually.
There really aren't that many things
There really aren't that many things
that take that many steps to learn like
that take that many steps to learn like
on the uh like the game environments
and the episodes are not like crazy long
and the episodes are not like crazy long
either.
It's a good environment.
It's a good environment.
Thank you for the contribution.
10x improvement.
10x improvement.
Yeah, I this is what we've sort of seen
Yeah, I this is what we've sort of seen
with a lot of my work, right?
Sweeps are kind of just ridiculously
Sweeps are kind of just ridiculously
overpowered. Oh, yeah. This is also with
overpowered. Oh, yeah. This is also with
a simpler and smaller model than uh the
a simpler and smaller model than uh the
one that you used. So
it's pretty crazy.
Uh this got 470 before, did it not?
Uh this got 470 before, did it not?
Hang on. Let me go get the I closed the
Hang on. Let me go get the I closed the
tab because Neptune was crashing stuff.
Uh, it's very similar.
So, I guess we'll see whether this helps
So, I guess we'll see whether this helps
it stay stable and keep learning or not.
it stay stable and keep learning or not.
All I did was uh this experiment is I
All I did was uh this experiment is I
relativized the observations. Actually,
relativized the observations. Actually,
you know what I should do? Every time I
you know what I should do? Every time I
think of a thing that's like a basic
think of a thing that's like a basic
trick that I want to talk about,
trick that I want to talk about,
I'm going to just put it into the bottom
I'm going to just put it into the bottom
as a note.
That'll make the article way better.
Okay, so this looks maybe a little
Okay, so this looks maybe a little
better.
better.
Uh, still kind of crashing a bit though.
Well, it still ended up better, right?
Yeah, it still ended up a little tiny
Yeah, it still ended up a little tiny
bit better.
bit better.
I guess what you would expect.
I guess what you would expect.
Here's drone sphere.
Okay. So next what we can do
we train them for all the tasks
we train them for all the tasks
simultaneously.
That means I get to delete
I get to delete four
I get to delete four
dimensions
dimensions
from the obace.
So that is
So that is
20.
20.
Wait, am I stupid?
27.
27.
Yeah.
Yeah.
Or I cannot add
Seven.
Seven.
Okay.
Now
we rebuild this and we see if we can do
we rebuild this and we see if we can do
all four tasks simultaneously.
So, this is actually a fair bit easier
So, this is actually a fair bit easier
because you really don't even need to
because you really don't even need to
know what task you're doing in order to
know what task you're doing in order to
do this. You just need to know where the
do this. You just need to know where the
target is. But, let it be known that we
target is. But, let it be known that we
actually had a version of this working
actually had a version of this working
pretty well even without that. So like
pretty well even without that. So like
task conditional RL kind of just works
task conditional RL kind of just works
which is crazy because that's not a like
which is crazy because that's not a like
that's not a thing at all that used to
that's not a thing at all that used to
Dark.
Actually,
if task conditional RL works now, yeah,
if task conditional RL works now, yeah,
there's some crazy demos we can throw
there's some crazy demos we can throw
together from
I have the score normalized such that or
I have the score normalized such that or
the perf normalized especially such that
the perf normalized especially such that
I think one is ideal like it's working
I think one is ideal like it's working
perfectly but I don't think you can
perfectly but I don't think you can
actually get one.
So hopefully this should be like
So hopefully this should be like
reasonably good behavior. here.
Okay. So this is orbit. Yeah.
Idle
follow.
Oh yeah, this is working. And they're
Oh yeah, this is working. And they're
trying not to crash as well.
obviously we have to fix these drone
obviously we have to fix these drone
trails and stuff
like 20 as Well,
way better. And I we'll fix this.
way better. And I we'll fix this.
Actually, we'll do this next. We'll just
Actually, we'll do this next. We'll just
fix this next. And then we'll add in the
fix this next. And then we'll add in the
rest of the tasks and then we will be
rest of the tasks and then we will be
pretty well set. Like we'll have an
pretty well set. Like we'll have an
awesome drone sim that works with RL in
awesome drone sim that works with RL in
like day and a half of like pretty lazy
like day and a half of like pretty lazy
work.
work.
All right. I'd be right back.
I forgot my daily deadlift.
Okay,
back to
Let's do
we'll do the two component reward. In
we'll do the two component reward. In
fact,
all sore today and I don't know why
all sore today and I don't know why
a bunch of pull-ups and like some pearls
a bunch of pull-ups and like some pearls
yesterday anything else
weird
Oh, I guess then this does get
Oh, I guess then this does get
does get updated, huh?
does get updated, huh?
Yeah, you can do
when I'm assessing a new area of work, I
when I'm assessing a new area of work, I
always look for wrong fundamental
always look for wrong fundamental
assumptions. Why puffer will win?
assumptions. Why puffer will win?
Pretty much what we do.
I mean,
I mean,
I kind of have a probably not as great
I kind of have a probably not as great
of an outlook on it in how I get to that
of an outlook on it in how I get to that
conclusion, which is like I kind of
conclusion, which is like I kind of
every I kind of assume everything is
every I kind of assume everything is
done in the stupidest and most
done in the stupidest and most
incompetent way possible until proven
incompetent way possible until proven
otherwise.
otherwise.
And like when I see a few things done
And like when I see a few things done
incompetently, I look for other things
incompetently, I look for other things
done incompetently.
This is solid.
Okay, we do actually need this stuff as
Okay, we do actually need this stuff as
well, but
well, but
it can go into compute
it can go into compute
board.
episode return.
Okay. Episode length
Okay. Episode length
or
get absor.
get absor.
Yeah.
Now, the only thing I have to do besides
Now, the only thing I have to do besides
this, making sure that I I didn't pass
this, making sure that I I didn't pass
anything else up.
Decision reward, target reward, and
Decision reward, target reward, and
that's it.
I could do the absolute reward.
I may as well let it see the
May as well let it see, right? Let there
May as well let it see, right? Let there
be light.
H numbers.
Definitely better.
reward like this.
And we also wanted to fix the trails,
And we also wanted to fix the trails,
right?
little awkward
and probably do something like
maybe I can do something like this.
Not quite.
really. I would think that this would do
really. I would think that this would do
it. Now.
Oh, hang on. I think it just indexed
Oh, hang on. I think it just indexed
wrong somehow.
This is it here, isn't it?
thought this would be it.
thought this would be it.
Really good references in your quick
Really good references in your quick
start blog. Thank you. I am working on
start blog. Thank you. I am working on
another one. I've started on like
another one. I've started on like
another educational article. It's going
another educational article. It's going
to be much longer.
to be much longer.
Uh, and it's going to take me quite a
Uh, and it's going to take me quite a
bit of work.
I'm just kind of doing it bit by bit,
I'm just kind of doing it bit by bit,
but
but
I'm working on that.
Costa is
Costa is
I think Costa is like the only person
I think Costa is like the only person
the only other person in Arl where I'd
the only other person in Arl where I'd
like I have literally nothing negative
like I have literally nothing negative
to say about Costa at all. Costa is just
to say about Costa at all. Costa is just
awesome.
Like it's one of these things where I
Like it's one of these things where I
don't think the field realizes how
don't think the field realizes how
screwed reinforcement learning would be
screwed reinforcement learning would be
without Costa.
without Costa.
Like including all the stuff I do. Like
Like including all the stuff I do. Like
we would just be beyond screwed.
How could this happen?
The heck is going on with this thing?
It said it follows the drone.
Count to zero.
Really
for one frame.
Why does this guy have both trails and
Why does this guy have both trails and
this other one doesn't have any?
this other one doesn't have any?
Oh, this needs to be zero.
Oh, this needs to be zero.
Now they both get trails.
That was stupid right thing.
When it's out of bounds, you reset the
When it's out of bounds, you reset the
agent and terminals is set to one.
Okay.
And then you call render.
doesn't draw the trail.
very weird that this thing does this.
very weird that this thing does this.
How does the trail jump on reset like
How does the trail jump on reset like
this?
It's like the frame after they reset or
It's like the frame after they reset or
whatever, right?
Okay. So, this is just not doing
Okay. So, this is just not doing
anything I guess.
Oh,
Oh,
you are stupid is why.
Actually, shouldn't it just be
just this
Okay, they still zap though like this.
Okay, they still zap though like this.
Why this is out?
Okay. So, this is still
still doing this weird zappy
That's
So, this is getting cold.
Very
silly bug to get stuck on for this long.
Is it just drawing it somewhere else and
Is it just drawing it somewhere else and
I'm just dumb?
No,
No,
this is where it's drawing it.
very odd.
Okay, this is the expected behavior.
Okay. Okay. So, you can actually see
Okay. Okay. So, you can actually see
that it is wrapping around and screwing
that it is wrapping around and screwing
it
This terminated condition does work.
This terminated condition does work.
The heck is wrong?
Hello,
Hello,
your potato.
Uh, this is a live reinforcement
Uh, this is a live reinforcement
learning dev. I'm currently working on a
learning dev. I'm currently working on a
drone simulator.
drone simulator.
Show you a different version.
Okay, apparently I don't have it. I can
Okay, apparently I don't have it. I can
show you this version at least.
show you this version at least.
So, we have a couple different drone
So, we have a couple different drone
simulators and I'm currently working on
simulators and I'm currently working on
a version that has a ton of different
a version that has a ton of different
drones that can like fly in a sphere or
drones that can like fly in a sphere or
hover or like do a few different things
hover or like do a few different things
and we're training them with
and we're training them with
reinforcement learning.
reinforcement learning.
That is currently what is going on.
You can watch some of these live in your
You can watch some of these live in your
browser at puffer.ai.
You have all sorts of games and
You have all sorts of games and
simulators and other things.
This is a trained agent playing it in
This is a trained agent playing it in
your browser.
your browser.
This is a trained agent that plays in
This is a trained agent that plays in
your browser.
We have lots of different things in
We have lots of different things in
here.
I'm currently just trying to figure out
I'm currently just trying to figure out
why these uh trails on these drones are
why these uh trails on these drones are
not rendering correctly.
not rendering correctly.
Stuck on a very basic thing at the
Stuck on a very basic thing at the
moment.
Yeah. See, it like it zaps and like
Yeah. See, it like it zaps and like
follows them for some reason.
It's like an off by one or some weird
It's like an off by one or some weird
thing.
thing.
I honestly don't know why this is doing
I honestly don't know why this is doing
this.
We can just re
We can just re
do how the trail works a little. So you
do how the trail works a little. So you
get the position.
Oh, I see.
that. Well, that wasn't it, but
that. Well, that wasn't it, but
hang on. It's something like this.
See what their original indexing was.
I forgot how the indexing was done
I forgot how the indexing was done
originally.
originally.
Probably just in
plus I -1. How does this make sense?
Increment the trail length.
I see. Yeah, this wasn't designed to be
I see. Yeah, this wasn't designed to be
used this way. Okay. So, we have to
used this way. Okay. So, we have to
redesign a little bit.
two variables ever different?
No, they're not right.
Well, they are in the sense that um
I see no the original is actually
I see no the original is actually
correct.
correct.
Do like this
Do like this
up to this cap.
And it should be that you count
And it should be that you count
backwards.
But instead of subtracting J.
Okay. So, the intensity is backwards.
Somehow this breaks it.
Just not by one now I believe. Think how
Just not by one now I believe. Think how
we do this
we do this
back. Okay.
I hate when I get stuck on silly things
I hate when I get stuck on silly things
like this.
like this.
It's just like it needs to be done, but
It's just like it needs to be done, but
I'm stuck for some dumb reason.
like incredibly incredibly basic as
like incredibly incredibly basic as
well.
well.
Literally just a ring buffer.
This is really the simplest way to do it
This is really the simplest way to do it
as well, isn't it?
Hey man, I'm not from a coding
Hey man, I'm not from a coding
background. Should I learn coding?
I mean, if you want to, right? I don't
I mean, if you want to, right? I don't
know. It's your life, man.
What the heck?
I'm sure I just have the like the modulo
I'm sure I just have the like the modulo
arithmetic screwed up in some dumb way.
I'm 19. All this looks too flashy.
If you want to see some cool demos,
If you want to see some cool demos,
there's some stuff on puffer.ai.
there's some stuff on puffer.ai.
some of the agents that we've got.
Thank you for the reminder for folks.
Thank you for the reminder for folks.
Linky, do star the puffer all open
Linky, do star the puffer all open
source code. It's on GitHub. Find the
source code. It's on GitHub. Find the
link at puffer.ai.
link at puffer.ai.
The repo helps us out a lot.
give up. Going to just debug it like
give up. Going to just debug it like
this.
Yeah.
How are we seging?
What?
Okay.
I got silence for dropping a link.
I don't have anything on that does that.
I don't have anything on that does that.
It just does it automatically.
Oh, this is weird.
Yeah, these numbers are way too big,
Yeah, these numbers are way too big,
aren't they?
Okay, it was literally an off by one.
That was annoying, but whatever. We got
That was annoying, but whatever. We got
it.
Okay,
Okay,
we are ready.
Train a model on this.
See how this looks.
See how this looks.
Lab the new rewards in. You'd be able to
Lab the new rewards in. You'd be able to
have this cleaned up for today.
Rain this now.
How this goes.
The article got more than twice as many
The article got more than twice as many
views as the release that literally
views as the release that literally
rewrites reinforcement learning.
rewrites reinforcement learning.
Crazy.
love the new video today.
love the new video today.
Oh, the trailer that I put online.
Yeah, I realized that I had not I hadn't
Yeah, I realized that I had not I hadn't
put our release trailer from X onto uh
put our release trailer from X onto uh
onto YouTube. So, I uploaded as as a uh
onto YouTube. So, I uploaded as as a uh
I uploaded the 1080p one and then I also
I uploaded the 1080p one and then I also
uploaded the shorts one.
Oh, that's hilarious.
Community note, not an operating system.
Don't underestimate the power of
Don't underestimate the power of
Schwarz. Yeah, I've uploaded a few small
Schwarz. Yeah, I've uploaded a few small
things and they do well. It's funny. Oh,
things and they do well. It's funny. Oh,
hey Arin. Yes, now I remember. Compan
hey Arin. Yes, now I remember. Compan
things. I saw it naturally in YouTube
things. I saw it naturally in YouTube
reals.
reals.
That's the algorithm.
Okay. So, can we do eval?
Okay. So, can we do eval?
Have it look decent now.
Oh, yeah. Look at that.
following this ball Now,
me to create a channel. My friend, I'm
me to create a channel. My friend, I'm
preparing a review paper on machine
preparing a review paper on machine
learning force fields. Very cool.
As you can see on the uh the channel, I
As you can see on the uh the channel, I
don't really post a ton of like videos.
don't really post a ton of like videos.
They're a ton of work. I have uh I have
They're a ton of work. I have uh I have
like 400 something live streams though
like 400 something live streams though
on the channel so far. And um
on the channel so far. And um
I also I mean I write articles. I post
I also I mean I write articles. I post
those on X
fighting start discussing a lot of RL
fighting start discussing a lot of RL
and chemistry. Absolutely.
You account for the turbulence caused by
You account for the turbulence caused by
other drones in the area.
other drones in the area.
No, that should be accounted for by just
No, that should be accounted for by just
telling them not to slam into each other
telling them not to slam into each other
or get too
What RL methods are the drones using
What RL methods are the drones using
currently? It's the main trainer in Papa
currently? It's the main trainer in Papa
Lip, which is not exactly PO. It's quite
Lip, which is not exactly PO. It's quite
a bit better, but it's based on it.
Oops.
One second, folks. Right back.
Okay.
Okay.
Add the uh the task for them to form a
Add the uh the task for them to form a
line, I guess.
One
us.
target.
target.
I see.
But I do need to figure this last thing
But I do need to figure this last thing
out, which is I need to figure out a
out, which is I need to figure out a
separate way to set the target and then
separate way to set the target and then
uh move the target, I guess.
Where is this?
Okay. So this is random position.
target. Idle
target. Idle
target
hover.
Okay, so this works.
Okay, so this works.
This is just going to be set target
This is just going to be set target
orbit.
Follow
go to the first agent or whatever.
dinner soon.
dinner soon.
Going to end first.
Got the target and the line
Got the target and the line
update function.
The only ones that need update
The only ones that need update
we have idle
we have idle
Follow.
What are you fixing now? I'm making I'm
What are you fixing now? I'm making I'm
just adding a bunch of tasks. The goal
just adding a bunch of tasks. The goal
is you're going to have like a whole
is you're going to have like a whole
bunch of different tasks that the drones
bunch of different tasks that the drones
can do and now uh or like commands they
can do and now uh or like commands they
can follow and uh I'm adding that
Don't need this.
What was your school experience like?
What was your school experience like?
What were the biggest rewards and
What were the biggest rewards and
takeaways?
Uh like undergrad or PhD or everything.
I'm usually I'm pretty negative for the
I'm usually I'm pretty negative for the
most part. uh overall on like
most part. uh overall on like
traditional coursework to learn stuff.
traditional coursework to learn stuff.
I guess it's more like the vast majority
I guess it's more like the vast majority
of the courses are not well taught. Some
of the courses are not well taught. Some
are. The ones that are good are very
are. The ones that are good are very
good, but the majority are just kind of
good, but the majority are just kind of
a waste of time.
a waste of time.
Um
Um
for PhD, it's not really school in the
for PhD, it's not really school in the
same way. At least not in CS. like you
same way. At least not in CS. like you
take to a total of four courses that
take to a total of four courses that
aren't really relevant or helpful in any
aren't really relevant or helpful in any
way to what you're doing. There really
way to what you're doing. There really
isn't course work that you can do that's
isn't course work that you can do that's
going to be relevant to the research.
going to be relevant to the research.
It's kind of just up to you to like
It's kind of just up to you to like
teach yourself and figure it out.
Couple of the intro courses in undergrad
Couple of the intro courses in undergrad
were good. I had one really good ML
were good. I had one really good ML
course. I had like a couple decent
course. I had like a couple decent
miscellaneous other ones and other than
miscellaneous other ones and other than
that, I mean, I spent like half of my
that, I mean, I spent like half of my
time in undergrad just doing research.
time in undergrad just doing research.
Like I was pretty much doing full-time
Like I was pretty much doing full-time
AI research starting sophomore year, a
AI research starting sophomore year, a
little earlier.
A little earlier actually.
Think if there's anything else like
Think if there's anything else like
super interesting
takeaways.
takeaways.
A lot of the stuff has just been you
A lot of the stuff has just been you
need to spend a ludicrous amount of time
need to spend a ludicrous amount of time
learning the thing and like use the
learning the thing and like use the
materials that are good to learn, but
materials that are good to learn, but
very often it's just going to be you
very often it's just going to be you
have to figure stuff out and it's going
have to figure stuff out and it's going
to be slow and it's going to be a grind
to be slow and it's going to be a grind
because there just isn't material out
because there just isn't material out
there that you can use to like be taught
there that you can use to like be taught
it. Basically, you have to learn it
it. Basically, you have to learn it
yourself.
I mean, it literally took me like I
I mean, it literally took me like I
think it took me well over a thousand
think it took me well over a thousand
hours to figure out the basics of neural
hours to figure out the basics of neural
nets because there were just zero good
nets because there were just zero good
resources back then at all.
resources back then at all.
That was even a little before undergrad
That was even a little before undergrad
to be fair.
But yeah, like when I took the uh the
But yeah, like when I took the uh the
main Stanford ML course, it was
main Stanford ML course, it was
completely irrelevant and it didn't even
completely irrelevant and it didn't even
touch on neural nets at all. Um
I think if anything else
I think if anything else
I don't know if you have other
I don't know if you have other
specifics, I can answer stuff.
learning takes time. Well, it's like
learning takes time. Well, it's like
a lot of the coursework isn't even going
a lot of the coursework isn't even going
to help you. Like take RL specifically.
to help you. Like take RL specifically.
You can perfectly, you can go take an RL
You can perfectly, you can go take an RL
course and understand everything
course and understand everything
perfectly and get a 100red in the course
perfectly and get a 100red in the course
and have absolutely no idea what you're
and have absolutely no idea what you're
doing.
Like I literally have people that spend
Like I literally have people that spend
a few days going through some of the
a few days going through some of the
stuff that I've done and they have a
stuff that I've done and they have a
better understanding than if you go read
better understanding than if you go read
the entire Sutton and Bardau book.
I don't know. Like academia has a way of
I don't know. Like academia has a way of
teaching stuff and a language by which
teaching stuff and a language by which
they teach stuff. They kind of just like
they teach stuff. They kind of just like
to beat you over the head with math
to beat you over the head with math
until you like get bored and stop, I
until you like get bored and stop, I
guess.
guess.
But like they'll do it even if it has no
But like they'll do it even if it has no
practical application or it's like not
practical application or it's like not
even fully correct. They'll just do it
even fully correct. They'll just do it
anyways.
I don't know. This has been one of the
I don't know. This has been one of the
things I've been pretty good at, right?
things I've been pretty good at, right?
Is like identifying gaps in the way that
Is like identifying gaps in the way that
things are done and then just doing it a
things are done and then just doing it a
completely different way.
I got into my CS masters and I have gaps
I got into my CS masters and I have gaps
in math only fill them after I finish
in math only fill them after I finish
grad. My trying to do it along courses
grad. My trying to do it along courses
research is much honestly most of the
research is much honestly most of the
math in RL is like wrong.
math in RL is like wrong.
Most of the RL math is just wrong.
There are very small bits of math that
There are very small bits of math that
actually matter.
like the whole basis of a lot of stuff
like the whole basis of a lot of stuff
it's like all derived from tabular
it's like all derived from tabular
Q-learning on MDPs
Q-learning on MDPs
and it's just a mess. Yes.
Please mention what needs to be changed.
Please mention what needs to be changed.
I'm working on an article that will
I'm working on an article that will
cover a lot of it. Um, it's mainly like
cover a lot of it. Um, it's mainly like
they do 10 times too much math and 10
they do 10 times too much math and 10
times too little engineering.
Like they don't care about solving the
Like they don't care about solving the
problem. They care about doing a bunch
problem. They care about doing a bunch
of math. It's weird. like they care
of math. It's weird. like they care
about writing fancy algorithms and like
about writing fancy algorithms and like
running their experiments and like
running their experiments and like
saying a better than b even though
saying a better than b even though
statistically it makes no sense. It's
statistically it makes no sense. It's
like there's like a very cookie cutter
like there's like a very cookie cutter
way that stuff is done
way that stuff is done
and that worked up to a point and then
and that worked up to a point and then
when it was time to actually like make
when it was time to actually like make
all this stuff fast enough so that that
all this stuff fast enough so that that
approach could continue to be useful,
approach could continue to be useful,
everybody kind of just threw up their
everybody kind of just threw up their
hands, didn't do it, and let the field
hands, didn't do it, and let the field
die.
die.
I'm not even remotely exaggerating.
RL is a field where understanding a
RL is a field where understanding a
little bit about the history of like how
little bit about the history of like how
stuff has developed over the last few
stuff has developed over the last few
years will do you a lot more good than
years will do you a lot more good than
like understanding 20 algorithm.
like understanding 20 algorithm.
This is a generic question. I'm a
This is a generic question. I'm a
third-year undergrad and ideally you
third-year undergrad and ideally you
want to be some kind of ML research or
want to be some kind of ML research or
applied scientist. Pretty comfortable
applied scientist. Pretty comfortable
with understanding the latest
with understanding the latest
developments in LMS and based models.
developments in LMS and based models.
Okay, that's a lot of math. So, you're
Okay, that's a lot of math. So, you're
probably set there. Minus RL. If you
probably set there. Minus RL. If you
were me, what would you focus on right
were me, what would you focus on right
now? I don't know what I should do to
now? I don't know what I should do to
achieve my goals.
achieve my goals.
Research engineer or applied scientist?
Research engineer or applied scientist?
Yeah. So, research engineer is a little
Yeah. So, research engineer is a little
bit trickier because it's usually like
bit trickier because it's usually like
they kind of just grab people out of
they kind of just grab people out of
masters or whatever. um for re like for
masters or whatever. um for re like for
ML research and then also qualifies you
ML research and then also qualifies you
for research engineer positions doing a
for research engineer positions doing a
bit of your own research is probably
bit of your own research is probably
good publishing something is probably
good publishing something is probably
good. Um, so getting to the point that
good. Um, so getting to the point that
you can function autonomously like that
you can function autonomously like that
is good. And then on the engineering
is good. And then on the engineering
side, just like if you want to go that
side, just like if you want to go that
route, then just do the exact same
route, then just do the exact same
thing, but do it with an engineering
thing, but do it with an engineering
heavy approach, right?
heavy approach, right?
like focus on doing stuff that is
like focus on doing stuff that is
engineering intensive and also produces
engineering intensive and also produces
a cool result that you can publish
a cool result that you can publish
instead of like
instead of like
the traditional one which is the
the traditional one which is the
traditional science thing where like
traditional science thing where like
scientists can't write code at all.
I don't know. That's the vague general
I don't know. That's the vague general
advice I have today.
appreciate it a lot. Yeah, you can look
appreciate it a lot. Yeah, you can look
at like my RL specific thing. There's a
at like my RL specific thing. There's a
quick start guide on puffer.ai. It has a
quick start guide on puffer.ai. It has a
lot of good reference material.
I mean, my path was pretty much that I
I mean, my path was pretty much that I
started research really early on. I
started research really early on. I
didn't really have a specific topic of
didn't really have a specific topic of
interest. So I started doing some
interest. So I started doing some
natural language processing because that
natural language processing because that
was the lab that was there and then I
was the lab that was there and then I
went and I did some computer vision. I
went and I did some computer vision. I
managed to publish one thing in natural
managed to publish one thing in natural
language processing. Put a couple just
language processing. Put a couple just
archive manuscripts out on vision stuff
archive manuscripts out on vision stuff
and then I came up with the idea for
and then I came up with the idea for
neural MMO and I learned the RL and all
neural MMO and I learned the RL and all
the stuff around it to make that happen.
the stuff around it to make that happen.
I did that for my whole PhD and then in
I did that for my whole PhD and then in
the last year year and a half I started
the last year year and a half I started
doing puffer and the goal here is to use
doing puffer and the goal here is to use
all the knowledge I gained about RL to
all the knowledge I gained about RL to
make RL a faster ser more stable field
make RL a faster ser more stable field
because I saw that as a gap
a lot of science is a lot more cookie
a lot of science is a lot more cookie
cutter than the path that I've taken
cutter than the path that I've taken
uh the path that I've taken is like the
uh the path that I've taken is like the
very high variance path
very high variance path
where you're kind of just going to get
where you're kind of just going to get
stomped a lot of the time because
stomped a lot of the time because
researchers don't like it when you do
researchers don't like it when you do
work this way. Uh but you're also going
work this way. Uh but you're also going
to be able to solve problems that nobody
to be able to solve problems that nobody
else can.
So that's the that's what I can speak
So that's the that's what I can speak
to.
all very impressive. Oh, thank you. It's
all very impressive. Oh, thank you. It's
most of what I do, so I would hope it
most of what I do, so I would hope it
is.
Hey, what's going on? Can I get a quick
Hey, what's going on? Can I get a quick
overview? Uh, this is reinforcement
overview? Uh, this is reinforcement
learning dev. I stream all of my
learning dev. I stream all of my
research. I'm currently working on a
research. I'm currently working on a
drone environment where you can send
drone environment where you can send
commands to make drones go in uh arrange
commands to make drones go in uh arrange
themselves in a variety of patterns and
themselves in a variety of patterns and
follow each other and do stuff like
follow each other and do stuff like
that.
that.
If you want to check out some cool
If you want to check out some cool
demos, they're all on puffer.ai. You
demos, they're all on puffer.ai. You
have agents that play games and like do
have agents that play games and like do
other fun stuff all in your browser.
Any
advice on YouTube versus Twitch
advice on YouTube versus Twitch
streaming? Free automation tool? I
streaming? Free automation tool? I
stream on both. I just do it through
stream on both. I just do it through
reream.
reream.
And I don't know what you mean for free
And I don't know what you mean for free
automation tools
specifically.
So, Congo,
how to make the posts get automated.
how to make the posts get automated.
Message everything externally.
Do you mean how to make the post get
Do you mean how to make the post get
automated?
like
post
post
it just like YouTube just shows up.
it just like YouTube just shows up.
YouTube will just record your VODs
YouTube will just record your VODs
automatically for you. You don't have to
automatically for you. You don't have to
do anything.
do anything.
Twitch will record them, but it won't
Twitch will record them, but it won't
store them forever. That's just Twitch
store them forever. That's just Twitch
being Twitch. Nothing you do about that.
being Twitch. Nothing you do about that.
YouTube is really going to be your main
YouTube is really going to be your main
archive. Uh X will store I don't know
archive. Uh X will store I don't know
how many. I think X has a cap, but it'll
how many. I think X has a cap, but it'll
store the last many. Um,
store the last many. Um,
X automatically posts your stream when
X automatically posts your stream when
you stream YouTube. It automatically
you stream YouTube. It automatically
shows up in the live tab and it gets
shows up in the live tab and it gets
recommended to people. Same for Twitch.
recommended to people. Same for Twitch.
You really don't need any like extra
You really don't need any like extra
tools. You do need something like Reream
tools. You do need something like Reream
to make it a little easier to stream
to make it a little easier to stream
simultaneously to many services.
Oh yeah, this is going to be really
Oh yeah, this is going to be really
good.
Thanks a lot. How would you learn RL
Thanks a lot. How would you learn RL
teach RL to beginner researchers? The uh
teach RL to beginner researchers? The uh
I'm making another one of these, but the
I'm making another one of these, but the
quick start guide on my website is very
quick start guide on my website is very
good.
Like that's literally it. Do that. Start
Like that's literally it. Do that. Start
building environments.
building environments.
If you already know how to program, you
If you already know how to program, you
can literally start doing RL over a
can literally start doing RL over a
weekend. If you don't know how to
weekend. If you don't know how to
program, well, then that's the hard
program, well, then that's the hard
part, right?
We'll add one more task.
What are you working on here? Um
here. So you can see that there are all
here. So you can see that there are all
sorts of different configurations.
sorts of different configurations.
Some are stationary, some are mobile.
Some are stationary, some are mobile.
Uh, and I'm going to I'm defining a
Uh, and I'm going to I'm defining a
bunch of these and I'm going to
bunch of these and I'm going to
reinforcement learn these drones such
reinforcement learn these drones such
that they can uh do any of those
that they can uh do any of those
patterns. They can arrange themselves in
patterns. They can arrange themselves in
any of those patterns.
Almost done as well.
You
Uh, almost
Uh, almost
white.
Okay. So almost
make it better later. I want to at least
make it better later. I want to at least
get it to run.
What's your recommended way of
What's your recommended way of
understanding a given environment?
understanding a given environment?
Know in it step and a reset function.
Know in it step and a reset function.
Well, understanding like one of the
Well, understanding like one of the
puffer environments, you can mostly read
puffer environments, you can mostly read
it from top to bottom.
it from top to bottom.
Um,
Um,
like these are like except for some of
like these are like except for some of
the messier ones, they're mostly written
the messier ones, they're mostly written
in as simple as possible basic C. But
in as simple as possible basic C. But
like go watch it. If it's playable, play
like go watch it. If it's playable, play
it a little bit.
If it's playable, play it a little bit.
If it's playable, play it a little bit.
That helps a lot.
Still not arranged correctly.
try this. Um,
try this. Um,
yeah, mostly it's like playing the
yeah, mostly it's like playing the
environment. The way you design rewards
environment. The way you design rewards
is less even to do. There are a couple
is less even to do. There are a couple
RL specific things you need to know, but
RL specific things you need to know, but
like the biggest thing honestly is just
like the biggest thing honestly is just
knowing what information the agent needs
knowing what information the agent needs
to solve the task and like what signal
to solve the task and like what signal
makes sense
makes sense
to actually tell you how to solve the
to actually tell you how to solve the
task. It's like not even RL specific,
task. It's like not even RL specific,
right? It's just like basic first
right? It's just like basic first
principles reasoning
wrong here. It's Sixide by 8
wrong here. It's Sixide by 8
and 8
and 8
0 to 7.
from the ML side where is the
from the ML side where is the
observation space, action space and
observation space, action space and
reward stuff. So the actual shape of it
reward stuff. So the actual shape of it
is in the Python file
is in the Python file
um
um
and that gets passed in as just a
and that gets passed in as just a
pointer. So you just have a pointer to
pointer. So you just have a pointer to
the observations
the observations
and then usually most ends have like a
and then usually most ends have like a
compute observation
compute observation
function or it'll be inlined
function or it'll be inlined
inside of the step function and then
inside of the step function and then
reward similarly either there's either
reward similarly either there's either
going to be a function or it'll be
going to be a function or it'll be
inlined in the step function.
Okay, this is I think this is correct.
Okay, this is I think this is correct.
Good.
Let's see if this thing learns.
Roer color.
Okay, so this is now trained on I
Okay, so this is now trained on I
believe seven or eight tasks.
believe seven or eight tasks.
See,
See,
seven tasks.
seven tasks.
One of them is just do like it's like an
One of them is just do like it's like an
idle task.
idle task.
One of them is to hover in place. One of
One of them is to hover in place. One of
them is to be in this like spherical
them is to be in this like spherical
orbit thing.
orbit thing.
There's a follow task where you have to
There's a follow task where you have to
follow a single target. There's a line
follow a single target. There's a line
task where they all have to put
task where they all have to put
themselves into a line. Congo task where
themselves into a line. Congo task where
they got to follow each other. There's a
they got to follow each other. There's a
plane task.
Should be able to do some stuff with
Should be able to do some stuff with
this.
And that's a decent policy in like
And that's a decent policy in like
literally 30 seconds as well. He'll get
literally 30 seconds as well. He'll get
better, but this is a very good start, I
better, but this is a very good start, I
would say.
This looks very fun. How do I get
This looks very fun. How do I get
involved? It's all open source
involved? It's all open source
puffer.ai.
Wait till you see this result as soon as
Wait till you see this result as soon as
this thing is trained.
this thing is trained.
These are all the ends. Uh most of these
These are all the ends. Uh most of these
are made by contributors. Some of them
are made by contributors. Some of them
are made by me.
are made by me.
There is uh documentation on how to get
There is uh documentation on how to get
started. We suggest that most new
started. We suggest that most new
contributors start by going through the
contributors start by going through the
quick start guide on the blog here.
quick start guide on the blog here.
And then you're going to want to write
And then you're going to want to write
an environment.
Typically, like you look for something
Typically, like you look for something
that's fun that you can do in maybe a
that's fun that you can do in maybe a
few hundred lines of code, not a massive
few hundred lines of code, not a massive
project. People have come up with all
project. People have come up with all
sorts of stuff. We like things that are
sorts of stuff. We like things that are
interesting, like interesting challenges
interesting, like interesting challenges
for RL in a new way. We also like things
for RL in a new way. We also like things
that are just cool and interesting. Like
that are just cool and interesting. Like
here, Tetris ended up being really cool
here, Tetris ended up being really cool
to watch. Just Tetris, but like look how
to watch. Just Tetris, but like look how
cool it is to watch the AI play it.
cool it is to watch the AI play it.
Like mesmerizing, right?
We had somebody submit 2048 and uh you
We had somebody submit 2048 and uh you
know, completely counterintuitively,
know, completely counterintuitively,
this ended up being actually a very
this ended up being actually a very
useful environment for research.
useful environment for research.
As it turns out, it's actually kind of
As it turns out, it's actually kind of
hard.
There tons of things in here.
I don't know what that is
type of Polish dance. What?
Is this sick? Happy I stumbled across
Is this sick? Happy I stumbled across
you. Thank you. Here, let me show you
you. Thank you. Here, let me show you
this thing real quick
this thing real quick
because we just trained this model.
because we just trained this model.
Okay, so if I hold tab, this will show
Okay, so if I hold tab, this will show
you the target objectives. They do a
you the target objectives. They do a
pretty decent job of uh going to these
pretty decent job of uh going to these
targets.
targets.
And if we sort of change up the tasks,
And if we sort of change up the tasks,
so this is just a do whatever task,
so this is just a do whatever task,
don't collide.
don't collide.
We've got a hover task which is stay in
We've got a hover task which is stay in
place.
place.
Orbit follow the single dot. Got this
Orbit follow the single dot. Got this
line task.
Arrange themselves in a line. Got this
Arrange themselves in a line. Got this
congo task.
I need to make it so it doesn't reset so
I need to make it so it doesn't reset so
frequently so you can actually see. They
frequently so you can actually see. They
are doing a congo though. You can kind
are doing a congo though. You can kind
of see it.
of see it.
It could be a little better, but not bad
It could be a little better, but not bad
for a first result plane.
That was quick. Yeah. So, this is the
That was quick. Yeah. So, this is the
thing with Puffer, right? It's literally
thing with Puffer, right? It's literally
a thousand times faster than everything
a thousand times faster than everything
that else that is out there in
that else that is out there in
reinforcement learning. You can
reinforcement learning. You can
literally train superhuman models in
literally train superhuman models in
seconds.
Like this pong agent here, you know how
Like this pong agent here, you know how
long it takes to train this pong agent?
long it takes to train this pong agent?
Okay, so this is something that would
Okay, so this is something that would
take like hours or days uh before puffer
take like hours or days uh before puffer
lib. This is how long it takes to train
lib. This is how long it takes to train
Pong.
Okay, it's done.
And if I will have to convince you.
There you go. There's your agent that
There you go. There's your agent that
plays pong. You're the blue one,
plays pong. You're the blue one,
obviously.
So yeah, this is what I do all day. This
So yeah, this is what I do all day. This
is all open source. We do our own RL
is all open source. We do our own RL
research on the algorithms. We do our
research on the algorithms. We do our
own crazy infrastructure to make
own crazy infrastructure to make
everything fast. We write tons of
everything fast. We write tons of
environments for use in research and
environments for use in research and
applications.
applications.
Uh yeah, this is this is the main thing.
Uh yeah, this is this is the main thing.
What did you optimize so well? We tore
What did you optimize so well? We tore
out and rewrote the whole stack. The
out and rewrote the whole stack. The
result is actually pretty concise. like
result is actually pretty concise. like
our code is actually a lot simpler than
our code is actually a lot simpler than
the other things out there as well even
the other things out there as well even
though it's this fast but the
though it's this fast but the
environments are in C very simple C but
environments are in C very simple C but
it's C uh they write observations
it's C uh they write observations
directly into shared memory so like you
directly into shared memory so like you
can have thousands of environments and
can have thousands of environments and
all the data is immediately available on
all the data is immediately available on
the main process without redundant
the main process without redundant
copies
copies
trainers optimized for super large
trainers optimized for super large
batches which is not usual we optimize
batches which is not usual we optimize
the heck out of a lot of the overhead on
the heck out of a lot of the overhead on
the trainer as well
the trainer as well
we
we
And we made some fundamental algorithm
And we made some fundamental algorithm
improvements that let you do that more
improvements that let you do that more
effectively.
effectively.
The mix of a lot of things.
This is what I think this is the first
This is what I think this is the first
environment that I did in pure state is
environment that I did in pure state is
this snake environment. It's maybe 300
this snake environment. It's maybe 300
linesish of code. very very simple
linesish of code. very very simple
environment but cool each snake is an
environment but cool each snake is an
agent.
agent.
What batch sizes are we talking about?
What batch sizes are we talking about?
So I think our most common training
So I think our most common training
setting at this point is 8192
setting at this point is 8192
environments or agents. So if you have a
environments or agents. So if you have a
multi- aent environment you count total
multi- aent environment you count total
number of agents. 8192 agents and a
number of agents. 8192 agents and a
batch size of about 500,000. and our
batch size of about 500,000. and our
biggest experiments. If you haven't seen
biggest experiments. If you haven't seen
this article, this is this is a pretty
this article, this is this is a pretty
cool article.
cool article.
So this one here, we did RL on a pabyte
So this one here, we did RL on a pabyte
of data. So uh it was 640 billion steps
of data. So uh it was 640 billion steps
or 640 billion observations. And this
or 640 billion observations. And this
one used a batch size of 3 million.
one used a batch size of 3 million.
You deploy a neural net for each trained
You deploy a neural net for each trained
agent. What's the data format of the
agent. What's the data format of the
policy when you save it? It is the same
policy when you save it? It is the same
neural network executed independently.
neural network executed independently.
So they're not the same agent. They are
So they're not the same agent. They are
completely independent of each other. Uh
completely independent of each other. Uh
but they share the same logic.
That is our standard setting.
And my PhD is in multi-agent RL. There
And my PhD is in multi-agent RL. There
are a lot of other things you can do.
are a lot of other things you can do.
Some of them make sense, but mostly it's
Some of them make sense, but mostly it's
kind of best to just do it this way.
This
This
not log in this.
not log in this.
Oh, yes.
Probably needs to be swept. Batch size 3
Probably needs to be swept. Batch size 3
million. I'm going to go read up.
million. I'm going to go read up.
Yeah, we have some pretty cool stuff. I
Yeah, we have some pretty cool stuff. I
think the best agent Very nice work,
think the best agent Very nice work,
Kingpuffer. Thank you. The best agent
Kingpuffer. Thank you. The best agent
that we have is the uh so the one
that we have is the uh so the one
pedabyte agent is available on the
pedabyte agent is available on the
website.
website.
It plays neural MMO 3. Takes a second to
It plays neural MMO 3. Takes a second to
load in because now it's loading a
load in because now it's loading a
neural net and stuff. Um
neural net and stuff. Um
so this is a big game. Oops.
so this is a big game. Oops.
I think I hit escape by mistake. Escape
I think I hit escape by mistake. Escape
is mapped to uh
is mapped to uh
undo. Hang on.
Did we break it?
Did we break it?
When does tab break it?
When does tab break it?
Oh, that's obnoxious.
You should be able to zoom out on the
You should be able to zoom out on the
map.
I didn't even push an update to this
I didn't even push an update to this
thing recently.
thing recently.
Well, apparently I can't zoom out to
Well, apparently I can't zoom out to
show you how big the map is, but the
show you how big the map is, but the
trailer for that is on X. Actually, you
trailer for that is on X. Actually, you
know what? No, I totally can because I
know what? No, I totally can because I
have it locally.
Neural MMO policy is only 3 million
Neural MMO policy is only 3 million
parameters. All right, this is the map.
parameters. All right, this is the map.
It's not actually fractal, but we It's I
It's not actually fractal, but we It's I
left it this way because we do actually
left it this way because we do actually
train on multiple maps at the same time,
train on multiple maps at the same time,
so it makes sense.
so it makes sense.
So, it's like this big MMO.
And
And
if you watch the agent, you'll see that
if you watch the agent, you'll see that
it's capable of using tools. It gets
it's capable of using tools. It gets
equipment. It knows how to put stuff on.
equipment. It knows how to put stuff on.
It knows how to fight. It knows how to
It knows how to fight. It knows how to
kite enemies. Sometimes it even knows
kite enemies. Sometimes it even knows
how to sell and buy items on this
how to sell and buy items on this
marketplace.
like a 3.4 million parameter-ish
like a 3.4 million parameter-ish
network.
This is our best agent. I would say
This is our best agent. I would say
I wrote an article about this. I
I wrote an article about this. I
subjectively consider this result to be
subjectively consider this result to be
better than emergent tool use and
better than emergent tool use and
capture the flag, but uh nowhere near as
capture the flag, but uh nowhere near as
good as something like Alpha Star and
good as something like Alpha Star and
Dota
Dota
based on my own subjective opinion. So
based on my own subjective opinion. So
deal with it.
Option space there is huge.
Option space there is huge.
in neural MMO. Yeah, you'd think so. But
in neural MMO. Yeah, you'd think so. But
guess what? I have the action space
guess what? I have the action space
mapped to something like a discrete of
mapped to something like a discrete of
26.
26.
That's part of energy design.
There are some tricks that we have.
It's a bit ry. I mean, I'd hope it's
It's a bit ry. I mean, I'd hope it's
cool. I've literally neural MMO was the
cool. I've literally neural MMO was the
topic of my entire PhD and two years
topic of my entire PhD and two years
worth of research before that.
I'd hope it's cool.
Yeah, thank you. We're not done with it
Yeah, thank you. We're not done with it
either. I literally have um I have an
either. I literally have um I have an
experiment going right now.
It's doing another one pabyte experiment
It's doing another one pabyte experiment
at the moment.
This is approximately
This is approximately
uh 350 terabytes. No wait is it 350?
uh 350 terabytes. No wait is it 350?
Yeah, 350 terabytes into training and
Yeah, 350 terabytes into training and
currently it is doing
currently it is doing
pretty dang well.
pretty dang well.
Can you say what hardware you're running
Can you say what hardware you're running
this on?
this on?
You see right behind me,
You see right behind me,
you see the white boxes up on the
you see the white boxes up on the
shelves? Those are tiny boxes. There's
shelves? Those are tiny boxes. There's
six GPUs a piece, six 4090s.
six GPUs a piece, six 4090s.
And uh we ran these experiments. Just
And uh we ran these experiments. Just
need one of those boxes to run an
need one of those boxes to run an
experiment like this for maybe three
experiment like this for maybe three
days, three to four days.
You don't need a crazy amount of
You don't need a crazy amount of
hardware. You need a little bit of
hardware. You need a little bit of
hardware, not a crazy amount.
hardware, not a crazy amount.
This is the only thing in Puffer that
This is the only thing in Puffer that
requires a multiGPU machine as well.
requires a multiGPU machine as well.
Nothing else requires multiGPU.
Nothing else requires multiGPU.
Everything else you can train at home on
Everything else you can train at home on
like a single 4090
like a single 4090
3080 or whatever if you have one. It'll
3080 or whatever if you have one. It'll
just take long, right?
just take long, right?
You're never going to be out of memory
You're never going to be out of memory
for the most part.
Okay, let me get this stuff configured.
Okay, let me get this stuff configured.
I got to go to dinner soonish. I want to
I got to go to dinner soonish. I want to
make sure that we get a sweep going on
make sure that we get a sweep going on
this
read up on the details. This is awesome.
read up on the details. This is awesome.
Thanks. Hey, I hope you enjoy. We're
Thanks. Hey, I hope you enjoy. We're
always looking for new contributors. So,
always looking for new contributors. So,
if you want to get involved with
if you want to get involved with
research, be very happy for the help.
Yep.
stream every day. I do not stream seven
stream every day. I do not stream seven
days a week. I do occasionally rest. Uh
days a week. I do occasionally rest. Uh
I mostly stream at the moment on
I mostly stream at the moment on
reasonable hours Eastern time subject to
reasonable hours Eastern time subject to
other meetings and stuff that I have to
other meetings and stuff that I have to
take. So, most of the day EST,
take. So, most of the day EST,
sometimes in the evenings, depends how,
sometimes in the evenings, depends how,
you know, depends how I'm feeling.
you know, depends how I'm feeling.
Sometimes I work late as well. Uh,
Sometimes I work late as well. Uh,
usually stream like Monday through
usually stream like Monday through
Saturday.
Saturday.
Now, the thing is I am going in uh in
Now, the thing is I am going in uh in
like a week. I'm going to Palo Alto. So,
like a week. I'm going to Palo Alto. So,
I'll be on Pacific for a bit and I'll
I'll be on Pacific for a bit and I'll
probably be having a lot of like
probably be having a lot of like
business meetings to deal with because
business meetings to deal with because
that's the point of being there right by
that's the point of being there right by
SF. All sorts of meetings. Then I'm
SF. All sorts of meetings. Then I'm
going to RLC. So, I will be at RLC in
going to RLC. So, I will be at RLC in
person for uh presenting Puffer Lib
person for uh presenting Puffer Lib
Puffer Lib 2, which is old at this
Puffer Lib 2, which is old at this
point, but that's the paper that got
point, but that's the paper that got
accepted. And then I'll be back in Po
accepted. And then I'll be back in Po
Alto for a few weeks and then I'll be
Alto for a few weeks and then I'll be
back here for quite a while.
Oh, it's not super consistent when, but
Oh, it's not super consistent when, but
the number of hours is quite cons. That
the number of hours is quite cons. That
makes sense.
Congrats
on all the W's. Thank you.
Well,
Well,
we could still use uh some larger
we could still use uh some larger
contracts, right?
contracts, right?
We have a
We have a
slightly profitable private RL lab.
slightly profitable private RL lab.
Ideally, we could have a very profitable
Ideally, we could have a very profitable
private RL lab and then we can fund way
private RL lab and then we can fund way
more research.
That is the ideal.
Make that happen for sure. I hope so as
Make that happen for sure. I hope so as
well. I think we should be good.
I pretty much just need to be spending
I pretty much just need to be spending
uh a decent chunk of time looking for
uh a decent chunk of time looking for
good applications where we can really uh
good applications where we can really uh
solve people's problems with RL.
solve people's problems with RL.
Sort of been doing that passively over
Sort of been doing that passively over
the last weeks since the release.
Find a couple of those and we should
Find a couple of those and we should
get back to doing more research.
UK.
So this works. Yeah.
Have you looked at chip optimization
Have you looked at chip optimization
with RL? Planning to give that a go
with RL? Planning to give that a go
soon.
It's a much harder problem because it's
It's a much harder problem because it's
a placement problem. You kind of just
a placement problem. You kind of just
have to zero shot output the entire
have to zero shot output the entire
chip.
chip.
We do have some good RL stuff, so it's
We do have some good RL stuff, so it's
possible we could do something there.
possible we could do something there.
I've sort of thought about it. It's not
I've sort of thought about it. It's not
anywhere near as easy of an application
anywhere near as easy of an application
for initial entry point into industry.
for initial entry point into industry.
Um, we actually almost got a client in
Um, we actually almost got a client in
that space quite a while ago just on
that space quite a while ago just on
like the general RL tech that we were
like the general RL tech that we were
doing.
need a high-speed simulator is a big
need a high-speed simulator is a big
barrier. Yep. Are there workarounds that
barrier. Yep. Are there workarounds that
you could invent? Yes, there very much
you could invent? Yes, there very much
are. And that is the uh the subject of
are. And that is the uh the subject of
quite a bit of research. I think we are
quite a bit of research. I think we are
better positioned than anybody else to
better positioned than anybody else to
do that research. But the thing is like
do that research. But the thing is like
we kind of already have a bunch of
we kind of already have a bunch of
valuable tech. So my plan for the time
valuable tech. So my plan for the time
being is to find useful areas where we
being is to find useful areas where we
can build fast simulators. Uh make the
can build fast simulators. Uh make the
company much more profitable doing a
company much more profitable doing a
couple of those things and then invest
couple of those things and then invest
that to do the research to make RL work
that to do the research to make RL work
in other areas. Right? That seems the
in other areas. Right? That seems the
most sensible course to me.
most sensible course to me.
Can we just appreciate that this thing
Can we just appreciate that this thing
is running at 4 million steps per
is running at 4 million steps per
second? By the way,
thing is running like an overnight the
thing is running like an overnight the
equivalent of like an overnight
equivalent of like an overnight
experiment from my PhD every two
experiment from my PhD every two
seconds.
seconds.
All right, we'll leave this here and
All right, we'll leave this here and
then this will uh run us a nice hyper
then this will uh run us a nice hyper
pram sweep.
He should be good shape with that.
What else do I want to do on this? I may
What else do I want to do on this? I may
as well just clean it up for a little
as well just clean it up for a little
bit right now before I have to head for
bit right now before I have to head for
dinner. I'm going to head out just a
dinner. I'm going to head out just a
little bit early, I think, as well. My
little bit early, I think, as well. My
uh my family is visiting. They just got
uh my family is visiting. They just got
here. Um, but let me real quick I just
here. Um, but let me real quick I just
want to rename it real
Hey yay.
I'm back. How much of the drone code
I'm back. How much of the drone code
have you written by yourself? How much
have you written by yourself? How much
of it is off this shelf? Such a huge
of it is off this shelf? Such a huge
space. We have two undergrads who are
space. We have two undergrads who are
helping with the drone stuff. Uh they
helping with the drone stuff. Uh they
wrote I will show you their sim.
wrote I will show you their sim.
None of it's off the shelf though,
None of it's off the shelf though,
that's for sure.
So Finn and Sam, who are in the Discord,
So Finn and Sam, who are in the Discord,
wrote this.
wrote this.
I helped a little bit with some of the
I helped a little bit with some of the
learning, but they wrote this.
trained with Puffer Lib.
trained with Puffer Lib.
And then in the last like day and a
And then in the last like day and a
half, I modified this. I made a version
half, I modified this. I made a version
of it that has supports a bunch of
of it that has supports a bunch of
drones. And then I instead of having
drones. And then I instead of having
ring targets, I have a configuration
ring targets, I have a configuration
that's essentially just like tells the
that's essentially just like tells the
drone to follow an instruction. There's
drone to follow an instruction. There's
Finn. Finn's one of the authors of this.
You'll see, Larry, that um like a lot of
You'll see, Larry, that um like a lot of
the stuff in Puffer Lib, it's like these
the stuff in Puffer Lib, it's like these
crazy things, but it ends up just being
crazy things, but it ends up just being
a few hundred lines of code with the way
a few hundred lines of code with the way
we build everything.
we build everything.
Like the more complicated stuff ends up
Like the more complicated stuff ends up
being a few thousand lines of code. But
being a few thousand lines of code. But
I think all of neural MMO 3, this whole
I think all of neural MMO 3, this whole
project here is under 3,000 lines.
No, it's the exact opposite. None of it
No, it's the exact opposite. None of it
is abstracted. That's why it's short.
This is why you like you see me writing
This is why you like you see me writing
like uh almost no dependencies C.
Oh, whoops.
Environments and C. I have some practice
Environments and C. I have some practice
to do. I'm a physics grad. Oh, yeah.
to do. I'm a physics grad. Oh, yeah.
Perfect. You'll be well positioned then.
Perfect. You'll be well positioned then.
That's actually super useful cuz that's
That's actually super useful cuz that's
like one of the things I'm very bad at
like one of the things I'm very bad at
and I love having people around who are
and I love having people around who are
good at that.
We keep the C really simple though, like
We keep the C really simple though, like
really really simple.
We actually have brand new programmers
We actually have brand new programmers
who uh who have gotten into Puffer Lab
who uh who have gotten into Puffer Lab
and have been just fine.
Like this is the entire source code
Like this is the entire source code
right here is this 800 line file. And
right here is this 800 line file. And
I'm actually embarrassed that this is
I'm actually embarrassed that this is
800 lines. Like it should not be 800
800 lines. Like it should not be 800
lines. So I'll have to go figure out
lines. So I'll have to go figure out
what the heck redundant stuff I have in
what the heck redundant stuff I have in
here.
Okay, there we go. Still works. Commit
Okay, there we go. Still works. Commit
this.
trying to solve a fiber optic path
trying to solve a fiber optic path
finding algorithm at the moment.
finding algorithm at the moment.
Cool.
The name of the game with RL is like
The name of the game with RL is like
fast
fast
as fast simulation as you possibly can
as fast simulation as you possibly can
for interactive processes, right?
for interactive processes, right?
So if you have a problem that can be
So if you have a problem that can be
formulated as an interactive process,
formulated as an interactive process,
you can write a fast sim for it. RL is
you can write a fast sim for it. RL is
usually a good fit. There are a few
usually a good fit. There are a few
exceptions. Stuff that relies a ton on
exceptions. Stuff that relies a ton on
like language is not great. Vision is
like language is not great. Vision is
better, but still not amazing, mainly
better, but still not amazing, mainly
just because it makes the Sim slow. Um,
just because it makes the Sim slow. Um,
but other than that, yeah, you can solve
but other than that, yeah, you can solve
like a lot of really unintuitive
like a lot of really unintuitive
problems really, really fast with this
problems really, really fast with this
stuff.
Do you think pathf finding could be an
Do you think pathf finding could be an
RL problem? Uh, you could turn it into
RL problem? Uh, you could turn it into
one.
one.
Yeah, you could definitely turn it into
Yeah, you could definitely turn it into
one. I mean, we have um
one. I mean, we have um
well, it actually takes a second to
well, it actually takes a second to
train an agent to do our mazes.
train an agent to do our mazes.
Let me see if I can find the graphic of
Let me see if I can find the graphic of
our mazes.
our mazes.
It was in the one of the articles.
It was in the one of the articles.
We have the best maze solving RL agent
We have the best maze solving RL agent
that doesn't like hack it with other
that doesn't like hack it with other
stuff.
Yeah. So, here's our maze solving agent.
You kind of need to be familiar with RL
You kind of need to be familiar with RL
stuff to know how impressive this is.
stuff to know how impressive this is.
Um, this maze right here, like that tiny
Um, this maze right here, like that tiny
one. Yeah, this that's about as big as
one. Yeah, this that's about as big as
the mazes usually get in RL. And even
the mazes usually get in RL. And even
that doesn't really work. And people
that doesn't really work. And people
like hack the algorithm to force it to
like hack the algorithm to force it to
work. So, this is what we got just out
work. So, this is what we got just out
of the box without really doing anything
of the box without really doing anything
special, just running our algorithm.
cominatorial optimizations on graphs in
cominatorial optimizations on graphs in
the dev channel. You can definitely try
the dev channel. You can definitely try
it.
Yeah, you can definitely try it.
It's like kind of a decent approach for
It's like kind of a decent approach for
stuff where verifying the problem is
stuff where verifying the problem is
really fast,
really fast,
but like can't even really get good data
but like can't even really get good data
on the problem because generating the
on the problem because generating the
data is super slow.
The heck is this?
RG puffer.
See, I'll check this and then I got to
See, I'll check this and then I got to
run.
Oh, wait. in the VC do you mean or what
we have this weird case where some
we have this weird case where some
networks subsidized like free to build
networks subsidized like free to build
so some of the edges in the nodes are
so some of the edges in the nodes are
free mitations limit that's fun
I I don't know who this is just chilling
I I don't know who this is just chilling
in the VC if that's what you meant
in the VC if that's what you meant
I do have to run and uh I got to run for
I do have to run and uh I got to run for
in there.
Okay. So, for the folks watching here,
Okay. So, for the folks watching here,
thank you for tuning in today.
thank you for tuning in today.
Probably won't be back after dinner.
Probably won't be back after dinner.
We'll see. My family is here. Uh they're
We'll see. My family is here. Uh they're
visiting.
I will be back in the morning. So if
I will be back in the morning. So if
you're interested in all this stuff,
you're interested in all this stuff,
puffer.ai for all the things,
puffer.ai for all the things,
lots of cool projects built by
lots of cool projects built by
contributors here. If you want to help
contributors here. If you want to help
me out for free, literally free in 5
me out for free, literally free in 5
seconds, just star the repo. Feed the
seconds, just star the repo. Feed the
puffer. It really helps. Like actually
puffer. It really helps. Like actually
starring the repo really helps. And uh
starring the repo really helps. And uh
other than that, yeah, join the Discord.
other than that, yeah, join the Discord.
You can follow me on X for more and all
You can follow me on X for more and all
that. And I will be back tomorrow. More
that. And I will be back tomorrow. More
reinforcement learning.
