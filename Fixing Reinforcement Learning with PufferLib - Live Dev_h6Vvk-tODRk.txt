Kind: captions
Language: en
back live
okay
okay
so we're going to get back onto
so we're going to get back onto
this I came up with some
this I came up with some
ideas I came up with some ideas
ideas I came up with some ideas
um there's still some stuff to decide
um there's still some stuff to decide
though isn't there
I think this Norm is
better really it's just this transform
better really it's just this transform
that I need to
keep yeah I me keep this
transform e
okay I think that uh what I decided
okay I think that uh what I decided
while I was off on my
while I was off on my
run was that the way that we are going
run was that the way that we are going
to do
to do
this welcome linky
how's it
going yeah I think what we're going to
going yeah I think what we're going to
do is first of all this sweep. metric
thing do I have this for One V
compatibility it's probably what I have
compatibility it's probably what I have
this there for right
this there for right
but I don't use Wy sweep so that's
but I don't use Wy sweep so that's
irrelevant
okay so we will just go to
method name metric goal
fine that is
fine that is
fine now we need to add some stuff
maybe I should have left that
in yeah that was dumb I should have left
in yeah that was dumb I should have left
that
in all right no harm done it's cuz and
in all right no harm done it's cuz and
the reason I need to leave it in is
the reason I need to leave it in is
because I realized I need to add Min and
because I realized I need to add Min and
Max to this thing right
by default but we're going to
by default but we're going to
do
zero uh and I guess one for now
at least leave it in the
at least leave it in the
defaults no no no we're not we're not
defaults no no no we're not we're not
deprecating WB sweeps we are dropping WB
deprecating WB sweeps we are dropping WB
sweep support but we are still going to
sweep support but we are still going to
support sweeps in Wy just not using
support sweeps in Wy just not using
their sweeps API so you will have the
their sweeps API so you will have the
same thing just not with the one to be
same thing just not with the one to be
sweeps
API we don't do deprecated
API we don't do deprecated
man deprecated is like oh we'll leave it
man deprecated is like oh we'll leave it
in for now to give you time to switch
in for now to give you time to switch
over no when something needs to change
over no when something needs to change
we change it deprecated is for big
we change it deprecated is for big
companies maintaining Legacy stuff if
companies maintaining Legacy stuff if
we're not if we don't specifically have
we're not if we don't specifically have
somebody we're supporting that needs it
somebody we're supporting that needs it
uh then we just change
uh then we just change
it correct for car carb sweep is gone
it correct for car carb sweep is gone
carb sweep will be gone after
this we will we're going to I'm not
this we will we're going to I'm not
going to ship this before I confirm that
going to ship this before I confirm that
this is just massively better than
carbs e
this 500 line file is going to replace
this 500 line file is going to replace
it it's going to be less than that one
it it's going to be less than that one
we're
done
for
e for
yeah this one I think is worse we'll
yeah this one I think is worse we'll
start with this
welcome YouTube
welcome YouTube
folks this is going to be most of the
folks this is going to be most of the
weekend here uh on trying to make
weekend here uh on trying to make
ridiculously good hyperparameter sweeps
ridiculously good hyperparameter sweeps
for reinforcement learning since we have
for reinforcement learning since we have
a few folks on I'll do a little bit of
a few folks on I'll do a little bit of
background while this experiment
runs my work here is based on mvi carbs
runs my work here is based on mvi carbs
method this is uh a work that's gone
method this is uh a work that's gone
relatively under the radar but made a
relatively under the radar but made a
huge impact on reinforcement learning I
huge impact on reinforcement learning I
really like it at
really like it at
least and it's a very mathy
least and it's a very mathy
paper it does a bunch of things with
paper it does a bunch of things with
various different gaussian processes
various different gaussian processes
it's got like this soft trust region
it's got like this soft trust region
here uh it does expected improvement
here uh it does expected improvement
over predictions from Gan
over predictions from Gan
processes and it does a few other things
processes and it does a few other things
as well um I've been going through the
as well um I've been going through the
released code for this uh I've used
released code for this uh I've used
carbs itself for many months many people
carbs itself for many months many people
in puffer have and we found some things
in puffer have and we found some things
that could be improved and when we
that could be improved and when we
started pulling at that thread well you
started pulling at that thread well you
know one thing led to another and we are
know one thing led to another and we are
really rewriting the majority of this
really rewriting the majority of this
algorithm now and fully rewriting the
algorithm now and fully rewriting the
code um so we're now doing some work to
code um so we're now doing some work to
see which ways we can improve this uh in
see which ways we can improve this uh in
particular carbs and most algorithms
particular carbs and most algorithms
will horribly fail uh the major of very
will horribly fail uh the major of very
simple benchmarks which that's doesn't
simple benchmarks which that's doesn't
seem good you know your algorithm should
seem good you know your algorithm should
not be failing simple benchmarks
not be failing simple benchmarks
um so we are looking at the reasons for
um so we are looking at the reasons for
that and we're going to get something
that and we're going to get something
that works very nicely on both simple
that works very nicely on both simple
benchmarks and then outperforms the
benchmarks and then outperforms the
original on all of our RL environments
original on all of our RL environments
and Puffer that is the
goal
yorm um so the work process for this is
yorm um so the work process for this is
pretty much just going to be me fiddling
pretty much just going to be me fiddling
around with the algorithm fiddling with
around with the algorithm fiddling with
the math fiddling with data
the math fiddling with data
normalization in various ways and then
normalization in various ways and then
trying to figure out how to improve upon
trying to figure out how to improve upon
this H so this is
interesting let me see what this curve
interesting let me see what this curve
is supposed to look like first
and then we'll figure out what's up with
and then we'll figure out what's up with
this
this
so the percentile Tas a synthetic
task it's supposed to be
task it's supposed to be
simple welcome yeah I see your
simple welcome yeah I see your
chats I just had forgotten to enable the
chats I just had forgotten to enable the
chat earlier today like I uh I made a
chat earlier today like I uh I made a
different scene because I had meetings
different scene because I had meetings
where I needed to screen share and I
where I needed to screen share and I
didn't want the chat on it and then I
didn't want the chat on it and then I
just I forgot to switch the scene back
just I forgot to switch the scene back
is
all
all
howdy
CL so right
here this is the
here this is the
score and then the
score and then the
cost cost is unchange so this goes up to
cost cost is unchange so this goes up to
200 so
uh let me think
one so
score one hold on
score one hold on
what over 1
what over 1
+ x
of uh I am
confused what did I make this like this
confused what did I make this like this
is supposed to be a zero to one reward
is supposed to be a zero to one reward
but I'm confused as to what I did here
so I think the maximum score
negative log of the
learning +
okay oh yeah cuz X zero should be
one right yeah you do this so it's it
one right yeah you do this so it's it
goes up to
one and then okay so then what we do
one and then okay so then what we do
is I
do the cost can go up to
do the cost can go up to
that uh so that goes up to about one
that uh so that goes up to about one
yeah
if we do
like oh that's what it's divided
like oh that's what it's divided
by I
see so this gives you
see so this gives you
6 and we see 6 perfect so this is what
6 and we see 6 perfect so this is what
it looks
it looks
like uh for whatever reason
it's scaled kind of
weird oh it goes from0
weird oh it goes from0
five and
five and
one let's
see yeah but it's just it's not being
see yeah but it's just it's not being
computed out far enough for some reason
computed out far enough for some reason
so let's figure that
out why have these
out why have these
been why are these given like
this there's also Max cost to
consider but I would like to look at
this okay
so oh hold on did I Norm this wrong I
so oh hold on did I Norm this wrong I
think I normed it
think I normed it
wrong
wrong
no huh okay okay well we wanted to
no huh okay okay well we wanted to
change this anyways so we're going to
do comment
do comment
these
y we're going to
y we're going to
use
use
um Gan Norm
um Gan Norm
here instead of linear
norm and then I have to remember to undo
this there we go
this there we go
let's see if that changes anything
let's see if that changes anything
before we go crazy looking at the
map the thing is that this should be
map the thing is that this should be
pushing this should pretty quickly push
pushing this should pretty quickly push
towards higher
towards higher
cost so if it doesn't then there's
cost so if it doesn't then there's
something weird
oh
wait I might have left uh left this
wait I might have left uh left this
parameter in
parameter in
right yes I left this parameter in okay
right yes I left this parameter in okay
that was
that was
done
done
10 so there's nothing wrong with this
10 so there's nothing wrong with this
weep I just left a bad hyper in well
weep I just left a bad hyper in well
let's take a look at it at least
let's take a look at it at least
this should now much more
this should now much more
quickly instead of capping it it was
quickly instead of capping it it was
being capped to cost four so now it's
being capped to cost four so now it's
Capp to cost
200 it still not push
outward that would be
odd huh
that doesn't sit
right oh
maybe
maybe
uhuh yeah something's definitely screwy
uhuh yeah something's definitely screwy
with this then
[Music]
okay so it's pushing out but very very
okay so it's pushing out but very very
slowly at
first so why
okay see the
quality okay so this portion here looks
quality okay so this portion here looks
reasonable there a couple
reasonable there a couple
misses
misses
um this is very dense over here
I'm starting to wonder
I'm starting to wonder
why okay hold
why okay hold
on so if you have your data distributed
on so if you have your data distributed
this
this
way it's roughly
linear your loss function should be or
linear your loss function should be or
your score function should be pushing it
your score function should be pushing it
out more aggressively than this
out more aggressively than this
let's go double check the log one just
let's go double check the log one just
in case because um know it's possible
in case because um know it's possible
that I screw that
up log task time log 10
oops
oops
2.3 we'll do
2.31 Max
2 can it go
negative I don't think so
so I want to basically make sure that I
so I want to basically make sure that I
didn't break it in the process of doing
didn't break it in the process of doing
what I was doing with uh the Norms
there CU if this one also takes forever
there CU if this one also takes forever
at the start now
at the start now
then there you have it
oops I got to remember to keep posting
oops I got to remember to keep posting
stuff on
stuff on
here it's kind of silly that this is
here it's kind of silly that this is
considered part of work now but we're
considered part of work now but we're
almost at
almost at
6,900
nice okay so this is is this lower than
before I think that's like an acceptable
before I think that's like an acceptable
Pace right
this cost is in units of 50 million if
this cost is in units of 50 million if
we think of it that
way I think I'm pretty happy for it to
way I think I'm pretty happy for it to
take you know maybe 20 experiments
take you know maybe 20 experiments
before it starts
accelerating but it did it only got up
accelerating but it did it only got up
to 70 here so it is slower than
before how did this
happen do I have the other
happen do I have the other
window yeah so this is what we got
window yeah so this is what we got
before we got like something like
this oops
and now we have a similar
shape this nice line curve
shape this nice line curve
yeah but it takes too many
yeah but it takes too many
samples it's just too many
samples okay
I can check if it was
I can check if it was
the the change of
mean let me just see if it was this
mean let me just see if it was this
first before we do anything
else I think it's more likely the change
else I think it's more likely the change
of normalization
that should be able to make it more
that should be able to make it more
aggressive not
less well we will see shortly
First Community note I've seen on an AI
First Community note I've seen on an AI
model
model
post that's
funny good note
looks like it's going to be
similar so in that case it must have
similar so in that case it must have
been the norm right
this is a little bit more
aggressive quite actually somewhat
aggressive quite actually somewhat
substantially
right yeah that's closer to the
original I think they're probably just
original I think they're probably just
going to have to be a coefficient that
going to have to be a coefficient that
gets uh
tuned for
I think we're also going to Benchmark
I think we're also going to Benchmark
this
this
versus some random methods as well so
versus some random methods as well so
we'll tune based on
we'll tune based on
that
that
um so this is fine for
um so this is fine for
now this gets out to 150ish
so here's just tuning up the because I
so here's just tuning up the because I
do think that we want to use mean
do think that we want to use mean
scaling so we're going to tune this
scaling so we're going to tune this
up so the full
up so the full
transformation you get your score data
transformation you get your score data
which is how well you did in the
which is how well you did in the
environment right and then you're going
environment right and then you're going
to first 01 scale
to first 01 scale
it and then you're going to exponential
it and then you're going to exponential
scale that so you get everything into a
scale that so you get everything into a
01 range and then you apply this
01 range and then you apply this
exponential transform which basically uh
exponential transform which basically uh
the closer you get to the max if you cut
the closer you get to the max if you cut
the distance in half you double your
the distance in half you double your
score um so you get this exponential
score um so you get this exponential
scalar and then we put it into
scalar and then we put it into
approximate we just uh we try to
approximate we just uh we try to
standard Norm it just because gaussians
standard Norm it just because gaussians
like standard
Norms I should do the same thing here
we're going to try this
we're going to try this
next the reason I'm making these changes
next the reason I'm making these changes
now is I did some uh some testing this
now is I did some uh some testing this
morning and it seems like I was
morning and it seems like I was
substantially underappreciated how much
substantially underappreciated how much
gaussian processes rely on nicely
gaussian processes rely on nicely
standard normalized
data the 01 scale is not bad to be
bear we'll
see let me think actually there might
see let me think actually there might
have been a reason I did that
well this didn't really do
well this didn't really do
much let's try
much let's try
again with the new
cost hang on
this might be something that I have to
this might be something that I have to
include both for until we test it
include both for until we test it
out for
oh you know
what linear is correct
here I say is this just absolutely
here I say is this just absolutely
shreds it when I do it the other way let
shreds it when I do it the other way let
me
see what happened
here why are these over
here why are these over
here that shouldn't have happened this
here that shouldn't have happened this
is
is
bad there's a lot of ways to compute
bad there's a lot of ways to compute
this curve is good but this is these
this curve is good but this is these
points are very very bad here yeah this
points are very very bad here yeah this
jumped up too quickly you see this
jumped up too quickly you see this
jumped way too
quickly okay we're going to
quickly okay we're going to
try linear and Norm so we're going to do
try linear and Norm so we're going to do
input Norm Norm
linear just going to put it here for
now and then
now and then
I have to do the same thing somewhere
I have to do the same thing somewhere
don't I
and now we rerun with this
very good
yeah this is going to be correct and
yeah this is going to be correct and
here's the reason that I think this is
here's the reason that I think this is
correct so this does slightly make it
correct so this does slightly make it
harder or this does make it harder
harder or this does make it harder
for the gaussian process to learn the
for the gaussian process to learn the
latent
latent
space okay because it it really likes
space okay because it it really likes
normally distributed data
but that like you're the tales of that
but that like you're the tales of that
distribution are going to grow and the
distribution are going to grow and the
tals are
tals are
important okay
um and if you set there's a mean
um and if you set there's a mean
function in a gin process right which
function in a gin process right which
defines what the function does when
defines what the function does when
you're not near any data
you're not near any data
points so if you have
points so if you have
uh a normally distributed data then as
uh a normally distributed data then as
that function grows uh basically the
that function grows uh basically the
gaum process is going to try to drag
gaum process is going to try to drag
points down at the extremities very
points down at the extremities very
aggressively and in a way that you
aggressively and in a way that you
cannot control whereas if you have it
cannot control whereas if you have it
zero or one scale then at the
zero or one scale then at the
extremities it's always going to be the
extremities it's always going to be the
same drag Force
essentially so here we go with both
essentially so here we go with both
linear I think I left the aggressive
linear I think I left the aggressive
scaling in here
scaling in here
we'll see in a second if this is too
aggressive it is covering the full space
pretty
pretty
good pretty good
maybe too many points over here you
maybe too many points over here you
could
could
argue um let's try on the log task or
argue um let's try on the log task or
the not the log task percentile
task and we need to remember to scale
task and we need to remember to scale
this uh this will be taking care of for
this uh this will be taking care of for
you once I'm
you once I'm
done we're just testing some
stuff I want good coverage in all three
stuff I want good coverage in all three
tasks
this is fair
one of my other favorites
here honestly open ai5 wins by such a
here honestly open ai5 wins by such a
huge
margin
margin
yeah I think from that
yeah I think from that
era open A5 is the most important paper
era open A5 is the most important paper
obviously we're emitting like pure
obviously we're emitting like pure
algorithm stuff like yeah the PO paper
algorithm stuff like yeah the PO paper
obviously but if you want to read one
obviously but if you want to read one
paper in RL you read the opening I5
paper model free deepl
algorithms is this from Eugene's
algorithms is this from Eugene's
lab we built
huh Eugene's at NYU this is
CMU ha that's
funny so I've never heard of any of
funny so I've never heard of any of
these algorithms but apparently that
these algorithms but apparently that
doesn't matter because po
doesn't matter because po
wins which is
wins which is
funny it's very
funny it's very
funny poo normally does win
I want to
I want to
so this is
so this is
good
good
um I have you I can kind of
um I have you I can kind of
understand I have questions for you and
understand I have questions for you and
I have big questions for you
where's the 150 Point all right
where's the 150 Point all right
here
so oh but this is with the aggressive
so oh but this is with the aggressive
schedule
yeah that's too
much it's approximately double
much it's approximately double
cost let me think about
that double cost
that seems too aggressive
right okay here's another way of
right okay here's another way of
thinking about this right
so if you want to go from 100 million to
so if you want to go from 100 million to
10 billion which is like a reasonable
10 billion which is like a reasonable
experiment
experiment
range
right
oops this give you four other way around
okay
so you need to double between six and
so you need to double between six and
seven times to do that so do you want to
seven times to do that so do you want to
be able your hyperparameter tuner to be
be able your hyperparameter tuner to be
able to in the course of seven
able to in the course of seven
experiments go from 100 million to 10
experiments go from 100 million to 10
billion no that seems way too
billion no that seems way too
aggressive what about
1.5 11 and 12
1.5 11 and 12
experiment a little
experiment a little
better what 25 is going to be 20
better what 25 is going to be 20
experiments
experiments
okay and then an additional 10
okay and then an additional 10
experiments to scale outward from there
that's kind of what we would go
for we're going to find a precise way to
for we're going to find a precise way to
tune into
this in a bit but for now let's just
this in a bit but for now let's just
crank it down a little
bit the other thing we can check is how
bit the other thing we can check is how
many experiments it actually
took I mean this is kind of an outlier
took I mean this is kind of an outlier
like this all looks mostly fine
the thing is I think this Point's higher
try this again see if I like this one
try this again see if I like this one
more and then I guess we
will I mean there's still some
will I mean there's still some
modifications to make
oh
where's their
comparison holy I did not know about
comparison holy I did not know about
this
this
I missed that that's
crazy solid
paper e
it's a very good
paper this is actually going to be my
paper this is actually going to be my
this might be I'm going to have to see
this might be I'm going to have to see
how well done this is but if this is
how well done this is but if this is
done correctly um then this will be my
done correctly um then this will be my
candidate
candidate
for probably most useful RL paper I've
for probably most useful RL paper I've
seen this
seen this
year good
year good
job 11 pager read this thing guys this
job 11 pager read this thing guys this
thing looks this is like the first thing
thing looks this is like the first thing
I've seen that looks legitimately worth
I've seen that looks legitimately worth
reading in a long time the only thing is
reading in a long time the only thing is
do they have how many games do they have
yeah they don't have
um they need more ends is what they
need all
I would not trust open spiels
I would not trust open spiels
implementation Over clean
RL absolutely
not DM is not open I follow you but your
not DM is not open I follow you but your
DMs are not open Pi if you want me to
DMs are not open Pi if you want me to
message you for free
message you for free
compute and things keep your DMs on open
compute and things keep your DMs on open
open on Twitter
folks okay so we
folks okay so we
have
interesting let's see what this
was okay this curve looks very good and
was okay this curve looks very good and
then they're two bad
points it's kind of crazy that there can
points it's kind of crazy that there can
be two points that miss that
heavily okay and just to confirm
let's do
um let's try log
[Music]
this I was really hoping that they would
this I was really hoping that they would
have run that over way more environments
have run that over way more environments
way more interesting environments than
way more interesting environments than
just hex and tic tac
toe e
interesting how much that changes the
interesting how much that changes the
Dynamics I think that makes sense
Dynamics I think that makes sense
though the mean functions get all messed
up I guess I could try to adjust the
up I guess I could try to adjust the
mean
mean
[Music]
functions okay let me see maybe this
functions okay let me see maybe this
isn't
isn't
terrible
terrible
so this was before
no it's not like this magically fixes it
no it's not like this magically fixes it
so that it never makes any errors
right so I'm going to prefer I'm going
right so I'm going to prefer I'm going
to prefer this
to prefer this
one until I've given compelling evidence
one until I've given compelling evidence
to the
contrary these are very very similar
curves so we don't need need to worry
curves so we don't need need to worry
about that one then for now good
um we should double check this on the
um we should double check this on the
linear task real
quick Max 4 200 here
just to make sure we didn't somehow
just to make sure we didn't somehow
break this I highly doubt it
but
yeah highly doubt we'll have broken this
yeah highly doubt we'll have broken this
but might
of e
play e
let just do that
it's good to
it's good to
me your
lime little aggressive but not terrible
I almost want to make the uh the total
I almost want to make the uh the total
time steps parameter
time steps parameter
like its own thing CU it's the parameter
like its own thing CU it's the parameter
that influences cost the most obviously
that influences cost the most obviously
and
um I don't know you could probably do
um I don't know you could probably do
something with
something with
it but this is mostly
fine Emory
fine Emory
what who that
is okay
is okay
let me see if there's um there is a
let me see if there's um there is a
little Quirk that I wanted to address
little Quirk that I wanted to address
with this
with this
algorithm not going to matter as much
algorithm not going to matter as much
for the synthetic tasks I think
but yeah okay so right
but yeah okay so right
here what happens if you improve an
here what happens if you improve an
existing
existing
Point okay
Point okay
so you are
so you are
nearest Paro YT is going to be some
nearest Paro YT is going to be some
score you come up with a better score
score you come up with a better score
for the same
for the same
point the nearest Paro distance will be
zero okay
that's really
bad what if we took the point to the
bad what if we took the point to the
right
so you take the score of the nearest
so you take the score of the nearest
point to the left and then the distance
point to the left and then the distance
of the nearest point to the right does
of the nearest point to the right does
that do it
I got to figure out how to handle
I got to figure out how to handle
bounds with that but yeah yeah
well then what if there's a burrito
well then what if there's a burrito
point right next to
you we can start with this
for e
nearest parito
distance e
L
difference e
so this sets it to zero if there's
so this sets it to zero if there's
nothing to the
nothing to the
right which means you can never go to
right which means you can never go to
the right which is
bad for
I can clip it I don't know if that's
I can clip it I don't know if that's
going to
enough I guess I can explain this in the
meantime Okay so
blueprint speaking of blueprint I should
blueprint speaking of blueprint I should
take that
those look like it is increasing in uh
those look like it is increasing in uh
the score is
the score is
increasing ratings are infinite
increasing ratings are infinite
lovely we'll have to fix
lovely we'll have to fix
that interesting to know how ratings are
that interesting to know how ratings are
infinite but it seems to still be
infinite but it seems to still be
working that's a little bit disturbing
ratings are no longer
infinite got all the infinite Alpha out
infinite got all the infinite Alpha out
of
there oh yeah
okay I'm actually curious to see what
okay I'm actually curious to see what
this looks like CU this might actually
this looks like CU this might actually
be a decent run be
be a decent run be
funny that's actually one of the
funny that's actually one of the
cleanest runs
ironically it's a very nice
ironically it's a very nice
spread let me figure out why these are
spread let me figure out why these are
infinite real quick
and then we'll go through the
and then we'll go through the
algorithm where the changes
least okay
can you check if is in
oh so that's actually funny so what that
oh so that's actually funny so what that
probably did is um it just kept pushing
probably did is um it just kept pushing
it aggressively to the right and because
it aggressively to the right and because
the model happened to be good enough
the model happened to be good enough
that's why you got the very nice
that's why you got the very nice
spread heavily rewarded for going off to
spread heavily rewarded for going off to
the right so we'll keep that in mind
the right so we'll keep that in mind
so here's what uh here's the deal at the
moment you have an underline curve
moment you have an underline curve
you're trying to discover that probably
you're trying to discover that probably
looks something like this right you got
looks something like this right you got
a parito point over here you got a
a parito point over here you got a
parito point over here you got a bunch
parito point over here you got a bunch
of points you don't care about
of points you don't care about
here you have a predictive model that
here you have a predictive model that
will try to get you a good set of hyper
will try to get you a good set of hyper
parameters somewhere here so where
parameters somewhere here so where
should you
should you
sample uh so well what this is at the
sample uh so well what this is at the
moment is that you should take if you're
moment is that you should take if you're
going to try to assess how good this
going to try to assess how good this
point is and what you care about is you
point is and what you care about is you
care about this
care about this
height and this
distance both of these are nicely
distance both of these are nicely
normalized because you know this curve
normalized because you know this curve
could come to you with any scale this
could come to you with any scale this
way and any scale this way so we've
way and any scale this way so we've
normalized everything to be pretty clean
normalized everything to be pretty clean
let me just ban that
bot um and it says you should multiply
bot um and it says you should multiply
these
these
things so you take this distance so this
things so you take this distance so this
is distance so this is a this is B then
is distance so this is a this is B then
you do a *
B for
this is the graph that matters
this is the graph that matters
here let's see what this just did for us
I think this will be a good but not
I think this will be a good but not
quite as good as the uh the previous one
so okay actually that's very nice that's
so okay actually that's very nice that's
very stable it only goes out to 50 is
very stable it only goes out to 50 is
the
problem very nice graph only goes to 50
so the thing that we have to think about
so the thing that we have to think about
here is what happens if you sample why
here is what happens if you sample why
is this an
object
hello
hello all right uh what happens if you
hello all right uh what happens if you
say samp Le a point
say samp Le a point
here and what happens if you sample a
here and what happens if you sample a
point here these are the
point here these are the
two
difficulties that need to be
difficulties that need to be
addressed because then you you need to
addressed because then you you need to
somehow do this distance and you need to
somehow do this distance and you need to
somehow
do uh this
do uh this
distance right so both of these are
distance right so both of these are
problem
on e
I'm trying to think what would be the
I'm trying to think what would be the
most principled way to choose
most principled way to choose
this cuz really all we're stuck with our
this cuz really all we're stuck with our
Edge conditions and actually I think
Edge conditions and actually I think
that this probably explains why our uh
that this probably explains why our uh
our pong algorithm was bad before as
our pong algorithm was bad before as
well it kept trying to go for these
well it kept trying to go for these
really cheap runs because it was looking
really cheap runs because it was looking
at this distance and saying look you
at this distance and saying look you
know look how much uh benefit I get by
know look how much uh benefit I get by
taking this distance
do you use the mean the medium
I mean we could try some stuff
we can do me
cost for
me clost
me clost
STP then we can
STP then we can
do for
break point in here
somewhere should be able to do this I'm
somewhere should be able to do this I'm
just getting
just getting
tired let me
see less than zero is infinite
oh
something like this
probably let's see how this works and
probably let's see how this works and
then decide to clean it up or
not just take the spread of
not just take the spread of
points just to sign at the mean I think
points just to sign at the mean I think
mean's better than median robust to
clustering median could be better I
clustering median could be better I
don't
know I think the mean is
know I think the mean is
just fine oh median doesn't even make
just fine oh median doesn't even make
yeah median is more annoying to compute
yeah median is more annoying to compute
in this
case algorithm does not agree algorithm
case algorithm does not agree algorithm
says not happy
apparently we will be interested to see
why e
silly
okay that looks really
okay that looks really
good it's just pretty passive is
all I mean
can't we control that
with I don't know if we can control that
with I don't know if we can control that
with scale can
with scale can
we let me see if I just set this to like
we let me see if I just set this to like
three or something does this like change
three or something does this like change
it I don't know if it does because this
it I don't know if it does because this
is now in the scoring function that
is now in the scoring function that
we've changed things
I mean me and parito point distance
I mean me and parito point distance
seems fine to me
see we'll see if this uh this does
anything this is very clean
oh okay
that's pretty
that's pretty
solid to
100 but the scale I think has limited
100 but the scale I think has limited
has a limited effect
hold on maybe this is a good thing
hold on maybe this is a good thing
though maybe this is a good
though maybe this is a good
thing yeah wait I
thing yeah wait I
was okay I
was okay I
see I think I know what
see I think I know what
happened give me a second and then I
happened give me a second and then I
will let me just confirm that I'm right
will let me just confirm that I'm right
here
yeah okay so you were kind of getting
yeah okay so you were kind of getting
you were there was kind of like double
you were there was kind of like double
incentive to really spread the graph out
incentive to really spread the graph out
before and the
reason
here actually we will go back to the
here actually we will go back to the
[Music]
[Music]
diagram so the reason here is you get
diagram so the reason here is you get
rewarded for this distance right and you
rewarded for this distance right and you
also get rewarded for this
also get rewarded for this
distance so
distance so
the way the algorithm works right is you
the way the algorithm works right is you
sample a whole bunch of points around
sample a whole bunch of points around
the existing
the existing
points uh and you get rewarded for being
points uh and you get rewarded for being
having the prediction be better than the
having the prediction be better than the
nearest point to the left and then you
nearest point to the left and then you
get rewarded for being farther than the
get rewarded for being farther than the
nearest point to the right or whatever
nearest point to the right or whatever
so in the original algorithm uh before I
so in the original algorithm uh before I
made these
made these
changes you're incentivized to put the
changes you're incentivized to put the
point as far to the right as possible
point as far to the right as possible
both by the fact that that's probably
both by the fact that that's probably
going to get you higher score but also
going to get you higher score but also
by directly this distance uh farther to
by directly this distance uh farther to
the
the
right so
right so
now instead of just putting the
now instead of just putting the
point as far to the right as
point as far to the right as
possible me
think you're still incentivized by the
think you're still incentivized by the
cost to put the point as far to the
cost to put the point as far to the
right as possible Right
right as possible Right
but we've just made it less aggressive
but we've just made it less aggressive
because uh you get the mean distance
because uh you get the mean distance
between points instead of just getting
between points instead of just getting
the however far you're able to put it
out okay
so actually this is good because this
so actually this is good because this
means that you
means that you
are you're driving the frontier
are you're driving the frontier
exploration via uh cost Improvement not
exploration via uh cost Improvement not
via I mean via score Improvement not via
via I mean via score Improvement not via
cost
Improvement now the only difficulty here
Improvement now the only difficulty here
is still very passive
I mean this is with a crazy coefficient
I mean this is with a crazy coefficient
set
set
still not spread out the way we'd
still not spread out the way we'd
want not
quite you can't just crank up that
quite you can't just crank up that
coefficient either you can't just crank
coefficient either you can't just crank
that coefficient indefinitely
I can stick it at two I
think highest you want
but then the rest of
it an example that we
it an example that we
like like this this good
honestly this one is really
nice just so
passive why is this so
passive 3x and it goes out to 100
you don't want to 3x though it's
just e
yeah this isn't
yeah this isn't
bad
2x let's think about the knobs that we
2x let's think about the knobs that we
control
control
here because it should just be a matter
here because it should just be a matter
of tuning this thing a bit now right
we have length scale set
that's a really big length scale for a
that's a really big length scale for a
matern isn't
it this is going to make it even more
it this is going to make it even more
passive though isn't
passive though isn't
it me see
maybe
not this lung scale might need to be set
not this lung scale might need to be set
to to actually 0.1 one come to think of
it yeah the uh the length the scale
it yeah the uh the length the scale
length is crazy right
length is crazy right
now I think that makes it trust the
now I think that makes it trust the
matern Fel like hugely across the whole
matern Fel like hugely across the whole
Space not great
seems to make it uh it worse
seems to make it uh it worse
though yeah so it's less
though yeah so it's less
aggressive the matur has to fall off and
aggressive the matur has to fall off and
the linear has to take
over so this didn't help
what are the knobs can we fiddle with
I mean the ironic thing here is that
um probably if I just do this
let me see if I understand if I
let me see if I understand if I
understand this
correctly then this should be very
correctly then this should be very
effective if I understand
correctly
e
e e
interesting so hang on this
worked this was what we had from 2x
worked this was what we had from 2x
scale
scale
right I think this is in the
middle
okay
so this one ended up pretty far
out that's a crazy jump so actually wait
out that's a crazy jump so actually wait
this is not a crazy jump because it's
this is not a crazy jump because it's
allowed to like double almost right or
allowed to like double almost right or
1.4x yeah so it's allowed to go up to
1.4x yeah so it's allowed to go up to
like about that much actually it could
like about that much actually it could
go up to like 20 yeah 28 this is about
go up to like 20 yeah 28 this is about
what it's allowed to do so it's about
what it's allowed to do so it's about
the max jump
the max jump
distance
distance
um this is perfectly clean so I am happy
um this is perfectly clean so I am happy
with this
let me try something because I think I
let me try something because I think I
understand this now but I think that um
understand this now but I think that um
in order to really sell
in order to really sell
it we need to
do so this is what
do so this is what
happens at the
happens at the
extreme when you are really heavily
extreme when you are really heavily
rewarded for scaling
rewarded for scaling
to
to
uh points off to the
right it should just go up
constantly oh hey
yeah oh this is a different n y Sharm
yeah oh this is a different n y Sharm
looks like huh I know a different one
yeah that's not good news good luck but
yeah that's not good news good luck but
that's not good news right
that's not good news right
there poor
there poor
folks oh
folks oh
man raising 1.2 mil Fe is
brutal oh was
brutal oh was
I no this is Rivals right yeah yeah yeah
I no this is Rivals right yeah yeah yeah
that's just silly
okay so right here this
is yeah this is the really aggressive
is yeah this is the really aggressive
expansion
setting all right so this is actually
setting all right so this is actually
this will be very good data then so this
this will be very good data then so this
is with
is with
2X and then
2X and then
this the exact same thing just rewarding
this the exact same thing just rewarding
you way more for going off to the right
it's funny that you don't get the
it's funny that you don't get the
distribution you'd
distribution you'd
expect it does push to
expect it does push to
200 it only makes one major error
I would think that's pretty good
overall e
you could take the Max and instead of
you could take the Max and instead of
the
mean let me think about that
hey how's it
going we
going we
are working on this hyper pram sweep
algorithm It's Tricky it's going to be
algorithm It's Tricky it's going to be
really good when it's done
really good when it's done
though very very good indeed
m
it's funny how much pressure this thing
it's funny how much pressure this thing
needs
I mean I guess it makes sense
actually let me there's one thing I want
actually let me there's one thing I want
to look at
it's occurred to me that the reason that
it's occurred to me that the reason that
we need to add such
aggressive aggressive parameter so that
aggressive aggressive parameter so that
it keeps finding more expensive points
it keeps finding more expensive points
is we have two different Gan processes
is we have two different Gan processes
one of them's pulling this way and the
one of them's pulling this way and the
other's pulling this way we're pulling
other's pulling this way we're pulling
it straight back
down1 unit away contributes half as much
well I have a lot left to
well I have a lot left to
learn oh please don't uh don't mistake
learn oh please don't uh don't mistake
this for me knowing what is going on
this for me knowing what is going on
here this is not the type of stuff that
here this is not the type of stuff that
I normally do
either I just figure that regard
either I just figure that regard
regardless of the uh you know the lack
regardless of the uh you know the lack
of heavy probability and stats
of heavy probability and stats
background um I've at least seen these
background um I've at least seen these
things before and I know enough about
things before and I know enough about
how reinforcement learning is supposed
how reinforcement learning is supposed
to work to be in a here this is what I
to work to be in a here this is what I
generally how I generally look at stuff
generally how I generally look at stuff
right I might not always know what I'm
right I might not always know what I'm
doing but I'm the most qualified to
doing but I'm the most qualified to
figure it
figure it
out that's a fine place to be
I'm not the most qualified to be
I'm not the most qualified to be
specifically looking at this math but
specifically looking at this math but
overall for getting this thing working
overall for getting this thing working
in RL practically
yeah e
h
that even have fall off I don't think it
that even have fall off I don't think it
does I don't think the linear kernel has
does I don't think the linear kernel has
fall
fall
off no localized Decay yep
do we need the linear
kernel without p
colel what happens without the linear
kernel I mean where making progress It's
kernel I mean where making progress It's
a lot of two steps forward one step back
a lot of two steps forward one step back
but um the main thing from today has
but um the main thing from today has
been that all the data is very nicely
been that all the data is very nicely
normalized now so in the actual space
normalized now so in the actual space
that you're learning um this axis goes
that you're learning um this axis goes
from 0 to one this axis goes from 0 to
from 0 to one this axis goes from 0 to
one there are few other improvements
one there are few other improvements
around that it's a little harder than it
around that it's a little harder than it
would normally be just to scale your
would normally be just to scale your
data duh
and it looks like you need the linear
kernel you really shouldn't
let's see if we actually maybe we get
let's see if we actually maybe we get
something similar to the uh the original
something similar to the uh the original
plot which was which one was
it and that went to
12 only up to eight
it's very
clean but
um you can see the predictions getting
um you can see the predictions getting
pulled
down put the linear kernel back
I'm trying to think what the most
I'm trying to think what the most
principled way of doing this
principled way of doing this
is I could make it a meta hyper
is I could make it a meta hyper
perameter we're trying to avoid those if
perameter we're trying to avoid those if
we can
we can
but I see we have new YouTube people so
but I see we have new YouTube people so
here I'll go through the thing again
here I'll go through the thing again
maybe I'll figure it out in the process
maybe I'll figure it out in the process
of going through it
oops so the way this algorithm works
right this is the curve that you're
right this is the curve that you're
trying to fit this axis is cost which is
trying to fit this axis is cost which is
how long it takes the r the experiment
how long it takes the r the experiment
to run this axis is
to run this axis is
score this is how well your experiment
score this is how well your experiment
does this is the Paro front this is the
does this is the Paro front this is the
set of like a best experiments in a
set of like a best experiments in a
sense where you can't make the
sense where you can't make the
experiment any faster and also better
experiment any faster and also better
so let's say that you have two existing
so let's say that you have two existing
experiments like this these are optimal
experiments like this these are optimal
experiments maybe you have some others
experiments maybe you have some others
over here that we don't care about the
over here that we don't care about the
way they algorithm works is you generate
way they algorithm works is you generate
a bunch of candidate points to score in
a bunch of candidate points to score in
here and then you uh you score them as
here and then you uh you score them as
follows for a candidate here you're
follows for a candidate here you're
going to score it by
multiplying this distance
multiplying this distance
a
a
by this distance B
and the idea there is that you
and the idea there is that you
incentivized to uh improve the score
incentivized to uh improve the score
over the nearest optimal point and then
over the nearest optimal point and then
you're incentivized to spread them out
you're incentivized to spread them out
so that you don't put a point near an
so that you don't put a point near an
existing optimal
existing optimal
Point uh the problem is when you have to
Point uh the problem is when you have to
score a point here or here right then
score a point here or here right then
you have this distance and you have this
you have this distance and you have this
distance uh so figuring out what to use
distance uh so figuring out what to use
there is
difficult and that's what we're trying
difficult and that's what we're trying
to figure
out so I have some ideas for the one on
out so I have some ideas for the one on
the right that I've been trying what
the right that I've been trying what
about the one on the left maybe I should
about the one on the left maybe I should
think about that one maybe that'll give
think about that one maybe that'll give
me some
Clues so for this one we want the cost
Clues so for this one we want the cost
difference
the difference in
the difference in
cost nice pdb
logo
what or do I have a pdb logo
h
well maybe this gives me some Clues
well maybe this gives me some Clues
because you definitely can't use the Max
because you definitely can't use the Max
cost difference
cost difference
right the
puffer it is just the shell prompt
puffer it is just the shell prompt
yeah we just use when you have uh it
yeah we just use when you have uh it
tells you that you're in the container
tells you that you're in the container
so if you download puffer tank puffer
so if you download puffer tank puffer
tank comes with a puffer is the prompt
tank comes with a puffer is the prompt
you can obviously change it but that's
you can obviously change it but that's
what we use Puffer tank comes fully
what we use Puffer tank comes fully
loaded with my editor setup and with the
puffer okay you know this is kind of
puffer okay you know this is kind of
informative
informative
because if you just keep assuming that
because if you just keep assuming that
you're going to use like the maximum
you're going to use like the maximum
difference or some large value you're
difference or some large value you're
going to keep trying to put points here
going to keep trying to put points here
you know you're going to keep trying to
you know you're going to keep trying to
put points over here even if they are
put points over here even if they are
know very close
however cost is normalized between Zer
however cost is normalized between Zer
and one isn't
it cost will go to
it cost will go to
zero at the
minimum so
I can just have that one be
zero I think I solve that one on the
zero I think I solve that one on the
left I should just be able to have that
left I should just be able to have that
one be zero score is normalized cost is
one be zero score is normalized cost is
normalized so the one on the left should
normalized so the one on the left should
be able to just go to
zero that's not
zero that's not
bad but hold on I don't think I do this
bad but hold on I don't think I do this
score in normalized space
GP
GP
YT Pito
YT YT
is so I would have to do this in YT Norm
space and then the distance
space and then the distance
I think the distance is done
in standard cost
space if I were to do both of these in
space if I were to do both of these in
Norm space which would require me to
Norm space which would require me to
rescale some things but I think I
rescale some things but I think I
probably
probably
should that would have some nice
should that would have some nice
interpretations
the maximum possible Square would be one
the maximum possible Square would be one
because the maximum difference on this
because the maximum difference on this
axis will be one and the maximum
axis will be one and the maximum
difference on this axis will be
one that would be
good and then I could use
I could just use
I could just use
one as the
one as the
distance that probably
works I want to try that that sounds
works I want to try that that sounds
very
very
good I think that that yeah I think this
good I think that that yeah I think this
is the
is the
way
okay so
first thing we will need to
do PYT
here is
pito
pito
okay nearest Pito
this one's a a little
this one's a a little
annoying but I should just be able to
annoying but I should just be able to
do see
do see
right
reto log C Norm
GP log C
norm and then we
norm and then we
do equal to
1us
1us
GP
nor let just make sure this works
you could also just set it to one
if this works this will be very
nice um that should not be should be a
nice um that should not be should be a
different
different
shape I guess it's fine yeah
oh it's a tensor
actually let's just do one for
actually let's just do one for
now think that'll be the
simplest actually hold on no it does
simplest actually hold on no it does
need to be one minus otherwise it
need to be one minus otherwise it
doesn't make
doesn't make
sense we have to finish the full
sense we have to finish the full
implementation then we'll be able to see
implementation then we'll be able to see
if it's good
this is gross but they should
run suggestion scores
hey
hey
welcome seriously how's this still a
welcome seriously how's this still a
problem
problem
uh 372
uh 372
see right fre to log
see right fre to log
c
c where's the other
c where's the other
one right here
we'll see if this
we'll see if this
works and if so I will go through
works and if so I will go through
it okay cool so what I did
it okay cool so what I did
here uh is I moved the scoring function
here uh is I moved the scoring function
so what happens here is Right internally
so what happens here is Right internally
uh this data comes into us in whatever
uh this data comes into us in whatever
format it comes in and then we turn it
format it comes in and then we turn it
into zero to one so this will be one one
into zero to one so this will be one one
and zero both of these
and zero both of these
axes um but I was still doing the
axes um but I was still doing the
scoring function in the original space
scoring function in the original space
so now if I do the scoring function in
so now if I do the scoring function in
the in the latent space first of all
the in the latent space first of all
it's a 0o to one function or I guess
it's a 0o to one function or I guess
negative 1 to one if you m if you mess
negative 1 to one if you m if you mess
up so it's nicely
up so it's nicely
bounded and on top of
bounded and on top of
that
that
we uh I think the boun problem gets
we uh I think the boun problem gets
fixed for us because see if this is at
fixed for us because see if this is at
zero the issue that we were having is we
zero the issue that we were having is we
didn't know how to score this point
didn't know how to score this point
because usually it's based on the point
because usually it's based on the point
to the left right normally you would if
to the left right normally you would if
you're looking at this point you would
you're looking at this point you would
go to the one to the left and look at
go to the one to the left and look at
this distance here so there's no point
this distance here so there's no point
to the left to look at but since it's
to the left to look at but since it's
normed to zero and you can actually go
normed to zero and you can actually go
all the way to zero uh we just get to
all the way to zero uh we just get to
use the this distance here which
use the this distance here which
actually I think I forgot to do in this
actually I think I forgot to do in this
update so I will fix that
update so I will fix that
um and then the one here uh this one is
um and then the one here uh this one is
going to be slightly more complex but if
going to be slightly more complex but if
you put a point here and this is at X
you put a point here and this is at X
then it's just one minus
then it's just one minus
X right so it's just this distance cut
X right so it's just this distance cut
off at
off at
one because we know the axis goes to
one because we know the axis goes to
one that's quite
good now where is the mean oh we have to
good now where is the mean oh we have to
rescale everything though to do this
rescale everything though to do this
which is a little
which is a little
annoying so we have to we have a little
annoying so we have to we have a little
bit of work to do
here
oops so
oops so
zero
zero
Z zero
okay run it again just to make sure it
okay run it again just to make sure it
doesn't fix and then
um from there we can actually figure
um from there we can actually figure
some stuff
out is very very
out is very very
good I can tell we're getting very close
good I can tell we're getting very close
to having this thing done it's just it's
to having this thing done it's just it's
going to be I mean this is a a
going to be I mean this is a a
sizable project this investment I think
sizable project this investment I think
this will pay
off
e e
all right what does
all right what does
this what's this look like obviously
this what's this look like obviously
it's not a full
curve
interesting uh
huh the predictions are not
huh the predictions are not
bad yeah no the predictions are quite
bad yeah no the predictions are quite
accurate
accurate
right yeah these are the early ones you
right yeah these are the early ones you
can ignore the blue ones these
can ignore the blue ones these
predictions are quite
predictions are quite
accurate oh uh the red dots are
accurate oh uh the red dots are
clustered up you can kind of see it
right let me make sure that's
correct uh they looked like they were
correct uh they looked like they were
clustered up hold
clustered up hold
on clustered one yeah one two 3 4 see
this so this should not be allowed to
happen this should give you very very
happen this should give you very very
low
low
score so that means we have a
bug suppos is better than the thing
bug suppos is better than the thing
being implemented correctly and not
being implemented correctly and not
working
h
e
e e
you have your
differences nearest Paro distance
oh hold
oh hold
on let me see
something it put this one then this one
something it put this one then this one
then this one then this
one and earlier on it
did this one then this one
that shouldn't happen there is a check
that shouldn't happen there is a check
on that
it is very difficult to take care of
it is very difficult to take care of
scaling though
yeah because you
yeah because you
can't the problem is that no matter how
can't the problem is that no matter how
you scale it there's always going to be
you scale it there's always going to be
weird stuff in lat
space so the only thing I can the only
space so the only thing I can the only
thing I can really do
cost is in log space as well
right you kind of want it in linearized
right you kind of want it in linearized
log space
let's do
let's do
that so we'll leave the C alone I think
that so we'll leave the C alone I think
that we got the
that we got the
cost I think what we screwed up for
score we want Pito C for
okay so we do
okay so we do
this and then we do
this and then we do
Pito
Pito
C I have Norm did I already do
C I have Norm did I already do
that I think
so and then this is
GPC when we have
GP log C GP log C
nor
nor
GPC okay so now this is
01 right
now we do Pito C
now we do Pito C
Norm minus
Norm minus
GPC
norm and then I think we do
abs
abs and then this will always work
abs and then this will always work
so we can just do nearest Pito
distance
men we will see if this
works I'm use rest real quick be right
back
e
e
e e
well that's
well that's
uh that's a result
um well it magically works it makes a
um well it magically works it makes a
couple mistakes though
magically works but makes a couple
mistakes which
are is that easily fixable
I think that's easily
fixable
fixable
yeah that
yeah that
is easily
is easily
fixable
fixable
okay we figured out how to do
okay we figured out how to do
that
that
um where do we put the clipping on
suggestions
suggestions
clip GP
cost
cost
oh that's kind of
oh that's kind of
awkward hang
on we do clip the
on we do clip the
suggestions but then it overestimates
why would it do such a
thing it's got nothing better to
do
look what you
look what you
doing trying to fix a hyper parameter
doing trying to fix a hyper parameter
sweep
sweep
algorithm this would be a major
algorithm this would be a major
contribution across the whole whole
contribution across the whole whole
stuff a whole set of RL things that
stuff a whole set of RL things that
we're
we're
doing if I can get this thing to work it
doing if I can get this thing to work it
depends how much better it works than
depends how much better it works than
the originals but if I get this thing
the originals but if I get this thing
working substantially better than carbs
working substantially better than carbs
this will be a major major win for the
field that's cool
field that's cool
if you type too many things or you put
if you type too many things or you put
links or stuff sometimes YouTube will
links or stuff sometimes YouTube will
eat
eat
them I don't have it set up to do that
them I don't have it set up to do that
it just does
it so the only thing I I have questions
it so the only thing I I have questions
on why are there so many points right at
on why are there so many points right at
the end here right
can't do anything over here over
here it's probably the exponential score
here it's probably the exponential score
rating
right we have to be
0.04 yeah it's got to be
that the score differences get
that the score differences get
accentuated
dramatically that's actually kind of a
dramatically that's actually kind of a
tough one to fix
tough one to fix
let me try something real quick just to
test Rani
okay this is
something oh wait wait the initial curve
something oh wait wait the initial curve
on this
on this
is initial curve on this is really good
some of the predictions are a bit
some of the predictions are a bit
off let me
see if nothing else this will show us
see if nothing else this will show us
that we
that we
uh the last piece to look at is really
uh the last piece to look at is really
looking at the score Norm
still doing it
Arizona is a perfectly fine
Arizona is a perfectly fine
state had some friends from
there that's pretty
there that's pretty
good now it's like way over sampled
good now it's like way over sampled
right here right yeah so it's way over
right here right yeah so it's way over
sampled this
sampled this
thing three four five but that's not
thing three four five but that's not
terrible that's not
terrible it's quite
clean less than a quarter of the compute
clean less than a quarter of the compute
spent
should be like half shouldn't
it and that was pretty darn aggressive
it and that was pretty darn aggressive
how it did that me go look at the auto
Fram oh it's not
Fram oh it's not
H let me look at some of these
H let me look at some of these
jumps 26 to 34
jumps 26 to 34
51 to 6
4 yeah these jumps are all within the
4 yeah these jumps are all within the
allowed
range
interesting I almost want to make it
interesting I almost want to make it
jump slower
jump slower
here now that we have this
and then W to play with that scaling
Factor try
this just to see
this might be too
passive could work
good Twitter day for RL I
guess
guess
6908 very nice
uh yeah so this is too
uh yeah so this is too
slow it's kind of funny that literally
slow it's kind of funny that literally
that's all I changes this one scale
that's all I changes this one scale
factor right it's all that changes the
factor right it's all that changes the
one scale factor and it's really really
one scale factor and it's really really
cripples
it
it
okay so uh this is our
chart what do we do about the
what do we do about the score
I mean any way you look at this this is
I mean any way you look at this this is
too
too
aggressive you should not spend so much
aggressive you should not spend so much
of your compute on these long
of your compute on these long
experiments I mean I it's fine here I
experiments I mean I it's fine here I
suppose but
suppose but
um and this is why we'll need the real
um and this is why we'll need the real
benchmarks I think what's going to
benchmarks I think what's going to
happen in a real end where it's harder
happen in a real end where it's harder
to model the performance is that this is
to model the performance is that this is
going to push it to expensive
going to push it to expensive
experiments too quickly
so why does it do this
it thinks that it's going to
it thinks that it's going to
be getting like 10%
higher so this is Max four
prediction and this is like
prediction and this is like
0.1 because it's a 10% increase
0.1 because it's a 10% increase
so yeah 0.1.0 yeah that tracks okay so
so yeah 0.1.0 yeah that tracks okay so
that's
screwy does it find anything better than
screwy does it find anything better than
this
this
after doesn't really find very many
after doesn't really find very many
things better than this as
well this one is .13 yeah
well this one is .13 yeah
okay um
do we have to cap this cost
prediction get rid of that
how do we cap the clost prediction
no you can't cap it it's a
prediction okay that's an
prediction okay that's an
issue that is an
issue hold on shouldn't this be
zero this work
let
see yeah and we can't even cut it off
see yeah and we can't even cut it off
that's yeah that's obnoxious okay
that's yeah that's obnoxious okay
0 to one normed
how's it over predicting cost in the
how's it over predicting cost in the
first
place bad
modeling you're taking the most wrong of
modeling you're taking the most wrong of
a lot of the predictions doing this
yeah that's a that's like that is a
problem well is
it yeah because you should go back and
it yeah because you should go back and
run
shouldn't go back and run more
shouldn't go back and run more
experiments you should be filling in as
experiments you should be filling in as
you go
H hard to
say the problem I'm dealing with at the
say the problem I'm dealing with at the
moment is you don't know the maximum
moment is you don't know the maximum
cost and you're measured by distance to
cost and you're measured by distance to
the nearest cost
so if you just have a wrong cost
so if you just have a wrong cost
prediction you're going to
overshoot that's
tricky who works on Valentine's Day
tricky who works on Valentine's Day
people trying to get [ __ ]
done who watches random Dev streams on
done who watches random Dev streams on
Valentine's Day just to make stupid
Valentine's Day just to make stupid
comments
yeah but you're not making stupid
yeah but you're not making stupid
comments is the thing plasm
plasma this is a tough
plasma this is a tough
one this is just a boundary uh a
one this is just a boundary uh a
boundary problem but I'm not quite sure
boundary problem but I'm not quite sure
how to deal with it
how to deal with it
because there's a really no way to know
because there's a really no way to know
the maximum
the maximum
cost um based on your parameters there's
cost um based on your parameters there's
no way to know
no way to know
that and if the model just predicts over
that and if the model just predicts over
the Max
cost I mean technically it should get
cost I mean technically it should get
better over time like you can
better over time like you can
see 230 216 210 209 like it will
see 230 216 210 209 like it will
eventually correct itself cuz the model
eventually correct itself cuz the model
will get better maybe it's fine there
will get better maybe it's fine there
what if I run this thing for longer what
what if I run this thing for longer what
happens if you do like a
100 prepping for
interviews yeah that's a rough
time it should get better over time
time it should get better over time
because um well there are more data
because um well there are more data
points to
points to
fit it will fit if it's going to fill in
fit it will fit if it's going to fill in
the boundary then that should fix the
the boundary then that should fix the
model at the boundary and then it should
model at the boundary and then it should
explore other regions and then the only
explore other regions and then the only
thing I need to look at then is the
thing I need to look at then is the
score normalization
score normalization
function so we'll run this we'll see if
function so we'll run this we'll see if
I am correct on that and then we'll look
I am correct on that and then we'll look
at the score normalization
at the score normalization
function I think that's the only really
function I think that's the only really
questionable choice
questionable choice
left
right yeah that should be the only
right yeah that should be the only
really questionable choice
left was there a reason I decided to
left was there a reason I decided to
predict log cost
as well instead just
cost let me think about
that I mean that could be that could be
that I mean that could be that could be
varied
yeah there are lots of small things to
yeah there are lots of small things to
tweak still I think the main one that
tweak still I think the main one that
like really the main one we really need
like really the main one we really need
to look at though should be the score
transform okay so by
transform okay so by
now yeah so here you can see right we
now yeah so here you can see right we
did the 200 it went over 200 but now
did the 200 it went over 200 but now
we're getting all sorts of other
we're getting all sorts of other
points it's gone
back and it's got an accurate model okay
back and it's got an accurate model okay
this is perfect this is exactly what we
this is perfect this is exactly what we
want so that problem is just a that's a
want so that problem is just a that's a
very temporary problem the thing that we
very temporary problem the thing that we
ran
ran
into it'll probably drop a few points at
into it'll probably drop a few points at
Max cost if it gets there but then
Max cost if it gets there but then
they'll go back so this is uh this is
they'll go back so this is uh this is
behaving the way that we want it to this
behaving the way that we want it to this
is generally
is generally
good this is probably enough to even
good this is probably enough to even
start doing some real experiments though
start doing some real experiments though
we might want to try it on a few more of
we might want to try it on a few more of
the synthetic tasks
first uh the only one it shouldn't do
first uh the only one it shouldn't do
too well on is I think the percentile
too well on is I think the percentile
task because we messed with the
Epsilon okay
Epsilon okay
so here oh that's
so here oh that's
beautiful
beautiful
holy yeah that's beautiful look at
holy yeah that's beautiful look at
that so the red points come later right
that so the red points come later right
so it filled this in and then it went
so it filled this in and then it went
back substantially into the curve we
back substantially into the curve we
don't really care about the really early
don't really care about the really early
portions of the curve but look at this
portions of the curve but look at this
it filled back in isn't that nice
yeah colors iteration
yeah colors iteration
Index this is the one thing that Neptune
Index this is the one thing that Neptune
doesn't have that I really wish they had
doesn't have that I really wish they had
um it gives you it kind of gives you a
um it gives you it kind of gives you a
third
third
access right this gives you a time AIS
that's like
perfect and so we should be very happy
perfect and so we should be very happy
with
with
this uh do I try this on the percentile
task okay I'm not going to have super
task okay I'm not going to have super
high hopes for the percentile task
high hopes for the percentile task
because of the normalization we're using
because of the normalization we're using
currently
currently
but we will check it
[Music]
is it five
error while Computing log
prob really
y over Max
4 think that might be
4 think that might be
numerical but you have the Epsilon
term me see
you have
you have
y divide by Max 4 really that doesn't
y divide by Max 4 really that doesn't
make sense to
me I accounted for that so something's
weird why is there so much random
garbage on the darn
timeline yes use China's version of x x
timeline yes use China's version of x x
but CCP lovely let's not
no we will not ever do that thank you
no we will not ever do that thank you
I have not once used Tik Tok and I'm not
I have not once used Tik Tok and I'm not
going to
start chamber of low
B I swear short form content causes ADHD
B I swear short form content causes ADHD
it's [ __ ] awful for
you it's like m
you it's like m
I know it'll make me feel better 3 hours
I know it'll make me feel better 3 hours
of scrolling short form content said no
of scrolling short form content said no
one
ever how is this thing
having error Computing log
prob
what n
Jesus I've definitely done longer gaming
Jesus I've definitely done longer gaming
sessions than that but not while
sessions than that but not while
scrolling garbage
I tried to limit that lately though got
I tried to limit that lately though got
a company to
build you got to field this
off well I've definitely done 24 plus
off well I've definitely done 24 plus
there's been some absolutely djun gaming
I don't even remember that was from when
I don't even remember that was from when
I was way younger I've definitely put
I was way younger I've definitely put
like ridiculously long sessions into a
like ridiculously long sessions into a
couple different MMOs
couple different MMOs
though to be fair I got a PhD thesis out
though to be fair I got a PhD thesis out
of
of
MMOs n mostly old school RuneScape
MMOs n mostly old school RuneScape
couple others that are less commonly
known yeah I mean the main thing that my
known yeah I mean the main thing that my
work was known for originally this is
work was known for originally this is
the latest version of it this is uh an
the latest version of it this is uh an
ultra high
ultra high
performance neural EG an ultra high
performance neural EG an ultra high
performance MMO written for
performance MMO written for
reinforcement learning
research
research
oops wrong
button this thing runs at like I don't
button this thing runs at like I don't
know ,000 times real
know ,000 times real
time one of the most complex RL
time one of the most complex RL
environments out
there and a lot of it is taken a lot of
there and a lot of it is taken a lot of
the design and stuff is taken directly
the design and stuff is taken directly
from my knowledge of the internals of
from my knowledge of the internals of
how MMOs are built just from playing
how MMOs are built just from playing
them for so
them for so
long see you
jez okay so YT does have a nan here
that's not supposed to be
that's not supposed to be
possible
possible
um how did that happen
let
say or and cost
somehow it's getting us4 greater than
somehow it's getting us4 greater than
one
uh okay that's
weird so it doesn't actually get to
weird so it doesn't actually get to
there but somehow we have a
there but somehow we have a
score is
not a 1.22 that's not possible at all
output
see self suggestion output score cost is
see self suggestion output score cost is
cost okay
if
cost score greater than one breako right
how does this thing get into
this
e e
if these backwards or something
if these backwards or something
absolutely
insane
insane
score
score
cost score is
cost score is
score cost is
cost oh I'm stupid
my
bad just getting
bad just getting
tired we'll be
good e
hey boss I got this new
hey boss I got this new
what damn it Ryan get out of here
I'm not going to give you neoc carbs
I'm not going to give you neoc carbs
access
early that
case do you know how many [ __ ] DMs I
case do you know how many [ __ ] DMs I
have look let me just show you how
have look let me just show you how
stupid this
stupid this
is this is almost all of this is meme
coin it's all meme coin and sex bots
coin it's all meme coin and sex bots
it's God awful
and it's like I occasionally get client
and it's like I occasionally get client
inquiries through there so it's like
inquiries through there so it's like
that really shouldn't be
spammed can
spammed can
I you know what they should
I you know what they should
do I would just like I would like legal
do I would just like I would like legal
protections against uh against cyber
protections against uh against cyber
attack to be stripped from spammers so I
attack to be stripped from spammers so I
think that legally if somebody spams you
think that legally if somebody spams you
you should be able to Dos them or like I
you should be able to Dos them or like I
don't know try to like just screw with
don't know try to like just screw with
them somehow that's what you should be
them somehow that's what you should be
able to
do I should be able to like you know to
do I should be able to like you know to
set their keyboard to dvorac or
set their keyboard to dvorac or
something and delete the settings files
something and delete the settings files
from their OS for other like layouts I
from their OS for other like layouts I
should just be able to do dumb [ __ ]
what are you working on today neoc carbs
what are you working on today neoc carbs
or well name in
or well name in
progress uh this is getting to be very
progress uh this is getting to be very
good at least on the synthetic tasks we
good at least on the synthetic tasks we
have to run a lot of experiments on it
have to run a lot of experiments on it
but I think this is going to be really
but I think this is going to be really
good it's based on
good it's based on
um it's based on two quantities at the
um it's based on two quantities at the
moment which is your expected
moment which is your expected
performance improvement over the nearest
performance improvement over the nearest
Paro point and then it's also based on a
Paro point and then it's also based on a
distance and cost Bas so distance from
distance and cost Bas so distance from
nearest Paro Point neoc
nearest Paro Point neoc
carbs hyper cram sweep we're doing uh
carbs hyper cram sweep we're doing uh
we're going to try to improve carbs by a
we're going to try to improve carbs by a
lot I've been working on this a while
yeah is
that it doesn't yet to be fair I I don't
that it doesn't yet to be fair I I don't
know if I want to call it neoc carbs or
know if I want to call it neoc carbs or
not we barely use anything from carbs so
not we barely use anything from carbs so
like you know
find a way to call it
find a way to call it
protein that'd be funny
it's
I don't know if I want to have some
I don't know if I want to have some
puffer adjacent thing with
that we'll
that we'll
see but it's quite
good 017
I don't understand how this
is o22
hypers okay that's more reasonable so
hypers okay that's more reasonable so
this says
88 so that's that looks correct but then
88 so that's that looks correct but then
what the heck does this do
1.22
huh oh you're dumb that's why
huh oh you're dumb that's why
reason is you're
done love it when that's the reason
spam running baselines for syllabus.
spam running baselines for syllabus.
tune typers for a few methods bunch of
tune typers for a few methods bunch of
environments and starting point for
environments and starting point for
people yep that is very
good puffers at the
Blackboard they're schooling
Blackboard they're schooling
oh yeah speaking of schooling I was
oh yeah speaking of schooling I was
thinking of building a high performance
thinking of building a high performance
puffer fish swimming simulator and then
puffer fish swimming simulator and then
trying to use reinforcement learning to
trying to use reinforcement learning to
see if we could get them to school does
see if we could get them to school does
that sound like a fun and completely
that sound like a fun and completely
novel project that you'd want to be
novel project that you'd want to be
involved
in we'll make sure to simulate fin tip
in we'll make sure to simulate fin tip
fores
yeah we should definitely do that in C++
yeah we should definitely do that in C++
that sounds great we should just choose
that sounds great we should just choose
the worst language out
the worst language out
there other than Java
there other than Java
maybe I might actually prefer to write
maybe I might actually prefer to write
Java than C++ like gez it's a tough call
Java than C++ like gez it's a tough call
between those two
I think submitting PRS in either of
I think submitting PRS in either of
those gets you [ __ ] slapped back to
those gets you [ __ ] slapped back to
programming boot
camp the zig people are kind of okay
camp the zig people are kind of okay
like okay yeah you got a new trendy
like okay yeah you got a new trendy
language that's fine I just don't want
language that's fine I just don't want
to deal with
it people made like it's from what I've
it people made like it's from what I've
seen it looks like a lot closer to what
seen it looks like a lot closer to what
C++ should have actually been
rust no
rust no
Julia not really Mojo absolutely
not C is really nice though you should
not C is really nice though you should
come write some
C it's just good
I don't want to write any more
I don't want to write any more
environments I haven't tried writing him
environments I haven't tried writing him
in C yet it's actually really
chill you basically you just do fast
chill you basically you just do fast
Game Dev
you just do fast Game
Dev I would like to know why this is so
Dev I would like to know why this is so
bunched up
here oh it doesn't suck it's pretty nice
here oh it doesn't suck it's pretty nice
have you seen the new neural MMO 3 code
I mean this thing is like way better
I mean this thing is like way better
render quality thousand times faster
render quality thousand times faster
fancier UI and
everything and all the
everything and all the
code is right
here that's the whole code it's a
here that's the whole code it's a
fraction of the length of neural mmo2
fraction of the length of neural mmo2
and this is all brain dead as well
and this is all brain dead as well
there's nothing in here that a first
there's nothing in here that a first
year CS undergrad won't understand after
year CS undergrad won't understand after
taking their first systems
taking their first systems
course there are no double
course there are no double
pointers I think there's like one
pointers I think there's like one
Dynamic allocation for the maps being
Dynamic allocation for the maps being
too big but other than that no dynamic
too big but other than that no dynamic
memory
memory
allocations by which I mean after you
allocations by which I mean after you
call a it no Dynamic allocation
no
no
macros just conditionals and Loops ifs
macros just conditionals and Loops ifs
and
and
Loops that's all you
do honestly the hardest part of this
do honestly the hardest part of this
whole thing was figuring out um how to
whole thing was figuring out um how to
get the bloody uh the tiles to look nice
get the bloody uh the tiles to look nice
like the tiling code not to look like
like the tiling code not to look like
Minecraft interpolating and like
Minecraft interpolating and like
snapping tiles and stuff for the
snapping tiles and stuff for the
renderer was the most annoying
thing
thing
Baseline yeah neur 2 is a much more
Baseline yeah neur 2 is a much more
complicated and difficult to work with
complicated and difficult to work with
project should just run some baselines
project should just run some baselines
on this
on this
thing I mean this thing is
thing I mean this thing is
solid we have policies that train for
solid we have policies that train for
this at 500k steps per second as well
this at 500k steps per second as well
like million parameter
policies there you go look at that
policies there you go look at that
oh Dodges Dodges picks up the tool picks
oh Dodges Dodges picks up the tool picks
up the bow doesn't realize that level
up the bow doesn't realize that level
seven is too high to fight back on low
seven is too high to fight back on low
HP but that's pretty decent you just saw
HP but that's pretty decent you just saw
that right it just executed multiple
that right it just executed multiple
Dodges picked up a tool picked up a
Dodges picked up a tool picked up a
weapon swapped to the weapon didn't
weapon swapped to the weapon didn't
realize though that it was too weak to
realize though that it was too weak to
beat the level
seven
seven
Dodge
Dodge
Dodge does doesn't realize that this guy
Dodge does doesn't realize that this guy
has
has
ranged doesn't realize that the really
ranged doesn't realize that the really
high levels have
high levels have
range okay gets the level one picks up
range okay gets the level one picks up
tool equips
tool equips
tool
collects a bunch of
stuff
stuff
kills does a no to equip the armor y
kills does a no to equip the armor y
it's got the weapon and it's equipped
it's got the weapon and it's equipped
it doesn't equip the boots it's got the
it doesn't equip the boots it's got the
helmet on it's got the chest plate on
helmet on it's got the chest plate on
it's got
this what happens if you train way
this what happens if you train way
longer uh this has played 1500 years
longer uh this has played 1500 years
worth of games though I really didn't
worth of games though I really didn't
tune the hyper parameters of the
tune the hyper parameters of the
architecture or the rewards much
architecture or the rewards much
so I think we can do lots better but it
so I think we can do lots better but it
only takes it this is like three days of
only takes it this is like three days of
training on one
GPU it does some pretty sophisticated
GPU it does some pretty sophisticated
stuff it's not perfect like you can see
stuff it's not perfect like you can see
they clear gaps but like there very well
they clear gaps but like there very well
could be just stuff you can't learn from
could be just stuff you can't learn from
the current observations in there right
the current observations in there right
like you need to rorm the observations
like you need to rorm the observations
so yeah I love this project um and
so yeah I love this project um and
eventually you know there will probably
eventually you know there will probably
be successors to this as well or
be successors to this as well or
expansions or whatnot like this will
expansions or whatnot like this will
continue
continue
eventually I got to build a successful
eventually I got to build a successful
company first
yeah but come on this is pretty cool
yeah but come on this is pretty cool
right like I built like a mini MMO over
right like I built like a mini MMO over
a few months and now it's like the most
a few months and now it's like the most
complex probably the most complex fast
complex probably the most complex fast
environment out there I don't think that
environment out there I don't think that
there's anything that is both faster and
there's anything that is both faster and
more complex than
this honestly the rendering was the only
this honestly the rendering was the only
shitty part the logic is pretty
shitty part the logic is pretty
nice yeah right and C is really cozy
well you can try this out
well you can try this out
then cuz it's pretty
then cuz it's pretty
fun there's uh there's Tech in this as
well let's take over okay I'm going to
well let's take over okay I'm going to
reset real
reset real
quick okay now I'm G to play this so now
quick okay now I'm G to play this so now
this is me playing it
let me see if I can show you that
let me see if I can show you that
there's some tech in
here don't you hit me
let me see if I'm good enough to do the
tech there are a few different ones
tech there are a few different ones
actually oh this guy is
perfect yeah you can
perfect yeah you can
strafe if you're good
I get the level seven let's
see yeah so there's Tech uh there's
see yeah so there's Tech uh there's
technically I think that there's a tech
technically I think that there's a tech
with the sword as well because it hits
with the sword as well because it hits
in uh in like three squares in front of
in uh in like three squares in front of
you so I think there's a corner Tech I
you so I think there's a corner Tech I
think there's like a uh there's like an
think there's like a uh there's like an
enemy pathing Tech like there are lots
enemy pathing Tech like there are lots
of things that you can do in here that
of things that you can do in here that
are pretty cool that would be it would
are pretty cool that would be it would
be awesome if the Bots learned to do um
be awesome if the Bots learned to do um
yeah I miss hitting lots of buttons man
yeah I miss hitting lots of buttons man
I've been playing OverWatch I don't know
I've been playing OverWatch I don't know
what's wrong with me and then I did that
what's wrong with me and then I did that
and then they actually they're launching
and then they actually they're launching
the biggest update to that game they've
the biggest update to that game they've
ever done next
week I keep my hitting lots of Buttons
week I keep my hitting lots of Buttons
game is RuneScape so I'm not allowed to
game is RuneScape so I'm not allowed to
do that because that's that's actually
heroin that update looks awful you
heroin that update looks awful you
kidding me dude it looks awesome
kidding me dude it looks awesome
loadouts for everything looks
great bounce is going to be so bad I
great bounce is going to be so bad I
don't understand balance I understand
don't understand balance I understand
swing
swing
Hammer okay
Hammer okay
I understand swing Hammer
good I've hit silver All
Rolls Ash one shot
can't one shot him if you're pinned all
right and also it's silver they can't
right and also it's silver they can't
hit
anything it's weird how it's like there
anything it's weird how it's like there
points over
points over
here there's no point points over here
here there's no point points over here
there there no red points in this
region I was there for a week yeah yeah
region I was there for a week yeah yeah
you and your cracked out
aim okay sometimes I miss the freaking
aim okay sometimes I miss the freaking
Hammer swings and then I have to go play
Winton wish I knew why this this was
Winton wish I knew why this this was
doing
doing
this I guess I can tune the exponential
do five
here
here
hemmer yeah Ryan is good it's annoying
hemmer yeah Ryan is good it's annoying
as hell on tank though because you can't
as hell on tank though because you can't
you can't just play one thing every game
you can't just play one thing every game
like other roles there are like you can
like other roles there are like you can
just play the same thing every game and
just play the same thing every game and
be
be
fine it's annoying
yeah oh it's going to cause tons of
yeah oh it's going to cause tons of
issues but it's still going to be
fun I think the two I haven't figured
fun I think the two I haven't figured
out are
out are
freaking well I have mostly figured out
freaking well I have mostly figured out
but it's like I've only figured it out
but it's like I've only figured it out
because they're bad I think if somebody
because they're bad I think if somebody
actually knows what they're doing on
actually knows what they're doing on
ratra or malga I don't know what to
do so
ridiculous all right this is doing
work re versus Ryan
it's not that bad yet because they they
it's not that bad yet because they they
are not aggressive enough and um they
are not aggressive enough and um they
don't understand that they're dead once
don't understand that they're dead once
they're out of
Nemesis but if as soon as they figure
Nemesis but if as soon as they figure
that
out what the heck is wrong with these
out what the heck is wrong with these
cost
cost
estimates why is the model just like
estimates why is the model just like
suddenly
suddenly
insane that's
insane that's
crazy I guess it's this Epsilon
term it's Perma stock
uh
uh
that's
that's
uh and that's
uh and that's
weird it shouldn't even be able to do
that 20us 2 is
.99 I think that
doesn't I might leave it at 1 E minus 2
doesn't I might leave it at 1 E minus 2
for
now it's
5:30 we're going to start to clean this
5:30 we're going to start to clean this
up and then we're going to be able to
up and then we're going to be able to
run some uh some experiments on
run some uh some experiments on
this this has been pretty good
I
wonder I kind of want to check on the
logs I don't want it to obsess over the
logs I don't want it to obsess over the
high range of the cost is the only
high range of the cost is the only
thing see you good luck and the only
thing see you good luck and the only
thing here is I don't want it to obsess
thing here is I don't want it to obsess
over
over
the high end of cost
here it definitely obsesses over
it I mean I can do this but I think this
it I mean I can do this but I think this
is going to start to screw up the
is going to start to screw up the
results
right so this is a little let me explain
right so this is a little let me explain
what's going on here um I did this thing
what's going on here um I did this thing
where I exponentially
where I exponentially
scale the score so as you cut the
scale the score so as you cut the
distance to the uh to Max score and a
distance to the uh to Max score and a
half you double
half you double
your you double your reward in the
your you double your reward in the
latent space
latent space
basically uh this gets unstable towards
basically uh this gets unstable towards
the high end but also you kind of need
the high end but also you kind of need
to have those like really big jumps at
to have those like really big jumps at
the top because let's say that your your
the top because let's say that your your
thing is Win rate right you want to go
thing is Win rate right you want to go
from 099 to 999 win rate like that
from 099 to 999 win rate like that
actually matters
or like if you're doing even if you're
or like if you're doing even if you're
doing something like pong where the max
doing something like pong where the max
score is 21 right you want a consistent
score is 21 right you want a consistent
21 Max score you don't want
20.5 so probably this break things but
20.5 so probably this break things but
we'll
see lots of notifications
the
heck so much spam on
timeline for
yeah this is a way better distribution
yeah this is a way better distribution
over cost
initially uh and this is getting
initially uh and this is getting
very good
scores
so it's still getting high High rating
so it's still getting high High rating
for
this there's probably some math detail
this there's probably some math detail
I'm missing but this actually looks very
I'm missing but this actually looks very
good let me
look so this is before with the lower
Epsilon
Epsilon
huh why do it get why is it so obsessed
huh why do it get why is it so obsessed
over
here maybe it's not
better spends more compute here but
better spends more compute here but
that's about
it all right
well E3 gives you
I'm going to set this to 23 I'm going to
I'm going to set this to 23 I'm going to
run it again just for good measure and
run it again just for good measure and
then we're going to stop tuning this and
then we're going to stop tuning this and
we're going to mess with other stuff and
we're going to mess with other stuff and
then what we'll do is we will uh we'll
then what we'll do is we will uh we'll
set up some runs on some real
set up some runs on some real
environments I think yeah and in the
environments I think yeah and in the
meantime I'm going to start looking at
meantime I'm going to start looking at
how to clean this up a little bit which
how to clean this up a little bit which
I think will be important so can I get
I think will be important so can I get
rid of this normal option
rid of this normal option
here I think we figured out that this
here I think we figured out that this
makes stuff a mess so we're just just
makes stuff a mess so we're just just
going to leave this as the main
one yeah I hate options and things that
one yeah I hate options and things that
like make the code longer and stupider
I think there's still technically a
I think there's still technically a
couple weird edge cases
here not terrible
though okay we've got prams EPS y me
though okay we've got prams EPS y me
Max do we care about y Max no
we don't use any of this
crap Min score
might men
it's fine
new
new
train get the
suggestions got numpy
Norm let's do this one this
one
one
Pito YT
Pito YT
C and log C Norm okay so you have your
C and log C Norm okay so you have your
pitos
pitos
here to y
and F you don't use
and F you don't use
this you don't use
this you don't use
this so
y we do nearest
Pito Pito
y l
c log C form
okay and then where's
Pito oh this doesn't get used okay so we
Pito oh this doesn't get used okay so we
use parito
C and
C and
purito warm yesc
that's a little better just a little
that's a little better just a little
bit I don't know why they're clustered
bit I don't know why they're clustered
like this but
like this but
whatever it's probably pretty hard for
whatever it's probably pretty hard for
it to learn to predict uh the fine grain
it to learn to predict uh the fine grain
differences here you'd think that it
differences here you'd think that it
would get it on cost
would get it on cost
but not a huge
deal so let's finish cleaning this up
deal so let's finish cleaning this up
and then I think we can throw this on
and then I think we can throw this on
pong pretty soon
here there's just a mess of things here
here there's just a mess of things here
so like nearest pero white do we use
this no
I don't use this do
I because yeah that's gone now okay cool
I because yeah that's gone now okay cool
so
uh it's pretty
good I'd say that's
solid make sure I didn't break anything
solid make sure I didn't break anything
in the process of doing that
I think I'd actually rather run the log
I think I'd actually rather run the log
one
for folks on YouTube this
for folks on YouTube this
is hopefully towards the end of having a
is hopefully towards the end of having a
working very nice hyper parameter sweep
working very nice hyper parameter sweep
algorithm for reinforcement
algorithm for reinforcement
learning um while this
learning um while this
runs so the algorithm that we've landed
runs so the algorithm that we've landed
on it's a little different from the last
on it's a little different from the last
time I went over it so
time I went over it so
idea here is this is your
idea here is this is your
curve you
curve you
have on this side
have on this side
cost and then this axis is
cost and then this axis is
four um and your goal is to discover
four um and your goal is to discover
this curve which contains the set of
this curve which contains the set of
experiments that you can run where
experiments that you can run where
there's nothing up and the right so
there's nothing up and the right so
there's nothing that's cheaper to run
there's nothing that's cheaper to run
that takes less time but is also
that takes less time but is also
performing better uh so the idea here
performing better uh so the idea here
I'm going to move that point just to
I'm going to move that point just to
make it more
make it more
obvious the idea behind the algorithm is
obvious the idea behind the algorithm is
that you're generating a whole bunch of
that you're generating a whole bunch of
potential points that you might want to
potential points that you might want to
run each point is a set of
run each point is a set of
hyperparameters and then when you run
hyperparameters and then when you run
the experiment it's going to end up
the experiment it's going to end up
somewhere on this curve and we're
somewhere on this curve and we're
training predictive models as well as to
training predictive models as well as to
where these are going to end up on the
where these are going to end up on the
curve but you still need to know which
curve but you still need to know which
point to select so what we say is if
point to select so what we say is if
that there's a point here that you want
that there's a point here that you want
to
to
select what you do is your going to look
select what you do is your going to look
at this distance so the distance
at this distance so the distance
vertically from this point to the
vertically from this point to the
nearest point to the left on this
nearest point to the left on this
curve uh and then you're going to look
curve uh and then you're going to look
at and this is the new
at and this is the new
part you're going to look at the Min of
part you're going to look at the Min of
these two
distances so you're looking for the
distances so you're looking for the
closest point on the curve to you
closest point on the curve to you
whether it's this one or this one and
whether it's this one or this one and
the goal of this is that this should
the goal of this is that this should
encourage you to fill out most of this
encourage you to fill out most of this
curve while also improving over know
curve while also improving over know
points as much as possible um you know
points as much as possible um you know
if you put a point down here for
if you put a point down here for
instance then you don't get anything for
instance then you don't get anything for
this because your final score is going
this because your final score is going
to be if this is a and this is uh this
to be if this is a and this is uh this
is
is
B and you're going to get a * B this is
B and you're going to get a * B this is
your score so if you put the point down
your score so if you put the point down
here a is zero you don't get anything uh
here a is zero you don't get anything uh
if you put the point like right on top
if you put the point like right on top
you don't get anything because you're
you don't get anything because you're
already on top and an exist point so
already on top and an exist point so
your goal is to fill out this curve and
your goal is to fill out this curve and
improve over these adjacent
improve over these adjacent
points this is a pretty nice algorithm
points this is a pretty nice algorithm
uh it's based on in Bui
uh it's based on in Bui
carbs but their version of this uh
carbs but their version of this uh
doesn't use adjacent points at all it
doesn't use adjacent points at all it
tries to substitute a function model of
tries to substitute a function model of
the curve and then they just try to look
the curve and then they just try to look
for like where they think that they can
for like where they think that they can
improve over their model of the Curve
improve over their model of the Curve
and there are a whole bunch of
and there are a whole bunch of
degenerate cases that are not handled um
degenerate cases that are not handled um
yeah there's just a bunch of problems
overall the only thing I'm not
overall the only thing I'm not
completely happy about is you know you
completely happy about is you know you
can improve a ton over an existing point
can improve a ton over an existing point
and you still get zero I don't really
and you still get zero I don't really
like that too much
like that too much
so I'm going to think about that because
so I'm going to think about that because
it's incentivizing you to try new spaces
it's incentivizing you to try new spaces
on the curve so it's not terrible that
on the curve so it's not terrible that
it works that
it works that
way it just really wants you to fill in
way it just really wants you to fill in
the
curve okay so this is a different
curve okay so this is a different
test
test
beautiful one bad point
total this is
perfect I'm curious to see what this is
perfect I'm curious to see what this is
going to do on Fong um let's commit well
going to do on Fong um let's commit well
let's let's configure a couple
let's let's configure a couple
things first let's configure a couple
things sweep. metric
7 mean is 2
E7
Auto e
okay Maro
Co so this is set up
Co so this is set up
nicely let's commit
nicely let's commit
everything so we have it
it's not very much code for this thing
really not a ton of code for
this the original repository for carbs
this the original repository for carbs
for reference was around 2,000 lines ARS
for reference was around 2,000 lines ARS
is going to end up between 4 and 500
is going to end up between 4 and 500
most likely though I might try to
most likely though I might try to
compress it even more than
compress it even more than
that because I think it would be funny
um there's still some things I want to
um there's still some things I want to
improve with this currently the
improve with this currently the
algorithm starts with random
algorithm starts with random
sampling around well it's like it's
sampling around well it's like it's
directed random sampling but still I
directed random sampling but still I
think that we have some things that
think that we have some things that
could be improved
could be improved
there we could improve the initial
there we could improve the initial
sampling
um yeah because it's quite a lot to
um yeah because it's quite a lot to
require 10 experiments before carbs
require 10 experiments before carbs
really does anything
really does anything
which is what we have
which is what we have
now I think after
that well we'll see how this goes on
that well we'll see how this goes on
pong um now pong is one of many tasks
pong um now pong is one of many tasks
that we can try the whole idea of this
that we can try the whole idea of this
is we have all these environments on
is we have all these environments on
puffer
puffer
AI right you can play any of these got
AI right you can play any of these got
breakout got like fancy stuff like uh
breakout got like fancy stuff like uh
like this right got multi-agent snake
like this right got multi-agent snake
lots of
lots of
environments so hopefully when we test
environments so hopefully when we test
this out on all those we're going to
this out on all those we're going to
figure out the gaps and the things that
figure out the gaps and the things that
could be improved and I don't want to
could be improved and I don't want to
shift this until I have something where
shift this until I have something where
I really feel like okay hyperparameter
I really feel like okay hyperparameter
sweeps for RL are stable consistent and
sweeps for RL are stable consistent and
easy that's the goal stable consistent
easy that's the goal stable consistent
and easy and I think if we can do that
and easy and I think if we can do that
just so much of RL research is going to
just so much of RL research is going to
just feel better and so much of RL in
just feel better and so much of RL in
practice is going to just feel better
practice is going to just feel better
because you're not going to ever have to
because you're not going to ever have to
wonder uhoh oh or my hyper parameters
wonder uhoh oh or my hyper parameters
just off right you're going to just be
just off right you're going to just be
able to run the sweep you're going to
able to run the sweep you're going to
get like really good information out of
get like really good information out of
that sweep it's going to be fat and uh
that sweep it's going to be fat and uh
yeah that's generally going to be the
yeah that's generally going to be the
case and I think we're pretty close to
case and I think we're pretty close to
that um obviously there's a ton of
that um obviously there's a ton of
testing there's a ton of tweaking I
testing there's a ton of tweaking I
could be wrong on various parts of this
could be wrong on various parts of this
algorithm but I think that the way that
algorithm but I think that the way that
I've handled the normalization
I've handled the normalization
everywhere just makes good sense and um
everywhere just makes good sense and um
should generally be pretty stable
should generally be pretty stable
there's still a couple things here and
there's still a couple things here and
there that I'm not too sure if I like
there that I'm not too sure if I like
like the exponential scaling with this
like the exponential scaling with this
like Epsilon
like Epsilon
maximum you need to have scaling it
maximum you need to have scaling it
should probably be exponential I don't
should probably be exponential I don't
know how you should be clipping it or
know how you should be clipping it or
you know handling edge cases so there's
you know handling edge cases so there's
still stuff to figure out there uh
still stuff to figure out there uh
there's a resampling option as well
there's a resampling option as well
where you can resample existing points I
where you can resample existing points I
think I probably need that because for
think I probably need that because for
environments where there's just a lot of
environments where there's just a lot of
instability um you kind of need to
instability um you kind of need to
resample yeah so there are a lot of
resample yeah so there are a lot of
different things that can be done
different things that can be done
there I'm not going to get off just yet
there I'm not going to get off just yet
I'm going to still do a couple
I'm going to still do a couple
additional things here um but since we
additional things here um but since we
do have a fair few folks watching at the
do have a fair few folks watching at the
moment happy Valentine's Day and um if
moment happy Valentine's Day and um if
you're interested in getting involved in
you're interested in getting involved in
all this open source RL can join the
all this open source RL can join the
Discord it's just discord.
Discord it's just discord.
GPU you can try all these environments
GPU you can try all these environments
out on puffer doai uh they're all very
out on puffer doai uh they're all very
simple to read they're all open source
simple to read they're all open source
most of these are contributed by new RL
most of these are contributed by new RL
folks in the Discord who have just you
folks in the Discord who have just you
know gotten involved with the stuff you
know gotten involved with the stuff you
don't really need a ton of RL experience
don't really need a ton of RL experience
for this side of
for this side of
it and uh they're all very fast like
it and uh they're all very fast like
10,000 times real time
10,000 times real time
fast all the code is right here on the
fast all the code is right here on the
GitHub you can star the repo to help us
GitHub you can star the repo to help us
out that really helps us out and if
out that really helps us out and if
you're looking to get into RL I would
you're looking to get into RL I would
suggest
suggest
specifically this quick start guide and
specifically this quick start guide and
if you're already an expert in RL then
if you're already an expert in RL then
we have some other articles on some of
we have some other articles on some of
the work that we've done here such as
the work that we've done here such as
the 2.0 article and I have some extra
the 2.0 article and I have some extra
ones on my X as well
and while I've been saying all of that
and while I've been saying all of that
we've mostly finished the random trials
we've mostly finished the random trials
I think it's 10 random trials by
default is it 10 random trials or did I
default is it 10 random trials or did I
reduce it something interesting that it
reduce it something interesting that it
goes up this way
let me see if I can find the previous
let me see if I can find the previous
best
best
one one that we're trying to beat
this it this one's pretty
this it this one's pretty
good I think this one but I don't think
good I think this one but I don't think
this is the best
one let me see this is the 34
one let me see this is the 34
one this one
better I see other
one I think this is the best weep that
one I think this is the best weep that
we
had so we have like a Pito front that
had so we have like a Pito front that
looks like
looks like
this most part I thought we had a better
this most part I thought we had a better
one as
one as
well no I think this might be it
well no I think this might be it
yeah uh and then we had what
yeah uh and then we had what
else there's so many different things
else there's so many different things
we've tried here
like I think this
one this was a carb sweep on
pong we didn't get the Pito front out of
pong we didn't get the Pito front out of
this
score okay yeah this is this is pretty
score okay yeah this is this is pretty
representative so we get stuff like this
representative so we get stuff like this
out of um carbs before which is pretty
out of um carbs before which is pretty
decent right you get
decent right you get
like what's this 28 seconds I think run
like what's this 28 seconds I think run
time to
time to
solve so like it discovers good
solve so like it discovers good
Solutions but like all this stuff in
Solutions but like all this stuff in
here is wasted it just it runs a lot of
here is wasted it just it runs a lot of
pretty wasteful
experiments you can see I've been
experiments you can see I've been
running like lots and lots of Trials on
running like lots and lots of Trials on
carbs this is all neoc carbs experiments
carbs this is all neoc carbs experiments
name work in progress
name work in progress
um but I think the first old version I
um but I think the first old version I
had over
had over
here
so yeah this was like a pretty stable
so yeah this was like a pretty stable
version that I was running experiments
version that I was running experiments
on not this
one it generally looks less
one it generally looks less
wasteful in that uh most of the good
wasteful in that uh most of the good
experiments right like they up here it's
experiments right like they up here it's
not running too many failures down here
not running too many failures down here
it's a little weird because like there
it's a little weird because like there
are still points here that are not great
are still points here that are not great
you shouldn't be here and then it
you shouldn't be here and then it
clusters a lot of stuff down here which
clusters a lot of stuff down here which
is not
is not
good so there are all sorts of different
good so there are all sorts of different
versions of this that I've run I think
versions of this that I've run I think
that there
that there
is there's one on breakout as well so
is there's one on breakout as well so
this is
breakout uh breakout is a lot is very
breakout uh breakout is a lot is very
noisy so you're going to get bad runs
noisy so you're going to get bad runs
regardless of what you do I think we can
regardless of what you do I think we can
do way better than this at least though
do way better than this at least though
yeah they're various different
yeah they're various different
environment so we do have some like nice
environment so we do have some like nice
benchmarks from the old version to
benchmarks from the old version to
try um but then the hope is that we're
try um but then the hope is that we're
going to be able to get something much
better and this is what uh this is the
better and this is what uh this is the
problem that I was having with something
problem that I was having with something
similar to the current version of the
similar to the current version of the
code where it would like it would kind
code where it would like it would kind
of cluster a bunch of experiments up
of cluster a bunch of experiments up
close to where it thinks it can solve
close to where it thinks it can solve
and then it would cluster a bunch of
and then it would cluster a bunch of
experiments at minimum cost I think this
experiments at minimum cost I think this
was just bad data
was just bad data
normalization we're going to see if this
normalization we're going to see if this
can do better than
that it's so cool to be able to run
that it's so cool to be able to run
these things like in one to three
these things like in one to three
minutes a
piece okay so interestingly it is
piece okay so interestingly it is
pushing up to Max cost it looks like
pushing up to Max cost it looks like
see the Paro
front I might have it pushing too
front I might have it pushing too
aggressively to Max
cost it doesn't have a great model of
cost it doesn't have a great model of
performance yet
I mean the good thing is it doesn't
I mean the good thing is it doesn't
get it has to at least predict that it's
get it has to at least predict that it's
going to improve over the nearest point
going to improve over the nearest point
so the prediction model can be
so the prediction model can be
off but it's not going to intentionally
off but it's not going to intentionally
run experiments that are worse than
run experiments that are worse than
existing
points is this just unstable this is
points is this just unstable this is
weird that it's this
slow yeah okay there's some
instability I mean the ideal thing right
instability I mean the ideal thing right
is that you get a pretty like dense set
is that you get a pretty like dense set
of points around here in the cheap range
of points around here in the cheap range
and then you like fill in longer and you
and then you like fill in longer and you
get like a nice clean curve
yeah this definitely pushing the Max
cost maybe we can think about that just
cost maybe we can think about that just
a little bit while this
runs because I do technically encourage
runs because I do technically encourage
that and I encourage it quite
explicitly I set the mean function to
one that shouldn't affect that
one that shouldn't affect that
though your score function
is you do explicitly get
rewarded we pushing the Max cost
shouldn't this happen anyways even if
shouldn't this happen anyways even if
you just deleted that term
you just deleted that term
entirely it should in theory
right just how much can you improve over
right just how much can you improve over
the nearest Paro point
I actually I think I remember the
I actually I think I remember the
reason so the reason that I added this
reason so the reason that I added this
term in
term in
there originally
it wasn't anything to do with trying to
it wasn't anything to do with trying to
push you towards higher
push you towards higher
cost the reason I added this term
cost the reason I added this term
originally is like if you have a point
originally is like if you have a point
here and a point here and you just look
here and a point here and you just look
for where is the highest point that I
for where is the highest point that I
can improve over the nearest parito to
can improve over the nearest parito to
the left CU you go to the left you look
the left CU you go to the left you look
for the nearest parito and then you see
for the nearest parito and then you see
where should I put your point to improve
where should I put your point to improve
the most over that so it would just put
the most over that so it would just put
a point like here right because this is
a point like here right because this is
the biggest Improvement and then it
the biggest Improvement and then it
would go like this and this and this so
would go like this and this and this so
it just densely fill in and like scale
it just densely fill in and like scale
back that
way so maybe this is being abused
maybe this is being abused
you have options
here you could clip it so you could clip
here you could clip it so you could clip
points that are too
far there's a parameter you have to
far there's a parameter you have to
control how far away you can put points
the thing is I really like the uh the
the thing is I really like the uh the
nearest penalty
nearest penalty
thing because it has a really nice
interpretation so if I if you do like
interpretation so if I if you do like
the minimize distance to nearest point
the minimize distance to nearest point
then this is the best solution right and
then this is the best solution right and
then maybe this is and this
then maybe this is and this
is and you literally end up doing binary
is and you literally end up doing binary
search so it has this very very nice
search so it has this very very nice
interpretation
so I kind of want to keep that term in
so I kind of want to keep that term in
though that doesn't mean that I have to
though that doesn't mean that I have to
keep the boundary uh condition
yeah I could just use the mean distance
yeah I could just use the mean distance
or something like
or something like
that okay so we'll see how aggressive
that okay so we'll see how aggressive
this thing is if this thing is pushing
this thing is if this thing is pushing
towards high cost way too much then uh
towards high cost way too much then uh
you know we have options to handle
you know we have options to handle
that so I think that the base algorithm
that so I think that the base algorithm
is good I really do it's just a matter
is good I really do it's just a matter
of boundry conditions and the
of boundry conditions and the
like yeah because it's not pushing
like yeah because it's not pushing
everything to Max cost
everything to Max cost
yet we look at
yet we look at
Paro we already have a point that's over
Paro we already have a point that's over
this is way too much running time for
this is way too much running time for
pong it should be able to do this back
pong it should be able to do this back
here so I do think that this is pushing
here so I do think that this is pushing
too high too
quickly because it's getting rewarded
quickly because it's getting rewarded
for it
yeah see look it's it's getting this
yeah see look it's it's getting this
distance here
distance here
because I don't even know how it samples
because I don't even know how it samples
that
far I don't think it should be able to
far I don't think it should be able to
sample this far away from this
point yeah okay so there's definitely
point yeah okay so there's definitely
something screwy
something screwy
here you're not supposed to be able to
here you're not supposed to be able to
do this
so it could just be that because the
so it could just be that because the
thing is if you don't have a if you're
thing is if you don't have a if you're
not parito then you don't go into the
not parito then you don't go into the
sample Index right so like it's not
sample Index right so like it's not
sampling around these points it had to
sampling around these points it had to
have sampled from like this
have sampled from like this
point it's not supposed to be able to do
point it's not supposed to be able to do
this big of a
jump I don't even know how this point
jump I don't even know how this point
got run this is ridiculous
oh to be fair it is technically it's
oh to be fair it is technically it's
possible to like it could have been like
possible to like it could have been like
this point ran and then this point ran
this point ran and then this point ran
or something or this point that still
or something or this point that still
doesn't really make sense no there's no
doesn't really make sense no there's no
way they should have
way they should have
run there's no point that they should
run there's no point that they should
have been able to have been sampled
from it is possible the cost model was
from it is possible the cost model was
just totally wrong
even
even
then it shouldn't
happen red
happen red
[Music]
[Music]
Norm num Ms okay so it did it's pushed
Norm num Ms okay so it did it's pushed
this down a ton so this is going to slow
stuff and
stuff and
then update epox is at one or two only
there's still quite a bit to do
here
here
okay well this is good progress at the
okay well this is good progress at the
very least um the sweeps are running
very least um the sweeps are running
they don't look totally
degenerate I will be curious to
see if we don't get too much noise down
see if we don't get too much noise down
here if it pushes up to Max cost but
here if it pushes up to Max cost but
most of the runs are of at least high
most of the runs are of at least high
quality then that I think will be a
quality then that I think will be a
success uh and then we'll just have to
success uh and then we'll just have to
adjust the sampling scheme a little bit
adjust the sampling scheme a little bit
more
more
tomorrow but I am going to be working on
tomorrow but I am going to be working on
this for most of the weekend so I will
this for most of the weekend so I will
be streaming this all day
be streaming this all day
tomorrow um and we're going to be doing
tomorrow um and we're going to be doing
more of this experiment side work I'll
more of this experiment side work I'll
see if I find other stuff to do in the
see if I find other stuff to do in the
middle
middle
because you know you have to wait for
because you know you have to wait for
the experiments to run but probably the
the experiments to run but probably the
way I'm going to approach it is I'm
way I'm going to approach it is I'm
going to start you know formally trying
going to start you know formally trying
to write up some of this stuff because
to write up some of this stuff because
there will be a nice blog post on this
there will be a nice blog post on this
uh and then I'll probably like fill in
uh and then I'll probably like fill in
stuff along the way so anything I want
stuff along the way so anything I want
to make like a cool figure a cool
to make like a cool figure a cool
visualization I'll probably like make
visualization I'll probably like make
that and I'll run that as well so we'll
that and I'll run that as well so we'll
start like really trying to polish this
start like really trying to polish this
stuff
stuff
up though I don't think the results the
up though I don't think the results the
results are not there yet but it looks
results are not there yet but it looks
to me like mostly we
to me like mostly we
are yeah it looks like mostly we are
are yeah it looks like mostly we are
limited
limited
from uh the sampling and like the like
from uh the sampling and like the like
pushing up too far cost the now I'm
pushing up too far cost the now I'm
looking at this actually maybe this
looking at this actually maybe this
isn't bad because it doesn't look like
isn't bad because it doesn't look like
it's pushed all the way up just
it's pushed all the way up just
yet maybe this ends up being good all
yet maybe this ends up being good all
right I'm going to call it here um for
right I'm going to call it here um for
folks watching Once Again puff. star the
folks watching Once Again puff. star the
GitHub really really helps you can
GitHub really really helps you can
actually get all this code that I just
actually get all this code that I just
uh all this code I just did you can go
uh all this code I just did you can go
play with it it's in the uh whatever fix
play with it it's in the uh whatever fix
neoc carbs Branch or whatnot it's the
neoc carbs Branch or whatnot it's the
latest commit join the Discord almost 1
latest commit join the Discord almost 1
th people in here discord. g/p
th people in here discord. g/p
puffer and uh yeah lots of fun RL
puffer and uh yeah lots of fun RL
articles on here if you are on X lots of
Articles this is all I do uh we are
Articles this is all I do uh we are
going to fix reinforcement learning this
going to fix reinforcement learning this
year and Hyper pram sweeps is a big part
year and Hyper pram sweeps is a big part
of
of
that we're spinning up a few other
that we're spinning up a few other
efforts that I'll talk about soon but
efforts that I'll talk about soon but
for now this is what we've got all right
for now this is what we've got all right
thanks uh enjoy

Kind: captions
Language: en
back live
okay
okay
so we're going to get back onto
so we're going to get back onto
this I came up with some
this I came up with some
ideas I came up with some ideas
ideas I came up with some ideas
um there's still some stuff to decide
um there's still some stuff to decide
though isn't there
I think this Norm is
better really it's just this transform
better really it's just this transform
that I need to
keep yeah I me keep this
transform e
okay I think that uh what I decided
okay I think that uh what I decided
while I was off on my
while I was off on my
run was that the way that we are going
run was that the way that we are going
to do
to do
this welcome linky
how's it
going yeah I think what we're going to
going yeah I think what we're going to
do is first of all this sweep. metric
thing do I have this for One V
compatibility it's probably what I have
compatibility it's probably what I have
this there for right
this there for right
but I don't use Wy sweep so that's
but I don't use Wy sweep so that's
irrelevant
okay so we will just go to
method name metric goal
fine that is
fine that is
fine now we need to add some stuff
maybe I should have left that
in yeah that was dumb I should have left
in yeah that was dumb I should have left
that
in all right no harm done it's cuz and
in all right no harm done it's cuz and
the reason I need to leave it in is
the reason I need to leave it in is
because I realized I need to add Min and
because I realized I need to add Min and
Max to this thing right
by default but we're going to
by default but we're going to
do
zero uh and I guess one for now
at least leave it in the
at least leave it in the
defaults no no no we're not we're not
defaults no no no we're not we're not
deprecating WB sweeps we are dropping WB
deprecating WB sweeps we are dropping WB
sweep support but we are still going to
sweep support but we are still going to
support sweeps in Wy just not using
support sweeps in Wy just not using
their sweeps API so you will have the
their sweeps API so you will have the
same thing just not with the one to be
same thing just not with the one to be
sweeps
API we don't do deprecated
API we don't do deprecated
man deprecated is like oh we'll leave it
man deprecated is like oh we'll leave it
in for now to give you time to switch
in for now to give you time to switch
over no when something needs to change
over no when something needs to change
we change it deprecated is for big
we change it deprecated is for big
companies maintaining Legacy stuff if
companies maintaining Legacy stuff if
we're not if we don't specifically have
we're not if we don't specifically have
somebody we're supporting that needs it
somebody we're supporting that needs it
uh then we just change
uh then we just change
it correct for car carb sweep is gone
it correct for car carb sweep is gone
carb sweep will be gone after
this we will we're going to I'm not
this we will we're going to I'm not
going to ship this before I confirm that
going to ship this before I confirm that
this is just massively better than
carbs e
this 500 line file is going to replace
this 500 line file is going to replace
it it's going to be less than that one
it it's going to be less than that one
we're
done
for
e for
yeah this one I think is worse we'll
yeah this one I think is worse we'll
start with this
welcome YouTube
welcome YouTube
folks this is going to be most of the
folks this is going to be most of the
weekend here uh on trying to make
weekend here uh on trying to make
ridiculously good hyperparameter sweeps
ridiculously good hyperparameter sweeps
for reinforcement learning since we have
for reinforcement learning since we have
a few folks on I'll do a little bit of
a few folks on I'll do a little bit of
background while this experiment
runs my work here is based on mvi carbs
runs my work here is based on mvi carbs
method this is uh a work that's gone
method this is uh a work that's gone
relatively under the radar but made a
relatively under the radar but made a
huge impact on reinforcement learning I
huge impact on reinforcement learning I
really like it at
really like it at
least and it's a very mathy
least and it's a very mathy
paper it does a bunch of things with
paper it does a bunch of things with
various different gaussian processes
various different gaussian processes
it's got like this soft trust region
it's got like this soft trust region
here uh it does expected improvement
here uh it does expected improvement
over predictions from Gan
over predictions from Gan
processes and it does a few other things
processes and it does a few other things
as well um I've been going through the
as well um I've been going through the
released code for this uh I've used
released code for this uh I've used
carbs itself for many months many people
carbs itself for many months many people
in puffer have and we found some things
in puffer have and we found some things
that could be improved and when we
that could be improved and when we
started pulling at that thread well you
started pulling at that thread well you
know one thing led to another and we are
know one thing led to another and we are
really rewriting the majority of this
really rewriting the majority of this
algorithm now and fully rewriting the
algorithm now and fully rewriting the
code um so we're now doing some work to
code um so we're now doing some work to
see which ways we can improve this uh in
see which ways we can improve this uh in
particular carbs and most algorithms
particular carbs and most algorithms
will horribly fail uh the major of very
will horribly fail uh the major of very
simple benchmarks which that's doesn't
simple benchmarks which that's doesn't
seem good you know your algorithm should
seem good you know your algorithm should
not be failing simple benchmarks
not be failing simple benchmarks
um so we are looking at the reasons for
um so we are looking at the reasons for
that and we're going to get something
that and we're going to get something
that works very nicely on both simple
that works very nicely on both simple
benchmarks and then outperforms the
benchmarks and then outperforms the
original on all of our RL environments
original on all of our RL environments
and Puffer that is the
goal
yorm um so the work process for this is
yorm um so the work process for this is
pretty much just going to be me fiddling
pretty much just going to be me fiddling
around with the algorithm fiddling with
around with the algorithm fiddling with
the math fiddling with data
the math fiddling with data
normalization in various ways and then
normalization in various ways and then
trying to figure out how to improve upon
trying to figure out how to improve upon
this H so this is
interesting let me see what this curve
interesting let me see what this curve
is supposed to look like first
and then we'll figure out what's up with
and then we'll figure out what's up with
this
this
so the percentile Tas a synthetic
task it's supposed to be
task it's supposed to be
simple welcome yeah I see your
simple welcome yeah I see your
chats I just had forgotten to enable the
chats I just had forgotten to enable the
chat earlier today like I uh I made a
chat earlier today like I uh I made a
different scene because I had meetings
different scene because I had meetings
where I needed to screen share and I
where I needed to screen share and I
didn't want the chat on it and then I
didn't want the chat on it and then I
just I forgot to switch the scene back
just I forgot to switch the scene back
is
all
all
howdy
CL so right
here this is the
here this is the
score and then the
score and then the
cost cost is unchange so this goes up to
cost cost is unchange so this goes up to
200 so
uh let me think
one so
score one hold on
score one hold on
what over 1
what over 1
+ x
of uh I am
confused what did I make this like this
confused what did I make this like this
is supposed to be a zero to one reward
is supposed to be a zero to one reward
but I'm confused as to what I did here
so I think the maximum score
negative log of the
learning +
okay oh yeah cuz X zero should be
one right yeah you do this so it's it
one right yeah you do this so it's it
goes up to
one and then okay so then what we do
one and then okay so then what we do
is I
do the cost can go up to
do the cost can go up to
that uh so that goes up to about one
that uh so that goes up to about one
yeah
if we do
like oh that's what it's divided
like oh that's what it's divided
by I
see so this gives you
see so this gives you
6 and we see 6 perfect so this is what
6 and we see 6 perfect so this is what
it looks
it looks
like uh for whatever reason
it's scaled kind of
weird oh it goes from0
weird oh it goes from0
five and
five and
one let's
see yeah but it's just it's not being
see yeah but it's just it's not being
computed out far enough for some reason
computed out far enough for some reason
so let's figure that
out why have these
out why have these
been why are these given like
this there's also Max cost to
consider but I would like to look at
this okay
so oh hold on did I Norm this wrong I
so oh hold on did I Norm this wrong I
think I normed it
think I normed it
wrong
wrong
no huh okay okay well we wanted to
no huh okay okay well we wanted to
change this anyways so we're going to
do comment
do comment
these
y we're going to
y we're going to
use
use
um Gan Norm
um Gan Norm
here instead of linear
norm and then I have to remember to undo
this there we go
this there we go
let's see if that changes anything
let's see if that changes anything
before we go crazy looking at the
map the thing is that this should be
map the thing is that this should be
pushing this should pretty quickly push
pushing this should pretty quickly push
towards higher
towards higher
cost so if it doesn't then there's
cost so if it doesn't then there's
something weird
oh
wait I might have left uh left this
wait I might have left uh left this
parameter in
parameter in
right yes I left this parameter in okay
right yes I left this parameter in okay
that was
that was
done
done
10 so there's nothing wrong with this
10 so there's nothing wrong with this
weep I just left a bad hyper in well
weep I just left a bad hyper in well
let's take a look at it at least
let's take a look at it at least
this should now much more
this should now much more
quickly instead of capping it it was
quickly instead of capping it it was
being capped to cost four so now it's
being capped to cost four so now it's
Capp to cost
200 it still not push
outward that would be
odd huh
that doesn't sit
right oh
maybe
maybe
uhuh yeah something's definitely screwy
uhuh yeah something's definitely screwy
with this then
[Music]
okay so it's pushing out but very very
okay so it's pushing out but very very
slowly at
first so why
okay see the
quality okay so this portion here looks
quality okay so this portion here looks
reasonable there a couple
reasonable there a couple
misses
misses
um this is very dense over here
I'm starting to wonder
I'm starting to wonder
why okay hold
why okay hold
on so if you have your data distributed
on so if you have your data distributed
this
this
way it's roughly
linear your loss function should be or
linear your loss function should be or
your score function should be pushing it
your score function should be pushing it
out more aggressively than this
out more aggressively than this
let's go double check the log one just
let's go double check the log one just
in case because um know it's possible
in case because um know it's possible
that I screw that
up log task time log 10
oops
oops
2.3 we'll do
2.31 Max
2 can it go
negative I don't think so
so I want to basically make sure that I
so I want to basically make sure that I
didn't break it in the process of doing
didn't break it in the process of doing
what I was doing with uh the Norms
there CU if this one also takes forever
there CU if this one also takes forever
at the start now
at the start now
then there you have it
oops I got to remember to keep posting
oops I got to remember to keep posting
stuff on
stuff on
here it's kind of silly that this is
here it's kind of silly that this is
considered part of work now but we're
considered part of work now but we're
almost at
almost at
6,900
nice okay so this is is this lower than
before I think that's like an acceptable
before I think that's like an acceptable
Pace right
this cost is in units of 50 million if
this cost is in units of 50 million if
we think of it that
way I think I'm pretty happy for it to
way I think I'm pretty happy for it to
take you know maybe 20 experiments
take you know maybe 20 experiments
before it starts
accelerating but it did it only got up
accelerating but it did it only got up
to 70 here so it is slower than
before how did this
happen do I have the other
happen do I have the other
window yeah so this is what we got
window yeah so this is what we got
before we got like something like
this oops
and now we have a similar
shape this nice line curve
shape this nice line curve
yeah but it takes too many
yeah but it takes too many
samples it's just too many
samples okay
I can check if it was
I can check if it was
the the change of
mean let me just see if it was this
mean let me just see if it was this
first before we do anything
else I think it's more likely the change
else I think it's more likely the change
of normalization
that should be able to make it more
that should be able to make it more
aggressive not
less well we will see shortly
First Community note I've seen on an AI
First Community note I've seen on an AI
model
model
post that's
funny good note
looks like it's going to be
similar so in that case it must have
similar so in that case it must have
been the norm right
this is a little bit more
aggressive quite actually somewhat
aggressive quite actually somewhat
substantially
right yeah that's closer to the
original I think they're probably just
original I think they're probably just
going to have to be a coefficient that
going to have to be a coefficient that
gets uh
tuned for
I think we're also going to Benchmark
I think we're also going to Benchmark
this
this
versus some random methods as well so
versus some random methods as well so
we'll tune based on
we'll tune based on
that
that
um so this is fine for
um so this is fine for
now this gets out to 150ish
so here's just tuning up the because I
so here's just tuning up the because I
do think that we want to use mean
do think that we want to use mean
scaling so we're going to tune this
scaling so we're going to tune this
up so the full
up so the full
transformation you get your score data
transformation you get your score data
which is how well you did in the
which is how well you did in the
environment right and then you're going
environment right and then you're going
to first 01 scale
to first 01 scale
it and then you're going to exponential
it and then you're going to exponential
scale that so you get everything into a
scale that so you get everything into a
01 range and then you apply this
01 range and then you apply this
exponential transform which basically uh
exponential transform which basically uh
the closer you get to the max if you cut
the closer you get to the max if you cut
the distance in half you double your
the distance in half you double your
score um so you get this exponential
score um so you get this exponential
scalar and then we put it into
scalar and then we put it into
approximate we just uh we try to
approximate we just uh we try to
standard Norm it just because gaussians
standard Norm it just because gaussians
like standard
Norms I should do the same thing here
we're going to try this
we're going to try this
next the reason I'm making these changes
next the reason I'm making these changes
now is I did some uh some testing this
now is I did some uh some testing this
morning and it seems like I was
morning and it seems like I was
substantially underappreciated how much
substantially underappreciated how much
gaussian processes rely on nicely
gaussian processes rely on nicely
standard normalized
data the 01 scale is not bad to be
bear we'll
see let me think actually there might
see let me think actually there might
have been a reason I did that
well this didn't really do
well this didn't really do
much let's try
much let's try
again with the new
cost hang on
this might be something that I have to
this might be something that I have to
include both for until we test it
include both for until we test it
out for
oh you know
what linear is correct
here I say is this just absolutely
here I say is this just absolutely
shreds it when I do it the other way let
shreds it when I do it the other way let
me
see what happened
here why are these over
here why are these over
here that shouldn't have happened this
here that shouldn't have happened this
is
is
bad there's a lot of ways to compute
bad there's a lot of ways to compute
this curve is good but this is these
this curve is good but this is these
points are very very bad here yeah this
points are very very bad here yeah this
jumped up too quickly you see this
jumped up too quickly you see this
jumped way too
quickly okay we're going to
quickly okay we're going to
try linear and Norm so we're going to do
try linear and Norm so we're going to do
input Norm Norm
linear just going to put it here for
now and then
now and then
I have to do the same thing somewhere
I have to do the same thing somewhere
don't I
and now we rerun with this
very good
yeah this is going to be correct and
yeah this is going to be correct and
here's the reason that I think this is
here's the reason that I think this is
correct so this does slightly make it
correct so this does slightly make it
harder or this does make it harder
harder or this does make it harder
for the gaussian process to learn the
for the gaussian process to learn the
latent
latent
space okay because it it really likes
space okay because it it really likes
normally distributed data
but that like you're the tales of that
but that like you're the tales of that
distribution are going to grow and the
distribution are going to grow and the
tals are
tals are
important okay
um and if you set there's a mean
um and if you set there's a mean
function in a gin process right which
function in a gin process right which
defines what the function does when
defines what the function does when
you're not near any data
you're not near any data
points so if you have
points so if you have
uh a normally distributed data then as
uh a normally distributed data then as
that function grows uh basically the
that function grows uh basically the
gaum process is going to try to drag
gaum process is going to try to drag
points down at the extremities very
points down at the extremities very
aggressively and in a way that you
aggressively and in a way that you
cannot control whereas if you have it
cannot control whereas if you have it
zero or one scale then at the
zero or one scale then at the
extremities it's always going to be the
extremities it's always going to be the
same drag Force
essentially so here we go with both
essentially so here we go with both
linear I think I left the aggressive
linear I think I left the aggressive
scaling in here
scaling in here
we'll see in a second if this is too
aggressive it is covering the full space
pretty
pretty
good pretty good
maybe too many points over here you
maybe too many points over here you
could
could
argue um let's try on the log task or
argue um let's try on the log task or
the not the log task percentile
task and we need to remember to scale
task and we need to remember to scale
this uh this will be taking care of for
this uh this will be taking care of for
you once I'm
you once I'm
done we're just testing some
stuff I want good coverage in all three
stuff I want good coverage in all three
tasks
this is fair
one of my other favorites
here honestly open ai5 wins by such a
here honestly open ai5 wins by such a
huge
margin
margin
yeah I think from that
yeah I think from that
era open A5 is the most important paper
era open A5 is the most important paper
obviously we're emitting like pure
obviously we're emitting like pure
algorithm stuff like yeah the PO paper
algorithm stuff like yeah the PO paper
obviously but if you want to read one
obviously but if you want to read one
paper in RL you read the opening I5
paper model free deepl
algorithms is this from Eugene's
algorithms is this from Eugene's
lab we built
huh Eugene's at NYU this is
CMU ha that's
funny so I've never heard of any of
funny so I've never heard of any of
these algorithms but apparently that
these algorithms but apparently that
doesn't matter because po
doesn't matter because po
wins which is
wins which is
funny it's very
funny it's very
funny poo normally does win
I want to
I want to
so this is
so this is
good
good
um I have you I can kind of
um I have you I can kind of
understand I have questions for you and
understand I have questions for you and
I have big questions for you
where's the 150 Point all right
where's the 150 Point all right
here
so oh but this is with the aggressive
so oh but this is with the aggressive
schedule
yeah that's too
much it's approximately double
much it's approximately double
cost let me think about
that double cost
that seems too aggressive
right okay here's another way of
right okay here's another way of
thinking about this right
so if you want to go from 100 million to
so if you want to go from 100 million to
10 billion which is like a reasonable
10 billion which is like a reasonable
experiment
experiment
range
right
oops this give you four other way around
okay
so you need to double between six and
so you need to double between six and
seven times to do that so do you want to
seven times to do that so do you want to
be able your hyperparameter tuner to be
be able your hyperparameter tuner to be
able to in the course of seven
able to in the course of seven
experiments go from 100 million to 10
experiments go from 100 million to 10
billion no that seems way too
billion no that seems way too
aggressive what about
1.5 11 and 12
1.5 11 and 12
experiment a little
experiment a little
better what 25 is going to be 20
better what 25 is going to be 20
experiments
experiments
okay and then an additional 10
okay and then an additional 10
experiments to scale outward from there
that's kind of what we would go
for we're going to find a precise way to
for we're going to find a precise way to
tune into
this in a bit but for now let's just
this in a bit but for now let's just
crank it down a little
bit the other thing we can check is how
bit the other thing we can check is how
many experiments it actually
took I mean this is kind of an outlier
took I mean this is kind of an outlier
like this all looks mostly fine
the thing is I think this Point's higher
try this again see if I like this one
try this again see if I like this one
more and then I guess we
will I mean there's still some
will I mean there's still some
modifications to make
oh
where's their
comparison holy I did not know about
comparison holy I did not know about
this
this
I missed that that's
crazy solid
paper e
it's a very good
paper this is actually going to be my
paper this is actually going to be my
this might be I'm going to have to see
this might be I'm going to have to see
how well done this is but if this is
how well done this is but if this is
done correctly um then this will be my
done correctly um then this will be my
candidate
candidate
for probably most useful RL paper I've
for probably most useful RL paper I've
seen this
seen this
year good
year good
job 11 pager read this thing guys this
job 11 pager read this thing guys this
thing looks this is like the first thing
thing looks this is like the first thing
I've seen that looks legitimately worth
I've seen that looks legitimately worth
reading in a long time the only thing is
reading in a long time the only thing is
do they have how many games do they have
yeah they don't have
um they need more ends is what they
need all
I would not trust open spiels
I would not trust open spiels
implementation Over clean
RL absolutely
not DM is not open I follow you but your
not DM is not open I follow you but your
DMs are not open Pi if you want me to
DMs are not open Pi if you want me to
message you for free
message you for free
compute and things keep your DMs on open
compute and things keep your DMs on open
open on Twitter
folks okay so we
folks okay so we
have
interesting let's see what this
was okay this curve looks very good and
was okay this curve looks very good and
then they're two bad
points it's kind of crazy that there can
points it's kind of crazy that there can
be two points that miss that
heavily okay and just to confirm
let's do
um let's try log
[Music]
this I was really hoping that they would
this I was really hoping that they would
have run that over way more environments
have run that over way more environments
way more interesting environments than
way more interesting environments than
just hex and tic tac
toe e
interesting how much that changes the
interesting how much that changes the
Dynamics I think that makes sense
Dynamics I think that makes sense
though the mean functions get all messed
up I guess I could try to adjust the
up I guess I could try to adjust the
mean
mean
[Music]
functions okay let me see maybe this
functions okay let me see maybe this
isn't
isn't
terrible
terrible
so this was before
no it's not like this magically fixes it
no it's not like this magically fixes it
so that it never makes any errors
right so I'm going to prefer I'm going
right so I'm going to prefer I'm going
to prefer this
to prefer this
one until I've given compelling evidence
one until I've given compelling evidence
to the
contrary these are very very similar
curves so we don't need need to worry
curves so we don't need need to worry
about that one then for now good
um we should double check this on the
um we should double check this on the
linear task real
quick Max 4 200 here
just to make sure we didn't somehow
just to make sure we didn't somehow
break this I highly doubt it
but
yeah highly doubt we'll have broken this
yeah highly doubt we'll have broken this
but might
of e
play e
let just do that
it's good to
it's good to
me your
lime little aggressive but not terrible
I almost want to make the uh the total
I almost want to make the uh the total
time steps parameter
time steps parameter
like its own thing CU it's the parameter
like its own thing CU it's the parameter
that influences cost the most obviously
that influences cost the most obviously
and
um I don't know you could probably do
um I don't know you could probably do
something with
something with
it but this is mostly
fine Emory
fine Emory
what who that
is okay
is okay
let me see if there's um there is a
let me see if there's um there is a
little Quirk that I wanted to address
little Quirk that I wanted to address
with this
with this
algorithm not going to matter as much
algorithm not going to matter as much
for the synthetic tasks I think
but yeah okay so right
but yeah okay so right
here what happens if you improve an
here what happens if you improve an
existing
existing
Point okay
Point okay
so you are
so you are
nearest Paro YT is going to be some
nearest Paro YT is going to be some
score you come up with a better score
score you come up with a better score
for the same
for the same
point the nearest Paro distance will be
zero okay
that's really
bad what if we took the point to the
bad what if we took the point to the
right
so you take the score of the nearest
so you take the score of the nearest
point to the left and then the distance
point to the left and then the distance
of the nearest point to the right does
of the nearest point to the right does
that do it
I got to figure out how to handle
I got to figure out how to handle
bounds with that but yeah yeah
well then what if there's a burrito
well then what if there's a burrito
point right next to
you we can start with this
for e
nearest parito
distance e
L
difference e
so this sets it to zero if there's
so this sets it to zero if there's
nothing to the
nothing to the
right which means you can never go to
right which means you can never go to
the right which is
bad for
I can clip it I don't know if that's
I can clip it I don't know if that's
going to
enough I guess I can explain this in the
meantime Okay so
blueprint speaking of blueprint I should
blueprint speaking of blueprint I should
take that
those look like it is increasing in uh
those look like it is increasing in uh
the score is
the score is
increasing ratings are infinite
increasing ratings are infinite
lovely we'll have to fix
lovely we'll have to fix
that interesting to know how ratings are
that interesting to know how ratings are
infinite but it seems to still be
infinite but it seems to still be
working that's a little bit disturbing
ratings are no longer
infinite got all the infinite Alpha out
infinite got all the infinite Alpha out
of
there oh yeah
okay I'm actually curious to see what
okay I'm actually curious to see what
this looks like CU this might actually
this looks like CU this might actually
be a decent run be
be a decent run be
funny that's actually one of the
funny that's actually one of the
cleanest runs
ironically it's a very nice
ironically it's a very nice
spread let me figure out why these are
spread let me figure out why these are
infinite real quick
and then we'll go through the
and then we'll go through the
algorithm where the changes
least okay
can you check if is in
oh so that's actually funny so what that
oh so that's actually funny so what that
probably did is um it just kept pushing
probably did is um it just kept pushing
it aggressively to the right and because
it aggressively to the right and because
the model happened to be good enough
the model happened to be good enough
that's why you got the very nice
that's why you got the very nice
spread heavily rewarded for going off to
spread heavily rewarded for going off to
the right so we'll keep that in mind
the right so we'll keep that in mind
so here's what uh here's the deal at the
moment you have an underline curve
moment you have an underline curve
you're trying to discover that probably
you're trying to discover that probably
looks something like this right you got
looks something like this right you got
a parito point over here you got a
a parito point over here you got a
parito point over here you got a bunch
parito point over here you got a bunch
of points you don't care about
of points you don't care about
here you have a predictive model that
here you have a predictive model that
will try to get you a good set of hyper
will try to get you a good set of hyper
parameters somewhere here so where
parameters somewhere here so where
should you
should you
sample uh so well what this is at the
sample uh so well what this is at the
moment is that you should take if you're
moment is that you should take if you're
going to try to assess how good this
going to try to assess how good this
point is and what you care about is you
point is and what you care about is you
care about this
care about this
height and this
distance both of these are nicely
distance both of these are nicely
normalized because you know this curve
normalized because you know this curve
could come to you with any scale this
could come to you with any scale this
way and any scale this way so we've
way and any scale this way so we've
normalized everything to be pretty clean
normalized everything to be pretty clean
let me just ban that
bot um and it says you should multiply
bot um and it says you should multiply
these
these
things so you take this distance so this
things so you take this distance so this
is distance so this is a this is B then
is distance so this is a this is B then
you do a *
B for
this is the graph that matters
this is the graph that matters
here let's see what this just did for us
I think this will be a good but not
I think this will be a good but not
quite as good as the uh the previous one
so okay actually that's very nice that's
so okay actually that's very nice that's
very stable it only goes out to 50 is
very stable it only goes out to 50 is
the
problem very nice graph only goes to 50
so the thing that we have to think about
so the thing that we have to think about
here is what happens if you sample why
here is what happens if you sample why
is this an
object
hello
hello all right uh what happens if you
hello all right uh what happens if you
say samp Le a point
say samp Le a point
here and what happens if you sample a
here and what happens if you sample a
point here these are the
point here these are the
two
difficulties that need to be
difficulties that need to be
addressed because then you you need to
addressed because then you you need to
somehow do this distance and you need to
somehow do this distance and you need to
somehow
do uh this
do uh this
distance right so both of these are
distance right so both of these are
problem
on e
I'm trying to think what would be the
I'm trying to think what would be the
most principled way to choose
most principled way to choose
this cuz really all we're stuck with our
this cuz really all we're stuck with our
Edge conditions and actually I think
Edge conditions and actually I think
that this probably explains why our uh
that this probably explains why our uh
our pong algorithm was bad before as
our pong algorithm was bad before as
well it kept trying to go for these
well it kept trying to go for these
really cheap runs because it was looking
really cheap runs because it was looking
at this distance and saying look you
at this distance and saying look you
know look how much uh benefit I get by
know look how much uh benefit I get by
taking this distance
do you use the mean the medium
I mean we could try some stuff
we can do me
cost for
me clost
me clost
STP then we can
STP then we can
do for
break point in here
somewhere should be able to do this I'm
somewhere should be able to do this I'm
just getting
just getting
tired let me
see less than zero is infinite
oh
something like this
probably let's see how this works and
probably let's see how this works and
then decide to clean it up or
not just take the spread of
not just take the spread of
points just to sign at the mean I think
points just to sign at the mean I think
mean's better than median robust to
clustering median could be better I
clustering median could be better I
don't
know I think the mean is
know I think the mean is
just fine oh median doesn't even make
just fine oh median doesn't even make
yeah median is more annoying to compute
yeah median is more annoying to compute
in this
case algorithm does not agree algorithm
case algorithm does not agree algorithm
says not happy
apparently we will be interested to see
why e
silly
okay that looks really
okay that looks really
good it's just pretty passive is
all I mean
can't we control that
with I don't know if we can control that
with I don't know if we can control that
with scale can
with scale can
we let me see if I just set this to like
we let me see if I just set this to like
three or something does this like change
three or something does this like change
it I don't know if it does because this
it I don't know if it does because this
is now in the scoring function that
is now in the scoring function that
we've changed things
I mean me and parito point distance
I mean me and parito point distance
seems fine to me
see we'll see if this uh this does
anything this is very clean
oh okay
that's pretty
that's pretty
solid to
100 but the scale I think has limited
100 but the scale I think has limited
has a limited effect
hold on maybe this is a good thing
hold on maybe this is a good thing
though maybe this is a good
though maybe this is a good
thing yeah wait I
thing yeah wait I
was okay I
was okay I
see I think I know what
see I think I know what
happened give me a second and then I
happened give me a second and then I
will let me just confirm that I'm right
will let me just confirm that I'm right
here
yeah okay so you were kind of getting
yeah okay so you were kind of getting
you were there was kind of like double
you were there was kind of like double
incentive to really spread the graph out
incentive to really spread the graph out
before and the
reason
here actually we will go back to the
here actually we will go back to the
[Music]
[Music]
diagram so the reason here is you get
diagram so the reason here is you get
rewarded for this distance right and you
rewarded for this distance right and you
also get rewarded for this
also get rewarded for this
distance so
distance so
the way the algorithm works right is you
the way the algorithm works right is you
sample a whole bunch of points around
sample a whole bunch of points around
the existing
the existing
points uh and you get rewarded for being
points uh and you get rewarded for being
having the prediction be better than the
having the prediction be better than the
nearest point to the left and then you
nearest point to the left and then you
get rewarded for being farther than the
get rewarded for being farther than the
nearest point to the right or whatever
nearest point to the right or whatever
so in the original algorithm uh before I
so in the original algorithm uh before I
made these
made these
changes you're incentivized to put the
changes you're incentivized to put the
point as far to the right as possible
point as far to the right as possible
both by the fact that that's probably
both by the fact that that's probably
going to get you higher score but also
going to get you higher score but also
by directly this distance uh farther to
by directly this distance uh farther to
the
the
right so
right so
now instead of just putting the
now instead of just putting the
point as far to the right as
point as far to the right as
possible me
think you're still incentivized by the
think you're still incentivized by the
cost to put the point as far to the
cost to put the point as far to the
right as possible Right
right as possible Right
but we've just made it less aggressive
but we've just made it less aggressive
because uh you get the mean distance
because uh you get the mean distance
between points instead of just getting
between points instead of just getting
the however far you're able to put it
out okay
so actually this is good because this
so actually this is good because this
means that you
means that you
are you're driving the frontier
are you're driving the frontier
exploration via uh cost Improvement not
exploration via uh cost Improvement not
via I mean via score Improvement not via
via I mean via score Improvement not via
cost
Improvement now the only difficulty here
Improvement now the only difficulty here
is still very passive
I mean this is with a crazy coefficient
I mean this is with a crazy coefficient
set
set
still not spread out the way we'd
still not spread out the way we'd
want not
quite you can't just crank up that
quite you can't just crank up that
coefficient either you can't just crank
coefficient either you can't just crank
that coefficient indefinitely
I can stick it at two I
think highest you want
but then the rest of
it an example that we
it an example that we
like like this this good
honestly this one is really
nice just so
passive why is this so
passive 3x and it goes out to 100
you don't want to 3x though it's
just e
yeah this isn't
yeah this isn't
bad
2x let's think about the knobs that we
2x let's think about the knobs that we
control
control
here because it should just be a matter
here because it should just be a matter
of tuning this thing a bit now right
we have length scale set
that's a really big length scale for a
that's a really big length scale for a
matern isn't
it this is going to make it even more
it this is going to make it even more
passive though isn't
passive though isn't
it me see
maybe
not this lung scale might need to be set
not this lung scale might need to be set
to to actually 0.1 one come to think of
it yeah the uh the length the scale
it yeah the uh the length the scale
length is crazy right
length is crazy right
now I think that makes it trust the
now I think that makes it trust the
matern Fel like hugely across the whole
matern Fel like hugely across the whole
Space not great
seems to make it uh it worse
seems to make it uh it worse
though yeah so it's less
though yeah so it's less
aggressive the matur has to fall off and
aggressive the matur has to fall off and
the linear has to take
over so this didn't help
what are the knobs can we fiddle with
I mean the ironic thing here is that
um probably if I just do this
let me see if I understand if I
let me see if I understand if I
understand this
correctly then this should be very
correctly then this should be very
effective if I understand
correctly
e
e e
interesting so hang on this
worked this was what we had from 2x
worked this was what we had from 2x
scale
scale
right I think this is in the
middle
okay
so this one ended up pretty far
out that's a crazy jump so actually wait
out that's a crazy jump so actually wait
this is not a crazy jump because it's
this is not a crazy jump because it's
allowed to like double almost right or
allowed to like double almost right or
1.4x yeah so it's allowed to go up to
1.4x yeah so it's allowed to go up to
like about that much actually it could
like about that much actually it could
go up to like 20 yeah 28 this is about
go up to like 20 yeah 28 this is about
what it's allowed to do so it's about
what it's allowed to do so it's about
the max jump
the max jump
distance
distance
um this is perfectly clean so I am happy
um this is perfectly clean so I am happy
with this
let me try something because I think I
let me try something because I think I
understand this now but I think that um
understand this now but I think that um
in order to really sell
in order to really sell
it we need to
do so this is what
do so this is what
happens at the
happens at the
extreme when you are really heavily
extreme when you are really heavily
rewarded for scaling
rewarded for scaling
to
to
uh points off to the
right it should just go up
constantly oh hey
yeah oh this is a different n y Sharm
yeah oh this is a different n y Sharm
looks like huh I know a different one
yeah that's not good news good luck but
yeah that's not good news good luck but
that's not good news right
that's not good news right
there poor
there poor
folks oh
folks oh
man raising 1.2 mil Fe is
brutal oh was
brutal oh was
I no this is Rivals right yeah yeah yeah
I no this is Rivals right yeah yeah yeah
that's just silly
okay so right here this
is yeah this is the really aggressive
is yeah this is the really aggressive
expansion
setting all right so this is actually
setting all right so this is actually
this will be very good data then so this
this will be very good data then so this
is with
is with
2X and then
2X and then
this the exact same thing just rewarding
this the exact same thing just rewarding
you way more for going off to the right
it's funny that you don't get the
it's funny that you don't get the
distribution you'd
distribution you'd
expect it does push to
expect it does push to
200 it only makes one major error
I would think that's pretty good
overall e
you could take the Max and instead of
you could take the Max and instead of
the
mean let me think about that
hey how's it
going we
going we
are working on this hyper pram sweep
algorithm It's Tricky it's going to be
algorithm It's Tricky it's going to be
really good when it's done
really good when it's done
though very very good indeed
m
it's funny how much pressure this thing
it's funny how much pressure this thing
needs
I mean I guess it makes sense
actually let me there's one thing I want
actually let me there's one thing I want
to look at
it's occurred to me that the reason that
it's occurred to me that the reason that
we need to add such
aggressive aggressive parameter so that
aggressive aggressive parameter so that
it keeps finding more expensive points
it keeps finding more expensive points
is we have two different Gan processes
is we have two different Gan processes
one of them's pulling this way and the
one of them's pulling this way and the
other's pulling this way we're pulling
other's pulling this way we're pulling
it straight back
down1 unit away contributes half as much
well I have a lot left to
well I have a lot left to
learn oh please don't uh don't mistake
learn oh please don't uh don't mistake
this for me knowing what is going on
this for me knowing what is going on
here this is not the type of stuff that
here this is not the type of stuff that
I normally do
either I just figure that regard
either I just figure that regard
regardless of the uh you know the lack
regardless of the uh you know the lack
of heavy probability and stats
of heavy probability and stats
background um I've at least seen these
background um I've at least seen these
things before and I know enough about
things before and I know enough about
how reinforcement learning is supposed
how reinforcement learning is supposed
to work to be in a here this is what I
to work to be in a here this is what I
generally how I generally look at stuff
generally how I generally look at stuff
right I might not always know what I'm
right I might not always know what I'm
doing but I'm the most qualified to
doing but I'm the most qualified to
figure it
figure it
out that's a fine place to be
I'm not the most qualified to be
I'm not the most qualified to be
specifically looking at this math but
specifically looking at this math but
overall for getting this thing working
overall for getting this thing working
in RL practically
yeah e
h
that even have fall off I don't think it
that even have fall off I don't think it
does I don't think the linear kernel has
does I don't think the linear kernel has
fall
fall
off no localized Decay yep
do we need the linear
kernel without p
colel what happens without the linear
kernel I mean where making progress It's
kernel I mean where making progress It's
a lot of two steps forward one step back
a lot of two steps forward one step back
but um the main thing from today has
but um the main thing from today has
been that all the data is very nicely
been that all the data is very nicely
normalized now so in the actual space
normalized now so in the actual space
that you're learning um this axis goes
that you're learning um this axis goes
from 0 to one this axis goes from 0 to
from 0 to one this axis goes from 0 to
one there are few other improvements
one there are few other improvements
around that it's a little harder than it
around that it's a little harder than it
would normally be just to scale your
would normally be just to scale your
data duh
and it looks like you need the linear
kernel you really shouldn't
let's see if we actually maybe we get
let's see if we actually maybe we get
something similar to the uh the original
something similar to the uh the original
plot which was which one was
it and that went to
12 only up to eight
it's very
clean but
um you can see the predictions getting
um you can see the predictions getting
pulled
down put the linear kernel back
I'm trying to think what the most
I'm trying to think what the most
principled way of doing this
principled way of doing this
is I could make it a meta hyper
is I could make it a meta hyper
perameter we're trying to avoid those if
perameter we're trying to avoid those if
we can
we can
but I see we have new YouTube people so
but I see we have new YouTube people so
here I'll go through the thing again
here I'll go through the thing again
maybe I'll figure it out in the process
maybe I'll figure it out in the process
of going through it
oops so the way this algorithm works
right this is the curve that you're
right this is the curve that you're
trying to fit this axis is cost which is
trying to fit this axis is cost which is
how long it takes the r the experiment
how long it takes the r the experiment
to run this axis is
to run this axis is
score this is how well your experiment
score this is how well your experiment
does this is the Paro front this is the
does this is the Paro front this is the
set of like a best experiments in a
set of like a best experiments in a
sense where you can't make the
sense where you can't make the
experiment any faster and also better
experiment any faster and also better
so let's say that you have two existing
so let's say that you have two existing
experiments like this these are optimal
experiments like this these are optimal
experiments maybe you have some others
experiments maybe you have some others
over here that we don't care about the
over here that we don't care about the
way they algorithm works is you generate
way they algorithm works is you generate
a bunch of candidate points to score in
a bunch of candidate points to score in
here and then you uh you score them as
here and then you uh you score them as
follows for a candidate here you're
follows for a candidate here you're
going to score it by
multiplying this distance
multiplying this distance
a
a
by this distance B
and the idea there is that you
and the idea there is that you
incentivized to uh improve the score
incentivized to uh improve the score
over the nearest optimal point and then
over the nearest optimal point and then
you're incentivized to spread them out
you're incentivized to spread them out
so that you don't put a point near an
so that you don't put a point near an
existing optimal
existing optimal
Point uh the problem is when you have to
Point uh the problem is when you have to
score a point here or here right then
score a point here or here right then
you have this distance and you have this
you have this distance and you have this
distance uh so figuring out what to use
distance uh so figuring out what to use
there is
difficult and that's what we're trying
difficult and that's what we're trying
to figure
out so I have some ideas for the one on
out so I have some ideas for the one on
the right that I've been trying what
the right that I've been trying what
about the one on the left maybe I should
about the one on the left maybe I should
think about that one maybe that'll give
think about that one maybe that'll give
me some
Clues so for this one we want the cost
Clues so for this one we want the cost
difference
the difference in
the difference in
cost nice pdb
logo
what or do I have a pdb logo
h
well maybe this gives me some Clues
well maybe this gives me some Clues
because you definitely can't use the Max
because you definitely can't use the Max
cost difference
cost difference
right the
puffer it is just the shell prompt
puffer it is just the shell prompt
yeah we just use when you have uh it
yeah we just use when you have uh it
tells you that you're in the container
tells you that you're in the container
so if you download puffer tank puffer
so if you download puffer tank puffer
tank comes with a puffer is the prompt
tank comes with a puffer is the prompt
you can obviously change it but that's
you can obviously change it but that's
what we use Puffer tank comes fully
what we use Puffer tank comes fully
loaded with my editor setup and with the
puffer okay you know this is kind of
puffer okay you know this is kind of
informative
informative
because if you just keep assuming that
because if you just keep assuming that
you're going to use like the maximum
you're going to use like the maximum
difference or some large value you're
difference or some large value you're
going to keep trying to put points here
going to keep trying to put points here
you know you're going to keep trying to
you know you're going to keep trying to
put points over here even if they are
put points over here even if they are
know very close
however cost is normalized between Zer
however cost is normalized between Zer
and one isn't
it cost will go to
it cost will go to
zero at the
minimum so
I can just have that one be
zero I think I solve that one on the
zero I think I solve that one on the
left I should just be able to have that
left I should just be able to have that
one be zero score is normalized cost is
one be zero score is normalized cost is
normalized so the one on the left should
normalized so the one on the left should
be able to just go to
zero that's not
zero that's not
bad but hold on I don't think I do this
bad but hold on I don't think I do this
score in normalized space
GP
GP
YT Pito
YT YT
is so I would have to do this in YT Norm
space and then the distance
space and then the distance
I think the distance is done
in standard cost
space if I were to do both of these in
space if I were to do both of these in
Norm space which would require me to
Norm space which would require me to
rescale some things but I think I
rescale some things but I think I
probably
probably
should that would have some nice
should that would have some nice
interpretations
the maximum possible Square would be one
the maximum possible Square would be one
because the maximum difference on this
because the maximum difference on this
axis will be one and the maximum
axis will be one and the maximum
difference on this axis will be
one that would be
good and then I could use
I could just use
I could just use
one as the
one as the
distance that probably
works I want to try that that sounds
works I want to try that that sounds
very
very
good I think that that yeah I think this
good I think that that yeah I think this
is the
is the
way
okay so
first thing we will need to
do PYT
here is
pito
pito
okay nearest Pito
this one's a a little
this one's a a little
annoying but I should just be able to
annoying but I should just be able to
do see
do see
right
reto log C Norm
GP log C
norm and then we
norm and then we
do equal to
1us
1us
GP
nor let just make sure this works
you could also just set it to one
if this works this will be very
nice um that should not be should be a
nice um that should not be should be a
different
different
shape I guess it's fine yeah
oh it's a tensor
actually let's just do one for
actually let's just do one for
now think that'll be the
simplest actually hold on no it does
simplest actually hold on no it does
need to be one minus otherwise it
need to be one minus otherwise it
doesn't make
doesn't make
sense we have to finish the full
sense we have to finish the full
implementation then we'll be able to see
implementation then we'll be able to see
if it's good
this is gross but they should
run suggestion scores
hey
hey
welcome seriously how's this still a
welcome seriously how's this still a
problem
problem
uh 372
uh 372
see right fre to log
see right fre to log
c
c where's the other
c where's the other
one right here
we'll see if this
we'll see if this
works and if so I will go through
works and if so I will go through
it okay cool so what I did
it okay cool so what I did
here uh is I moved the scoring function
here uh is I moved the scoring function
so what happens here is Right internally
so what happens here is Right internally
uh this data comes into us in whatever
uh this data comes into us in whatever
format it comes in and then we turn it
format it comes in and then we turn it
into zero to one so this will be one one
into zero to one so this will be one one
and zero both of these
and zero both of these
axes um but I was still doing the
axes um but I was still doing the
scoring function in the original space
scoring function in the original space
so now if I do the scoring function in
so now if I do the scoring function in
the in the latent space first of all
the in the latent space first of all
it's a 0o to one function or I guess
it's a 0o to one function or I guess
negative 1 to one if you m if you mess
negative 1 to one if you m if you mess
up so it's nicely
up so it's nicely
bounded and on top of
bounded and on top of
that
that
we uh I think the boun problem gets
we uh I think the boun problem gets
fixed for us because see if this is at
fixed for us because see if this is at
zero the issue that we were having is we
zero the issue that we were having is we
didn't know how to score this point
didn't know how to score this point
because usually it's based on the point
because usually it's based on the point
to the left right normally you would if
to the left right normally you would if
you're looking at this point you would
you're looking at this point you would
go to the one to the left and look at
go to the one to the left and look at
this distance here so there's no point
this distance here so there's no point
to the left to look at but since it's
to the left to look at but since it's
normed to zero and you can actually go
normed to zero and you can actually go
all the way to zero uh we just get to
all the way to zero uh we just get to
use the this distance here which
use the this distance here which
actually I think I forgot to do in this
actually I think I forgot to do in this
update so I will fix that
update so I will fix that
um and then the one here uh this one is
um and then the one here uh this one is
going to be slightly more complex but if
going to be slightly more complex but if
you put a point here and this is at X
you put a point here and this is at X
then it's just one minus
then it's just one minus
X right so it's just this distance cut
X right so it's just this distance cut
off at
off at
one because we know the axis goes to
one because we know the axis goes to
one that's quite
good now where is the mean oh we have to
good now where is the mean oh we have to
rescale everything though to do this
rescale everything though to do this
which is a little
which is a little
annoying so we have to we have a little
annoying so we have to we have a little
bit of work to do
here
oops so
oops so
zero
zero
Z zero
okay run it again just to make sure it
okay run it again just to make sure it
doesn't fix and then
um from there we can actually figure
um from there we can actually figure
some stuff
out is very very
out is very very
good I can tell we're getting very close
good I can tell we're getting very close
to having this thing done it's just it's
to having this thing done it's just it's
going to be I mean this is a a
going to be I mean this is a a
sizable project this investment I think
sizable project this investment I think
this will pay
off
e e
all right what does
all right what does
this what's this look like obviously
this what's this look like obviously
it's not a full
curve
interesting uh
huh the predictions are not
huh the predictions are not
bad yeah no the predictions are quite
bad yeah no the predictions are quite
accurate
accurate
right yeah these are the early ones you
right yeah these are the early ones you
can ignore the blue ones these
can ignore the blue ones these
predictions are quite
predictions are quite
accurate oh uh the red dots are
accurate oh uh the red dots are
clustered up you can kind of see it
right let me make sure that's
correct uh they looked like they were
correct uh they looked like they were
clustered up hold
clustered up hold
on clustered one yeah one two 3 4 see
this so this should not be allowed to
happen this should give you very very
happen this should give you very very
low
low
score so that means we have a
bug suppos is better than the thing
bug suppos is better than the thing
being implemented correctly and not
being implemented correctly and not
working
h
e
e e
you have your
differences nearest Paro distance
oh hold
oh hold
on let me see
something it put this one then this one
something it put this one then this one
then this one then this
one and earlier on it
did this one then this one
that shouldn't happen there is a check
that shouldn't happen there is a check
on that
it is very difficult to take care of
it is very difficult to take care of
scaling though
yeah because you
yeah because you
can't the problem is that no matter how
can't the problem is that no matter how
you scale it there's always going to be
you scale it there's always going to be
weird stuff in lat
space so the only thing I can the only
space so the only thing I can the only
thing I can really do
cost is in log space as well
right you kind of want it in linearized
right you kind of want it in linearized
log space
let's do
let's do
that so we'll leave the C alone I think
that so we'll leave the C alone I think
that we got the
that we got the
cost I think what we screwed up for
score we want Pito C for
okay so we do
okay so we do
this and then we do
this and then we do
Pito
Pito
C I have Norm did I already do
C I have Norm did I already do
that I think
so and then this is
GPC when we have
GP log C GP log C
nor
nor
GPC okay so now this is
01 right
now we do Pito C
now we do Pito C
Norm minus
Norm minus
GPC
norm and then I think we do
abs
abs and then this will always work
abs and then this will always work
so we can just do nearest Pito
distance
men we will see if this
works I'm use rest real quick be right
back
e
e
e e
well that's
well that's
uh that's a result
um well it magically works it makes a
um well it magically works it makes a
couple mistakes though
magically works but makes a couple
mistakes which
are is that easily fixable
I think that's easily
fixable
fixable
yeah that
yeah that
is easily
is easily
fixable
fixable
okay we figured out how to do
okay we figured out how to do
that
that
um where do we put the clipping on
suggestions
suggestions
clip GP
cost
cost
oh that's kind of
oh that's kind of
awkward hang
on we do clip the
on we do clip the
suggestions but then it overestimates
why would it do such a
thing it's got nothing better to
do
look what you
look what you
doing trying to fix a hyper parameter
doing trying to fix a hyper parameter
sweep
sweep
algorithm this would be a major
algorithm this would be a major
contribution across the whole whole
contribution across the whole whole
stuff a whole set of RL things that
stuff a whole set of RL things that
we're
we're
doing if I can get this thing to work it
doing if I can get this thing to work it
depends how much better it works than
depends how much better it works than
the originals but if I get this thing
the originals but if I get this thing
working substantially better than carbs
working substantially better than carbs
this will be a major major win for the
field that's cool
field that's cool
if you type too many things or you put
if you type too many things or you put
links or stuff sometimes YouTube will
links or stuff sometimes YouTube will
eat
eat
them I don't have it set up to do that
them I don't have it set up to do that
it just does
it so the only thing I I have questions
it so the only thing I I have questions
on why are there so many points right at
on why are there so many points right at
the end here right
can't do anything over here over
here it's probably the exponential score
here it's probably the exponential score
rating
right we have to be
0.04 yeah it's got to be
that the score differences get
that the score differences get
accentuated
dramatically that's actually kind of a
dramatically that's actually kind of a
tough one to fix
tough one to fix
let me try something real quick just to
test Rani
okay this is
something oh wait wait the initial curve
something oh wait wait the initial curve
on this
on this
is initial curve on this is really good
some of the predictions are a bit
some of the predictions are a bit
off let me
see if nothing else this will show us
see if nothing else this will show us
that we
that we
uh the last piece to look at is really
uh the last piece to look at is really
looking at the score Norm
still doing it
Arizona is a perfectly fine
Arizona is a perfectly fine
state had some friends from
there that's pretty
there that's pretty
good now it's like way over sampled
good now it's like way over sampled
right here right yeah so it's way over
right here right yeah so it's way over
sampled this
sampled this
thing three four five but that's not
thing three four five but that's not
terrible that's not
terrible it's quite
clean less than a quarter of the compute
clean less than a quarter of the compute
spent
should be like half shouldn't
it and that was pretty darn aggressive
it and that was pretty darn aggressive
how it did that me go look at the auto
Fram oh it's not
Fram oh it's not
H let me look at some of these
H let me look at some of these
jumps 26 to 34
jumps 26 to 34
51 to 6
4 yeah these jumps are all within the
4 yeah these jumps are all within the
allowed
range
interesting I almost want to make it
interesting I almost want to make it
jump slower
jump slower
here now that we have this
and then W to play with that scaling
Factor try
this just to see
this might be too
passive could work
good Twitter day for RL I
guess
guess
6908 very nice
uh yeah so this is too
uh yeah so this is too
slow it's kind of funny that literally
slow it's kind of funny that literally
that's all I changes this one scale
that's all I changes this one scale
factor right it's all that changes the
factor right it's all that changes the
one scale factor and it's really really
one scale factor and it's really really
cripples
it
it
okay so uh this is our
chart what do we do about the
what do we do about the score
I mean any way you look at this this is
I mean any way you look at this this is
too
too
aggressive you should not spend so much
aggressive you should not spend so much
of your compute on these long
of your compute on these long
experiments I mean I it's fine here I
experiments I mean I it's fine here I
suppose but
suppose but
um and this is why we'll need the real
um and this is why we'll need the real
benchmarks I think what's going to
benchmarks I think what's going to
happen in a real end where it's harder
happen in a real end where it's harder
to model the performance is that this is
to model the performance is that this is
going to push it to expensive
going to push it to expensive
experiments too quickly
so why does it do this
it thinks that it's going to
it thinks that it's going to
be getting like 10%
higher so this is Max four
prediction and this is like
prediction and this is like
0.1 because it's a 10% increase
0.1 because it's a 10% increase
so yeah 0.1.0 yeah that tracks okay so
so yeah 0.1.0 yeah that tracks okay so
that's
screwy does it find anything better than
screwy does it find anything better than
this
this
after doesn't really find very many
after doesn't really find very many
things better than this as
well this one is .13 yeah
well this one is .13 yeah
okay um
do we have to cap this cost
prediction get rid of that
how do we cap the clost prediction
no you can't cap it it's a
prediction okay that's an
prediction okay that's an
issue that is an
issue hold on shouldn't this be
zero this work
let
see yeah and we can't even cut it off
see yeah and we can't even cut it off
that's yeah that's obnoxious okay
that's yeah that's obnoxious okay
0 to one normed
how's it over predicting cost in the
how's it over predicting cost in the
first
place bad
modeling you're taking the most wrong of
modeling you're taking the most wrong of
a lot of the predictions doing this
yeah that's a that's like that is a
problem well is
it yeah because you should go back and
it yeah because you should go back and
run
shouldn't go back and run more
shouldn't go back and run more
experiments you should be filling in as
experiments you should be filling in as
you go
H hard to
say the problem I'm dealing with at the
say the problem I'm dealing with at the
moment is you don't know the maximum
moment is you don't know the maximum
cost and you're measured by distance to
cost and you're measured by distance to
the nearest cost
so if you just have a wrong cost
so if you just have a wrong cost
prediction you're going to
overshoot that's
tricky who works on Valentine's Day
tricky who works on Valentine's Day
people trying to get [ __ ]
done who watches random Dev streams on
done who watches random Dev streams on
Valentine's Day just to make stupid
Valentine's Day just to make stupid
comments
yeah but you're not making stupid
yeah but you're not making stupid
comments is the thing plasm
plasma this is a tough
plasma this is a tough
one this is just a boundary uh a
one this is just a boundary uh a
boundary problem but I'm not quite sure
boundary problem but I'm not quite sure
how to deal with it
how to deal with it
because there's a really no way to know
because there's a really no way to know
the maximum
the maximum
cost um based on your parameters there's
cost um based on your parameters there's
no way to know
no way to know
that and if the model just predicts over
that and if the model just predicts over
the Max
cost I mean technically it should get
cost I mean technically it should get
better over time like you can
better over time like you can
see 230 216 210 209 like it will
see 230 216 210 209 like it will
eventually correct itself cuz the model
eventually correct itself cuz the model
will get better maybe it's fine there
will get better maybe it's fine there
what if I run this thing for longer what
what if I run this thing for longer what
happens if you do like a
100 prepping for
interviews yeah that's a rough
time it should get better over time
time it should get better over time
because um well there are more data
because um well there are more data
points to
points to
fit it will fit if it's going to fill in
fit it will fit if it's going to fill in
the boundary then that should fix the
the boundary then that should fix the
model at the boundary and then it should
model at the boundary and then it should
explore other regions and then the only
explore other regions and then the only
thing I need to look at then is the
thing I need to look at then is the
score normalization
score normalization
function so we'll run this we'll see if
function so we'll run this we'll see if
I am correct on that and then we'll look
I am correct on that and then we'll look
at the score normalization
at the score normalization
function I think that's the only really
function I think that's the only really
questionable choice
questionable choice
left
right yeah that should be the only
right yeah that should be the only
really questionable choice
left was there a reason I decided to
left was there a reason I decided to
predict log cost
as well instead just
cost let me think about
that I mean that could be that could be
that I mean that could be that could be
varied
yeah there are lots of small things to
yeah there are lots of small things to
tweak still I think the main one that
tweak still I think the main one that
like really the main one we really need
like really the main one we really need
to look at though should be the score
transform okay so by
transform okay so by
now yeah so here you can see right we
now yeah so here you can see right we
did the 200 it went over 200 but now
did the 200 it went over 200 but now
we're getting all sorts of other
we're getting all sorts of other
points it's gone
back and it's got an accurate model okay
back and it's got an accurate model okay
this is perfect this is exactly what we
this is perfect this is exactly what we
want so that problem is just a that's a
want so that problem is just a that's a
very temporary problem the thing that we
very temporary problem the thing that we
ran
ran
into it'll probably drop a few points at
into it'll probably drop a few points at
Max cost if it gets there but then
Max cost if it gets there but then
they'll go back so this is uh this is
they'll go back so this is uh this is
behaving the way that we want it to this
behaving the way that we want it to this
is generally
is generally
good this is probably enough to even
good this is probably enough to even
start doing some real experiments though
start doing some real experiments though
we might want to try it on a few more of
we might want to try it on a few more of
the synthetic tasks
first uh the only one it shouldn't do
first uh the only one it shouldn't do
too well on is I think the percentile
too well on is I think the percentile
task because we messed with the
Epsilon okay
Epsilon okay
so here oh that's
so here oh that's
beautiful
beautiful
holy yeah that's beautiful look at
holy yeah that's beautiful look at
that so the red points come later right
that so the red points come later right
so it filled this in and then it went
so it filled this in and then it went
back substantially into the curve we
back substantially into the curve we
don't really care about the really early
don't really care about the really early
portions of the curve but look at this
portions of the curve but look at this
it filled back in isn't that nice
yeah colors iteration
yeah colors iteration
Index this is the one thing that Neptune
Index this is the one thing that Neptune
doesn't have that I really wish they had
doesn't have that I really wish they had
um it gives you it kind of gives you a
um it gives you it kind of gives you a
third
third
access right this gives you a time AIS
that's like
perfect and so we should be very happy
perfect and so we should be very happy
with
with
this uh do I try this on the percentile
task okay I'm not going to have super
task okay I'm not going to have super
high hopes for the percentile task
high hopes for the percentile task
because of the normalization we're using
because of the normalization we're using
currently
currently
but we will check it
[Music]
is it five
error while Computing log
prob really
y over Max
4 think that might be
4 think that might be
numerical but you have the Epsilon
term me see
you have
you have
y divide by Max 4 really that doesn't
y divide by Max 4 really that doesn't
make sense to
me I accounted for that so something's
weird why is there so much random
garbage on the darn
timeline yes use China's version of x x
timeline yes use China's version of x x
but CCP lovely let's not
no we will not ever do that thank you
no we will not ever do that thank you
I have not once used Tik Tok and I'm not
I have not once used Tik Tok and I'm not
going to
start chamber of low
B I swear short form content causes ADHD
B I swear short form content causes ADHD
it's [ __ ] awful for
you it's like m
you it's like m
I know it'll make me feel better 3 hours
I know it'll make me feel better 3 hours
of scrolling short form content said no
of scrolling short form content said no
one
ever how is this thing
having error Computing log
prob
what n
Jesus I've definitely done longer gaming
Jesus I've definitely done longer gaming
sessions than that but not while
sessions than that but not while
scrolling garbage
I tried to limit that lately though got
I tried to limit that lately though got
a company to
build you got to field this
off well I've definitely done 24 plus
off well I've definitely done 24 plus
there's been some absolutely djun gaming
I don't even remember that was from when
I don't even remember that was from when
I was way younger I've definitely put
I was way younger I've definitely put
like ridiculously long sessions into a
like ridiculously long sessions into a
couple different MMOs
couple different MMOs
though to be fair I got a PhD thesis out
though to be fair I got a PhD thesis out
of
of
MMOs n mostly old school RuneScape
MMOs n mostly old school RuneScape
couple others that are less commonly
known yeah I mean the main thing that my
known yeah I mean the main thing that my
work was known for originally this is
work was known for originally this is
the latest version of it this is uh an
the latest version of it this is uh an
ultra high
ultra high
performance neural EG an ultra high
performance neural EG an ultra high
performance MMO written for
performance MMO written for
reinforcement learning
research
research
oops wrong
button this thing runs at like I don't
button this thing runs at like I don't
know ,000 times real
know ,000 times real
time one of the most complex RL
time one of the most complex RL
environments out
there and a lot of it is taken a lot of
there and a lot of it is taken a lot of
the design and stuff is taken directly
the design and stuff is taken directly
from my knowledge of the internals of
from my knowledge of the internals of
how MMOs are built just from playing
how MMOs are built just from playing
them for so
them for so
long see you
jez okay so YT does have a nan here
that's not supposed to be
that's not supposed to be
possible
possible
um how did that happen
let
say or and cost
somehow it's getting us4 greater than
somehow it's getting us4 greater than
one
uh okay that's
weird so it doesn't actually get to
weird so it doesn't actually get to
there but somehow we have a
there but somehow we have a
score is
not a 1.22 that's not possible at all
output
see self suggestion output score cost is
see self suggestion output score cost is
cost okay
if
cost score greater than one breako right
how does this thing get into
this
e e
if these backwards or something
if these backwards or something
absolutely
insane
insane
score
score
cost score is
cost score is
score cost is
cost oh I'm stupid
my
bad just getting
bad just getting
tired we'll be
good e
hey boss I got this new
hey boss I got this new
what damn it Ryan get out of here
I'm not going to give you neoc carbs
I'm not going to give you neoc carbs
access
early that
case do you know how many [ __ ] DMs I
case do you know how many [ __ ] DMs I
have look let me just show you how
have look let me just show you how
stupid this
stupid this
is this is almost all of this is meme
coin it's all meme coin and sex bots
coin it's all meme coin and sex bots
it's God awful
and it's like I occasionally get client
and it's like I occasionally get client
inquiries through there so it's like
inquiries through there so it's like
that really shouldn't be
spammed can
spammed can
I you know what they should
I you know what they should
do I would just like I would like legal
do I would just like I would like legal
protections against uh against cyber
protections against uh against cyber
attack to be stripped from spammers so I
attack to be stripped from spammers so I
think that legally if somebody spams you
think that legally if somebody spams you
you should be able to Dos them or like I
you should be able to Dos them or like I
don't know try to like just screw with
don't know try to like just screw with
them somehow that's what you should be
them somehow that's what you should be
able to
do I should be able to like you know to
do I should be able to like you know to
set their keyboard to dvorac or
set their keyboard to dvorac or
something and delete the settings files
something and delete the settings files
from their OS for other like layouts I
from their OS for other like layouts I
should just be able to do dumb [ __ ]
what are you working on today neoc carbs
what are you working on today neoc carbs
or well name in
or well name in
progress uh this is getting to be very
progress uh this is getting to be very
good at least on the synthetic tasks we
good at least on the synthetic tasks we
have to run a lot of experiments on it
have to run a lot of experiments on it
but I think this is going to be really
but I think this is going to be really
good it's based on
good it's based on
um it's based on two quantities at the
um it's based on two quantities at the
moment which is your expected
moment which is your expected
performance improvement over the nearest
performance improvement over the nearest
Paro point and then it's also based on a
Paro point and then it's also based on a
distance and cost Bas so distance from
distance and cost Bas so distance from
nearest Paro Point neoc
nearest Paro Point neoc
carbs hyper cram sweep we're doing uh
carbs hyper cram sweep we're doing uh
we're going to try to improve carbs by a
we're going to try to improve carbs by a
lot I've been working on this a while
yeah is
that it doesn't yet to be fair I I don't
that it doesn't yet to be fair I I don't
know if I want to call it neoc carbs or
know if I want to call it neoc carbs or
not we barely use anything from carbs so
not we barely use anything from carbs so
like you know
find a way to call it
find a way to call it
protein that'd be funny
it's
I don't know if I want to have some
I don't know if I want to have some
puffer adjacent thing with
that we'll
that we'll
see but it's quite
good 017
I don't understand how this
is o22
hypers okay that's more reasonable so
hypers okay that's more reasonable so
this says
88 so that's that looks correct but then
88 so that's that looks correct but then
what the heck does this do
1.22
huh oh you're dumb that's why
huh oh you're dumb that's why
reason is you're
done love it when that's the reason
spam running baselines for syllabus.
spam running baselines for syllabus.
tune typers for a few methods bunch of
tune typers for a few methods bunch of
environments and starting point for
environments and starting point for
people yep that is very
good puffers at the
Blackboard they're schooling
Blackboard they're schooling
oh yeah speaking of schooling I was
oh yeah speaking of schooling I was
thinking of building a high performance
thinking of building a high performance
puffer fish swimming simulator and then
puffer fish swimming simulator and then
trying to use reinforcement learning to
trying to use reinforcement learning to
see if we could get them to school does
see if we could get them to school does
that sound like a fun and completely
that sound like a fun and completely
novel project that you'd want to be
novel project that you'd want to be
involved
in we'll make sure to simulate fin tip
in we'll make sure to simulate fin tip
fores
yeah we should definitely do that in C++
yeah we should definitely do that in C++
that sounds great we should just choose
that sounds great we should just choose
the worst language out
the worst language out
there other than Java
there other than Java
maybe I might actually prefer to write
maybe I might actually prefer to write
Java than C++ like gez it's a tough call
Java than C++ like gez it's a tough call
between those two
I think submitting PRS in either of
I think submitting PRS in either of
those gets you [ __ ] slapped back to
those gets you [ __ ] slapped back to
programming boot
camp the zig people are kind of okay
camp the zig people are kind of okay
like okay yeah you got a new trendy
like okay yeah you got a new trendy
language that's fine I just don't want
language that's fine I just don't want
to deal with
it people made like it's from what I've
it people made like it's from what I've
seen it looks like a lot closer to what
seen it looks like a lot closer to what
C++ should have actually been
rust no
rust no
Julia not really Mojo absolutely
not C is really nice though you should
not C is really nice though you should
come write some
C it's just good
I don't want to write any more
I don't want to write any more
environments I haven't tried writing him
environments I haven't tried writing him
in C yet it's actually really
chill you basically you just do fast
chill you basically you just do fast
Game Dev
you just do fast Game
Dev I would like to know why this is so
Dev I would like to know why this is so
bunched up
here oh it doesn't suck it's pretty nice
here oh it doesn't suck it's pretty nice
have you seen the new neural MMO 3 code
I mean this thing is like way better
I mean this thing is like way better
render quality thousand times faster
render quality thousand times faster
fancier UI and
everything and all the
everything and all the
code is right
here that's the whole code it's a
here that's the whole code it's a
fraction of the length of neural mmo2
fraction of the length of neural mmo2
and this is all brain dead as well
and this is all brain dead as well
there's nothing in here that a first
there's nothing in here that a first
year CS undergrad won't understand after
year CS undergrad won't understand after
taking their first systems
taking their first systems
course there are no double
course there are no double
pointers I think there's like one
pointers I think there's like one
Dynamic allocation for the maps being
Dynamic allocation for the maps being
too big but other than that no dynamic
too big but other than that no dynamic
memory
memory
allocations by which I mean after you
allocations by which I mean after you
call a it no Dynamic allocation
no
no
macros just conditionals and Loops ifs
macros just conditionals and Loops ifs
and
and
Loops that's all you
do honestly the hardest part of this
do honestly the hardest part of this
whole thing was figuring out um how to
whole thing was figuring out um how to
get the bloody uh the tiles to look nice
get the bloody uh the tiles to look nice
like the tiling code not to look like
like the tiling code not to look like
Minecraft interpolating and like
Minecraft interpolating and like
snapping tiles and stuff for the
snapping tiles and stuff for the
renderer was the most annoying
thing
thing
Baseline yeah neur 2 is a much more
Baseline yeah neur 2 is a much more
complicated and difficult to work with
complicated and difficult to work with
project should just run some baselines
project should just run some baselines
on this
on this
thing I mean this thing is
thing I mean this thing is
solid we have policies that train for
solid we have policies that train for
this at 500k steps per second as well
this at 500k steps per second as well
like million parameter
policies there you go look at that
policies there you go look at that
oh Dodges Dodges picks up the tool picks
oh Dodges Dodges picks up the tool picks
up the bow doesn't realize that level
up the bow doesn't realize that level
seven is too high to fight back on low
seven is too high to fight back on low
HP but that's pretty decent you just saw
HP but that's pretty decent you just saw
that right it just executed multiple
that right it just executed multiple
Dodges picked up a tool picked up a
Dodges picked up a tool picked up a
weapon swapped to the weapon didn't
weapon swapped to the weapon didn't
realize though that it was too weak to
realize though that it was too weak to
beat the level
seven
seven
Dodge
Dodge
Dodge does doesn't realize that this guy
Dodge does doesn't realize that this guy
has
has
ranged doesn't realize that the really
ranged doesn't realize that the really
high levels have
high levels have
range okay gets the level one picks up
range okay gets the level one picks up
tool equips
tool equips
tool
collects a bunch of
stuff
stuff
kills does a no to equip the armor y
kills does a no to equip the armor y
it's got the weapon and it's equipped
it's got the weapon and it's equipped
it doesn't equip the boots it's got the
it doesn't equip the boots it's got the
helmet on it's got the chest plate on
helmet on it's got the chest plate on
it's got
this what happens if you train way
this what happens if you train way
longer uh this has played 1500 years
longer uh this has played 1500 years
worth of games though I really didn't
worth of games though I really didn't
tune the hyper parameters of the
tune the hyper parameters of the
architecture or the rewards much
architecture or the rewards much
so I think we can do lots better but it
so I think we can do lots better but it
only takes it this is like three days of
only takes it this is like three days of
training on one
GPU it does some pretty sophisticated
GPU it does some pretty sophisticated
stuff it's not perfect like you can see
stuff it's not perfect like you can see
they clear gaps but like there very well
they clear gaps but like there very well
could be just stuff you can't learn from
could be just stuff you can't learn from
the current observations in there right
the current observations in there right
like you need to rorm the observations
like you need to rorm the observations
so yeah I love this project um and
so yeah I love this project um and
eventually you know there will probably
eventually you know there will probably
be successors to this as well or
be successors to this as well or
expansions or whatnot like this will
expansions or whatnot like this will
continue
continue
eventually I got to build a successful
eventually I got to build a successful
company first
yeah but come on this is pretty cool
yeah but come on this is pretty cool
right like I built like a mini MMO over
right like I built like a mini MMO over
a few months and now it's like the most
a few months and now it's like the most
complex probably the most complex fast
complex probably the most complex fast
environment out there I don't think that
environment out there I don't think that
there's anything that is both faster and
there's anything that is both faster and
more complex than
this honestly the rendering was the only
this honestly the rendering was the only
shitty part the logic is pretty
shitty part the logic is pretty
nice yeah right and C is really cozy
well you can try this out
well you can try this out
then cuz it's pretty
then cuz it's pretty
fun there's uh there's Tech in this as
well let's take over okay I'm going to
well let's take over okay I'm going to
reset real
reset real
quick okay now I'm G to play this so now
quick okay now I'm G to play this so now
this is me playing it
let me see if I can show you that
let me see if I can show you that
there's some tech in
here don't you hit me
let me see if I'm good enough to do the
tech there are a few different ones
tech there are a few different ones
actually oh this guy is
perfect yeah you can
perfect yeah you can
strafe if you're good
I get the level seven let's
see yeah so there's Tech uh there's
see yeah so there's Tech uh there's
technically I think that there's a tech
technically I think that there's a tech
with the sword as well because it hits
with the sword as well because it hits
in uh in like three squares in front of
in uh in like three squares in front of
you so I think there's a corner Tech I
you so I think there's a corner Tech I
think there's like a uh there's like an
think there's like a uh there's like an
enemy pathing Tech like there are lots
enemy pathing Tech like there are lots
of things that you can do in here that
of things that you can do in here that
are pretty cool that would be it would
are pretty cool that would be it would
be awesome if the Bots learned to do um
be awesome if the Bots learned to do um
yeah I miss hitting lots of buttons man
yeah I miss hitting lots of buttons man
I've been playing OverWatch I don't know
I've been playing OverWatch I don't know
what's wrong with me and then I did that
what's wrong with me and then I did that
and then they actually they're launching
and then they actually they're launching
the biggest update to that game they've
the biggest update to that game they've
ever done next
week I keep my hitting lots of Buttons
week I keep my hitting lots of Buttons
game is RuneScape so I'm not allowed to
game is RuneScape so I'm not allowed to
do that because that's that's actually
heroin that update looks awful you
heroin that update looks awful you
kidding me dude it looks awesome
kidding me dude it looks awesome
loadouts for everything looks
great bounce is going to be so bad I
great bounce is going to be so bad I
don't understand balance I understand
don't understand balance I understand
swing
swing
Hammer okay
Hammer okay
I understand swing Hammer
good I've hit silver All
Rolls Ash one shot
can't one shot him if you're pinned all
right and also it's silver they can't
right and also it's silver they can't
hit
anything it's weird how it's like there
anything it's weird how it's like there
points over
points over
here there's no point points over here
here there's no point points over here
there there no red points in this
region I was there for a week yeah yeah
region I was there for a week yeah yeah
you and your cracked out
aim okay sometimes I miss the freaking
aim okay sometimes I miss the freaking
Hammer swings and then I have to go play
Winton wish I knew why this this was
Winton wish I knew why this this was
doing
doing
this I guess I can tune the exponential
do five
here
here
hemmer yeah Ryan is good it's annoying
hemmer yeah Ryan is good it's annoying
as hell on tank though because you can't
as hell on tank though because you can't
you can't just play one thing every game
you can't just play one thing every game
like other roles there are like you can
like other roles there are like you can
just play the same thing every game and
just play the same thing every game and
be
be
fine it's annoying
yeah oh it's going to cause tons of
yeah oh it's going to cause tons of
issues but it's still going to be
fun I think the two I haven't figured
fun I think the two I haven't figured
out are
out are
freaking well I have mostly figured out
freaking well I have mostly figured out
but it's like I've only figured it out
but it's like I've only figured it out
because they're bad I think if somebody
because they're bad I think if somebody
actually knows what they're doing on
actually knows what they're doing on
ratra or malga I don't know what to
do so
ridiculous all right this is doing
work re versus Ryan
it's not that bad yet because they they
it's not that bad yet because they they
are not aggressive enough and um they
are not aggressive enough and um they
don't understand that they're dead once
don't understand that they're dead once
they're out of
Nemesis but if as soon as they figure
Nemesis but if as soon as they figure
that
out what the heck is wrong with these
out what the heck is wrong with these
cost
cost
estimates why is the model just like
estimates why is the model just like
suddenly
suddenly
insane that's
insane that's
crazy I guess it's this Epsilon
term it's Perma stock
uh
uh
that's
that's
uh and that's
uh and that's
weird it shouldn't even be able to do
that 20us 2 is
.99 I think that
doesn't I might leave it at 1 E minus 2
doesn't I might leave it at 1 E minus 2
for
now it's
5:30 we're going to start to clean this
5:30 we're going to start to clean this
up and then we're going to be able to
up and then we're going to be able to
run some uh some experiments on
run some uh some experiments on
this this has been pretty good
I
wonder I kind of want to check on the
logs I don't want it to obsess over the
logs I don't want it to obsess over the
high range of the cost is the only
high range of the cost is the only
thing see you good luck and the only
thing see you good luck and the only
thing here is I don't want it to obsess
thing here is I don't want it to obsess
over
over
the high end of cost
here it definitely obsesses over
it I mean I can do this but I think this
it I mean I can do this but I think this
is going to start to screw up the
is going to start to screw up the
results
right so this is a little let me explain
right so this is a little let me explain
what's going on here um I did this thing
what's going on here um I did this thing
where I exponentially
where I exponentially
scale the score so as you cut the
scale the score so as you cut the
distance to the uh to Max score and a
distance to the uh to Max score and a
half you double
half you double
your you double your reward in the
your you double your reward in the
latent space
latent space
basically uh this gets unstable towards
basically uh this gets unstable towards
the high end but also you kind of need
the high end but also you kind of need
to have those like really big jumps at
to have those like really big jumps at
the top because let's say that your your
the top because let's say that your your
thing is Win rate right you want to go
thing is Win rate right you want to go
from 099 to 999 win rate like that
from 099 to 999 win rate like that
actually matters
or like if you're doing even if you're
or like if you're doing even if you're
doing something like pong where the max
doing something like pong where the max
score is 21 right you want a consistent
score is 21 right you want a consistent
21 Max score you don't want
20.5 so probably this break things but
20.5 so probably this break things but
we'll
see lots of notifications
the
heck so much spam on
timeline for
yeah this is a way better distribution
yeah this is a way better distribution
over cost
initially uh and this is getting
initially uh and this is getting
very good
scores
so it's still getting high High rating
so it's still getting high High rating
for
this there's probably some math detail
this there's probably some math detail
I'm missing but this actually looks very
I'm missing but this actually looks very
good let me
look so this is before with the lower
Epsilon
Epsilon
huh why do it get why is it so obsessed
huh why do it get why is it so obsessed
over
here maybe it's not
better spends more compute here but
better spends more compute here but
that's about
it all right
well E3 gives you
I'm going to set this to 23 I'm going to
I'm going to set this to 23 I'm going to
run it again just for good measure and
run it again just for good measure and
then we're going to stop tuning this and
then we're going to stop tuning this and
we're going to mess with other stuff and
we're going to mess with other stuff and
then what we'll do is we will uh we'll
then what we'll do is we will uh we'll
set up some runs on some real
set up some runs on some real
environments I think yeah and in the
environments I think yeah and in the
meantime I'm going to start looking at
meantime I'm going to start looking at
how to clean this up a little bit which
how to clean this up a little bit which
I think will be important so can I get
I think will be important so can I get
rid of this normal option
rid of this normal option
here I think we figured out that this
here I think we figured out that this
makes stuff a mess so we're just just
makes stuff a mess so we're just just
going to leave this as the main
one yeah I hate options and things that
one yeah I hate options and things that
like make the code longer and stupider
I think there's still technically a
I think there's still technically a
couple weird edge cases
here not terrible
though okay we've got prams EPS y me
though okay we've got prams EPS y me
Max do we care about y Max no
we don't use any of this
crap Min score
might men
it's fine
new
new
train get the
suggestions got numpy
Norm let's do this one this
one
one
Pito YT
Pito YT
C and log C Norm okay so you have your
C and log C Norm okay so you have your
pitos
pitos
here to y
and F you don't use
and F you don't use
this you don't use
this you don't use
this so
y we do nearest
Pito Pito
y l
c log C form
okay and then where's
Pito oh this doesn't get used okay so we
Pito oh this doesn't get used okay so we
use parito
C and
C and
purito warm yesc
that's a little better just a little
that's a little better just a little
bit I don't know why they're clustered
bit I don't know why they're clustered
like this but
like this but
whatever it's probably pretty hard for
whatever it's probably pretty hard for
it to learn to predict uh the fine grain
it to learn to predict uh the fine grain
differences here you'd think that it
differences here you'd think that it
would get it on cost
would get it on cost
but not a huge
deal so let's finish cleaning this up
deal so let's finish cleaning this up
and then I think we can throw this on
and then I think we can throw this on
pong pretty soon
here there's just a mess of things here
here there's just a mess of things here
so like nearest pero white do we use
this no
I don't use this do
I because yeah that's gone now okay cool
I because yeah that's gone now okay cool
so
uh it's pretty
good I'd say that's
solid make sure I didn't break anything
solid make sure I didn't break anything
in the process of doing that
I think I'd actually rather run the log
I think I'd actually rather run the log
one
for folks on YouTube this
for folks on YouTube this
is hopefully towards the end of having a
is hopefully towards the end of having a
working very nice hyper parameter sweep
working very nice hyper parameter sweep
algorithm for reinforcement
algorithm for reinforcement
learning um while this
learning um while this
runs so the algorithm that we've landed
runs so the algorithm that we've landed
on it's a little different from the last
on it's a little different from the last
time I went over it so
time I went over it so
idea here is this is your
idea here is this is your
curve you
curve you
have on this side
have on this side
cost and then this axis is
cost and then this axis is
four um and your goal is to discover
four um and your goal is to discover
this curve which contains the set of
this curve which contains the set of
experiments that you can run where
experiments that you can run where
there's nothing up and the right so
there's nothing up and the right so
there's nothing that's cheaper to run
there's nothing that's cheaper to run
that takes less time but is also
that takes less time but is also
performing better uh so the idea here
performing better uh so the idea here
I'm going to move that point just to
I'm going to move that point just to
make it more
make it more
obvious the idea behind the algorithm is
obvious the idea behind the algorithm is
that you're generating a whole bunch of
that you're generating a whole bunch of
potential points that you might want to
potential points that you might want to
run each point is a set of
run each point is a set of
hyperparameters and then when you run
hyperparameters and then when you run
the experiment it's going to end up
the experiment it's going to end up
somewhere on this curve and we're
somewhere on this curve and we're
training predictive models as well as to
training predictive models as well as to
where these are going to end up on the
where these are going to end up on the
curve but you still need to know which
curve but you still need to know which
point to select so what we say is if
point to select so what we say is if
that there's a point here that you want
that there's a point here that you want
to
to
select what you do is your going to look
select what you do is your going to look
at this distance so the distance
at this distance so the distance
vertically from this point to the
vertically from this point to the
nearest point to the left on this
nearest point to the left on this
curve uh and then you're going to look
curve uh and then you're going to look
at and this is the new
at and this is the new
part you're going to look at the Min of
part you're going to look at the Min of
these two
distances so you're looking for the
distances so you're looking for the
closest point on the curve to you
closest point on the curve to you
whether it's this one or this one and
whether it's this one or this one and
the goal of this is that this should
the goal of this is that this should
encourage you to fill out most of this
encourage you to fill out most of this
curve while also improving over know
curve while also improving over know
points as much as possible um you know
points as much as possible um you know
if you put a point down here for
if you put a point down here for
instance then you don't get anything for
instance then you don't get anything for
this because your final score is going
this because your final score is going
to be if this is a and this is uh this
to be if this is a and this is uh this
is
is
B and you're going to get a * B this is
B and you're going to get a * B this is
your score so if you put the point down
your score so if you put the point down
here a is zero you don't get anything uh
here a is zero you don't get anything uh
if you put the point like right on top
if you put the point like right on top
you don't get anything because you're
you don't get anything because you're
already on top and an exist point so
already on top and an exist point so
your goal is to fill out this curve and
your goal is to fill out this curve and
improve over these adjacent
improve over these adjacent
points this is a pretty nice algorithm
points this is a pretty nice algorithm
uh it's based on in Bui
uh it's based on in Bui
carbs but their version of this uh
carbs but their version of this uh
doesn't use adjacent points at all it
doesn't use adjacent points at all it
tries to substitute a function model of
tries to substitute a function model of
the curve and then they just try to look
the curve and then they just try to look
for like where they think that they can
for like where they think that they can
improve over their model of the Curve
improve over their model of the Curve
and there are a whole bunch of
and there are a whole bunch of
degenerate cases that are not handled um
degenerate cases that are not handled um
yeah there's just a bunch of problems
overall the only thing I'm not
overall the only thing I'm not
completely happy about is you know you
completely happy about is you know you
can improve a ton over an existing point
can improve a ton over an existing point
and you still get zero I don't really
and you still get zero I don't really
like that too much
like that too much
so I'm going to think about that because
so I'm going to think about that because
it's incentivizing you to try new spaces
it's incentivizing you to try new spaces
on the curve so it's not terrible that
on the curve so it's not terrible that
it works that
it works that
way it just really wants you to fill in
way it just really wants you to fill in
the
curve okay so this is a different
curve okay so this is a different
test
test
beautiful one bad point
total this is
perfect I'm curious to see what this is
perfect I'm curious to see what this is
going to do on Fong um let's commit well
going to do on Fong um let's commit well
let's let's configure a couple
let's let's configure a couple
things first let's configure a couple
things sweep. metric
7 mean is 2
E7
Auto e
okay Maro
Co so this is set up
Co so this is set up
nicely let's commit
nicely let's commit
everything so we have it
it's not very much code for this thing
really not a ton of code for
this the original repository for carbs
this the original repository for carbs
for reference was around 2,000 lines ARS
for reference was around 2,000 lines ARS
is going to end up between 4 and 500
is going to end up between 4 and 500
most likely though I might try to
most likely though I might try to
compress it even more than
compress it even more than
that because I think it would be funny
um there's still some things I want to
um there's still some things I want to
improve with this currently the
improve with this currently the
algorithm starts with random
algorithm starts with random
sampling around well it's like it's
sampling around well it's like it's
directed random sampling but still I
directed random sampling but still I
think that we have some things that
think that we have some things that
could be improved
could be improved
there we could improve the initial
there we could improve the initial
sampling
um yeah because it's quite a lot to
um yeah because it's quite a lot to
require 10 experiments before carbs
require 10 experiments before carbs
really does anything
really does anything
which is what we have
which is what we have
now I think after
that well we'll see how this goes on
that well we'll see how this goes on
pong um now pong is one of many tasks
pong um now pong is one of many tasks
that we can try the whole idea of this
that we can try the whole idea of this
is we have all these environments on
is we have all these environments on
puffer
puffer
AI right you can play any of these got
AI right you can play any of these got
breakout got like fancy stuff like uh
breakout got like fancy stuff like uh
like this right got multi-agent snake
like this right got multi-agent snake
lots of
lots of
environments so hopefully when we test
environments so hopefully when we test
this out on all those we're going to
this out on all those we're going to
figure out the gaps and the things that
figure out the gaps and the things that
could be improved and I don't want to
could be improved and I don't want to
shift this until I have something where
shift this until I have something where
I really feel like okay hyperparameter
I really feel like okay hyperparameter
sweeps for RL are stable consistent and
sweeps for RL are stable consistent and
easy that's the goal stable consistent
easy that's the goal stable consistent
and easy and I think if we can do that
and easy and I think if we can do that
just so much of RL research is going to
just so much of RL research is going to
just feel better and so much of RL in
just feel better and so much of RL in
practice is going to just feel better
practice is going to just feel better
because you're not going to ever have to
because you're not going to ever have to
wonder uhoh oh or my hyper parameters
wonder uhoh oh or my hyper parameters
just off right you're going to just be
just off right you're going to just be
able to run the sweep you're going to
able to run the sweep you're going to
get like really good information out of
get like really good information out of
that sweep it's going to be fat and uh
that sweep it's going to be fat and uh
yeah that's generally going to be the
yeah that's generally going to be the
case and I think we're pretty close to
case and I think we're pretty close to
that um obviously there's a ton of
that um obviously there's a ton of
testing there's a ton of tweaking I
testing there's a ton of tweaking I
could be wrong on various parts of this
could be wrong on various parts of this
algorithm but I think that the way that
algorithm but I think that the way that
I've handled the normalization
I've handled the normalization
everywhere just makes good sense and um
everywhere just makes good sense and um
should generally be pretty stable
should generally be pretty stable
there's still a couple things here and
there's still a couple things here and
there that I'm not too sure if I like
there that I'm not too sure if I like
like the exponential scaling with this
like the exponential scaling with this
like Epsilon
like Epsilon
maximum you need to have scaling it
maximum you need to have scaling it
should probably be exponential I don't
should probably be exponential I don't
know how you should be clipping it or
know how you should be clipping it or
you know handling edge cases so there's
you know handling edge cases so there's
still stuff to figure out there uh
still stuff to figure out there uh
there's a resampling option as well
there's a resampling option as well
where you can resample existing points I
where you can resample existing points I
think I probably need that because for
think I probably need that because for
environments where there's just a lot of
environments where there's just a lot of
instability um you kind of need to
instability um you kind of need to
resample yeah so there are a lot of
resample yeah so there are a lot of
different things that can be done
different things that can be done
there I'm not going to get off just yet
there I'm not going to get off just yet
I'm going to still do a couple
I'm going to still do a couple
additional things here um but since we
additional things here um but since we
do have a fair few folks watching at the
do have a fair few folks watching at the
moment happy Valentine's Day and um if
moment happy Valentine's Day and um if
you're interested in getting involved in
you're interested in getting involved in
all this open source RL can join the
all this open source RL can join the
Discord it's just discord.
Discord it's just discord.
GPU you can try all these environments
GPU you can try all these environments
out on puffer doai uh they're all very
out on puffer doai uh they're all very
simple to read they're all open source
simple to read they're all open source
most of these are contributed by new RL
most of these are contributed by new RL
folks in the Discord who have just you
folks in the Discord who have just you
know gotten involved with the stuff you
know gotten involved with the stuff you
don't really need a ton of RL experience
don't really need a ton of RL experience
for this side of
for this side of
it and uh they're all very fast like
it and uh they're all very fast like
10,000 times real time
10,000 times real time
fast all the code is right here on the
fast all the code is right here on the
GitHub you can star the repo to help us
GitHub you can star the repo to help us
out that really helps us out and if
out that really helps us out and if
you're looking to get into RL I would
you're looking to get into RL I would
suggest
suggest
specifically this quick start guide and
specifically this quick start guide and
if you're already an expert in RL then
if you're already an expert in RL then
we have some other articles on some of
we have some other articles on some of
the work that we've done here such as
the work that we've done here such as
the 2.0 article and I have some extra
the 2.0 article and I have some extra
ones on my X as well
and while I've been saying all of that
and while I've been saying all of that
we've mostly finished the random trials
we've mostly finished the random trials
I think it's 10 random trials by
default is it 10 random trials or did I
default is it 10 random trials or did I
reduce it something interesting that it
reduce it something interesting that it
goes up this way
let me see if I can find the previous
let me see if I can find the previous
best
best
one one that we're trying to beat
this it this one's pretty
this it this one's pretty
good I think this one but I don't think
good I think this one but I don't think
this is the best
one let me see this is the 34
one let me see this is the 34
one this one
better I see other
one I think this is the best weep that
one I think this is the best weep that
we
had so we have like a Pito front that
had so we have like a Pito front that
looks like
looks like
this most part I thought we had a better
this most part I thought we had a better
one as
one as
well no I think this might be it
well no I think this might be it
yeah uh and then we had what
yeah uh and then we had what
else there's so many different things
else there's so many different things
we've tried here
like I think this
one this was a carb sweep on
pong we didn't get the Pito front out of
pong we didn't get the Pito front out of
this
score okay yeah this is this is pretty
score okay yeah this is this is pretty
representative so we get stuff like this
representative so we get stuff like this
out of um carbs before which is pretty
out of um carbs before which is pretty
decent right you get
decent right you get
like what's this 28 seconds I think run
like what's this 28 seconds I think run
time to
time to
solve so like it discovers good
solve so like it discovers good
Solutions but like all this stuff in
Solutions but like all this stuff in
here is wasted it just it runs a lot of
here is wasted it just it runs a lot of
pretty wasteful
experiments you can see I've been
experiments you can see I've been
running like lots and lots of Trials on
running like lots and lots of Trials on
carbs this is all neoc carbs experiments
carbs this is all neoc carbs experiments
name work in progress
name work in progress
um but I think the first old version I
um but I think the first old version I
had over
had over
here
so yeah this was like a pretty stable
so yeah this was like a pretty stable
version that I was running experiments
version that I was running experiments
on not this
one it generally looks less
one it generally looks less
wasteful in that uh most of the good
wasteful in that uh most of the good
experiments right like they up here it's
experiments right like they up here it's
not running too many failures down here
not running too many failures down here
it's a little weird because like there
it's a little weird because like there
are still points here that are not great
are still points here that are not great
you shouldn't be here and then it
you shouldn't be here and then it
clusters a lot of stuff down here which
clusters a lot of stuff down here which
is not
is not
good so there are all sorts of different
good so there are all sorts of different
versions of this that I've run I think
versions of this that I've run I think
that there
that there
is there's one on breakout as well so
is there's one on breakout as well so
this is
breakout uh breakout is a lot is very
breakout uh breakout is a lot is very
noisy so you're going to get bad runs
noisy so you're going to get bad runs
regardless of what you do I think we can
regardless of what you do I think we can
do way better than this at least though
do way better than this at least though
yeah they're various different
yeah they're various different
environment so we do have some like nice
environment so we do have some like nice
benchmarks from the old version to
benchmarks from the old version to
try um but then the hope is that we're
try um but then the hope is that we're
going to be able to get something much
better and this is what uh this is the
better and this is what uh this is the
problem that I was having with something
problem that I was having with something
similar to the current version of the
similar to the current version of the
code where it would like it would kind
code where it would like it would kind
of cluster a bunch of experiments up
of cluster a bunch of experiments up
close to where it thinks it can solve
close to where it thinks it can solve
and then it would cluster a bunch of
and then it would cluster a bunch of
experiments at minimum cost I think this
experiments at minimum cost I think this
was just bad data
was just bad data
normalization we're going to see if this
normalization we're going to see if this
can do better than
that it's so cool to be able to run
that it's so cool to be able to run
these things like in one to three
these things like in one to three
minutes a
piece okay so interestingly it is
piece okay so interestingly it is
pushing up to Max cost it looks like
pushing up to Max cost it looks like
see the Paro
front I might have it pushing too
front I might have it pushing too
aggressively to Max
cost it doesn't have a great model of
cost it doesn't have a great model of
performance yet
I mean the good thing is it doesn't
I mean the good thing is it doesn't
get it has to at least predict that it's
get it has to at least predict that it's
going to improve over the nearest point
going to improve over the nearest point
so the prediction model can be
so the prediction model can be
off but it's not going to intentionally
off but it's not going to intentionally
run experiments that are worse than
run experiments that are worse than
existing
points is this just unstable this is
points is this just unstable this is
weird that it's this
slow yeah okay there's some
instability I mean the ideal thing right
instability I mean the ideal thing right
is that you get a pretty like dense set
is that you get a pretty like dense set
of points around here in the cheap range
of points around here in the cheap range
and then you like fill in longer and you
and then you like fill in longer and you
get like a nice clean curve
yeah this definitely pushing the Max
cost maybe we can think about that just
cost maybe we can think about that just
a little bit while this
runs because I do technically encourage
runs because I do technically encourage
that and I encourage it quite
explicitly I set the mean function to
one that shouldn't affect that
one that shouldn't affect that
though your score function
is you do explicitly get
rewarded we pushing the Max cost
shouldn't this happen anyways even if
shouldn't this happen anyways even if
you just deleted that term
you just deleted that term
entirely it should in theory
right just how much can you improve over
right just how much can you improve over
the nearest Paro point
I actually I think I remember the
I actually I think I remember the
reason so the reason that I added this
reason so the reason that I added this
term in
term in
there originally
it wasn't anything to do with trying to
it wasn't anything to do with trying to
push you towards higher
push you towards higher
cost the reason I added this term
cost the reason I added this term
originally is like if you have a point
originally is like if you have a point
here and a point here and you just look
here and a point here and you just look
for where is the highest point that I
for where is the highest point that I
can improve over the nearest parito to
can improve over the nearest parito to
the left CU you go to the left you look
the left CU you go to the left you look
for the nearest parito and then you see
for the nearest parito and then you see
where should I put your point to improve
where should I put your point to improve
the most over that so it would just put
the most over that so it would just put
a point like here right because this is
a point like here right because this is
the biggest Improvement and then it
the biggest Improvement and then it
would go like this and this and this so
would go like this and this and this so
it just densely fill in and like scale
it just densely fill in and like scale
back that
way so maybe this is being abused
maybe this is being abused
you have options
here you could clip it so you could clip
here you could clip it so you could clip
points that are too
far there's a parameter you have to
far there's a parameter you have to
control how far away you can put points
the thing is I really like the uh the
the thing is I really like the uh the
nearest penalty
nearest penalty
thing because it has a really nice
interpretation so if I if you do like
interpretation so if I if you do like
the minimize distance to nearest point
the minimize distance to nearest point
then this is the best solution right and
then this is the best solution right and
then maybe this is and this
then maybe this is and this
is and you literally end up doing binary
is and you literally end up doing binary
search so it has this very very nice
search so it has this very very nice
interpretation
so I kind of want to keep that term in
so I kind of want to keep that term in
though that doesn't mean that I have to
though that doesn't mean that I have to
keep the boundary uh condition
yeah I could just use the mean distance
yeah I could just use the mean distance
or something like
or something like
that okay so we'll see how aggressive
that okay so we'll see how aggressive
this thing is if this thing is pushing
this thing is if this thing is pushing
towards high cost way too much then uh
towards high cost way too much then uh
you know we have options to handle
you know we have options to handle
that so I think that the base algorithm
that so I think that the base algorithm
is good I really do it's just a matter
is good I really do it's just a matter
of boundry conditions and the
of boundry conditions and the
like yeah because it's not pushing
like yeah because it's not pushing
everything to Max cost
everything to Max cost
yet we look at
yet we look at
Paro we already have a point that's over
Paro we already have a point that's over
this is way too much running time for
this is way too much running time for
pong it should be able to do this back
pong it should be able to do this back
here so I do think that this is pushing
here so I do think that this is pushing
too high too
quickly because it's getting rewarded
quickly because it's getting rewarded
for it
yeah see look it's it's getting this
yeah see look it's it's getting this
distance here
distance here
because I don't even know how it samples
because I don't even know how it samples
that
far I don't think it should be able to
far I don't think it should be able to
sample this far away from this
point yeah okay so there's definitely
point yeah okay so there's definitely
something screwy
something screwy
here you're not supposed to be able to
here you're not supposed to be able to
do this
so it could just be that because the
so it could just be that because the
thing is if you don't have a if you're
thing is if you don't have a if you're
not parito then you don't go into the
not parito then you don't go into the
sample Index right so like it's not
sample Index right so like it's not
sampling around these points it had to
sampling around these points it had to
have sampled from like this
have sampled from like this
point it's not supposed to be able to do
point it's not supposed to be able to do
this big of a
jump I don't even know how this point
jump I don't even know how this point
got run this is ridiculous
oh to be fair it is technically it's
oh to be fair it is technically it's
possible to like it could have been like
possible to like it could have been like
this point ran and then this point ran
this point ran and then this point ran
or something or this point that still
or something or this point that still
doesn't really make sense no there's no
doesn't really make sense no there's no
way they should have
way they should have
run there's no point that they should
run there's no point that they should
have been able to have been sampled
from it is possible the cost model was
from it is possible the cost model was
just totally wrong
even
even
then it shouldn't
happen red
happen red
[Music]
[Music]
Norm num Ms okay so it did it's pushed
Norm num Ms okay so it did it's pushed
this down a ton so this is going to slow
stuff and
stuff and
then update epox is at one or two only
there's still quite a bit to do
here
here
okay well this is good progress at the
okay well this is good progress at the
very least um the sweeps are running
very least um the sweeps are running
they don't look totally
degenerate I will be curious to
see if we don't get too much noise down
see if we don't get too much noise down
here if it pushes up to Max cost but
here if it pushes up to Max cost but
most of the runs are of at least high
most of the runs are of at least high
quality then that I think will be a
quality then that I think will be a
success uh and then we'll just have to
success uh and then we'll just have to
adjust the sampling scheme a little bit
adjust the sampling scheme a little bit
more
more
tomorrow but I am going to be working on
tomorrow but I am going to be working on
this for most of the weekend so I will
this for most of the weekend so I will
be streaming this all day
be streaming this all day
tomorrow um and we're going to be doing
tomorrow um and we're going to be doing
more of this experiment side work I'll
more of this experiment side work I'll
see if I find other stuff to do in the
see if I find other stuff to do in the
middle
middle
because you know you have to wait for
because you know you have to wait for
the experiments to run but probably the
the experiments to run but probably the
way I'm going to approach it is I'm
way I'm going to approach it is I'm
going to start you know formally trying
going to start you know formally trying
to write up some of this stuff because
to write up some of this stuff because
there will be a nice blog post on this
there will be a nice blog post on this
uh and then I'll probably like fill in
uh and then I'll probably like fill in
stuff along the way so anything I want
stuff along the way so anything I want
to make like a cool figure a cool
to make like a cool figure a cool
visualization I'll probably like make
visualization I'll probably like make
that and I'll run that as well so we'll
that and I'll run that as well so we'll
start like really trying to polish this
start like really trying to polish this
stuff
stuff
up though I don't think the results the
up though I don't think the results the
results are not there yet but it looks
results are not there yet but it looks
to me like mostly we
to me like mostly we
are yeah it looks like mostly we are
are yeah it looks like mostly we are
limited
limited
from uh the sampling and like the like
from uh the sampling and like the like
pushing up too far cost the now I'm
pushing up too far cost the now I'm
looking at this actually maybe this
looking at this actually maybe this
isn't bad because it doesn't look like
isn't bad because it doesn't look like
it's pushed all the way up just
it's pushed all the way up just
yet maybe this ends up being good all
yet maybe this ends up being good all
right I'm going to call it here um for
right I'm going to call it here um for
folks watching Once Again puff. star the
folks watching Once Again puff. star the
GitHub really really helps you can
GitHub really really helps you can
actually get all this code that I just
actually get all this code that I just
uh all this code I just did you can go
uh all this code I just did you can go
play with it it's in the uh whatever fix
play with it it's in the uh whatever fix
neoc carbs Branch or whatnot it's the
neoc carbs Branch or whatnot it's the
latest commit join the Discord almost 1
latest commit join the Discord almost 1
th people in here discord. g/p
th people in here discord. g/p
puffer and uh yeah lots of fun RL
puffer and uh yeah lots of fun RL
articles on here if you are on X lots of
Articles this is all I do uh we are
Articles this is all I do uh we are
going to fix reinforcement learning this
going to fix reinforcement learning this
year and Hyper pram sweeps is a big part
year and Hyper pram sweeps is a big part
of
of
that we're spinning up a few other
that we're spinning up a few other
efforts that I'll talk about soon but
efforts that I'll talk about soon but
for now this is what we've got all right
for now this is what we've got all right
thanks uh enjoy
