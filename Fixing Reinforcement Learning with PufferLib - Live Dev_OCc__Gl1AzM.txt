Kind: captions
Language: en
all right morning we are
live we got some stuff to start out with
live we got some stuff to start out with
today
first let's check on the perer
Discord good job on the environment
Spencer there you go he's got stats very
Spencer there you go he's got stats very
good
okay looks like we've got our community
okay looks like we've got our community
helping out on support request
well hold on is added to flattening or
more e
back e
all
all
right that cover
the
DMS oh this is well this is different
DMS oh this is well this is different
data the thing
yeah but this is not
bad this should be able to be learned
bad this should be able to be learned
okay
so I'm trying to think today what the
so I'm trying to think today what the
plan's going to
plan's going to
be this is going to be done tomorrow
let me check one other thing to make
let me check one other thing to make
sure the other group I'm working with
sure the other group I'm working with
isn't uh going nuts and if so cuz I'd
isn't uh going nuts and if so cuz I'd
really like to get in a little bit of
really like to get in a little bit of
depth at least like an hour hour and a
depth at least like an hour hour and a
half on the uh hyper pram stuff though
half on the uh hyper pram stuff though
realistically I'm going to be in a way
realistically I'm going to be in a way
better mind state for that once this
better mind state for that once this
contract is
done
done
okay so this is about where it was
cool we will we come back to this we're
cool we will we come back to this we're
going to do a little bit on
going to do a little bit on
our hyper pram stuff just a little bit
our hyper pram stuff just a little bit
for the
morning e
so I realized
something about the uh the function I've
something about the uh the function I've
been using
here which is that the nearest parito
here which is that the nearest parito
distance
here if you improve over an existing
here if you improve over an existing
point
you don't get
anything that doesn't seem good
right e
yeah so that's definitely not what we
yeah so that's definitely not what we
want
here let's make this a little more
here let's make this a little more
interactive we'll start drawing some of
interactive we'll start drawing some of
this you can see what uh
this you can see what uh
what I'm thinking about
what I'm thinking about
here
so all
right right
now you have a point
here okay this is and you have a you
here okay this is and you have a you
have a Pito Point here maybe you have
have a Pito Point here maybe you have
some points down here somewhere who
some points down here somewhere who
cares right uh this is your poo
cares right uh this is your poo
point and then you decide that you're
point and then you decide that you're
going to sample a point and you end up
going to sample a point and you end up
sampling a point here then you get
sampling a point here then you get
rewarded by this
rewarded by this
distance
distance
times uh we'll put one over here I
times uh we'll put one over here I
guess you get rewarded times this
guess you get rewarded times this
distance times this distance and if the
distance times this distance and if the
Paro Point were like if the Cito point
Paro Point were like if the Cito point
we here it would be this distance all
we here it would be this distance all
right so you're getting rewarded for
right so you're getting rewarded for
improving and you're getting rewarded
improving and you're getting rewarded
for uh putting parito points or filling
for uh putting parito points or filling
out the cost curve
out the cost curve
rather hey
linky e
do we even need this filling out the
do we even need this filling out the
cost curve
term like in practice I could see why
term like in practice I could see why
you might need it in
practice hold
practice hold
on no you do need up turn because here
on no you do need up turn because here
if you just do GP YT minus nearest Paro
if you just do GP YT minus nearest Paro
YT yeah I remember why I did
YT yeah I remember why I did
this okay so I think maybe before I
this okay so I think maybe before I
identified the problem correctly but I
identified the problem correctly but I
had the solution wrong
so let's say that you have another
so let's say that you have another
paredo point up here
paredo point up here
right and this is going to be the point
right and this is going to be the point
that you've
that you've
sampled
sampled
then what I had before is if you just
then what I had before is if you just
give it this term then why would it ever
give it this term then why would it ever
pick this point right it may as well
pick this point right it may as well
move this point as close as possible to
move this point as close as possible to
right
right
here so maybe it does a little better
here so maybe it does a little better
because it gets longer but it's like
because it gets longer but it's like
right next to an existing point so
right next to an existing point so
basically it was just filling in points
basically it was just filling in points
like this and we saw it kind of fill in
like this and we saw it kind of fill in
that way so that's what I was trying to
that way so that's what I was trying to
address maybe I didn't address
it maybe I didn't address it in a
it maybe I didn't address it in a
reasonable way
maybe it should be distance from next
maybe it should be distance from next
Paro point
okay so if it's distance to next
Point let think about
that so let's say you have a log
curve you have a log curve like
curve you have a log curve like
this and then this is it'll the log base
this and then this is it'll the log base
2 to make it easy so this is 2
2 to make it easy so this is 2
8 oh no other way
around oh yeah wait hold on 2 48 and
around oh yeah wait hold on 2 48 and
then this is going to
then this is going to
be
be
one
one
2 and then I guess I didn't really make
2 and then I guess I didn't really make
it longer so
it longer so
like the
so
so
then you have this Paro Point here is at
one so GP YT minus nearest Paro
one so GP YT minus nearest Paro
YT time nearest Paro
distance have another Point
here so if we linearize this this is
here so if we linearize this this is
going to be
roughly we can't linearize [ __ ]
um oh wait no this is why I made a third
um oh wait no this is why I made a third
point I'm
point I'm
Dum okay
so this is eight over
so this is eight over
here so if we were to score this
here so if we were to score this
point this is 1 minus nearest burito if
point this is 1 minus nearest burito if
we're going to look this
we're going to look this
way so one minus wait no two minus one
way so one minus wait no two minus one
that's the first term and then the
that's the first term and then the
distance is
distance is
four right so this is =
4 is this the optimal
suppose the question is what are you
suppose the question is what are you
trying to
do so this is not even I'm asking the
do so this is not even I'm asking the
wrong question here let me give a little
wrong question here let me give a little
bit of background because a few folks
bit of background because a few folks
are on YouTube
are on YouTube
now so this is a hyperparameter tuning
now so this is a hyperparameter tuning
algorithm uh it's based on carbs which
algorithm uh it's based on carbs which
is in VIIs parito optimal basian search
is in VIIs parito optimal basian search
method I found a bunch of weird things
method I found a bunch of weird things
with the math in that so I'm trying to
with the math in that so I'm trying to
redesign some things but the fundamental
redesign some things but the fundamental
question uh is kind of always the same
question uh is kind of always the same
it's how do you actually want to be
it's how do you actually want to be
exploring your parito Frontier like
exploring your parito Frontier like
there are some things that you can say
there are some things that you can say
like there's some properties that you
like there's some properties that you
might want your algorithm to have but uh
might want your algorithm to have but uh
it's very difficult to characterize the
it's very difficult to characterize the
overall Behavior here so let me get a a
overall Behavior here so let me get a a
fresh one if we have first of all your
fresh one if we have first of all your
parito front can have lots of different
parito front can have lots of different
shapes you can't model it as one shape
shapes you can't model it as one shape
it can look like this right it can look
it can look like this right it can look
like more like a log it can be uh is it
like more like a log it can be uh is it
linear there shouldn't intersect there I
linear there shouldn't intersect there I
think it's like this oops close enough
think it's like this oops close enough
uh you know it can be lots of different
uh you know it can be lots of different
things so you can't assume one shape
so that's part of the problem um now the
so that's part of the problem um now the
second problem right is kind of figuring
second problem right is kind of figuring
out what Behavior you want this thing to
out what Behavior you want this thing to
have I would think
have I would think
that generally a good algorithm if if
that generally a good algorithm if if
you know the Paro front exactly so let's
you know the Paro front exactly so let's
say that you have a good model of the
say that you have a good model of the
Paro front and you have some
Paro front and you have some
points then you probably want your
points then you probably want your
algorithm to
algorithm to
like fill in the Pito front
like fill in the Pito front
this would look something like a binary
this would look something like a binary
search
search
right filling in the
right filling in the
predo so I have something that kind of
predo so I have something that kind of
does
does
that but then the thing I
that but then the thing I
neglected is if the actual pero front is
neglected is if the actual pero front is
like this and you have some points over
here then what should you uh then what
here then what should you uh then what
should it look like
I've also tried several different
I've also tried several different
methods of
um like trying to get you to pay for
um like trying to get you to pay for
experiments with
experiments with
cost so like you're trying to optimize
cost so like you're trying to optimize
the total runtime of the whole hyper
the total runtime of the whole hyper
parameter
parameter
sweep that's been pretty
tricky
e e
I could just take a int on this
or Max I could just do Max one in
or Max I could just do Max one in
this that fixes the problem of not being
this that fixes the problem of not being
able to improve okay hold
on idea
that's one
idea that should do it
I also don't know why I guess why I do
I also don't know why I guess why I do
this in linear
this in linear
[Music]
[Music]
space so that would technically
space so that would technically
work that would fix this bug but I don't
work that would fix this bug but I don't
know if this is everything that we want
know if this is everything that we want
yet this is not the only bug let's show
yet this is not the only bug let's show
some of the existing experiments
so I ran
this cost mostly push down but
score really push up
and we get some
variant but this just really isn't a
variant but this just really isn't a
very good parito
here six yeah these just aren't very
here six yeah these just aren't very
good
good
now I'm trying to think the why you know
now I'm trying to think the why you know
before I go too crazy on
before I go too crazy on
this
this
um the BPT Horizon pram here is
um the BPT Horizon pram here is
suspicious to
suspicious to
me so let me start with that because I'm
me so let me start with that because I'm
a little bit
a little bit
suspicious of that
yeah even the random samples are all
yeah even the random samples are all
right let me just double check and make
right let me just double check and make
sure that's the
case okay yeah so the random samples are
case okay yeah so the random samples are
all down so that's weird
all
okay so we
okay so we
have Min random sample is a BPT Horizon
have Min random sample is a BPT Horizon
of
of
8 and Mac should be
32 here are our suggestions
BPT
BPT
Horizon yeah you see the Min should be
Horizon yeah you see the Min should be
two here but or the Min should be eight
two here but or the Min should be eight
but we get two so that is defin Inc
correct this is a uniform sample
space. unnormalized
get search Center
0.6
0.6 Dot
mm so this should be like 16
here oh you know what maybe I
here oh you know what maybe I
um hang on there was a fix that I I
um hang on there was a fix that I I
didn't take I
think yeah yeah hold on I remember I
think yeah yeah hold on I remember I
fixed this bug but then I broke
fixed this bug but then I broke
something else and I think I rolled this
something else and I think I rolled this
back
right here yeah I didn't return the
right here yeah I didn't return the
index there we go
[Music]
1610 yeah that's better
these are now what you would expect them
these are now what you would expect them
to
be okay
ah shoot I forgot that I needed to
ah shoot I forgot that I needed to
uh there's a thing that I need to do
it's fine
so we should not take this graph
so we should not take this graph
particularly
particularly
seriously um because it simply was
seriously um because it simply was
not suggesting stuff
correctly but that doesn't mean that
correctly but that doesn't mean that
everything is all fixed yet we will
see let me think about the properties
see let me think about the properties
okay so without having the bias of ah
okay so without having the bias of ah
this experiment went terribly in my head
this experiment went terribly in my head
let me think about this algorithm again
let me think about this algorithm again
from first
principles this is really the Crux of it
principles this is really the Crux of it
right here and really you can ignore
right here and really you can ignore
this so it's just this this is the whole
this so it's just this this is the whole
algorithm which is this all breaks down
too can I do
too can I do
maybe this is
maybe this is
better yeah it's
better kind of like
this
so gpy T minus nearest perrito
so in the in the case of in the optimal
case we have something like
this let's put this point like here so
this let's put this point like here so
in the optimal case you are going to
in the optimal case you are going to
fill in here uh this will push to
fill in here uh this will push to
maximum cost as well because the nearest
maximum cost as well because the nearest
distance right this is like like this
distance right this is like like this
distance so it'll push to here and on
distance so it'll push to here and on
the low end it'll push to Min cost as
the low end it'll push to Min cost as
well after it's filled in like these
points so that should be good
points so that should be good
now it does rely
on GP
on GP
YT as the distance
measure okay so there is something
measure okay so there is something
consider with the curvature here that I
consider with the curvature here that I
didn't think of too too well so if you
didn't think of too too well so if you
have it all if the algorithm is if the
have it all if the algorithm is if the
curve is a
curve is a
line then and you just take the raw
line then and you just take the raw
distance
distance
right then you will get binary search if
right then you will get binary search if
you just take that distance because
you just take that distance because
you're going to go here because this is
you're going to go here because this is
this distance times this distance is
this distance times this distance is
going to be the largest product and then
going to be the largest product and then
you're going to go like here here the
you're going to go like here here the
order will be randomized but you will
order will be randomized but you will
get
get
you know binary
you know binary
search like
search like
that okay and then the um what is it the
that okay and then the um what is it the
max or whatever that I put on it is fine
max or whatever that I put on it is fine
as
well now we are doing this on YT GP YT
well now we are doing this on YT GP YT
what is the transform that I have
what is the transform that I have
applied it is a log transform thing
plus
Epsilon
okay let's uh put some values in
so this is what you get for if you have
so this is what you get for if you have
pong
oh this gives
you you get a negative number
here we'll have to think about
here we'll have to think about
that Let's ignore the negative sign for
that Let's ignore the negative sign for
a bit so this is the lowest possible
a bit so this is the lowest possible
score in PA but if I put in
score in PA but if I put in
zero okay then you get basically zero
zero okay then you get basically zero
and get
Epsilon if I put in 10 you get 6 if I
Epsilon if I put in 10 you get 6 if I
put in 15 you get 1.25 it roughly
put in 15 you get 1.25 it roughly
doubles to get
doubles to get
closer and then if I put in 20 we're at
closer and then if I put in 20 we're at
three 20.5 there's still like a
three 20.5 there's still like a
substantial incentive to increase here
substantial incentive to increase here
and then
and then
21 it goes up to all the way to 11
be nice to have this better
normalized so just by messing with the
normalized so just by messing with the
Epsilon term right you can scale this
Epsilon term right you can scale this
thing quite a
lot as you would
lot as you would
like and that basically tells you the
like and that basically tells you the
number of zeros on the score that are
number of zeros on the score that are
going to matter
I'm going to think about this because
I'm going to think about this because
there's an interaction here that needs
there's an interaction here that needs
to be accounted for so I'm going to be
to be accounted for so I'm going to be
back in a few let me make sure this
back in a few let me make sure this
sweep is going
on okay yeah so this is the sweep is on
on okay yeah so this is the sweep is on
for sure I'll be back in a
few
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e e
Okay so
okay we'll let this one continue for a
okay we'll let this one continue for a
bit
bit
um but I'm kind of realizing
um but I'm kind of realizing
I have an exponential here right it's a
I have an exponential here right it's a
smooth exponential it's like clipped and
stuff one over
log no it's one over it's a one it's one
log no it's one over it's a one it's one
over log is what it is right or hold on
over log is what it is right or hold on
log no it's a
log no it's a
log it's log bound okay
so the scaling of these things is very
awkward I think I think I did this with
awkward I think I think I did this with
percentile scoring in
percentile scoring in
mind so like if you have
mind so like if you have
90% right then you want 95% to be better
90% right then you want 95% to be better
and 97.5 to be much
better it works with a lot of things
better it works with a lot of things
though because
though because
like you still want to get the high you
like you still want to get the high you
want to fully solve a lot of environment
want to fully solve a lot of environment
so I guess this does make
sense for
let's see what it's
let's see what it's
doing the moment on this sweep
okay so batch size is kind of stuck
okay so batch size is kind of stuck
around here maybe this should be sampled
around here maybe this should be sampled
a little
a little
more we will
more we will
uh consider increasing
that learning rates being pushed up very
that learning rates being pushed up very
high odd
one and
one and
Gamma
Lambda
Lambda
EO it's
fine it's kind of
okay m
okay m
y we get the parito
front they're
front they're
all technically parito
okay there's no way that the learning
okay there's no way that the learning
rate should be this
High Why is it setting the learning rate
High Why is it setting the learning rate
this
high oh hang on wait did I
okay it is setting
value let's make a couple quick tweaks
value let's make a couple quick tweaks
and rerun this because it's setting
and rerun this because it's setting
um it's setting coefficients that are
um it's setting coefficients that are
going to cause it to do weird things
going to cause it to do weird things
that I'm not going to be able to tell
that I'm not going to be able to tell
what's going on
I mean it should be able to tune this
I mean it should be able to tune this
though to be
fair pushing Lambda pushing all these
fair pushing Lambda pushing all these
parameters to the ceiling was very odd
though it's going for very short RS
oh hang on it's going for short runs
oh hang on it's going for short runs
here because there's
no I don't know
there might be something that's pushing
there might be something that's pushing
it this way
looks back very clearly that there is
actually
score9
score9
same cost is 14
so it thinks that it's going to
get
Point score nearby
Point score nearby
is -12
12 was it's also just not going to get
9 model's
off right
there isn't even a Paro point with -12
there isn't even a Paro point with -12
that's
weird I was doing this repeatedly hang
weird I was doing this repeatedly hang
on
yeah look it's making the same
yeah look it's making the same
recommendation repeatedly until it's
recommendation repeatedly until it's
it's slowly realizing that it's not
it's slowly realizing that it's not
working
working
out so why is it so obsessed with this
one e
so here are all the
points still trying to do it
and it's weird because it's
and it's weird because it's
wrong like the model is just
wrong
e e
this nearby
point it's still
hold
hold
nearest -20 point
s there isn't a burrito point that is
s there isn't a burrito point that is
like
like
this as far as I can see so there's an
this as far as I can see so there's an
issue here somehow
reset button on this thing really
and
silly I can't figure out why it's doing
silly I can't figure out why it's doing
this
this
though it's still doing it
for some stupid reason the models wrong
right that's what it is the score model
right that's what it is the score model
is wrong
and what does
and what does
the what's the score get dragged down
too YT nor
men
e e
brag to Mid
score it's not happening
score it's not happening
though through all these points and
though through all these points and
still predicting completely freaking
wrong okay now you have all these
wrong okay now you have all these
freaking points here right and you're
freaking points here right and you're
still going to be predicting
wrong yeah look it thinks it's getting
wrong yeah look it thinks it's getting
12 cost which is over here
wait
wait
distance even make
sense now this doesn't even make
sense oh wait maybe the Pito hold long
what actually gets logged
here score and cost
ahuh that tells us a very different
ahuh that tells us a very different
story now doesn't
it so we just have the graph
WR
okay so it thinks it's going to get -5
okay so it thinks it's going to get -5
at a cost of
12 which is very
reasonable oh no is it
reasonable oh no is it
it's still pretty
optimistic there's a point very nearby
optimistic there's a point very nearby
it says
okay so it's still a bit
unrealistic H
maybe but it thinks it's going to get a
maybe but it thinks it's going to get a
four of-5 which is
here the thing is that shouldn't even
here the thing is that shouldn't even
give you all that much
reward hang on hang on this could be the
reward hang on hang on this could be the
negative in the function screwing us
over let me
over let me
see remember we were looking at that
see remember we were looking at that
before and I ignored it for a
before and I ignored it for a
second that could be
it let me see if that negative makes
it let me see if that negative makes
sense
all e
I think this should still work cuz this
I think this should still work cuz this
one minus this
one but like is this better
than
than
three no cuz three gives you a 0.15
three no cuz three gives you a 0.15
increment
18 let's do
negative
5 gives you a
5 gives you a
0.1 that .12
or one one yeah no this is
fine -8 to -5 gives
you one two hold
on it gives you .11
no I think it's fine it's very
no I think it's fine it's very
linear um towards the
linear um towards the
bottom think
so this is low it as it goes
okay so it does give this a positive
okay so it does give this a positive
rating but
why why is this the highest positive
why why is this the highest positive
rating
and it's still doing it
very screwy
e e
I wonder if it's the mean function
maybe that would do it
we should be able to actually just
we should be able to actually just
scroll up a bunch and see depending how
scroll up a bunch and see depending how
far back the terminal
far back the terminal
goes
goes
and did it
and did it
uh
uh
oops Yeah we have all our runs
right so here are the random
right so here are the random
runs we you should be able to see what
runs we you should be able to see what
happened okay so here's our first
prediction -3 at a cost of
24 nine at a cost of
31 five it across to 30
seven
uh yeah so it looks like the score
uh yeah so it looks like the score
function just straight up never predicts
function just straight up never predicts
anything good oh here's one
anything good oh here's one
13 at a cost of 2
13 at a cost of 2
too it looks like it Nails this
one but it seems very difficult for it
one but it seems very difficult for it
to actually make those
predictions maybe I just
rescale
e e
okay so there's a large negative I can
okay so there's a large negative I can
screw it up
still ideally we have Min score and Max
still ideally we have Min score and Max
score
hey welcome
we'll start with this
one for
what was F sanitized and how does it
what was F sanitized and how does it
work it's a compile
work it's a compile
flag it tells well there various options
flag it tells well there various options
for it but it'll do stuff like array
for it but it'll do stuff like array
bounds checking memory leaks and the
bounds checking memory leaks and the
like so you're not just completely doing
like so you're not just completely doing
everything blind
yeah that's probably fine
let's see if this does
it or if this does anything
it or if this does anything
substantially different at
least crazy how uh messes
up um wall W extra and like you can get
up um wall W extra and like you can get
you can end up getting too much pedantic
you can end up getting too much pedantic
stuff if you're not careful
look this in real quick
this is definitely starting to annoy me
this is definitely starting to annoy me
though because I'm
though because I'm
getting I'm starting to get problems
getting I'm starting to get problems
that seem seem like problems of gaussian
processes
so that's probably going to be the next
so that's probably going to be the next
thing is to fiddle with other models
yeah this thing
yeah this thing
here kind of other models I don't know
here kind of other models I don't know
throw Wonder
throw Wonder
ifbm would be the same it probably SPM
ifbm would be the same it probably SPM
would probably be the same I could just
would probably be the same I could just
throw linear regression at it with a
throw linear regression at it with a
reasonable
reasonable
kernel just give it like
um I don't know like a linear log some
um I don't know like a linear log some
weird kernel we' probably just have
weird kernel we' probably just have
something work for
technically I guess the linear kernel
technically I guess the linear kernel
should be able to do that huh
well the thing is that in order to
well the thing is that in order to
really investigate this I'm going to
really investigate this I'm going to
need more time than just doing this for
need more time than just doing this for
an hour and a half in the
an hour and a half in the
morning so once contract is done we'll
morning so once contract is done we'll
probably do this over the
probably do this over the
weekend along with some other stuff
cuz I'm not entirely sure why this is
cuz I'm not entirely sure why this is
happening that it's like it's so
happening that it's like it's so
obsessed with this terrible region I
obsessed with this terrible region I
think that it's most likely doing this
think that it's most likely doing this
because um the Gan
because um the Gan
process it tries to drag everything to
process it tries to drag everything to
the mean so the farther you are from the
the mean so the farther you are from the
mean the more it drags stuff so so it's
mean the more it drags stuff so so it's
very difficult to even make good score
very difficult to even make good score
predictions like this now technically
predictions like this now technically
you can fix all this by like being very
you can fix all this by like being very
very careful about how you normalize all
very careful about how you normalize all
your data um but the thing is this is
your data um but the thing is this is
supposed to be an automatic method so
supposed to be an automatic method so
like you kind of want something more
like you kind of want something more
resilient than this in the first
resilient than this in the first
place yeah it's pretty
obnoxious so here we have this
I mean I've looked at the base method
I mean I've looked at the base method
and the base method seems to be
and the base method seems to be
mostly mostly reasonable
there are a few tweaks I could
there are a few tweaks I could
potentially still make
but if you have a linear kernel
I don't even know if there is any
locality no there is
we're very close to having this thing
we're very close to having this thing
it's just there are a few like math
it's just there are a few like math
details that don't they're not quite
details that don't they're not quite
working out here
so it's kind of the same thing
will the API be similar to
will the API be similar to
carbs yeah just less
carbs yeah just less
crap I'll show you how easy it is at the
crap I'll show you how easy it is at the
moment
all right this is
all right this is
it this is how you use neoc
carbs I'm name might be uh work in
carbs I'm name might be uh work in
progress because this is getting to be
progress because this is getting to be
pretty distant from carbs like I really
pretty distant from carbs like I really
had to re architect a lot of their stuff
but you can see it's way
easier and the thing is that the code is
easier and the thing is that the code is
going to
be so right now I have 479 lines and a
be so right now I have 479 lines and a
lot of that's like this type of debug
lot of that's like this type of debug
stuff
stuff
so let me see yeah and I don't even need
so let me see yeah and I don't even need
a half of the stuff that's in here so
a half of the stuff that's in here so
let's say it's going to be about 400
let's say it's going to be about 400
lines
lines
for the whole thing versus I think the
for the whole thing versus I think the
original repo is like 2,000
lines what haven't you changed from
lines what haven't you changed from
carbs at this
carbs at this
point well we're still using Doan
point well we're still using Doan
presses in some capacity and we still
presses in some capacity and we still
have two of the we're still predicting
have two of the we're still predicting
two of the same quantity score and cost
two of the same quantity score and cost
from the original but the the scoring
from the original but the the scoring
function is completely
function is completely
different
um yeah I mean a lot has
um yeah I mean a lot has
changed I still have like a distance
changed I still have like a distance
term and a semi acquisition term but
term and a semi acquisition term but
they're very different from the original
forms yeah to be fair a lot of it is
forms yeah to be fair a lot of it is
very
different I mean the core thing is just
different I mean the core thing is just
the idea of trying to do a Paro optimal
search oops
you can see it's still pushing this down
I do not know why it's doing this
that one was reasonable
uh found some unstable parameters
okay but it is actually now trying to
okay but it is actually now trying to
do higher cost stuff it looks
like and so
yeah okay so I was right at least I was
yeah okay so I was right at least I was
at least partially right and that what
at least partially right and that what
was happening is and this is why these
was happening is and this is why these
things are so obnoxious um it assumes
things are so obnoxious um it assumes
everything's normally distributed so I
everything's normally distributed so I
specified the mean function as the
specified the mean function as the
minimum
minimum
score in like some transform space and
score in like some transform space and
it was a pretty nicely scaled transform
it was a pretty nicely scaled transform
space but it was like I think the the
space but it was like I think the the
maximum would have been like five and uh
maximum would have been like five and uh
no that's too much for a gum process got
no that's too much for a gum process got
to drag everything aggressively down to
to drag everything aggressively down to
the mean so or to
yeah the idea of a mean function just
yeah the idea of a mean function just
doesn't even
doesn't even
make sense for this
I mean it's kind of a way of trying to
I mean it's kind of a way of trying to
make stuff conservative but
um and I don't
know I guess it could
know I guess it could
work the thing that just sketches me out
work the thing that just sketches me out
here is like it could work but it needs
here is like it could work but it needs
to be carefully tuned
so it is actually trying to go for high
so it is actually trying to go for high
cost higher cost points
here not
perfect
e e
yeah
so this is like just such a tricky thing
so this is like just such a tricky thing
to reason
about because like a gaan process gives
about because like a gaan process gives
you something that's a sort of like an
you something that's a sort of like an
approximate nearest neighbor
which sounds
good but the way in which it does it is
good but the way in which it does it is
kind of unintuitive and difficult to
kind of unintuitive and difficult to
reason
about it thought it was going to get
about it thought it was going to get
score 15
score 15
here and end up getting -7 how's this
here and end up getting -7 how's this
even happen
the cost was about right
here hang on maybe I messed something up
here hang on maybe I messed something up
with my scoring
with my scoring
function cuz that's a little bit
function cuz that's a little bit
suspicious getting like this
stuff
e e
no this is looking correct
12 of
14 it's
-20 why is the variance on this thing
-20 why is the variance on this thing
just so
just so
garbage can we add
do we have this plot
already we don't
one
zero
just no longer doing crazy things to my
just no longer doing crazy things to my
other hyper
parameters yeah but the models just
parameters yeah but the models just
completely freaking
completely freaking
wrong on these
wrong on these
costs not on the cost the cost model is
costs not on the cost the cost model is
good actually the um on the force
what do these curves look
like
like
sweep give it a
sweep give it a
bit nothing is safe
yet okay so we don't have like crazy
yet okay so we don't have like crazy
crashing
crashing
completely I'm offense
I'm looking at it nothing is reasonable
I'm looking at it nothing is reasonable
yet all right nothing actually like
yet all right nothing actually like
fully Works yet
why is it having such a hard time with
why is it having such a hard time with
this if we
this if we
do this board here
we can see the learning
we can see the learning
ratey coefficient Lambda G like we can
ratey coefficient Lambda G like we can
see where all these parameters need to
be most of these just have stable
regions
for
e
e
e
e
for e
thing that's hard is there's probably a
thing that's hard is there's probably a
lot of noise in the actual
runs and now I can't find any
runs and now I can't find any
improvements
improvements
so at the moment it thinks it can't
so at the moment it thinks it can't
improve the parito
improve the parito
front morning can you briefly describe
front morning can you briefly describe
yeah
yeah
so I mean this is my attempt at making a
so I mean this is my attempt at making a
very good uh hyper parameter sweep
very good uh hyper parameter sweep
algorithm for reinforcement learning
algorithm for reinforcement learning
it's based off of the ideas uh the Poo
it's based off of the ideas uh the Poo
optimality ideas in the MB carbs
optimality ideas in the MB carbs
paper and uh this does very well on a
paper and uh this does very well on a
number of synthetic tasks this algorithm
number of synthetic tasks this algorithm
that I have here but on the real task it
that I have here but on the real task it
seems that it
seems that it
is less than ideal I'm trying to
is less than ideal I'm trying to
characterize currently exactly what's
characterize currently exactly what's
happening and why
happening and why
um it seems
um it seems
like it might just be taking more
like it might just be taking more
samples to build up a good model because
samples to build up a good model because
there's a lot of noise in many of the
there's a lot of noise in many of the
real RL tasks uh you know you can run
real RL tasks uh you know you can run
the same hyper parameters multiple times
the same hyper parameters multiple times
with different seeds
with different seeds
and some of the runs will be stable and
and some of the runs will be stable and
some will not
some will not
be that is a separate
be that is a separate
challenge but also there are just some
challenge but also there are just some
algorithmic works these things rely on
algorithmic works these things rely on
gaussian processes which are not
gaussian processes which are not
entirely ideal all the time
entirely ideal all the time
um yeah there's some quirks of gussian
um yeah there's some quirks of gussian
processes that I'm currently annoyed by
processes that I'm currently annoyed by
so it's clear to me that you need need
so it's clear to me that you need need
some sort of
some sort of
global uh Global
global uh Global
learnability which would come from a
learnability which would come from a
linear Kel or polinomial kernel or
linear Kel or polinomial kernel or
something but that doesn't play nicely
something but that doesn't play nicely
with uh the other kernels which require
with uh the other kernels which require
a mean function it's going to basically
a mean function it's going to basically
tell you what the minimum score is and
tell you what the minimum score is and
then the maximum
cost so I'm currently considering
cost so I'm currently considering
whether gin processes are really even a
whether gin processes are really even a
good choice all um they're kind of
good choice all um they're kind of
bloated for what this
bloated for what this
is and like if you actually look at a
is and like if you actually look at a
lot of the so here if you look at like
lot of the so here if you look at like
the sweep progress so this is like what
the sweep progress so this is like what
parameters are being tried out over time
parameters are being tried out over time
you can see how the sweep
you can see how the sweep
changes you know but uh if you just look
changes you know but uh if you just look
at it this
at it this
way you can kind of see that a lot of
way you can kind of see that a lot of
these hyper parameters just have stable
these hyper parameters just have stable
regions
regions
like stable region here stable region
like stable region here stable region
here here here right and none of these
here here here right and none of these
have any impact whatsoever on the
have any impact whatsoever on the
runtime the only ones that impact the
runtime the only ones that impact the
runtime are like these
runtime are like these
ones and these ones affect both the
ones and these ones affect both the
runtime and the
cost so I'm like I'm wondering here if I
cost so I'm like I'm wondering here if I
could do some sort of simple linear
could do some sort of simple linear
model
model
with uh with like some really basic
with uh with like some really basic
featurization so I just give it like you
featurization so I just give it like you
know the values the log of the
know the values the log of the
values and maybe that's
values and maybe that's
it and see if I can fit something I
it and see if I can fit something I
don't
know I mean there's stuff like this as
know I mean there's stuff like this as
well where you have these like very
well where you have these like very
discrete values
the other thing is that the Gan process
the other thing is that the Gan process
is supposed to give you a variance
is supposed to give you a variance
estimate
estimate
which is supposed to be
which is supposed to be
useful but the thing is I've observed
useful but the thing is I've observed
that the variance estimate is just
that the variance estimate is just
complete bullets it's just completely
complete bullets it's just completely
worthless so the fact that it gives you
worthless so the fact that it gives you
a variance estimate as a selling point
a variance estimate as a selling point
the variance estimate is terrible so
the variance estimate is terrible so
it's not actually useful for
anything like it should not be it should
anything like it should not be it should
not still after running 50 experiments
not still after running 50 experiments
be dropping points down here
like how do we not have anything over 20
yet 21 should be the max not 20
I mean I've got a very simple method at
I mean I've got a very simple method at
this point that
this point that
should it's just based on your expected
should it's just based on your expected
Improvement um over the nearest parito
Improvement um over the nearest parito
optimal point and then it also the
optimal point and then it also the
runtime could play a factor
runtime could play a factor
here well no that is one of the things
here well no that is one of the things
that we're explicitly modeling there are
that we're explicitly modeling there are
two gaussian processes one of them
two gaussian processes one of them
predicts how long the experiment will
predicts how long the experiment will
take to to run and the other will
take to to run and the other will
predict how well the experiment is going
predict how well the experiment is going
to do so your goal here is to discover
to do so your goal here is to discover
the Paro front uh the Paro front being
the Paro front uh the Paro front being
the set of points for which there is
the set of points for which there is
nothing up and to the left so there's
nothing up and to the left so there's
nothing that is both better and faster
nothing that is both better and faster
so in this case the Paro front is this
so in this case the Paro front is this
point this point this point this point
point this point this point this point
this point this point this point this
this point this point this point this
point and this point so it kind of goes
point and this point so it kind of goes
like this so uh you know you would
like this so uh you know you would
expect then that there's probably some
expect then that there's probably some
points over here that you can get to do
points over here that you can get to do
better and I know that you can do better
better and I know that you can do better
over
over
here actually these points aren't parito
here actually these points aren't parito
because I think this one is higher by a
because I think this one is higher by a
little bit so yeah it should be able to
little bit so yeah it should be able to
discover something some slightly higher
discover something some slightly higher
points over
points over
here but it's not quite doing
that e
yeah so here's this one that gets no
yeah so here's this one that gets no
score because for some
score because for some
reason algorithm has decided to make the
reason algorithm has decided to make the
maximum gradient Norm zero that's
bizarre I mean this shouldn't happen is
bizarre I mean this shouldn't happen is
the
the
thing hang on do I have Max Brad Norman
thing hang on do I have Max Brad Norman
here
okay I guess that's kind of funny there
okay I guess that's kind of funny there
happened to be one decent point over
happened to be one decent point over
here so it probably caused some of these
here so it probably caused some of these
samples but still it should have very
samples but still it should have very
quickly figured out uh from these
quickly figured out uh from these
adjacent points to stop doing this
okay here's a decent burito
point there are only four parito points
point there are only four parito points
actually I think on this whole
curve a and then it moves it over
curve a and then it moves it over
here CU it ran the experiment for very
here CU it ran the experiment for very
long let see
wait what and then is it going to move
wait what and then is it going to move
it this
it this
one what happened
here
here
okay now this is fine
it shouldn't even be sampling over here
it shouldn't even be sampling over here
there's nothing for
it I guess it thinks if it fills in here
it I guess it thinks if it fills in here
there's a pretty
decent not very familiar with
decent not very familiar with
multiobjective optim
ation there's nothing particularly fancy
ation there's nothing particularly fancy
about
it I if Pito optimality is a useful
it I if Pito optimality is a useful
concept if you're not familiar with it
concept if you're not familiar with it
already but it it just says that you
already but it it just says that you
want the set of points for which you
want the set of points for which you
cannot get you cannot run the experiment
cannot get you cannot run the experiment
both faster and get a better result
both faster and get a better result
that's all it says for this case
hold on there are more than four Creo
hold on there are more than four Creo
points wait one two three four five six
points wait one two three four five six
seven8 nine Paro points here
seven8 nine Paro points here
now so it is filling in the curve but
now so it is filling in the curve but
there's just is so much garbage here
If this just thinned out a little this
If this just thinned out a little this
is
fine I don't know how it randomly gets a
fine I don't know how it randomly gets a
sample
here unless this is a Pito
here unless this is a Pito
Point yeah this has to be a Paro Point
Point yeah this has to be a Paro Point
otherwise it wouldn't be able to sample
otherwise it wouldn't be able to sample
that I don't know what this
that I don't know what this
is 044
turquoise Point
huh it's very weird
okay ignoring these CU weird stuff this
okay ignoring these CU weird stuff this
section looks
fine Lambda still kind of
fine Lambda still kind of
spread it's okay and then update
EO starting to explore over
here ry's fine
yeah it's just not predicting at all
oh hold on look at
this8 rating
zero okay so a lot of these points now
zero okay so a lot of these points now
are scoring zero meaning it just is not
are scoring zero meaning it just is not
finding any samples it thinks are good
finding any samples it thinks are good
so this one it thinks is good and then
so this one it thinks is good and then
it completely gets it
it completely gets it
wrong
zero zero
negative that's crazy that it's not
negative that's crazy that it's not
finding
finding
any anything around any of the Cito
any anything around any of the Cito
points
think we either definitely have to swap
think we either definitely have to swap
the gussian process or figure out how to
the gussian process or figure out how to
use the linear kernel
correctly
for
e e
okay well we will think about this a bit
okay well we will think about this a bit
um I'm going to go get some breakfast go
um I'm going to go get some breakfast go
get some
get some
exercise and then we have uh we have to
exercise and then we have uh we have to
finish all the robotic stuff today so
finish all the robotic stuff today so
I'll be doing that live on stream uh in
I'll be doing that live on stream uh in
the I don't know a couple hours once I
the I don't know a couple hours once I
get some food and stuff uh so we'll
get some food and stuff uh so we'll
finish all that
finish all that
today and then I will have a lot more
today and then I will have a lot more
mental bandwidth to really focus on this
mental bandwidth to really focus on this
will be good
will be good
so uh for
so uh for
folks who are interested in this stuff
folks who are interested in this stuff
you can check out all the RL I do at
you can check out all the RL I do at
puffer doai it's all free and open
puffer doai it's all free and open
source you can try out all the
source you can try out all the
environments that we have many are
environments that we have many are
written by
written by
contributors you want to help us out
contributors you want to help us out
start the repository really helps when
start the repository really helps when
people start the
people start the
repo join the Discord if you want to get
repo join the Discord if you want to get
involved we've got all sorts of material
involved we've got all sorts of material
on our
on our
docs as well as on the blog want
docs as well as on the blog want
additional RL content you can't find any
additional RL content you can't find any
anywhere else I've got articles on my X
anywhere else I've got articles on my X
for that so thank you and

Kind: captions
Language: en
all right morning we are
live we got some stuff to start out with
live we got some stuff to start out with
today
first let's check on the perer
Discord good job on the environment
Spencer there you go he's got stats very
Spencer there you go he's got stats very
good
okay looks like we've got our community
okay looks like we've got our community
helping out on support request
well hold on is added to flattening or
more e
back e
all
all
right that cover
the
DMS oh this is well this is different
DMS oh this is well this is different
data the thing
yeah but this is not
bad this should be able to be learned
bad this should be able to be learned
okay
so I'm trying to think today what the
so I'm trying to think today what the
plan's going to
plan's going to
be this is going to be done tomorrow
let me check one other thing to make
let me check one other thing to make
sure the other group I'm working with
sure the other group I'm working with
isn't uh going nuts and if so cuz I'd
isn't uh going nuts and if so cuz I'd
really like to get in a little bit of
really like to get in a little bit of
depth at least like an hour hour and a
depth at least like an hour hour and a
half on the uh hyper pram stuff though
half on the uh hyper pram stuff though
realistically I'm going to be in a way
realistically I'm going to be in a way
better mind state for that once this
better mind state for that once this
contract is
done
done
okay so this is about where it was
cool we will we come back to this we're
cool we will we come back to this we're
going to do a little bit on
going to do a little bit on
our hyper pram stuff just a little bit
our hyper pram stuff just a little bit
for the
morning e
so I realized
something about the uh the function I've
something about the uh the function I've
been using
here which is that the nearest parito
here which is that the nearest parito
distance
here if you improve over an existing
here if you improve over an existing
point
you don't get
anything that doesn't seem good
right e
yeah so that's definitely not what we
yeah so that's definitely not what we
want
here let's make this a little more
here let's make this a little more
interactive we'll start drawing some of
interactive we'll start drawing some of
this you can see what uh
this you can see what uh
what I'm thinking about
what I'm thinking about
here
so all
right right
now you have a point
here okay this is and you have a you
here okay this is and you have a you
have a Pito Point here maybe you have
have a Pito Point here maybe you have
some points down here somewhere who
some points down here somewhere who
cares right uh this is your poo
cares right uh this is your poo
point and then you decide that you're
point and then you decide that you're
going to sample a point and you end up
going to sample a point and you end up
sampling a point here then you get
sampling a point here then you get
rewarded by this
rewarded by this
distance
distance
times uh we'll put one over here I
times uh we'll put one over here I
guess you get rewarded times this
guess you get rewarded times this
distance times this distance and if the
distance times this distance and if the
Paro Point were like if the Cito point
Paro Point were like if the Cito point
we here it would be this distance all
we here it would be this distance all
right so you're getting rewarded for
right so you're getting rewarded for
improving and you're getting rewarded
improving and you're getting rewarded
for uh putting parito points or filling
for uh putting parito points or filling
out the cost curve
out the cost curve
rather hey
linky e
do we even need this filling out the
do we even need this filling out the
cost curve
term like in practice I could see why
term like in practice I could see why
you might need it in
practice hold
practice hold
on no you do need up turn because here
on no you do need up turn because here
if you just do GP YT minus nearest Paro
if you just do GP YT minus nearest Paro
YT yeah I remember why I did
YT yeah I remember why I did
this okay so I think maybe before I
this okay so I think maybe before I
identified the problem correctly but I
identified the problem correctly but I
had the solution wrong
so let's say that you have another
so let's say that you have another
paredo point up here
paredo point up here
right and this is going to be the point
right and this is going to be the point
that you've
that you've
sampled
sampled
then what I had before is if you just
then what I had before is if you just
give it this term then why would it ever
give it this term then why would it ever
pick this point right it may as well
pick this point right it may as well
move this point as close as possible to
move this point as close as possible to
right
right
here so maybe it does a little better
here so maybe it does a little better
because it gets longer but it's like
because it gets longer but it's like
right next to an existing point so
right next to an existing point so
basically it was just filling in points
basically it was just filling in points
like this and we saw it kind of fill in
like this and we saw it kind of fill in
that way so that's what I was trying to
that way so that's what I was trying to
address maybe I didn't address
it maybe I didn't address it in a
it maybe I didn't address it in a
reasonable way
maybe it should be distance from next
maybe it should be distance from next
Paro point
okay so if it's distance to next
Point let think about
that so let's say you have a log
curve you have a log curve like
curve you have a log curve like
this and then this is it'll the log base
this and then this is it'll the log base
2 to make it easy so this is 2
2 to make it easy so this is 2
8 oh no other way
around oh yeah wait hold on 2 48 and
around oh yeah wait hold on 2 48 and
then this is going to
then this is going to
be
be
one
one
2 and then I guess I didn't really make
2 and then I guess I didn't really make
it longer so
it longer so
like the
so
so
then you have this Paro Point here is at
one so GP YT minus nearest Paro
one so GP YT minus nearest Paro
YT time nearest Paro
distance have another Point
here so if we linearize this this is
here so if we linearize this this is
going to be
roughly we can't linearize [ __ ]
um oh wait no this is why I made a third
um oh wait no this is why I made a third
point I'm
point I'm
Dum okay
so this is eight over
so this is eight over
here so if we were to score this
here so if we were to score this
point this is 1 minus nearest burito if
point this is 1 minus nearest burito if
we're going to look this
we're going to look this
way so one minus wait no two minus one
way so one minus wait no two minus one
that's the first term and then the
that's the first term and then the
distance is
distance is
four right so this is =
4 is this the optimal
suppose the question is what are you
suppose the question is what are you
trying to
do so this is not even I'm asking the
do so this is not even I'm asking the
wrong question here let me give a little
wrong question here let me give a little
bit of background because a few folks
bit of background because a few folks
are on YouTube
are on YouTube
now so this is a hyperparameter tuning
now so this is a hyperparameter tuning
algorithm uh it's based on carbs which
algorithm uh it's based on carbs which
is in VIIs parito optimal basian search
is in VIIs parito optimal basian search
method I found a bunch of weird things
method I found a bunch of weird things
with the math in that so I'm trying to
with the math in that so I'm trying to
redesign some things but the fundamental
redesign some things but the fundamental
question uh is kind of always the same
question uh is kind of always the same
it's how do you actually want to be
it's how do you actually want to be
exploring your parito Frontier like
exploring your parito Frontier like
there are some things that you can say
there are some things that you can say
like there's some properties that you
like there's some properties that you
might want your algorithm to have but uh
might want your algorithm to have but uh
it's very difficult to characterize the
it's very difficult to characterize the
overall Behavior here so let me get a a
overall Behavior here so let me get a a
fresh one if we have first of all your
fresh one if we have first of all your
parito front can have lots of different
parito front can have lots of different
shapes you can't model it as one shape
shapes you can't model it as one shape
it can look like this right it can look
it can look like this right it can look
like more like a log it can be uh is it
like more like a log it can be uh is it
linear there shouldn't intersect there I
linear there shouldn't intersect there I
think it's like this oops close enough
think it's like this oops close enough
uh you know it can be lots of different
uh you know it can be lots of different
things so you can't assume one shape
so that's part of the problem um now the
so that's part of the problem um now the
second problem right is kind of figuring
second problem right is kind of figuring
out what Behavior you want this thing to
out what Behavior you want this thing to
have I would think
have I would think
that generally a good algorithm if if
that generally a good algorithm if if
you know the Paro front exactly so let's
you know the Paro front exactly so let's
say that you have a good model of the
say that you have a good model of the
Paro front and you have some
Paro front and you have some
points then you probably want your
points then you probably want your
algorithm to
algorithm to
like fill in the Pito front
like fill in the Pito front
this would look something like a binary
this would look something like a binary
search
search
right filling in the
right filling in the
predo so I have something that kind of
predo so I have something that kind of
does
does
that but then the thing I
that but then the thing I
neglected is if the actual pero front is
neglected is if the actual pero front is
like this and you have some points over
here then what should you uh then what
here then what should you uh then what
should it look like
I've also tried several different
I've also tried several different
methods of
um like trying to get you to pay for
um like trying to get you to pay for
experiments with
experiments with
cost so like you're trying to optimize
cost so like you're trying to optimize
the total runtime of the whole hyper
the total runtime of the whole hyper
parameter
parameter
sweep that's been pretty
tricky
e e
I could just take a int on this
or Max I could just do Max one in
or Max I could just do Max one in
this that fixes the problem of not being
this that fixes the problem of not being
able to improve okay hold
on idea
that's one
idea that should do it
I also don't know why I guess why I do
I also don't know why I guess why I do
this in linear
this in linear
[Music]
[Music]
space so that would technically
space so that would technically
work that would fix this bug but I don't
work that would fix this bug but I don't
know if this is everything that we want
know if this is everything that we want
yet this is not the only bug let's show
yet this is not the only bug let's show
some of the existing experiments
so I ran
this cost mostly push down but
score really push up
and we get some
variant but this just really isn't a
variant but this just really isn't a
very good parito
here six yeah these just aren't very
here six yeah these just aren't very
good
good
now I'm trying to think the why you know
now I'm trying to think the why you know
before I go too crazy on
before I go too crazy on
this
this
um the BPT Horizon pram here is
um the BPT Horizon pram here is
suspicious to
suspicious to
me so let me start with that because I'm
me so let me start with that because I'm
a little bit
a little bit
suspicious of that
yeah even the random samples are all
yeah even the random samples are all
right let me just double check and make
right let me just double check and make
sure that's the
case okay yeah so the random samples are
case okay yeah so the random samples are
all down so that's weird
all
okay so we
okay so we
have Min random sample is a BPT Horizon
have Min random sample is a BPT Horizon
of
of
8 and Mac should be
32 here are our suggestions
BPT
BPT
Horizon yeah you see the Min should be
Horizon yeah you see the Min should be
two here but or the Min should be eight
two here but or the Min should be eight
but we get two so that is defin Inc
correct this is a uniform sample
space. unnormalized
get search Center
0.6
0.6 Dot
mm so this should be like 16
here oh you know what maybe I
here oh you know what maybe I
um hang on there was a fix that I I
um hang on there was a fix that I I
didn't take I
think yeah yeah hold on I remember I
think yeah yeah hold on I remember I
fixed this bug but then I broke
fixed this bug but then I broke
something else and I think I rolled this
something else and I think I rolled this
back
right here yeah I didn't return the
right here yeah I didn't return the
index there we go
[Music]
1610 yeah that's better
these are now what you would expect them
these are now what you would expect them
to
be okay
ah shoot I forgot that I needed to
ah shoot I forgot that I needed to
uh there's a thing that I need to do
it's fine
so we should not take this graph
so we should not take this graph
particularly
particularly
seriously um because it simply was
seriously um because it simply was
not suggesting stuff
correctly but that doesn't mean that
correctly but that doesn't mean that
everything is all fixed yet we will
see let me think about the properties
see let me think about the properties
okay so without having the bias of ah
okay so without having the bias of ah
this experiment went terribly in my head
this experiment went terribly in my head
let me think about this algorithm again
let me think about this algorithm again
from first
principles this is really the Crux of it
principles this is really the Crux of it
right here and really you can ignore
right here and really you can ignore
this so it's just this this is the whole
this so it's just this this is the whole
algorithm which is this all breaks down
too can I do
too can I do
maybe this is
maybe this is
better yeah it's
better kind of like
this
so gpy T minus nearest perrito
so in the in the case of in the optimal
case we have something like
this let's put this point like here so
this let's put this point like here so
in the optimal case you are going to
in the optimal case you are going to
fill in here uh this will push to
fill in here uh this will push to
maximum cost as well because the nearest
maximum cost as well because the nearest
distance right this is like like this
distance right this is like like this
distance so it'll push to here and on
distance so it'll push to here and on
the low end it'll push to Min cost as
the low end it'll push to Min cost as
well after it's filled in like these
points so that should be good
points so that should be good
now it does rely
on GP
on GP
YT as the distance
measure okay so there is something
measure okay so there is something
consider with the curvature here that I
consider with the curvature here that I
didn't think of too too well so if you
didn't think of too too well so if you
have it all if the algorithm is if the
have it all if the algorithm is if the
curve is a
curve is a
line then and you just take the raw
line then and you just take the raw
distance
distance
right then you will get binary search if
right then you will get binary search if
you just take that distance because
you just take that distance because
you're going to go here because this is
you're going to go here because this is
this distance times this distance is
this distance times this distance is
going to be the largest product and then
going to be the largest product and then
you're going to go like here here the
you're going to go like here here the
order will be randomized but you will
order will be randomized but you will
get
get
you know binary
you know binary
search like
search like
that okay and then the um what is it the
that okay and then the um what is it the
max or whatever that I put on it is fine
max or whatever that I put on it is fine
as
well now we are doing this on YT GP YT
well now we are doing this on YT GP YT
what is the transform that I have
what is the transform that I have
applied it is a log transform thing
plus
Epsilon
okay let's uh put some values in
so this is what you get for if you have
so this is what you get for if you have
pong
oh this gives
you you get a negative number
here we'll have to think about
here we'll have to think about
that Let's ignore the negative sign for
that Let's ignore the negative sign for
a bit so this is the lowest possible
a bit so this is the lowest possible
score in PA but if I put in
score in PA but if I put in
zero okay then you get basically zero
zero okay then you get basically zero
and get
Epsilon if I put in 10 you get 6 if I
Epsilon if I put in 10 you get 6 if I
put in 15 you get 1.25 it roughly
put in 15 you get 1.25 it roughly
doubles to get
doubles to get
closer and then if I put in 20 we're at
closer and then if I put in 20 we're at
three 20.5 there's still like a
three 20.5 there's still like a
substantial incentive to increase here
substantial incentive to increase here
and then
and then
21 it goes up to all the way to 11
be nice to have this better
normalized so just by messing with the
normalized so just by messing with the
Epsilon term right you can scale this
Epsilon term right you can scale this
thing quite a
lot as you would
lot as you would
like and that basically tells you the
like and that basically tells you the
number of zeros on the score that are
number of zeros on the score that are
going to matter
I'm going to think about this because
I'm going to think about this because
there's an interaction here that needs
there's an interaction here that needs
to be accounted for so I'm going to be
to be accounted for so I'm going to be
back in a few let me make sure this
back in a few let me make sure this
sweep is going
on okay yeah so this is the sweep is on
on okay yeah so this is the sweep is on
for sure I'll be back in a
few
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e e
Okay so
okay we'll let this one continue for a
okay we'll let this one continue for a
bit
bit
um but I'm kind of realizing
um but I'm kind of realizing
I have an exponential here right it's a
I have an exponential here right it's a
smooth exponential it's like clipped and
stuff one over
log no it's one over it's a one it's one
log no it's one over it's a one it's one
over log is what it is right or hold on
over log is what it is right or hold on
log no it's a
log no it's a
log it's log bound okay
so the scaling of these things is very
awkward I think I think I did this with
awkward I think I think I did this with
percentile scoring in
percentile scoring in
mind so like if you have
mind so like if you have
90% right then you want 95% to be better
90% right then you want 95% to be better
and 97.5 to be much
better it works with a lot of things
better it works with a lot of things
though because
though because
like you still want to get the high you
like you still want to get the high you
want to fully solve a lot of environment
want to fully solve a lot of environment
so I guess this does make
sense for
let's see what it's
let's see what it's
doing the moment on this sweep
okay so batch size is kind of stuck
okay so batch size is kind of stuck
around here maybe this should be sampled
around here maybe this should be sampled
a little
a little
more we will
more we will
uh consider increasing
that learning rates being pushed up very
that learning rates being pushed up very
high odd
one and
one and
Gamma
Lambda
Lambda
EO it's
fine it's kind of
okay m
okay m
y we get the parito
front they're
front they're
all technically parito
okay there's no way that the learning
okay there's no way that the learning
rate should be this
High Why is it setting the learning rate
High Why is it setting the learning rate
this
high oh hang on wait did I
okay it is setting
value let's make a couple quick tweaks
value let's make a couple quick tweaks
and rerun this because it's setting
and rerun this because it's setting
um it's setting coefficients that are
um it's setting coefficients that are
going to cause it to do weird things
going to cause it to do weird things
that I'm not going to be able to tell
that I'm not going to be able to tell
what's going on
I mean it should be able to tune this
I mean it should be able to tune this
though to be
fair pushing Lambda pushing all these
fair pushing Lambda pushing all these
parameters to the ceiling was very odd
though it's going for very short RS
oh hang on it's going for short runs
oh hang on it's going for short runs
here because there's
no I don't know
there might be something that's pushing
there might be something that's pushing
it this way
looks back very clearly that there is
actually
score9
score9
same cost is 14
so it thinks that it's going to
get
Point score nearby
Point score nearby
is -12
12 was it's also just not going to get
9 model's
off right
there isn't even a Paro point with -12
there isn't even a Paro point with -12
that's
weird I was doing this repeatedly hang
weird I was doing this repeatedly hang
on
yeah look it's making the same
yeah look it's making the same
recommendation repeatedly until it's
recommendation repeatedly until it's
it's slowly realizing that it's not
it's slowly realizing that it's not
working
working
out so why is it so obsessed with this
one e
so here are all the
points still trying to do it
and it's weird because it's
and it's weird because it's
wrong like the model is just
wrong
e e
this nearby
point it's still
hold
hold
nearest -20 point
s there isn't a burrito point that is
s there isn't a burrito point that is
like
like
this as far as I can see so there's an
this as far as I can see so there's an
issue here somehow
reset button on this thing really
and
silly I can't figure out why it's doing
silly I can't figure out why it's doing
this
this
though it's still doing it
for some stupid reason the models wrong
right that's what it is the score model
right that's what it is the score model
is wrong
and what does
and what does
the what's the score get dragged down
too YT nor
men
e e
brag to Mid
score it's not happening
score it's not happening
though through all these points and
though through all these points and
still predicting completely freaking
wrong okay now you have all these
wrong okay now you have all these
freaking points here right and you're
freaking points here right and you're
still going to be predicting
wrong yeah look it thinks it's getting
wrong yeah look it thinks it's getting
12 cost which is over here
wait
wait
distance even make
sense now this doesn't even make
sense oh wait maybe the Pito hold long
what actually gets logged
here score and cost
ahuh that tells us a very different
ahuh that tells us a very different
story now doesn't
it so we just have the graph
WR
okay so it thinks it's going to get -5
okay so it thinks it's going to get -5
at a cost of
12 which is very
reasonable oh no is it
reasonable oh no is it
it's still pretty
optimistic there's a point very nearby
optimistic there's a point very nearby
it says
okay so it's still a bit
unrealistic H
maybe but it thinks it's going to get a
maybe but it thinks it's going to get a
four of-5 which is
here the thing is that shouldn't even
here the thing is that shouldn't even
give you all that much
reward hang on hang on this could be the
reward hang on hang on this could be the
negative in the function screwing us
over let me
over let me
see remember we were looking at that
see remember we were looking at that
before and I ignored it for a
before and I ignored it for a
second that could be
it let me see if that negative makes
it let me see if that negative makes
sense
all e
I think this should still work cuz this
I think this should still work cuz this
one minus this
one but like is this better
than
than
three no cuz three gives you a 0.15
three no cuz three gives you a 0.15
increment
18 let's do
negative
5 gives you a
5 gives you a
0.1 that .12
or one one yeah no this is
fine -8 to -5 gives
you one two hold
on it gives you .11
no I think it's fine it's very
no I think it's fine it's very
linear um towards the
linear um towards the
bottom think
so this is low it as it goes
okay so it does give this a positive
okay so it does give this a positive
rating but
why why is this the highest positive
why why is this the highest positive
rating
and it's still doing it
very screwy
e e
I wonder if it's the mean function
maybe that would do it
we should be able to actually just
we should be able to actually just
scroll up a bunch and see depending how
scroll up a bunch and see depending how
far back the terminal
far back the terminal
goes
goes
and did it
and did it
uh
uh
oops Yeah we have all our runs
right so here are the random
right so here are the random
runs we you should be able to see what
runs we you should be able to see what
happened okay so here's our first
prediction -3 at a cost of
24 nine at a cost of
31 five it across to 30
seven
uh yeah so it looks like the score
uh yeah so it looks like the score
function just straight up never predicts
function just straight up never predicts
anything good oh here's one
anything good oh here's one
13 at a cost of 2
13 at a cost of 2
too it looks like it Nails this
one but it seems very difficult for it
one but it seems very difficult for it
to actually make those
predictions maybe I just
rescale
e e
okay so there's a large negative I can
okay so there's a large negative I can
screw it up
still ideally we have Min score and Max
still ideally we have Min score and Max
score
hey welcome
we'll start with this
one for
what was F sanitized and how does it
what was F sanitized and how does it
work it's a compile
work it's a compile
flag it tells well there various options
flag it tells well there various options
for it but it'll do stuff like array
for it but it'll do stuff like array
bounds checking memory leaks and the
bounds checking memory leaks and the
like so you're not just completely doing
like so you're not just completely doing
everything blind
yeah that's probably fine
let's see if this does
it or if this does anything
it or if this does anything
substantially different at
least crazy how uh messes
up um wall W extra and like you can get
up um wall W extra and like you can get
you can end up getting too much pedantic
you can end up getting too much pedantic
stuff if you're not careful
look this in real quick
this is definitely starting to annoy me
this is definitely starting to annoy me
though because I'm
though because I'm
getting I'm starting to get problems
getting I'm starting to get problems
that seem seem like problems of gaussian
processes
so that's probably going to be the next
so that's probably going to be the next
thing is to fiddle with other models
yeah this thing
yeah this thing
here kind of other models I don't know
here kind of other models I don't know
throw Wonder
throw Wonder
ifbm would be the same it probably SPM
ifbm would be the same it probably SPM
would probably be the same I could just
would probably be the same I could just
throw linear regression at it with a
throw linear regression at it with a
reasonable
reasonable
kernel just give it like
um I don't know like a linear log some
um I don't know like a linear log some
weird kernel we' probably just have
weird kernel we' probably just have
something work for
technically I guess the linear kernel
technically I guess the linear kernel
should be able to do that huh
well the thing is that in order to
well the thing is that in order to
really investigate this I'm going to
really investigate this I'm going to
need more time than just doing this for
need more time than just doing this for
an hour and a half in the
an hour and a half in the
morning so once contract is done we'll
morning so once contract is done we'll
probably do this over the
probably do this over the
weekend along with some other stuff
cuz I'm not entirely sure why this is
cuz I'm not entirely sure why this is
happening that it's like it's so
happening that it's like it's so
obsessed with this terrible region I
obsessed with this terrible region I
think that it's most likely doing this
think that it's most likely doing this
because um the Gan
because um the Gan
process it tries to drag everything to
process it tries to drag everything to
the mean so the farther you are from the
the mean so the farther you are from the
mean the more it drags stuff so so it's
mean the more it drags stuff so so it's
very difficult to even make good score
very difficult to even make good score
predictions like this now technically
predictions like this now technically
you can fix all this by like being very
you can fix all this by like being very
very careful about how you normalize all
very careful about how you normalize all
your data um but the thing is this is
your data um but the thing is this is
supposed to be an automatic method so
supposed to be an automatic method so
like you kind of want something more
like you kind of want something more
resilient than this in the first
resilient than this in the first
place yeah it's pretty
obnoxious so here we have this
I mean I've looked at the base method
I mean I've looked at the base method
and the base method seems to be
and the base method seems to be
mostly mostly reasonable
there are a few tweaks I could
there are a few tweaks I could
potentially still make
but if you have a linear kernel
I don't even know if there is any
locality no there is
we're very close to having this thing
we're very close to having this thing
it's just there are a few like math
it's just there are a few like math
details that don't they're not quite
details that don't they're not quite
working out here
so it's kind of the same thing
will the API be similar to
will the API be similar to
carbs yeah just less
carbs yeah just less
crap I'll show you how easy it is at the
crap I'll show you how easy it is at the
moment
all right this is
all right this is
it this is how you use neoc
carbs I'm name might be uh work in
carbs I'm name might be uh work in
progress because this is getting to be
progress because this is getting to be
pretty distant from carbs like I really
pretty distant from carbs like I really
had to re architect a lot of their stuff
but you can see it's way
easier and the thing is that the code is
easier and the thing is that the code is
going to
be so right now I have 479 lines and a
be so right now I have 479 lines and a
lot of that's like this type of debug
lot of that's like this type of debug
stuff
stuff
so let me see yeah and I don't even need
so let me see yeah and I don't even need
a half of the stuff that's in here so
a half of the stuff that's in here so
let's say it's going to be about 400
let's say it's going to be about 400
lines
lines
for the whole thing versus I think the
for the whole thing versus I think the
original repo is like 2,000
lines what haven't you changed from
lines what haven't you changed from
carbs at this
carbs at this
point well we're still using Doan
point well we're still using Doan
presses in some capacity and we still
presses in some capacity and we still
have two of the we're still predicting
have two of the we're still predicting
two of the same quantity score and cost
two of the same quantity score and cost
from the original but the the scoring
from the original but the the scoring
function is completely
function is completely
different
um yeah I mean a lot has
um yeah I mean a lot has
changed I still have like a distance
changed I still have like a distance
term and a semi acquisition term but
term and a semi acquisition term but
they're very different from the original
forms yeah to be fair a lot of it is
forms yeah to be fair a lot of it is
very
different I mean the core thing is just
different I mean the core thing is just
the idea of trying to do a Paro optimal
search oops
you can see it's still pushing this down
I do not know why it's doing this
that one was reasonable
uh found some unstable parameters
okay but it is actually now trying to
okay but it is actually now trying to
do higher cost stuff it looks
like and so
yeah okay so I was right at least I was
yeah okay so I was right at least I was
at least partially right and that what
at least partially right and that what
was happening is and this is why these
was happening is and this is why these
things are so obnoxious um it assumes
things are so obnoxious um it assumes
everything's normally distributed so I
everything's normally distributed so I
specified the mean function as the
specified the mean function as the
minimum
minimum
score in like some transform space and
score in like some transform space and
it was a pretty nicely scaled transform
it was a pretty nicely scaled transform
space but it was like I think the the
space but it was like I think the the
maximum would have been like five and uh
maximum would have been like five and uh
no that's too much for a gum process got
no that's too much for a gum process got
to drag everything aggressively down to
to drag everything aggressively down to
the mean so or to
yeah the idea of a mean function just
yeah the idea of a mean function just
doesn't even
doesn't even
make sense for this
I mean it's kind of a way of trying to
I mean it's kind of a way of trying to
make stuff conservative but
um and I don't
know I guess it could
know I guess it could
work the thing that just sketches me out
work the thing that just sketches me out
here is like it could work but it needs
here is like it could work but it needs
to be carefully tuned
so it is actually trying to go for high
so it is actually trying to go for high
cost higher cost points
here not
perfect
e e
yeah
so this is like just such a tricky thing
so this is like just such a tricky thing
to reason
about because like a gaan process gives
about because like a gaan process gives
you something that's a sort of like an
you something that's a sort of like an
approximate nearest neighbor
which sounds
good but the way in which it does it is
good but the way in which it does it is
kind of unintuitive and difficult to
kind of unintuitive and difficult to
reason
about it thought it was going to get
about it thought it was going to get
score 15
score 15
here and end up getting -7 how's this
here and end up getting -7 how's this
even happen
the cost was about right
here hang on maybe I messed something up
here hang on maybe I messed something up
with my scoring
with my scoring
function cuz that's a little bit
function cuz that's a little bit
suspicious getting like this
stuff
e e
no this is looking correct
12 of
14 it's
-20 why is the variance on this thing
-20 why is the variance on this thing
just so
just so
garbage can we add
do we have this plot
already we don't
one
zero
just no longer doing crazy things to my
just no longer doing crazy things to my
other hyper
parameters yeah but the models just
parameters yeah but the models just
completely freaking
completely freaking
wrong on these
wrong on these
costs not on the cost the cost model is
costs not on the cost the cost model is
good actually the um on the force
what do these curves look
like
like
sweep give it a
sweep give it a
bit nothing is safe
yet okay so we don't have like crazy
yet okay so we don't have like crazy
crashing
crashing
completely I'm offense
I'm looking at it nothing is reasonable
I'm looking at it nothing is reasonable
yet all right nothing actually like
yet all right nothing actually like
fully Works yet
why is it having such a hard time with
why is it having such a hard time with
this if we
this if we
do this board here
we can see the learning
we can see the learning
ratey coefficient Lambda G like we can
ratey coefficient Lambda G like we can
see where all these parameters need to
be most of these just have stable
regions
for
e
e
e
e
for e
thing that's hard is there's probably a
thing that's hard is there's probably a
lot of noise in the actual
runs and now I can't find any
runs and now I can't find any
improvements
improvements
so at the moment it thinks it can't
so at the moment it thinks it can't
improve the parito
improve the parito
front morning can you briefly describe
front morning can you briefly describe
yeah
yeah
so I mean this is my attempt at making a
so I mean this is my attempt at making a
very good uh hyper parameter sweep
very good uh hyper parameter sweep
algorithm for reinforcement learning
algorithm for reinforcement learning
it's based off of the ideas uh the Poo
it's based off of the ideas uh the Poo
optimality ideas in the MB carbs
optimality ideas in the MB carbs
paper and uh this does very well on a
paper and uh this does very well on a
number of synthetic tasks this algorithm
number of synthetic tasks this algorithm
that I have here but on the real task it
that I have here but on the real task it
seems that it
seems that it
is less than ideal I'm trying to
is less than ideal I'm trying to
characterize currently exactly what's
characterize currently exactly what's
happening and why
happening and why
um it seems
um it seems
like it might just be taking more
like it might just be taking more
samples to build up a good model because
samples to build up a good model because
there's a lot of noise in many of the
there's a lot of noise in many of the
real RL tasks uh you know you can run
real RL tasks uh you know you can run
the same hyper parameters multiple times
the same hyper parameters multiple times
with different seeds
with different seeds
and some of the runs will be stable and
and some of the runs will be stable and
some will not
some will not
be that is a separate
be that is a separate
challenge but also there are just some
challenge but also there are just some
algorithmic works these things rely on
algorithmic works these things rely on
gaussian processes which are not
gaussian processes which are not
entirely ideal all the time
entirely ideal all the time
um yeah there's some quirks of gussian
um yeah there's some quirks of gussian
processes that I'm currently annoyed by
processes that I'm currently annoyed by
so it's clear to me that you need need
so it's clear to me that you need need
some sort of
some sort of
global uh Global
global uh Global
learnability which would come from a
learnability which would come from a
linear Kel or polinomial kernel or
linear Kel or polinomial kernel or
something but that doesn't play nicely
something but that doesn't play nicely
with uh the other kernels which require
with uh the other kernels which require
a mean function it's going to basically
a mean function it's going to basically
tell you what the minimum score is and
tell you what the minimum score is and
then the maximum
cost so I'm currently considering
cost so I'm currently considering
whether gin processes are really even a
whether gin processes are really even a
good choice all um they're kind of
good choice all um they're kind of
bloated for what this
bloated for what this
is and like if you actually look at a
is and like if you actually look at a
lot of the so here if you look at like
lot of the so here if you look at like
the sweep progress so this is like what
the sweep progress so this is like what
parameters are being tried out over time
parameters are being tried out over time
you can see how the sweep
you can see how the sweep
changes you know but uh if you just look
changes you know but uh if you just look
at it this
at it this
way you can kind of see that a lot of
way you can kind of see that a lot of
these hyper parameters just have stable
these hyper parameters just have stable
regions
regions
like stable region here stable region
like stable region here stable region
here here here right and none of these
here here here right and none of these
have any impact whatsoever on the
have any impact whatsoever on the
runtime the only ones that impact the
runtime the only ones that impact the
runtime are like these
runtime are like these
ones and these ones affect both the
ones and these ones affect both the
runtime and the
cost so I'm like I'm wondering here if I
cost so I'm like I'm wondering here if I
could do some sort of simple linear
could do some sort of simple linear
model
model
with uh with like some really basic
with uh with like some really basic
featurization so I just give it like you
featurization so I just give it like you
know the values the log of the
know the values the log of the
values and maybe that's
values and maybe that's
it and see if I can fit something I
it and see if I can fit something I
don't
know I mean there's stuff like this as
know I mean there's stuff like this as
well where you have these like very
well where you have these like very
discrete values
the other thing is that the Gan process
the other thing is that the Gan process
is supposed to give you a variance
is supposed to give you a variance
estimate
estimate
which is supposed to be
which is supposed to be
useful but the thing is I've observed
useful but the thing is I've observed
that the variance estimate is just
that the variance estimate is just
complete bullets it's just completely
complete bullets it's just completely
worthless so the fact that it gives you
worthless so the fact that it gives you
a variance estimate as a selling point
a variance estimate as a selling point
the variance estimate is terrible so
the variance estimate is terrible so
it's not actually useful for
anything like it should not be it should
anything like it should not be it should
not still after running 50 experiments
not still after running 50 experiments
be dropping points down here
like how do we not have anything over 20
yet 21 should be the max not 20
I mean I've got a very simple method at
I mean I've got a very simple method at
this point that
this point that
should it's just based on your expected
should it's just based on your expected
Improvement um over the nearest parito
Improvement um over the nearest parito
optimal point and then it also the
optimal point and then it also the
runtime could play a factor
runtime could play a factor
here well no that is one of the things
here well no that is one of the things
that we're explicitly modeling there are
that we're explicitly modeling there are
two gaussian processes one of them
two gaussian processes one of them
predicts how long the experiment will
predicts how long the experiment will
take to to run and the other will
take to to run and the other will
predict how well the experiment is going
predict how well the experiment is going
to do so your goal here is to discover
to do so your goal here is to discover
the Paro front uh the Paro front being
the Paro front uh the Paro front being
the set of points for which there is
the set of points for which there is
nothing up and to the left so there's
nothing up and to the left so there's
nothing that is both better and faster
nothing that is both better and faster
so in this case the Paro front is this
so in this case the Paro front is this
point this point this point this point
point this point this point this point
this point this point this point this
this point this point this point this
point and this point so it kind of goes
point and this point so it kind of goes
like this so uh you know you would
like this so uh you know you would
expect then that there's probably some
expect then that there's probably some
points over here that you can get to do
points over here that you can get to do
better and I know that you can do better
better and I know that you can do better
over
over
here actually these points aren't parito
here actually these points aren't parito
because I think this one is higher by a
because I think this one is higher by a
little bit so yeah it should be able to
little bit so yeah it should be able to
discover something some slightly higher
discover something some slightly higher
points over
points over
here but it's not quite doing
that e
yeah so here's this one that gets no
yeah so here's this one that gets no
score because for some
score because for some
reason algorithm has decided to make the
reason algorithm has decided to make the
maximum gradient Norm zero that's
bizarre I mean this shouldn't happen is
bizarre I mean this shouldn't happen is
the
the
thing hang on do I have Max Brad Norman
thing hang on do I have Max Brad Norman
here
okay I guess that's kind of funny there
okay I guess that's kind of funny there
happened to be one decent point over
happened to be one decent point over
here so it probably caused some of these
here so it probably caused some of these
samples but still it should have very
samples but still it should have very
quickly figured out uh from these
quickly figured out uh from these
adjacent points to stop doing this
okay here's a decent burito
point there are only four parito points
point there are only four parito points
actually I think on this whole
curve a and then it moves it over
curve a and then it moves it over
here CU it ran the experiment for very
here CU it ran the experiment for very
long let see
wait what and then is it going to move
wait what and then is it going to move
it this
it this
one what happened
here
here
okay now this is fine
it shouldn't even be sampling over here
it shouldn't even be sampling over here
there's nothing for
it I guess it thinks if it fills in here
it I guess it thinks if it fills in here
there's a pretty
decent not very familiar with
decent not very familiar with
multiobjective optim
ation there's nothing particularly fancy
ation there's nothing particularly fancy
about
it I if Pito optimality is a useful
it I if Pito optimality is a useful
concept if you're not familiar with it
concept if you're not familiar with it
already but it it just says that you
already but it it just says that you
want the set of points for which you
want the set of points for which you
cannot get you cannot run the experiment
cannot get you cannot run the experiment
both faster and get a better result
both faster and get a better result
that's all it says for this case
hold on there are more than four Creo
hold on there are more than four Creo
points wait one two three four five six
points wait one two three four five six
seven8 nine Paro points here
seven8 nine Paro points here
now so it is filling in the curve but
now so it is filling in the curve but
there's just is so much garbage here
If this just thinned out a little this
If this just thinned out a little this
is
fine I don't know how it randomly gets a
fine I don't know how it randomly gets a
sample
here unless this is a Pito
here unless this is a Pito
Point yeah this has to be a Paro Point
Point yeah this has to be a Paro Point
otherwise it wouldn't be able to sample
otherwise it wouldn't be able to sample
that I don't know what this
that I don't know what this
is 044
turquoise Point
huh it's very weird
okay ignoring these CU weird stuff this
okay ignoring these CU weird stuff this
section looks
fine Lambda still kind of
fine Lambda still kind of
spread it's okay and then update
EO starting to explore over
here ry's fine
yeah it's just not predicting at all
oh hold on look at
this8 rating
zero okay so a lot of these points now
zero okay so a lot of these points now
are scoring zero meaning it just is not
are scoring zero meaning it just is not
finding any samples it thinks are good
finding any samples it thinks are good
so this one it thinks is good and then
so this one it thinks is good and then
it completely gets it
it completely gets it
wrong
zero zero
negative that's crazy that it's not
negative that's crazy that it's not
finding
finding
any anything around any of the Cito
any anything around any of the Cito
points
think we either definitely have to swap
think we either definitely have to swap
the gussian process or figure out how to
the gussian process or figure out how to
use the linear kernel
correctly
for
e e
okay well we will think about this a bit
okay well we will think about this a bit
um I'm going to go get some breakfast go
um I'm going to go get some breakfast go
get some
get some
exercise and then we have uh we have to
exercise and then we have uh we have to
finish all the robotic stuff today so
finish all the robotic stuff today so
I'll be doing that live on stream uh in
I'll be doing that live on stream uh in
the I don't know a couple hours once I
the I don't know a couple hours once I
get some food and stuff uh so we'll
get some food and stuff uh so we'll
finish all that
finish all that
today and then I will have a lot more
today and then I will have a lot more
mental bandwidth to really focus on this
mental bandwidth to really focus on this
will be good
will be good
so uh for
so uh for
folks who are interested in this stuff
folks who are interested in this stuff
you can check out all the RL I do at
you can check out all the RL I do at
puffer doai it's all free and open
puffer doai it's all free and open
source you can try out all the
source you can try out all the
environments that we have many are
environments that we have many are
written by
written by
contributors you want to help us out
contributors you want to help us out
start the repository really helps when
start the repository really helps when
people start the
people start the
repo join the Discord if you want to get
repo join the Discord if you want to get
involved we've got all sorts of material
involved we've got all sorts of material
on our
on our
docs as well as on the blog want
docs as well as on the blog want
additional RL content you can't find any
additional RL content you can't find any
anywhere else I've got articles on my X
anywhere else I've got articles on my X
for that so thank you and
