Kind: captions
Language: en
Okay, good
Okay, good
morning. We're
live. So, here's the plan for
live. So, here's the plan for
today. The latest version of Puffer Lib
today. The latest version of Puffer Lib
is doing very, very well on isolated
is doing very, very well on isolated
runs uh on a number of different
runs uh on a number of different
environments. We've set soda in the past
environments. We've set soda in the past
3, four weeks on pretty much everything
3, four weeks on pretty much everything
and by a huge margin. Uh the only last
and by a huge margin. Uh the only last
few things blocking are just a few
few things blocking are just a few
technical errors. We pretty much have
technical errors. We pretty much have
not run a fresh hyperparameter sweep in
not run a fresh hyperparameter sweep in
like a good couple of months on any of
like a good couple of months on any of
these things. So there's probably can
these things. So there's probably can
even do way better than it's doing now.
even do way better than it's doing now.
We just have some technical issues
We just have some technical issues
preventing that. Um specifically we have
preventing that. Um specifically we have
runs crashing
runs crashing
uh due to like nans and imps. Torch
uh due to like nans and imps. Torch
should not be crashing with nans and
should not be crashing with nans and
imps. Those should just be, you know,
imps. Those should just be, you know,
nanner and floss. That should not
nanner and floss. That should not
actually crash Torch. Uh the lazy fix on
actually crash Torch. Uh the lazy fix on
this would be to just throw everything
this would be to just throw everything
into a subprocess. I don't want to do
into a subprocess. I don't want to do
that. So instead, we're going to
that. So instead, we're going to
actually go through the transcript
actually go through the transcript
today. We're going to figure out why
today. We're going to figure out why
we're getting ns and imps on stuff and
we're getting ns and imps on stuff and
yeah, we're going to go from there.
yeah, we're going to go from there.
Switch the view over.
Hey man, how's it
going? Upper
indeed. Let's just get ourselves set up
indeed. Let's just get ourselves set up
here. I think we actually have some
here. I think we actually have some
errors to check
errors to check
potentially. Yeah. So this one right
here, I mean it's not going to give us
here, I mean it's not going to give us
very much information other than just uh
very much information other than just uh
policy gradient loss just
crashed. It is a multinnomial
crashed. It is a multinnomial
kernel. So I suspect that this is not
kernel. So I suspect that this is not
actually in
actually in
uh the policy gradient loss. It's
uh the policy gradient loss. It's
probably in the sample function unless
probably in the sample function unless
something else internally has
something else internally has
multinnomial.
I guess cross entropy probably
I guess cross entropy probably
internally has
internally has
it. This could also just be like a
it. This could also just be like a
pietorch versioning difference in like
pietorch versioning difference in like
what errors and what doesn't as
well. To be clear, we're not trying to
well. To be clear, we're not trying to
make it we're not trying to make it like
make it we're not trying to make it like
not fail runs because if you have bad
not fail runs because if you have bad
hypers of course the loss will explode.
hypers of course the loss will explode.
Um we just want it to not crash, right?
Um we just want it to not crash, right?
We want it to knock CUDA error
out. What this gives
out. What this gives
us? Yeah, this is just giving us on loss
us? Yeah, this is just giving us on loss
backwards. It's the same error
everywhere in either in nan or element
everywhere in either in nan or element
less than zero.
Which one was this? This is puffer grid.
Which one was this? This is puffer grid.
This one's going to be
This one's going to be
slow. This one will probably I can I
slow. This one will probably I can I
just run this on CPU and get like a
just run this on CPU and get like a
better error message.
Maybe I think that this should still run
Maybe I think that this should still run
at like a reasonable enough
pace.
Crazy. This is a thousand or 100x faster
Crazy. This is a thousand or 100x faster
than uh most academia even on
CPU. 250K. That's a quarter million step
CPU. 250K. That's a quarter million step
per second training with the CNN and
per second training with the CNN and
LSTM on
LSTM on
CPU. That's
ridiculous. Okay, so we'll see. I'm
ridiculous. Okay, so we'll see. I'm
going to just put this on the other
going to just put this on the other
monitor for a
monitor for a
bit and we will uh we'll see how that
does and then in the meanwhile
does and then in the meanwhile
here we will take a look at
uh not this we'll take a look at the
uh not this we'll take a look at the
code
code
itself and we will see if we can spot
itself and we will see if we can spot
anywhere where uh we've done a bad
anywhere where uh we've done a bad
multinnomial the only place I can think
multinnomial the only place I can think
of is in the sampling function
though. So I mean the only place we
though. So I mean the only place we
explicitly have a multinnomial that gets
explicitly have a multinnomial that gets
called is right here,
right? I guess I don't remember whether
right? I guess I don't remember whether
I added
Let's try to like get a setup that that
Let's try to like get a setup that that
uh reliably triggers this error on our
uh reliably triggers this error on our
local while we're running other stuff,
right? If I just set the learning rate
right? If I just set the learning rate
to something
to something
ridiculous, like what if I just set the
ridiculous, like what if I just set the
learning rate to like 10x higher, it
learning rate to like 10x higher, it
should instantly crash, right?
Okay. Interestingly, this
Okay. Interestingly, this
doesn't instantly
doesn't instantly
crash. It doesn't frame, but it doesn't
crash. It doesn't frame, but it doesn't
instantly crash.
What setting could there possibly have
What setting could there possibly have
been
then? That's
then? That's
bizarre.
Um, I could have like Huh.
Okay, let's
Okay, let's
try let's see if we can check hyper
try let's see if we can check hyper
prams from one of these like failed
prams from one of these like failed
runs. It like crashed on this,
runs. It like crashed on this,
right? So, we should just be able to
right? So, we should just be able to
look at like hypers for this
look at like hypers for this
maybe. We didn't even full sweep
hypers. Alpha
beta gradient
norm. I guess the giant batch
size
size
and 32k
and 32k
mini. Do we think that does it?
Is it
Is it
20 97? Whoops.
I do get a warning
here on policy
loss. This doesn't really tell me
loss. This doesn't really tell me
anything. And the losses look fine,
anything. And the losses look fine,
though.
Yeah, this also just trained
fine. I'm trying to think how we
fine. I'm trying to think how we
reliably trigger this
bug. Is it just make
um make training blow up somehow?
I guess we
like
like
here five max
here five max
crab.
crab.
See, that should blow up, right?
The fact I can't break this even if I
The fact I can't break this even if I
try is a little
ridiculous. It doesn't look like it's
ridiculous. It doesn't look like it's
logging KL.
It's not logging KL, is
It's not logging KL, is
it? Oh, it
is update. Epox
maybe. I can't think of what else.
I guess instead of doing this, I could
I guess instead of doing this, I could
like go set a few different things to
like go set a few different things to
infern and and see if I can break stuff
infern and and see if I can break stuff
that way.
So, I can't break it like
So, I can't break it like
this, which is surprising that it's that
this, which is surprising that it's that
stable.
Okay. So, this gives
me
me
mask. Where does it error?
probabil. Okay, so this gives me the
probabil. Okay, so this gives me the
same error
same error
here. And then if I do
train.device. Yeah. So there's
train.device. Yeah. So there's
multinnomial and then we
do probably do this as well, right?
Okay. Interestingly, we still have
Okay. Interestingly, we still have
this.
Try props.
This is supposed to be plus not
This is supposed to be plus not
times boolean
addition.
No. Okay. Okay. So now we get in sample
No. Okay. Okay. So now we get in sample
logits we get
errors. What is the correct way to do
errors. What is the correct way to do
this?
or did they do is this uh
I don't think this is
I don't think this is
enabled by default.
Wait, this is forward pass, right?
Logitative
problems.
Huh. It does seem like something is off
Huh. It does seem like something is off
here.
I I don't remember Torch ever doing
I I don't remember Torch ever doing
this. Like this feels like something
changed, right? You know, you used to
changed, right? You know, you used to
get like Nan loss or whatever.
Max
Max
logic. This doesn't
logic. This doesn't
work with nan.
Well, I guess technically the other
Well, I guess technically the other
thing we could try to do is we could try
thing we could try to do is we could try
to detect
to detect
this and we could try to end the run.
Maybe that seems bad.
N to
numb. Wait.
numb. Wait.
Nan pause
Nan pause
in. Okay. Wait. They have a thing for
in. Okay. Wait. They have a thing for
this.
replaces nan positive infinity and
replaces nan positive infinity and
negative
negative
infinity. Okay, that's
good. I didn't know that this function
good. I didn't know that this function
exist
exist
existed. So we have to do
existed. So we have to do
this only before action
sampling. I think other losses like KL
sampling. I think other losses like KL
should be fine, right?
Okay, so this is specific to prob
distributions nor uh okay distributions
distributions nor uh okay distributions
we handle
we handle
these cross entropy obviously uses it in
these cross entropy obviously uses it in
softmax
arithmetic obser
operations. Well, I guess we'll see
operations. Well, I guess we'll see
whether this is stable,
right? But yeah, let's start with uh
right? But yeah, let's start with uh
let's start with this for sure.
OBS
and pause in equals
none. So it's 0
none. So it's 0
0 like
this and then
this and then
[Music]
[Music]
multi. Yeah, this is the only
multi. Yeah, this is the only
multinnomial
multinnomial
here. So we do
What would you want logits to
be
be
props? What does logistics to props do?
to do
sigmoid. I think we want to do negative
sigmoid. I think we want to do negative
infinity, don't
we? And then this here is going to be a
we? And then this here is going to be a
little different. So,
nan, we'll see what this does.
contains. Okay, so this still
contains. Okay, so this still
somehow messes up.
I thought that you can put this into
I thought that you can put this into
logistics to props.
I thought you could put this into
I thought you could put this into
logistic props.
No. Oh, actually this is my fun. Is this
No. Oh, actually this is my fun. Is this
my
my
function? No, this is not portrait
function? No, this is not portrait
distribution.
Oh, it's just a soft
Oh, it's just a soft
max. Well, that's dumb. We don't need to
max. Well, that's dumb. We don't need to
have. We need to have this,
have. We need to have this,
right? We can totally replace
right? We can totally replace
this. And then what is it? Soft
max. Okay, I got to go do stuff for like
max. Okay, I got to go do stuff for like
10 minutes. I'll be back and uh we will
10 minutes. I'll be back and uh we will
continue fixing this. I'm going to leave
continue fixing this. I'm going to leave
stream on. I'm just going to mute the
stream on. I'm just going to mute the
mic. Don't let me forget to unmute it.
mic. Don't let me forget to unmute it.
Be back soon.
Okay, back
here.
here.
Let's fix this bug.
Is that a CrossFit gym with a desktop
Is that a CrossFit gym with a desktop
and 4090s in the back? Not
quite. This is the puffer training
quite. This is the puffer training
facility. It is where I train agents and
facility. It is where I train agents and
where I train myself.
where I train myself.
Uh, the equipment is not all here yet.
Uh, the equipment is not all here yet.
There's much much more coming. For now,
There's much much more coming. For now,
I just
I just
have I've got
have I've got
the the rack with the fun pull-up bars,
the the rack with the fun pull-up bars,
got the climbing rope, got the log for,
got the climbing rope, got the log for,
the bench, and then I've got the uh the
the bench, and then I've got the uh the
comp bench in the back. We're getting
comp bench in the back. We're getting
uh I think in a week or so, we're
uh I think in a week or so, we're
getting a bunch of new bars and some
getting a bunch of new bars and some
like nice accessory things. And then
like nice accessory things. And then
there are four commercial grade pieces
there are four commercial grade pieces
of equipment that'll show up in about a
of equipment that'll show up in about a
month. Plus, I got to get um I got a
month. Plus, I got to get um I got a
quote from a bunko for dumbbells. I got
quote from a bunko for dumbbells. I got
to get a full dumbbell set as
well. Now, the one desktop, that's a
well. Now, the one desktop, that's a
little trickier. We're going to get 40
little trickier. We're going to get 40
of those, but not until the tariffs come
of those, but not until the tariffs come
down because I'm not playing paying plus
down because I'm not playing paying plus
40% for
40% for
desktops. But yeah, then we will get 40
desktops. But yeah, then we will get 40
of them and then uh the majority of them
of them and then uh the majority of them
will be allocated to like all the open
will be allocated to like all the open
source stuff that Puffer does. So
source stuff that Puffer does. So
ideally we are able to provide compute
ideally we are able to provide compute
for a bunch of contributors, people who
for a bunch of contributors, people who
are interested in doing RL work with us.
are interested in doing RL work with us.
Uh all free all open
source. I mean we already do that now.
source. I mean we already do that now.
We have uh 10 of them total at the
We have uh 10 of them total at the
moment. Only one of them is here. The
moment. Only one of them is here. The
other ones are in Florida. But uh
yeah. Oh, and also that one in the back
yeah. Oh, and also that one in the back
is not 4090. That one's a 5090.
The
heck interesting way to spend seed
heck interesting way to spend seed
funding. There's no seed
funding. Buffer is bootstrapped.
The
The
um the gym equipment is not puffer
um the gym equipment is not puffer
stuff, right? That's just my personal
stuff, right? That's just my personal
stuff. Um the machines will be on uh
stuff. Um the machines will be on uh
puffer. Uh you know, we're doing pretty
puffer. Uh you know, we're doing pretty
well so far. Like we have revenue. Uh 40
well so far. Like we have revenue. Uh 40
bucks is a big ask. So some of that will
bucks is a big ask. So some of that will
also be from my personal um like I'm
also be from my personal um like I'm
going to be spons uh spotting some of
going to be spons uh spotting some of
that. But uh you know at the current
that. But uh you know at the current
rate we should be definitely more than
rate we should be definitely more than
breaking even on that this year.
breaking even on that this year.
So big expense but we're doing all right
So big expense but we're doing all right
with
it. I specifically did not want to get
it. I specifically did not want to get
seed funding so I don't have strings
seed funding so I don't have strings
attached to what I can do, right? Like
attached to what I can do, right? Like
I'm really big on all the open source
I'm really big on all the open source
work. I want to keep like you know as
work. I want to keep like you know as
soon as you start talking to VCs they
soon as you start talking to VCs they
say, "Oh yeah, open core. Yeah, it's
say, "Oh yeah, open core. Yeah, it's
good." It's like, yeah, open core. Like,
good." It's like, yeah, open core. Like,
they want you to make some
they want you to make some
non-opensource stuff separate. Like, no,
non-opensource stuff separate. Like, no,
it's all open source just there. There's
it's all open source just there. There's
what it is. And uh this is just a much
what it is. And uh this is just a much
better way to build things.
Apparently, you can't
Apparently, you can't
just I thought you could put negative
just I thought you could put negative
infinities into um into a soft
max. Oh, I guess you can't put all
max. Oh, I guess you can't put all
negative
negative
infinities into a soft max. Is that the
infinities into a soft max. Is that the
problem?
If we do like
If we do like
logets zero.
But we do like
zero
zero budgets to
props. Okay, so this
props. Okay, so this
actually that actually
actually that actually
works. So I guess you can't have all
works. So I guess you can't have all
names in there.
I guess multinnomial doesn't need
I guess multinnomial doesn't need
probabilities either though. What
probabilities either though. What
happens if you put zeros into
multinnomial sum of probability is less
multinnomial sum of probability is less
than equal
than equal
zero. So
um we just do this directly in prob
um we just do this directly in prob
space
maybe if we do
maybe if we do
like yeah here bot uh if we do this
like yeah here bot uh if we do this
directly in prob
space. Let me make sure I block the
space. Let me make sure I block the
right. Yeah good.
Torch.num nan to
Torch.num nan to
num probs 0 0
0 and um I guess what we'll do is
0 and um I guess what we'll do is
instead of doing zeros we'll do
instead of doing zeros we'll do
like 1 e minus 8 or
something let's see about
this cannot
access what I mess up
here.
here.
Okay. See if this is
stable. All right. So now this is
stable. All right. So now this is
correct. All the losses are nans here.
correct. All the losses are nans here.
Um but this is what we want. We wanted
Um but this is what we want. We wanted
it. So if you have nans it should not
it. So if you have nans it should not
crash.
Now, if I run this on
Now, if I run this on
CUDA, does it still not
CUDA, does it still not
crash? Perfect. So, I think that this
crash? Perfect. So, I think that this
should be good. I think we should be
should be good. I think we should be
good with
this. You see, I explicitly put this
this. You see, I explicitly put this
infant there.
infant there.
Let me make sure it's still
trans. Oh, we also want to do the same
trans. Oh, we also want to do the same
thing in um we want to add like an
thing in um we want to add like an
epsilon or something
epsilon or something
to the pyro maybe.
Yeah, we want to add uh to
pyro. There's this like normalization
pyro. There's this like normalization
operation,
right? Do max
score. So this is
like abs
like abs
+ 20 - 6 or thing.
Then this
is I think this is all of
them. This should be all of
them. All
right. So, uh, this one here actually
right. So, uh, this one here actually
hasn't crashed yet, though. Like, it's
hasn't crashed yet, though. Like, it's
running 10x slower, so it would take 10x
running 10x slower, so it would take 10x
longer to crash. Anyways, uh what we'll
longer to crash. Anyways, uh what we'll
do for
now pull the release
branch
train and we'll hope that this
train and we'll hope that this
actually Oh, yeah. I forgot I did a
actually Oh, yeah. I forgot I did a
whole bunch of refactoring at the same
whole bunch of refactoring at the same
time that I didn't account for.
else. Upper li
So, I just I moved a bunch of files
around.
Uh, you know, I was like waiting for
Uh, you know, I was like waiting for
these experiments to come back, so I
these experiments to come back, so I
just I did some refactoring and I broke
just I did some refactoring and I broke
some stuff.
Okay, so now it
Okay, so now it
works. I will uh wait for one experiment
works. I will uh wait for one experiment
before
before
I before I fully set up the new ones on
I before I fully set up the new ones on
this one as
this one as
well because we're going to do two boxes
well because we're going to do two boxes
worth of experiments.
This is not up to date. Oh, this is the
This is not up to date. Oh, this is the
same
tab. Same
tab. This is the other tab.
Okay. So, uh you can see the result of
Okay. So, uh you can see the result of
the latest refactor here. Deleted three.
the latest refactor here. Deleted three.
One, two, three, four, five, six, seven,
One, two, three, four, five, six, seven,
eight, nine. Nine files. added one file
eight, nine. Nine files. added one file
minus 500 lines. Good
minus 500 lines. Good
refactor. This seems to run stably
refactor. This seems to run stably
enough.
enough.
So, we will just go ahead and run our
experiment. And uh now we will have
experiment. And uh now we will have
breakout sweep and maze sweep both
breakout sweep and maze sweep both
running.
Just detach the
T-Moxes. Make sure I haven't missed any
T-Moxes. Make sure I haven't missed any
DMs. Set myself an alarm for
DMs. Set myself an alarm for
uh meeting later
today. Okay, cool.
Uh hopefully this is
Uh hopefully this is
fixed. We will see
fixed. We will see
shortly. Uh what we should expect to
shortly. Uh what we should expect to
happen
happen
here. So I have this set up in Neptune.
here. So I have this set up in Neptune.
A whole bunch of these
A whole bunch of these
runs. And see here we have three runs
runs. And see here we have three runs
that have just gone on this set. And
that have just gone on this set. And
then there's one run on this set so far.
then there's one run on this set so far.
If I just like click this tab
If I just like click this tab
here, I you know move some
things then we see this is the initial
things then we see this is the initial
run. The initial run is using the center
run. The initial run is using the center
point of the search distribution. So
point of the search distribution. So
it's meant to give you like a reasonable
it's meant to give you like a reasonable
starting point and then it's going to
starting point and then it's going to
take a while after that for to find uh
take a while after that for to find uh
to figure out some good parameters to
to figure out some good parameters to
sample. Uh actually there's some
sample. Uh actually there's some
corrections we can make I think to
corrections we can make I think to
sweeps as well. There's some things I
sweeps as well. There's some things I
want to try with this. Um, but then
want to try with this. Um, but then
yeah, we will have these running
yeah, we will have these running
throughout the day and we will see what
throughout the day and we will see what
else there is uh to work on for the
else there is uh to work on for the
release. I'm going
release. I'm going
to difference between Neptune and Wani.
to difference between Neptune and Wani.
Uh, so far I've been liking Neptune
Uh, so far I've been liking Neptune
more. I've been using it for the past
more. I've been using it for the past
few months. Puffer lip supports both. I
few months. Puffer lip supports both. I
really like how you can just define
really like how you can just define
dashboards with like different groups of
dashboards with like different groups of
plots and then you can apply this
plots and then you can apply this
dashboard view to any of the different
dashboard view to any of the different
groups of plots that you have here. Like
groups of plots that you have here. Like
it's really easy to make these nice
it's really easy to make these nice
views and to do my analysis. It's quite
views and to do my analysis. It's quite
nice. It's also more performant overall.
nice. It's also more performant overall.
All right, back into and just get a
All right, back into and just get a
little bit of exercise in here. what the
little bit of exercise in here. what the
equipment is for. And uh we will think
equipment is for. And uh we will think
about what we do what we do next.
All right.
So far so
So far so
good.
Now, there's one thing I want to look at
Now, there's one thing I want to look at
on the sweeps real
quick. Yeah. So this cost thing here I'm
quick. Yeah. So this cost thing here I'm
not appending
not appending
cost. So what's what's this actually
cost. So what's what's this actually
doing for cost time
steps simple
linear. Oh, so this is just not going to
linear. Oh, so this is just not going to
I
I
see. Yeah, this will totally mess up
see. Yeah, this will totally mess up
sweeps. It's a good thing I caught this
sweeps. It's a good thing I caught this
because the sweeps probably run stably
because the sweeps probably run stably
now. But
now. But
um yeah, this is not going to work well.
um yeah, this is not going to work well.
So the way that the uh the sweeps work,
So the way that the uh the sweeps work,
we take the trajectory. So we basically
we take the trajectory. So we basically
we take this plot that we that we see
we take this plot that we that we see
from training, right? And the way the
from training, right? And the way the
puffer sweep algo works, we cut this up.
puffer sweep algo works, we cut this up.
We like down sample it to 10 points
We like down sample it to 10 points
instead of however many points are on
instead of however many points are on
this graph. And then we pass those 10
this graph. And then we pass those 10
points to a learned model. So it maps
points to a learned model. So it maps
like this number of h this number of
like this number of h this number of
step training steps with these
step training steps with these
hyperparams to that level of
hyperparams to that level of
performance. Um so it's not getting all
performance. Um so it's not getting all
those numbers right now. So, I guess
those numbers right now. So, I guess
what we doing right now, we will fix
what we doing right now, we will fix
that. And then once we fix that, we'll
that. And then once we fix that, we'll
figure out what else to do on uh
figure out what else to do on uh
optimizing today. A whole bunch of
optimizing today. A whole bunch of
pre-release work to do.
I don't remember
I don't remember
why. I guess because the profile doesn't
why. I guess because the profile doesn't
have uptime anymore.
I can just do this for now, right?
Eval and
train like
this. We'll just do
this. We'll just do
cost.append that
Oh, there's also just Hang on. I can
Oh, there's also just Hang on. I can
just do
just do
uptime as part of the train run, which
uptime as part of the train run, which
would be better, right? I can just not
would be better, right? I can just not
even have this.
I can just do data that is it clean
I can just do data that is it clean
puffer
uptime. I think it's just puffer
here. Time minus start
here. Time minus start
time. It should be fine.
Let's add this to breakout and let's see
Let's add this to breakout and let's see
if it does anything different.
Okay, so this is what we were getting
Okay, so this is what we were getting
initially and we should actually see a
initially and we should actually see a
pretty big difference
pretty big difference
um because it's like it's very difficult
um because it's like it's very difficult
for it to learn well the the hyperparam
for it to learn well the the hyperparam
sweep can't really learn anything. It
sweep can't really learn anything. It
becomes closer to a random search uh
becomes closer to a random search uh
without that additional arg.
without that additional arg.
Let's just see how well it was
Let's just see how well it was
doing. We're still finding some
doing. We're still finding some
stuff. Uh but I think we should expect
stuff. Uh but I think we should expect
it to do substantially better than
it to do substantially better than
this. Yeah, we should expect
this. Yeah, we should expect
substantially better
substantially better
uh
results. Just making sure that I didn't
results. Just making sure that I didn't
break
it. Did I get the last point right?
Yes, I did. I did get the last point
right. All right. So, this is working
fine. This
fine. This
window, same thing.
and then this should actually give us
something 2.2 mil per
something 2.2 mil per
model. All right. So that should be
model. All right. So that should be
sweeps uh fixed and if not we will find
sweeps uh fixed and if not we will find
that out later when we get uh some
that out later when we get uh some
actual know some substantial results
actual know some substantial results
back from
this. Go back to the to-do
list. So the um kind of the name of the
list. So the um kind of the name of the
game for the next few weeks is going to
game for the next few weeks is going to
be prepare for release.
be prepare for release.
Um, so no really new big features going
Um, so no really new big features going
in at the moment. Just like trying to
in at the moment. Just like trying to
polish up everything that we have. Uh,
polish up everything that we have. Uh,
deliver some really nice baselines, make
deliver some really nice baselines, make
it really easy to use, do any last
it really easy to use, do any last
little performance
little performance
tweaks. That's kind of the
tweaks. That's kind of the
idea. My hope is that this block doesn't
idea. My hope is that this block doesn't
take too long and then, you know, we're
take too long and then, you know, we're
able to get this release out within the
able to get this release out within the
next couple of weeks. It's a lot of work
next couple of weeks. It's a lot of work
and it's a lot of quite boring work
and it's a lot of quite boring work
frankly as well. But um the idea is once
frankly as well. But um the idea is once
I finish this block so once we do this
I finish this block so once we do this
release which is going to be uh mostly
release which is going to be uh mostly
like
like
cleanup benchmarking
cleanup benchmarking
uh doing the packaging you know the
uh doing the packaging you know the
refactor and packaging and then writing
refactor and packaging and then writing
the blog post and stuff for release.
the blog post and stuff for release.
Once we get all that done and we have
Once we get all that done and we have
this out, then the next block for the
this out, then the next block for the
next uh probably like a month or
next uh probably like a month or
whatever is going to be some hardcore
whatever is going to be some hardcore
algorithm development. It's going to be
algorithm development. It's going to be
uh pretty much going back through
uh pretty much going back through
everything that DeepMind has done over
everything that DeepMind has done over
the last five years and trying to see
the last five years and trying to see
what they figured out and uh how we can
what they figured out and uh how we can
like leverage what works and toss what
like leverage what works and toss what
doesn't.
Okay.
Okay.
So, layer norm, we tried that. Let's
So, layer norm, we tried that. Let's
just go through everything. Why not? Uh,
just go through everything. Why not? Uh,
layer norm, we tried. It sometimes
layer norm, we tried. It sometimes
works, it sometimes doesn't. It's not a
works, it sometimes doesn't. It's not a
clear win. Value function batch
clear win. Value function batch
norm. Norm not over many. Yeah, we could
norm. Norm not over many. Yeah, we could
actually mess with a few small things
actually mess with a few small things
here.
here.
Okay, retune batch size. We're doing
Okay, retune batch size. We're doing
that
that
now. Basic model architecture scaling.
now. Basic model architecture scaling.
We did that. It works. Analing
We did that. It works. Analing
gamma. We didn't really mess with this
gamma. We didn't really mess with this
and we're not going to do that this
and we're not going to do that this
release. Harder algorithm stuff is going
release. Harder algorithm stuff is going
to be for next
to be for next
segment. Fix dumb end bindings. We
segment. Fix dumb end bindings. We
did transpose obs. We tried this. It
did transpose obs. We tried this. It
didn't. We didn't need to do it. We just
didn't. We didn't need to do it. We just
profile ordering. We did this. Compile
profile ordering. We did this. Compile
and AMP shenanigans. We did this really
and AMP shenanigans. We did this really
clean multi benchmarking. I need to make
clean multi benchmarking. I need to make
a script for that. Still all M's a
a script for that. Still all M's a
normalized score. We did
normalized score. We did
it. Run script to do all runs under one
it. Run script to do all runs under one
tag. Yeah, this is the same thing as
tag. Yeah, this is the same thing as
this. We'll do that. Mean cross scores.
this. We'll do that. Mean cross scores.
This will work as soon as that's done.
This will work as soon as that's done.
Uh, this needs ablations but is
Uh, this needs ablations but is
done. This needs ablations but is done.
done. This needs ablations but is done.
This is done.
Done. This is the same as this. We kind
Done. This is the same as this. We kind
of did everything
of did everything
else. We do need to run some tests on
else. We do need to run some tests on
distributed
training. We do need to get meta
running and preset does.
running and preset does.
Okay. And then the rest of this is
remove some some old files and
remove some some old files and
functions. Mostly done. I think there's
functions. Mostly done. I think there's
only maybe some stuff in PyTorch we can
only maybe some stuff in PyTorch we can
find, but I think we mostly got rid of
find, but I think we mostly got rid of
redundant stuff. We do have to go like
redundant stuff. We do have to go like
make Atari and all the other M's work.
make Atari and all the other M's work.
Merge small files into puffer lib. We
Merge small files into puffer lib. We
did lip range for continuous policy. So
did lip range for continuous policy. So
we found that out the other day. We have
we found that out the other day. We have
not done this yet.
not done this yet.
And then there's some notes to add.
And then there's some notes to add.
Cool. Oh, and I forgot to mention docs.
Cool. Oh, and I forgot to mention docs.
Yeah, we still need to do new docs for
Yeah, we still need to do new docs for
the new release as well. So, that's
the new release as well. So, that's
going to be a
pain. I think that the best thing we can
pain. I think that the best thing we can
do right now is to start getting some of
do right now is to start getting some of
the other M's working cuz uh you know, I
the other M's working cuz uh you know, I
probably broke some bindings and stuff
probably broke some bindings and stuff
with those and uh meta needs to still
with those and uh meta needs to still
work. That's a big end. And probably
work. That's a big end. And probably
later today, Spencer will be around and
later today, Spencer will be around and
uh Spencer will want to take a look at
uh Spencer will want to take a look at
GPU drive as well. Try to make that work
GPU drive as well. Try to make that work
for him. Got impulse wars from Captain.
for him. Got impulse wars from Captain.
I think that pretty much there two
I think that pretty much there two
things that we have other than like the
things that we have other than like the
final
final
experiments. The two things we have, we
experiments. The two things we have, we
need to clean up little bits of the
need to clean up little bits of the
training code here and there and then we
training code here and there and then we
need to get like good benchmarks on all
need to get like good benchmarks on all
the M's. Once train code is clean and we
the M's. Once train code is clean and we
have good benchmarks, I will be
have good benchmarks, I will be
comfortable running final experiments
comfortable running final experiments
and shipping. So those are the two
and shipping. So those are the two
things start with
meta. Let's see if we can get that to
work. Actually, let's just upgrade.
work. Actually, let's just upgrade.
Let's just like do the full upgrade on
Let's just like do the full upgrade on
this right now.
So, uh, this is one of the keys we're
So, uh, this is one of the keys we're
looking at
looking at
here. It's this like kind of
here. It's this like kind of
factorioesque. Not really. It's like the
factorioesque. Not really. It's like the
agents collect resources, then they put
agents collect resources, then they put
them into converters and get other
them into converters and get other
resources, so on and so forth.
I have to make their script
311. That
311. That
it. Oh yeah, they made this script a
it. Oh yeah, they made this script a
whole bunch simpler it looks
like. You must be in the metaconda m to
like. You must be in the metaconda m to
run this. God damn it. They made
run this. God damn it. They made
required.
Uh, that
sucks.
sucks.
Huh? Can I just like do these
Huh? Can I just like do these
independently?
Why is this installing torch
27? That's just going to break. Why? Why
27? That's just going to break. Why? Why
is it doing this?
is it doing this?
They have this like specified in
requirements. Oh, they have freaking
requirements. Oh, they have freaking
torch RL in here which then pins
Where do they actually set up
meta? Don't do it anywhere here.
Check out and Hold.
So they don't have meta in here at all,
So they don't have meta in here at all,
right?
Metagrid.sh. Okay. So this has
Metagrid.sh. Okay. So this has
separate I see. So they didn't actually
separate I see. So they didn't actually
move it into one package.
Yeah. So, they didn't actually fully
Yeah. So, they didn't actually fully
port this at
port this at
all. They just like put it into the
repo.
Um, tons of
Um, tons of
these. This doesn't have requirements
these. This doesn't have requirements
listed at all.
It seems that does something.
Let's see if this will build Syon for
us. We can just use this as
us. We can just use this as
is. Looks like we're going to have to
is. Looks like we're going to have to
rewrite this and see this. The thing is
rewrite this and see this. The thing is
this is kind of
this is kind of
already in uh Python and
C++. But yeah, absolutely. I could make
C++. But yeah, absolutely. I could make
this thing way faster and simpler.
We have a good collaboration with the uh
We have a good collaboration with the uh
the folks that make this. Um the one
the folks that make this. Um the one
tricky thing is just the way that we
tricky thing is just the way that we
tend to build stuff is very very
tend to build stuff is very very
different. They have like a very big
different. They have like a very big
step big tech style approach to doing
step big tech style approach to doing
things where like everything is highly
things where like everything is highly
modularized. Um and Puffer is the exact
modularized. Um and Puffer is the exact
opposite. We like really try to just
opposite. We like really try to just
like contain
like contain
everything like as much as possible to a
everything like as much as possible to a
few simple components which are even
few simple components which are even
intended to just read the source code
intended to just read the source code
of. They're not meant to be
abstracted. But we've basically what
abstracted. But we've basically what
we've done is we've done our best to
we've done is we've done our best to
like make these things cross-co
like make these things cross-co
compatible in a way that they can build
compatible in a way that they can build
in the way that they want to build and
in the way that they want to build and
we can build our stuff in the way that
we can build our stuff in the way that
we want to build and you know we can
we want to build and you know we can
still ship them useful things and then
still ship them useful things and then
you know we can still use their end in a
you know we can still use their end in a
way that's useful for testing.
I think we're going to have to do the
I think we're going to have to do the
new API port as well,
right? Uh, that is this one's on me. I
right? Uh, that is this one's on me. I
got to fix this.
Okay.
Okay.
So, right, I put numbum M's and num I
So, right, I put numbum M's and num I
put all this stuff into vec, not into
M upper
li. Yeah. So this goes into
vec. So I don't know why I did
that. Make end from Yeah. So now this is
that. Make end from Yeah. So now this is
where we have to do the
port make M from config. And I think
port make M from config. And I think
this is where we have to
this is where we have to
like see how they did it.
They should have some like scripts or
They should have some like scripts or
whatever.
I'm just going to check this on their
I'm just going to check this on their
web UI. There's like too much stuff to
web UI. There's like too much stuff to
even look
at. Is it
at. Is it
tools? I think it is
tools. So then they do
tools. So then they do
Omega
comp.load. I don't think that this is it
though. Set up meta
though. Set up meta
n set up
metag. Set up
metag. Set up
util runtime configuration.
set up metag of
set up metag of
config. So I think we can just
do. This doesn't return you an end.
Yeah, this doesn't even return to an
Yeah, this doesn't even return to an
end.
Where do they actually get the
end? They
end? They
don't. So they get
don't. So they get
train and then train is
train and then train is
this. So they do load the
config. They have their own policy
store
config.trainer. So I guess this somehow
Is it somehow in puffer like their
Is it somehow in puffer like their
puffer
code?
Yes. This takes a
config. So they have config from path
config. So they have config from path
here.
Where does the end like where do they
Where does the end like where do they
actually make the
end? Make
end. Wait, what?
Meta Sim back ends.
Oh, I guess it's literally they just
Oh, I guess it's literally they just
pass they just pass the config
pass they just pass the config
to the end,
to the end,
right? Okay. Okay. So then all I need to
right? Okay. Okay. So then all I need to
know is how they load it, which I think
know is how they load it, which I think
I saw already.
I think it is just
I think it is just
nomeg.load,
nomeg.load,
right? So I can I just do
right? So I can I just do
that? But can I just do like n equal or
that? But can I just do like n equal or
config equals
Just import Omega
comp. import
Omega. Okay. And then you load
Omega. Okay. And then you load
this. And then where is
this. And then where is
the end
the end
creation thing?
The end of creation
thing probably
this. So
it's from
it's from
Metagrid Metagrid N. import Metagrid
Metagrid Metagrid N. import Metagrid
N. This takes an N config.
Yeah, like
this. And does this take a
buffer? This does take buffer.
And then this should probably
And then this should probably
go after
this. I don't
this. I don't
know. We'll do this for now.
Metagrid M
init. Okay. So we do render
mode and this doesn't have seed yet.
Okay, this is a Python 311
Okay, this is a Python 311
issue. Um, I knew I was going to have to
issue. Um, I knew I was going to have to
fix this at some
point. So, for some reason, the Python
point. So, for some reason, the Python
devs decided that slice should not be
devs decided that slice should not be
hashable, and then they decided it
hashable, and then they decided it
should be hashable, and now it's like
should be hashable, and now it's like
there's a breaking change from 311 to
there's a breaking change from 311 to
312.
Um, we'll just use the
Start. This LSTM here
Okay. And
Okay. And
then
then
lib.utils. This is API stuff that we've
changed. Okay, so this does
run. Cool.
We'll just uh Neptune this
We'll just uh Neptune this
thing and we will see what this does out
thing and we will see what this does out
of the
box. See what this does out of the box
box. See what this does out of the box
in a few
in a few
minutes.
Meanwhile, maze looks like it
Meanwhile, maze looks like it
crashed. Yeah, these look like they
crashed. Yeah, these look like they
might have both
crashed. We did get some better results
though.
Interesting. Well, let's let's get
Interesting. Well, let's let's get
this Yeah, it's going to be a lot of
this Yeah, it's going to be a lot of
context switching today. Let's get this
context switching today. Let's get this
to run.
to run.
And then we'll have this window
up. Oh, maybe this is still
going because this just
launched. So, here's our run that we
launched. So, here's our run that we
have for the thing we just
have for the thing we just
launched. And let's go check. Let's go
launched. And let's go check. Let's go
check to see if either of these crashed.
This looks totally fine,
This looks totally fine,
right? Yep. So, breakout is still
right? Yep. So, breakout is still
going. And then
here. This one did
crash. Error while computing log
crash. Error while computing log
prop at site Y.
What on earth is this?
What on earth is this?
Pyro. It isn't
pyro. Okay. So then the only thing
pyro. Okay. So then the only thing
that's left here is it seems like it is
that's left here is it seems like it is
possible for
possible for
um uh the
um uh the
actual sweep itself to still error out.
We will double check
that. Where do we think we could get NS
that. Where do we think we could get NS
in here?
The score is not something that can be
The score is not something that can be
nanable because we don't use the loss
nanable because we don't use the loss
for the Four.
So somehow
So somehow
here uh something is not
here uh something is not
getting propagated correctly.
Oh, wait. Log C minus log C
Oh, wait. Log C minus log C
min. This could
be if this is
zero. Well, then we're just training
zero. Well, then we're just training
everything to map to zero, right?
and then 0 divided by 1 e 1 e minus
6 is
6 is
zero. I don't think that it's possible
zero. I don't think that it's possible
that you get um nans in the training
that you get um nans in the training
data, but I mean I guess
data, but I mean I guess
oops I forgot I had multiple
workspaces. What is this going to tell
workspaces. What is this going to tell
us here?
So GPUs train is where this
So GPUs train is where this
breaks
428 it breaks on this GP cost and cost
428 it breaks on this GP cost and cost
opt
GP cost is the
process. What's cost
opt? Oh, the
optimizer. So, it's just uh this data
optimizer. So, it's just uh this data
that's set from here.
It's a mapping from
params the log C
norm I can just do
like and do something like this.
And is this a um is this a CUDA
And is this a um is this a CUDA
error or can I catch
error or can I catch
this? I actually think we can catch this
this? I actually think we can catch this
because that's not a CUDA error, right?
because that's not a CUDA error, right?
That's like a validation
error. We do try
What line was
it? GP.util.train.
friend. Okay.
So, we redo this
So, we redo this
sweep. And now we should hopefully get a
sweep. And now we should hopefully get a
break point the next time it
break point the next time it
crashes because I think we got all of
crashes because I think we got all of
the nan bugs out of the main
the nan bugs out of the main
transcript. There's like one last
transcript. There's like one last
potential
potential
instability uh in the inputs to
instability uh in the inputs to
pyro and then hopefully we should have
pyro and then hopefully we should have
stable
stable
sweeps. Go check on this
sweeps. Go check on this
experiment. Okay. So, yeah, this is
experiment. Okay. So, yeah, this is
unfortunately this is on par with the
unfortunately this is on par with the
previous
previous
uh not so great train
uh not so great train
runs where they get stuck at 0.5.
Pyro is uh it's the Gaussian process
Pyro is uh it's the Gaussian process
optimizer that we're using. It's like
optimizer that we're using. It's like
um it's just like a torch extension
um it's just like a torch extension
library that has Gaussian processes and
library that has Gaussian processes and
stuff in it. So we will unfortunately
stuff in it. So we will unfortunately
have to add that as a depth unless we
have to add that as a depth unless we
want to implement our own Gaussian
want to implement our own Gaussian
processes which are really annoying to
processes which are really annoying to
implement.
Upper lib
Upper lib
environments meta
meta and this is the config we
meta and this is the config we
used. Let's just open it.
Another good
Another good
question was when I did this
question was when I did this
experiment, which actually I linked this
experiment, which actually I linked this
to Aaron yesterday, so I can go find
to Aaron yesterday, so I can go find
that
that
link. I did go link this to Aaron.
[Music]
This was the heart
That met ID.
This was
21st 3
21st 3
E06. It was this commit here.
in which I added some
hypers. We can double check these real
hypers. We can double check these real
quick, but I'm pretty sure these are the
same. Yep. So,
same. Yep. So,
like these are all the same, right?
Okay. The other thing I wasn't sure
Okay. The other thing I wasn't sure
about with this that I wanted to go
about with this that I wanted to go
double check
on is did we have the end file committed
on is did we have the end file committed
at this point?
We did have the Nap file committed, but
We did have the Nap file committed, but
I can actually verify here
I can actually verify here
uh that this is exactly what we trained
on with all these cool downs just as
on with all these cool downs just as
they were
before. Okay.
I wonder if it's possible that something
I wonder if it's possible that something
changed in their config
format. You think something could have
format. You think something could have
changed in their config format such that
changed in their config format such that
like now uh this is like no longer valid
like now uh this is like no longer valid
or
something? This is a totally different
something? This is a totally different
curve,
curve,
right? I want to check
right? I want to check
that. That could be the case.
This is this like taking tons of
memory. Just loading the GPU quite a
memory. Just loading the GPU quite a
bit.
this
buffer cuz this gets passed. This gets
buffer cuz this gets passed. This gets
passed in.
But this will just give us the drive
around. 16 players
at the
at the
data. Nothing there.
objects. Yeah. So, this just tells you
objects. Yeah. So, this just tells you
everything that's in the end, which is
everything that's in the end, which is
going to be a ton of stuff,
going to be a ton of stuff,
right? Oh, yeah. This is a massive
right? Oh, yeah. This is a massive
amount of stuff.
wrapper
wrapper
attribute. Where's the config get uh
attribute. Where's the config get uh
applied in here? I think I got to just
applied in here? I think I got to just
start reading
start reading
their their end code, right?
underscorem
config. Shouldn't this have an
underscore? Does have an underscorem
underscore? Does have an underscorem
config and it is the one that I
passed correctly.
Wait.
Wait.
Self.config equals
Self.config equals
get new end
get new end
config.
config.
Wait, this gets
Wait, this gets
passed and then it makes a template of
passed and then it makes a template of
this.
this.
Okay. And then it resolves this
Okay. And then it resolves this
config. Now this is the config that we
pass. We get the renderer working.
Okay, so here's the
end. Agents like walk around and do
stuff kind
of. They don't really move very much.
All these are red
All these are red
ores. These ones
still
going.
Uh trying to think how we debug this.
It's like what could have possibly
changed. Like it would have to be the
changed. Like it would have to be the
end, right? Because
It's got to be the
It's got to be the
end. Let me see. So, I like I remember
end. Let me see. So, I like I remember
it wasn't working. We got curves that
it wasn't working. We got curves that
looked like
looked like
this and then I pasted
this and then I pasted
in where is
it? Okay. So, I pasted in these new
it? Okay. So, I pasted in these new
params.
Not
these. Okay. So I pasted in these new
these. Okay. So I pasted in these new
params which was the new learning rate,
params which was the new learning rate,
gamma, lambda, all that. And then we had
gamma, lambda, all that. And then we had
it working very
well. I just pasted these in from like a
well. I just pasted these in from like a
quick sweep. I remember
m* 16, right? That was the idea. 16
m* 16, right? That was the idea. 16
workers
batch size 64.
batch size 64.
Yeah, this is a uh double buffered
Yeah, this is a uh double buffered
setup with a bunch of
setup with a bunch of
workers. Same
params. Didn't mess with the end config
params. Didn't mess with the end config
in any weird way.
trying to think if there's like is it
trying to think if there's like is it
possible I did
something the meta code
Let me
see. Reset enth.
see. Reset enth.
So they have this reset
m.reset. I should be fine just calling
m.reset. I should be fine just calling
reset here then.
Is this thing
seated? No, they don't use
seed. We could double check. We should
seed. We could double check. We should
double check. We're getting real
data. Pretty darn sure we did this
data. Pretty darn sure we did this
right.
Always possible I messed up
Always possible I messed up
though. So we go
though. So we go
here and we do mode
train. They're all zeros.
Okay. I mean, like, we see that there's
Okay. I mean, like, we see that there's
data in here, right? Like not a ton of
data in here, right? Like not a ton of
stuff, but like there is we've seen a
stuff, but like there is we've seen a
couple channels already that had stuff
couple channels already that had stuff
in
in
them. Yeah. So, I mean, there's data
And then we have our
And then we have our
encoder network is a small
CNN. I'll be
fine. And this is what we used
fine. And this is what we used
importantly as well.
I wonder if I messed up the action
I wonder if I messed up the action
decoding for
multidiscreet. That could do
it. I tried on old puffer li though too,
it. I tried on old puffer li though too,
didn't
didn't
I? Pretty darn sure I tried on old
I? Pretty darn sure I tried on old
puffer
li. Worth
li. Worth
checking. Do I have any other like
checking. Do I have any other like
multi-discrete
M's? Hang on. Actually, I do. Let me
M's? Hang on. Actually, I do. Let me
just test if I can learn one of those
just test if I can learn one of those
real quick. We should have like the
sanity
sanity
make we had
multi-discrete. I know we have a
multi-discrete. I know we have a
multi-discreet in here.
Oh, it's just called spaces.
Uh, I'm trying to figure out how do I
Uh, I'm trying to figure out how do I
reconnect
reconnect
these real quick
M. Oh, let's just
M. Oh, let's just
make faces.
unexpected keyword arg.
seed.
seed.
Holy. Well, this was what we wanted.
Uh, it does not instantly solve this.
and just make sure they're not all
bugged. Okay, so there is something
bugged. Okay, so there is something
wrong I think with spaces. I don't know
wrong I think with spaces. I don't know
whether it's the same bug or
not, but uh it's worth us looking
not, but uh it's worth us looking
oops into this decoder.
So this is the
multi-discretet. You know, it looks like
multi-discretet. You know, it looks like
I could have messed this up at all. like
I could have messed this up at all. like
quite a bit
here. Let me try something.
and just check how I did this in like
and just check how I did this in like
earlier
earlier
versions. I think
versions. I think
um this could definitely be it. I could
um this could definitely be it. I could
have just messed up multi-discrete
have just messed up multi-discrete
sampling.
That's the only other thing I could
That's the only other thing I could
think of that I touched that would like
think of that I touched that would like
specifically mess up meta and not
specifically mess up meta and not
anything
anything
else. I thought I was being pretty
else. I thought I was being pretty
careful with it, but maybe not.
So,
So,
interestingly, yeah, but this is the dev
interestingly, yeah, but this is the dev
branch. We need to go back
branch. We need to go back
farther to like
farther to like
before I did
before I did
this, like to here
maybe. Right.
Can I just like copy this whole
Can I just like copy this whole
function?
function?
Actually, I should be able
to. I don't know if I messed with
to. I don't know if I messed with
anything else that would matter in
anything else that would matter in
here. Entropy.
gets called unnormalized
gets called unnormalized
budgets budgets.
budgets budgets.
Okay, I think I can actually
Okay, I think I can actually
not mess with this so much and just
not mess with this so much and just
do
this this one.
We'll see if this produces anything
We'll see if this produces anything
different.
26 to
26 to
262 97. Right.
Yeah, right
there. Yes. This was the original
there. Yes. This was the original
one. Now this is the new one.
So this
So this
was we can see the two different we can
was we can see the two different we can
see this one lines up with this one. So
see this one lines up with this one. So
even if we go back to the
earlier the earlier action sampling it
earlier the earlier action sampling it
does not seem to make a difference.
Did I mess with any of the other
Did I mess with any of the other
functions in
here?
here?
Nope, that is
correct. This is identical.
correct. This is identical.
And I do not
And I do not
believe I did anything
else. Evidently, I did not just break
else. Evidently, I did not just break
sampling.
What else could it be
then? I know I didn't just break
then? I know I didn't just break
sampling.
Leave it for now as well just to be
sure. Let's kill
this. Thank
this. Thank
I've already also to be clear I've
I've already also to be clear I've
tested this exact branch as well. I'm
tested this exact branch as well. I'm
not just like
guessing. Adding the resets here. Added
guessing. Adding the resets here. Added
max
max
steps. These are all the changes I
steps. These are all the changes I
remember and these are all up to date.
Um, hang on. We have somebody here with
Um, hang on. We have somebody here with
delivery that I don't know who this is.
Apparently, we have an entire semi worth
Apparently, we have an entire semi worth
of lights uh that our electric guys
of lights uh that our electric guys
ordered for a different job to our
ordered for a different job to our
address.
for I
know
weird. What are we going to do about
weird. What are we going to do about
this freaking this run?
This isn't a case where I just like did
This isn't a case where I just like did
something and I don't remember what I
something and I don't remember what I
did. Like I know exactly what I
did. Like I know exactly what I
did. I think I'm doing the same thing
did. I think I'm doing the same thing
and it's not
and it's not
replicating. In fact, it's not just I
replicating. In fact, it's not just I
think I know what I did, right? I have
think I know what I did, right? I have
the get
the get
commits. I have the diff to the commit.
Exactly. The heck could have possibly
Exactly. The heck could have possibly
changed? And all the other M's work
changed? And all the other M's work
great as
well. Jiggle the hyperparameters around
well. Jiggle the hyperparameters around
a little bit, but
a little bit, but
like,
like,
right, I could also rerun a hyperparam
right, I could also rerun a hyperparam
sweep on this. That's a thing I could
sweep on this. That's a thing I could
do.
I mean realistically right this is
I mean realistically right this is
supposed to
supposed to
fix this is supposed to do well
within okay 1 E8 so 100 million steps
within okay 1 E8 so 100 million steps
you should be able to see a very
you should be able to see a very
substantial
I can rerun the
sweep. I'm not confident that's going to
sweep. I'm not confident that's going to
get us
get us
anywhere, but I can at least try that.
It's weird because we got the we got
It's weird because we got the we got
this curve with these
hyperparams. Same
model. No other
model. No other
diffs unless Hang on. Wait a second.
diffs unless Hang on. Wait a second.
Does this record This does record the
Does this record This does record the
entire diff,
right? Not just the diff to the
transcript. Wait. Ah, hang
on. I think it is just a diff to the
on. I think it is just a diff to the
train
train
screenshot. It should just It is just a
screenshot. It should just It is just a
diff to this one
diff to this one
file. Okay. Wait. that that changes
things. Yeah. And you can see the diff
things. Yeah. And you can see the diff
here just it's on the config file
only. Okay.
Let's do some like 100 milish runs,
Let's do some like 100 milish runs,
right? Just let's play with some
things. 100 mil run.
No energy steps.
if this does anything.
if this does anything.
I'm just gonna I don't want to spend all
I'm just gonna I don't want to spend all
day doing this, but you know, it's worth
day doing this, but you know, it's worth
playing with this a little bit just to
playing with this a little bit just to
make sure I didn't screw something
make sure I didn't screw something
up because I just realized if it's not
up because I just realized if it's not
recording the full
diff and uh there could be different
diff and uh there could be different
there could be differences.
This
This
here to
there. In the
there. In the
meantime, double check on some runs.
meantime, double check on some runs.
up for grid is still going just
fine and this this
one. Okay. So, there's like some rare
one. Okay. So, there's like some rare
instability in pyro, but other than
instability in pyro, but other than
that, we've kind of gotten our sweep
that, we've kind of gotten our sweep
stable as well, but we are in a decent
stable as well, but we are in a decent
spot. I would say
spot. I would say
overall in a decent spot.
overall in a decent spot.
We can see we actually
We can see we actually
have quite comprehensive sweep on
have quite comprehensive sweep on
breakout
breakout
here. Uh not seeing a bunch of good runs
here. Uh not seeing a bunch of good runs
though. We probably are going to want to
though. We probably are going to want to
mess with our sweep setup if this is all
mess with our sweep setup if this is all
we're getting out of
we're getting out of
it. Open
it. Open
dashboard sweep
dashboard sweep
progress. Yeah, not great on the sweeps.
progress. Yeah, not great on the sweeps.
So, we definitely screwed something up
So, we definitely screwed something up
with our sweeps.
It is possible. It's just like the
It is possible. It's just like the
normalization change I
made. So, this is not doing great. But
made. So, this is not doing great. But
if it's not sweeping breakout well, then
if it's not sweeping breakout well, then
we don't expect it to do particularly
we don't expect it to do particularly
well.
Okay, this ain't
This one.
our breakout sweep right.
our breakout sweep right.
This is breakout.
changes it having the max score in place
changes it having the max score in place
and if so then we can work off of
that. Leave that over there.
build. Okay, so this just doesn't run.
Maybe we can track some other stats from
Maybe we can track some other stats from
this and we can get like a hint from
this and we can get like a hint from
um from some of these stats,
eh? Cuz like this should have logged a
eh? Cuz like this should have logged a
whole bunch of
stuff. The episode length is a thousand.
Yes. No, we didn't log SPS or
Yes. No, we didn't log SPS or
anything. How is there so many metrics
anything. How is there so many metrics
here?
Let's look at them side by side.
Maybe we can find like a telling
stat. Okay. So, they don't like this
stat. Okay. So, they don't like this
attack
attack
nearest. It doesn't learn this quickly
nearest. It doesn't learn this quickly
at all.
Get
Get
output. Just learn super
output. Just learn super
quickly. Get output.
Interestingly, we learn to move around a
Interestingly, we learn to move around a
whole bunch.
I mean this is like going up cleanly.
But we just have like this very
But we just have like this very
slow. I mean, even from
slow. I mean, even from
like you can tell these apart like 20
like you can tell these apart like 20
million steps
million steps
in right here. This
in right here. This
is battery
is battery
gained. This should be learnable
gained. This should be learnable
immediately as well.
immediately as well.
It gets rewarded for
it.
Okay. It's funny because this it's not
Okay. It's funny because this it's not
getting rewarded for
this. So these this agent just says
this. So these this agent just says
screw that and this agent's like you
screw that and this agent's like you
know doing its own
thing. Would it make
thing. Would it make
sense? Hang
sense? Hang
on
two. It's not at 0.2. It's at like 0.4.
two. It's not at 0.2. It's at like 0.4.
But like
But like
still these are probably rare. It's kind
still these are probably rare. It's kind
of treating these like any other
of treating these like any other
resource,
right? But
or and then this heart here. It's also
or and then this heart here. It's also
not again like 50 mil steps. You can
not again like 50 mil steps. You can
tell it
tell it
apart for less.
Okay. So, this
Okay. So, this
is it's
is it's
treating it seems like it's not getting
treating it seems like it's not getting
the rewards is what it really seems like
the rewards is what it really seems like
to me.
We get red
ore. Ah, okay. Hang
ore. Ah, okay. Hang
on. So,
here or
here or
red.get. This is like not terribly far
red.get. This is like not terribly far
off,
off,
right? It's getting the ore
right? It's getting the ore
here. It's not learning to do anything
here. It's not learning to do anything
with
with
them. Yeah. It hasn't learned to like
them. Yeah. It hasn't learned to like
put
put
them
them
anywhere. But I mean, this would imply
anywhere. But I mean, this would imply
that it is getting the reward,
right? You think I changed the
right? You think I changed the
conversion time to zero?
mine
produce. Let me run that real
quick. And we already have one
quick. And we already have one
conversion
conversion
tick on
tick on
everything. And that was like that's the
everything. And that was like that's the
way it just was.
You know, we do actually know one other
You know, we do actually know one other
thing which is that I did I committed
thing which is that I did I committed
this
file. I actually did commit this
file. I actually did commit this
file with uh that PR that I marked.
file with uh that PR that I marked.
like it was actually quite well
organized as you can see
here
file. Yeah. So you can actually see here
uh that this was this was the state this
uh that this was this was the state this
file was in.
file was in.
So actually I am quite confident then
So actually I am quite confident then
that I didn't just mess with the end
config. In which case I can't think of
config. In which case I can't think of
really anything better to do than just
really anything better to do than just
run a sweep,
right?
Of course, our current sweep stuff is
Of course, our current sweep stuff is
messed
up. Isn't it in
healing that guy? Hey,
healing that guy? Hey,
Tyler. Yeah, I know. It's all right. He
Tyler. Yeah, I know. It's all right. He
uh he's mostly just a poster. He's like
uh he's mostly just a poster. He's like
I don't know maybe half the engineer
I don't know maybe half the engineer
that he is a poster. And thanks for the
that he is a poster. And thanks for the
free exposure. I
guess he didn't do it again. All right.
I know. I thought that was pretty funny.
I know. I thought that was pretty funny.
It's
It's
like you can poke a little bit of fun at
like you can poke a little bit of fun at
Google, right?
I mean, they were like, "Yeah,
I mean, they were like, "Yeah,
artificial uh puffer intelligence and
artificial uh puffer intelligence and
stuff in the comments." All
stuff in the comments." All
right, grab some
second. It's also pretty funny that I've
second. It's also pretty funny that I've
been in RL longer than this.
been in RL longer than this.
So, nice try, buddy.
Nice
try. Yeah, Tyler. The thing I'm trying
try. Yeah, Tyler. The thing I'm trying
to figure out right at the moment, there
to figure out right at the moment, there
are two things. One is I'm just fixing
are two things. One is I'm just fixing
hyper pram sweeps and like fixing some
hyper pram sweeps and like fixing some
stability issues in the latest build
stability issues in the latest build
that I'm pretty confident we'll be able
that I'm pretty confident we'll be able
to get to work.
to get to work.
The thing that's really weird at the
The thing that's really weird at the
moment
though, I can't get We are setting soda
though, I can't get We are setting soda
on every single M pretty much out of the
on every single M pretty much out of the
box except this one M that we set soda
box except this one M that we set soda
on like three weeks ago. We can't
on like three weeks ago. We can't
reproduce at
reproduce at
all. And it's a pretty important
all. And it's a pretty important
one. I have no idea why this one end is
one. I have no idea why this one end is
just not working the way it was expected
just not working the way it was expected
to.
It's meta. It's a third party M that's
It's meta. It's a third party M that's
built with the Puffer APIs.
Um, do I really trust this
Um, do I really trust this
gamma? I'm going to just do something
gamma? I'm going to just do something
dumb for the hell of
dumb for the hell of
it. One random thing just to check.
And then after that, I'll just ignore
And then after that, I'll just ignore
this. I'll go back
this. I'll go back
to the hyperparam sweep stuff or general
to the hyperparam sweep stuff or general
cleanup. Then when the hyperp stuff
cleanup. Then when the hyperp stuff
works correctly,
works correctly,
uh then we will just rerun on this and
uh then we will just rerun on this and
see. And if that doesn't work, it must
see. And if that doesn't work, it must
have been an M change because
have been an M change because
like it's just not a thing that happens
like it's just not a thing that happens
in Puffer, right? We don't lose
in Puffer, right? We don't lose
experiments.
I mean, it's like pretty
I mean, it's like pretty
instant that this thing learns. And it
instant that this thing learns. And it
should be
What order did I merge these
commits? Meta
working. Yeah. And then none of these
working. Yeah. And then none of these
are applicable here.
are applicable here.
Oh, I guess there is the April. If we go
here, there are a bunch of
here, there are a bunch of
changes. This one
especially, we might just have to retune
So, this actually is like pretty close
So, this actually is like pretty close
to this one as well. It's suspicious
to this one as well. It's suspicious
that I can't find anything that's
that I can't find anything that's
like everything kind of matches this.
like everything kind of matches this.
Nothing like gets even 6 or
Nothing like gets even 6 or
anything. It's kind of weird. It's like
anything. It's kind of weird. It's like
it everything is screaming that this is
it everything is screaming that this is
an Mside change.
Is this trajectory
Is this trajectory
related? What is
related? What is
um 26
um 26
[Music]
[Music]
over
128 128 horizon
128 128 horizon
length be
length be
fine.
Wait, that's not that many.
Wait, that's not that many.
That's not that many
M's. Honestly, don't know what I'm
M's. Honestly, don't know what I'm
looking at, but keep it
looking at, but keep it
up. Thanks. I This is currently
up. Thanks. I This is currently
debugging like a fiddly some fiddly RL
debugging like a fiddly some fiddly RL
experiments. Um, pretty much like we set
experiments. Um, pretty much like we set
a whole bunch of really good results a
a whole bunch of really good results a
couple of weeks ago and then I left for
couple of weeks ago and then I left for
a week and I came back and we reproduced
a week and I came back and we reproduced
all the results perfectly except for
all the results perfectly except for
one. I'm trying to figure out what
one. I'm trying to figure out what
happened to this like one experiment.
happened to this like one experiment.
Um, and usually I'm pretty good at like
Um, and usually I'm pretty good at like
tracking or tracking our changes, making
tracking or tracking our changes, making
sure we don't lose stuff. So, it's a
sure we don't lose stuff. So, it's a
really weird a really weird case.
I don't even know why I'm spending so
I don't even know why I'm spending so
much time thinking about this when it's
much time thinking about this when it's
like I know I didn't modify the
like I know I didn't modify the
environment file,
right? I know I ran
right? I know I ran
experiments on the same thing.
experiments on the same thing.
with the exact same
commit of puffer
lib. Those two things don't make sense
lib. Those two things don't make sense
together, right?
Maybe I shouldn't be
Maybe I shouldn't be
too suspicious of this flat curve
too suspicious of this flat curve
either. I do seem to remember it being
either. I do seem to remember it being
very difficult to get it to go above 0.5
very difficult to get it to go above 0.5
until I set the new hyperparams.
Would totally make sense though if I
Would totally make sense though if I
change something
change something
else at the same
time. Pretty well remember what I did
time. Pretty well remember what I did
though that day and I didn't do anything
though that day and I didn't do anything
else.
At least I didn't do anything else in
At least I didn't do anything else in
the end
configuration. Possible I had like some
configuration. Possible I had like some
local changes to
local changes to
Metagrid. Had some like local changes to
Metagrid. Had some like local changes to
the environment
the environment
file. The only thing I remember doing
file. The only thing I remember doing
there though was
there though was
um resetting the ends. Making sure I
um resetting the ends. Making sure I
reset the ends. Doing that correctly now
reset the ends. Doing that correctly now
as well.
like truly
bizarre. I also don't know how it is
bizarre. I also don't know how it is
that my
that my
uh breakout sweep suddenly doesn't work.
Oh, that's definitely a bug,
right? That's definitely got to be a
right? That's definitely got to be a
bug. Okay, I'm going to let this do the
bug. Okay, I'm going to let this do the
do its thing. I'm going to grab a drink
do its thing. I'm going to grab a drink
and then we'll just we'll ignore this
and then we'll just we'll ignore this
for now and we'll just fix sweeps
for now and we'll just fix sweeps
because maybe in fixing sweeps we just
because maybe in fixing sweeps we just
rerun the sweep and we get RAMs that
work. You see it literally starts off
work. You see it literally starts off
wrong. You see
wrong. You see
that? Literally the first point starts
that? Literally the first point starts
off
off
wrong. Doesn't that imply it has to be
wrong. Doesn't that imply it has to be
end
config? It almost has to be, right?
Unless it's just like it learned so much
Unless it's just like it learned so much
in the first
update, but no, right? Because you
update, but no, right? Because you
collect all the
data. No, this is literally has to be
data. No, this is literally has to be
end config.
end config.
Unless it could just take a few updates,
Unless it could just take a few updates,
I guess. You
I guess. You
know, I already reran the I already
know, I already reran the I already
reran the commit is the thing. Hey,
reran the commit is the thing. Hey,
Plasma. I'm doing okay. I'm still just
Plasma. I'm doing okay. I'm still just
like trying to reproduce this
like trying to reproduce this
experiment, which is weird.
I was so careful to not change the
I was so careful to not change the
environment, but
environment, but
like this gap here, it like it almost
like this gap here, it like it almost
has to
has to
be environment changed if it's like
be environment changed if it's like
literally the first point recorded. I
literally the first point recorded. I
mean, technically this is already 14
mean, technically this is already 14
million steps
in. Like that's a few batches, but
still. H. Okay, here's what we're going
still. H. Okay, here's what we're going
to do. This is going to drive me crazy
to do. This is going to drive me crazy
if I just spend all day doing this. And
if I just spend all day doing this. And
uh unlikely we're going to get anywhere
uh unlikely we're going to get anywhere
with just me staring at it.
with just me staring at it.
Um and grab a drink, do a set or two
Um and grab a drink, do a set or two
real
real
quick, clear my head,
quick, clear my head,
and then we will see if I can fix the
and then we will see if I can fix the
hyper pram sweep stuff that I actually
hyper pram sweep stuff that I actually
have some idea of what I might have
have some idea of what I might have
broken that I know should work very
broken that I know should work very
well. And I know like I have a better
well. And I know like I have a better
idea of what can be uh of what stuff I
idea of what can be uh of what stuff I
changed there and what like we can fix.
changed there and what like we can fix.
We fix hyperparam sweeps. Um we can at
We fix hyperparam sweeps. Um we can at
least rerun all the other experiments
least rerun all the other experiments
except this end. Come back to this and
except this end. Come back to this and
we'll go from there. Be right back.
pink and green as a result. Yeah, the
pink and green as a result. Yeah, the
green is the uh the pink is the original
green is the uh the pink is the original
one and then we can't get anywhere close
one and then we can't get anywhere close
to it. It's very
to it. It's very
weird. It's very very weird.
Okay, let's go do stuff on sweeps.
All right
here and not in
report.
report.
Interesting. Oh, cuz it's
Interesting. Oh, cuz it's
311 there.
So, we should be
So, we should be
getting 10 observations back here.
There's nothing in total time steps.
These
These
hypers look totally wrong.
Okay. So, these are the
Okay. So, these are the
correct these are the correct ones.
So we have here is the observe.
Right? It shouldn't it just be
Okay, we do have total time steps here.
Okay, we do have total time steps here.
So this is 1.5 million steps. So this is
So this is 1.5 million steps. So this is
like a very
like a very
early first point it looks
like. Score is zero.
like. Score is zero.
cost is like nothing, right? So, we just
cost is like nothing, right? So, we just
do or cost. We'll do like this.
do or cost. We'll do like this.
Continue. Now, the next
Continue. Now, the next
one is at 11
million, which is 17 score and 7 seconds
million, which is 17 score and 7 seconds
into
into
training. 20 mil
Okay. So, we can see that we're actually
Okay. So, we can see that we're actually
observing
observing
correctly the various different
correctly the various different
um
points. Now, this should be the last
points. Now, this should be the last
point here. And this is on
point here. And this is on
eval. This total time step should be
wrong. Yeah, because this is only for
wrong. Yeah, because this is only for
eval. So, we'll fix this real
quick. Some improvement
Let's
Let's
see. So,
um,
timesteps.append global step
We should just put this up top,
right? That will get us to 80 mil or
right? That will get us to 80 mil or
whatever. That's not the bug, though.
whatever. That's not the bug, though.
That's not the thing that's breaking
That's not the thing that's breaking
everything. Tell you that for sure.
We go
again. So this will run.
again. So this will run.
And uh we will see whether we observe
And uh we will see whether we observe
the correct step.
suggestion index.
50 random
samples. We have 10 success
observations. So this is going to give
observations. So this is going to give
us a random suggestion.
Random. Choice.
The goal is just going to be to see how
The goal is just going to be to see how
all the data is getting
all the data is getting
normalized and uh why the predictions
normalized and uh why the predictions
don't make any sense cuz like looking at
don't make any sense cuz like looking at
this graph right from over where is
this graph right from over where is
it? But like you get a couple of
it? But like you get a couple of
reasonable random suggestions and then
reasonable random suggestions and then
it just doesn't do
it just doesn't do
anything. Like for some reason it's
anything. Like for some reason it's
pushing cost all the way to the bottom
pushing cost all the way to the bottom
or whatever.
So here are our
parameters. Expect these to be
parameters. Expect these to be
reasonable.
Here's our
Here's our
Y. Does it look good? Right.
Min score is
Min score is
zero. That's
fine. Max score.
fine. Max score.
Whoa.
What? Well, this is completely
What? Well, this is completely
wrong right here. This is
wrong. I don't know why I would do this
wrong. I don't know why I would do this
abs thing like
abs thing like
this. It should
be
be
this. Okay.
Take abs of max score minus min
score. That could totally be it right
score. That could totally be it right
there if I'm not setting max scores.
there if I'm not setting max scores.
Right.
I want to keep going a little bit here
though. Okay. So, like this is half
though. Okay. So, like this is half
offish, right? But it's bad. It's like
offish, right? But it's bad. It's like
not
awful. And then the cost I
guess. Okay. So, let's get the
costs. Apparently, that didn't work, but
costs. Apparently, that didn't work, but
whatever.
We will try again with the our new found
We will try again with the our new found
fixes. This
Okay. So now we have reasonable mins and
maxes. Nicely normed 0 to one, right?
We've got reasonable cost
observations. Now we have reasonable log
observations. Now we have reasonable log
cost observations, right?
cost goes into log
cost goes into log
space. I actually don't know why we put
space. I actually don't know why we put
cost in log space to be fair,
cost in log space to be fair,
right? We've played with it a few
right? We've played with it a few
different
ways. Well, we'll leave this as is for
ways. Well, we'll leave this as is for
now.
These are both
reasonable. Okay, here's your norm. 0 to
reasonable. Okay, here's your norm. 0 to
one. Quite clean.
You train your
GPC. Okay, so now we get our PTO points.
There quite a few of
them. Pretty much all of them, right?
them. Pretty much all of them, right?
Yeah, literally all of them. It should
Yeah, literally all of them. It should
be if we have a good initial
be if we have a good initial
curve. Then we sample some
suggestions. suggestions, shape, whole
suggestions. suggestions, shape, whole
bunch of suggestions,
bunch of suggestions,
right?
right?
We we score
them in this latent space, right?
Then we have GPY
Then we have GPY
norm log C
norm
norm
GPY. What do we do? It's times max score
GPY. What do we do? It's times max score
minus min
score. You actually don't need this uh
score. You actually don't need this uh
this abs at
all. The worst case is zero
all. The worst case is zero
here.
here.
Right. I don't think you need this abs.
The worst case should be
zero. So now they're getting multiplied
zero. So now they're getting multiplied
by max minus
by max minus
min and then add to min.
Yeah. Then we have log
Yeah. Then we have log
c it's x.
c it's x.
You have to see get a min and a
You have to see get a min and a
max.
See?
See?
Okay. And you have your parto
Okay. And you have your parto
y parto indices.
Okay, got your
Okay, got your
PTO. Was it log C
norm? Uh, I don't think this
norm? Uh, I don't think this
C. Wait, do we still use this like C
C. Wait, do we still use this like C
right thing?
This doesn't get
used. Yeah. So, let's not confuse
used. Yeah. So, let's not confuse
ourselves
here because none of these get used
here because none of these get used
anymore, right?
anymore, right?
Now, this doesn't get
Now, this doesn't get
used. This does get used.
Hang on. What are we doing
here? This is not what I
here? This is not what I
remember, but maybe I'm reading my own
remember, but maybe I'm reading my own
stuff wrong. Hang on.
So,
So,
target equals
target equals
GPC
norm. Oh, look. This this just gets
norm. Oh, look. This this just gets
deleted here. You see
deleted here. You see
this? Yeah. This all just goes away.
this? Yeah. This all just goes away.
It's right here. Yeah. This is what I
remember. So, it's just
remember. So, it's just
1.25 times a
1.25 times a
random. It's multiplied by a
random. It's multiplied by a
weight. This GPY
weight. This GPY
norm, you got to make sure GPY norm is
norm, you got to make sure GPY norm is
right. Is right here.
right. Is right here.
times the
weight. Then it's an
argmax. Let's commit this and then see
argmax. Let's commit this and then see
if this does anything different.
of
This All
right. See,
uh, let's see how this changes
uh, let's see how this changes
it. So, we had
Okay, this actually this breakout sweep
Okay, this actually this breakout sweep
was starting to do kind of
was starting to do kind of
something. Let's see now with the fixes
something. Let's see now with the fixes
if we actually get something reasonable
if we actually get something reasonable
out of
out of
it. Let me read that in a second.
Tyler, let me at least get this run
Tyler, let me at least get this run
started so we can have this
started so we can have this
going. Check your thing.
Romy. Okay. So, yeah, let me let me help
Romy. Okay. So, yeah, let me let me help
you with
you with
that. The Romy show drone
that. The Romy show drone
ideas for our natural
gas survey.
I'm trying to think if you actually
I'm trying to think if you actually
really need a
coordinated much of anything for
it. And the no military is always a fun
it. And the no military is always a fun
thing.
Um, surveying.
What kind of pro? Well, all of them
What kind of pro? Well, all of them
honestly in like drones like the whole
honestly in like drones like the whole
RL is super human at drone piloting for
RL is super human at drone piloting for
the first part. Uh if you get it right,
the first part. Uh if you get it right,
it's also super human at
it's also super human at
coordination. the
coordination. the
like so like some communication stuff
like so like some communication stuff
would
would
be useful in like a variety of
be useful in like a variety of
applications. The really like heavily
applications. The really like heavily
like swarm-based stuff is probably
like swarm-based stuff is probably
military stuff. Um but I mean the tech
military stuff. Um but I mean the tech
goes way farther than that. Like if you
goes way farther than that. Like if you
want to get into something that is like
want to get into something that is like
defense but not military for instance,
defense but not military for instance,
right? Um, you can purely have these
right? Um, you can purely have these
things for like surveying an existing
things for like surveying an existing
premise and like covering an
premise and like covering an
area. That's like security, even private
area. That's like security, even private
security
security
there. That's like a pretty reasonable
thing. I think generally you want to
thing. I think generally you want to
have these things be able to
have these things be able to
like you want to have these things be
like you want to have these things be
able to make reasonable decisions based
able to make reasonable decisions based
off of either shared information or like
off of either shared information or like
local or responsive to one another
local or responsive to one another
depending
depending
um I guess like the spread out and do X
um I guess like the spread out and do X
is a good application. So
like there is probably stuff in
like there is probably stuff in
agriculture with that to be fair.
agriculture with that to be fair.
Although I don't know if it's effective
Although I don't know if it's effective
like powering them and having like all
like powering them and having like all
that stuff versus just like having
that stuff versus just like having
something on the
ground. Let me think of like what would
ground. Let me think of like what would
get somebody excited that's not military
get somebody excited that's not military
drone stuff.
We'll think
quick. Well, I mean, is she interested
quick. Well, I mean, is she interested
in science generally because it's like
in science generally because it's like
an excellent
an excellent
uh it's an excellent problem for
uh it's an excellent problem for
studying like
studying like
decentralized uh like decentralized
decentralized uh like decentralized
aggregate behavior and the like,
aggregate behavior and the like,
right? I mean, it's like the problem
right? I mean, it's like the problem
that you would go to in the real world
that you would go to in the real world
for like relatively efficient,
for like relatively efficient,
relatively doable coordinated behavior.
relatively doable coordinated behavior.
I mean that's like fundamental to our
I mean that's like fundamental to our
understanding
understanding
of everything from ants to how companies
of everything from ants to how companies
are run,
right? So in a sense it's just like it's
right? So in a sense it's just like it's
a very good science problem in some
a very good science problem in some
sense, right? That also will get enough
sense, right? That also will get enough
people in industry interested that it's
people in industry interested that it's
like actually viable to scale research
like actually viable to scale research
on it. And yeah, obviously there's like
on it. And yeah, obviously there's like
some stuff that's military there.
some stuff that's military there.
There's stuff that's like security
There's stuff that's like security
adjacent, but I mean broader than that,
adjacent, but I mean broader than that,
like the same tech goes on everything,
like the same tech goes on everything,
right? So like the things that you came
right? So like the things that you came
up with are possibly reasonable. Um even
up with are possibly reasonable. Um even
if you don't apply the exact same stuff
if you don't apply the exact same stuff
to a drone form factor, you can apply
to a drone form factor, you can apply
the same algorithm to like a ground unit
the same algorithm to like a ground unit
for removing weeds if you wanted to do
for removing weeds if you wanted to do
that. Maybe that's more reasonable. Like
that. Maybe that's more reasonable. Like
the algorithm side is going to be very
the algorithm side is going to be very
very similar. It's just that if you're
very similar. It's just that if you're
trying to pick a problem to get a large
trying to pick a problem to get a large
number of people interested, um, drones
number of people interested, um, drones
are just a very flashy one that's very
are just a very flashy one that's very
good at that. And technically, it's very
good at that. And technically, it's very
similar to many other things that you
similar to many other things that you
could look
could look
at. That's kind of the way I would look
at. That's kind of the way I would look
at it, right? Because I do a lot of
at it, right? Because I do a lot of
general RL tech and then every so often
general RL tech and then every so often
I look for problems where it's like,
I look for problems where it's like,
okay, this is an area where a lot of
okay, this is an area where a lot of
people will get excited if we kind of
people will get excited if we kind of
demonstrated our tech on this. There
demonstrated our tech on this. There
probably a lot of downstream
probably a lot of downstream
applications. There always going to be
applications. There always going to be
some that are military and some that
some that are military and some that
aren't, right?
aren't, right?
But I think that this is just generally
But I think that this is just generally
an area where uh if you can get RL
an area where uh if you can get RL
working on it very well, you will get a
working on it very well, you will get a
lot of people excited. You'll power a
lot of people excited. You'll power a
lot of like fundamental advancements in
lot of like fundamental advancements in
RL and in our understanding of aggregate
RL and in our understanding of aggregate
intelligence in general or collective
intelligence in general or collective
intelligence in general. And you'll push
intelligence in general. And you'll push
a lot of things quite far
a lot of things quite far
forward. And it's actually a problem
forward. And it's actually a problem
where I think it's like relatively
where I think it's like relatively
reasonable to do that because like it's
reasonable to do that because like it's
the air. They have to not collide with
the air. They have to not collide with
each other and that's about it.
So you'll probably just even if you
So you'll probably just even if you
don't like you will probably get some
don't like you will probably get some
really fascinating aerial displays out
really fascinating aerial displays out
of it, right? You'll probably get some
of it, right? You'll probably get some
really fascinating aerial
displays. Like if you can just control a
displays. Like if you can just control a
whole bunch of them and say, "Hey, all
whole bunch of them and say, "Hey, all
of you go do this. All of you go do
of you go do this. All of you go do
that." And do it like in a way that
that." And do it like in a way that
makes sense without crashing into each
makes sense without crashing into each
other and stuff like that will already
other and stuff like that will already
be and there's really not much like
be and there's really not much like
that. They show her where like M agent
that. They show her where like M agent
for instance like it's on David Ha's
for instance like it's on David Ha's
website. So like M agent or
Boyds, where's
this? If you look at even just like
this? If you look at even just like
basic stuff like
basic stuff like
this, right? Imagine doing this in like
this, right? Imagine doing this in like
actual 3D with drones or like even like
actual 3D with drones or like even like
voids.
right there. Like all these flocking
right there. Like all these flocking
type sims and
things. This is all these are all like
things. This is all these are all like
models of coordinated
behavior. There you go.
All
right. Have we run any
right. Have we run any
experiments in the
experiments in the
meantime or did they
fail? They failed. Yay.
or cost rating.
Welcome YouTube folks.
Welcome YouTube folks.
We're currently working on getting our
We're currently working on getting our
hyperprem stuff uh sweeps back working
hyperprem stuff uh sweeps back working
so we can run some large scale
so we can run some large scale
uh like few hundred order few hundred
uh like few hundred order few hundred
run hyperp sweeps over all our new
run hyperp sweeps over all our new
environments and see how well our our
environments and see how well our our
new algorithm can
new algorithm can
do on all of the environments because
do on all of the environments because
like right now we're pretty much solving
like right now we're pretty much solving
everything out of the box uh without
everything out of the box uh without
even having retune stuff. So, I imagine
even having retune stuff. So, I imagine
that we can do quite a bit better even
that we can do quite a bit better even
than we're doing
than we're doing
now, which should set us up
now, which should set us up
for a a very solid
for a a very solid
release. I'm particularly interested to
release. I'm particularly interested to
see like neural MMO is kind of an
see like neural MMO is kind of an
expensive M, so we don't retune hyper
expensive M, so we don't retune hyper
prams all that often. And like this is
prams all that often. And like this is
kind of just what we've gotten out
kind of just what we've gotten out
of mostly scaling up the network a
of mostly scaling up the network a
little bit, but also just little tweaks
little bit, but also just little tweaks
I've made here and there to it. Um, so
I've made here and there to it. Um, so
I'm interested to see with a really
I'm interested to see with a really
optimized hypers how well we can do this
optimized hypers how well we can do this
thing. This is an old
thing. This is an old
website. Yeah, I mean there are a bunch
website. Yeah, I mean there are a bunch
of implementations of it. Um, uh, Plasma
of implementations of it. Um, uh, Plasma
in the Discord is actually doing a voids
in the Discord is actually doing a voids
environment for Puffer right now.
So actually, do we even have Hang on.
Uh we don't have voids on this one, but
Uh we don't have voids on this one, but
yeah, he showed us uh he we've got like
yeah, he showed us uh he we've got like
a little interesting voids type sim that
a little interesting voids type sim that
he's been working on for Popper. Have
he's been working on for Popper. Have
that merged in soon
that merged in soon
hopefully. And Spencer is also
hopefully. And Spencer is also
interested in drones. Well, there are a
interested in drones. Well, there are a
lot of people interested in the
space. Oops.
Oh, one of the uh pieces of gym
Oh, one of the uh pieces of gym
equipment I'm waiting for shipped. The
equipment I'm waiting for shipped. The
one I'm really looking forward
to. Going to be fun.
It's got my quote for some dumbbells as
well. Very fun.
But probably uh sometime in the next few
But probably uh sometime in the next few
days I will have to get up and go take
days I will have to get up and go take
freight
delivery. All right, this is now
delivery. All right, this is now
running. We will see whether this is
running. We will see whether this is
stable or not.
Um, so the first five
Um, so the first five
runs
runs
are well the first run is like going to
are well the first run is like going to
always be good and then the next few are
always be good and then the next few are
randomly sampled and then after that the
randomly sampled and then after that the
algorithm takes
over. So now the algorithm is suggesting
over. So now the algorithm is suggesting
stuff that's like 20 mil. I don't know
stuff that's like 20 mil. I don't know
why it's suggesting such short runs.
why it's suggesting such short runs.
That will be the next thing uh for us to
That will be the next thing uh for us to
look at.
Nice shipping.
Okay. Yeah. So, it's doing something. It
Okay. Yeah. So, it's doing something. It
should not be doing this where it's like
should not be doing this where it's like
pushing
pushing
uh the cost all the way to the bottom.
I'm going to give it a few more runs to
I'm going to give it a few more runs to
see if it keeps doing this. And then I'm
see if it keeps doing this. And then I'm
going to what we'll do is we'll like
going to what we'll do is we'll like
we'll boot up an individual run and
we'll boot up an individual run and
we'll see if we can figure out why. In
we'll see if we can figure out why. In
fact, why don't we just do that on our
fact, why don't we just do that on our
local while it's doing
that. I like this is something that I
that. I like this is something that I
actually I worked very hard to make sure
actually I worked very hard to make sure
that this algorithm doesn't do. So, this
that this algorithm doesn't do. So, this
must just be like some weird bug in
must just be like some weird bug in
something I did
something I did
recently. A lot of these algorithms,
recently. A lot of these algorithms,
they'll kind of just give up and they'll
they'll kind of just give up and they'll
be like, I can't figure out how to make
be like, I can't figure out how to make
the long experiments work anymore, so
the long experiments work anymore, so
I'll just run cheap
experiments. That's quite silly,
experiments. That's quite silly,
actually. I know that this divide
actually. I know that this divide
parameter is not used. We don't have to
parameter is not used. We don't have to
worry about
that. Oh, and here actually this LF
that. Oh, and here actually this LF
false. Oh, I committed this. So,
false. Oh, I committed this. So,
actually then the first few runs were
actually then the first few runs were
fine,
fine,
right? The first few runs were fine and
right? The first few runs were fine and
then it started doing this.
H, we'll start uh we'll start from here
H, we'll start uh we'll start from here
and we'll see what this uh what this
does. Yeah. You see all these runs being
does. Yeah. You see all these runs being
here? Yeah, it's because they're all
here? Yeah, it's because they're all
down here in total time steps except
down here in total time steps except
this
one. I wonder if this is like something
one. I wonder if this is like something
to do with log
to do with log
cost. This could just be something weird
cost. This could just be something weird
with the way I've defined log cost,
with the way I've defined log cost,
right?
You know, cuz cost starts starts at
zero. Oh, you know, that's totally what
zero. Oh, you know, that's totally what
it is,
it is,
right? I see. So, I think it's
because this is a little silly. So
because this is a little silly. So
because cost starts like very close to
because cost starts like very close to
zero
zero
um and it's going on a log scale, it's
um and it's going on a log scale, it's
actually going to put a decent chunk of
actually going to put a decent chunk of
our runs
our runs
uh very low
cost and we literally like it can it
cost and we literally like it can it
can't set fewer than 20 million time
can't set fewer than 20 million time
steps. That's the minimum we allow.
How do we fix
that? Totally what it is.
Yeah. So like generally if you think
Yeah. So like generally if you think
about that then if I did if I try to do
about that then if I did if I try to do
a run that was like between a billion
a run that was like between a billion
and 1.5 billion steps it's always going
and 1.5 billion steps it's always going
to do a billion because on a log scale
to do a billion because on a log scale
it's going to get some early
checkpoints and then it's going to try
checkpoints and then it's going to try
to sample in the space of cost 0 to 1.5
to sample in the space of cost 0 to 1.5
billion in a log
billion in a log
scale. Most of the time you're going to
scale. Most of the time you're going to
be uh below a billion. So it rounds up
be uh below a billion. So it rounds up
to a
to a
billion. This is why when I like I look
billion. This is why when I like I look
at this
here, get
stuck. Well, I know what now I know what
stuck. Well, I know what now I know what
the problem is. I don't even need to
the problem is. I don't even need to
look at this. I just need to think of
look at this. I just need to think of
how I want to solve it.
And this specifically comes from the
And this specifically comes from the
fact that I'm adding traces like full uh
fact that I'm adding traces like full uh
full
full
traces of the
traces of the
curves. I guess one thing we could do
curves. I guess one thing we could do
is
is
we we only
need. We can just change the way our
need. We can just change the way our
sampling works, right?
But let's say we don't log any partial
But let's say we don't log any partial
points. We don't log any points that
points. We don't log any points that
are below the minimum number of time
are below the minimum number of time
steps that we could run a full
steps that we could run a full
experiment
experiment
for. That would be a start.
would be a
start, I think. Let's just do that for
start, I think. Let's just do that for
now and then let's see what happens,
now and then let's see what happens,
right?
We can just do it as like a quick hack
We can just do it as like a quick hack
for now as well. Make sure it works and
for now as well. Make sure it works and
then we can like figure out how we want
then we can like figure out how we want
to really do it.
to really do it.
Like here this this down sample
linear. So actually we just feed in
here
here
for you. You help with one topic. I'm
for you. You help with one topic. I'm
stuck. Depends what it
stuck. Depends what it
is. Is anything adjacent to any of this
is. Is anything adjacent to any of this
stuff? Then
sure. Um, global
sure. Um, global
step greater than
equal. Let me figure out what the
equal. Let me figure out what the
parameter is called.
There's a
There's a
config ars.
distic
regression. I can point you to better
regression. I can point you to better
resources depending on what you're where
resources depending on what you're where
you're trying to learn stuff from.
I imagine you're like studying stuff
I imagine you're like studying stuff
like where are you currently studying
like where are you currently studying
that from?
Okay, that'll run. We'll see if that
Okay, that'll run. We'll see if that
does anything.
for reference. By the way, like
um
That's literally logistic regression
That's literally logistic regression
right
right
there. Like that's
there. Like that's
it. Now obviously you got to write your
it. Now obviously you got to write your
own backwards and stuff, but
own backwards and stuff, but
like it's just a linear layer in a
like it's just a linear layer in a
sigmoid.
between linear and logistic regression.
between linear and logistic regression.
It's the sigmoid.
Well, I guess it depends on regression
Well, I guess it depends on regression
and
and
classification. If you're regressing one
classification. If you're regressing one
variable as a as a sample, it's
variable as a as a sample, it's
literally all right. And then you do
literally all right. And then you do
like the
loss. It's like
loss. It's like
forward
rag like
rag like
boss something like this. Y is your like
boss something like this. Y is your like
your output
your output
variable and then it's for logistic
variable and then it's for logistic
regression you literally just add in the
sigmoid. So you can only learn linear
sigmoid. So you can only learn linear
decision boundaries. Your data has to be
decision boundaries. Your data has to be
linearly separable for linear regression
linearly separable for linear regression
to work. Logistic regression gives you
to work. Logistic regression gives you
one nonlinear activation to play with.
one nonlinear activation to play with.
can learn nonlinear
bounds. That's
all. Now, look, I mean, I'm I'm
all. Now, look, I mean, I'm I'm
minimizing a little bit here cuz like I
minimizing a little bit here cuz like I
remember spending several hundred hours
remember spending several hundred hours
when I was 16 being very very confused
when I was 16 being very very confused
by like fundamental ML stuff as well.
by like fundamental ML stuff as well.
And I still would be confused if I went
And I still would be confused if I went
and go look at like pure math after not
and go look at like pure math after not
having looked at it for like the last
having looked at it for like the last
couple years or whatever. But
couple years or whatever. But
conceptually these things are quite
conceptually these things are quite
simple. And then
simple. And then
um I mean when you go implement your own
um I mean when you go implement your own
autograd and stuff things are like
autograd and stuff things are like
annoying because you have to make sure
annoying because you have to make sure
you get everything right and like there
you get everything right and like there
are million tricks in modern uh ML that
are million tricks in modern uh ML that
make things just work the way that you
make things just work the way that you
would expect them to. If you don't if
would expect them to. If you don't if
you implement stuff yourself without
you implement stuff yourself without
those tricks, it just won't work
those tricks, it just won't work
anywhere near as well and you'll be
anywhere near as well and you'll be
confused as to why. But conceptually
confused as to why. But conceptually
these things are quite simple.
gotten any experiments working in the
meanwhile. It is still pushing this all
meanwhile. It is still pushing this all
the way down to the
the way down to the
bottom. Still
bottom. Still
doing ridiculously short runs.
That seems weird to
me. That seems very
weird. Make sure I just
like scores
lost. Oh, you know what it is. I'm dumb.
lost. Oh, you know what it is. I'm dumb.
Okay, I'm dumb. I know what I did wrong.
Okay, I'm dumb. I know what I did wrong.
And I know why this did like
And I know why this did like
um Yeah, I know exactly what I
did. Surprised I didn't hit this
before. Target
before. Target
minus. Oh, no. Wait. Isn't this fine?
This is fine, right? Because it's
This is fine, right? Because it's
point minus GP log C
point minus GP log C
norm. Wait, this should be in log space
norm. Wait, this should be in log space
then,
then,
right? And this is running a longer
right? And this is running a longer
experiment right
here. Maybe it is fine.
So, um, to give you a bit of an idea of
So, um, to give you a bit of an idea of
what we're looking at here,
what we're looking at here,
um, this is our new hyperpar tuning
um, this is our new hyperpar tuning
algorithm. I've been sitting on this
algorithm. I've been sitting on this
result for several months. It's a very,
result for several months. It's a very,
very good hyperparam tuning algorithm,
very good hyperparam tuning algorithm,
but we made a few changes recently and
but we made a few changes recently and
we kind of broke a few things. Um, so
we kind of broke a few things. Um, so
I'm trying to get it back to its old
I'm trying to get it back to its old
level of PF for the upcoming release. uh
level of PF for the upcoming release. uh
and currently what's happening is that
and currently what's happening is that
uh the way the algorithm works is it
uh the way the algorithm works is it
picks a length of experiment
picks a length of experiment
uh and then it tries to select and it
uh and then it tries to select and it
tries to guess an experiment that it
tries to guess an experiment that it
thinks it'll do well that'll take about
thinks it'll do well that'll take about
that long. What it does is it runs a
that long. What it does is it runs a
whole bunch of experiments of different
whole bunch of experiments of different
lengths. It builds up predictive models
lengths. It builds up predictive models
of how long an experiment is going to
of how long an experiment is going to
take and how well it thinks it's going
take and how well it thinks it's going
to do and then tries to pick the best
to do and then tries to pick the best
experiments of all different lengths.
experiments of all different lengths.
The idea here is that you know you run
The idea here is that you know you run
short experiments, you run long
short experiments, you run long
experiments, you actually start off
experiments, you actually start off
running shorter experiments and then
running shorter experiments and then
gradually start running longer ones as
gradually start running longer ones as
you be get more confident. Uh it's a
you be get more confident. Uh it's a
very simple algorithm. It's very robust.
very simple algorithm. It's very robust.
It doesn't have a lot of the problems
It doesn't have a lot of the problems
that a lot of the other algorithms had.
that a lot of the other algorithms had.
But one of those uh right now is that
But one of those uh right now is that
it's running a lot of really really
it's running a lot of really really
short experiments. And I think the
short experiments. And I think the
reason for this is just that I messed
reason for this is just that I messed
up. And uh instead of trying to tell it
up. And uh instead of trying to tell it
to pick an experiment from uh that takes
to pick an experiment from uh that takes
between the length of the shortest
between the length of the shortest
experiment it's ever run and the length
experiment it's ever run and the length
of the longest experiment, it instead
of the longest experiment, it instead
just tries to like pick an experiment of
just tries to like pick an experiment of
any length up to the longest. So like
any length up to the longest. So like
it's going to pick a lot of experiments
it's going to pick a lot of experiments
that are below the minimum length which
that are below the minimum length which
then just get capped off to the minimum
then just get capped off to the minimum
length. And uh yeah, that's what I think
length. And uh yeah, that's what I think
is happening.
It's still running a bunch of really
It's still running a bunch of really
short experiments though, even though I
short experiments though, even though I
I should have had that fixed based on
I should have had that fixed based on
this. How's a random forest model make
this. How's a random forest model make
predictions? No idea. Those are so old.
predictions? No idea. Those are so old.
I literally like I've never used a
I literally like I've never used a
random forest.
like actually never used one.
I mean all my work is deep neural nets,
I mean all my work is deep neural nets,
right? Except for I guess technically
right? Except for I guess technically
this um this hyperparameter tuning
this um this hyperparameter tuning
algorithm uses Gaussian processes.
algorithm uses Gaussian processes.
That's about it.
All right. So, the problem is still
All right. So, the problem is still
definitely here,
definitely here,
right? We got one reasonably length like
right? We got one reasonably length like
one reasonable length to run and the
one reasonable length to run and the
rest of them are they went all the way
rest of them are they went all the way
to the top and then all the way to the
to the top and then all the way to the
bottom. So, something's screwy here.
bottom. So, something's screwy here.
Why do deep neural networks tend to
Why do deep neural networks tend to
perform better than shallow ones? I mean
perform better than shallow ones? I mean
they can
they can
well the real answer is
well the real answer is
um like what is it uh divine serendipity
um like what is it uh divine serendipity
or whatever like we don't know but uh
or whatever like we don't know but uh
approximately correct answer handwavy
approximately correct answer handwavy
answer is deeper neural nets you have
answer is deeper neural nets you have
more nonlinearities in the middle uh
more nonlinearities in the middle uh
they also tend to be larger and they can
they also tend to be larger and they can
represent more classes of functions
represent more classes of functions
uh so that they can represent more data.
uh so that they can represent more data.
Like if you have a complex function, you
Like if you have a complex function, you
have a one layer neural net of like a
have a one layer neural net of like a
specific capacity, it might not just be
specific capacity, it might not just be
able to represent the decision boundary
able to represent the decision boundary
that you want. It's a regression class.
that you want. It's a regression class.
might not be able to represent that
problem like you're training a thing to
problem like you're training a thing to
approximate another thing, right? If
approximate another thing, right? If
first thing is very simple and then
first thing is very simple and then
second thing is very complicated, simple
second thing is very complicated, simple
thing can't represent complicated thing
thing can't represent complicated thing
very well.
So it is this one is a longer experiment
So it is this one is a longer experiment
here I can
here I can
see. So it is running some longer
see. So it is running some longer
experiments but
like it's
like it's
screwy. It's like screwy what it's
doing. Let me figure out what this is.
doing. Let me figure out what this is.
What's happening here? What a break
What's happening here? What a break
point like right
here. Do like
here. Do like
this. Hey, free to work on GPU drive
this. Hey, free to work on GPU drive
stuff. Sure, Spencer. Uh, give
stuff. Sure, Spencer. Uh, give
me give me like two minutes to go run
me give me like two minutes to go run
use the restroom and then we will uh
use the restroom and then we will uh
I'll jump on a call or whatever for
I'll jump on a call or whatever for
that and do a set.
Ara, is this asking you stuff or you
Ara, is this asking you stuff or you
giving me
giving me
like introductory ML quiz? You know, I
like introductory ML quiz? You know, I
haven't used any of these algorithms in
haven't used any of these algorithms in
like almost a decade,
like almost a decade,
right? It's a clustering algorithm. It's
right? It's a clustering algorithm. It's
an unsupervised learning algorithm. You
an unsupervised learning algorithm. You
want to partition data into K groups
want to partition data into K groups
where the things in each group are
where the things in each group are
similar to each
other. I don't remember the distance
other. I don't remember the distance
metric that is used in the algorithm
metric that is used in the algorithm
because I haven't used it in a
decade. Dear
Spencer probably already in the Discord.
Spencer probably already in the Discord.
Nope.
I'll hop in the Discord.
Yep. How's it going, man? Hey, going
Yep. How's it going, man? Hey, going
well. Let me uh mute you on the stream.
well. Let me uh mute you on the stream.
Hold up. Uhhuh. I've been
Hold up. Uhhuh. I've been
debugging all sorts of crazy things.
debugging all sorts of crazy things.
Oh, yeah.
Oh, yeah.
We're making progress. Slow though.
Uh, so I made a PR by just pulling in
Uh, so I made a PR by just pulling in
the latest dev stuff into my GPU drive
the latest dev stuff into my GPU drive
branch. Um, let me go deal with that.
branch. Um, let me go deal with that.
Hang on. Oops.
I will note up front it does
I will note up front it does
not compile to to train from the latest
not compile to to train from the latest
stuff in dev.
I'm not certain if you would have wanted
I'm not certain if you would have wanted
me to just put that into the PR and then
me to just put that into the PR and then
you'd handle it in dev or if you want to
you'd handle it in dev or if you want to
pull my or pull my existing branch from
pull my or pull my existing branch from
my repo.
Uh what why doesn't it compile?
Uh what why doesn't it compile?
Uh you have some new agents per batch
Uh you have some new agents per batch
thing in buffer. Just we'll just pull
thing in buffer. Just we'll just pull
that and fix
it. Okay.
And then it looks like from the files I
And then it looks like from the files I
dropped in there when I pulled dev, it
dropped in there when I pulled dev, it
looks like you have a new build
looks like you have a new build
simple.sh as
simple.sh as
well.
well.
Build simple. I don't know what the heck
Build simple. I don't know what the heck
that
is. Okay. So, a lot of file
is. Okay. So, a lot of file
changes. You PR this to dev. Okay.
Well, you haven't seen the new release
Well, you haven't seen the new release
branch stuff, which is way crazier even.
Yeah. I mean, I don't know what's all in
Yeah. I mean, I don't know what's all in
between various things. A lot. A lot.
between various things. A lot. A lot.
So, I can start I can pull some things
So, I can start I can pull some things
out of here. Well, I love So, let me see
out of here. Well, I love So, let me see
what So, what
what So, what
is So, I see that there is some reward
is So, I see that there is some reward
tuning.
tuning.
This was a little bit of like kind of
This was a little bit of like kind of
like a dirty pull from just like me just
like a dirty pull from just like me just
syncing from dev and then merging stuff.
syncing from dev and then merging stuff.
Okay. And then we have this demo file.
Okay. And then we have this demo file.
Most of what's changed is
in theh
in theh
file which has more render stuff I
file which has more render stuff I
worked on. Uhhuh. Um that that GPU drive
worked on. Uhhuh. Um that that GPU drive
test file can probably be dropped out. I
test file can probably be dropped out. I
guess that just got tossed in there from
guess that just got tossed in there from
my branch. It's a dev branch. Doesn't
my branch. It's a dev branch. Doesn't
freaking matter. So, I mean, those files
freaking matter. So, I mean, those files
can just be deleted in the future. It's
can just be deleted in the future. It's
no big deal.
no big deal.
There's a diff here. There's a 300 some
There's a diff here. There's a 300 some
odd line edition here.
odd line edition here.
Yeah, that's um my changes to render
Yeah, that's um my changes to render
in.h means new drive. And then also
in.h means new drive. And then also
there's a there's some changes I had to
there's a there's some changes I had to
make to match how the NYU project
make to match how the NYU project
worked. Okay, that's good.
The means trick right there was just
The means trick right there was just
something so that the the camera always
something so that the the camera always
is on
origin. Also, did you I just ran one
origin. Also, did you I just ran one
random thing. Did you make a full set of
random thing. Did you make a full set of
animations for um power climb or is
animations for um power climb or is
there like one missing where it just
there like one missing where it just
like snaps?
Um the one that it would be missing
Um the one that it would be missing
is jumping off a block.
is jumping off a block.
I see. Everything else there's something
I see. Everything else there's something
where there's one where it's like it
where there's one where it's like it
looks really smooth and then it just
looks really smooth and then it just
snaps.
snaps.
Um I'll have to you you'll have to show
Um I'll have to you you'll have to show
me which one that is.
me which one that is.
Because some of them it's about playing
Because some of them it's about playing
with like the timing of when the
with like the timing of when the
animation ends versus
like when the next action is ready.
For sure. If you're wrapping a block, it
For sure. If you're wrapping a block, it
snaps because there's not really a good
snaps because there's not really a good
way to animate like
way to animate like
going around the cube.
going around the cube.
I'll have to fix the config for this.
I'll have to fix the config for this.
Um, but yeah, there's a couple weird
Um, but yeah, there's a couple weird
things. Anyways,
um, GPU drive doesn't have any animation
um, GPU drive doesn't have any animation
stuff. This is all just like drawings
stuff. This is all just like drawings
and
and
camera and c uh this one also has the
camera and c uh this one also has the
three the third person camera uh
view. Um that is me turning a curb into
view. Um that is me turning a curb into
a 3D rectangle.
Wait.
Wait.
3D raised by curb
height. Wait, is this now you're drawing
height. Wait, is this now you're drawing
triangles for the curb?
triangles for the curb?
Yeah.
Yeah.
What is this actually like a triangle
What is this actually like a triangle
strip or what is this? It makes it so
strip or what is this? It makes it so
that as you're wrapping a corner and the
that as you're wrapping a corner and the
curb curves, it looks like a like a
curb curves, it looks like a like a
round corner.
round corner.
All right, we'll look at what this is.
All right, we'll look at what this is.
Cool. I I guess I will see what it looks
Cool. I I guess I will see what it looks
like. Done a whole bunch of stuff on
this. Oh, you added a car.
this. Oh, you added a car.
Yeah.
Yeah.
Yay. Sure. I'm going to have complaints
Yay. Sure. I'm going to have complaints
about the car and have to get a cool car
about the car and have to get a cool car
made.
made.
Yeah. I mean, I I just picked a car from
Yeah. I mean, I I just picked a car from
online and then went inside of Blender
online and then went inside of Blender
to go change the color of it to have
to go change the color of it to have
multiple different colored cars.
multiple different colored cars.
Uh, you committed TF record files.
Uh, you committed TF record files.
Are these levels? What are these? Uh,
Are these levels? What are these? Uh,
those look to be
I can toss those out. Are they sample
I can toss those out. Are they sample
levels or like what are they? I think
levels or like what are they? I think
they're from the examples of the like
they're from the examples of the like
pre-process stuff when I first was doing
pre-process stuff when I first was doing
it. It seems like my commit also just
it. It seems like my commit also just
dropped. It's not bad to have an example
dropped. It's not bad to have an example
level by the way. Um then those are
level by the way. Um then those are
example levels. Cool. Whatever. We're
example levels. Cool. Whatever. We're
fine. I don't And I don't know what
fine. I don't And I don't know what
build simple is. I don't know what this
build simple is. I don't know what this
is.
is.
It looks like when I did my merge, it
It looks like when I did my merge, it
just like pulled stuff in. Yeah,
just like pulled stuff in. Yeah,
whatever.
We merge
thing. All right. So here we have your
thing. All right. So here we have your
GPU
GPU
drive build
ocean supposed to do something.
Uh you're on uh test performance. Go to
Uh you're on uh test performance. Go to
this. Go to the C file and
um switch it to
demo.
demo.
Oh, does look
cool. Is these are these are 3D curves?
cool. Is these are these are 3D curves?
Yep. You actually made Okay. The only
Yep. You actually made Okay. The only
feedback I have you for there is that
feedback I have you for there is that
there is a draw triangle strip function.
instead of having to draw individual
instead of having to draw individual
triangles. But yeah, that is awesome.
triangles. But yeah, that is awesome.
Cool. Uh and like because you have that,
Cool. Uh and like because you have that,
it's actually probably not that hard now
it's actually probably not that hard now
to make potentially more elevated things
to make potentially more elevated things
and put the cars in a maze. H
and put the cars in a maze. H
Yeah. I mean, you could do whatever you
Yeah. I mean, you could do whatever you
want at this point in terms of drawing
want at this point in terms of drawing
levels.
Yeah. And if only they drove around.
Yeah. And if only they drove around.
Yeah. If you switch to move expert and
Yeah. If you switch to move expert and
step, you can see what the policy is
step, you can see what the policy is
supposed to be
supposed to be
doing in theh file.
doing in theh file.
Okay, I can do that. What is the thing
Okay, I can do that. What is the thing
we want to debug? This thing not train
we want to debug? This thing not train
well or what? Yes, that would be
well or what? Yes, that would be
priority number one. Okay, let's let's
priority number one. Okay, let's let's
do that. So, but step one is first
do that. So, but step one is first
getting it to work with the new dev
getting it to work with the new dev
stuff that's in there cuz Okay, I was
stuff that's in there cuz Okay, I was
working on a fairly old
dev. It compiles, but it does not rain.
dev. It compiles, but it does not rain.
I guess
um I think it's just missing a parameter
um I think it's just missing a parameter
because if you put it on
because if you put it on
uh native on on without multipprocessing
uh native on on without multipprocessing
it just runs into a bug in clean buffer
it just runs into a bug in clean buffer
RL right
just stop. Oh, someone from your someone
just stop. Oh, someone from your someone
from your chat says that uh your audio
from your chat says that uh your audio
is kind of low.
is kind of low.
[Music]
[Music]
Joseph's audio is way low
comparatively. Does that mean that
comparatively. Does that mean that
you're too Say something? Hello. Yeah.
you're too Say something? Hello. Yeah.
Okay. Your mic is just super
Okay. Your mic is just super
high. All
high. All
right. Say something again. What's up?
right. Say something again. What's up?
Mic down a little bit more. All right.
Mic down a little bit more. All right.
Let me know if this is good. I had to
Let me know if this is good. I had to
just mix the thing.
Dec agents
Dec agents
per doesn't exist in native M2, but we
per doesn't exist in native M2, but we
can
multiprocess. I think multipprocessing
multiprocess. I think multipprocessing
is a little weird on this as well, but
is a little weird on this as well, but
we can look at that later at one point.
we can look at that later at one point.
Okay, we have it as default now for
Okay, we have it as default now for
everything pretty much. Ah, okay. I
everything pretty much. Ah, okay. I
think I've noticed some differences on
think I've noticed some differences on
multipprocessing versus native.
multipprocessing versus native.
Your mic super high. All right, we'll
Your mic super high. All right, we'll
try this.
try this.
Am I still exploding eardrums?
Am I still exploding eardrums?
Um I it should be pretty close to mine
Um I it should be pretty close to mine
now at this point. I just for me to mix.
now at this point. I just for me to mix.
No
No
worries.
Uh yeah. So, this is this is the fun
Uh yeah. So, this is this is the fun
thing with uh having to get the batches
thing with uh having to get the batches
all correct, right?
Yeah. Yeah. So, you want you want to
Yeah. Yeah. So, you want you want to
have like a multiple of the number of
have like a multiple of the number of
cars or whatever the number of agents.
cars or whatever the number of agents.
So, how many agents is this? Do we know
So, how many agents is this? Do we know
up front
up front
um for this round?
No, it's an awkward number. Let me do a
No, it's an awkward number. Let me do a
Let me It looks like 1847 or
3536. 3536. It is.
But we do
But we do
36. Is that the total number?
36. Is that the total number?
So, one thing to take a note of is I did
So, one thing to take a note of is I did
something funky in my Sython.
something funky in my Sython.
Before you do some of this, I multiplied
Before you do some of this, I multiplied
times eight already inside the Sython.
What do you multiply by eight? The
What do you multiply by eight? The
number of agents. Why?
Um, it was an experiment because at the
Um, it was an experiment because at the
time I was only doing something I was
time I was only doing something I was
only just kind of getting 75 levels to
only just kind of getting 75 levels to
go and when you only had 75 levels, it
go and when you only had 75 levels, it
only gave you like, you know, a few
only gave you like, you know, a few
hundred agents. So, I wanted to get more
hundred agents. So, I wanted to get more
parallelization going on those seven on
parallelization going on those seven on
this on the when working with 75 maps.
this on the when working with 75 maps.
So, I cloned that those agents into more
So, I cloned that those agents into more
M's.
M's.
Okay. All I want to do here for
Okay. All I want to do here for
reference is I just want to figure out
reference is I just want to figure out
how many cards you have and set the
how many cards you have and set the
batch size to be like 64 times that and
batch size to be like 64 times that and
the mini batch size to be like eight
the mini batch size to be like eight
times that. That's all I really want to
times that. That's all I really want to
do.
Okay. So, like how many cars do we have?
Okay. So, like how many cars do we have?
Then you're going to be looking
at should be 582.
582 cars. That's it. Across 75 maps.
582 cars. That's it. Across 75 maps.
Yeah. All
Yeah. All
right. That's how that's how many active
right. That's how that's how many active
agent cars there should
be. You have a pretty small batch size,
be. You have a pretty small batch size,
but whatever.
Yeah. I mean, that's why I I decided to
Yeah. I mean, that's why I I decided to
do like the the multiply by eight thing
do like the the multiply by eight thing
inside of the Sython. So if you want to
inside of the Sython. So if you want to
reverse that out, what but the
multi if you have 8x the number of cars
multi if you have 8x the number of cars
being used for
being used for
obs, don't I? Yeah. So that that's what
obs, don't I? Yeah. So that that's what
I was I thought you wanted the original
I was I thought you wanted the original
number. I mean 4656. Okay. So it's it is
number. I mean 4656. Okay. So it's it is
32. Not it is
32. Not it is
226. Your batch size is
226. Your batch size is
226. And what are you doing with those
226. And what are you doing with those
extra cars?
extra cars?
I was just trying to get some more M's
I was just trying to get some more M's
going. What do you mean more?
going. What do you mean more?
Okay, so right now the num m's parameter
Okay, so right now the num m's parameter
is directly correlates to the map index
is directly correlates to the map index
0 through 74. Did you just make eight
0 through 74. Did you just make eight
copies of each map? Yes. Oh yeah, that's
copies of each map? Yes. Oh yeah, that's
if you said that it immediately. Yeah,
if you said that it immediately. Yeah,
that's totally fine. Whatever.
that's totally fine. Whatever.
Okay. Yeah, that's I Okay,
cool. So, where is this
cool. So, where is this
thing? 5 30 this divide by what is it? 8
28,000. These things take a while to
28,000. These things take a while to
load.
And they spam a
Is it
Is it
stuck?
stuck?
It looks that way.
Normally when there's something like
Normally when there's something like
that going on, it's related to Neptune
that going on, it's related to Neptune
or Wani.
I didn't think I ran it with Neptune,
I didn't think I ran it with Neptune,
did I?
did I?
No, I don't know if you did, but
No, I don't know if you did, but
normally that's like what happens if it
normally that's like what happens if it
if it halts for
if it halts for
me. I did not run it with anything.
me. I did not run it with anything.
So
um
native is it cuz you have one
worker. It shouldn't matter. It should
worker. It shouldn't matter. It should
be fine like this.
Multi. There should not be an issue with
Multi. There should not be an issue with
this. This is weird.
this. This is weird.
Multiprocessing. You always had to have
Multiprocessing. You always had to have
two workers, two M's.
two workers, two M's.
No, you can have as many as you want or
No, you can have as many as you want or
as few as you
want. The uh the new branches also will
want. The uh the new branches also will
have better warnings for like batch size
have better warnings for like batch size
stuff as well.
What is it
doing? If it's done, it should just go
doing? If it's done, it should just go
into starting. It It really shouldn't.
These are all things that have just
This is just taking
This is just taking
forever.
forever.
Before I pulled in dev, this was not a
Before I pulled in dev, this was not a
an
issue. I guess we just like put some
issue. I guess we just like put some
break
break
points. But this is very
points. But this is very
odd. Oh, wait. Is the policy kind of big
or the I mean not big enough where it
or the I mean not big enough where it
should be delaying like that.
should be delaying like that.
Is the mini batch like ridiculous?
Like is this mini batch ridiculously
Like is this mini batch ridiculously
large?
It could just be slow.
Let's see what the default mini batch
is. Mini batch on default on mine is
is. Mini batch on default on mine is
8192,
8192,
but by
but by
this if not, we'll start stepping
this if not, we'll start stepping
through this to see what the heck is
through this to see what the heck is
going
on. Clone agent
on. Clone agent
offset. So, this says that you have
offset. So, this says that you have
4,9 4637 agents.
4,9 4637 agents.
Um,
Um,
plus one more
plus one more
round that the But that's not the number
round that the But that's not the number
that you told me.
that you told me.
No, the number I told you is
No, the number I told you is
the is the actual number divided by
the is the actual number divided by
eight.
Well, no.
Well, no.
Like it's you if you have multiple
Like it's you if you have multiple
copies of the of M's that still counts.
copies of the of M's that still counts.
Like those are all unique cars.
Like those are all unique cars.
Um, like I I wanted to know the OBS
Um, like I I wanted to know the OBS
batch size. Is this like not the OBS
batch size. Is this like not the OBS
batch size?
The 500 something I told you earlier.
The 500 something I told you earlier.
It's It's probably just not the OBS
It's It's probably just not the OBS
batch size. No, it's 4,000 something.
batch size. No, it's 4,000 something.
Yeah. So then that's Yeah, it's totally
Yeah. So then that's Yeah, it's totally
going to break because this is a dev
going to break because this is a dev
branch that doesn't have safety checks
branch that doesn't have safety checks
on stuff not being divisible. So it's
on stuff not being divisible. So it's
probably just infinite looping somehow.
probably just infinite looping somehow.
Um, I'm trying to get that number for
Um, I'm trying to get that number for
you right now. When I when I reloaded
you right now. When I when I reloaded
the the levels, the numbers I was
the the levels, the numbers I was
working with changed. So, let
working with changed. So, let
me Well, you will actually get warnings
me Well, you will actually get warnings
about that on the release branch. Like,
about that on the release branch. Like,
it'll make sure everything's evenly
divisible. We're not even getting to run
divisible. We're not even getting to run
the policy.
It's probably just like
running be getting here at least, right?
Okay, it's not even getting to evaluate.
Okay, it's not even getting to evaluate.
So, something's just screwy.
So, something's just screwy.
It could be mad at what I
It could be mad at what I
did, but like it looks like it's just
did, but like it looks like it's just
hanging in the
end. Okay.
Go to native
Go to native
then serial.
I've got a meeting, by the way, with the
I've got a meeting, by the way, with the
the guys that I was uh the the tech guy
the guys that I was uh the the tech guy
of the the guys that I chatted with you
of the the guys that I chatted with you
about a few weeks ago at 4:15 if you
about a few weeks ago at 4:15 if you
want to join. If not, I'll just handle.
want to join. If not, I'll just handle.
Is that uh today or what? Yeah, in was
Is that uh today or what? Yeah, in was
it a little under an hour? Okay. Oh,
it a little under an hour? Okay. Oh,
your time 4:15. Okay. Okay.
your time 4:15. Okay. Okay.
Oh, yeah. I forgot there wasn't an hour
Oh, yeah. I forgot there wasn't an hour
difference. Yeah. Yeah. I'm I'm in
difference. Yeah. Yeah. I'm I'm in
central
You will appreciate the flag that's
You will appreciate the flag that's
going in the background then
is large. Nice.
Yeah. So the total agent should be 4656.
in terms of like the num agents times 8
in terms of like the num agents times 8
number
number
total agents equals 582 is what's being
total agents equals 582 is what's being
returned. Yeah. So the times 8 is the
returned. Yeah. So the times 8 is the
4656.
I see
because I was cloning those just to try
because I was cloning those just to try
and get more parallel going on 75. 48
and get more parallel going on 75. 48
was say 4856 40
4656. I don't think this is the error,
4656. I don't think this is the error,
but we will fix this at least.
What if it's a torch
What if it's a torch
issue? be
weird. And then on reset is when it
weird. And then on reset is when it
loads all the maps or right
here. It loads all of them in the Syon,
here. It loads all of them in the Syon,
but in a nit it does it
all. Wait, is that the right order?
all. Wait, is that the right order?
Observations, actions, rewards, masks,
Observations, actions, rewards, masks,
terminals. I think the order is wrong.
terminals. I think the order is wrong.
Oh, we probably check that.
Is that something with the new bindings?
Is that something with the new bindings?
Is that would be an issue? No, that's
Is that would be an issue? No, that's
just been like that
forever. Yeah, this this has
forever. Yeah, this this has
observations in it, man.
observations in it, man.
Um, hang
on.
OBS actions rewards terminals.
OBS actions rewards terminals.
Terminals then masks. There's not even a
Terminals then masks. There's not even a
masks in the Oh, I guess it depends on
masks in the Oh, I guess it depends on
if you actually if you put it in the
if you actually if you put it in the
that order in the Syon, it's
fine. Let
me see if you did.
Yeah, you did it
fine. You did it fine.
Okay, let's see if this runs.
Okay, so this runs except for
um how do we get this to be a
um how do we get this to be a
reasonable number of
Um, how do we get this thing to be a
Um, how do we get this thing to be a
reasonable size?
What do you mean by that? Can we get
What do you mean by that? Can we get
this to be a multiple
this to be a multiple
of 128 or something? Or not really? No,
of 128 or something? Or not really? No,
it's entirely dynamic because it's based
it's entirely dynamic because it's based
on the amount of agents per map of those
on the amount of agents per map of those
maps that you're given.
maps that you're given.
I mean, you could
I mean, you could
technically reduce the amount of static
technically reduce the amount of static
cars in a map. Or no, hold up. Because
cars in a map. Or no, hold up. Because
you only care about active cars. You You
you only care about active cars. You You
just be taking out some active cars
just be taking out some active cars
theoretically. Okay, let me see if I can
theoretically. Okay, let me see if I can
hack this thing then. Like, but that
hack this thing then. Like, but that
would be a little
jank. If I can hack this thing.
jank. If I can hack this thing.
Like if I just comment this, does it
Like if I just comment this, does it
run?
I mean, I think to get it to at least a
I mean, I think to get it to at least a
less annoying place, maybe getting rid
less annoying place, maybe getting rid
of my cloning in the Sython would
of my cloning in the Sython would
probably make things a little less. It's
probably make things a little less. It's
just that we're shipping we're shipping
just that we're shipping we're shipping
Huda stuff now and it's
like it doesn't like when things aren't
like it doesn't like when things aren't
fixed sizes. There's technically I can
fixed sizes. There's technically I can
make it work. Just I haven't done it
make it work. Just I haven't done it
yet. Let me see if this breaks or not.
Building the
kernels. Oh, now it's rea tuning. Takes
kernels. Oh, now it's rea tuning. Takes
forever.
Much work to be
Yep. So that's not It's just not happy.
Yep. So that's not It's just not happy.
It's just not
It's just not
happy. It's the Okay. Is it cuz it's
happy. It's the Okay. Is it cuz it's
over
4096? Hang
4096? Hang
on. I mean
I just
I just
do see if I do this good for
To be fair, the mini batch size doesn't
To be fair, the mini batch size doesn't
have to be this way.
Maybe this is the trick.
Maybe this is the trick.
Are you just forcing the mini batch to
Are you just forcing the mini batch to
be a good number? Six.
This is
16k like you see the issue is like the
16k like you see the issue is like the
CUDA kernels they expect like a certain
CUDA kernels they expect like a certain
number of rows. Mhm.
number of rows. Mhm.
Maybe this is the this is the thing
Maybe this is the this is the thing
though. We just let you
though. We just let you
do different mini batch size compared to
do different mini batch size compared to
batch
batch
size because we no longer like iterate
size because we no longer like iterate
through anymore. We sample
anyways. So maybe that's the play. You
anyways. So maybe that's the play. You
have to be kind of careful with your
have to be kind of careful with your
batch size, but you don't have to really
batch size, but you don't have to really
care about the mini batch size. As long
care about the mini batch size. As long
as it's like
as it's like
a big enough that
works assertion.
How is this still screwed
up? Want to compute the puffer
advantage. I
advantage. I
mean, it's still not going to let me
mean, it's still not going to let me
compute. It's this one
here. Maybe what we'll just do.
I just want to get you like a version of
I just want to get you like a version of
this that you can play with and solve
this that you can play with and solve
the problem
the problem
on. And then like it'll be on me to
on. And then like it'll be on me to
figure out what we're going to
figure out what we're going to
do longer
do longer
term to like make this thing not such a
term to like make this thing not such a
pain in the
ass whether that's figuring out how to
ass whether that's figuring out how to
make the CUDA kernels run better and
make the CUDA kernels run better and
yeah there here.
yeah there here.
So, is that an assert or was that not
So, is that an assert or was that not
an? We got some weird message up there.
an? We got some weird message up there.
It's
fine. 61% of time is not
happy. Wait,
happy. Wait,
Spencer, why did you do
You did eight replicas and and you but
You did eight replicas and and you but
you put them on the same core instead of
you put them on the same core instead of
doing it on multiple cores.
Yeah. Well, you're 60% M time right now.
If you get rid of that, I think it drops
If you get rid of that, I think it drops
down to like 17% of time or something
down to like 17% of time or something
like that.
Well, that doesn't make sense because
Well, that doesn't make sense because
it's 8x more data. The problem is it's
it's 8x more data. The problem is it's
on one core, right? But I thought GP I
on one core, right? But I thought GP I
thought the thing was fast. Is it not?
thought the thing was fast. Is it not?
So, it's at
So, it's at
like end time ranges from like 700,000
like end time ranges from like 700,000
to a million steps per second. But the
to a million steps per second. But the
train if you get all of the obs in there
train if you get all of the obs in there
whether they're really required or not.
whether they're really required or not.
Okay. So this is the thing I was saying
Okay. So this is the thing I was saying
where it's like if we want this thing to
where it's like if we want this thing to
just work we should just respawn the
just work we should just respawn the
cars.
cars.
Okay. Actually here this is this is
Okay. Actually here this is this is
working though. Here let's let's at
working though. Here let's let's at
least get a reasonable setup out of
least get a reasonable setup out of
this. Um yeah. So, so what that right
this. Um yeah. So, so what that right
now is your penalties right there. But I
now is your penalties right there. But I
I all I want to do is like
I all I want to do is like
where's this factor? Where's this factor
where's this factor? Where's this factor
of eight coming in? Syon. In the Sython.
of eight coming in? Syon. In the Sython.
In the Sython.
In the Sython.
Eight. If I just look for eight.
Eight. If I just look for eight.
Yeah, you'll find it. I see
Yeah, you'll find it. I see
UTF8. Num clones equals one.
UTF8. Num clones equals one.
Num clones is eight.
Okay. And then you hold up hold you have
Okay. And then you hold up hold you have
to do one more thing. What else? Uh you
to do one more thing. What else? Uh you
have to go inside of step and
have to go inside of step and
reset in the Sython and change the times
reset in the Sython and change the times
8 because that variable wasn't defined
8 because that variable wasn't defined
in
in
uh I only defined it in in it.
Okay, why don't we actually use our CPU
Okay, why don't we actually use our CPU
which has multiple cores.
Actually, let's do that. I I didn't do
Actually, let's do that. I I didn't do
it at first because I felt like whenever
it at first because I felt like whenever
I did multiprocessing, I was getting
I did multiprocessing, I was getting
weirdly
less successful results and I didn't
less successful results and I didn't
know if it was just because of like how
know if it was just because of like how
my like agent setups were. Well, we will
my like agent setups were. Well, we will
find that
out. This is spamming way faster.
out. This is spamming way faster.
Whoa. That total agent. Now you're only
Whoa. That total agent. Now you're only
going to have like 500 something agents.
No, because I have eight I'm doing this
No, because I have eight I'm doing this
eight
eight
times on eight different processes. I'm
times on eight different processes. I'm
doing the same thing that you're doing.
doing the same thing that you're doing.
So instead of making eight copies of one
So instead of making eight copies of one
process,
process,
right? Right.
right? Right.
Okay. Why is this a total O agents
Okay. Why is this a total O agents
32,000? Did it not recompile? Is there a
32,000? Did it not recompile? Is there a
factor of eight somewhere still?
Um, GPU drive.py possibly. Yeah, GPU
drive.py. Numb agents. Total agents
drive.py. Numb agents. Total agents
times 8.
We'll have some sanity
today. Okay. A little better, right?
We just doubled the training speed.
We just doubled the training speed.
Yeah. And if you if you take out some of
Yeah. And if you if you take out some of
the obs, I mean, then you you drop you
the obs, I mean, then you you drop you
can increase it even more. I was really
can increase it even more. I was really
I only really slowed things down because
I only really slowed things down because
I was getting I was confused as to why I
I was getting I was confused as to why I
couldn't get something that was matching
couldn't get something that was matching
exactly. So I was like, "Okay, maybe
exactly. So I was like, "Okay, maybe
it's something to do with the ops." So,
it's something to do with the ops." So,
I decided to just copy exactly what
I decided to just copy exactly what
there was, even though I know it really
there was, even though I know it really
shouldn't affect it,
but I use this.
but I use this.
So, so this is also the zero penalty
So, so this is also the zero penalty
test. So, this test should always get
test. So, this test should always get
you to pretty much um 99 point, you
you to pretty much um 99 point, you
know, like 99 if it's has zero um
know, like 99 if it's has zero um
penalty collisions on off-road or
penalty collisions on off-road or
hitting a car. Okay. So, why is it not
hitting a car. Okay. So, why is it not
instant solving this if it's easy? It
instant solving this if it's easy? It
generally for me took about 100 million
generally for me took about 100 million
steps to get to 0.99.
steps to get to 0.99.
Uh, I'm used to things running 10x this
Uh, I'm used to things running 10x this
fast. So, it's still at 15 mil.
Yeah, there's a lot of speed loss
Yeah, there's a lot of speed loss
getting from environment to polic to the
getting from environment to polic to the
the torch side of things.
the torch side of things.
The ops are huge.
Yeah, I fix all this
And then I added the one hot encoding on
And then I added the one hot encoding on
on the classifications of the roads.
So this shared embedding what is hang on
So this shared embedding what is hang on
where's the one that has the max on it.
where's the one that has the max on it.
If you go into the encode observations
If you go into the encode observations
the maxes are on the road and the
the maxes are on the road and the
partner
partner
features. Okay. And those go to input
features. Okay. And those go to input
size, which is
size, which is
uh 128,
which is what the NYU group had. All
which is what the NYU group had. All
right. I kind of want to up your hidden
right. I kind of want to up your hidden
size, but we'll
see. We actually have we have um I
see. We actually have we have um I
believe 512 hidden dim with a simple
believe 512 hidden dim with a simple
policy.
policy.
This This one's pretty cool. Uh so grid
This This one's pretty cool. Uh so grid
here has a 512 hidden dim RNN. It's like
here has a 512 hidden dim RNN. It's like
a 2 mil perm policy or whatever. Transit
a 2 mil perm policy or whatever. Transit
1.8 million steps a second.
So like puffer very fast,
but ob's really small on grid, right?
but ob's really small on grid, right?
Mhm.
Give me one second.
Okay, I'm back.
Mhm. It's not terrible. It's just it
Mhm. It's not terrible. It's just it
feels slow because it's training slow.
feels slow because it's training slow.
Yeah,
Yeah,
but this is without collisions,
but this is without collisions,
correct?
correct?
It's my it's it's my sanity test just to
It's my it's it's my sanity test just to
make sure that it can actually get to
make sure that it can actually get to
the goal and like figure out that
the goal and like figure out that
portion because I was like, why is this
portion because I was like, why is this
not figuring it out with collisions?
not figuring it out with collisions?
And does it get reward for hitting goal
And does it get reward for hitting goal
or what does it get? Yeah, just gets
or what does it get? Yeah, just gets
reward for hitting goal the same way
reward for hitting goal the same way
that they've set up
that they've set up
theirs and you get one
reward. It it it's kind of down to like
reward. It it it's kind of down to like
an entropy thing at some point because
an entropy thing at some point because
it's like it has to find the
it's like it has to find the
goal, but if it's having to find it and
goal, but if it's having to find it and
it's hitting walls the whole time
it's hitting walls the whole time
getting there, it it tends to find it to
getting there, it it tends to find it to
be kind of a random luck event. Have you
be kind of a random luck event. Have you
seen how Puffer handles random luck
seen how Puffer handles random luck
events?
This is kind of the best that there is
This is kind of the best that there is
in RL right
in RL right
now with this maze
now with this maze
finding. Like we're pretty good at that.
finding. Like we're pretty good at that.
This kind of just works out of the box.
This kind of just works out of the box.
Look, it actually even solves this one.
Look, it actually even solves this one.
Like that's why I feel like this
Like that's why I feel like this
shouldn't be a challenging it problem.
shouldn't be a challenging it problem.
It shouldn't.
cuz the environment's fast enough where
cuz the environment's fast enough where
it should be able to
it should be able to
just get there. You would think it's
just get there. You would think it's
possible the hypers are just bad. I
possible the hypers are just bad. I
don't know. Let's see what your hypers
don't know. Let's see what your hypers
are. I mean, they're just default
are. I mean, they're just default
hypers, I think. I mean, oh, see if that
hypers, I think. I mean, oh, see if that
is true.
Your learning rate is your learning rate
Your learning rate is your learning rate
is 5x lower than mine.
What about
What about
grid? We
grid? We
do 05 for
do 05 for
grid. But in grid, we have a way bigger
grid. But in grid, we have a way bigger
policy than you have.
policy than you have.
Why is your entropy coefficient?
Hey, no mind the entropy coefficient.
Hey, no mind the entropy coefficient.
I don't know. We just It's not even a
I don't know. We just It's not even a
fully tuned run is the thing. I kind of
fully tuned run is the thing. I kind of
just threw partial defaults on stuff and
just threw partial defaults on stuff and
kind of so everything.
That's the crazy thing. It's like we're
That's the crazy thing. It's like we're
not even remotely close to like this is
not even remotely close to like this is
not even my final form, right?
Let me try and link you as well.
Let me try and link you as well.
Uh previous runs that I've gotten
to I'm going to just like make the
to I'm going to just like make the
policy bigger after this.
policy bigger after this.
Um, it looks like one of the runs where
Um, it looks like one of the runs where
I got to 99 pretty quickly, or at least
I got to 99 pretty quickly, or at least
relatively quickly speaking, was with a
relatively quickly speaking, was with a
kneeling on.
kneeling on.
Yeah, this has a kneeling on
Yeah, this has a kneeling on
with a higher default learning rate.
with a higher default learning rate.
Yeah, this is like 5x too low. I think I
Yeah, this is like 5x too low. I think I
just had the original one that you had
just had the original one that you had
the 025 when I had purely the original
the 025 when I had purely the original
defaults. Mhm. It got there
defaults. Mhm. It got there
in 15 minutes. In 15
in 15 minutes. In 15
minutes. Oh, but you were using ultra
minutes. Oh, but you were using ultra
slow version. Yeah. I mean, maybe it'll
slow version. Yeah. I mean, maybe it'll
be
be
like five minutes or something.
like five minutes or something.
Five minutes. Still slow.
I did the maze policy trained in 90
I did the maze policy trained in 90
seconds and it's bigger.
seconds and it's bigger.
I am all here if you're able to get this
I am all here if you're able to get this
to go to the the
to go to the the
902. Oh, I'll definitely be able to.
902. Oh, I'll definitely be able to.
It's just a matter of
It's just a matter of
um I mean, ideally I get this ideally I
um I mean, ideally I get this ideally I
want to get this merged onto I know it's
want to get this merged onto I know it's
a pain in the ass to keep up with my
a pain in the ass to keep up with my
release branches, but it does make it
release branches, but it does make it
easier to test Um
easier to test Um
I mean for a while you said to just not
I mean for a while you said to just not
touch the new dev branch for a while
touch the new dev branch for a while
too. Yeah, I think also was that around
too. Yeah, I think also was that around
when because I knew I was going to be
when because I knew I was going to be
gone for a week and wasn't going to be
gone for a week and wasn't going to be
able to help you either. Yeah, it so
able to help you either. Yeah, it so
this is just like, hey, I just merged
this is just like, hey, I just merged
it. I'm going to throw this in your
it. I'm going to throw this in your
direction.
direction.
We will see what uh what magic I can
We will see what uh what magic I can
apply to this.
It does not seem to be doing 99 or
It does not seem to be doing 99 or
whatever. It seems to be stuck at 80
whatever. It seems to be stuck at 80
something.
It's probably because the learning rate
It's probably because the learning rate
there. I mean that that was just a
there. I mean that that was just a
recent learning rate I just dropped on
recent learning rate I just dropped on
there. If you put it back to the the
there. If you put it back to the the
original 1025, it probably can solve
original 1025, it probably can solve
it. Okay. So, can I
it. Okay. So, can I
um Yeah, fine. We'll do 25. We'll do one
um Yeah, fine. We'll do 25. We'll do one
more experiment on this. But then what
more experiment on this. But then what
about the This is with the freaking
about the This is with the freaking
collisions off like correct.
collisions off like correct.
It's kind of ridiculous.
It's kind of ridiculous.
Yeah. It's lame. Yeah.
Yeah. It's lame. Yeah.
And this should just be solved by now.
And this should just be solved by now.
Um,
Um,
with collisions on one of the things of
with collisions on one of the things of
a recent run I got, but it took a while.
a recent run I got, but it took a while.
I just put it in the chat was this run.
I just put it in the chat was this run.
Yeah, if you have existing experiments,
Yeah, if you have existing experiments,
I'm actually going to be able to give
I'm actually going to be able to give
you feedback on stuff. Let me go
find Are you
slow8? Why is there so this is with
slow8? Why is there so this is with
collisions? That's with collisions. So
collisions? That's with collisions. So
score, which is you the percentage of
score, which is you the percentage of
time that the agents reach their goal,
time that the agents reach their goal,
give collision rate and then off-road
give collision rate and then off-road
rate. Your collision rate goes down,
rate. Your collision rate goes down,
right? But it's not as good as theirs.
right? But it's not as good as theirs.
Theirs is like less than 1%. Yeah, but
Theirs is like less than 1%. Yeah, but
you're not solving the freaking task
you're not solving the freaking task
yet, man.
Yeah, but there's also got there at a
Yeah, but there's also got there at a
time where in terms of the steps would
time where in terms of the steps would
have already achieved it because they
have already achieved it because they
have a bunch of annoying policy
have a bunch of annoying policy
differences
differences
though. They've got like a bunch of
though. They've got like a bunch of
layer norms and weird stuff.
layer norms and weird stuff.
True, but should it not just do? No,
True, but should it not just do? No,
it'll be we got to sweep stuff and it's
it'll be we got to sweep stuff and it's
like, okay, you're you're now operating
like, okay, you're you're now operating
within like a margin of like fiddly
within like a margin of like fiddly
stuff is possible and just like run more
stuff is possible and just like run more
experiments. Um, like get this thing be
experiments. Um, like get this thing be
first, then we'll worry about whether
first, then we'll worry about whether
this thing actually is not there still.
this thing actually is not there still.
Because if you look at the time, I mean,
Because if you look at the time, I mean,
that's like an hour, but even then,
that's like an hour, but even then,
yeah, it's an hour cuz it's freaking
yeah, it's an hour cuz it's freaking
slow. This is less than a tenth of the
slow. This is less than a tenth of the
speed of our other
speed of our other
Ms. This should This would be 6 minutes.
Ms. This should This would be 6 minutes.
True.
True.
We got to fix that
We got to fix that
I mean, this is not even async
I mean, this is not even async
right
right
here. I I just did this. I got I This is
here. I I just did this. I got I This is
2.6x the speed of this run, and I didn't
2.6x the speed of this run, and I didn't
even do
async, right?
Yeah.
Yeah.
So, I mean, we this should be able to be
So, I mean, we this should be able to be
something reasonable. And then also, we
something reasonable. And then also, we
can play around. I'd be happy if it was
can play around. I'd be happy if it was
in like the 600 to 750 range at this
in like the 600 to 750 range at this
point. But, I mean, we Your obs are
point. But, I mean, we Your obs are
freaking like the thing is the obs are
freaking like the thing is the obs are
just big.
just big.
If we can get this version to
If we can get this version to
a successful result, I'm very confident
a successful result, I'm very confident
we can kill a lot of the obs and
we can kill a lot of the obs and
probably get something comparable. Okay,
probably get something comparable. Okay,
let's then let's do
let's then let's do
this. Got boxes. Let's throw some stuff
this. Got boxes. Let's throw some stuff
at things. All right, let's see what we
at things. All right, let's see what we
have in our
uh not this one. Where did the GP drive
uh not this one. Where did the GP drive
go?
Yeah. Okay.
Yeah. Okay.
So, that's that doesn't actually
help. That doesn't actually help.
Okay. So, input size to the RNN's got to
Okay. So, input size to the RNN's got to
be
be
512.
512.
512. Well, let's let's get this to run.
512. Well, let's let's get this to run.
And we're gonna like let's actually get
And we're gonna like let's actually get
a real
a real
policy because okay when I was doing
policy because okay when I was doing
although not the smartest approach the
although not the smartest approach the
8x cloning on a single core this was the
8x cloning on a single core this was the
policy that I
policy that I
got I just linked to you in chat and it
got I just linked to you in chat and it
was a pretty smooth train curve.
What did what was
What did what was
this? This is the one that I that is uh
this? This is the one that I that is uh
pretty much default params
pretty much default params
um but with the 8x
um but with the 8x
clone on one
clone on one
core. Weird.
I guess it's possible there's a
I guess it's possible there's a
multipprocessing difference. I haven't
multipprocessing difference. I haven't
seen it on anything else.
Okay, here's your thing running at
Okay, here's your thing running at
basically the exact same speed as
basically the exact same speed as
before.
before.
Um, but with a 2 million parameter
policy. How was it running at the same
policy. How was it running at the same
speed?
speed?
You're completely freaking bound by M's
You're completely freaking bound by M's
and communication and This is
and communication and This is
not the right one, I don't think,
not the right one, I don't think,
though, because it doesn't this doesn't
though, because it doesn't this doesn't
look
look
right. What's What's going on with
right. What's What's going on with
this? Not 84 score, right? I'm looking
this? Not 84 score, right? I'm looking
at it right
here. Not this either.
Where's my freaking run? Did I not I
Where's my freaking run? Did I not I
guess it's not on Neptune. Yeah. Okay.
guess it's not on Neptune. Yeah. Okay.
So, 4 at 10
mil. Oh, that might be still be
mil. Oh, that might be still be
comparable.
You have zero reward for collision, zero
You have zero reward for collision, zero
off-road.
off-road.
Did you want to reset your learning rate
Did you want to reset your learning rate
to the default?
to the default?
No, this is what we use for this size
policy. So, here's your next train.
policy. So, here's your next train.
Where is
Where is
it? Okay, there it is.
See what this does. Does my torch even
See what this does. Does my torch even
use the hidden size variable? Do I not
use the hidden size variable? Do I not
just use input size on everything? No,
just use input size on everything? No,
you use it. You use hidden
size. You do use it. I checked.
Okay. I did it for the shared layer at
Okay. I did it for the shared layer at
the very end. Yeah. Which is all because
the very end. Yeah. Which is all because
then that goes into the main network,
then that goes into the main network,
right?
I mean, I could like there are like
I mean, I could like there are like
several improvements I could make to
several improvements I could make to
this as
this as
well potentially.
Okay. I mean, this is doing something,
Okay. I mean, this is doing something,
right?
potentially. Let's see what other things
potentially. Let's see what other things
you have going on
here. Got learning rate
here. Got learning rate
set batch size. batch
size. Have you tried Have you messed
size. Have you tried Have you messed
with gamma lambda at all?
with gamma lambda at all?
Not beyond me just having a sweep a
Not beyond me just having a sweep a
while back ago.
while back ago.
What gamma and lambda did you get out of
What gamma and lambda did you get out of
it?
it?
Um, pull up my
Um, pull up my
sweep cuz the default gamma is really
sweep cuz the default gamma is really
freaking high.
This is doing way better though. You
This is doing way better though. You
see,
see,
uh, it looks like my highest gamma on
uh, it looks like my highest gamma on
that best run was fairly low. Actually,
that best run was fairly low. Actually,
it was
it was
point Never mind. I was looking at the
point Never mind. I was looking at the
wrong uh.99 and 0.987.
wrong uh.99 and 0.987.
Okay. So, that's not that far off of
Okay. So, that's not that far off of
what we have. That's
fine. I think default is
0.995. I'm hoping this just gives us a
0.995. I'm hoping this just gives us a
better rain
better rain
curve. It should just get to
curve. It should just get to
0.99. Mhm. If with the additional
0.99. Mhm. If with the additional
network capacity it doesn't, then
network capacity it doesn't, then
there's going to be some something
there's going to be some something
weird.
and these offsets in here haven't
and these offsets in here haven't
changed,
right? These should still be up to date.
I don't think anything should have
I don't think anything should have
changed
from any of that stuff.
I did notice my active agents count
I did notice my active agents count
changed fairly recently with that's the
changed fairly recently with that's the
other thing is we're not masking stuff
other thing is we're not masking stuff
at all. Like the thing that made the GPU
at all. Like the thing that made the GPU
drive uh their GPU drive stuff work very
drive uh their GPU drive stuff work very
very well was like the masked
very well was like the masked
No, this has mask in right now. Yeah,
No, this has mask in right now. Yeah,
but our code doesn't fix like doesn't
but our code doesn't fix like doesn't
use it correctly in the new version.
use it correctly in the new version.
Oh, yeah. Oh, in the latest dev version.
Oh, yeah. Oh, in the latest dev version.
know what you're saying. Mhm. Uh
this is going to be massively easier if
this is going to be massively easier if
we just respawn the cars. I'm
we just respawn the cars. I'm
telling you,
telling you,
and then just have them try and avoid
and then just have them try and avoid
not spawning on top of a car that's
not spawning on top of a car that's
where in the path of where another car
where in the path of where another car
is.
is.
Don't even bother doing that. Literally
Don't even bother doing that. Literally
just like cuz they they don't bounce off
just like cuz they they don't bounce off
each other. They just get a negative
each other. They just get a negative
reward. Right. Correct. Okay. completely
reward. Right. Correct. Okay. completely
ignore the fact that that can happen.
ignore the fact that that can happen.
Respawn the cars where they're supposed
Respawn the cars where they're supposed
to start whenever they either get to
to start whenever they either get to
their objective or or
their objective or or
collide. So collide equals negative
collide. So collide equals negative
reward and respawn.
Okay. Guarantee you it's so much it's
Okay. Guarantee you it's so much it's
going to be so much easier.
All right. Well, that's an easy change.
All right. Well, that's an easy change.
Yeah, it's not that hard of a change.
Yeah, it's not that hard of a change.
And it's like, well, it's not realistic.
And it's like, well, it's not realistic.
Well, it's not realistic to have the
Well, it's not realistic to have the
cars freaking phase through each other
cars freaking phase through each other
either, right? It's like arguably this
either, right? It's like arguably this
is more realistic cuz if you've crashed,
is more realistic cuz if you've crashed,
you've already screwed up.
Okay. Okay. I'll take that logic. Yes.
Okay. Okay. I'll take that logic. Yes.
And now here, uh, we are doing better
And now here, uh, we are doing better
than before.
So, yeah, it took me three experiments
So, yeah, it took me three experiments
to fix this mostly.
And the way that I knew what to do is
And the way that I knew what to do is
because I just did the exact same thing
because I just did the exact same thing
that worked on every other
environment. That's all I
environment. That's all I
did. I should try this on breakout to be
did. I should try this on breakout to be
fair. I have not done that
fair. I have not done that
yet. Bigger network to see if I can
yet. Bigger network to see if I can
install
install
it.
So, I don't know if we're getting N9 out
So, I don't know if we're getting N9 out
of this. We will see. We're definitely
of this. We will see. We're definitely
doing better than before.
But hey, look, this is like
But hey, look, this is like
substantially better than before. I cut
substantially better than before. I cut
your error rate in half pretty
much. Assuming this gets a little bit
much. Assuming this gets a little bit
better than this. When is gym stream?
better than this. When is gym stream?
Gymstream is between all other things
Gymstream is between all other things
I'm doing while streaming. I just get up
I'm doing while streaming. I just get up
and use equipment. But you will see many
and use equipment. But you will see many
pieces of equipment be delivered over
pieces of equipment be delivered over
the next few
the next few
weeks. We have, I think, two orders that
weeks. We have, I think, two orders that
should be coming in either end of this
should be coming in either end of this
week, start of next week, and then
week, start of next week, and then
there's a big order that should be
there's a big order that should be
coming in in a few weeks.
And then the thing I'm still waiting on
And then the thing I'm still waiting on
is terrace to go down so I can order all
is terrace to go down so I can order all
of the servers for the racks behind
Okay. So, I'm trying to think how I give
Okay. So, I'm trying to think how I give
this to I think I just push this to a
this to I think I just push this to a
new branch for
you. That sound good. I just pushed this
you. That sound good. I just pushed this
to a new branch for you. You can like
to a new branch for you. You can like
just make those changes, push to this
just make those changes, push to this
branch and see that it solves
branch and see that it solves
everything.
I suspect the encoder layer should also
I suspect the encoder layer should also
probably be bigger.
you're running these on. Yeah, you have
you're running these on. Yeah, you have
at least eight cores to run stuff
at least eight cores to run stuff
on. So, yeah, there you
on. So, yeah, there you
go. That ought to be decent for you.
still doesn't get to max. But like just
still doesn't get to max. But like just
fix the masking
thing. Be right back.
Spencer.
Oh, he disappeared.
Sorry, I had to take a quick phone call.
Sorry, I had to take a quick phone call.
Mhm. Um, okay. So, you pushed up to
Mhm. Um, okay. So, you pushed up to
Huffer Drive GitHub
Huffer Drive GitHub
Huffer Drive branch. It actually gets
Huffer Drive branch. It actually gets
89%.
89%.
Okay.
Okay.
It looks like it's still doing a little
It looks like it's still doing a little
bit of stuff.
bit of stuff.
So, turn off
um
um
masking, turn on uh
masking, turn on uh
respawning and take it from there.
respawning and take it from there.
So, when they collide or reach the
So, when they collide or reach the
goal, they should
goal, they should
respawn at the start. If they hit the
respawn at the start. If they hit the
goal, they get the plus goal reward. If
goal, they get the plus goal reward. If
they collide, they get the minus collide
they collide, they get the minus collide
reward. Yeah, sure. So, run
reward. Yeah, sure. So, run
that and you should just
that and you should just
solve. Like, it's an inf it's a pure
solve. Like, it's an inf it's a pure
infrastructure limitation. The old
infrastructure limitation. The old
infrastructure could handle this, but
infrastructure could handle this, but
the new infrastructure is like
the new infrastructure is like
dramatically better algorithmically.
Okay. Um, I can do that. And then
Okay. Um, I can do that. And then
you want me to sit on the call with
you want me to sit on the call with
these with the upcoming call with the
these with the upcoming call with the
415 one? Yeah, we can tell them just
415 one? Yeah, we can tell them just
like to make this thing quick.
And then um after that, do we want to
And then um after that, do we want to
keep working on this or uh can you How
keep working on this or uh can you How
long is it going to take you to make
long is it going to take you to make
those changes?
I don't think it should take me any time
I don't think it should take me any time
at all, honestly. All right, do that
at all, honestly. All right, do that
real quick. I'm go use the restroom. Go
real quick. I'm go use the restroom. Go
do that stuff real quick and then we'll
do that stuff real quick and then we'll
I'll start working on this with you as
I'll start working on this with you as
soon as you have that stuff ready
soon as you have that stuff ready
because I think it's like this version
because I think it's like this version
it's just you're fighting the
it's just you're fighting the
infrastructure and I don't want to be
infrastructure and I don't want to be
wasting our time running experiments
wasting our time running experiments
when it's like going to be so so so much
when it's like going to be so so so much
easier. So this thing it looks like it's
easier. So this thing it looks like it's
crashing now.
crashing now.
Uh which is like it's actually something
Uh which is like it's actually something
I have to deal with with the analing. I
I have to deal with with the analing. I
figured it out. But this got to 91 92
figured it out. But this got to 91 92
before that. So, okay. Well, um yeah,
before that. So, okay. Well, um yeah,
just go ahead and just um I don't know.
just go ahead and just um I don't know.
Are you hopping on a Google call? What
Are you hopping on a Google call? What
are you doing? Are you paying?
are you doing? Are you paying?
Whatever it is, I'll get you an invite.
Whatever it is, I'll get you an invite.
All right, sounds good. And I'll just
All right, sounds good. And I'll just
send you on Discord. Sounds good. All
send you on Discord. Sounds good. All
right. See you,
right. See you,
Spencer.
Spencer.
Cool. All right. So, uh here's the uh
Cool. All right. So, uh here's the uh
the plan, folks.
the plan, folks.
I gotta go take a call in a few.
I gotta go take a call in a few.
Um, oh, we have quite a few folks on
Um, oh, we have quite a few folks on
here. Hey everyone on Twitch. If you
here. Hey everyone on Twitch. If you
haven't been around here before,
haven't been around here before,
uh, I do hyper reinforcement learning
uh, I do hyper reinforcement learning
dev. It's all open source. It's all
dev. It's all open source. It's all
free. You can see a bunch of demos at
free. You can see a bunch of demos at
puffer.ai. And, uh, you know, Spencer's
puffer.ai. And, uh, you know, Spencer's
just a collaborator who came in with no
just a collaborator who came in with no
RL experience. That could be you. you're
RL experience. That could be you. you're
interested in getting
interested in getting
involved. If you want to help me out for
involved. If you want to help me out for
free, just star the GitHub. Really helps
free, just star the GitHub. Really helps
when we get stars on GitHub. Uh and you
when we get stars on GitHub. Uh and you
can join the Discord to get involved
can join the Discord to get involved
with
with
dev. Cool. So, here's the plan.
dev. Cool. So, here's the plan.
Um we're going to keep fixing GPU drive
Um we're going to keep fixing GPU drive
stuff today. Driving sim. Actually, I
stuff today. Driving sim. Actually, I
can show this off real quick. Why
can show this off real quick. Why
not? We have the EVEL, I think, working,
not? We have the EVEL, I think, working,
right?
Yeah. So, here's the
sim. Pretty
sim. Pretty
cool.
cool.
Um, so the plan here is going to be to
Um, so the plan here is going to be to
fix this with Spencer today. We also
fix this with Spencer today. We also
have hyperparam tuning algorithm stuff
have hyperparam tuning algorithm stuff
to
to
fix. That's my alarm to get ready for
fix. That's my alarm to get ready for
meeting. Um, we're going to do all that.
meeting. Um, we're going to do all that.
I got to
I got to
take a quick meeting and then I'll be
take a quick meeting and then I'll be
back for probably an hour after that
back for probably an hour after that
before 6 and then I should be back after
before 6 and then I should be back after
dinner for a little bit more work things
dinner for a little bit more work things
pending and then I'm pretty much live
pending and then I'm pretty much live
all day every day otherwise. So, uh,
all day every day otherwise. So, uh,
yeah, thanks for tuning in

Kind: captions
Language: en
Okay, good
Okay, good
morning. We're
live. So, here's the plan for
live. So, here's the plan for
today. The latest version of Puffer Lib
today. The latest version of Puffer Lib
is doing very, very well on isolated
is doing very, very well on isolated
runs uh on a number of different
runs uh on a number of different
environments. We've set soda in the past
environments. We've set soda in the past
3, four weeks on pretty much everything
3, four weeks on pretty much everything
and by a huge margin. Uh the only last
and by a huge margin. Uh the only last
few things blocking are just a few
few things blocking are just a few
technical errors. We pretty much have
technical errors. We pretty much have
not run a fresh hyperparameter sweep in
not run a fresh hyperparameter sweep in
like a good couple of months on any of
like a good couple of months on any of
these things. So there's probably can
these things. So there's probably can
even do way better than it's doing now.
even do way better than it's doing now.
We just have some technical issues
We just have some technical issues
preventing that. Um specifically we have
preventing that. Um specifically we have
runs crashing
runs crashing
uh due to like nans and imps. Torch
uh due to like nans and imps. Torch
should not be crashing with nans and
should not be crashing with nans and
imps. Those should just be, you know,
imps. Those should just be, you know,
nanner and floss. That should not
nanner and floss. That should not
actually crash Torch. Uh the lazy fix on
actually crash Torch. Uh the lazy fix on
this would be to just throw everything
this would be to just throw everything
into a subprocess. I don't want to do
into a subprocess. I don't want to do
that. So instead, we're going to
that. So instead, we're going to
actually go through the transcript
actually go through the transcript
today. We're going to figure out why
today. We're going to figure out why
we're getting ns and imps on stuff and
we're getting ns and imps on stuff and
yeah, we're going to go from there.
yeah, we're going to go from there.
Switch the view over.
Hey man, how's it
going? Upper
indeed. Let's just get ourselves set up
indeed. Let's just get ourselves set up
here. I think we actually have some
here. I think we actually have some
errors to check
errors to check
potentially. Yeah. So this one right
here, I mean it's not going to give us
here, I mean it's not going to give us
very much information other than just uh
very much information other than just uh
policy gradient loss just
crashed. It is a multinnomial
crashed. It is a multinnomial
kernel. So I suspect that this is not
kernel. So I suspect that this is not
actually in
actually in
uh the policy gradient loss. It's
uh the policy gradient loss. It's
probably in the sample function unless
probably in the sample function unless
something else internally has
something else internally has
multinnomial.
I guess cross entropy probably
I guess cross entropy probably
internally has
internally has
it. This could also just be like a
it. This could also just be like a
pietorch versioning difference in like
pietorch versioning difference in like
what errors and what doesn't as
well. To be clear, we're not trying to
well. To be clear, we're not trying to
make it we're not trying to make it like
make it we're not trying to make it like
not fail runs because if you have bad
not fail runs because if you have bad
hypers of course the loss will explode.
hypers of course the loss will explode.
Um we just want it to not crash, right?
Um we just want it to not crash, right?
We want it to knock CUDA error
out. What this gives
out. What this gives
us? Yeah, this is just giving us on loss
us? Yeah, this is just giving us on loss
backwards. It's the same error
everywhere in either in nan or element
everywhere in either in nan or element
less than zero.
Which one was this? This is puffer grid.
Which one was this? This is puffer grid.
This one's going to be
This one's going to be
slow. This one will probably I can I
slow. This one will probably I can I
just run this on CPU and get like a
just run this on CPU and get like a
better error message.
Maybe I think that this should still run
Maybe I think that this should still run
at like a reasonable enough
pace.
Crazy. This is a thousand or 100x faster
Crazy. This is a thousand or 100x faster
than uh most academia even on
CPU. 250K. That's a quarter million step
CPU. 250K. That's a quarter million step
per second training with the CNN and
per second training with the CNN and
LSTM on
LSTM on
CPU. That's
ridiculous. Okay, so we'll see. I'm
ridiculous. Okay, so we'll see. I'm
going to just put this on the other
going to just put this on the other
monitor for a
monitor for a
bit and we will uh we'll see how that
does and then in the meanwhile
does and then in the meanwhile
here we will take a look at
uh not this we'll take a look at the
uh not this we'll take a look at the
code
code
itself and we will see if we can spot
itself and we will see if we can spot
anywhere where uh we've done a bad
anywhere where uh we've done a bad
multinnomial the only place I can think
multinnomial the only place I can think
of is in the sampling function
though. So I mean the only place we
though. So I mean the only place we
explicitly have a multinnomial that gets
explicitly have a multinnomial that gets
called is right here,
right? I guess I don't remember whether
right? I guess I don't remember whether
I added
Let's try to like get a setup that that
Let's try to like get a setup that that
uh reliably triggers this error on our
uh reliably triggers this error on our
local while we're running other stuff,
right? If I just set the learning rate
right? If I just set the learning rate
to something
to something
ridiculous, like what if I just set the
ridiculous, like what if I just set the
learning rate to like 10x higher, it
learning rate to like 10x higher, it
should instantly crash, right?
Okay. Interestingly, this
Okay. Interestingly, this
doesn't instantly
doesn't instantly
crash. It doesn't frame, but it doesn't
crash. It doesn't frame, but it doesn't
instantly crash.
What setting could there possibly have
What setting could there possibly have
been
then? That's
then? That's
bizarre.
Um, I could have like Huh.
Okay, let's
Okay, let's
try let's see if we can check hyper
try let's see if we can check hyper
prams from one of these like failed
prams from one of these like failed
runs. It like crashed on this,
runs. It like crashed on this,
right? So, we should just be able to
right? So, we should just be able to
look at like hypers for this
look at like hypers for this
maybe. We didn't even full sweep
hypers. Alpha
beta gradient
norm. I guess the giant batch
size
size
and 32k
and 32k
mini. Do we think that does it?
Is it
Is it
20 97? Whoops.
I do get a warning
here on policy
loss. This doesn't really tell me
loss. This doesn't really tell me
anything. And the losses look fine,
anything. And the losses look fine,
though.
Yeah, this also just trained
fine. I'm trying to think how we
fine. I'm trying to think how we
reliably trigger this
bug. Is it just make
um make training blow up somehow?
I guess we
like
like
here five max
here five max
crab.
crab.
See, that should blow up, right?
The fact I can't break this even if I
The fact I can't break this even if I
try is a little
ridiculous. It doesn't look like it's
ridiculous. It doesn't look like it's
logging KL.
It's not logging KL, is
It's not logging KL, is
it? Oh, it
is update. Epox
maybe. I can't think of what else.
I guess instead of doing this, I could
I guess instead of doing this, I could
like go set a few different things to
like go set a few different things to
infern and and see if I can break stuff
infern and and see if I can break stuff
that way.
So, I can't break it like
So, I can't break it like
this, which is surprising that it's that
this, which is surprising that it's that
stable.
Okay. So, this gives
me
me
mask. Where does it error?
probabil. Okay, so this gives me the
probabil. Okay, so this gives me the
same error
same error
here. And then if I do
train.device. Yeah. So there's
train.device. Yeah. So there's
multinnomial and then we
do probably do this as well, right?
Okay. Interestingly, we still have
Okay. Interestingly, we still have
this.
Try props.
This is supposed to be plus not
This is supposed to be plus not
times boolean
addition.
No. Okay. Okay. So now we get in sample
No. Okay. Okay. So now we get in sample
logits we get
errors. What is the correct way to do
errors. What is the correct way to do
this?
or did they do is this uh
I don't think this is
I don't think this is
enabled by default.
Wait, this is forward pass, right?
Logitative
problems.
Huh. It does seem like something is off
Huh. It does seem like something is off
here.
I I don't remember Torch ever doing
I I don't remember Torch ever doing
this. Like this feels like something
changed, right? You know, you used to
changed, right? You know, you used to
get like Nan loss or whatever.
Max
Max
logic. This doesn't
logic. This doesn't
work with nan.
Well, I guess technically the other
Well, I guess technically the other
thing we could try to do is we could try
thing we could try to do is we could try
to detect
to detect
this and we could try to end the run.
Maybe that seems bad.
N to
numb. Wait.
numb. Wait.
Nan pause
Nan pause
in. Okay. Wait. They have a thing for
in. Okay. Wait. They have a thing for
this.
replaces nan positive infinity and
replaces nan positive infinity and
negative
negative
infinity. Okay, that's
good. I didn't know that this function
good. I didn't know that this function
exist
exist
existed. So we have to do
existed. So we have to do
this only before action
sampling. I think other losses like KL
sampling. I think other losses like KL
should be fine, right?
Okay, so this is specific to prob
distributions nor uh okay distributions
distributions nor uh okay distributions
we handle
we handle
these cross entropy obviously uses it in
these cross entropy obviously uses it in
softmax
arithmetic obser
operations. Well, I guess we'll see
operations. Well, I guess we'll see
whether this is stable,
right? But yeah, let's start with uh
right? But yeah, let's start with uh
let's start with this for sure.
OBS
and pause in equals
none. So it's 0
none. So it's 0
0 like
this and then
this and then
[Music]
[Music]
multi. Yeah, this is the only
multi. Yeah, this is the only
multinnomial
multinnomial
here. So we do
What would you want logits to
be
be
props? What does logistics to props do?
to do
sigmoid. I think we want to do negative
sigmoid. I think we want to do negative
infinity, don't
we? And then this here is going to be a
we? And then this here is going to be a
little different. So,
nan, we'll see what this does.
contains. Okay, so this still
contains. Okay, so this still
somehow messes up.
I thought that you can put this into
I thought that you can put this into
logistics to props.
I thought you could put this into
I thought you could put this into
logistic props.
No. Oh, actually this is my fun. Is this
No. Oh, actually this is my fun. Is this
my
my
function? No, this is not portrait
function? No, this is not portrait
distribution.
Oh, it's just a soft
Oh, it's just a soft
max. Well, that's dumb. We don't need to
max. Well, that's dumb. We don't need to
have. We need to have this,
have. We need to have this,
right? We can totally replace
right? We can totally replace
this. And then what is it? Soft
max. Okay, I got to go do stuff for like
max. Okay, I got to go do stuff for like
10 minutes. I'll be back and uh we will
10 minutes. I'll be back and uh we will
continue fixing this. I'm going to leave
continue fixing this. I'm going to leave
stream on. I'm just going to mute the
stream on. I'm just going to mute the
mic. Don't let me forget to unmute it.
mic. Don't let me forget to unmute it.
Be back soon.
Okay, back
here.
here.
Let's fix this bug.
Is that a CrossFit gym with a desktop
Is that a CrossFit gym with a desktop
and 4090s in the back? Not
quite. This is the puffer training
quite. This is the puffer training
facility. It is where I train agents and
facility. It is where I train agents and
where I train myself.
where I train myself.
Uh, the equipment is not all here yet.
Uh, the equipment is not all here yet.
There's much much more coming. For now,
There's much much more coming. For now,
I just
I just
have I've got
have I've got
the the rack with the fun pull-up bars,
the the rack with the fun pull-up bars,
got the climbing rope, got the log for,
got the climbing rope, got the log for,
the bench, and then I've got the uh the
the bench, and then I've got the uh the
comp bench in the back. We're getting
comp bench in the back. We're getting
uh I think in a week or so, we're
uh I think in a week or so, we're
getting a bunch of new bars and some
getting a bunch of new bars and some
like nice accessory things. And then
like nice accessory things. And then
there are four commercial grade pieces
there are four commercial grade pieces
of equipment that'll show up in about a
of equipment that'll show up in about a
month. Plus, I got to get um I got a
month. Plus, I got to get um I got a
quote from a bunko for dumbbells. I got
quote from a bunko for dumbbells. I got
to get a full dumbbell set as
well. Now, the one desktop, that's a
well. Now, the one desktop, that's a
little trickier. We're going to get 40
little trickier. We're going to get 40
of those, but not until the tariffs come
of those, but not until the tariffs come
down because I'm not playing paying plus
down because I'm not playing paying plus
40% for
40% for
desktops. But yeah, then we will get 40
desktops. But yeah, then we will get 40
of them and then uh the majority of them
of them and then uh the majority of them
will be allocated to like all the open
will be allocated to like all the open
source stuff that Puffer does. So
source stuff that Puffer does. So
ideally we are able to provide compute
ideally we are able to provide compute
for a bunch of contributors, people who
for a bunch of contributors, people who
are interested in doing RL work with us.
are interested in doing RL work with us.
Uh all free all open
source. I mean we already do that now.
source. I mean we already do that now.
We have uh 10 of them total at the
We have uh 10 of them total at the
moment. Only one of them is here. The
moment. Only one of them is here. The
other ones are in Florida. But uh
yeah. Oh, and also that one in the back
yeah. Oh, and also that one in the back
is not 4090. That one's a 5090.
The
heck interesting way to spend seed
heck interesting way to spend seed
funding. There's no seed
funding. Buffer is bootstrapped.
The
The
um the gym equipment is not puffer
um the gym equipment is not puffer
stuff, right? That's just my personal
stuff, right? That's just my personal
stuff. Um the machines will be on uh
stuff. Um the machines will be on uh
puffer. Uh you know, we're doing pretty
puffer. Uh you know, we're doing pretty
well so far. Like we have revenue. Uh 40
well so far. Like we have revenue. Uh 40
bucks is a big ask. So some of that will
bucks is a big ask. So some of that will
also be from my personal um like I'm
also be from my personal um like I'm
going to be spons uh spotting some of
going to be spons uh spotting some of
that. But uh you know at the current
that. But uh you know at the current
rate we should be definitely more than
rate we should be definitely more than
breaking even on that this year.
breaking even on that this year.
So big expense but we're doing all right
So big expense but we're doing all right
with
it. I specifically did not want to get
it. I specifically did not want to get
seed funding so I don't have strings
seed funding so I don't have strings
attached to what I can do, right? Like
attached to what I can do, right? Like
I'm really big on all the open source
I'm really big on all the open source
work. I want to keep like you know as
work. I want to keep like you know as
soon as you start talking to VCs they
soon as you start talking to VCs they
say, "Oh yeah, open core. Yeah, it's
say, "Oh yeah, open core. Yeah, it's
good." It's like, yeah, open core. Like,
good." It's like, yeah, open core. Like,
they want you to make some
they want you to make some
non-opensource stuff separate. Like, no,
non-opensource stuff separate. Like, no,
it's all open source just there. There's
it's all open source just there. There's
what it is. And uh this is just a much
what it is. And uh this is just a much
better way to build things.
Apparently, you can't
Apparently, you can't
just I thought you could put negative
just I thought you could put negative
infinities into um into a soft
max. Oh, I guess you can't put all
max. Oh, I guess you can't put all
negative
negative
infinities into a soft max. Is that the
infinities into a soft max. Is that the
problem?
If we do like
If we do like
logets zero.
But we do like
zero
zero budgets to
props. Okay, so this
props. Okay, so this
actually that actually
actually that actually
works. So I guess you can't have all
works. So I guess you can't have all
names in there.
I guess multinnomial doesn't need
I guess multinnomial doesn't need
probabilities either though. What
probabilities either though. What
happens if you put zeros into
multinnomial sum of probability is less
multinnomial sum of probability is less
than equal
than equal
zero. So
um we just do this directly in prob
um we just do this directly in prob
space
maybe if we do
maybe if we do
like yeah here bot uh if we do this
like yeah here bot uh if we do this
directly in prob
space. Let me make sure I block the
space. Let me make sure I block the
right. Yeah good.
Torch.num nan to
Torch.num nan to
num probs 0 0
0 and um I guess what we'll do is
0 and um I guess what we'll do is
instead of doing zeros we'll do
instead of doing zeros we'll do
like 1 e minus 8 or
something let's see about
this cannot
access what I mess up
here.
here.
Okay. See if this is
stable. All right. So now this is
stable. All right. So now this is
correct. All the losses are nans here.
correct. All the losses are nans here.
Um but this is what we want. We wanted
Um but this is what we want. We wanted
it. So if you have nans it should not
it. So if you have nans it should not
crash.
Now, if I run this on
Now, if I run this on
CUDA, does it still not
CUDA, does it still not
crash? Perfect. So, I think that this
crash? Perfect. So, I think that this
should be good. I think we should be
should be good. I think we should be
good with
this. You see, I explicitly put this
this. You see, I explicitly put this
infant there.
infant there.
Let me make sure it's still
trans. Oh, we also want to do the same
trans. Oh, we also want to do the same
thing in um we want to add like an
thing in um we want to add like an
epsilon or something
epsilon or something
to the pyro maybe.
Yeah, we want to add uh to
pyro. There's this like normalization
pyro. There's this like normalization
operation,
right? Do max
score. So this is
like abs
like abs
+ 20 - 6 or thing.
Then this
is I think this is all of
them. This should be all of
them. All
right. So, uh, this one here actually
right. So, uh, this one here actually
hasn't crashed yet, though. Like, it's
hasn't crashed yet, though. Like, it's
running 10x slower, so it would take 10x
running 10x slower, so it would take 10x
longer to crash. Anyways, uh what we'll
longer to crash. Anyways, uh what we'll
do for
now pull the release
branch
train and we'll hope that this
train and we'll hope that this
actually Oh, yeah. I forgot I did a
actually Oh, yeah. I forgot I did a
whole bunch of refactoring at the same
whole bunch of refactoring at the same
time that I didn't account for.
else. Upper li
So, I just I moved a bunch of files
around.
Uh, you know, I was like waiting for
Uh, you know, I was like waiting for
these experiments to come back, so I
these experiments to come back, so I
just I did some refactoring and I broke
just I did some refactoring and I broke
some stuff.
Okay, so now it
Okay, so now it
works. I will uh wait for one experiment
works. I will uh wait for one experiment
before
before
I before I fully set up the new ones on
I before I fully set up the new ones on
this one as
this one as
well because we're going to do two boxes
well because we're going to do two boxes
worth of experiments.
This is not up to date. Oh, this is the
This is not up to date. Oh, this is the
same
tab. Same
tab. This is the other tab.
Okay. So, uh you can see the result of
Okay. So, uh you can see the result of
the latest refactor here. Deleted three.
the latest refactor here. Deleted three.
One, two, three, four, five, six, seven,
One, two, three, four, five, six, seven,
eight, nine. Nine files. added one file
eight, nine. Nine files. added one file
minus 500 lines. Good
minus 500 lines. Good
refactor. This seems to run stably
refactor. This seems to run stably
enough.
enough.
So, we will just go ahead and run our
experiment. And uh now we will have
experiment. And uh now we will have
breakout sweep and maze sweep both
breakout sweep and maze sweep both
running.
Just detach the
T-Moxes. Make sure I haven't missed any
T-Moxes. Make sure I haven't missed any
DMs. Set myself an alarm for
DMs. Set myself an alarm for
uh meeting later
today. Okay, cool.
Uh hopefully this is
Uh hopefully this is
fixed. We will see
fixed. We will see
shortly. Uh what we should expect to
shortly. Uh what we should expect to
happen
happen
here. So I have this set up in Neptune.
here. So I have this set up in Neptune.
A whole bunch of these
A whole bunch of these
runs. And see here we have three runs
runs. And see here we have three runs
that have just gone on this set. And
that have just gone on this set. And
then there's one run on this set so far.
then there's one run on this set so far.
If I just like click this tab
If I just like click this tab
here, I you know move some
things then we see this is the initial
things then we see this is the initial
run. The initial run is using the center
run. The initial run is using the center
point of the search distribution. So
point of the search distribution. So
it's meant to give you like a reasonable
it's meant to give you like a reasonable
starting point and then it's going to
starting point and then it's going to
take a while after that for to find uh
take a while after that for to find uh
to figure out some good parameters to
to figure out some good parameters to
sample. Uh actually there's some
sample. Uh actually there's some
corrections we can make I think to
corrections we can make I think to
sweeps as well. There's some things I
sweeps as well. There's some things I
want to try with this. Um, but then
want to try with this. Um, but then
yeah, we will have these running
yeah, we will have these running
throughout the day and we will see what
throughout the day and we will see what
else there is uh to work on for the
else there is uh to work on for the
release. I'm going
release. I'm going
to difference between Neptune and Wani.
to difference between Neptune and Wani.
Uh, so far I've been liking Neptune
Uh, so far I've been liking Neptune
more. I've been using it for the past
more. I've been using it for the past
few months. Puffer lip supports both. I
few months. Puffer lip supports both. I
really like how you can just define
really like how you can just define
dashboards with like different groups of
dashboards with like different groups of
plots and then you can apply this
plots and then you can apply this
dashboard view to any of the different
dashboard view to any of the different
groups of plots that you have here. Like
groups of plots that you have here. Like
it's really easy to make these nice
it's really easy to make these nice
views and to do my analysis. It's quite
views and to do my analysis. It's quite
nice. It's also more performant overall.
nice. It's also more performant overall.
All right, back into and just get a
All right, back into and just get a
little bit of exercise in here. what the
little bit of exercise in here. what the
equipment is for. And uh we will think
equipment is for. And uh we will think
about what we do what we do next.
All right.
So far so
So far so
good.
Now, there's one thing I want to look at
Now, there's one thing I want to look at
on the sweeps real
quick. Yeah. So this cost thing here I'm
quick. Yeah. So this cost thing here I'm
not appending
not appending
cost. So what's what's this actually
cost. So what's what's this actually
doing for cost time
steps simple
linear. Oh, so this is just not going to
linear. Oh, so this is just not going to
I
I
see. Yeah, this will totally mess up
see. Yeah, this will totally mess up
sweeps. It's a good thing I caught this
sweeps. It's a good thing I caught this
because the sweeps probably run stably
because the sweeps probably run stably
now. But
now. But
um yeah, this is not going to work well.
um yeah, this is not going to work well.
So the way that the uh the sweeps work,
So the way that the uh the sweeps work,
we take the trajectory. So we basically
we take the trajectory. So we basically
we take this plot that we that we see
we take this plot that we that we see
from training, right? And the way the
from training, right? And the way the
puffer sweep algo works, we cut this up.
puffer sweep algo works, we cut this up.
We like down sample it to 10 points
We like down sample it to 10 points
instead of however many points are on
instead of however many points are on
this graph. And then we pass those 10
this graph. And then we pass those 10
points to a learned model. So it maps
points to a learned model. So it maps
like this number of h this number of
like this number of h this number of
step training steps with these
step training steps with these
hyperparams to that level of
hyperparams to that level of
performance. Um so it's not getting all
performance. Um so it's not getting all
those numbers right now. So, I guess
those numbers right now. So, I guess
what we doing right now, we will fix
what we doing right now, we will fix
that. And then once we fix that, we'll
that. And then once we fix that, we'll
figure out what else to do on uh
figure out what else to do on uh
optimizing today. A whole bunch of
optimizing today. A whole bunch of
pre-release work to do.
I don't remember
I don't remember
why. I guess because the profile doesn't
why. I guess because the profile doesn't
have uptime anymore.
I can just do this for now, right?
Eval and
train like
this. We'll just do
this. We'll just do
cost.append that
Oh, there's also just Hang on. I can
Oh, there's also just Hang on. I can
just do
just do
uptime as part of the train run, which
uptime as part of the train run, which
would be better, right? I can just not
would be better, right? I can just not
even have this.
I can just do data that is it clean
I can just do data that is it clean
puffer
uptime. I think it's just puffer
here. Time minus start
here. Time minus start
time. It should be fine.
Let's add this to breakout and let's see
Let's add this to breakout and let's see
if it does anything different.
Okay, so this is what we were getting
Okay, so this is what we were getting
initially and we should actually see a
initially and we should actually see a
pretty big difference
pretty big difference
um because it's like it's very difficult
um because it's like it's very difficult
for it to learn well the the hyperparam
for it to learn well the the hyperparam
sweep can't really learn anything. It
sweep can't really learn anything. It
becomes closer to a random search uh
becomes closer to a random search uh
without that additional arg.
without that additional arg.
Let's just see how well it was
Let's just see how well it was
doing. We're still finding some
doing. We're still finding some
stuff. Uh but I think we should expect
stuff. Uh but I think we should expect
it to do substantially better than
it to do substantially better than
this. Yeah, we should expect
this. Yeah, we should expect
substantially better
substantially better
uh
results. Just making sure that I didn't
results. Just making sure that I didn't
break
it. Did I get the last point right?
Yes, I did. I did get the last point
right. All right. So, this is working
fine. This
fine. This
window, same thing.
and then this should actually give us
something 2.2 mil per
something 2.2 mil per
model. All right. So that should be
model. All right. So that should be
sweeps uh fixed and if not we will find
sweeps uh fixed and if not we will find
that out later when we get uh some
that out later when we get uh some
actual know some substantial results
actual know some substantial results
back from
this. Go back to the to-do
list. So the um kind of the name of the
list. So the um kind of the name of the
game for the next few weeks is going to
game for the next few weeks is going to
be prepare for release.
be prepare for release.
Um, so no really new big features going
Um, so no really new big features going
in at the moment. Just like trying to
in at the moment. Just like trying to
polish up everything that we have. Uh,
polish up everything that we have. Uh,
deliver some really nice baselines, make
deliver some really nice baselines, make
it really easy to use, do any last
it really easy to use, do any last
little performance
little performance
tweaks. That's kind of the
tweaks. That's kind of the
idea. My hope is that this block doesn't
idea. My hope is that this block doesn't
take too long and then, you know, we're
take too long and then, you know, we're
able to get this release out within the
able to get this release out within the
next couple of weeks. It's a lot of work
next couple of weeks. It's a lot of work
and it's a lot of quite boring work
and it's a lot of quite boring work
frankly as well. But um the idea is once
frankly as well. But um the idea is once
I finish this block so once we do this
I finish this block so once we do this
release which is going to be uh mostly
release which is going to be uh mostly
like
like
cleanup benchmarking
cleanup benchmarking
uh doing the packaging you know the
uh doing the packaging you know the
refactor and packaging and then writing
refactor and packaging and then writing
the blog post and stuff for release.
the blog post and stuff for release.
Once we get all that done and we have
Once we get all that done and we have
this out, then the next block for the
this out, then the next block for the
next uh probably like a month or
next uh probably like a month or
whatever is going to be some hardcore
whatever is going to be some hardcore
algorithm development. It's going to be
algorithm development. It's going to be
uh pretty much going back through
uh pretty much going back through
everything that DeepMind has done over
everything that DeepMind has done over
the last five years and trying to see
the last five years and trying to see
what they figured out and uh how we can
what they figured out and uh how we can
like leverage what works and toss what
like leverage what works and toss what
doesn't.
Okay.
Okay.
So, layer norm, we tried that. Let's
So, layer norm, we tried that. Let's
just go through everything. Why not? Uh,
just go through everything. Why not? Uh,
layer norm, we tried. It sometimes
layer norm, we tried. It sometimes
works, it sometimes doesn't. It's not a
works, it sometimes doesn't. It's not a
clear win. Value function batch
clear win. Value function batch
norm. Norm not over many. Yeah, we could
norm. Norm not over many. Yeah, we could
actually mess with a few small things
actually mess with a few small things
here.
here.
Okay, retune batch size. We're doing
Okay, retune batch size. We're doing
that
that
now. Basic model architecture scaling.
now. Basic model architecture scaling.
We did that. It works. Analing
We did that. It works. Analing
gamma. We didn't really mess with this
gamma. We didn't really mess with this
and we're not going to do that this
and we're not going to do that this
release. Harder algorithm stuff is going
release. Harder algorithm stuff is going
to be for next
to be for next
segment. Fix dumb end bindings. We
segment. Fix dumb end bindings. We
did transpose obs. We tried this. It
did transpose obs. We tried this. It
didn't. We didn't need to do it. We just
didn't. We didn't need to do it. We just
profile ordering. We did this. Compile
profile ordering. We did this. Compile
and AMP shenanigans. We did this really
and AMP shenanigans. We did this really
clean multi benchmarking. I need to make
clean multi benchmarking. I need to make
a script for that. Still all M's a
a script for that. Still all M's a
normalized score. We did
normalized score. We did
it. Run script to do all runs under one
it. Run script to do all runs under one
tag. Yeah, this is the same thing as
tag. Yeah, this is the same thing as
this. We'll do that. Mean cross scores.
this. We'll do that. Mean cross scores.
This will work as soon as that's done.
This will work as soon as that's done.
Uh, this needs ablations but is
Uh, this needs ablations but is
done. This needs ablations but is done.
done. This needs ablations but is done.
This is done.
Done. This is the same as this. We kind
Done. This is the same as this. We kind
of did everything
of did everything
else. We do need to run some tests on
else. We do need to run some tests on
distributed
training. We do need to get meta
running and preset does.
running and preset does.
Okay. And then the rest of this is
remove some some old files and
remove some some old files and
functions. Mostly done. I think there's
functions. Mostly done. I think there's
only maybe some stuff in PyTorch we can
only maybe some stuff in PyTorch we can
find, but I think we mostly got rid of
find, but I think we mostly got rid of
redundant stuff. We do have to go like
redundant stuff. We do have to go like
make Atari and all the other M's work.
make Atari and all the other M's work.
Merge small files into puffer lib. We
Merge small files into puffer lib. We
did lip range for continuous policy. So
did lip range for continuous policy. So
we found that out the other day. We have
we found that out the other day. We have
not done this yet.
not done this yet.
And then there's some notes to add.
And then there's some notes to add.
Cool. Oh, and I forgot to mention docs.
Cool. Oh, and I forgot to mention docs.
Yeah, we still need to do new docs for
Yeah, we still need to do new docs for
the new release as well. So, that's
the new release as well. So, that's
going to be a
pain. I think that the best thing we can
pain. I think that the best thing we can
do right now is to start getting some of
do right now is to start getting some of
the other M's working cuz uh you know, I
the other M's working cuz uh you know, I
probably broke some bindings and stuff
probably broke some bindings and stuff
with those and uh meta needs to still
with those and uh meta needs to still
work. That's a big end. And probably
work. That's a big end. And probably
later today, Spencer will be around and
later today, Spencer will be around and
uh Spencer will want to take a look at
uh Spencer will want to take a look at
GPU drive as well. Try to make that work
GPU drive as well. Try to make that work
for him. Got impulse wars from Captain.
for him. Got impulse wars from Captain.
I think that pretty much there two
I think that pretty much there two
things that we have other than like the
things that we have other than like the
final
final
experiments. The two things we have, we
experiments. The two things we have, we
need to clean up little bits of the
need to clean up little bits of the
training code here and there and then we
training code here and there and then we
need to get like good benchmarks on all
need to get like good benchmarks on all
the M's. Once train code is clean and we
the M's. Once train code is clean and we
have good benchmarks, I will be
have good benchmarks, I will be
comfortable running final experiments
comfortable running final experiments
and shipping. So those are the two
and shipping. So those are the two
things start with
meta. Let's see if we can get that to
work. Actually, let's just upgrade.
work. Actually, let's just upgrade.
Let's just like do the full upgrade on
Let's just like do the full upgrade on
this right now.
So, uh, this is one of the keys we're
So, uh, this is one of the keys we're
looking at
looking at
here. It's this like kind of
here. It's this like kind of
factorioesque. Not really. It's like the
factorioesque. Not really. It's like the
agents collect resources, then they put
agents collect resources, then they put
them into converters and get other
them into converters and get other
resources, so on and so forth.
I have to make their script
311. That
311. That
it. Oh yeah, they made this script a
it. Oh yeah, they made this script a
whole bunch simpler it looks
like. You must be in the metaconda m to
like. You must be in the metaconda m to
run this. God damn it. They made
run this. God damn it. They made
required.
Uh, that
sucks.
sucks.
Huh? Can I just like do these
Huh? Can I just like do these
independently?
Why is this installing torch
27? That's just going to break. Why? Why
27? That's just going to break. Why? Why
is it doing this?
is it doing this?
They have this like specified in
requirements. Oh, they have freaking
requirements. Oh, they have freaking
torch RL in here which then pins
Where do they actually set up
meta? Don't do it anywhere here.
Check out and Hold.
So they don't have meta in here at all,
So they don't have meta in here at all,
right?
Metagrid.sh. Okay. So this has
Metagrid.sh. Okay. So this has
separate I see. So they didn't actually
separate I see. So they didn't actually
move it into one package.
Yeah. So, they didn't actually fully
Yeah. So, they didn't actually fully
port this at
port this at
all. They just like put it into the
repo.
Um, tons of
Um, tons of
these. This doesn't have requirements
these. This doesn't have requirements
listed at all.
It seems that does something.
Let's see if this will build Syon for
us. We can just use this as
us. We can just use this as
is. Looks like we're going to have to
is. Looks like we're going to have to
rewrite this and see this. The thing is
rewrite this and see this. The thing is
this is kind of
this is kind of
already in uh Python and
C++. But yeah, absolutely. I could make
C++. But yeah, absolutely. I could make
this thing way faster and simpler.
We have a good collaboration with the uh
We have a good collaboration with the uh
the folks that make this. Um the one
the folks that make this. Um the one
tricky thing is just the way that we
tricky thing is just the way that we
tend to build stuff is very very
tend to build stuff is very very
different. They have like a very big
different. They have like a very big
step big tech style approach to doing
step big tech style approach to doing
things where like everything is highly
things where like everything is highly
modularized. Um and Puffer is the exact
modularized. Um and Puffer is the exact
opposite. We like really try to just
opposite. We like really try to just
like contain
like contain
everything like as much as possible to a
everything like as much as possible to a
few simple components which are even
few simple components which are even
intended to just read the source code
intended to just read the source code
of. They're not meant to be
abstracted. But we've basically what
abstracted. But we've basically what
we've done is we've done our best to
we've done is we've done our best to
like make these things cross-co
like make these things cross-co
compatible in a way that they can build
compatible in a way that they can build
in the way that they want to build and
in the way that they want to build and
we can build our stuff in the way that
we can build our stuff in the way that
we want to build and you know we can
we want to build and you know we can
still ship them useful things and then
still ship them useful things and then
you know we can still use their end in a
you know we can still use their end in a
way that's useful for testing.
I think we're going to have to do the
I think we're going to have to do the
new API port as well,
right? Uh, that is this one's on me. I
right? Uh, that is this one's on me. I
got to fix this.
Okay.
Okay.
So, right, I put numbum M's and num I
So, right, I put numbum M's and num I
put all this stuff into vec, not into
M upper
li. Yeah. So this goes into
vec. So I don't know why I did
that. Make end from Yeah. So now this is
that. Make end from Yeah. So now this is
where we have to do the
port make M from config. And I think
port make M from config. And I think
this is where we have to
this is where we have to
like see how they did it.
They should have some like scripts or
They should have some like scripts or
whatever.
I'm just going to check this on their
I'm just going to check this on their
web UI. There's like too much stuff to
web UI. There's like too much stuff to
even look
at. Is it
at. Is it
tools? I think it is
tools. So then they do
tools. So then they do
Omega
comp.load. I don't think that this is it
though. Set up meta
though. Set up meta
n set up
metag. Set up
metag. Set up
util runtime configuration.
set up metag of
set up metag of
config. So I think we can just
do. This doesn't return you an end.
Yeah, this doesn't even return to an
Yeah, this doesn't even return to an
end.
Where do they actually get the
end? They
end? They
don't. So they get
don't. So they get
train and then train is
train and then train is
this. So they do load the
config. They have their own policy
store
config.trainer. So I guess this somehow
Is it somehow in puffer like their
Is it somehow in puffer like their
puffer
code?
Yes. This takes a
config. So they have config from path
config. So they have config from path
here.
Where does the end like where do they
Where does the end like where do they
actually make the
end? Make
end. Wait, what?
Meta Sim back ends.
Oh, I guess it's literally they just
Oh, I guess it's literally they just
pass they just pass the config
pass they just pass the config
to the end,
to the end,
right? Okay. Okay. So then all I need to
right? Okay. Okay. So then all I need to
know is how they load it, which I think
know is how they load it, which I think
I saw already.
I think it is just
I think it is just
nomeg.load,
nomeg.load,
right? So I can I just do
right? So I can I just do
that? But can I just do like n equal or
that? But can I just do like n equal or
config equals
Just import Omega
comp. import
Omega. Okay. And then you load
Omega. Okay. And then you load
this. And then where is
this. And then where is
the end
the end
creation thing?
The end of creation
thing probably
this. So
it's from
it's from
Metagrid Metagrid N. import Metagrid
Metagrid Metagrid N. import Metagrid
N. This takes an N config.
Yeah, like
this. And does this take a
buffer? This does take buffer.
And then this should probably
And then this should probably
go after
this. I don't
this. I don't
know. We'll do this for now.
Metagrid M
init. Okay. So we do render
mode and this doesn't have seed yet.
Okay, this is a Python 311
Okay, this is a Python 311
issue. Um, I knew I was going to have to
issue. Um, I knew I was going to have to
fix this at some
point. So, for some reason, the Python
point. So, for some reason, the Python
devs decided that slice should not be
devs decided that slice should not be
hashable, and then they decided it
hashable, and then they decided it
should be hashable, and now it's like
should be hashable, and now it's like
there's a breaking change from 311 to
there's a breaking change from 311 to
312.
Um, we'll just use the
Start. This LSTM here
Okay. And
Okay. And
then
then
lib.utils. This is API stuff that we've
changed. Okay, so this does
run. Cool.
We'll just uh Neptune this
We'll just uh Neptune this
thing and we will see what this does out
thing and we will see what this does out
of the
box. See what this does out of the box
box. See what this does out of the box
in a few
in a few
minutes.
Meanwhile, maze looks like it
Meanwhile, maze looks like it
crashed. Yeah, these look like they
crashed. Yeah, these look like they
might have both
crashed. We did get some better results
though.
Interesting. Well, let's let's get
Interesting. Well, let's let's get
this Yeah, it's going to be a lot of
this Yeah, it's going to be a lot of
context switching today. Let's get this
context switching today. Let's get this
to run.
to run.
And then we'll have this window
up. Oh, maybe this is still
going because this just
launched. So, here's our run that we
launched. So, here's our run that we
have for the thing we just
have for the thing we just
launched. And let's go check. Let's go
launched. And let's go check. Let's go
check to see if either of these crashed.
This looks totally fine,
This looks totally fine,
right? Yep. So, breakout is still
right? Yep. So, breakout is still
going. And then
here. This one did
crash. Error while computing log
crash. Error while computing log
prop at site Y.
What on earth is this?
What on earth is this?
Pyro. It isn't
pyro. Okay. So then the only thing
pyro. Okay. So then the only thing
that's left here is it seems like it is
that's left here is it seems like it is
possible for
possible for
um uh the
um uh the
actual sweep itself to still error out.
We will double check
that. Where do we think we could get NS
that. Where do we think we could get NS
in here?
The score is not something that can be
The score is not something that can be
nanable because we don't use the loss
nanable because we don't use the loss
for the Four.
So somehow
So somehow
here uh something is not
here uh something is not
getting propagated correctly.
Oh, wait. Log C minus log C
Oh, wait. Log C minus log C
min. This could
be if this is
zero. Well, then we're just training
zero. Well, then we're just training
everything to map to zero, right?
and then 0 divided by 1 e 1 e minus
6 is
6 is
zero. I don't think that it's possible
zero. I don't think that it's possible
that you get um nans in the training
that you get um nans in the training
data, but I mean I guess
data, but I mean I guess
oops I forgot I had multiple
workspaces. What is this going to tell
workspaces. What is this going to tell
us here?
So GPUs train is where this
So GPUs train is where this
breaks
428 it breaks on this GP cost and cost
428 it breaks on this GP cost and cost
opt
GP cost is the
process. What's cost
opt? Oh, the
optimizer. So, it's just uh this data
optimizer. So, it's just uh this data
that's set from here.
It's a mapping from
params the log C
norm I can just do
like and do something like this.
And is this a um is this a CUDA
And is this a um is this a CUDA
error or can I catch
error or can I catch
this? I actually think we can catch this
this? I actually think we can catch this
because that's not a CUDA error, right?
because that's not a CUDA error, right?
That's like a validation
error. We do try
What line was
it? GP.util.train.
friend. Okay.
So, we redo this
So, we redo this
sweep. And now we should hopefully get a
sweep. And now we should hopefully get a
break point the next time it
break point the next time it
crashes because I think we got all of
crashes because I think we got all of
the nan bugs out of the main
the nan bugs out of the main
transcript. There's like one last
transcript. There's like one last
potential
potential
instability uh in the inputs to
instability uh in the inputs to
pyro and then hopefully we should have
pyro and then hopefully we should have
stable
stable
sweeps. Go check on this
sweeps. Go check on this
experiment. Okay. So, yeah, this is
experiment. Okay. So, yeah, this is
unfortunately this is on par with the
unfortunately this is on par with the
previous
previous
uh not so great train
uh not so great train
runs where they get stuck at 0.5.
Pyro is uh it's the Gaussian process
Pyro is uh it's the Gaussian process
optimizer that we're using. It's like
optimizer that we're using. It's like
um it's just like a torch extension
um it's just like a torch extension
library that has Gaussian processes and
library that has Gaussian processes and
stuff in it. So we will unfortunately
stuff in it. So we will unfortunately
have to add that as a depth unless we
have to add that as a depth unless we
want to implement our own Gaussian
want to implement our own Gaussian
processes which are really annoying to
processes which are really annoying to
implement.
Upper lib
Upper lib
environments meta
meta and this is the config we
meta and this is the config we
used. Let's just open it.
Another good
Another good
question was when I did this
question was when I did this
experiment, which actually I linked this
experiment, which actually I linked this
to Aaron yesterday, so I can go find
to Aaron yesterday, so I can go find
that
that
link. I did go link this to Aaron.
[Music]
This was the heart
That met ID.
This was
21st 3
21st 3
E06. It was this commit here.
in which I added some
hypers. We can double check these real
hypers. We can double check these real
quick, but I'm pretty sure these are the
same. Yep. So,
same. Yep. So,
like these are all the same, right?
Okay. The other thing I wasn't sure
Okay. The other thing I wasn't sure
about with this that I wanted to go
about with this that I wanted to go
double check
on is did we have the end file committed
on is did we have the end file committed
at this point?
We did have the Nap file committed, but
We did have the Nap file committed, but
I can actually verify here
I can actually verify here
uh that this is exactly what we trained
on with all these cool downs just as
on with all these cool downs just as
they were
before. Okay.
I wonder if it's possible that something
I wonder if it's possible that something
changed in their config
format. You think something could have
format. You think something could have
changed in their config format such that
changed in their config format such that
like now uh this is like no longer valid
like now uh this is like no longer valid
or
something? This is a totally different
something? This is a totally different
curve,
curve,
right? I want to check
right? I want to check
that. That could be the case.
This is this like taking tons of
memory. Just loading the GPU quite a
memory. Just loading the GPU quite a
bit.
this
buffer cuz this gets passed. This gets
buffer cuz this gets passed. This gets
passed in.
But this will just give us the drive
around. 16 players
at the
at the
data. Nothing there.
objects. Yeah. So, this just tells you
objects. Yeah. So, this just tells you
everything that's in the end, which is
everything that's in the end, which is
going to be a ton of stuff,
going to be a ton of stuff,
right? Oh, yeah. This is a massive
right? Oh, yeah. This is a massive
amount of stuff.
wrapper
wrapper
attribute. Where's the config get uh
attribute. Where's the config get uh
applied in here? I think I got to just
applied in here? I think I got to just
start reading
start reading
their their end code, right?
underscorem
config. Shouldn't this have an
underscore? Does have an underscorem
underscore? Does have an underscorem
config and it is the one that I
passed correctly.
Wait.
Wait.
Self.config equals
Self.config equals
get new end
get new end
config.
config.
Wait, this gets
Wait, this gets
passed and then it makes a template of
passed and then it makes a template of
this.
this.
Okay. And then it resolves this
Okay. And then it resolves this
config. Now this is the config that we
pass. We get the renderer working.
Okay, so here's the
end. Agents like walk around and do
stuff kind
of. They don't really move very much.
All these are red
All these are red
ores. These ones
still
going.
Uh trying to think how we debug this.
It's like what could have possibly
changed. Like it would have to be the
changed. Like it would have to be the
end, right? Because
It's got to be the
It's got to be the
end. Let me see. So, I like I remember
end. Let me see. So, I like I remember
it wasn't working. We got curves that
it wasn't working. We got curves that
looked like
looked like
this and then I pasted
this and then I pasted
in where is
it? Okay. So, I pasted in these new
it? Okay. So, I pasted in these new
params.
Not
these. Okay. So I pasted in these new
these. Okay. So I pasted in these new
params which was the new learning rate,
params which was the new learning rate,
gamma, lambda, all that. And then we had
gamma, lambda, all that. And then we had
it working very
well. I just pasted these in from like a
well. I just pasted these in from like a
quick sweep. I remember
m* 16, right? That was the idea. 16
m* 16, right? That was the idea. 16
workers
batch size 64.
batch size 64.
Yeah, this is a uh double buffered
Yeah, this is a uh double buffered
setup with a bunch of
setup with a bunch of
workers. Same
params. Didn't mess with the end config
params. Didn't mess with the end config
in any weird way.
trying to think if there's like is it
trying to think if there's like is it
possible I did
something the meta code
Let me
see. Reset enth.
see. Reset enth.
So they have this reset
m.reset. I should be fine just calling
m.reset. I should be fine just calling
reset here then.
Is this thing
seated? No, they don't use
seed. We could double check. We should
seed. We could double check. We should
double check. We're getting real
data. Pretty darn sure we did this
data. Pretty darn sure we did this
right.
Always possible I messed up
Always possible I messed up
though. So we go
though. So we go
here and we do mode
train. They're all zeros.
Okay. I mean, like, we see that there's
Okay. I mean, like, we see that there's
data in here, right? Like not a ton of
data in here, right? Like not a ton of
stuff, but like there is we've seen a
stuff, but like there is we've seen a
couple channels already that had stuff
couple channels already that had stuff
in
in
them. Yeah. So, I mean, there's data
And then we have our
And then we have our
encoder network is a small
CNN. I'll be
fine. And this is what we used
fine. And this is what we used
importantly as well.
I wonder if I messed up the action
I wonder if I messed up the action
decoding for
multidiscreet. That could do
it. I tried on old puffer li though too,
it. I tried on old puffer li though too,
didn't
didn't
I? Pretty darn sure I tried on old
I? Pretty darn sure I tried on old
puffer
li. Worth
li. Worth
checking. Do I have any other like
checking. Do I have any other like
multi-discrete
M's? Hang on. Actually, I do. Let me
M's? Hang on. Actually, I do. Let me
just test if I can learn one of those
just test if I can learn one of those
real quick. We should have like the
sanity
sanity
make we had
multi-discrete. I know we have a
multi-discrete. I know we have a
multi-discreet in here.
Oh, it's just called spaces.
Uh, I'm trying to figure out how do I
Uh, I'm trying to figure out how do I
reconnect
reconnect
these real quick
M. Oh, let's just
M. Oh, let's just
make faces.
unexpected keyword arg.
seed.
seed.
Holy. Well, this was what we wanted.
Uh, it does not instantly solve this.
and just make sure they're not all
bugged. Okay, so there is something
bugged. Okay, so there is something
wrong I think with spaces. I don't know
wrong I think with spaces. I don't know
whether it's the same bug or
not, but uh it's worth us looking
not, but uh it's worth us looking
oops into this decoder.
So this is the
multi-discretet. You know, it looks like
multi-discretet. You know, it looks like
I could have messed this up at all. like
I could have messed this up at all. like
quite a bit
here. Let me try something.
and just check how I did this in like
and just check how I did this in like
earlier
earlier
versions. I think
versions. I think
um this could definitely be it. I could
um this could definitely be it. I could
have just messed up multi-discrete
have just messed up multi-discrete
sampling.
That's the only other thing I could
That's the only other thing I could
think of that I touched that would like
think of that I touched that would like
specifically mess up meta and not
specifically mess up meta and not
anything
anything
else. I thought I was being pretty
else. I thought I was being pretty
careful with it, but maybe not.
So,
So,
interestingly, yeah, but this is the dev
interestingly, yeah, but this is the dev
branch. We need to go back
branch. We need to go back
farther to like
farther to like
before I did
before I did
this, like to here
maybe. Right.
Can I just like copy this whole
Can I just like copy this whole
function?
function?
Actually, I should be able
to. I don't know if I messed with
to. I don't know if I messed with
anything else that would matter in
anything else that would matter in
here. Entropy.
gets called unnormalized
gets called unnormalized
budgets budgets.
budgets budgets.
Okay, I think I can actually
Okay, I think I can actually
not mess with this so much and just
not mess with this so much and just
do
this this one.
We'll see if this produces anything
We'll see if this produces anything
different.
26 to
26 to
262 97. Right.
Yeah, right
there. Yes. This was the original
there. Yes. This was the original
one. Now this is the new one.
So this
So this
was we can see the two different we can
was we can see the two different we can
see this one lines up with this one. So
see this one lines up with this one. So
even if we go back to the
earlier the earlier action sampling it
earlier the earlier action sampling it
does not seem to make a difference.
Did I mess with any of the other
Did I mess with any of the other
functions in
here?
here?
Nope, that is
correct. This is identical.
correct. This is identical.
And I do not
And I do not
believe I did anything
else. Evidently, I did not just break
else. Evidently, I did not just break
sampling.
What else could it be
then? I know I didn't just break
then? I know I didn't just break
sampling.
Leave it for now as well just to be
sure. Let's kill
this. Thank
this. Thank
I've already also to be clear I've
I've already also to be clear I've
tested this exact branch as well. I'm
tested this exact branch as well. I'm
not just like
guessing. Adding the resets here. Added
guessing. Adding the resets here. Added
max
max
steps. These are all the changes I
steps. These are all the changes I
remember and these are all up to date.
Um, hang on. We have somebody here with
Um, hang on. We have somebody here with
delivery that I don't know who this is.
Apparently, we have an entire semi worth
Apparently, we have an entire semi worth
of lights uh that our electric guys
of lights uh that our electric guys
ordered for a different job to our
ordered for a different job to our
address.
for I
know
weird. What are we going to do about
weird. What are we going to do about
this freaking this run?
This isn't a case where I just like did
This isn't a case where I just like did
something and I don't remember what I
something and I don't remember what I
did. Like I know exactly what I
did. Like I know exactly what I
did. I think I'm doing the same thing
did. I think I'm doing the same thing
and it's not
and it's not
replicating. In fact, it's not just I
replicating. In fact, it's not just I
think I know what I did, right? I have
think I know what I did, right? I have
the get
the get
commits. I have the diff to the commit.
Exactly. The heck could have possibly
Exactly. The heck could have possibly
changed? And all the other M's work
changed? And all the other M's work
great as
well. Jiggle the hyperparameters around
well. Jiggle the hyperparameters around
a little bit, but
a little bit, but
like,
like,
right, I could also rerun a hyperparam
right, I could also rerun a hyperparam
sweep on this. That's a thing I could
sweep on this. That's a thing I could
do.
I mean realistically right this is
I mean realistically right this is
supposed to
supposed to
fix this is supposed to do well
within okay 1 E8 so 100 million steps
within okay 1 E8 so 100 million steps
you should be able to see a very
you should be able to see a very
substantial
I can rerun the
sweep. I'm not confident that's going to
sweep. I'm not confident that's going to
get us
get us
anywhere, but I can at least try that.
It's weird because we got the we got
It's weird because we got the we got
this curve with these
hyperparams. Same
model. No other
model. No other
diffs unless Hang on. Wait a second.
diffs unless Hang on. Wait a second.
Does this record This does record the
Does this record This does record the
entire diff,
right? Not just the diff to the
transcript. Wait. Ah, hang
on. I think it is just a diff to the
on. I think it is just a diff to the
train
train
screenshot. It should just It is just a
screenshot. It should just It is just a
diff to this one
diff to this one
file. Okay. Wait. that that changes
things. Yeah. And you can see the diff
things. Yeah. And you can see the diff
here just it's on the config file
only. Okay.
Let's do some like 100 milish runs,
Let's do some like 100 milish runs,
right? Just let's play with some
things. 100 mil run.
No energy steps.
if this does anything.
if this does anything.
I'm just gonna I don't want to spend all
I'm just gonna I don't want to spend all
day doing this, but you know, it's worth
day doing this, but you know, it's worth
playing with this a little bit just to
playing with this a little bit just to
make sure I didn't screw something
make sure I didn't screw something
up because I just realized if it's not
up because I just realized if it's not
recording the full
diff and uh there could be different
diff and uh there could be different
there could be differences.
This
This
here to
there. In the
there. In the
meantime, double check on some runs.
meantime, double check on some runs.
up for grid is still going just
fine and this this
one. Okay. So, there's like some rare
one. Okay. So, there's like some rare
instability in pyro, but other than
instability in pyro, but other than
that, we've kind of gotten our sweep
that, we've kind of gotten our sweep
stable as well, but we are in a decent
stable as well, but we are in a decent
spot. I would say
spot. I would say
overall in a decent spot.
overall in a decent spot.
We can see we actually
We can see we actually
have quite comprehensive sweep on
have quite comprehensive sweep on
breakout
breakout
here. Uh not seeing a bunch of good runs
here. Uh not seeing a bunch of good runs
though. We probably are going to want to
though. We probably are going to want to
mess with our sweep setup if this is all
mess with our sweep setup if this is all
we're getting out of
we're getting out of
it. Open
it. Open
dashboard sweep
dashboard sweep
progress. Yeah, not great on the sweeps.
progress. Yeah, not great on the sweeps.
So, we definitely screwed something up
So, we definitely screwed something up
with our sweeps.
It is possible. It's just like the
It is possible. It's just like the
normalization change I
made. So, this is not doing great. But
made. So, this is not doing great. But
if it's not sweeping breakout well, then
if it's not sweeping breakout well, then
we don't expect it to do particularly
we don't expect it to do particularly
well.
Okay, this ain't
This one.
our breakout sweep right.
our breakout sweep right.
This is breakout.
changes it having the max score in place
changes it having the max score in place
and if so then we can work off of
that. Leave that over there.
build. Okay, so this just doesn't run.
Maybe we can track some other stats from
Maybe we can track some other stats from
this and we can get like a hint from
this and we can get like a hint from
um from some of these stats,
eh? Cuz like this should have logged a
eh? Cuz like this should have logged a
whole bunch of
stuff. The episode length is a thousand.
Yes. No, we didn't log SPS or
Yes. No, we didn't log SPS or
anything. How is there so many metrics
anything. How is there so many metrics
here?
Let's look at them side by side.
Maybe we can find like a telling
stat. Okay. So, they don't like this
stat. Okay. So, they don't like this
attack
attack
nearest. It doesn't learn this quickly
nearest. It doesn't learn this quickly
at all.
Get
Get
output. Just learn super
output. Just learn super
quickly. Get output.
Interestingly, we learn to move around a
Interestingly, we learn to move around a
whole bunch.
I mean this is like going up cleanly.
But we just have like this very
But we just have like this very
slow. I mean, even from
slow. I mean, even from
like you can tell these apart like 20
like you can tell these apart like 20
million steps
million steps
in right here. This
in right here. This
is battery
is battery
gained. This should be learnable
gained. This should be learnable
immediately as well.
immediately as well.
It gets rewarded for
it.
Okay. It's funny because this it's not
Okay. It's funny because this it's not
getting rewarded for
this. So these this agent just says
this. So these this agent just says
screw that and this agent's like you
screw that and this agent's like you
know doing its own
thing. Would it make
thing. Would it make
sense? Hang
sense? Hang
on
two. It's not at 0.2. It's at like 0.4.
two. It's not at 0.2. It's at like 0.4.
But like
But like
still these are probably rare. It's kind
still these are probably rare. It's kind
of treating these like any other
of treating these like any other
resource,
right? But
or and then this heart here. It's also
or and then this heart here. It's also
not again like 50 mil steps. You can
not again like 50 mil steps. You can
tell it
tell it
apart for less.
Okay. So, this
Okay. So, this
is it's
is it's
treating it seems like it's not getting
treating it seems like it's not getting
the rewards is what it really seems like
the rewards is what it really seems like
to me.
We get red
ore. Ah, okay. Hang
ore. Ah, okay. Hang
on. So,
here or
here or
red.get. This is like not terribly far
red.get. This is like not terribly far
off,
off,
right? It's getting the ore
right? It's getting the ore
here. It's not learning to do anything
here. It's not learning to do anything
with
with
them. Yeah. It hasn't learned to like
them. Yeah. It hasn't learned to like
put
put
them
them
anywhere. But I mean, this would imply
anywhere. But I mean, this would imply
that it is getting the reward,
right? You think I changed the
right? You think I changed the
conversion time to zero?
mine
produce. Let me run that real
quick. And we already have one
quick. And we already have one
conversion
conversion
tick on
tick on
everything. And that was like that's the
everything. And that was like that's the
way it just was.
You know, we do actually know one other
You know, we do actually know one other
thing which is that I did I committed
thing which is that I did I committed
this
file. I actually did commit this
file. I actually did commit this
file with uh that PR that I marked.
file with uh that PR that I marked.
like it was actually quite well
organized as you can see
here
file. Yeah. So you can actually see here
uh that this was this was the state this
uh that this was this was the state this
file was in.
file was in.
So actually I am quite confident then
So actually I am quite confident then
that I didn't just mess with the end
config. In which case I can't think of
config. In which case I can't think of
really anything better to do than just
really anything better to do than just
run a sweep,
right?
Of course, our current sweep stuff is
Of course, our current sweep stuff is
messed
up. Isn't it in
healing that guy? Hey,
healing that guy? Hey,
Tyler. Yeah, I know. It's all right. He
Tyler. Yeah, I know. It's all right. He
uh he's mostly just a poster. He's like
uh he's mostly just a poster. He's like
I don't know maybe half the engineer
I don't know maybe half the engineer
that he is a poster. And thanks for the
that he is a poster. And thanks for the
free exposure. I
guess he didn't do it again. All right.
I know. I thought that was pretty funny.
I know. I thought that was pretty funny.
It's
It's
like you can poke a little bit of fun at
like you can poke a little bit of fun at
Google, right?
I mean, they were like, "Yeah,
I mean, they were like, "Yeah,
artificial uh puffer intelligence and
artificial uh puffer intelligence and
stuff in the comments." All
stuff in the comments." All
right, grab some
second. It's also pretty funny that I've
second. It's also pretty funny that I've
been in RL longer than this.
been in RL longer than this.
So, nice try, buddy.
Nice
try. Yeah, Tyler. The thing I'm trying
try. Yeah, Tyler. The thing I'm trying
to figure out right at the moment, there
to figure out right at the moment, there
are two things. One is I'm just fixing
are two things. One is I'm just fixing
hyper pram sweeps and like fixing some
hyper pram sweeps and like fixing some
stability issues in the latest build
stability issues in the latest build
that I'm pretty confident we'll be able
that I'm pretty confident we'll be able
to get to work.
to get to work.
The thing that's really weird at the
The thing that's really weird at the
moment
though, I can't get We are setting soda
though, I can't get We are setting soda
on every single M pretty much out of the
on every single M pretty much out of the
box except this one M that we set soda
box except this one M that we set soda
on like three weeks ago. We can't
on like three weeks ago. We can't
reproduce at
reproduce at
all. And it's a pretty important
all. And it's a pretty important
one. I have no idea why this one end is
one. I have no idea why this one end is
just not working the way it was expected
just not working the way it was expected
to.
It's meta. It's a third party M that's
It's meta. It's a third party M that's
built with the Puffer APIs.
Um, do I really trust this
Um, do I really trust this
gamma? I'm going to just do something
gamma? I'm going to just do something
dumb for the hell of
dumb for the hell of
it. One random thing just to check.
And then after that, I'll just ignore
And then after that, I'll just ignore
this. I'll go back
this. I'll go back
to the hyperparam sweep stuff or general
to the hyperparam sweep stuff or general
cleanup. Then when the hyperp stuff
cleanup. Then when the hyperp stuff
works correctly,
works correctly,
uh then we will just rerun on this and
uh then we will just rerun on this and
see. And if that doesn't work, it must
see. And if that doesn't work, it must
have been an M change because
have been an M change because
like it's just not a thing that happens
like it's just not a thing that happens
in Puffer, right? We don't lose
in Puffer, right? We don't lose
experiments.
I mean, it's like pretty
I mean, it's like pretty
instant that this thing learns. And it
instant that this thing learns. And it
should be
What order did I merge these
commits? Meta
working. Yeah. And then none of these
working. Yeah. And then none of these
are applicable here.
are applicable here.
Oh, I guess there is the April. If we go
here, there are a bunch of
here, there are a bunch of
changes. This one
especially, we might just have to retune
So, this actually is like pretty close
So, this actually is like pretty close
to this one as well. It's suspicious
to this one as well. It's suspicious
that I can't find anything that's
that I can't find anything that's
like everything kind of matches this.
like everything kind of matches this.
Nothing like gets even 6 or
Nothing like gets even 6 or
anything. It's kind of weird. It's like
anything. It's kind of weird. It's like
it everything is screaming that this is
it everything is screaming that this is
an Mside change.
Is this trajectory
Is this trajectory
related? What is
related? What is
um 26
um 26
[Music]
[Music]
over
128 128 horizon
128 128 horizon
length be
length be
fine.
Wait, that's not that many.
Wait, that's not that many.
That's not that many
M's. Honestly, don't know what I'm
M's. Honestly, don't know what I'm
looking at, but keep it
looking at, but keep it
up. Thanks. I This is currently
up. Thanks. I This is currently
debugging like a fiddly some fiddly RL
debugging like a fiddly some fiddly RL
experiments. Um, pretty much like we set
experiments. Um, pretty much like we set
a whole bunch of really good results a
a whole bunch of really good results a
couple of weeks ago and then I left for
couple of weeks ago and then I left for
a week and I came back and we reproduced
a week and I came back and we reproduced
all the results perfectly except for
all the results perfectly except for
one. I'm trying to figure out what
one. I'm trying to figure out what
happened to this like one experiment.
happened to this like one experiment.
Um, and usually I'm pretty good at like
Um, and usually I'm pretty good at like
tracking or tracking our changes, making
tracking or tracking our changes, making
sure we don't lose stuff. So, it's a
sure we don't lose stuff. So, it's a
really weird a really weird case.
I don't even know why I'm spending so
I don't even know why I'm spending so
much time thinking about this when it's
much time thinking about this when it's
like I know I didn't modify the
like I know I didn't modify the
environment file,
right? I know I ran
right? I know I ran
experiments on the same thing.
experiments on the same thing.
with the exact same
commit of puffer
lib. Those two things don't make sense
lib. Those two things don't make sense
together, right?
Maybe I shouldn't be
Maybe I shouldn't be
too suspicious of this flat curve
too suspicious of this flat curve
either. I do seem to remember it being
either. I do seem to remember it being
very difficult to get it to go above 0.5
very difficult to get it to go above 0.5
until I set the new hyperparams.
Would totally make sense though if I
Would totally make sense though if I
change something
change something
else at the same
time. Pretty well remember what I did
time. Pretty well remember what I did
though that day and I didn't do anything
though that day and I didn't do anything
else.
At least I didn't do anything else in
At least I didn't do anything else in
the end
configuration. Possible I had like some
configuration. Possible I had like some
local changes to
local changes to
Metagrid. Had some like local changes to
Metagrid. Had some like local changes to
the environment
the environment
file. The only thing I remember doing
file. The only thing I remember doing
there though was
there though was
um resetting the ends. Making sure I
um resetting the ends. Making sure I
reset the ends. Doing that correctly now
reset the ends. Doing that correctly now
as well.
like truly
bizarre. I also don't know how it is
bizarre. I also don't know how it is
that my
that my
uh breakout sweep suddenly doesn't work.
Oh, that's definitely a bug,
right? That's definitely got to be a
right? That's definitely got to be a
bug. Okay, I'm going to let this do the
bug. Okay, I'm going to let this do the
do its thing. I'm going to grab a drink
do its thing. I'm going to grab a drink
and then we'll just we'll ignore this
and then we'll just we'll ignore this
for now and we'll just fix sweeps
for now and we'll just fix sweeps
because maybe in fixing sweeps we just
because maybe in fixing sweeps we just
rerun the sweep and we get RAMs that
work. You see it literally starts off
work. You see it literally starts off
wrong. You see
wrong. You see
that? Literally the first point starts
that? Literally the first point starts
off
off
wrong. Doesn't that imply it has to be
wrong. Doesn't that imply it has to be
end
config? It almost has to be, right?
Unless it's just like it learned so much
Unless it's just like it learned so much
in the first
update, but no, right? Because you
update, but no, right? Because you
collect all the
data. No, this is literally has to be
data. No, this is literally has to be
end config.
end config.
Unless it could just take a few updates,
Unless it could just take a few updates,
I guess. You
I guess. You
know, I already reran the I already
know, I already reran the I already
reran the commit is the thing. Hey,
reran the commit is the thing. Hey,
Plasma. I'm doing okay. I'm still just
Plasma. I'm doing okay. I'm still just
like trying to reproduce this
like trying to reproduce this
experiment, which is weird.
I was so careful to not change the
I was so careful to not change the
environment, but
environment, but
like this gap here, it like it almost
like this gap here, it like it almost
has to
has to
be environment changed if it's like
be environment changed if it's like
literally the first point recorded. I
literally the first point recorded. I
mean, technically this is already 14
mean, technically this is already 14
million steps
in. Like that's a few batches, but
still. H. Okay, here's what we're going
still. H. Okay, here's what we're going
to do. This is going to drive me crazy
to do. This is going to drive me crazy
if I just spend all day doing this. And
if I just spend all day doing this. And
uh unlikely we're going to get anywhere
uh unlikely we're going to get anywhere
with just me staring at it.
with just me staring at it.
Um and grab a drink, do a set or two
Um and grab a drink, do a set or two
real
real
quick, clear my head,
quick, clear my head,
and then we will see if I can fix the
and then we will see if I can fix the
hyper pram sweep stuff that I actually
hyper pram sweep stuff that I actually
have some idea of what I might have
have some idea of what I might have
broken that I know should work very
broken that I know should work very
well. And I know like I have a better
well. And I know like I have a better
idea of what can be uh of what stuff I
idea of what can be uh of what stuff I
changed there and what like we can fix.
changed there and what like we can fix.
We fix hyperparam sweeps. Um we can at
We fix hyperparam sweeps. Um we can at
least rerun all the other experiments
least rerun all the other experiments
except this end. Come back to this and
except this end. Come back to this and
we'll go from there. Be right back.
pink and green as a result. Yeah, the
pink and green as a result. Yeah, the
green is the uh the pink is the original
green is the uh the pink is the original
one and then we can't get anywhere close
one and then we can't get anywhere close
to it. It's very
to it. It's very
weird. It's very very weird.
Okay, let's go do stuff on sweeps.
All right
here and not in
report.
report.
Interesting. Oh, cuz it's
Interesting. Oh, cuz it's
311 there.
So, we should be
So, we should be
getting 10 observations back here.
There's nothing in total time steps.
These
These
hypers look totally wrong.
Okay. So, these are the
Okay. So, these are the
correct these are the correct ones.
So we have here is the observe.
Right? It shouldn't it just be
Okay, we do have total time steps here.
Okay, we do have total time steps here.
So this is 1.5 million steps. So this is
So this is 1.5 million steps. So this is
like a very
like a very
early first point it looks
like. Score is zero.
like. Score is zero.
cost is like nothing, right? So, we just
cost is like nothing, right? So, we just
do or cost. We'll do like this.
do or cost. We'll do like this.
Continue. Now, the next
Continue. Now, the next
one is at 11
million, which is 17 score and 7 seconds
million, which is 17 score and 7 seconds
into
into
training. 20 mil
Okay. So, we can see that we're actually
Okay. So, we can see that we're actually
observing
observing
correctly the various different
correctly the various different
um
points. Now, this should be the last
points. Now, this should be the last
point here. And this is on
point here. And this is on
eval. This total time step should be
wrong. Yeah, because this is only for
wrong. Yeah, because this is only for
eval. So, we'll fix this real
quick. Some improvement
Let's
Let's
see. So,
um,
timesteps.append global step
We should just put this up top,
right? That will get us to 80 mil or
right? That will get us to 80 mil or
whatever. That's not the bug, though.
whatever. That's not the bug, though.
That's not the thing that's breaking
That's not the thing that's breaking
everything. Tell you that for sure.
We go
again. So this will run.
again. So this will run.
And uh we will see whether we observe
And uh we will see whether we observe
the correct step.
suggestion index.
50 random
samples. We have 10 success
observations. So this is going to give
observations. So this is going to give
us a random suggestion.
Random. Choice.
The goal is just going to be to see how
The goal is just going to be to see how
all the data is getting
all the data is getting
normalized and uh why the predictions
normalized and uh why the predictions
don't make any sense cuz like looking at
don't make any sense cuz like looking at
this graph right from over where is
this graph right from over where is
it? But like you get a couple of
it? But like you get a couple of
reasonable random suggestions and then
reasonable random suggestions and then
it just doesn't do
it just doesn't do
anything. Like for some reason it's
anything. Like for some reason it's
pushing cost all the way to the bottom
pushing cost all the way to the bottom
or whatever.
So here are our
parameters. Expect these to be
parameters. Expect these to be
reasonable.
Here's our
Here's our
Y. Does it look good? Right.
Min score is
Min score is
zero. That's
fine. Max score.
fine. Max score.
Whoa.
What? Well, this is completely
What? Well, this is completely
wrong right here. This is
wrong. I don't know why I would do this
wrong. I don't know why I would do this
abs thing like
abs thing like
this. It should
be
be
this. Okay.
Take abs of max score minus min
score. That could totally be it right
score. That could totally be it right
there if I'm not setting max scores.
there if I'm not setting max scores.
Right.
I want to keep going a little bit here
though. Okay. So, like this is half
though. Okay. So, like this is half
offish, right? But it's bad. It's like
offish, right? But it's bad. It's like
not
awful. And then the cost I
guess. Okay. So, let's get the
costs. Apparently, that didn't work, but
costs. Apparently, that didn't work, but
whatever.
We will try again with the our new found
We will try again with the our new found
fixes. This
Okay. So now we have reasonable mins and
maxes. Nicely normed 0 to one, right?
We've got reasonable cost
observations. Now we have reasonable log
observations. Now we have reasonable log
cost observations, right?
cost goes into log
cost goes into log
space. I actually don't know why we put
space. I actually don't know why we put
cost in log space to be fair,
cost in log space to be fair,
right? We've played with it a few
right? We've played with it a few
different
ways. Well, we'll leave this as is for
ways. Well, we'll leave this as is for
now.
These are both
reasonable. Okay, here's your norm. 0 to
reasonable. Okay, here's your norm. 0 to
one. Quite clean.
You train your
GPC. Okay, so now we get our PTO points.
There quite a few of
them. Pretty much all of them, right?
them. Pretty much all of them, right?
Yeah, literally all of them. It should
Yeah, literally all of them. It should
be if we have a good initial
be if we have a good initial
curve. Then we sample some
suggestions. suggestions, shape, whole
suggestions. suggestions, shape, whole
bunch of suggestions,
bunch of suggestions,
right?
right?
We we score
them in this latent space, right?
Then we have GPY
Then we have GPY
norm log C
norm
norm
GPY. What do we do? It's times max score
GPY. What do we do? It's times max score
minus min
score. You actually don't need this uh
score. You actually don't need this uh
this abs at
all. The worst case is zero
all. The worst case is zero
here.
here.
Right. I don't think you need this abs.
The worst case should be
zero. So now they're getting multiplied
zero. So now they're getting multiplied
by max minus
by max minus
min and then add to min.
Yeah. Then we have log
Yeah. Then we have log
c it's x.
c it's x.
You have to see get a min and a
You have to see get a min and a
max.
See?
See?
Okay. And you have your parto
Okay. And you have your parto
y parto indices.
Okay, got your
Okay, got your
PTO. Was it log C
norm? Uh, I don't think this
norm? Uh, I don't think this
C. Wait, do we still use this like C
C. Wait, do we still use this like C
right thing?
This doesn't get
used. Yeah. So, let's not confuse
used. Yeah. So, let's not confuse
ourselves
here because none of these get used
here because none of these get used
anymore, right?
anymore, right?
Now, this doesn't get
Now, this doesn't get
used. This does get used.
Hang on. What are we doing
here? This is not what I
here? This is not what I
remember, but maybe I'm reading my own
remember, but maybe I'm reading my own
stuff wrong. Hang on.
So,
So,
target equals
target equals
GPC
norm. Oh, look. This this just gets
norm. Oh, look. This this just gets
deleted here. You see
deleted here. You see
this? Yeah. This all just goes away.
this? Yeah. This all just goes away.
It's right here. Yeah. This is what I
remember. So, it's just
remember. So, it's just
1.25 times a
1.25 times a
random. It's multiplied by a
random. It's multiplied by a
weight. This GPY
weight. This GPY
norm, you got to make sure GPY norm is
norm, you got to make sure GPY norm is
right. Is right here.
right. Is right here.
times the
weight. Then it's an
argmax. Let's commit this and then see
argmax. Let's commit this and then see
if this does anything different.
of
This All
right. See,
uh, let's see how this changes
uh, let's see how this changes
it. So, we had
Okay, this actually this breakout sweep
Okay, this actually this breakout sweep
was starting to do kind of
was starting to do kind of
something. Let's see now with the fixes
something. Let's see now with the fixes
if we actually get something reasonable
if we actually get something reasonable
out of
out of
it. Let me read that in a second.
Tyler, let me at least get this run
Tyler, let me at least get this run
started so we can have this
started so we can have this
going. Check your thing.
Romy. Okay. So, yeah, let me let me help
Romy. Okay. So, yeah, let me let me help
you with
you with
that. The Romy show drone
that. The Romy show drone
ideas for our natural
gas survey.
I'm trying to think if you actually
I'm trying to think if you actually
really need a
coordinated much of anything for
it. And the no military is always a fun
it. And the no military is always a fun
thing.
Um, surveying.
What kind of pro? Well, all of them
What kind of pro? Well, all of them
honestly in like drones like the whole
honestly in like drones like the whole
RL is super human at drone piloting for
RL is super human at drone piloting for
the first part. Uh if you get it right,
the first part. Uh if you get it right,
it's also super human at
it's also super human at
coordination. the
coordination. the
like so like some communication stuff
like so like some communication stuff
would
would
be useful in like a variety of
be useful in like a variety of
applications. The really like heavily
applications. The really like heavily
like swarm-based stuff is probably
like swarm-based stuff is probably
military stuff. Um but I mean the tech
military stuff. Um but I mean the tech
goes way farther than that. Like if you
goes way farther than that. Like if you
want to get into something that is like
want to get into something that is like
defense but not military for instance,
defense but not military for instance,
right? Um, you can purely have these
right? Um, you can purely have these
things for like surveying an existing
things for like surveying an existing
premise and like covering an
premise and like covering an
area. That's like security, even private
area. That's like security, even private
security
security
there. That's like a pretty reasonable
thing. I think generally you want to
thing. I think generally you want to
have these things be able to
have these things be able to
like you want to have these things be
like you want to have these things be
able to make reasonable decisions based
able to make reasonable decisions based
off of either shared information or like
off of either shared information or like
local or responsive to one another
local or responsive to one another
depending
depending
um I guess like the spread out and do X
um I guess like the spread out and do X
is a good application. So
like there is probably stuff in
like there is probably stuff in
agriculture with that to be fair.
agriculture with that to be fair.
Although I don't know if it's effective
Although I don't know if it's effective
like powering them and having like all
like powering them and having like all
that stuff versus just like having
that stuff versus just like having
something on the
ground. Let me think of like what would
ground. Let me think of like what would
get somebody excited that's not military
get somebody excited that's not military
drone stuff.
We'll think
quick. Well, I mean, is she interested
quick. Well, I mean, is she interested
in science generally because it's like
in science generally because it's like
an excellent
an excellent
uh it's an excellent problem for
uh it's an excellent problem for
studying like
studying like
decentralized uh like decentralized
decentralized uh like decentralized
aggregate behavior and the like,
aggregate behavior and the like,
right? I mean, it's like the problem
right? I mean, it's like the problem
that you would go to in the real world
that you would go to in the real world
for like relatively efficient,
for like relatively efficient,
relatively doable coordinated behavior.
relatively doable coordinated behavior.
I mean that's like fundamental to our
I mean that's like fundamental to our
understanding
understanding
of everything from ants to how companies
of everything from ants to how companies
are run,
right? So in a sense it's just like it's
right? So in a sense it's just like it's
a very good science problem in some
a very good science problem in some
sense, right? That also will get enough
sense, right? That also will get enough
people in industry interested that it's
people in industry interested that it's
like actually viable to scale research
like actually viable to scale research
on it. And yeah, obviously there's like
on it. And yeah, obviously there's like
some stuff that's military there.
some stuff that's military there.
There's stuff that's like security
There's stuff that's like security
adjacent, but I mean broader than that,
adjacent, but I mean broader than that,
like the same tech goes on everything,
like the same tech goes on everything,
right? So like the things that you came
right? So like the things that you came
up with are possibly reasonable. Um even
up with are possibly reasonable. Um even
if you don't apply the exact same stuff
if you don't apply the exact same stuff
to a drone form factor, you can apply
to a drone form factor, you can apply
the same algorithm to like a ground unit
the same algorithm to like a ground unit
for removing weeds if you wanted to do
for removing weeds if you wanted to do
that. Maybe that's more reasonable. Like
that. Maybe that's more reasonable. Like
the algorithm side is going to be very
the algorithm side is going to be very
very similar. It's just that if you're
very similar. It's just that if you're
trying to pick a problem to get a large
trying to pick a problem to get a large
number of people interested, um, drones
number of people interested, um, drones
are just a very flashy one that's very
are just a very flashy one that's very
good at that. And technically, it's very
good at that. And technically, it's very
similar to many other things that you
similar to many other things that you
could look
could look
at. That's kind of the way I would look
at. That's kind of the way I would look
at it, right? Because I do a lot of
at it, right? Because I do a lot of
general RL tech and then every so often
general RL tech and then every so often
I look for problems where it's like,
I look for problems where it's like,
okay, this is an area where a lot of
okay, this is an area where a lot of
people will get excited if we kind of
people will get excited if we kind of
demonstrated our tech on this. There
demonstrated our tech on this. There
probably a lot of downstream
probably a lot of downstream
applications. There always going to be
applications. There always going to be
some that are military and some that
some that are military and some that
aren't, right?
aren't, right?
But I think that this is just generally
But I think that this is just generally
an area where uh if you can get RL
an area where uh if you can get RL
working on it very well, you will get a
working on it very well, you will get a
lot of people excited. You'll power a
lot of people excited. You'll power a
lot of like fundamental advancements in
lot of like fundamental advancements in
RL and in our understanding of aggregate
RL and in our understanding of aggregate
intelligence in general or collective
intelligence in general or collective
intelligence in general. And you'll push
intelligence in general. And you'll push
a lot of things quite far
a lot of things quite far
forward. And it's actually a problem
forward. And it's actually a problem
where I think it's like relatively
where I think it's like relatively
reasonable to do that because like it's
reasonable to do that because like it's
the air. They have to not collide with
the air. They have to not collide with
each other and that's about it.
So you'll probably just even if you
So you'll probably just even if you
don't like you will probably get some
don't like you will probably get some
really fascinating aerial displays out
really fascinating aerial displays out
of it, right? You'll probably get some
of it, right? You'll probably get some
really fascinating aerial
displays. Like if you can just control a
displays. Like if you can just control a
whole bunch of them and say, "Hey, all
whole bunch of them and say, "Hey, all
of you go do this. All of you go do
of you go do this. All of you go do
that." And do it like in a way that
that." And do it like in a way that
makes sense without crashing into each
makes sense without crashing into each
other and stuff like that will already
other and stuff like that will already
be and there's really not much like
be and there's really not much like
that. They show her where like M agent
that. They show her where like M agent
for instance like it's on David Ha's
for instance like it's on David Ha's
website. So like M agent or
Boyds, where's
this? If you look at even just like
this? If you look at even just like
basic stuff like
basic stuff like
this, right? Imagine doing this in like
this, right? Imagine doing this in like
actual 3D with drones or like even like
actual 3D with drones or like even like
voids.
right there. Like all these flocking
right there. Like all these flocking
type sims and
things. This is all these are all like
things. This is all these are all like
models of coordinated
behavior. There you go.
All
right. Have we run any
right. Have we run any
experiments in the
experiments in the
meantime or did they
fail? They failed. Yay.
or cost rating.
Welcome YouTube folks.
Welcome YouTube folks.
We're currently working on getting our
We're currently working on getting our
hyperprem stuff uh sweeps back working
hyperprem stuff uh sweeps back working
so we can run some large scale
so we can run some large scale
uh like few hundred order few hundred
uh like few hundred order few hundred
run hyperp sweeps over all our new
run hyperp sweeps over all our new
environments and see how well our our
environments and see how well our our
new algorithm can
new algorithm can
do on all of the environments because
do on all of the environments because
like right now we're pretty much solving
like right now we're pretty much solving
everything out of the box uh without
everything out of the box uh without
even having retune stuff. So, I imagine
even having retune stuff. So, I imagine
that we can do quite a bit better even
that we can do quite a bit better even
than we're doing
than we're doing
now, which should set us up
now, which should set us up
for a a very solid
for a a very solid
release. I'm particularly interested to
release. I'm particularly interested to
see like neural MMO is kind of an
see like neural MMO is kind of an
expensive M, so we don't retune hyper
expensive M, so we don't retune hyper
prams all that often. And like this is
prams all that often. And like this is
kind of just what we've gotten out
kind of just what we've gotten out
of mostly scaling up the network a
of mostly scaling up the network a
little bit, but also just little tweaks
little bit, but also just little tweaks
I've made here and there to it. Um, so
I've made here and there to it. Um, so
I'm interested to see with a really
I'm interested to see with a really
optimized hypers how well we can do this
optimized hypers how well we can do this
thing. This is an old
thing. This is an old
website. Yeah, I mean there are a bunch
website. Yeah, I mean there are a bunch
of implementations of it. Um, uh, Plasma
of implementations of it. Um, uh, Plasma
in the Discord is actually doing a voids
in the Discord is actually doing a voids
environment for Puffer right now.
So actually, do we even have Hang on.
Uh we don't have voids on this one, but
Uh we don't have voids on this one, but
yeah, he showed us uh he we've got like
yeah, he showed us uh he we've got like
a little interesting voids type sim that
a little interesting voids type sim that
he's been working on for Popper. Have
he's been working on for Popper. Have
that merged in soon
that merged in soon
hopefully. And Spencer is also
hopefully. And Spencer is also
interested in drones. Well, there are a
interested in drones. Well, there are a
lot of people interested in the
space. Oops.
Oh, one of the uh pieces of gym
Oh, one of the uh pieces of gym
equipment I'm waiting for shipped. The
equipment I'm waiting for shipped. The
one I'm really looking forward
to. Going to be fun.
It's got my quote for some dumbbells as
well. Very fun.
But probably uh sometime in the next few
But probably uh sometime in the next few
days I will have to get up and go take
days I will have to get up and go take
freight
delivery. All right, this is now
delivery. All right, this is now
running. We will see whether this is
running. We will see whether this is
stable or not.
Um, so the first five
Um, so the first five
runs
runs
are well the first run is like going to
are well the first run is like going to
always be good and then the next few are
always be good and then the next few are
randomly sampled and then after that the
randomly sampled and then after that the
algorithm takes
over. So now the algorithm is suggesting
over. So now the algorithm is suggesting
stuff that's like 20 mil. I don't know
stuff that's like 20 mil. I don't know
why it's suggesting such short runs.
why it's suggesting such short runs.
That will be the next thing uh for us to
That will be the next thing uh for us to
look at.
Nice shipping.
Okay. Yeah. So, it's doing something. It
Okay. Yeah. So, it's doing something. It
should not be doing this where it's like
should not be doing this where it's like
pushing
pushing
uh the cost all the way to the bottom.
I'm going to give it a few more runs to
I'm going to give it a few more runs to
see if it keeps doing this. And then I'm
see if it keeps doing this. And then I'm
going to what we'll do is we'll like
going to what we'll do is we'll like
we'll boot up an individual run and
we'll boot up an individual run and
we'll see if we can figure out why. In
we'll see if we can figure out why. In
fact, why don't we just do that on our
fact, why don't we just do that on our
local while it's doing
that. I like this is something that I
that. I like this is something that I
actually I worked very hard to make sure
actually I worked very hard to make sure
that this algorithm doesn't do. So, this
that this algorithm doesn't do. So, this
must just be like some weird bug in
must just be like some weird bug in
something I did
something I did
recently. A lot of these algorithms,
recently. A lot of these algorithms,
they'll kind of just give up and they'll
they'll kind of just give up and they'll
be like, I can't figure out how to make
be like, I can't figure out how to make
the long experiments work anymore, so
the long experiments work anymore, so
I'll just run cheap
experiments. That's quite silly,
experiments. That's quite silly,
actually. I know that this divide
actually. I know that this divide
parameter is not used. We don't have to
parameter is not used. We don't have to
worry about
that. Oh, and here actually this LF
that. Oh, and here actually this LF
false. Oh, I committed this. So,
false. Oh, I committed this. So,
actually then the first few runs were
actually then the first few runs were
fine,
fine,
right? The first few runs were fine and
right? The first few runs were fine and
then it started doing this.
H, we'll start uh we'll start from here
H, we'll start uh we'll start from here
and we'll see what this uh what this
does. Yeah. You see all these runs being
does. Yeah. You see all these runs being
here? Yeah, it's because they're all
here? Yeah, it's because they're all
down here in total time steps except
down here in total time steps except
this
one. I wonder if this is like something
one. I wonder if this is like something
to do with log
to do with log
cost. This could just be something weird
cost. This could just be something weird
with the way I've defined log cost,
with the way I've defined log cost,
right?
You know, cuz cost starts starts at
zero. Oh, you know, that's totally what
zero. Oh, you know, that's totally what
it is,
it is,
right? I see. So, I think it's
because this is a little silly. So
because this is a little silly. So
because cost starts like very close to
because cost starts like very close to
zero
zero
um and it's going on a log scale, it's
um and it's going on a log scale, it's
actually going to put a decent chunk of
actually going to put a decent chunk of
our runs
our runs
uh very low
cost and we literally like it can it
cost and we literally like it can it
can't set fewer than 20 million time
can't set fewer than 20 million time
steps. That's the minimum we allow.
How do we fix
that? Totally what it is.
Yeah. So like generally if you think
Yeah. So like generally if you think
about that then if I did if I try to do
about that then if I did if I try to do
a run that was like between a billion
a run that was like between a billion
and 1.5 billion steps it's always going
and 1.5 billion steps it's always going
to do a billion because on a log scale
to do a billion because on a log scale
it's going to get some early
checkpoints and then it's going to try
checkpoints and then it's going to try
to sample in the space of cost 0 to 1.5
to sample in the space of cost 0 to 1.5
billion in a log
billion in a log
scale. Most of the time you're going to
scale. Most of the time you're going to
be uh below a billion. So it rounds up
be uh below a billion. So it rounds up
to a
to a
billion. This is why when I like I look
billion. This is why when I like I look
at this
here, get
stuck. Well, I know what now I know what
stuck. Well, I know what now I know what
the problem is. I don't even need to
the problem is. I don't even need to
look at this. I just need to think of
look at this. I just need to think of
how I want to solve it.
And this specifically comes from the
And this specifically comes from the
fact that I'm adding traces like full uh
fact that I'm adding traces like full uh
full
full
traces of the
traces of the
curves. I guess one thing we could do
curves. I guess one thing we could do
is
is
we we only
need. We can just change the way our
need. We can just change the way our
sampling works, right?
But let's say we don't log any partial
But let's say we don't log any partial
points. We don't log any points that
points. We don't log any points that
are below the minimum number of time
are below the minimum number of time
steps that we could run a full
steps that we could run a full
experiment
experiment
for. That would be a start.
would be a
start, I think. Let's just do that for
start, I think. Let's just do that for
now and then let's see what happens,
now and then let's see what happens,
right?
We can just do it as like a quick hack
We can just do it as like a quick hack
for now as well. Make sure it works and
for now as well. Make sure it works and
then we can like figure out how we want
then we can like figure out how we want
to really do it.
to really do it.
Like here this this down sample
linear. So actually we just feed in
here
here
for you. You help with one topic. I'm
for you. You help with one topic. I'm
stuck. Depends what it
stuck. Depends what it
is. Is anything adjacent to any of this
is. Is anything adjacent to any of this
stuff? Then
sure. Um, global
sure. Um, global
step greater than
equal. Let me figure out what the
equal. Let me figure out what the
parameter is called.
There's a
There's a
config ars.
distic
regression. I can point you to better
regression. I can point you to better
resources depending on what you're where
resources depending on what you're where
you're trying to learn stuff from.
I imagine you're like studying stuff
I imagine you're like studying stuff
like where are you currently studying
like where are you currently studying
that from?
Okay, that'll run. We'll see if that
Okay, that'll run. We'll see if that
does anything.
for reference. By the way, like
um
That's literally logistic regression
That's literally logistic regression
right
right
there. Like that's
there. Like that's
it. Now obviously you got to write your
it. Now obviously you got to write your
own backwards and stuff, but
own backwards and stuff, but
like it's just a linear layer in a
like it's just a linear layer in a
sigmoid.
between linear and logistic regression.
between linear and logistic regression.
It's the sigmoid.
Well, I guess it depends on regression
Well, I guess it depends on regression
and
and
classification. If you're regressing one
classification. If you're regressing one
variable as a as a sample, it's
variable as a as a sample, it's
literally all right. And then you do
literally all right. And then you do
like the
loss. It's like
loss. It's like
forward
rag like
rag like
boss something like this. Y is your like
boss something like this. Y is your like
your output
your output
variable and then it's for logistic
variable and then it's for logistic
regression you literally just add in the
sigmoid. So you can only learn linear
sigmoid. So you can only learn linear
decision boundaries. Your data has to be
decision boundaries. Your data has to be
linearly separable for linear regression
linearly separable for linear regression
to work. Logistic regression gives you
to work. Logistic regression gives you
one nonlinear activation to play with.
one nonlinear activation to play with.
can learn nonlinear
bounds. That's
all. Now, look, I mean, I'm I'm
all. Now, look, I mean, I'm I'm
minimizing a little bit here cuz like I
minimizing a little bit here cuz like I
remember spending several hundred hours
remember spending several hundred hours
when I was 16 being very very confused
when I was 16 being very very confused
by like fundamental ML stuff as well.
by like fundamental ML stuff as well.
And I still would be confused if I went
And I still would be confused if I went
and go look at like pure math after not
and go look at like pure math after not
having looked at it for like the last
having looked at it for like the last
couple years or whatever. But
couple years or whatever. But
conceptually these things are quite
conceptually these things are quite
simple. And then
simple. And then
um I mean when you go implement your own
um I mean when you go implement your own
autograd and stuff things are like
autograd and stuff things are like
annoying because you have to make sure
annoying because you have to make sure
you get everything right and like there
you get everything right and like there
are million tricks in modern uh ML that
are million tricks in modern uh ML that
make things just work the way that you
make things just work the way that you
would expect them to. If you don't if
would expect them to. If you don't if
you implement stuff yourself without
you implement stuff yourself without
those tricks, it just won't work
those tricks, it just won't work
anywhere near as well and you'll be
anywhere near as well and you'll be
confused as to why. But conceptually
confused as to why. But conceptually
these things are quite simple.
gotten any experiments working in the
meanwhile. It is still pushing this all
meanwhile. It is still pushing this all
the way down to the
the way down to the
bottom. Still
bottom. Still
doing ridiculously short runs.
That seems weird to
me. That seems very
weird. Make sure I just
like scores
lost. Oh, you know what it is. I'm dumb.
lost. Oh, you know what it is. I'm dumb.
Okay, I'm dumb. I know what I did wrong.
Okay, I'm dumb. I know what I did wrong.
And I know why this did like
And I know why this did like
um Yeah, I know exactly what I
did. Surprised I didn't hit this
before. Target
before. Target
minus. Oh, no. Wait. Isn't this fine?
This is fine, right? Because it's
This is fine, right? Because it's
point minus GP log C
point minus GP log C
norm. Wait, this should be in log space
norm. Wait, this should be in log space
then,
then,
right? And this is running a longer
right? And this is running a longer
experiment right
here. Maybe it is fine.
So, um, to give you a bit of an idea of
So, um, to give you a bit of an idea of
what we're looking at here,
what we're looking at here,
um, this is our new hyperpar tuning
um, this is our new hyperpar tuning
algorithm. I've been sitting on this
algorithm. I've been sitting on this
result for several months. It's a very,
result for several months. It's a very,
very good hyperparam tuning algorithm,
very good hyperparam tuning algorithm,
but we made a few changes recently and
but we made a few changes recently and
we kind of broke a few things. Um, so
we kind of broke a few things. Um, so
I'm trying to get it back to its old
I'm trying to get it back to its old
level of PF for the upcoming release. uh
level of PF for the upcoming release. uh
and currently what's happening is that
and currently what's happening is that
uh the way the algorithm works is it
uh the way the algorithm works is it
picks a length of experiment
picks a length of experiment
uh and then it tries to select and it
uh and then it tries to select and it
tries to guess an experiment that it
tries to guess an experiment that it
thinks it'll do well that'll take about
thinks it'll do well that'll take about
that long. What it does is it runs a
that long. What it does is it runs a
whole bunch of experiments of different
whole bunch of experiments of different
lengths. It builds up predictive models
lengths. It builds up predictive models
of how long an experiment is going to
of how long an experiment is going to
take and how well it thinks it's going
take and how well it thinks it's going
to do and then tries to pick the best
to do and then tries to pick the best
experiments of all different lengths.
experiments of all different lengths.
The idea here is that you know you run
The idea here is that you know you run
short experiments, you run long
short experiments, you run long
experiments, you actually start off
experiments, you actually start off
running shorter experiments and then
running shorter experiments and then
gradually start running longer ones as
gradually start running longer ones as
you be get more confident. Uh it's a
you be get more confident. Uh it's a
very simple algorithm. It's very robust.
very simple algorithm. It's very robust.
It doesn't have a lot of the problems
It doesn't have a lot of the problems
that a lot of the other algorithms had.
that a lot of the other algorithms had.
But one of those uh right now is that
But one of those uh right now is that
it's running a lot of really really
it's running a lot of really really
short experiments. And I think the
short experiments. And I think the
reason for this is just that I messed
reason for this is just that I messed
up. And uh instead of trying to tell it
up. And uh instead of trying to tell it
to pick an experiment from uh that takes
to pick an experiment from uh that takes
between the length of the shortest
between the length of the shortest
experiment it's ever run and the length
experiment it's ever run and the length
of the longest experiment, it instead
of the longest experiment, it instead
just tries to like pick an experiment of
just tries to like pick an experiment of
any length up to the longest. So like
any length up to the longest. So like
it's going to pick a lot of experiments
it's going to pick a lot of experiments
that are below the minimum length which
that are below the minimum length which
then just get capped off to the minimum
then just get capped off to the minimum
length. And uh yeah, that's what I think
length. And uh yeah, that's what I think
is happening.
It's still running a bunch of really
It's still running a bunch of really
short experiments though, even though I
short experiments though, even though I
I should have had that fixed based on
I should have had that fixed based on
this. How's a random forest model make
this. How's a random forest model make
predictions? No idea. Those are so old.
predictions? No idea. Those are so old.
I literally like I've never used a
I literally like I've never used a
random forest.
like actually never used one.
I mean all my work is deep neural nets,
I mean all my work is deep neural nets,
right? Except for I guess technically
right? Except for I guess technically
this um this hyperparameter tuning
this um this hyperparameter tuning
algorithm uses Gaussian processes.
algorithm uses Gaussian processes.
That's about it.
All right. So, the problem is still
All right. So, the problem is still
definitely here,
definitely here,
right? We got one reasonably length like
right? We got one reasonably length like
one reasonable length to run and the
one reasonable length to run and the
rest of them are they went all the way
rest of them are they went all the way
to the top and then all the way to the
to the top and then all the way to the
bottom. So, something's screwy here.
bottom. So, something's screwy here.
Why do deep neural networks tend to
Why do deep neural networks tend to
perform better than shallow ones? I mean
perform better than shallow ones? I mean
they can
they can
well the real answer is
well the real answer is
um like what is it uh divine serendipity
um like what is it uh divine serendipity
or whatever like we don't know but uh
or whatever like we don't know but uh
approximately correct answer handwavy
approximately correct answer handwavy
answer is deeper neural nets you have
answer is deeper neural nets you have
more nonlinearities in the middle uh
more nonlinearities in the middle uh
they also tend to be larger and they can
they also tend to be larger and they can
represent more classes of functions
represent more classes of functions
uh so that they can represent more data.
uh so that they can represent more data.
Like if you have a complex function, you
Like if you have a complex function, you
have a one layer neural net of like a
have a one layer neural net of like a
specific capacity, it might not just be
specific capacity, it might not just be
able to represent the decision boundary
able to represent the decision boundary
that you want. It's a regression class.
that you want. It's a regression class.
might not be able to represent that
problem like you're training a thing to
problem like you're training a thing to
approximate another thing, right? If
approximate another thing, right? If
first thing is very simple and then
first thing is very simple and then
second thing is very complicated, simple
second thing is very complicated, simple
thing can't represent complicated thing
thing can't represent complicated thing
very well.
So it is this one is a longer experiment
So it is this one is a longer experiment
here I can
here I can
see. So it is running some longer
see. So it is running some longer
experiments but
like it's
like it's
screwy. It's like screwy what it's
doing. Let me figure out what this is.
doing. Let me figure out what this is.
What's happening here? What a break
What's happening here? What a break
point like right
here. Do like
here. Do like
this. Hey, free to work on GPU drive
this. Hey, free to work on GPU drive
stuff. Sure, Spencer. Uh, give
stuff. Sure, Spencer. Uh, give
me give me like two minutes to go run
me give me like two minutes to go run
use the restroom and then we will uh
use the restroom and then we will uh
I'll jump on a call or whatever for
I'll jump on a call or whatever for
that and do a set.
Ara, is this asking you stuff or you
Ara, is this asking you stuff or you
giving me
giving me
like introductory ML quiz? You know, I
like introductory ML quiz? You know, I
haven't used any of these algorithms in
haven't used any of these algorithms in
like almost a decade,
like almost a decade,
right? It's a clustering algorithm. It's
right? It's a clustering algorithm. It's
an unsupervised learning algorithm. You
an unsupervised learning algorithm. You
want to partition data into K groups
want to partition data into K groups
where the things in each group are
where the things in each group are
similar to each
other. I don't remember the distance
other. I don't remember the distance
metric that is used in the algorithm
metric that is used in the algorithm
because I haven't used it in a
decade. Dear
Spencer probably already in the Discord.
Spencer probably already in the Discord.
Nope.
I'll hop in the Discord.
Yep. How's it going, man? Hey, going
Yep. How's it going, man? Hey, going
well. Let me uh mute you on the stream.
well. Let me uh mute you on the stream.
Hold up. Uhhuh. I've been
Hold up. Uhhuh. I've been
debugging all sorts of crazy things.
debugging all sorts of crazy things.
Oh, yeah.
Oh, yeah.
We're making progress. Slow though.
Uh, so I made a PR by just pulling in
Uh, so I made a PR by just pulling in
the latest dev stuff into my GPU drive
the latest dev stuff into my GPU drive
branch. Um, let me go deal with that.
branch. Um, let me go deal with that.
Hang on. Oops.
I will note up front it does
I will note up front it does
not compile to to train from the latest
not compile to to train from the latest
stuff in dev.
I'm not certain if you would have wanted
I'm not certain if you would have wanted
me to just put that into the PR and then
me to just put that into the PR and then
you'd handle it in dev or if you want to
you'd handle it in dev or if you want to
pull my or pull my existing branch from
pull my or pull my existing branch from
my repo.
Uh what why doesn't it compile?
Uh what why doesn't it compile?
Uh you have some new agents per batch
Uh you have some new agents per batch
thing in buffer. Just we'll just pull
thing in buffer. Just we'll just pull
that and fix
it. Okay.
And then it looks like from the files I
And then it looks like from the files I
dropped in there when I pulled dev, it
dropped in there when I pulled dev, it
looks like you have a new build
looks like you have a new build
simple.sh as
simple.sh as
well.
well.
Build simple. I don't know what the heck
Build simple. I don't know what the heck
that
is. Okay. So, a lot of file
is. Okay. So, a lot of file
changes. You PR this to dev. Okay.
Well, you haven't seen the new release
Well, you haven't seen the new release
branch stuff, which is way crazier even.
Yeah. I mean, I don't know what's all in
Yeah. I mean, I don't know what's all in
between various things. A lot. A lot.
between various things. A lot. A lot.
So, I can start I can pull some things
So, I can start I can pull some things
out of here. Well, I love So, let me see
out of here. Well, I love So, let me see
what So, what
what So, what
is So, I see that there is some reward
is So, I see that there is some reward
tuning.
tuning.
This was a little bit of like kind of
This was a little bit of like kind of
like a dirty pull from just like me just
like a dirty pull from just like me just
syncing from dev and then merging stuff.
syncing from dev and then merging stuff.
Okay. And then we have this demo file.
Okay. And then we have this demo file.
Most of what's changed is
in theh
in theh
file which has more render stuff I
file which has more render stuff I
worked on. Uhhuh. Um that that GPU drive
worked on. Uhhuh. Um that that GPU drive
test file can probably be dropped out. I
test file can probably be dropped out. I
guess that just got tossed in there from
guess that just got tossed in there from
my branch. It's a dev branch. Doesn't
my branch. It's a dev branch. Doesn't
freaking matter. So, I mean, those files
freaking matter. So, I mean, those files
can just be deleted in the future. It's
can just be deleted in the future. It's
no big deal.
no big deal.
There's a diff here. There's a 300 some
There's a diff here. There's a 300 some
odd line edition here.
odd line edition here.
Yeah, that's um my changes to render
Yeah, that's um my changes to render
in.h means new drive. And then also
in.h means new drive. And then also
there's a there's some changes I had to
there's a there's some changes I had to
make to match how the NYU project
make to match how the NYU project
worked. Okay, that's good.
The means trick right there was just
The means trick right there was just
something so that the the camera always
something so that the the camera always
is on
origin. Also, did you I just ran one
origin. Also, did you I just ran one
random thing. Did you make a full set of
random thing. Did you make a full set of
animations for um power climb or is
animations for um power climb or is
there like one missing where it just
there like one missing where it just
like snaps?
Um the one that it would be missing
Um the one that it would be missing
is jumping off a block.
is jumping off a block.
I see. Everything else there's something
I see. Everything else there's something
where there's one where it's like it
where there's one where it's like it
looks really smooth and then it just
looks really smooth and then it just
snaps.
snaps.
Um I'll have to you you'll have to show
Um I'll have to you you'll have to show
me which one that is.
me which one that is.
Because some of them it's about playing
Because some of them it's about playing
with like the timing of when the
with like the timing of when the
animation ends versus
like when the next action is ready.
For sure. If you're wrapping a block, it
For sure. If you're wrapping a block, it
snaps because there's not really a good
snaps because there's not really a good
way to animate like
way to animate like
going around the cube.
going around the cube.
I'll have to fix the config for this.
I'll have to fix the config for this.
Um, but yeah, there's a couple weird
Um, but yeah, there's a couple weird
things. Anyways,
um, GPU drive doesn't have any animation
um, GPU drive doesn't have any animation
stuff. This is all just like drawings
stuff. This is all just like drawings
and
and
camera and c uh this one also has the
camera and c uh this one also has the
three the third person camera uh
view. Um that is me turning a curb into
view. Um that is me turning a curb into
a 3D rectangle.
Wait.
Wait.
3D raised by curb
height. Wait, is this now you're drawing
height. Wait, is this now you're drawing
triangles for the curb?
triangles for the curb?
Yeah.
Yeah.
What is this actually like a triangle
What is this actually like a triangle
strip or what is this? It makes it so
strip or what is this? It makes it so
that as you're wrapping a corner and the
that as you're wrapping a corner and the
curb curves, it looks like a like a
curb curves, it looks like a like a
round corner.
round corner.
All right, we'll look at what this is.
All right, we'll look at what this is.
Cool. I I guess I will see what it looks
Cool. I I guess I will see what it looks
like. Done a whole bunch of stuff on
this. Oh, you added a car.
this. Oh, you added a car.
Yeah.
Yeah.
Yay. Sure. I'm going to have complaints
Yay. Sure. I'm going to have complaints
about the car and have to get a cool car
about the car and have to get a cool car
made.
made.
Yeah. I mean, I I just picked a car from
Yeah. I mean, I I just picked a car from
online and then went inside of Blender
online and then went inside of Blender
to go change the color of it to have
to go change the color of it to have
multiple different colored cars.
multiple different colored cars.
Uh, you committed TF record files.
Uh, you committed TF record files.
Are these levels? What are these? Uh,
Are these levels? What are these? Uh,
those look to be
I can toss those out. Are they sample
I can toss those out. Are they sample
levels or like what are they? I think
levels or like what are they? I think
they're from the examples of the like
they're from the examples of the like
pre-process stuff when I first was doing
pre-process stuff when I first was doing
it. It seems like my commit also just
it. It seems like my commit also just
dropped. It's not bad to have an example
dropped. It's not bad to have an example
level by the way. Um then those are
level by the way. Um then those are
example levels. Cool. Whatever. We're
example levels. Cool. Whatever. We're
fine. I don't And I don't know what
fine. I don't And I don't know what
build simple is. I don't know what this
build simple is. I don't know what this
is.
is.
It looks like when I did my merge, it
It looks like when I did my merge, it
just like pulled stuff in. Yeah,
just like pulled stuff in. Yeah,
whatever.
We merge
thing. All right. So here we have your
thing. All right. So here we have your
GPU
GPU
drive build
ocean supposed to do something.
Uh you're on uh test performance. Go to
Uh you're on uh test performance. Go to
this. Go to the C file and
um switch it to
demo.
demo.
Oh, does look
cool. Is these are these are 3D curves?
cool. Is these are these are 3D curves?
Yep. You actually made Okay. The only
Yep. You actually made Okay. The only
feedback I have you for there is that
feedback I have you for there is that
there is a draw triangle strip function.
instead of having to draw individual
instead of having to draw individual
triangles. But yeah, that is awesome.
triangles. But yeah, that is awesome.
Cool. Uh and like because you have that,
Cool. Uh and like because you have that,
it's actually probably not that hard now
it's actually probably not that hard now
to make potentially more elevated things
to make potentially more elevated things
and put the cars in a maze. H
and put the cars in a maze. H
Yeah. I mean, you could do whatever you
Yeah. I mean, you could do whatever you
want at this point in terms of drawing
want at this point in terms of drawing
levels.
Yeah. And if only they drove around.
Yeah. And if only they drove around.
Yeah. If you switch to move expert and
Yeah. If you switch to move expert and
step, you can see what the policy is
step, you can see what the policy is
supposed to be
supposed to be
doing in theh file.
doing in theh file.
Okay, I can do that. What is the thing
Okay, I can do that. What is the thing
we want to debug? This thing not train
we want to debug? This thing not train
well or what? Yes, that would be
well or what? Yes, that would be
priority number one. Okay, let's let's
priority number one. Okay, let's let's
do that. So, but step one is first
do that. So, but step one is first
getting it to work with the new dev
getting it to work with the new dev
stuff that's in there cuz Okay, I was
stuff that's in there cuz Okay, I was
working on a fairly old
dev. It compiles, but it does not rain.
dev. It compiles, but it does not rain.
I guess
um I think it's just missing a parameter
um I think it's just missing a parameter
because if you put it on
because if you put it on
uh native on on without multipprocessing
uh native on on without multipprocessing
it just runs into a bug in clean buffer
it just runs into a bug in clean buffer
RL right
just stop. Oh, someone from your someone
just stop. Oh, someone from your someone
from your chat says that uh your audio
from your chat says that uh your audio
is kind of low.
is kind of low.
[Music]
[Music]
Joseph's audio is way low
comparatively. Does that mean that
comparatively. Does that mean that
you're too Say something? Hello. Yeah.
you're too Say something? Hello. Yeah.
Okay. Your mic is just super
Okay. Your mic is just super
high. All
high. All
right. Say something again. What's up?
right. Say something again. What's up?
Mic down a little bit more. All right.
Mic down a little bit more. All right.
Let me know if this is good. I had to
Let me know if this is good. I had to
just mix the thing.
Dec agents
Dec agents
per doesn't exist in native M2, but we
per doesn't exist in native M2, but we
can
multiprocess. I think multipprocessing
multiprocess. I think multipprocessing
is a little weird on this as well, but
is a little weird on this as well, but
we can look at that later at one point.
we can look at that later at one point.
Okay, we have it as default now for
Okay, we have it as default now for
everything pretty much. Ah, okay. I
everything pretty much. Ah, okay. I
think I've noticed some differences on
think I've noticed some differences on
multipprocessing versus native.
multipprocessing versus native.
Your mic super high. All right, we'll
Your mic super high. All right, we'll
try this.
try this.
Am I still exploding eardrums?
Am I still exploding eardrums?
Um I it should be pretty close to mine
Um I it should be pretty close to mine
now at this point. I just for me to mix.
now at this point. I just for me to mix.
No
No
worries.
Uh yeah. So, this is this is the fun
Uh yeah. So, this is this is the fun
thing with uh having to get the batches
thing with uh having to get the batches
all correct, right?
Yeah. Yeah. So, you want you want to
Yeah. Yeah. So, you want you want to
have like a multiple of the number of
have like a multiple of the number of
cars or whatever the number of agents.
cars or whatever the number of agents.
So, how many agents is this? Do we know
So, how many agents is this? Do we know
up front
up front
um for this round?
No, it's an awkward number. Let me do a
No, it's an awkward number. Let me do a
Let me It looks like 1847 or
3536. 3536. It is.
But we do
But we do
36. Is that the total number?
36. Is that the total number?
So, one thing to take a note of is I did
So, one thing to take a note of is I did
something funky in my Sython.
something funky in my Sython.
Before you do some of this, I multiplied
Before you do some of this, I multiplied
times eight already inside the Sython.
What do you multiply by eight? The
What do you multiply by eight? The
number of agents. Why?
Um, it was an experiment because at the
Um, it was an experiment because at the
time I was only doing something I was
time I was only doing something I was
only just kind of getting 75 levels to
only just kind of getting 75 levels to
go and when you only had 75 levels, it
go and when you only had 75 levels, it
only gave you like, you know, a few
only gave you like, you know, a few
hundred agents. So, I wanted to get more
hundred agents. So, I wanted to get more
parallelization going on those seven on
parallelization going on those seven on
this on the when working with 75 maps.
this on the when working with 75 maps.
So, I cloned that those agents into more
So, I cloned that those agents into more
M's.
M's.
Okay. All I want to do here for
Okay. All I want to do here for
reference is I just want to figure out
reference is I just want to figure out
how many cards you have and set the
how many cards you have and set the
batch size to be like 64 times that and
batch size to be like 64 times that and
the mini batch size to be like eight
the mini batch size to be like eight
times that. That's all I really want to
times that. That's all I really want to
do.
Okay. So, like how many cars do we have?
Okay. So, like how many cars do we have?
Then you're going to be looking
at should be 582.
582 cars. That's it. Across 75 maps.
582 cars. That's it. Across 75 maps.
Yeah. All
Yeah. All
right. That's how that's how many active
right. That's how that's how many active
agent cars there should
be. You have a pretty small batch size,
be. You have a pretty small batch size,
but whatever.
Yeah. I mean, that's why I I decided to
Yeah. I mean, that's why I I decided to
do like the the multiply by eight thing
do like the the multiply by eight thing
inside of the Sython. So if you want to
inside of the Sython. So if you want to
reverse that out, what but the
multi if you have 8x the number of cars
multi if you have 8x the number of cars
being used for
being used for
obs, don't I? Yeah. So that that's what
obs, don't I? Yeah. So that that's what
I was I thought you wanted the original
I was I thought you wanted the original
number. I mean 4656. Okay. So it's it is
number. I mean 4656. Okay. So it's it is
32. Not it is
32. Not it is
226. Your batch size is
226. Your batch size is
226. And what are you doing with those
226. And what are you doing with those
extra cars?
extra cars?
I was just trying to get some more M's
I was just trying to get some more M's
going. What do you mean more?
going. What do you mean more?
Okay, so right now the num m's parameter
Okay, so right now the num m's parameter
is directly correlates to the map index
is directly correlates to the map index
0 through 74. Did you just make eight
0 through 74. Did you just make eight
copies of each map? Yes. Oh yeah, that's
copies of each map? Yes. Oh yeah, that's
if you said that it immediately. Yeah,
if you said that it immediately. Yeah,
that's totally fine. Whatever.
that's totally fine. Whatever.
Okay. Yeah, that's I Okay,
cool. So, where is this
cool. So, where is this
thing? 5 30 this divide by what is it? 8
28,000. These things take a while to
28,000. These things take a while to
load.
And they spam a
Is it
Is it
stuck?
stuck?
It looks that way.
Normally when there's something like
Normally when there's something like
that going on, it's related to Neptune
that going on, it's related to Neptune
or Wani.
I didn't think I ran it with Neptune,
I didn't think I ran it with Neptune,
did I?
did I?
No, I don't know if you did, but
No, I don't know if you did, but
normally that's like what happens if it
normally that's like what happens if it
if it halts for
if it halts for
me. I did not run it with anything.
me. I did not run it with anything.
So
um
native is it cuz you have one
worker. It shouldn't matter. It should
worker. It shouldn't matter. It should
be fine like this.
Multi. There should not be an issue with
Multi. There should not be an issue with
this. This is weird.
this. This is weird.
Multiprocessing. You always had to have
Multiprocessing. You always had to have
two workers, two M's.
two workers, two M's.
No, you can have as many as you want or
No, you can have as many as you want or
as few as you
want. The uh the new branches also will
want. The uh the new branches also will
have better warnings for like batch size
have better warnings for like batch size
stuff as well.
What is it
doing? If it's done, it should just go
doing? If it's done, it should just go
into starting. It It really shouldn't.
These are all things that have just
This is just taking
This is just taking
forever.
forever.
Before I pulled in dev, this was not a
Before I pulled in dev, this was not a
an
issue. I guess we just like put some
issue. I guess we just like put some
break
break
points. But this is very
points. But this is very
odd. Oh, wait. Is the policy kind of big
or the I mean not big enough where it
or the I mean not big enough where it
should be delaying like that.
should be delaying like that.
Is the mini batch like ridiculous?
Like is this mini batch ridiculously
Like is this mini batch ridiculously
large?
It could just be slow.
Let's see what the default mini batch
is. Mini batch on default on mine is
is. Mini batch on default on mine is
8192,
8192,
but by
but by
this if not, we'll start stepping
this if not, we'll start stepping
through this to see what the heck is
through this to see what the heck is
going
on. Clone agent
on. Clone agent
offset. So, this says that you have
offset. So, this says that you have
4,9 4637 agents.
4,9 4637 agents.
Um,
Um,
plus one more
plus one more
round that the But that's not the number
round that the But that's not the number
that you told me.
that you told me.
No, the number I told you is
No, the number I told you is
the is the actual number divided by
the is the actual number divided by
eight.
Well, no.
Well, no.
Like it's you if you have multiple
Like it's you if you have multiple
copies of the of M's that still counts.
copies of the of M's that still counts.
Like those are all unique cars.
Like those are all unique cars.
Um, like I I wanted to know the OBS
Um, like I I wanted to know the OBS
batch size. Is this like not the OBS
batch size. Is this like not the OBS
batch size?
The 500 something I told you earlier.
The 500 something I told you earlier.
It's It's probably just not the OBS
It's It's probably just not the OBS
batch size. No, it's 4,000 something.
batch size. No, it's 4,000 something.
Yeah. So then that's Yeah, it's totally
Yeah. So then that's Yeah, it's totally
going to break because this is a dev
going to break because this is a dev
branch that doesn't have safety checks
branch that doesn't have safety checks
on stuff not being divisible. So it's
on stuff not being divisible. So it's
probably just infinite looping somehow.
probably just infinite looping somehow.
Um, I'm trying to get that number for
Um, I'm trying to get that number for
you right now. When I when I reloaded
you right now. When I when I reloaded
the the levels, the numbers I was
the the levels, the numbers I was
working with changed. So, let
working with changed. So, let
me Well, you will actually get warnings
me Well, you will actually get warnings
about that on the release branch. Like,
about that on the release branch. Like,
it'll make sure everything's evenly
divisible. We're not even getting to run
divisible. We're not even getting to run
the policy.
It's probably just like
running be getting here at least, right?
Okay, it's not even getting to evaluate.
Okay, it's not even getting to evaluate.
So, something's just screwy.
So, something's just screwy.
It could be mad at what I
It could be mad at what I
did, but like it looks like it's just
did, but like it looks like it's just
hanging in the
end. Okay.
Go to native
Go to native
then serial.
I've got a meeting, by the way, with the
I've got a meeting, by the way, with the
the guys that I was uh the the tech guy
the guys that I was uh the the tech guy
of the the guys that I chatted with you
of the the guys that I chatted with you
about a few weeks ago at 4:15 if you
about a few weeks ago at 4:15 if you
want to join. If not, I'll just handle.
want to join. If not, I'll just handle.
Is that uh today or what? Yeah, in was
Is that uh today or what? Yeah, in was
it a little under an hour? Okay. Oh,
it a little under an hour? Okay. Oh,
your time 4:15. Okay. Okay.
your time 4:15. Okay. Okay.
Oh, yeah. I forgot there wasn't an hour
Oh, yeah. I forgot there wasn't an hour
difference. Yeah. Yeah. I'm I'm in
difference. Yeah. Yeah. I'm I'm in
central
You will appreciate the flag that's
You will appreciate the flag that's
going in the background then
is large. Nice.
Yeah. So the total agent should be 4656.
in terms of like the num agents times 8
in terms of like the num agents times 8
number
number
total agents equals 582 is what's being
total agents equals 582 is what's being
returned. Yeah. So the times 8 is the
returned. Yeah. So the times 8 is the
4656.
I see
because I was cloning those just to try
because I was cloning those just to try
and get more parallel going on 75. 48
and get more parallel going on 75. 48
was say 4856 40
4656. I don't think this is the error,
4656. I don't think this is the error,
but we will fix this at least.
What if it's a torch
What if it's a torch
issue? be
weird. And then on reset is when it
weird. And then on reset is when it
loads all the maps or right
here. It loads all of them in the Syon,
here. It loads all of them in the Syon,
but in a nit it does it
all. Wait, is that the right order?
all. Wait, is that the right order?
Observations, actions, rewards, masks,
Observations, actions, rewards, masks,
terminals. I think the order is wrong.
terminals. I think the order is wrong.
Oh, we probably check that.
Is that something with the new bindings?
Is that something with the new bindings?
Is that would be an issue? No, that's
Is that would be an issue? No, that's
just been like that
forever. Yeah, this this has
forever. Yeah, this this has
observations in it, man.
observations in it, man.
Um, hang
on.
OBS actions rewards terminals.
OBS actions rewards terminals.
Terminals then masks. There's not even a
Terminals then masks. There's not even a
masks in the Oh, I guess it depends on
masks in the Oh, I guess it depends on
if you actually if you put it in the
if you actually if you put it in the
that order in the Syon, it's
fine. Let
me see if you did.
Yeah, you did it
fine. You did it fine.
Okay, let's see if this runs.
Okay, so this runs except for
um how do we get this to be a
um how do we get this to be a
reasonable number of
Um, how do we get this thing to be a
Um, how do we get this thing to be a
reasonable size?
What do you mean by that? Can we get
What do you mean by that? Can we get
this to be a multiple
this to be a multiple
of 128 or something? Or not really? No,
of 128 or something? Or not really? No,
it's entirely dynamic because it's based
it's entirely dynamic because it's based
on the amount of agents per map of those
on the amount of agents per map of those
maps that you're given.
maps that you're given.
I mean, you could
I mean, you could
technically reduce the amount of static
technically reduce the amount of static
cars in a map. Or no, hold up. Because
cars in a map. Or no, hold up. Because
you only care about active cars. You You
you only care about active cars. You You
just be taking out some active cars
just be taking out some active cars
theoretically. Okay, let me see if I can
theoretically. Okay, let me see if I can
hack this thing then. Like, but that
hack this thing then. Like, but that
would be a little
jank. If I can hack this thing.
jank. If I can hack this thing.
Like if I just comment this, does it
Like if I just comment this, does it
run?
I mean, I think to get it to at least a
I mean, I think to get it to at least a
less annoying place, maybe getting rid
less annoying place, maybe getting rid
of my cloning in the Sython would
of my cloning in the Sython would
probably make things a little less. It's
probably make things a little less. It's
just that we're shipping we're shipping
just that we're shipping we're shipping
Huda stuff now and it's
like it doesn't like when things aren't
like it doesn't like when things aren't
fixed sizes. There's technically I can
fixed sizes. There's technically I can
make it work. Just I haven't done it
make it work. Just I haven't done it
yet. Let me see if this breaks or not.
Building the
kernels. Oh, now it's rea tuning. Takes
kernels. Oh, now it's rea tuning. Takes
forever.
Much work to be
Yep. So that's not It's just not happy.
Yep. So that's not It's just not happy.
It's just not
It's just not
happy. It's the Okay. Is it cuz it's
happy. It's the Okay. Is it cuz it's
over
4096? Hang
4096? Hang
on. I mean
I just
I just
do see if I do this good for
To be fair, the mini batch size doesn't
To be fair, the mini batch size doesn't
have to be this way.
Maybe this is the trick.
Maybe this is the trick.
Are you just forcing the mini batch to
Are you just forcing the mini batch to
be a good number? Six.
This is
16k like you see the issue is like the
16k like you see the issue is like the
CUDA kernels they expect like a certain
CUDA kernels they expect like a certain
number of rows. Mhm.
number of rows. Mhm.
Maybe this is the this is the thing
Maybe this is the this is the thing
though. We just let you
though. We just let you
do different mini batch size compared to
do different mini batch size compared to
batch
batch
size because we no longer like iterate
size because we no longer like iterate
through anymore. We sample
anyways. So maybe that's the play. You
anyways. So maybe that's the play. You
have to be kind of careful with your
have to be kind of careful with your
batch size, but you don't have to really
batch size, but you don't have to really
care about the mini batch size. As long
care about the mini batch size. As long
as it's like
as it's like
a big enough that
works assertion.
How is this still screwed
up? Want to compute the puffer
advantage. I
advantage. I
mean, it's still not going to let me
mean, it's still not going to let me
compute. It's this one
here. Maybe what we'll just do.
I just want to get you like a version of
I just want to get you like a version of
this that you can play with and solve
this that you can play with and solve
the problem
the problem
on. And then like it'll be on me to
on. And then like it'll be on me to
figure out what we're going to
figure out what we're going to
do longer
do longer
term to like make this thing not such a
term to like make this thing not such a
pain in the
ass whether that's figuring out how to
ass whether that's figuring out how to
make the CUDA kernels run better and
make the CUDA kernels run better and
yeah there here.
yeah there here.
So, is that an assert or was that not
So, is that an assert or was that not
an? We got some weird message up there.
an? We got some weird message up there.
It's
fine. 61% of time is not
happy. Wait,
happy. Wait,
Spencer, why did you do
You did eight replicas and and you but
You did eight replicas and and you but
you put them on the same core instead of
you put them on the same core instead of
doing it on multiple cores.
Yeah. Well, you're 60% M time right now.
If you get rid of that, I think it drops
If you get rid of that, I think it drops
down to like 17% of time or something
down to like 17% of time or something
like that.
Well, that doesn't make sense because
Well, that doesn't make sense because
it's 8x more data. The problem is it's
it's 8x more data. The problem is it's
on one core, right? But I thought GP I
on one core, right? But I thought GP I
thought the thing was fast. Is it not?
thought the thing was fast. Is it not?
So, it's at
So, it's at
like end time ranges from like 700,000
like end time ranges from like 700,000
to a million steps per second. But the
to a million steps per second. But the
train if you get all of the obs in there
train if you get all of the obs in there
whether they're really required or not.
whether they're really required or not.
Okay. So this is the thing I was saying
Okay. So this is the thing I was saying
where it's like if we want this thing to
where it's like if we want this thing to
just work we should just respawn the
just work we should just respawn the
cars.
cars.
Okay. Actually here this is this is
Okay. Actually here this is this is
working though. Here let's let's at
working though. Here let's let's at
least get a reasonable setup out of
least get a reasonable setup out of
this. Um yeah. So, so what that right
this. Um yeah. So, so what that right
now is your penalties right there. But I
now is your penalties right there. But I
I all I want to do is like
I all I want to do is like
where's this factor? Where's this factor
where's this factor? Where's this factor
of eight coming in? Syon. In the Sython.
of eight coming in? Syon. In the Sython.
In the Sython.
In the Sython.
Eight. If I just look for eight.
Eight. If I just look for eight.
Yeah, you'll find it. I see
Yeah, you'll find it. I see
UTF8. Num clones equals one.
UTF8. Num clones equals one.
Num clones is eight.
Okay. And then you hold up hold you have
Okay. And then you hold up hold you have
to do one more thing. What else? Uh you
to do one more thing. What else? Uh you
have to go inside of step and
have to go inside of step and
reset in the Sython and change the times
reset in the Sython and change the times
8 because that variable wasn't defined
8 because that variable wasn't defined
in
in
uh I only defined it in in it.
Okay, why don't we actually use our CPU
Okay, why don't we actually use our CPU
which has multiple cores.
Actually, let's do that. I I didn't do
Actually, let's do that. I I didn't do
it at first because I felt like whenever
it at first because I felt like whenever
I did multiprocessing, I was getting
I did multiprocessing, I was getting
weirdly
less successful results and I didn't
less successful results and I didn't
know if it was just because of like how
know if it was just because of like how
my like agent setups were. Well, we will
my like agent setups were. Well, we will
find that
out. This is spamming way faster.
out. This is spamming way faster.
Whoa. That total agent. Now you're only
Whoa. That total agent. Now you're only
going to have like 500 something agents.
No, because I have eight I'm doing this
No, because I have eight I'm doing this
eight
eight
times on eight different processes. I'm
times on eight different processes. I'm
doing the same thing that you're doing.
doing the same thing that you're doing.
So instead of making eight copies of one
So instead of making eight copies of one
process,
process,
right? Right.
right? Right.
Okay. Why is this a total O agents
Okay. Why is this a total O agents
32,000? Did it not recompile? Is there a
32,000? Did it not recompile? Is there a
factor of eight somewhere still?
Um, GPU drive.py possibly. Yeah, GPU
drive.py. Numb agents. Total agents
drive.py. Numb agents. Total agents
times 8.
We'll have some sanity
today. Okay. A little better, right?
We just doubled the training speed.
We just doubled the training speed.
Yeah. And if you if you take out some of
Yeah. And if you if you take out some of
the obs, I mean, then you you drop you
the obs, I mean, then you you drop you
can increase it even more. I was really
can increase it even more. I was really
I only really slowed things down because
I only really slowed things down because
I was getting I was confused as to why I
I was getting I was confused as to why I
couldn't get something that was matching
couldn't get something that was matching
exactly. So I was like, "Okay, maybe
exactly. So I was like, "Okay, maybe
it's something to do with the ops." So,
it's something to do with the ops." So,
I decided to just copy exactly what
I decided to just copy exactly what
there was, even though I know it really
there was, even though I know it really
shouldn't affect it,
but I use this.
but I use this.
So, so this is also the zero penalty
So, so this is also the zero penalty
test. So, this test should always get
test. So, this test should always get
you to pretty much um 99 point, you
you to pretty much um 99 point, you
know, like 99 if it's has zero um
know, like 99 if it's has zero um
penalty collisions on off-road or
penalty collisions on off-road or
hitting a car. Okay. So, why is it not
hitting a car. Okay. So, why is it not
instant solving this if it's easy? It
instant solving this if it's easy? It
generally for me took about 100 million
generally for me took about 100 million
steps to get to 0.99.
steps to get to 0.99.
Uh, I'm used to things running 10x this
Uh, I'm used to things running 10x this
fast. So, it's still at 15 mil.
Yeah, there's a lot of speed loss
Yeah, there's a lot of speed loss
getting from environment to polic to the
getting from environment to polic to the
the torch side of things.
the torch side of things.
The ops are huge.
Yeah, I fix all this
And then I added the one hot encoding on
And then I added the one hot encoding on
on the classifications of the roads.
So this shared embedding what is hang on
So this shared embedding what is hang on
where's the one that has the max on it.
where's the one that has the max on it.
If you go into the encode observations
If you go into the encode observations
the maxes are on the road and the
the maxes are on the road and the
partner
partner
features. Okay. And those go to input
features. Okay. And those go to input
size, which is
size, which is
uh 128,
which is what the NYU group had. All
which is what the NYU group had. All
right. I kind of want to up your hidden
right. I kind of want to up your hidden
size, but we'll
see. We actually have we have um I
see. We actually have we have um I
believe 512 hidden dim with a simple
believe 512 hidden dim with a simple
policy.
policy.
This This one's pretty cool. Uh so grid
This This one's pretty cool. Uh so grid
here has a 512 hidden dim RNN. It's like
here has a 512 hidden dim RNN. It's like
a 2 mil perm policy or whatever. Transit
a 2 mil perm policy or whatever. Transit
1.8 million steps a second.
So like puffer very fast,
but ob's really small on grid, right?
but ob's really small on grid, right?
Mhm.
Give me one second.
Okay, I'm back.
Mhm. It's not terrible. It's just it
Mhm. It's not terrible. It's just it
feels slow because it's training slow.
feels slow because it's training slow.
Yeah,
Yeah,
but this is without collisions,
but this is without collisions,
correct?
correct?
It's my it's it's my sanity test just to
It's my it's it's my sanity test just to
make sure that it can actually get to
make sure that it can actually get to
the goal and like figure out that
the goal and like figure out that
portion because I was like, why is this
portion because I was like, why is this
not figuring it out with collisions?
not figuring it out with collisions?
And does it get reward for hitting goal
And does it get reward for hitting goal
or what does it get? Yeah, just gets
or what does it get? Yeah, just gets
reward for hitting goal the same way
reward for hitting goal the same way
that they've set up
that they've set up
theirs and you get one
reward. It it it's kind of down to like
reward. It it it's kind of down to like
an entropy thing at some point because
an entropy thing at some point because
it's like it has to find the
it's like it has to find the
goal, but if it's having to find it and
goal, but if it's having to find it and
it's hitting walls the whole time
it's hitting walls the whole time
getting there, it it tends to find it to
getting there, it it tends to find it to
be kind of a random luck event. Have you
be kind of a random luck event. Have you
seen how Puffer handles random luck
seen how Puffer handles random luck
events?
This is kind of the best that there is
This is kind of the best that there is
in RL right
in RL right
now with this maze
now with this maze
finding. Like we're pretty good at that.
finding. Like we're pretty good at that.
This kind of just works out of the box.
This kind of just works out of the box.
Look, it actually even solves this one.
Look, it actually even solves this one.
Like that's why I feel like this
Like that's why I feel like this
shouldn't be a challenging it problem.
shouldn't be a challenging it problem.
It shouldn't.
cuz the environment's fast enough where
cuz the environment's fast enough where
it should be able to
it should be able to
just get there. You would think it's
just get there. You would think it's
possible the hypers are just bad. I
possible the hypers are just bad. I
don't know. Let's see what your hypers
don't know. Let's see what your hypers
are. I mean, they're just default
are. I mean, they're just default
hypers, I think. I mean, oh, see if that
hypers, I think. I mean, oh, see if that
is true.
Your learning rate is your learning rate
Your learning rate is your learning rate
is 5x lower than mine.
What about
What about
grid? We
grid? We
do 05 for
do 05 for
grid. But in grid, we have a way bigger
grid. But in grid, we have a way bigger
policy than you have.
policy than you have.
Why is your entropy coefficient?
Hey, no mind the entropy coefficient.
Hey, no mind the entropy coefficient.
I don't know. We just It's not even a
I don't know. We just It's not even a
fully tuned run is the thing. I kind of
fully tuned run is the thing. I kind of
just threw partial defaults on stuff and
just threw partial defaults on stuff and
kind of so everything.
That's the crazy thing. It's like we're
That's the crazy thing. It's like we're
not even remotely close to like this is
not even remotely close to like this is
not even my final form, right?
Let me try and link you as well.
Let me try and link you as well.
Uh previous runs that I've gotten
to I'm going to just like make the
to I'm going to just like make the
policy bigger after this.
policy bigger after this.
Um, it looks like one of the runs where
Um, it looks like one of the runs where
I got to 99 pretty quickly, or at least
I got to 99 pretty quickly, or at least
relatively quickly speaking, was with a
relatively quickly speaking, was with a
kneeling on.
kneeling on.
Yeah, this has a kneeling on
Yeah, this has a kneeling on
with a higher default learning rate.
with a higher default learning rate.
Yeah, this is like 5x too low. I think I
Yeah, this is like 5x too low. I think I
just had the original one that you had
just had the original one that you had
the 025 when I had purely the original
the 025 when I had purely the original
defaults. Mhm. It got there
defaults. Mhm. It got there
in 15 minutes. In 15
in 15 minutes. In 15
minutes. Oh, but you were using ultra
minutes. Oh, but you were using ultra
slow version. Yeah. I mean, maybe it'll
slow version. Yeah. I mean, maybe it'll
be
be
like five minutes or something.
like five minutes or something.
Five minutes. Still slow.
I did the maze policy trained in 90
I did the maze policy trained in 90
seconds and it's bigger.
seconds and it's bigger.
I am all here if you're able to get this
I am all here if you're able to get this
to go to the the
to go to the the
902. Oh, I'll definitely be able to.
902. Oh, I'll definitely be able to.
It's just a matter of
It's just a matter of
um I mean, ideally I get this ideally I
um I mean, ideally I get this ideally I
want to get this merged onto I know it's
want to get this merged onto I know it's
a pain in the ass to keep up with my
a pain in the ass to keep up with my
release branches, but it does make it
release branches, but it does make it
easier to test Um
easier to test Um
I mean for a while you said to just not
I mean for a while you said to just not
touch the new dev branch for a while
touch the new dev branch for a while
too. Yeah, I think also was that around
too. Yeah, I think also was that around
when because I knew I was going to be
when because I knew I was going to be
gone for a week and wasn't going to be
gone for a week and wasn't going to be
able to help you either. Yeah, it so
able to help you either. Yeah, it so
this is just like, hey, I just merged
this is just like, hey, I just merged
it. I'm going to throw this in your
it. I'm going to throw this in your
direction.
direction.
We will see what uh what magic I can
We will see what uh what magic I can
apply to this.
It does not seem to be doing 99 or
It does not seem to be doing 99 or
whatever. It seems to be stuck at 80
whatever. It seems to be stuck at 80
something.
It's probably because the learning rate
It's probably because the learning rate
there. I mean that that was just a
there. I mean that that was just a
recent learning rate I just dropped on
recent learning rate I just dropped on
there. If you put it back to the the
there. If you put it back to the the
original 1025, it probably can solve
original 1025, it probably can solve
it. Okay. So, can I
it. Okay. So, can I
um Yeah, fine. We'll do 25. We'll do one
um Yeah, fine. We'll do 25. We'll do one
more experiment on this. But then what
more experiment on this. But then what
about the This is with the freaking
about the This is with the freaking
collisions off like correct.
collisions off like correct.
It's kind of ridiculous.
It's kind of ridiculous.
Yeah. It's lame. Yeah.
Yeah. It's lame. Yeah.
And this should just be solved by now.
And this should just be solved by now.
Um,
Um,
with collisions on one of the things of
with collisions on one of the things of
a recent run I got, but it took a while.
a recent run I got, but it took a while.
I just put it in the chat was this run.
I just put it in the chat was this run.
Yeah, if you have existing experiments,
Yeah, if you have existing experiments,
I'm actually going to be able to give
I'm actually going to be able to give
you feedback on stuff. Let me go
find Are you
slow8? Why is there so this is with
slow8? Why is there so this is with
collisions? That's with collisions. So
collisions? That's with collisions. So
score, which is you the percentage of
score, which is you the percentage of
time that the agents reach their goal,
time that the agents reach their goal,
give collision rate and then off-road
give collision rate and then off-road
rate. Your collision rate goes down,
rate. Your collision rate goes down,
right? But it's not as good as theirs.
right? But it's not as good as theirs.
Theirs is like less than 1%. Yeah, but
Theirs is like less than 1%. Yeah, but
you're not solving the freaking task
you're not solving the freaking task
yet, man.
Yeah, but there's also got there at a
Yeah, but there's also got there at a
time where in terms of the steps would
time where in terms of the steps would
have already achieved it because they
have already achieved it because they
have a bunch of annoying policy
have a bunch of annoying policy
differences
differences
though. They've got like a bunch of
though. They've got like a bunch of
layer norms and weird stuff.
layer norms and weird stuff.
True, but should it not just do? No,
True, but should it not just do? No,
it'll be we got to sweep stuff and it's
it'll be we got to sweep stuff and it's
like, okay, you're you're now operating
like, okay, you're you're now operating
within like a margin of like fiddly
within like a margin of like fiddly
stuff is possible and just like run more
stuff is possible and just like run more
experiments. Um, like get this thing be
experiments. Um, like get this thing be
first, then we'll worry about whether
first, then we'll worry about whether
this thing actually is not there still.
this thing actually is not there still.
Because if you look at the time, I mean,
Because if you look at the time, I mean,
that's like an hour, but even then,
that's like an hour, but even then,
yeah, it's an hour cuz it's freaking
yeah, it's an hour cuz it's freaking
slow. This is less than a tenth of the
slow. This is less than a tenth of the
speed of our other
speed of our other
Ms. This should This would be 6 minutes.
Ms. This should This would be 6 minutes.
True.
True.
We got to fix that
We got to fix that
I mean, this is not even async
I mean, this is not even async
right
right
here. I I just did this. I got I This is
here. I I just did this. I got I This is
2.6x the speed of this run, and I didn't
2.6x the speed of this run, and I didn't
even do
async, right?
Yeah.
Yeah.
So, I mean, we this should be able to be
So, I mean, we this should be able to be
something reasonable. And then also, we
something reasonable. And then also, we
can play around. I'd be happy if it was
can play around. I'd be happy if it was
in like the 600 to 750 range at this
in like the 600 to 750 range at this
point. But, I mean, we Your obs are
point. But, I mean, we Your obs are
freaking like the thing is the obs are
freaking like the thing is the obs are
just big.
just big.
If we can get this version to
If we can get this version to
a successful result, I'm very confident
a successful result, I'm very confident
we can kill a lot of the obs and
we can kill a lot of the obs and
probably get something comparable. Okay,
probably get something comparable. Okay,
let's then let's do
let's then let's do
this. Got boxes. Let's throw some stuff
this. Got boxes. Let's throw some stuff
at things. All right, let's see what we
at things. All right, let's see what we
have in our
uh not this one. Where did the GP drive
uh not this one. Where did the GP drive
go?
Yeah. Okay.
Yeah. Okay.
So, that's that doesn't actually
help. That doesn't actually help.
Okay. So, input size to the RNN's got to
Okay. So, input size to the RNN's got to
be
be
512.
512.
512. Well, let's let's get this to run.
512. Well, let's let's get this to run.
And we're gonna like let's actually get
And we're gonna like let's actually get
a real
a real
policy because okay when I was doing
policy because okay when I was doing
although not the smartest approach the
although not the smartest approach the
8x cloning on a single core this was the
8x cloning on a single core this was the
policy that I
policy that I
got I just linked to you in chat and it
got I just linked to you in chat and it
was a pretty smooth train curve.
What did what was
What did what was
this? This is the one that I that is uh
this? This is the one that I that is uh
pretty much default params
pretty much default params
um but with the 8x
um but with the 8x
clone on one
clone on one
core. Weird.
I guess it's possible there's a
I guess it's possible there's a
multipprocessing difference. I haven't
multipprocessing difference. I haven't
seen it on anything else.
Okay, here's your thing running at
Okay, here's your thing running at
basically the exact same speed as
basically the exact same speed as
before.
before.
Um, but with a 2 million parameter
policy. How was it running at the same
policy. How was it running at the same
speed?
speed?
You're completely freaking bound by M's
You're completely freaking bound by M's
and communication and This is
and communication and This is
not the right one, I don't think,
not the right one, I don't think,
though, because it doesn't this doesn't
though, because it doesn't this doesn't
look
look
right. What's What's going on with
right. What's What's going on with
this? Not 84 score, right? I'm looking
this? Not 84 score, right? I'm looking
at it right
here. Not this either.
Where's my freaking run? Did I not I
Where's my freaking run? Did I not I
guess it's not on Neptune. Yeah. Okay.
guess it's not on Neptune. Yeah. Okay.
So, 4 at 10
mil. Oh, that might be still be
mil. Oh, that might be still be
comparable.
You have zero reward for collision, zero
You have zero reward for collision, zero
off-road.
off-road.
Did you want to reset your learning rate
Did you want to reset your learning rate
to the default?
to the default?
No, this is what we use for this size
policy. So, here's your next train.
policy. So, here's your next train.
Where is
Where is
it? Okay, there it is.
See what this does. Does my torch even
See what this does. Does my torch even
use the hidden size variable? Do I not
use the hidden size variable? Do I not
just use input size on everything? No,
just use input size on everything? No,
you use it. You use hidden
size. You do use it. I checked.
Okay. I did it for the shared layer at
Okay. I did it for the shared layer at
the very end. Yeah. Which is all because
the very end. Yeah. Which is all because
then that goes into the main network,
then that goes into the main network,
right?
I mean, I could like there are like
I mean, I could like there are like
several improvements I could make to
several improvements I could make to
this as
this as
well potentially.
Okay. I mean, this is doing something,
Okay. I mean, this is doing something,
right?
potentially. Let's see what other things
potentially. Let's see what other things
you have going on
here. Got learning rate
here. Got learning rate
set batch size. batch
size. Have you tried Have you messed
size. Have you tried Have you messed
with gamma lambda at all?
with gamma lambda at all?
Not beyond me just having a sweep a
Not beyond me just having a sweep a
while back ago.
while back ago.
What gamma and lambda did you get out of
What gamma and lambda did you get out of
it?
it?
Um, pull up my
Um, pull up my
sweep cuz the default gamma is really
sweep cuz the default gamma is really
freaking high.
This is doing way better though. You
This is doing way better though. You
see,
see,
uh, it looks like my highest gamma on
uh, it looks like my highest gamma on
that best run was fairly low. Actually,
that best run was fairly low. Actually,
it was
it was
point Never mind. I was looking at the
point Never mind. I was looking at the
wrong uh.99 and 0.987.
wrong uh.99 and 0.987.
Okay. So, that's not that far off of
Okay. So, that's not that far off of
what we have. That's
fine. I think default is
0.995. I'm hoping this just gives us a
0.995. I'm hoping this just gives us a
better rain
better rain
curve. It should just get to
curve. It should just get to
0.99. Mhm. If with the additional
0.99. Mhm. If with the additional
network capacity it doesn't, then
network capacity it doesn't, then
there's going to be some something
there's going to be some something
weird.
and these offsets in here haven't
and these offsets in here haven't
changed,
right? These should still be up to date.
I don't think anything should have
I don't think anything should have
changed
from any of that stuff.
I did notice my active agents count
I did notice my active agents count
changed fairly recently with that's the
changed fairly recently with that's the
other thing is we're not masking stuff
other thing is we're not masking stuff
at all. Like the thing that made the GPU
at all. Like the thing that made the GPU
drive uh their GPU drive stuff work very
drive uh their GPU drive stuff work very
very well was like the masked
very well was like the masked
No, this has mask in right now. Yeah,
No, this has mask in right now. Yeah,
but our code doesn't fix like doesn't
but our code doesn't fix like doesn't
use it correctly in the new version.
use it correctly in the new version.
Oh, yeah. Oh, in the latest dev version.
Oh, yeah. Oh, in the latest dev version.
know what you're saying. Mhm. Uh
this is going to be massively easier if
this is going to be massively easier if
we just respawn the cars. I'm
we just respawn the cars. I'm
telling you,
telling you,
and then just have them try and avoid
and then just have them try and avoid
not spawning on top of a car that's
not spawning on top of a car that's
where in the path of where another car
where in the path of where another car
is.
is.
Don't even bother doing that. Literally
Don't even bother doing that. Literally
just like cuz they they don't bounce off
just like cuz they they don't bounce off
each other. They just get a negative
each other. They just get a negative
reward. Right. Correct. Okay. completely
reward. Right. Correct. Okay. completely
ignore the fact that that can happen.
ignore the fact that that can happen.
Respawn the cars where they're supposed
Respawn the cars where they're supposed
to start whenever they either get to
to start whenever they either get to
their objective or or
their objective or or
collide. So collide equals negative
collide. So collide equals negative
reward and respawn.
Okay. Guarantee you it's so much it's
Okay. Guarantee you it's so much it's
going to be so much easier.
All right. Well, that's an easy change.
All right. Well, that's an easy change.
Yeah, it's not that hard of a change.
Yeah, it's not that hard of a change.
And it's like, well, it's not realistic.
And it's like, well, it's not realistic.
Well, it's not realistic to have the
Well, it's not realistic to have the
cars freaking phase through each other
cars freaking phase through each other
either, right? It's like arguably this
either, right? It's like arguably this
is more realistic cuz if you've crashed,
is more realistic cuz if you've crashed,
you've already screwed up.
Okay. Okay. I'll take that logic. Yes.
Okay. Okay. I'll take that logic. Yes.
And now here, uh, we are doing better
And now here, uh, we are doing better
than before.
So, yeah, it took me three experiments
So, yeah, it took me three experiments
to fix this mostly.
And the way that I knew what to do is
And the way that I knew what to do is
because I just did the exact same thing
because I just did the exact same thing
that worked on every other
environment. That's all I
environment. That's all I
did. I should try this on breakout to be
did. I should try this on breakout to be
fair. I have not done that
fair. I have not done that
yet. Bigger network to see if I can
yet. Bigger network to see if I can
install
install
it.
So, I don't know if we're getting N9 out
So, I don't know if we're getting N9 out
of this. We will see. We're definitely
of this. We will see. We're definitely
doing better than before.
But hey, look, this is like
But hey, look, this is like
substantially better than before. I cut
substantially better than before. I cut
your error rate in half pretty
much. Assuming this gets a little bit
much. Assuming this gets a little bit
better than this. When is gym stream?
better than this. When is gym stream?
Gymstream is between all other things
Gymstream is between all other things
I'm doing while streaming. I just get up
I'm doing while streaming. I just get up
and use equipment. But you will see many
and use equipment. But you will see many
pieces of equipment be delivered over
pieces of equipment be delivered over
the next few
the next few
weeks. We have, I think, two orders that
weeks. We have, I think, two orders that
should be coming in either end of this
should be coming in either end of this
week, start of next week, and then
week, start of next week, and then
there's a big order that should be
there's a big order that should be
coming in in a few weeks.
And then the thing I'm still waiting on
And then the thing I'm still waiting on
is terrace to go down so I can order all
is terrace to go down so I can order all
of the servers for the racks behind
Okay. So, I'm trying to think how I give
Okay. So, I'm trying to think how I give
this to I think I just push this to a
this to I think I just push this to a
new branch for
you. That sound good. I just pushed this
you. That sound good. I just pushed this
to a new branch for you. You can like
to a new branch for you. You can like
just make those changes, push to this
just make those changes, push to this
branch and see that it solves
branch and see that it solves
everything.
I suspect the encoder layer should also
I suspect the encoder layer should also
probably be bigger.
you're running these on. Yeah, you have
you're running these on. Yeah, you have
at least eight cores to run stuff
at least eight cores to run stuff
on. So, yeah, there you
on. So, yeah, there you
go. That ought to be decent for you.
still doesn't get to max. But like just
still doesn't get to max. But like just
fix the masking
thing. Be right back.
Spencer.
Oh, he disappeared.
Sorry, I had to take a quick phone call.
Sorry, I had to take a quick phone call.
Mhm. Um, okay. So, you pushed up to
Mhm. Um, okay. So, you pushed up to
Huffer Drive GitHub
Huffer Drive GitHub
Huffer Drive branch. It actually gets
Huffer Drive branch. It actually gets
89%.
89%.
Okay.
Okay.
It looks like it's still doing a little
It looks like it's still doing a little
bit of stuff.
bit of stuff.
So, turn off
um
um
masking, turn on uh
masking, turn on uh
respawning and take it from there.
respawning and take it from there.
So, when they collide or reach the
So, when they collide or reach the
goal, they should
goal, they should
respawn at the start. If they hit the
respawn at the start. If they hit the
goal, they get the plus goal reward. If
goal, they get the plus goal reward. If
they collide, they get the minus collide
they collide, they get the minus collide
reward. Yeah, sure. So, run
reward. Yeah, sure. So, run
that and you should just
that and you should just
solve. Like, it's an inf it's a pure
solve. Like, it's an inf it's a pure
infrastructure limitation. The old
infrastructure limitation. The old
infrastructure could handle this, but
infrastructure could handle this, but
the new infrastructure is like
the new infrastructure is like
dramatically better algorithmically.
Okay. Um, I can do that. And then
Okay. Um, I can do that. And then
you want me to sit on the call with
you want me to sit on the call with
these with the upcoming call with the
these with the upcoming call with the
415 one? Yeah, we can tell them just
415 one? Yeah, we can tell them just
like to make this thing quick.
And then um after that, do we want to
And then um after that, do we want to
keep working on this or uh can you How
keep working on this or uh can you How
long is it going to take you to make
long is it going to take you to make
those changes?
I don't think it should take me any time
I don't think it should take me any time
at all, honestly. All right, do that
at all, honestly. All right, do that
real quick. I'm go use the restroom. Go
real quick. I'm go use the restroom. Go
do that stuff real quick and then we'll
do that stuff real quick and then we'll
I'll start working on this with you as
I'll start working on this with you as
soon as you have that stuff ready
soon as you have that stuff ready
because I think it's like this version
because I think it's like this version
it's just you're fighting the
it's just you're fighting the
infrastructure and I don't want to be
infrastructure and I don't want to be
wasting our time running experiments
wasting our time running experiments
when it's like going to be so so so much
when it's like going to be so so so much
easier. So this thing it looks like it's
easier. So this thing it looks like it's
crashing now.
crashing now.
Uh which is like it's actually something
Uh which is like it's actually something
I have to deal with with the analing. I
I have to deal with with the analing. I
figured it out. But this got to 91 92
figured it out. But this got to 91 92
before that. So, okay. Well, um yeah,
before that. So, okay. Well, um yeah,
just go ahead and just um I don't know.
just go ahead and just um I don't know.
Are you hopping on a Google call? What
Are you hopping on a Google call? What
are you doing? Are you paying?
are you doing? Are you paying?
Whatever it is, I'll get you an invite.
Whatever it is, I'll get you an invite.
All right, sounds good. And I'll just
All right, sounds good. And I'll just
send you on Discord. Sounds good. All
send you on Discord. Sounds good. All
right. See you,
right. See you,
Spencer.
Spencer.
Cool. All right. So, uh here's the uh
Cool. All right. So, uh here's the uh
the plan, folks.
the plan, folks.
I gotta go take a call in a few.
I gotta go take a call in a few.
Um, oh, we have quite a few folks on
Um, oh, we have quite a few folks on
here. Hey everyone on Twitch. If you
here. Hey everyone on Twitch. If you
haven't been around here before,
haven't been around here before,
uh, I do hyper reinforcement learning
uh, I do hyper reinforcement learning
dev. It's all open source. It's all
dev. It's all open source. It's all
free. You can see a bunch of demos at
free. You can see a bunch of demos at
puffer.ai. And, uh, you know, Spencer's
puffer.ai. And, uh, you know, Spencer's
just a collaborator who came in with no
just a collaborator who came in with no
RL experience. That could be you. you're
RL experience. That could be you. you're
interested in getting
interested in getting
involved. If you want to help me out for
involved. If you want to help me out for
free, just star the GitHub. Really helps
free, just star the GitHub. Really helps
when we get stars on GitHub. Uh and you
when we get stars on GitHub. Uh and you
can join the Discord to get involved
can join the Discord to get involved
with
with
dev. Cool. So, here's the plan.
dev. Cool. So, here's the plan.
Um we're going to keep fixing GPU drive
Um we're going to keep fixing GPU drive
stuff today. Driving sim. Actually, I
stuff today. Driving sim. Actually, I
can show this off real quick. Why
can show this off real quick. Why
not? We have the EVEL, I think, working,
not? We have the EVEL, I think, working,
right?
Yeah. So, here's the
sim. Pretty
sim. Pretty
cool.
cool.
Um, so the plan here is going to be to
Um, so the plan here is going to be to
fix this with Spencer today. We also
fix this with Spencer today. We also
have hyperparam tuning algorithm stuff
have hyperparam tuning algorithm stuff
to
to
fix. That's my alarm to get ready for
fix. That's my alarm to get ready for
meeting. Um, we're going to do all that.
meeting. Um, we're going to do all that.
I got to
I got to
take a quick meeting and then I'll be
take a quick meeting and then I'll be
back for probably an hour after that
back for probably an hour after that
before 6 and then I should be back after
before 6 and then I should be back after
dinner for a little bit more work things
dinner for a little bit more work things
pending and then I'm pretty much live
pending and then I'm pretty much live
all day every day otherwise. So, uh,
all day every day otherwise. So, uh,
yeah, thanks for tuning in
