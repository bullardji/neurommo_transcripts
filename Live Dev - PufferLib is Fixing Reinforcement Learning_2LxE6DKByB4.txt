Kind: captions
Language: en
Hey, we are
Hey, we are
live.
Hi. Quite a lot to do this
week. Get Reream
week. Get Reream
open and uh we'll go through some of the
open and uh we'll go through some of the
experiments that have run overnight to
experiments that have run overnight to
start with.
and we'll see where we go from
there. Looks like they all ran correctly
there. Looks like they all ran correctly
this
time. Start with Adam.
about 44 second
about 44 second
solve which is better than
solve which is better than
before for
before for
Adam. That's
Adam. That's
solid. That is
solid. Any interesting
solid. Any interesting
uh interesting bits with that? I see we
uh interesting bits with that? I see we
have oh we have higher value function
coefficients. We've got some higher
coefficients. We've got some higher
entropy a little
entropy a little
bit higher BPT. So yeah the uh it's
bit higher BPT. So yeah the uh it's
use all the new uh the new
use all the new uh the new
horizons or the new maximums I set on
horizons or the new maximums I set on
some of these hyperparameters.
some of these hyperparameters.
It's an important thing is um if you're
It's an important thing is um if you're
doing sweeps and you see it butting up
doing sweeps and you see it butting up
the edge of the range of what you've
the edge of the range of what you've
allowed, got to increase the
range. Epsilon doesn't seem to do
range. Epsilon doesn't seem to do
much.
Cool. So now exact same thing but with
Cool. So now exact same thing but with
muon.
31 seconds and down there's a
31 seconds and down there's a
24. It's pretty well a 30 second
24. It's pretty well a 30 second
solve. Definitely
better. That's pretty
nice. I think we will just look
nice. I think we will just look
at 2561.
That's a clean RL
That's a clean RL
curve. That is solid.
You kind of wonder if at the end
um it doesn't
um it doesn't
get it's a little shallower. You almost
get it's a little shallower. You almost
wonder if I want to start sweeping coine
wonder if I want to start sweeping coine
and kneeling params. That would be a bit
and kneeling params. That would be a bit
much.
much.
But you're pretty well solved in 30
seconds. This is a 78 million step run.
Uh, no. This is the final learning
Uh, no. This is the final learning
rate. Don't worry about
rate. Don't worry about
that. 4096 total
that. 4096 total
m, which is what you would expect for a
m, which is what you would expect for a
very efficient run. It's
perfect. Let's look at some of these
perfect. Let's look at some of these
hypers.
hypers.
So I think the default is 0.9 here
So I think the default is 0.9 here
and.999. So actually very close to the
and.999. So actually very close to the
defaults. Adam epsilon has gone all the
defaults. Adam epsilon has gone all the
way
way
down. That's
down. That's
interesting. Neiling the learning rate.
interesting. Neiling the learning rate.
Yes, it increased the maximum batch
Yes, it increased the maximum batch
size. That means I have to up this
size. That means I have to up this
number yet again.
number yet again.
Horizon. Let's actually get the
Horizon. Let's actually get the
um let's get the config window open so I
um let's get the config window open so I
can like tweak some of these
live. This is a really nice result.
Okay. So, for sweep ranges
Okay. So, for sweep ranges
here, I set a max of
here, I set a max of
64 and go up to
64 and go up to
128. I don't know if that will create
128. I don't know if that will create
invalid
shouldn't create invalid uh invalid
shouldn't create invalid uh invalid
settings. So, I think that's
settings. So, I think that's
good. Bat size actually has to go up as
well. It's at the upper end of this. So,
well. It's at the upper end of this. So,
this is
one. Yeah.
Do we increase the
Do we increase the
mean? Think we do increase the
mean. Adam epsilon is
uh is it
Add a couple zeros in there. I think you
Add a couple zeros in there. I think you
can actually just do one
can actually just do one
e minus 12 or
e minus 12 or
whatever. We'll leave it for
now. What else has been swept here?
now. What else has been swept here?
Okay, interestingly, we had a very high
Okay, interestingly, we had a very high
entropy coefficient before. Um, but now
entropy coefficient before. Um, but now
it is not anywhere near that. So, I
it is not anywhere near that. So, I
guess it just found a different
guess it just found a different
setting. Lambda gamma within normal
setting. Lambda gamma within normal
ranges I would
say. Yeah. 9999. Okay. So, within normal
say. Yeah. 9999. Okay. So, within normal
ranges, mini batch size of 8192. I think
ranges, mini batch size of 8192. I think
that's my default.
And the value function coefficient is
And the value function coefficient is
[Music]
2.17 but max grad norm. Did I see that
2.17 but max grad norm. Did I see that
in there? 0.38. So it's interesting that
in there? 0.38. So it's interesting that
it doesn't always find oh wait here
it doesn't always find oh wait here
there's also I missed the learning rate
there's also I missed the learning rate
is very high. So it's interesting it
is very high. So it's interesting it
doesn't always find like the exact same
doesn't always find like the exact same
parameters. That kind of means that
parameters. That kind of means that
either there are like multiple good
either there are like multiple good
regions or that maybe some of these are
regions or that maybe some of these are
just stable across very wide ranges
just stable across very wide ranges
though. I think it's likely the
though. I think it's likely the
former. Okay, let's get these
former. Okay, let's get these
into let's get these into
into let's get these into
breakout. Make sure this
replicates. I'll post this as well cuz
replicates. I'll post this as well cuz
this is a cool result.
You see, one of my contributors has
You see, one of my contributors has
gotten Path of
gotten Path of
Exile. Chat's not up,
Exile. Chat's not up,
FYI. My bad. Morning. Muan seems faster
FYI. My bad. Morning. Muan seems faster
with Breakout at least.
with Breakout at least.
Yep. It's uh I think Muan is going to be
Yep. It's uh I think Muan is going to be
just a good addition overall. How was
just a good addition overall. How was
your run yesterday? Run was pretty good.
your run yesterday? Run was pretty good.
Did about six miles with my
Did about six miles with my
dad. We had to stop for something after
dad. We had to stop for something after
four miles, but then we went fast for
four miles, but then we went fast for
the last two, so it was
the last two, so it was
good. Went to the gym after that.
good. Went to the gym after that.
Haven't been to that gym in a while.
Haven't been to that gym in a while.
I've never been into their big
I've never been into their big
bodybuilding
bodybuilding
section. And
section. And
uh it's actually like a ridiculously
uh it's actually like a ridiculously
ridiculously well equipped gym. It's
ridiculously well equipped gym. It's
like all of the best machines on the
like all of the best machines on the
market and it with a $30 membership.
market and it with a $30 membership.
It's
crazy. I was there doing a little bit of
crazy. I was there doing a little bit of
reconnaissance trying to figure out what
reconnaissance trying to figure out what
I want to
buy. Found a few awesome things. No, I
buy. Found a few awesome things. No, I
am buying equipment cuz this gym is here
am buying equipment cuz this gym is here
in Florida. Equipment's for Maryland.
Yeah, it's like 30 bucks a month and
Yeah, it's like 30 bucks a month and
like it's it's four separate gyms in one
like it's it's four separate gyms in one
gym with like I don't know at least a
gym with like I don't know at least a
hundred different machines. They have
hundred different machines. They have
like probably every Atlantis
like probably every Atlantis
Prime Arsenal
Prime Arsenal
um they've got like every good machine
um they've got like every good machine
that you would want to see. Are you
that you would want to see. Are you
moving or I seasonally? It's going to be
seasonal. Florida's my resident still
seasonal. Florida's my resident still
and I'm here in the
winter. Need a summer home in Colorado.
Yeah, Florida in the summer is just not
Yeah, Florida in the summer is just not
a fun time at
a fun time at
all.
Generally, just really
isn't. So, I spend um the plan is winter
isn't. So, I spend um the plan is winter
in
in
like a couple months in the winter, two,
like a couple months in the winter, two,
three months in the winter here. Uh you
three months in the winter here. Uh you
know, few months in the summer in
know, few months in the summer in
California, depending on what I'm doing
California, depending on what I'm doing
there, and then uh fall and spring in
there, and then uh fall and spring in
uh in Maryland, this is going to be the
uh in Maryland, this is going to be the
most likely
most likely
outcome. And the Maryland one is going
outcome. And the Maryland one is going
to be the best outfitted for all my
to be the best outfitted for all my
work. So, we have the most space by a
work. So, we have the most space by a
mile.
Yep. That it
is. There's a reason I'm not staying in
is. There's a reason I'm not staying in
California year
California year
round. Isn't that
round. Isn't that
funny? That's how badly they [ __ ]
funny? That's how badly they [ __ ]
themselves with uh the
themselves with uh the
current with what they're doing
current with what they're doing
currently.
currently.
If they had no state tax, it'd be pretty
If they had no state tax, it'd be pretty
easy. Like everyone would just be
there.
Moving.
Moving.
Oh, I'm with my family here and kind of
Oh, I'm with my family here and kind of
in Maryland. Not
in Maryland. Not
quite. They paid double for gas. Yeah. I
quite. They paid double for gas. Yeah. I
don't I It's kind of sad. I don't know
don't I It's kind of sad. I don't know
what they're
doing. The economics are totally
doing. The economics are totally
screwed. Um, at least I will say Palo
screwed. Um, at least I will say Palo
Alto is still like it's nice
Alto is still like it's nice
there. SF is a hell hole. Like with some
there. SF is a hell hole. Like with some
of the stuff that's happened in SF
of the stuff that's happened in SF
lately. Uh, I don't think I'm even
lately. Uh, I don't think I'm even
taking business meetings in SF anymore.
taking business meetings in SF anymore.
Like I think I'm just not going to SF.
Like I think I'm just not going to SF.
It's like NAS screw
It's like NAS screw
that. Y'all can come down to Mountain
that. Y'all can come down to Mountain
View or Palo Alto where we're
civilized is run by the VC car. It's
civilized is run by the VC car. It's
certainly run by a
certainly run by a
cartel. I don't know about the VC
cartel. I don't know about the VC
one. You got the first part right.
But yeah, when founders are getting beat
But yeah, when founders are getting beat
over the head with metal pipes, no thank
over the head with metal pipes, no thank
you. I have worked too hard to live
you. I have worked too hard to live
somewhere or to even be somewhere where
somewhere or to even be somewhere where
founders get beat over the head with
founders get beat over the head with
metal
metal
pipes. No thank
pipes. No thank
you. I will be literally anywhere
you. I will be literally anywhere
else. That sounds like a smarter thing
else. That sounds like a smarter thing
to do.
especially in AI. I didn't realize value
especially in AI. I didn't realize value
co function could go above. It's a
co function could go above. It's a
coefficient. It's not like a logic space
coefficient. It's not like a logic space
thing, right? It's just a multiple of a
thing, right? It's just a multiple of a
loss. And it couldn't before in sweeps.
loss. And it couldn't before in sweeps.
I increased the range because I noticed
I increased the range because I noticed
it was always up against
one. That's part of one of the things.
one. That's part of one of the things.
Uh I don't know if you were here for
Uh I don't know if you were here for
when I started stream and said that, but
when I started stream and said that, but
when you see that your sweeps are
when you see that your sweeps are
pushing up against one end of the range,
pushing up against one end of the range,
you got to increase the
you got to increase the
range. You see? Now, obviously, you
range. You see? Now, obviously, you
don't go, "Oh, well, what if we just
don't go, "Oh, well, what if we just
make gamma over one?" Yeah, that doesn't
make gamma over one?" Yeah, that doesn't
make any sense.
I haven't swept any of the clip
I haven't swept any of the clip
coefficients in a while either. We might
coefficients in a while either. We might
go back to doing that again. But yeah,
go back to doing that again. But yeah,
this is kind of cool. Back size 500k
this is kind of cool. Back size 500k
breakout par amps. We can get rid of
breakout par amps. We can get rid of
these now.
That's pretty damn cool,
right? Why is this one 55
seconds? Oh, hold. Hold on.
seconds? Oh, hold. Hold on.
cuz I just ran it for longer to make
cuz I just ran it for longer to make
sure it would be stable. Let's run it a
sure it would be stable. Let's run it a
couple times to see uh if it's, you
couple times to see uh if it's, you
know, needs any tweak. But yeah, this is
know, needs any tweak. But yeah, this is
what I'm saying, right? Like once you
what I'm saying, right? Like once you
get everything lined up
get everything lined up
correctly. Yeah, this is
breakout. I mean, what we're doing here,
breakout. I mean, what we're doing here,
you know, we're kind of using the
you know, we're kind of using the
breakout speedrun as just a benchmark
breakout speedrun as just a benchmark
for general algorithm stuff.
for general algorithm stuff.
It's not like I'm hacking on the reward
It's not like I'm hacking on the reward
function or anything. I haven't touched
function or anything. I haven't touched
it. And we've gone down from 5 minutes
it. And we've gone down from 5 minutes
to damn near 30
seconds. And then the original breakout
seconds. And then the original breakout
like that most of the labs use takes
like that most of the labs use takes
several
hours. What were the changes that made
hours. What were the changes that made
the curves that smooth? So this is just
the curves that smooth? So this is just
running faster uh and with a
running faster uh and with a
substantially larger batch size. So
substantially larger batch size. So
that's going to prevent some of the
that's going to prevent some of the
jaggedness. But then like the big dips
jaggedness. But then like the big dips
in stuff that you were getting
in stuff that you were getting
before, better optimizer, better
before, better optimizer, better
learning rateuler,
learning rateuler,
um actually just improving the speed of
um actually just improving the speed of
some of the stuff allows it to take
some of the stuff allows it to take
advantage of larger batch sizes which
advantage of larger batch sizes which
then translates to smoother curves.
then translates to smoother curves.
Like, yeah, it's kind of magic when you
Like, yeah, it's kind of magic when you
get everything
get everything
right. It just
works. That's another run right
there. And actually, you see how there's
there. And actually, you see how there's
this little like dip, right? Like this.
this little like dip, right? Like this.
Like these dips aren't even from it
Like these dips aren't even from it
being weird. These dips are from the
being weird. These dips are from the
cosine and kneeling learning rate
cosine and kneeling learning rate
scheduling.
scheduling.
Yeah. No, this is literally compared to
Yeah. No, this is literally compared to
like original clean RL speeds. And you
like original clean RL speeds. And you
got to give them a little bit of credit
got to give them a little bit of credit
because I think you know they were doing
because I think you know they were doing
from pixels. So, okay, the net has to be
from pixels. So, okay, the net has to be
a bit bigger. But still, like the
a bit bigger. But still, like the
original
original
there, this is over 1,500 times
there, this is over 1,500 times
faster. And I think even over an
faster. And I think even over an
optimized implementation like the
optimized implementation like the
optimized clean RL or whatever which
optimized clean RL or whatever which
doesn't even have LSTM support I think
doesn't even have LSTM support I think
is like 300 times slower than
this. Like I said this is what we're
this. Like I said this is what we're
doing with RL. Okay. Now imagine this
doing with RL. Okay. Now imagine this
everywhere in RL, right? Imagine this on
everywhere in RL, right? Imagine this on
neural MMO 3 on whatever industry
neural MMO 3 on whatever industry
problem you do everywhere. And we let's
problem you do everywhere. And we let's
imagine that we also figure out the like
imagine that we also figure out the like
roughly out of the box hyperparameters
roughly out of the box hyperparameters
that you're going to get close to this
that you're going to get close to this
before you even
before you even
tune. That's RL back right there, man.
tune. That's RL back right there, man.
That's RL
back. Look at that. Little bit of
back. Look at that. Little bit of
variance. Little bit of variance. Not
variance. Little bit of variance. Not
much though.
I think we can make this even a little
I think we can make this even a little
faster. Hang
on. Yeah, cuz this agent stabs. Hold on.
This is 50 million
steps. Maybe we reduce it to
60. See how that changes the curves.
I always go a little bit above whatever
I always go a little bit above whatever
we got uh in the train run in steps cuz
we got uh in the train run in steps cuz
like even if it's this consistent,
like even if it's this consistent,
right, I'm always going to assume that
right, I'm always going to assume that
we got this run in the training, right?
we got this run in the training, right?
We got a little bit lucky. So I have to
We got a little bit lucky. So I have to
add a few steps in case we get this run
add a few steps in case we get this run
right when we actually go to do it.
Does torch compile help? Let me uh I
Does torch compile help? Let me uh I
will
will
check. Yeah. So that worked perfectly.
Not
noticeably. No noticeable
noticeably. No noticeable
difference though. Possibly, you know,
difference though. Possibly, you know,
there's like the cudigraph stuff that we
there's like the cudigraph stuff that we
could look into that could make a decent
could look into that could make a decent
difference, but there's no noticeable
difference, but there's no noticeable
difference right here with that.
linear. Yes, linear is the default
linear. Yes, linear is the default
captain that we replaced with cosine and
captain that we replaced with cosine and
cosine's better. This is insane. I
cosine's better. This is insane. I
remember training a baseline months ago.
remember training a baseline months ago.
Struggle to get five miss now 30 to 40.
Struggle to get five miss now 30 to 40.
Yeah. Isn't this
Yeah. Isn't this
cool? And look how consistent this is as
cool? And look how consistent this is as
well.
well.
Like this is not just faster, it's also
Like this is not just faster, it's also
like fundamentally this feels like
like fundamentally this feels like
stable. And you look at the hyper pram
stable. And you look at the hyper pram
and they actually make
sense. I mean, yeah, Spencer helped us
sense. I mean, yeah, Spencer helped us
get it to 5 minutes as well. It was way
get it to 5 minutes as well. It was way
longer before that.
That's
what's just see if this does
anything. I don't have remotely good
anything. I don't have remotely good
params. Let's just see if we be a little
cocky. Several hours with high variance
cocky. Several hours with high variance
down to 30 seconds with Yeah, exactly.
down to 30 seconds with Yeah, exactly.
Now, to be fair, a big chunk of the
Now, to be fair, a big chunk of the
initial Perf game there, like we had to
initial Perf game there, like we had to
cut down uh we had to go from the
cut down uh we had to go from the
original Atari M to our version that's
original Atari M to our version that's
way faster cuz the original Atari we
way faster cuz the original Atari we
could only get to run about 30,000 steps
could only get to run about 30,000 steps
per
per
second. I mean, but still, if we have to
second. I mean, but still, if we have to
run 60 million
steps, I think that's still down to like
steps, I think that's still down to like
40 minutes or whatever, uh, with the
40 minutes or whatever, uh, with the
same algorithm. And then the thing is it
same algorithm. And then the thing is it
would tune separately. Like the tuning
would tune separately. Like the tuning
would apply differently. So 40 minutes
would apply differently. So 40 minutes
would be like a high-end. It's probably
would be like a high-end. It's probably
way shorter than
way shorter than
that. And the original ends are in C.
that. And the original ends are in C.
It's just that people decided to train
It's just that people decided to train
on pixels for no damn
reason. Okay, so this is like the
reason. Okay, so this is like the
original uh pong params which are
original uh pong params which are
completely wrong at the moment, right?
completely wrong at the moment, right?
like the pong params are completely
like the pong params are completely
wrong because of all the changes that we
wrong because of all the changes that we
made and um with the new optimizer just
made and um with the new optimizer just
like throwing in muon and the like
like throwing in muon and the like
network changes and cosign and dealing
network changes and cosign and dealing
with whatever the hell hyperps are
there. It still
works. And not only does it still work,
works. And not only does it still work,
it still works with a consistent
it still works with a consistent
training curve. These little jaggies
training curve. These little jaggies
here are just like the batch size being
here are just like the batch size being
slightly smaller. The point is you don't
slightly smaller. The point is you don't
get any like massive dips and then
get any like massive dips and then
recoveries.
So yeah, that's just pong
solved. I was going to try to get it on
solved. I was going to try to get it on
neural MMO and stuff right
neural MMO and stuff right
now, but connect four is also good.
Look at
Look at
that. I think we're going to tune
that. I think we're going to tune
everything, Captain. So, I think what
everything, Captain. So, I think what
we'll do now is let's see if I can go
we'll do now is let's see if I can go
look and uh like look at the
look and uh like look at the
defaults if we can improve some of the
defaults if we can improve some of the
defaults and then see if like you know
defaults and then see if like you know
with the defaults changed if we can like
with the defaults changed if we can like
get better perf like let's see if I can
get better perf like let's see if I can
get Pong to do way better just by
get Pong to do way better just by
changing the defaults and then see if
changing the defaults and then see if
those defaults like just learn anything
those defaults like just learn anything
at all on a harder end. We'll do a lot
at all on a harder end. We'll do a lot
of this type of stuff today. And then
of this type of stuff today. And then
aside from that, the only two things I
aside from that, the only two things I
think I really need to do today, I have
think I really need to do today, I have
uh one client EN that uh needs to be
uh one client EN that uh needs to be
like integrated and we need to throw
like integrated and we need to throw
some puffer stuff on and then I have
some puffer stuff on and then I have
another client and that needs uh me to
another client and that needs uh me to
look at what the hell's wrong with the
look at what the hell's wrong with the
god awful
Python. And other than that, I think
Python. And other than that, I think
we're good. So, I have lots of time now.
we're good. So, I have lots of time now.
This week, we finished one of the uh the
This week, we finished one of the uh the
previous
previous
contracts, which is
great. So, I have a little more
time. Okay, let's look at these in
time. Okay, let's look at these in
comparison to the defaults next.
very high learning rate.
Uh, float 16 is slower for small
Uh, float 16 is slower for small
networks. I tested it. It's faster. It's
networks. I tested it. It's faster. It's
I got like a 15% f boost on neural MMO
I got like a 15% f boost on neural MMO
with a like 1 mil perm net and it was
with a like 1 mil perm net and it was
substantially slower uh on the smaller
substantially slower uh on the smaller
nets that we use normally
700k. It might be a little
faster. Uh, I wouldn't do that though
faster. Uh, I wouldn't do that though
until you've timed it, man.
Also, also I have a way to eliminate
Also, also I have a way to eliminate
copy time. Um, I don't think it works
copy time. Um, I don't think it works
until Python 3.14,
until Python 3.14,
though. Let me show you this real quick
though. Let me show you this real quick
because I thought this was kind of cool.
because I thought this was kind of cool.
I had a really productive
I had a really productive
Saturday. It was hard work. I was like
Saturday. It was hard work. I was like
grinding this stuff out on Saturday. But
grinding this stuff out on Saturday. But
uh
here I made a threading based back end
basically. So this is multi-threading
basically. So this is multi-threading
back
back
end and uh this is kind of cool because
end and uh this is kind of cool because
what you can do here is you can pass
what you can do here is you can pass
stuff in as torch tensors, right? So you
stuff in as torch tensors, right? So you
pass in torch
pass in torch
tensors and then uh on the individual
tensors and then uh on the individual
process, right? or on the thread you can
process, right? or on the thread you can
queue up the transfer directly to the
queue up the transfer directly to the
torch
torch
tensor. So you do the async uh the async
tensor. So you do the async uh the async
memory you do the memory transfers async
memory you do the memory transfers async
which I think depending on how CUDA
which I think depending on how CUDA
works under the hood should actually cut
works under the hood should actually cut
that time out
that time out
completely. Now the problem with this is
completely. Now the problem with this is
I tried to do this with the
I tried to do this with the
multipprocessing version with uh PyTorch
multipprocessing version with uh PyTorch
like shared memory tensors and uh I it's
like shared memory tensors and uh I it's
technically possible but it's really
technically possible but it's really
like a total pain in the ass because of
like a total pain in the ass because of
the way that um you you can't use
the way that um you you can't use
multiprocessing fork with uh with this
multiprocessing fork with uh with this
and we rely heavily on fork in order for
and we rely heavily on fork in order for
this to work. So really, it's just going
this to work. So really, it's just going
to be a lot easier once we get the uh
to be a lot easier once we get the uh
true threading stuff in Python
true threading stuff in Python
314. No
314. No
IPC. Um I mean, no, there's still
IPC. Um I mean, no, there's still
like there's still async shenanigans.
like there's still async shenanigans.
You can't just be totally stupid about
You can't just be totally stupid about
stuff because threads versus
stuff because threads versus
multipprocessing. Like the
multipprocessing. Like the
implementation is actually going to look
implementation is actually going to look
very very similar.
Yeah. Have you set a 2.5 release
Yeah. Have you set a 2.5 release
goal? Not
goal? Not
really. It's kind of just whenever I
really. It's kind of just whenever I
feel like we have enough stuff to merit
feel like we have enough stuff to merit
a big release. I don't like doing short
a big release. I don't like doing short
release cycles cuz like you know there's
release cycles cuz like you know there's
always going to be a certain number of
always going to be a certain number of
bugs that you have to fix with every
bugs that you have to fix with every
release and you have to do a lot of work
release and you have to do a lot of work
to like get everything back stable and
to like get everything back stable and
stuff. So, I kind of like having the
stuff. So, I kind of like having the
longer release cycles where I can really
longer release cycles where I can really
like come up with something really cool
like come up with something really cool
that'll get people excited and then, you
that'll get people excited and then, you
know, if if people want access to stuff
know, if if people want access to stuff
early, they can either very closely
early, they can either very closely
monitor the dev branch or if they're
monitor the dev branch or if they're
companies, you know, they can get a
companies, you know, they can get a
support
contract and then you basically get
contract and then you basically get
access to news on all the developments
access to news on all the developments
up to six months early.
I think that's a pretty good model. It
I think that's a pretty good model. It
saves me
saves me
work and uh you know companies get value
work and uh you know companies get value
out of it
too. I like
this. Don't don't do LLMs, folks.
this. Don't don't do LLMs, folks.
Don't do LLMs. Just say no to
LLM. Just say
no. Just say no to
laws. I like that.
Okay, first thing is what if I just do
Okay, first thing is what if I just do
this?
I it the thing is they're kind of right.
I it the thing is they're kind of right.
Like there's so much stupid hype in LLMs
Like there's so much stupid hype in LLMs
right
right
now. Yeah. Let me show you the latest
now. Yeah. Let me show you the latest
thing that I tried to use LLMs for. It's
thing that I tried to use LLMs for. It's
like I literally regret opening them
like I literally regret opening them
every single time I do.
Go find me a piece of ab equipment from
Go find me a piece of ab equipment from
one of these brands. Okay, try this.
one of these brands. Okay, try this.
Doesn't
Doesn't
exist. Just made up a piece of
exist. Just made up a piece of
equipment. Oh, look. See, I searched all
equipment. Oh, look. See, I searched all
the web pages. I'm going to go actually
the web pages. I'm going to go actually
return search results. Nope. Made it
up. And then I tried chat GPT. And guess
up. And then I tried chat GPT. And guess
what? it
uh it didn't make it up, but it gave me
uh it didn't make it up, but it gave me
a completely stupid suggestion that made
a completely stupid suggestion that made
no sense.
Yeah, exactly. And then and then you
Yeah, exactly. And then and then you
have like the absolute morons who are
have like the absolute morons who are
like, "Hey, you need to learn how to
like, "Hey, you need to learn how to
become the prompt wizard. See, I'm so
become the prompt wizard. See, I'm so
smart. I know how to type things into an
smart. I know how to type things into an
LM even though I can't write any code.
Uhoh, that doesn't look
Uhoh, that doesn't look
right.
Huh?
What object is an art form?
Well, uh, there was something happening
here is
here is
not I'd rather spend my time learning
not I'd rather spend my time learning
how to do the thing rather than learning
how to do the thing rather than learning
how to coax the LLM into figuring out a
how to coax the LLM into figuring out a
thing.
making numerical models. I don't know.
making numerical models. I don't know.
I've tried it in like various different
I've tried it in like various different
capacities in my research and it's
capacities in my research and it's
always been a waste of time. Like it's
always been a waste of time. Like it's
kind of a decent rubber duck that like
kind of a decent rubber duck that like
can kind of spit out some sort of math
can kind of spit out some sort of math
looking
looking
things. You can describe formulas and
things. You can describe formulas and
it'll write them up in Latte like really
it'll write them up in Latte like really
really nice and quick. It's kind of nice
really nice and quick. It's kind of nice
for that.
for that.
But like it can't really it just it's
But like it can't really it just it's
just just not that
smart. Report interval is 128.
I don't know. Maybe you've got a good
I don't know. Maybe you've got a good
use case,
but I think I'm doing even simpler math
but I think I'm doing even simpler math
than you and it's not that
helpful. Something is definitely screwy
helpful. Something is definitely screwy
here that
here that
um we're not getting
um we're not getting
back report results.
Oh, there it is.
What did I have before? Just like really
What did I have before? Just like really
tiny mini batch
tiny mini batch
size. This was what I had before.
Wow. But that's going to make it like
Wow. But that's going to make it like
slower wall
clock. I mean, it
clock. I mean, it
runs is probably faster, too, right?
runs is probably faster, too, right?
Like if I just do like 150
Like if I just do like 150
mil. This is probably still faster than
mil. This is probably still faster than
the
original. Let's not do checkpoint
original. Let's not do checkpoint
interval
25. GPU drive question. Does splitting
25. GPU drive question. Does splitting
each observation
each observation
modality to be
modality to be
processed independently in their own
processed independently in their own
layer make that much of a difference
layer make that much of a difference
versus one layer for all
ops? Does splitting each
observation. I think we've talked
observation. I think we've talked
something about architectures, right,
something about architectures, right,
Spencer? Because the question doesn't
Spencer? Because the question doesn't
make
sense. And this is why I don't want to
sense. And this is why I don't want to
delete
delete
this.
this.
Um, let's find another one.
What's
this? Paint online. Cool. Um, so like
this? Paint online. Cool. Um, so like
you
have
have
like self
So how do you make how does it make
So how do you make how does it make
sense to process these together? Because
sense to process these together? Because
here you have this is a
here you have this is a
vector, right? And like this needs to go
vector, right? And like this needs to go
through a linear
through a linear
layer. Okay? And then this needs to go
layer. Okay? And then this needs to go
this other thing this needs to go like
this other thing this needs to go like
through some linear layers or whatever
through some linear layers or whatever
and then needs to get like maxed
and then needs to get like maxed
right as an embedding. And then this
right as an embedding. And then this
probably needs to go through like you
probably needs to go through like you
know a CNN of some
sort and then go through a linear
sort and then go through a linear
layer. So you can't like concatenate all
layer. So you can't like concatenate all
these together and put them through the
these together and put them through the
same
same
layer, right?
layer, right?
So what's the question
here? It's not whether it makes as much
here? It's not whether it makes as much
of a difference. It's like how do you
of a difference. It's like how do you
even do it the other way? You're not
even do it the other way? You're not
going to flatten all the
data. Well, yeah, but that's kind of
data. Well, yeah, but that's kind of
like saying, okay, an image is a list of
like saying, okay, an image is a list of
floats. Why don't we use flat like why
floats. Why don't we use flat like why
don't we use linear layers for like
don't we use linear layers for like
instead of compat, right?
Do you know
why? I think we've had this conversation
why? I think we've had this conversation
before. It's a very important and
before. It's a very important and
fundamental one to understand. If
fundamental one to understand. If
not, like why do we
not, like why do we
use if you have an image,
use if you have an image,
right? Why do we use a competent instead
right? Why do we use a competent instead
of a linear layer?
It's separation and it's the same it's
It's separation and it's the same it's
the same intuition for everything. It
the same intuition for everything. It
just applies a little differently.
just applies a little differently.
Right? So the idea here is that if you
Right? So the idea here is that if you
were to learn separately a weight for
were to learn separately a weight for
each of these inputs like a linear layer
each of these inputs like a linear layer
does then you have to learn like all
does then you have to learn like all
sorts of different like you have to
sorts of different like you have to
learn a representation for here you have
learn a representation for here you have
to learn a representation here. You have
to learn a representation here. You have
to learn a representation here. Now what
to learn a representation here. Now what
a comm says is hey you probably want to
a comm says is hey you probably want to
learn the same representation over here
learn the same representation over here
right as over here. So no matter where
right as over here. So no matter where
you apply this filter to the image it's
you apply this filter to the image it's
going to do the same thing and you get
going to do the same thing and you get
this automatically just from the
this automatically just from the
structure of the network. Right? That's
structure of the network. Right? That's
why you do it. It's because you assume
why you do it. It's because you assume
that in an image it says hey you know
that in an image it says hey you know
this part of the image over here is
this part of the image over here is
generally going to behave the same as
generally going to behave the same as
over here is over here is over here
over here is over here is over here
right now you can construct a setting in
right now you can construct a setting in
which this doesn't hold true right you
which this doesn't hold true right you
can construct counter examples but
can construct counter examples but
generally this is a pretty darn good
generally this is a pretty darn good
assumption okay now the same thing with
assumption okay now the same thing with
the cars
right if you have like one two three,
right if you have like one two three,
four different cars you can see or
four different cars you can see or
entities. This is an entity encoder,
entities. This is an entity encoder,
right? What happens if I switch the
right? What happens if I switch the
positions of these
positions of these
two, right? What happens if I see the
two, right? What happens if I see the
cars in a different order? I have to
cars in a different order? I have to
learn a representation now with a flat
learn a representation now with a flat
linear layer that is robust to that. And
linear layer that is robust to that. And
that's really hard to do, right? You
that's really hard to do, right? You
have to kind of relearn the same
have to kind of relearn the same
representation many
representation many
times. But if you use an entity style
times. But if you use an entity style
encoder where you just do this in max,
encoder where you just do this in max,
then you can flip these around however
then you can flip these around however
you want, right? And it's invariant. You
you want, right? And it's invariant. You
provably will get the same
output. So that's why you do
output. So that's why you do
this. And now the thing with uh like the
this. And now the thing with uh like the
same thing with attention, right? What
same thing with attention, right? What
is attention? Attention is just a fancy
is attention? Attention is just a fancy
way of doing this this exact operation.
way of doing this this exact operation.
what I just described here. This is an
what I just described here. This is an
attentional encoder, right? A
attentional encoder, right? A
transformer is just a very fancy way of
transformer is just a very fancy way of
doing this operation, but it still has
doing this operation, but it still has
this key property of the order doesn't
this key property of the order doesn't
matter. Now, why you do this for
matter. Now, why you do this for
language is a little bit more
language is a little bit more
complicated because you also have
complicated because you also have
positional encodings. But, you know, for
positional encodings. But, you know, for
this type of case that holds true
precisely. So, very very important to
precisely. So, very very important to
understand that. And also uh we solved
understand that. And also uh we solved
breakout while I was talking which is
breakout while I was talking which is
with like a completely random asset of
with like a completely random asset of
hyperparameters and in less time than
hyperparameters and in less time than
the original. We didn't get like so this
the original. We didn't get like so this
is not even a weird graph. It's just we
is not even a weird graph. It's just we
didn't get enough like data points in
didn't get enough like data points in
it. But uh yeah so there we go. There's
it. But uh yeah so there we go. There's
breakout in a minute. Uh I think the
breakout in a minute. Uh I think the
original was breakout in 30 seconds. So
original was breakout in 30 seconds. So
we'll have to sweep this separately. But
we'll have to sweep this separately. But
it looks like just out of the box those
it looks like just out of the box those
hypers are kind of fine.
hypers are kind of fine.
Moa use one for the ordering issue. MOA
Moa use one for the ordering issue. MOA
doesn't have any sort of entity encoder.
doesn't have any sort of entity encoder.
Um MOA just has a conf
Um MOA just has a conf
encoder. It just has a com encoder, I'm
encoder. It just has a com encoder, I'm
pretty
pretty
sure. So I just packed the entities like
sure. So I just packed the entities like
I picked whatever properties I wanted
I picked whatever properties I wanted
you to be able to see of the other
you to be able to see of the other
agents and I pack them into the
agents and I pack them into the
conf. Same thing with neural MMO.
It's also a perfectly fine
representation. I did that so I wouldn't
representation. I did that so I wouldn't
have to deal with entity
encoders. Okay, so this is pretty sweet.
encoders. Okay, so this is pretty sweet.
Uh, what else can we just insta solve
Uh, what else can we just insta solve
with this?
Enduro.
This doesn't even have optimized
hypers. Easier to see. I'm going to go
hypers. Easier to see. I'm going to go
through
through
them. I'm working my way up.
So the original config here is pretty
fast but days completed is stuck at
fast but days completed is stuck at
zero.
I think this one just takes a little bit
I think this one just takes a little bit
though to uh because like the episodes
though to uh because like the episodes
are really long so you just have to
are really long so you just have to
like Yeah, it's
like Yeah, it's
tough. Past cars is also a decent one I
think. Yeah, there's days completed
think. Yeah, there's days completed
going up.
going up.
I think I got to ask B why cars pass
I think I got to ask B why cars pass
can't be the score because I think past
can't be the score because I think past
car should pretty well just tell you
car should pretty well just tell you
um what is the best
Okay. So, here's your days completed.
Okay. And now what happens if I just get
Okay. And now what happens if I just get
rid of all this?
rid of all this?
So say a 1.1
I mean, this is like the same set of
I mean, this is like the same set of
hypers from everything. Hey, how's it
hypers from everything. Hey, how's it
going,
going,
man? This is the same set of
man? This is the same set of
hypers for three environments so far or
hypers for three environments so far or
whatever. And it's like these are fine
whatever. And it's like these are fine
for everything. This is pretty darn
for everything. This is pretty darn
cool. And we haven't even fixed the GA
cool. And we haven't even fixed the GA
nonsense
yet. It's not
bad. We'll have to sweep it. But I think
bad. We'll have to sweep it. But I think
this is fine for now. I It's like It'll
this is fine for now. I It's like It'll
take off. You give it a little
longer. I mean, that
works. What do we do
works. What do we do
next? Which end? Let me
next? Which end? Let me
see.
see.
Um,
our neural MMO is going to just take
our neural MMO is going to just take
longer.
Is Spencer still here? Let's see. Tower
climb. How long does tower climb take to
climb. How long does tower climb take to
train?
Ah, we got to do the we got to take this
Ah, we got to do the we got to take this
these steps way
down 50
mil. Do you think I should be able to
mil. Do you think I should be able to
pull dev branch? I mean, if you are
pull dev branch? I mean, if you are
going to overwrite your local, I would
going to overwrite your local, I would
make sure you have that saved because
make sure you have that saved because
dev is never like guaranteed stable. But
dev is never like guaranteed stable. But
yeah, we have a whole bunch of cool
yeah, we have a whole bunch of cool
stuff in dev for
stuff in dev for
sure. Adjust the number of PLG
sure. Adjust the number of PLG
maps. All
maps. All
right. What do you think it should be,
Spencer? I
Spencer? I
tried take a few minutes to generate
tried take a few minutes to generate
them all.
It looked like it was only doing 100.
It looked like it was only doing 100.
Oh, is it
more? Isn't the C isn't the generation
more? Isn't the C isn't the generation
code in C? Why does it take so long?
You need to do some fancy
checking
online. Ah, okay. It's verifying.
That has like 50 in
there. Oh, adjust it up. I
see here. Let me get let me fix one
see here. Let me get let me fix one
thing first.
Yeah, I broke uh I broke multilayer LS
Yeah, I broke uh I broke multilayer LS
cam. Doesn't matter.
And does it start learning relatively
And does it start learning relatively
quickly or not
really? Cool. I pretty much just want to
really? Cool. I pretty much just want to
test like our new params versus whatever
test like our new params versus whatever
you swept.
I forgot we had tower climb.
I forgot we had tower climb.
Now that's a nice new
Now that's a nice new
environment for testing things with.
Um, it's whatever the it's just the
Um, it's whatever the it's just the
optimizer. Muon has some stuff set by
optimizer. Muon has some stuff set by
default.
default.
I think we're we're going to like get
I think we're we're going to like get
rid of this in uh whatever version we
rid of this in uh whatever version we
release because it's really
obnoxious, right? I think it should only
obnoxious, right? I think it should only
bother doing this stuff if you set like
bother doing this stuff if you set like
the rest of the optimization flags to
compile. Okay, so this is um your hypers
compile. Okay, so this is um your hypers
with the new
changes. You're at a million steps per
changes. You're at a million steps per
second already. So, I wouldn't be
second already. So, I wouldn't be
surprised that we underperform your
hypers. Oh, well, I didn't even change
hypers. Oh, well, I didn't even change
any of that yet, Spencer. This is just
any of that yet, Spencer. This is just
from like our general purpose
improvements. It'll go faster than this,
improvements. It'll go faster than this,
don't
worry. What is it? Rose cleared.
worry. What is it? Rose cleared.
Uh the one thing I would ask you to do
Uh the one thing I would ask you to do
is I want all of the environments to
is I want all of the environments to
have a variable score which is the thing
have a variable score which is the thing
that you optimize over if possible. I
that you optimize over if possible. I
can hack around it in the meantime. Um I
can hack around it in the meantime. Um I
like yeah I can hack around it in the
like yeah I can hack around it in the
meantime but it is way better if all the
meantime but it is way better if all the
ends have a score
variable. I think that we're going to do
variable. I think that we're going to do
that for everything. We'll go back
that for everything. We'll go back
Yeah. Yeah. Yeah. But I think like there
Yeah. Yeah. Yeah. But I think like there
you even if you just duplicate the same
you even if you just duplicate the same
variable name like I think we need to
variable name like I think we need to
have one named score so that when you
have one named score so that when you
run like a sweep or something and you
run like a sweep or something and you
set up your panels right for whatever
set up your panels right for whatever
environment you're looking at you can
environment you're looking at you can
just look at
score. So here's levels completed.
Presumably this is uh 93% of levels
[Music]
Mhm. And now let's see what happens if I
Mhm. And now let's see what happens if I
do this.
I'm going do 2048 M's as well because of
I'm going do 2048 M's as well because of
uh well because of
uh well because of
reasons. Let me see. What did you have
reasons. Let me see. What did you have
on here? Oh, no. You actually did have
on here? Oh, no. You actually did have
two M's, two
two M's, two
workers. So we can do 4096 for you.
That should have been
That should have been
faster. Unless you had a really big mini
faster. Unless you had a really big mini
batch
batch
before. Yeah, you had a big mini batch
before. Yeah, you had a big mini batch
size before, I
think. Yeah. So, uh, the one whatever
think. Yeah. So, uh, the one whatever
the 1 mill or whatever came from,
the 1 mill or whatever came from,
um, our optimizations to that is still
um, our optimizations to that is still
900k. I mean, we can probably, you know,
900k. I mean, we can probably, you know,
maybe your prams are better in this
maybe your prams are better in this
case. We'll see.
Interesting. So, it levels out a little
Interesting. So, it levels out a little
bit at 80
now. What did we screw with
now. What did we screw with
here? Probably gamma lambda the
here? Probably gamma lambda the
culprits.
Something like
that. Oh, entropy is probably or entropy
that. Oh, entropy is probably or entropy
it could
be. No, your entropy is pretty close.
Easy. Well, yeah, but I'm just doing
Easy. Well, yeah, but I'm just doing
quick little experiments anyways right
quick little experiments anyways right
now. We can run full sweep for
now. We can run full sweep for
you,
right? So, we'll leave your hypers
right? So, we'll leave your hypers
alone, but the key thing that I was
alone, but the key thing that I was
looking for, which we confirmed, um, is
looking for, which we confirmed, um, is
that the defaults just do something,
that the defaults just do something,
right? The defaults get you 80% solve
right? The defaults get you 80% solve
rate before you even sweep.
And also we made yours uh your swept
And also we made yours uh your swept
prams go to a
mill. I want to try mobile.
Yeah, it's buffer fast.
MOA is a lot harder. Let's see. Let's
MOA is a lot harder. Let's see. Let's
see if this does
see if this does
anything. MOA is like a lot
anything. MOA is like a lot
harder. Also, I think it's going to
harder. Also, I think it's going to
break some of our
break some of our
um our slicing optimizations.
Well, I didn't I didn't really do very
Well, I didn't I didn't really do very
many experiments on mobile or on neural
many experiments on mobile or on neural
MMO,
right? I kind of just built them when I
right? I kind of just built them when I
was building cool MS and like ran a few
was building cool MS and like ran a few
things.
Like the bots in MOA at the moment, they
Like the bots in MOA at the moment, they
just know how to run down mid and use
just know how to run down mid and use
their abilities. Yes.
How good are the scripted
How good are the scripted
opponents? Um, they run down mid and
opponents? Um, they run down mid and
spam their abilities, I'm pretty sure.
Why is backwards pass so expensive? Cuz
Why is backwards pass so expensive? Cuz
it's set to three update epochs.
This one has a ton of metrics on
it. It is training though.
See, now it wins all the
games.
Okay. What happens if I do this?
This one I remember being a total pain
This one I remember being a total pain
to tune as
well. So I will be very impressed if
well. So I will be very impressed if
this works.
Why is sweet metric radiant towers alive
Why is sweet metric radiant towers alive
and not win rate? Uh because win rate's
and not win rate? Uh because win rate's
going to be zero a lot of the time.
going to be zero a lot of the time.
So, how many towers you have left just
So, how many towers you have left just
ends up being a pretty darn good one
ends up being a pretty darn good one
because also it's like if you win with
because also it's like if you win with
zero towers taken, like having lost
zero towers taken, like having lost
hero's tower, that's also probably a
hero's tower, that's also probably a
better
policy. You can't use D like you can't
policy. You can't use D like you can't
use dire towers taken or whatever
use dire towers taken or whatever
because you can take all the enemy
because you can take all the enemy
towers and still lose.
towers and still lose.
So, it's a little tricky.
Oh.
Haha. And I
slice another optimization.
I will have to come back to this
I will have to come back to this
particular one. Why is it not working in
particular one. Why is it not working in
the meantime
though? I think there's an optimization
though? I think there's an optimization
missing here.
minor bug
X interesting that the
uh ah the end is the slow thing
uh ah the end is the slow thing
now. That's
now. That's
unfortunate, but I can probably fix that
unfortunate, but I can probably fix that
just with
like Get out of here, bot.
like Get out of here, bot.
I build the box here.
run a PL sweep.
Oh, radiant victory one. And it's
Oh, radiant victory one. And it's
faster. I was just doing this on the
faster. I was just doing this on the
side. Look at
that. That's kind of crazy. So, I just
that. That's kind of crazy. So, I just
deleted all the hyper prams. I made it
faster. And uh yeah, there's their
faster. And uh yeah, there's their
victory
victory
instantly. So, I think it's safe to say
instantly. So, I think it's safe to say
that we've got something
that we've got something
here. I think it's safe to say we've got
here. I think it's safe to say we've got
something
something
here. I'll be back in a few. Got to do a
here. I'll be back in a few. Got to do a
couple quick
couple quick
things and get more tea as well. And
things and get more tea as well. And
then uh I think we're going to see if we
then uh I think we're going to see if we
can get neural MMO working cuz holy hell
can get neural MMO working cuz holy hell
is this good.
is this good.
I mean, I don't think I can even like
I mean, I don't think I can even like
express how crazy it is to just delete
express how crazy it is to just delete
the nicely tuned hyperparameters, throw
the nicely tuned hyperparameters, throw
on a janky set of defaults from
on a janky set of defaults from
Breakout, and then outperform by a mile
Breakout, and then outperform by a mile
like the best thing I previously got
like the best thing I previously got
from tuning on what was already the best
from tuning on what was already the best
PO implementation out there and make it
PO implementation out there and make it
faster. That's insane. So, I'll be back
faster. That's insane. So, I'll be back
soon and we will I think we're going to
soon and we will I think we're going to
make a big dent on RL overall today. Be
make a big dent on RL overall today. Be
back.
Okay,
cool. Oops.
Let me do a thing real quick. One
Let me do a thing real quick. One
second.
Let me send a couple quick messages and
Let me send a couple quick messages and
we're going to run some awesome
we're going to run some awesome
experiments.
send a couple quick messages and then
send a couple quick messages and then
we're going to run MMO
Okay. Um, this is insane right here. I I
Okay. Um, this is insane right here. I I
don't know if I can describe how insane
don't know if I can describe how insane
this is.
So,
um,
um,
yeah, that's
crazy. Neural MMO 3 is up next.
We also have pong sweeps
We also have pong sweeps
running.
So I don't know if you can read this
So I don't know if you can read this
access. Let me add some uh let me add
access. Let me add some uh let me add
this so you can
this so you can
see the original train access for neural
see the original train access for neural
MMO 3
MMO 3
is7 billion time steps.
is7 billion time steps.
Uh, I chose this number because it's
Uh, I chose this number because it's
equal to, I believe,
equal to, I believe,
2,25 years worth of gameplay.
Where's the report?
Interval 120. It's hardcoded.
Oh, wait. Hang on. This one is
Oh, wait. Hang on. This one is
hardcoded. This one is
not. See about this.
There we go. So now we have
There we go. So now we have
stable stable
reporting. And I believe we want to look
reporting. And I believe we want to look
at min.
com
Maybe this one's a little ambitious
Maybe this one's a little ambitious
because this is one
because this is one
where it just took a lot of
training. See what params we
have. Very low learning rate.
What about episode
What about episode
length or
return? Okay. episode length at least is
return? Okay. episode length at least is
increasing. So this is
increasing. So this is
potentially you know the
potentially you know the
signal that at least the agents are
signal that at least the agents are
surviving for
longer and then eventually that
longer and then eventually that
translates into them accomplishing stuff
translates into them accomplishing stuff
in the
in the
environment. We'll let this run for 100
environment. We'll let this run for 100
mil. You can see that the original here
mil. You can see that the original here
was like almost a three-day run.
original was like almost a three-day
original was like almost a three-day
run.
Oh, and this is now with the new
Oh, and this is now with the new
optimizer as
well, just with the old parameters.
There. Okay.
So 100 million ep 100 million agent
steps gives you about a 100ish
steps gives you about a 100ish
uh survival time is what we see here
uh survival time is what we see here
right and I think you disabled a
right and I think you disabled a
kneeling you disabled a ton of other
kneeling you disabled a ton of other
stuff that tends to be important so why
stuff that tends to be important so why
don't we do this is just going to be 100
don't we do this is just going to be 100
mil. It's a tiny number of
mil. It's a tiny number of
steps by comparison for neural
steps by comparison for neural
MMO. And we just get rid of all of
this. How many agents? Five times
this. How many agents? Five times
this. Yeah. So, this is going to be
this. Yeah. So, this is going to be
8192 total agents.
Just get rid of
this. So we will also put compile on
this. So we will also put compile on
because it does make it a little bit
because it does make it a little bit
faster.
for comparison, right? This is what we
for comparison, right? This is what we
had before. It was one update epoch,
had before. It was one update epoch,
which was good. It was good batch sizes.
which was good. It was good batch sizes.
Uh I think the mini batch was kind of
crazy. Okay. Something's wrong with this
crazy. Okay. Something's wrong with this
because it shouldn't be this slow.
Yeah. So, it was compile screwing it
up. Interestingly, it's uh still
up. Interestingly, it's uh still
slightly slower than before. We had a
slightly slower than before. We had a
really big mini batch size, though.
So, here's the new
one. Well, I don't know what happened
one. Well, I don't know what happened
here.
Oh, this is the wrong one here. Yeah,
Oh, this is the wrong one here. Yeah,
there we go. Oh, okay.
there we go. Oh, okay.
Yeah. What?
That's
something.
So,
So,
well, not quite. It's there are a lot of
well, not quite. It's there are a lot of
things that it has to learn. This the
things that it has to learn. This the
original for this is a 107 billion step
original for this is a 107 billion step
run, but I don't think I can emphasize
run, but I don't think I can emphasize
how crazy this is. Okay, I took a random
how crazy this is. Okay, I took a random
set of hyperparameters that I tuned for
set of hyperparameters that I tuned for
breakout. Very simple game, right? I
breakout. Very simple game, right? I
took breakout
took breakout
parameters and I've thrown them on a
parameters and I've thrown them on a
bunch of different environments and they
bunch of different environments and they
do reasonably well in all of them. uh
do reasonably well in all of them. uh
and in half of them they do better than
and in half of them they do better than
the like carefully optimized set of
the like carefully optimized set of
parameters that I hand that I that I
parameters that I hand that I that I
tuned for this specific environment via
tuned for this specific environment via
hand tuning and like uh automated
hand tuning and like uh automated
sweeps.
sweeps.
So yeah, that's kind of something like
So yeah, that's kind of something like
that's not something that happens in
RL. I am curious as to what they're
RL. I am curious as to what they're
doing though because this mid you'd
doing though because this mid you'd
expect one of the other metrics to have
expect one of the other metrics to have
gone up by now.
They're
like just very sparse.
I mean, that's something right there
I mean, that's something right there
though, right? Like
So, this is the crazy part, Captain. I
So, this is the crazy part, Captain. I
deleted the handtuned hyperparameters
deleted the handtuned hyperparameters
from when I was running I did this at
from when I was running I did this at
work
work
originally and I just like used the
originally and I just like used the
defaults that I got from
defaults that I got from
Breakout with the new algorithms and the
Breakout with the new algorithms and the
new tuning and everything.
What's
What's
different? Uh, Muan is a big one. Cosign
different? Uh, Muan is a big one. Cosign
and kneeling is a big
and kneeling is a big
one. I think those are the two main
one. I think those are the two main
ones. I fixed a bug, but that bug wasn't
ones. I fixed a bug, but that bug wasn't
in these like when I ran these original
in these like when I ran these original
experiments. Uh, that bug wasn't there.
experiments. Uh, that bug wasn't there.
So I think it's mainly muon and cosine
So I think it's mainly muon and cosine
and kneeling. I'm trying to think if I
and kneeling. I'm trying to think if I
did anything else
did anything else
major. I think those were the two
major. I think those were the two
biggest ones.
I mean also though the thing is like
I mean also though the thing is like
because of these new uh because of these
because of these new uh because of these
new uh techniques like the
new uh techniques like the
the the hyperparameters are way more
the the hyperparameters are way more
robust and like you can use bigger batch
robust and like you can use bigger batch
sizes and stuff without breaking things
sizes and stuff without breaking things
which is
crazy. Okay. Um I would like to see this
crazy. Okay. Um I would like to see this
number go
number go
up. Muan seems to be just better than
up. Muan seems to be just better than
Adam. Yeah, it is. Well, it's a small
Adam. Yeah, it is. Well, it's a small
modification on top of
modification on top of
Adam from what I understand that
Adam from what I understand that
orthogonalizes u model updates.
Oh, by the way, you can do
this. Let's take Neptune
off. It's actually slower in Bflat
off. It's actually slower in Bflat
16. And then if you do float
16, it's like maybe a little
16, it's like maybe a little
faster. Not great overall though with
faster. Not great overall though with
the
precision.
Okay, these are crazy results. These are
Okay, these are crazy results. These are
really crazy
results. I don't think that's going to
results. I don't think that's going to
do anything. But I'm just going to run
do anything. But I'm just going to run
this while I'm thinking about other
this while I'm thinking about other
stuff.
Um cuz I like where do we go from here?
Um cuz I like where do we go from here?
Right. We kind of we kind of did the
Right. We kind of we kind of did the
thing built in. Okay. So I have to fix
thing built in. Okay. So I have to fix
that
that
one. That's
fine. I think we want to get a really
fine. I think we want to get a really
nice policy on neural MMO 3. We want to
nice policy on neural MMO 3. We want to
get a lot of the tuning stuff
get a lot of the tuning stuff
working. G. It's kind of the same as
working. G. It's kind of the same as
before except now there's more of an
before except now there's more of an
emphasis on baselining
more man
So here's default connect
So here's default connect
4. Actually I want to take this graph.
This is
pong. Oh, okay. So, this is our original
pong. Oh, okay. So, this is our original
connect 4 right here. It works, right?
This is
This is
4096 total
m. So let's just do this is
m. So let's just do this is
four and we just delete this. And what
happens? Well, it's a bit faster.
Yeah, that might have been a little
Yeah, that might have been a little
ambitious for a 10 million step end to
ambitious for a 10 million step end to
train that
fast. It started taking
fast. It started taking
off. Hang on, let me just see what they
off. Hang on, let me just see what they
did. So, batch size 32K.
Yeah, there we go. Just needed the uh
Yeah, there we go. Just needed the uh
the batch size reduced because there's
the batch size reduced because there's
like so few total
steps. Okay. Yeah, Spencer, there's
steps. Okay. Yeah, Spencer, there's
Connect 4 in uh in 20 seconds matching
Connect 4 in uh in 20 seconds matching
previous
baseline with untuned
baseline with untuned
hypers. That's pretty damn
hypers. That's pretty damn
good. If we run it for 20, does it do
good. If we run it for 20, does it do
any better?
Holy.
That gives me a 95 in like 40
seconds. Little
seconds. Little
better. That's kind of
better. That's kind of
crazy. We should definitely use this as
crazy. We should definitely use this as
a baseline.
a baseline.
The only thing that's slightly annoying
The only thing that's slightly annoying
is the
is the
um this M is way too slow. Like the uh
um this M is way too slow. Like the uh
the scripted AI is way too slow in
this. What other
this. What other
apps? Multi- aent snake. I haven't
apps? Multi- aent snake. I haven't
played with this one in a while.
I want to do the uh the fulls size
snake. Let's write this one.
live evals on new
live evals on new
models. Oh yeah. Uh we're going to want
models. Oh yeah. Uh we're going to want
to do that. I have to fix some of the
to do that. I have to fix some of the
eval stuff for
eval stuff for
sure. I think I broke a few things. I
sure. I think I broke a few things. I
want to like at least get these configs
want to like at least get these configs
cleaned up a little bit first.
cleaned up a little bit first.
And then we'll look at
them. And this is going to be just
them. And this is going to be just
amazing for research.
Uh, where did I screw
Uh, where did I screw
up? Oh.
Okay, this Muon autotuning is really
annoying. It also lags everything
annoying. It also lags everything
because it spins everything at max.
Okay. So, this
is Why is this running at 3.8 million
is Why is this running at 3.8 million
steps per
steps per
second? That's a bit much, isn't it?
It's also the snakes aren't very good,
It's also the snakes aren't very good,
are
are
they? The length is
they? The length is
60. Oh, I think I went off of episode
60. Oh, I think I went off of episode
length with snake, didn't
I? Hang
on. Yeah. Yeah, I went off of episode
on. Yeah. Yeah, I went off of episode
length. Okay, so 88 is already better
length. Okay, so 88 is already better
than we had
before. Uh, this is not RLB and cursed.
before. Uh, this is not RLB and cursed.
This is multi-agent dynamics
This is multi-agent dynamics
specifically. So you get a pass on this
one. Yeah, you get a pass on this one
here. My value. Hang on.
What?
What? Wrong
one.
one.
Score. Uh, is this the Yeah, this is the
Score. Uh, is this the Yeah, this is the
wrong
one.
one.
Oh, okay. That was a random sweep. This
Oh, okay. That was a random sweep. This
is actually perfectly
stable. So we have perfectly stable 3.8
stable. So we have perfectly stable 3.8
million step per second training on
snake. We got to figure out what it is
snake. We got to figure out what it is
that makes the snake end so so fast
that makes the snake end so so fast
compared to the other ones.
Oh, and it eval at 109. That's
crazy. And what if I do
crazy. And what if I do
this? This probably actually does make
this? This probably actually does make
it slower to be fair.
Hey, do you have a Neptune fork or just
Hey, do you have a Neptune fork or just
install? You just did pip install it. I
install? You just did pip install it. I
just haven't pinned all the new
just haven't pinned all the new
dependencies to um dev branch yet. You
dependencies to um dev branch yet. You
probably are going to need to install uh
probably are going to need to install uh
well, make sure you do pip install- e
well, make sure you do pip install- e
dot of clean rl. Make sure you add the
dot of clean rl. Make sure you add the
clean rl args. That'll get pyro, which
clean rl args. That'll get pyro, which
you need for hyper pram
you need for hyper pram
sweeps. Is it just an insane number of
sweeps. Is it just an insane number of
agents in a fast? pretty
agents in a fast? pretty
much. But uh honestly here I just set
much. But uh honestly here I just set
these to way more reasonable params and
these to way more reasonable params and
still at
3.4. I had to go back to an old commit
3.4. I had to go back to an old commit
because of CUDA
because of CUDA
stuff. Yikes.
Yeah, CUDA might be AI complete.
So, this just matches perfectly or did I
So, this just matches perfectly or did I
forget to save this
forget to save this
file? I think this just matches
file? I think this just matches
perfectly,
right? Run it
right? Run it
again. Where do I need to put my Neptune
again. Where do I need to put my Neptune
API and variable? Yeah, if you just
API and variable? Yeah, if you just
click the link that's like, you know,
click the link that's like, you know,
get my key or whatever, it'll link you
get my key or whatever, it'll link you
to get your
to get your
key and it'll just say, yeah, paste this
key and it'll just say, yeah, paste this
as an
variable. I mean, as you can see, I've
variable. I mean, as you can see, I've
been using Neptune pretty much
been using Neptune pretty much
exclusively for the last couple of
exclusively for the last couple of
months, and I really like it. like the
months, and I really like it. like the
dashboards are better, the UI is faster,
dashboards are better, the UI is faster,
it displays more data points, uh it's
it displays more data points, uh it's
better for organizing my work, it's just
better for organizing my work, it's just
better
better
overall. We're going to support both.
overall. We're going to support both.
Like I don't see any reason to drop wand
Like I don't see any reason to drop wand
support, especially with the number of
support, especially with the number of
people using it. Uh the only thing we're
people using it. Uh the only thing we're
dropping support for is wand sweeps API.
dropping support for is wand sweeps API.
So you will still be able to do sweeps
So you will still be able to do sweeps
using Wandi, but you're not going to use
using Wandi, but you're not going to use
their sweeps API. You use our sweep
their sweeps API. You use our sweep
tools.
tools.
Never done real sweeps. Now getting
Never done real sweeps. Now getting
Yeah, sweeps are like goated. You need
Yeah, sweeps are like goated. You need
sweeps. Like people not sweeping hyper
sweeps. Like people not sweeping hyper
prams is one of the main reasons RL
prams is one of the main reasons RL
didn't
work. Sweeps are like not
work. Sweeps are like not
optional. It's the first thing people
optional. It's the first thing people
drop and it's like it's so so so
drop and it's like it's so so so
essential. But to be fair, I've been
essential. But to be fair, I've been
using the same set of hyperparameters
using the same set of hyperparameters
for all of these environments now with
for all of these environments now with
the new optimizer stuff, and it kind of
the new optimizer stuff, and it kind of
just works. So,
just works. So,
um, the new puffer update, the next
um, the new puffer update, the next
puffer update that has all this stuff is
puffer update that has all this stuff is
going to reduce the reliance on sweeps
going to reduce the reliance on sweeps
by a good margin. They'll still be good,
by a good margin. They'll still be good,
but it won't be as bad if you don't do
but it won't be as bad if you don't do
them because our defaults will be way
them because our defaults will be way
better.
Okay, I need to change one of these
Okay, I need to change one of these
hyperpar to see
like if I just do this, does it change
like if I just do this, does it change
the
curve? It should.
how the breakout params
how the breakout params
applies. I I think it's just that the
applies. I I think it's just that the
optimizer is way more stable and less
optimizer is way more stable and less
fiddly than before,
fiddly than before,
frankly. Like the main thing with the
frankly. Like the main thing with the
the main thing is that now you can
the main thing is that now you can
actually train at large batch sizes and
actually train at large batch sizes and
the optimizer doesn't just like give
the optimizer doesn't just like give
up. Learning rate scheduler is good as
up. Learning rate scheduler is good as
well. I it's
well. I it's
just better overall. I don't know what
just better overall. I don't know what
to
to
say. Okay, so here I've
say. Okay, so here I've
definitely No, I definitely am using the
definitely No, I definitely am using the
right
right
paramps. Not this
one. I mean, this is just remarkably
one. I mean, this is just remarkably
consistent though. This
graph like snake length with um
with steps
trained. Oh, if you look at score, it's
trained. Oh, if you look at score, it's
a different story though, right? So,
a different story though, right? So,
this was the original and this is my new
this was the original and this is my new
one. So, my new one is
one. So, my new one is
better. Oh, no, it isn't. That's a
better. Oh, no, it isn't. That's a
relative time. Okay, this is the same.
relative time. Okay, this is the same.
This one, you can see, is going to be
This one, you can see, is going to be
stretched out because it takes um
stretched out because it takes um
because it's running
because it's running
slower. But I think in terms of episode
slower. But I think in terms of episode
length, yeah, it's remarkably remarkably
length, yeah, it's remarkably remarkably
consistent of an environment. I mean, it
consistent of an environment. I mean, it
makes sense. It's like
makes sense. It's like
very it's a very self- similar
very it's a very self- similar
environment.
Okay. Uh, I'll let this finish and then
Okay. Uh, I'll let this finish and then
I'm going to do a slightly more
ambitious. I want to see what happens
ambitious. I want to see what happens
over 500 mil with
this.
Crazy
Crazy
progress, man. You know that this was my
progress, man. You know that this was my
goal for the end of the year pretty much
goal for the end of the year pretty much
was like get RL to be stable and
was like get RL to be stable and
consistent and like even last week this
consistent and like even last week this
was still kind of a crazy thing to say
was still kind of a crazy thing to say
and now this week it kind of just works.
and now this week it kind of just works.
This is
nuts. Perfectly stable learning
curves. Many applications. Well, this is
curves. Many applications. Well, this is
the goal, right? If you make RL sane and
the goal, right? If you make RL sane and
consistent, you can throw it on a ton of
consistent, you can throw it on a ton of
problems in
problems in
industry. And hopefully, you know, at
industry. And hopefully, you know, at
least some of them will want to hire
least some of them will want to hire
puffer for
him. At least initially. I don't know
him. At least initially. I don't know
why you wouldn't. We don't charge that
why you wouldn't. We don't charge that
much. Now, eventually we're going to go
much. Now, eventually we're going to go
eventually we will be looking for much
eventually we will be looking for much
higher value contracts, but for now it's
higher value contracts, but for now it's
like it's really really cheap and easy
like it's really really cheap and easy
to get us to look at your
to get us to look at your
problem. It's kind of a no-brainer.
Okay, so now here's my question. Uh,
Okay, so now here's my question. Uh,
when is it going to level
out? It can't go up infinitely, right?
out? It can't go up infinitely, right?
Like at some point the whole screen is
Like at some point the whole screen is
full of
full of
snakes. But does this just zero shot
snakes. But does this just zero shot
beat the previous best thing I've ever
beat the previous best thing I've ever
seen?
What?
Uh, okay. I'm going to have to render
Uh, okay. I'm going to have to render
this to make sure that I'm not like
this to make sure that I'm not like
going insane here.
There's no way that this could be a
There's no way that this could be a
reporting book, though. There's no
reporting book, though. There's no
way.
How? What?
Once I have some time, I need to try
Once I have some time, I need to try
training Impulse Wars.
Yeah.
Yeah.
Um, okay. We need to render this because
Um, okay. We need to render this because
I
I
What? It just keeps going up. Like,
what? What about
score? Well, they're living for 182
score? Well, they're living for 182
freaking time
steps. Okay, look. At least score levels
steps. Okay, look. At least score levels
off. There's only so much
food. What's the previous best length
food. What's the previous best length
you've seen? Like 110, maybe
you've seen? Like 110, maybe
120. And it's still going up in like a
120. And it's still going up in like a
straight
line. And this is one of the M's I
line. And this is one of the M's I
actually spent a good bit of time
actually spent a good bit of time
on. Holy
hell. Gosh.
It's going to take me a second to get
It's going to take me a second to get
render working, I assume.
Maybe they're less janky. Could
Maybe they're less janky. Could
be. I mean, I've I've been saying for
be. I mean, I've I've been saying for
the last two months since I got back
the last two months since I got back
more 3 months, right, exactly how we
more 3 months, right, exactly how we
fixed that, right, with the continuous
fixed that, right, with the continuous
versions of these arcade ads.
I see bed is up.
logits
values. Spencer added.
values. Spencer added.
Yep. Yeah. We can just run those
Yep. Yeah. We can just run those
experiments.
Uh, we'll fix that. I don't know why
Uh, we'll fix that. I don't know why
it's so slow.
There's sleep on
this. Ah, thank you very
much. Wait, but it's 10. That would be
much. Wait, but it's 10. That would be
fine. It's way slower than that, right?
Yeah, that would be fine. 100 ms 10
Yeah, that would be fine. 100 ms 10
steps per second, which is what you
steps per second, which is what you
would want for snake.
That is way too
That is way too
big. Why is the action this big?
Wait. N
Wait. N
bars num ends.
Oh, that's an
Oh, that's an
issue.
issue.
Um, I'm surprised that
works. That's a crazy number of amps.
or
or
something. See what the model
does. I broke the charm.
Okay, here's puffer snake.
They don't seem very
They don't seem very
smart. Don't you need one end if you're
smart. Don't you need one end if you're
going to watch it, not
going to watch it, not
16? Yeah, it doesn't matter. It's it
16? Yeah, it doesn't matter. It's it
like this is running 16 and it's still
like this is running 16 and it's still
like running in real time for watching
like running in real time for watching
it.
it.
So, I don't see um I don't see
So, I don't see um I don't see
like this policy doesn't look good,
right? Maybe it was
right? Maybe it was
score. Maybe score was the uh the
score. Maybe score was the uh the
important one. Hang on.
Yeah, maybe I just screwed up. Okay,
Yeah, maybe I just screwed up. Okay,
maybe maybe this particular end I
maybe maybe this particular end I
screwed up.
screwed up.
Reward food. Reward corpse. Reward
Reward food. Reward corpse. Reward
death.
But I thought there was like a snake
But I thought there was like a snake
length param.
Is score
consistent? Score is also consistent
here.
Couldn't be learning, could it?
Well, that's why it was so fast
actually cuz I was actually saturating
actually cuz I was actually saturating
the
the
GPU massive amounts of
data. Yeah. 1.5 mil.
Oh, it is score is the variable that
Oh, it is score is the variable that
matters. Okay, I'm
dumb. I mean, it immediately jumps
up. And what did I just specify? So, 256
up. And what did I just specify? So, 256
*
*
16 is 4096. So, this is correct.
Yeah.
Yeah.
Okay. So, that particular graph I had
Okay. So, that particular graph I had
was
stupid. Get rid of that one. The rest of
stupid. Get rid of that one. The rest of
them are all correct though.
Yeah, there you
go. So, the real one that we should be
go. So, the real one that we should be
running
running
here, get this
Let's let it run. Let's see if it
Let's let it run. Let's see if it
figures out uh anything
smart. This is the end where um
smart. This is the end where um
diversity is all you need. actually
diversity is all you need. actually
helped. Helped a
lot. Huh.
lot. Huh.
It's actually going back
It's actually going back
up,
but you got 3 mil before by running more
but you got 3 mil before by running more
amps per process, right? Yeah, it was
amps per process, right? Yeah, it was
just like a massive number of amps. So,
just like a massive number of amps. So,
the GPU was The reason that that worked
the GPU was The reason that that worked
is because um Snake has pretty small
is because um Snake has pretty small
compact observations and we were sending
compact observations and we were sending
it like
it like
What the heck even is that? 160k batch
What the heck even is that? 160k batch
size or something
size or something
ridiculous. Maybe it was like
ridiculous. Maybe it was like
40k. It had a big batch size. So yeah,
40k. It had a big batch size. So yeah,
that's what
happened. We should probably play with
happened. We should probably play with
that at some point because it was
that at some point because it was
interesting how well that worked.
Uh this is actually kind of cool that it
Uh this is actually kind of cool that it
is it is now going back
up with default params.
There's some multi-agent like
There's some multi-agent like
competitive
competitive
dynamics going on that make this emble a
dynamics going on that make this emble a
little
little
tricky. It's like very easy to get
tricky. It's like very easy to get
snakes that do something reasonable, but
snakes that do something reasonable, but
then there are like some pitfalls that
then there are like some pitfalls that
you have to avoid to make the policy
you have to avoid to make the policy
really good.
I mean, this is
solid technically competitive selfplay.
solid technically competitive selfplay.
Yes, it
is. It's in fact strict
is. It's in fact strict
strictly competitive softplay.
good
good
policy, cool environment in the sense
policy, cool environment in the sense
that you can train it, you can train
that you can train it, you can train
something reasonable in 10 seconds, but
something reasonable in 10 seconds, but
like it gets meaningfully better if you
like it gets meaningfully better if you
train it for 5 minutes, like 500 mil
train it for 5 minutes, like 500 mil
steps.
So this is what a good snake model looks
So this is what a good snake model looks
like.
It's kind of cool to
watch. I haven't seen a single one die
yet. Oh, there's
yet. Oh, there's
one. Couple died so far.
That's a good policy
That's a good policy
though. It's not like biasing towards
though. It's not like biasing towards
one side
one side
excessively. It's a really cool
excessively. It's a really cool
policy. Yeah, I like this environment.
policy. Yeah, I like this environment.
These like big multi- aent
These like big multi- aent
M. These are
fun.
Cool
Cool
sim. Very very cool
sim. Very very cool
sim. Yeah, this policy is definitely
sim. Yeah, this policy is definitely
better as well than what we've had
better as well than what we've had
before. Like it it figured out. So what
before. Like it it figured out. So what
happened here is like I can guarantee
happened here is like I can guarantee
you it figured out how to kind of like
you it figured out how to kind of like
do some stuff and then the snakes get a
do some stuff and then the snakes get a
directional bias. So like they all go in
directional bias. So like they all go in
one direction and um that works fine
one direction and um that works fine
until they crowd up against one side and
until they crowd up against one side and
then this is them figuring out not to do
that. Uh no it does not outperform the
that. Uh no it does not outperform the
scores on diversity is all you need yet.
scores on diversity is all you need yet.
Uh but I like we'll see what happens
Uh but I like we'll see what happens
when I try it with you know the new
when I try it with you know the new
optimizer with all that. There's more
optimizer with all that. There's more
research to be done. This is I I'm very
research to be done. This is I I'm very
happy with this result. I will say this
happy with this result. I will say this
is very
is very
good for this M
here. Very cool
here. Very cool
M. Cool. I mean, we're through half of
M. Cool. I mean, we're through half of
the puffer lip catalog
already. And like you can
already. And like you can
see this is one set of
see this is one set of
hypers. So the whole puffer catalog so
hypers. So the whole puffer catalog so
far with one set of hypers modulo a
far with one set of hypers modulo a
couple small batch tweaks for the ones
couple small batch tweaks for the ones
that have really short
horizons. See we did this. We did this.
horizons. See we did this. We did this.
We did this. Let's do triple triad real
We did this. Let's do triple triad real
quick.
go might be interesting. Yeah, I think
go might be interesting. Yeah, I think
that that's going to
that that's going to
be that's going to be fiddly regardless
be that's going to be fiddly regardless
just because of the way it's set up, but
just because of the way it's set up, but
we'll see.
Get our baseline
in. A long run.
It's got to redo all the optimizer. I'm
It's got to redo all the optimizer. I'm
going to actually kill this after it's
going to actually kill this after it's
done so that we don't screw up our graph
done so that we don't screw up our graph
axis.
Well, that's nice. Back me to the
Well, that's nice. Back me to the
restroom.
Yep. Well, that's a super clean train
Yep. Well, that's a super clean train
curve with just the uh the default like
curve with just the uh the default like
optimized
ones. I actually don't know what the max
ones. I actually don't know what the max
is on uh on triple triad. I think you
is on uh on triple triad. I think you
can technically get nine points, but I
can technically get nine points, but I
don't know if that's ever
don't know if that's ever
possible. Maybe Spencer knows.
Also, what was the train speed?
Also, what was the train speed?
1.38. That's pretty good.
Okay. So, it's like a little tiny bit
Okay. So, it's like a little tiny bit
worse. It looks
like mini badge.
Yeah, I'm going to guess that this one
Yeah, I'm going to guess that this one
you can probably do way better just with
you can probably do way better just with
like smaller batch or something with the
like smaller batch or something with the
the episode length being that
the episode length being that
short. We'll try that
short. We'll try that
next. Oh, and
also let's do this.
Yeah. So, this more m fewer M's doesn't
Yeah. So, this more m fewer M's doesn't
really matter
really matter
here. It looks like it's probably just
here. It looks like it's probably just
going to be the batch size.
Um probably do this.
Okay, that does weigh worse,
Okay, that does weigh worse,
interestingly
enough. You see what the original was?
enough. You see what the original was?
It was 4096 m
It was 4096 m
total. Bigger mini badge.
Let's try this.
Well, there you
Well, there you
go.
Okay. Is it going to get stuck at the
Okay. Is it going to get stuck at the
lower uh lower max though? Here.
Oh, no. It doesn't get
Oh, no. It doesn't get
stuck.
stuck.
Uh, we'll see if it does seem like it
Uh, we'll see if it does seem like it
flattens, though. Yeah. Okay, it does
flattens, though. Yeah. Okay, it does
flatten more than the other one.
Okay, so this one is somewhere in
between. You only need an episode length
between. You only need an episode length
of like 16, I think, right? So it's like
of like 16, I think, right? So it's like
uh
That's
131K. We'll see. But I think with the
131K. We'll see. But I think with the
way that we handle trajectory segments,
way that we handle trajectory segments,
you might need a little bit of wiggle
you might need a little bit of wiggle
room. We'll
room. We'll
see. This looks worse.
see. This looks worse.
Increase batch size is
Increase batch size is
worse. We had 131
before. If I just do
before. If I just do
131 and I do
131 and I do
m, it's probably pretty good,
m, it's probably pretty good,
right? Of course, it'll take a hit to
right? Of course, it'll take a hit to
the train speed. We don't need to get
the train speed. We don't need to get
these fully optimized. I just want to
these fully optimized. I just want to
have something like pretty good.
Uh, not this one. This one.
So, this the original tuned ones are
So, this the original tuned ones are
still like a little bit better, I think,
still like a little bit better, I think,
in their final
in their final
convergence. Unless this catches up.
Did you try the other optimizer? So, the
Did you try the other optimizer? So, the
other optimizers um have a big
other optimizers um have a big
performance penalty associated with
performance penalty associated with
them. Muon is the one that runs like as
them. Muon is the one that runs like as
fast as Adam and just is like is a free
fast as Adam and just is like is a free
win because right now we have this axis
win because right now we have this axis
in steps but usually we have it in
in steps but usually we have it in
seconds, right?
I don't really care much for this ample
I don't really care much for this ample
efficiency
nerds. Okay, that's cool. So, this is
fine. Triple triad works.
fine. Triple triad works.
Uh, we need to do the grid M's rware and
Uh, we need to do the grid M's rware and
trash pickup real quick. Those should be
trash pickup real quick. Those should be
easy.
Look at
that. This is fast. But does it do
anything? Oh, it's the length is the
anything? Oh, it's the length is the
thing that matters here, right? So lower
thing that matters here, right? So lower
length is better.
Okay. So, this is what we get with the
Okay. So, this is what we get with the
defaults.
Oops.
Okay.
So just out of the box, we just blow the
So just out of the box, we just blow the
previous result out of the water.
Well, we can just reduce the number of
Well, we can just reduce the number of
steps needed for this five to 50 mil,
steps needed for this five to 50 mil,
right? Like there's no reason to have
right? Like there's no reason to have
it. So we just increase sample
it. So we just increase sample
efficiency by a factor
efficiency by a factor
of
of
five, four, whatever.
That just works. Why wouldn't it?
This is just a custom comp. There's like
This is just a custom comp. There's like
not even anything
not even anything
remotely complex
here. We probably have like a ton of M's
here. We probably have like a ton of M's
in this one as well.
Okay, here's a trash
pickup. This one, I believe, is score
pickup. This one, I believe, is score
and um episode length or
and um episode length or
whatever. So, I don't know. We'll just
whatever. So, I don't know. We'll just
pick a metric.
Uh, was this the right
one? Yeah, that's Pong. Okay, this is
one? Yeah, that's Pong. Okay, this is
good.
So previous optin
So previous optin
params 100 mil steps 1.7 mill steps per
second and then what's this? Divide by
second and then what's this? Divide by
numbum agents. Num agents is
numbum agents. Num agents is
four. So I think we literally just
four. So I think we literally just
delete I'm going to leave the batch
delete I'm going to leave the batch
size. Maybe not. Maybe we just do this.
size. Maybe not. Maybe we just do this.
Maybe we just literally do. Hang on.
Maybe we just literally do. Hang on.
Let's do this. You
know. Oh.
Yeah.
Um. Oh, is it going to get stuck though?
Um. Oh, is it going to get stuck though?
Oh,
no. I think it's going to get stuck a
no. I think it's going to get stuck a
little
little
bit. It's so
close. Is it like permanently
close. Is it like permanently
stuck? Wait, it has trash collected at
stuck? Wait, it has trash collected at
max.
max.
But I guess it's the episode length is
But I guess it's the episode length is
too
long. That's
weird. Wait, what about episode return?
Oh, so it broke the end.
I guess it's just like this little
decline. Well, I think it broke the end.
decline. Well, I think it broke the end.
I don't
I don't
know. Here, let's do let's do batch
size. Set the batch size. See if that
size. Set the batch size. See if that
does anything.
Yeah, whatever this score is doesn't
Yeah, whatever this score is doesn't
seem particularly well correlated with
seem particularly well correlated with
uh the
return. So, we got to fix that.
cuz like look right it's like 20 is
cuz like look right it's like 20 is
solved and then it's supposed to I guess
solved and then it's supposed to I guess
get penalized for taking too long but
get penalized for taking too long but
like the score is not very well
like the score is not very well
correlated with the Turn.
It's the episode length, I
guess. That's weird.
Six. Yeah, this is the one you want.
Six. Yeah, this is the one you want.
So, yeah, that's a weird uh that's a
So, yeah, that's a weird uh that's a
weird problem to
have. Let's see if we can uh fix that.
Definitely something
Definitely something
screwy. Oh, you know, it's probably just
screwy. Oh, you know, it's probably just
a discount
factor. Would that make
sense? Maybe it is the discount factor
sense? Maybe it is the discount factor
here, right?
Let's try one more thing.
So one other
So one other
like you see anything else weird
like you see anything else weird
here? I see like the lower
gamma one mini
gamma one mini
batch 01 learning rate.
Yep, that was
Yep, that was
it. So, it's this
freaking the episode length here,
right? It's gamma.
Yeah. So that's a
gigasolve. That's gigasolved.
What else do we have
What else do we have
left? We did everything but go,
right? Let's get go running.
Also, we really would like to have like
Also, we really would like to have like
a much longer benchmark on Neural MMO 3.
a much longer benchmark on Neural MMO 3.
That's the cool end. I mean, not that's
That's the cool end. I mean, not that's
the hardest end. I will say neural MMO 3
the hardest end. I will say neural MMO 3
is definitely the hardest
is definitely the hardest
end. All
right, there's the restroom again. I'll
right, there's the restroom again. I'll
be right back.
All
right.
That does not appear to be doing
That does not appear to be doing
anything
good. Also, why is this training at
good. Also, why is this training at
50,000 steps per second?
Hello. What is wrong with go?
Why is Why is it like
this? Why is the mini batch size 131K?
this? Why is the mini batch size 131K?
Who did this?
That is not how GPUs
work. Don't do that ever. Thank you very
work. Don't do that ever. Thank you very
much.
Is it still slow? No, no, no, no, no. If
Is it still slow? No, no, no, no, no. If
it's still slow, then we've got issues.
This has got to be like the stupid uh
This has got to be like the stupid uh
action space, right?
model's really slow.
model's really slow.
What is the
model comp
2D
2D
two channels three stride Oh,
Is it the logic somehow? Hang on.
500,000
steps. That's what's wrong with this,
steps. That's what's wrong with this,
right?
There we go.
Yeah. So, it's all in the
network and we
network and we
have no not high GPU
utilization. Hang
on. Let me see if the batch size is what
on. Let me see if the batch size is what
we think it is.
This is what we think it
is. This is all zeros. I guess that's
is. This is all zeros. I guess that's
fine for the
start. 48
Default policy is much faster, but still
Default policy is much faster, but still
ways slower than
expected. Is it the action space being
expected. Is it the action space being
weird?
That doesn't seem to be it.
That doesn't seem to be it.
Right. Still slow.
fact that there was 17% forward.
How is there
How is there
17% in just this of
that default not
work. I just want to make doubly sure
work. I just want to make doubly sure
that this is
that this is
actually getting applied.
Yeah. So this is getting applied
Yeah. So this is getting applied
right policy is just super basic same as
right policy is just super basic same as
we use everywhere
else not
continuous and somehow this is slow
really
Uh device equals
CPU. Yeah.
CPU. Yeah.
Okay. Okay, buddy.
1.4 mil. And now let's rerun again with
1.4 mil. And now let's rerun again with
the bigger action space.
1.0 mil. Okay. So, there is actually
1.0 mil. Okay. So, there is actually
some sort of perf penalty it seems
some sort of perf penalty it seems
uh associated with that. We should look
uh associated with that. We should look
into that more the action
into that more the action
size. Um but for the meantime, this is
size. Um but for the meantime, this is
good and we can actually run this
This is also this is too many
This is also this is too many
steps to give
it. We'll give it 250.
it. We'll give it 250.
That's not going to matter for this
That's not going to matter for this
because there's no nailing
on. So what point does the learning
on. So what point does the learning
start?
the episode returns increasing. So it's
the episode returns increasing. So it's
I think this is the part where it takes
I think this is the part where it takes
forever to learn action masking.
You can see the episode return is
You can see the episode return is
actually optimizing
though. And now score starts to increase
though. And now score starts to increase
very rapidly.
And now it's winning almost all the
And now it's winning almost all the
games and only 100 mil
steps. So 100 million steps should be
steps. So 100 million steps should be
fine for uh for
this now.
this now.
We uh we do the exact same thing as
We uh we do the exact same thing as
before, but we delete all of
before, but we delete all of
this and we see how the defaults
work. Oh, N91 win rate actually. So 99%
work. Oh, N91 win rate actually. So 99%
of games won.
And then we will see whether our new
And then we will see whether our new
params
params
uh are any better at getting
unstuck. Oh yeah, look at that. The
unstuck. Oh yeah, look at that. The
episode
episode
return that is optimizing much
return that is optimizing much
faster. The uh the steps per second have
faster. The uh the steps per second have
taken a big hit for some reason. Let me
taken a big hit for some reason. Let me
see.
You see anything that would cause that
here? Size mini badge
here? Size mini badge
size. I don't see anything that should
size. I don't see anything that should
cause that, which is a little
cause that, which is a little
weird. Oh, actually, hold on. Maybe uh I
weird. Oh, actually, hold on. Maybe uh I
wasn't I didn't see these steps. Yeah.
wasn't I didn't see these steps. Yeah.
Yeah. No, it's it gets slower as you get
Yeah. No, it's it gets slower as you get
better at the game.
There we
There we
go. There's the
go. There's the
jump.
jump.
So, be better than previous
Yeah, better than
previous. That's crazy.
So, we've pretty much just shredded
So, we've pretty much just shredded
every single benchmark in
every single benchmark in
Puffer. I guess we can try Blastar real
Puffer. I guess we can try Blastar real
quick. Since Bet went through the effort
quick. Since Bet went through the effort
of making it, we may as well include it,
of making it, we may as well include it,
right? It's a fine N. It's a little
right? It's a fine N. It's a little
silly of an arcade N.
What did he set the total time steps
What did he set the total time steps
to? A
lot. Okay.
Bet invalid environment named Puffer
Blaster. I literally not even included
Blaster. I literally not even included
in uh
Welcome YouTube folks. Today is a very
Welcome YouTube folks. Today is a very
good day for
RL. If we can just finish this last M,
RL. If we can just finish this last M,
then pretty much we have one set of
then pretty much we have one set of
hyperpar that works for all but one of
hyperpar that works for all but one of
the Ms. And in the cases where it's like
the Ms. And in the cases where it's like
slightly suboptimal,
slightly suboptimal,
uh we know that the last impediment is
uh we know that the last impediment is
generalized advantage estimation because
generalized advantage estimation because
you cannot
you cannot
use you just cannot use the same gamma
use you just cannot use the same gamma
and lambda pms for all
and lambda pms for all
Ms. I think once we have that set we
Ms. I think once we have that set we
should be good to go. Maybe
should be good to go. Maybe
entropy entropy might be a little nsp
entropy entropy might be a little nsp
specific. We should be able to make that
specific. We should be able to make that
adaptive though pretty easily, much more
adaptive though pretty easily, much more
easily than the other
ones. So, a massive episode length
ones. So, a massive episode length
here. I wish I knew. So, this is
go. I wish I knew what
um score we could
um score we could
get. What's the max
score? But I guess what I'll do since
score? But I guess what I'll do since
this is he has it set for way too long,
this is he has it set for way too long,
I'll just let this run
I'll just let this run
for a little bit.
for a little bit.
Actually, this might be good right here.
Actually, this might be good right here.
mil. Yeah, because it starts
mil. Yeah, because it starts
oscillating. Cool. Um, and that's just
oscillating. Cool. Um, and that's just
from the long episodes, I assume. I
from the long episodes, I assume. I
assume num m is 4096 and batch size is
assume num m is 4096 and batch size is
one numm. So, we're going to change this
one numm. So, we're going to change this
to
2048. And we'll just we'll just do this.
Actually, hold on. It's You want to get
Actually, hold on. It's You want to get
rid of everything except total time
rid of everything except total time
steps there.
And the score is already way higher than
And the score is already way higher than
it
it
was. Yeah. Look at
that. Yeah. Massively better. Now, these
that. Yeah. Massively better. Now, these
could start at the same point, mind you,
could start at the same point, mind you,
but still like
but still like
Massively
Massively
better. Just make sure it doesn't get
better. Just make sure it doesn't get
caught at
21. Is it stuck?
Oh, it's still going back
up. What was his original gamma and
up. What was his original gamma and
lambda in
this? Nothing crazy.
Okay. I mean,
so it gets to there
so it gets to there
immediately, which 25 is max
immediately, which 25 is max
4. Yeah, I wouldn't be surprised. This
4. Yeah, I wouldn't be surprised. This
is just like a weird episode length
is just like a weird episode length
smoothing thing because 25, if you look
smoothing thing because 25, if you look
here, right, like with the oscillations,
here, right, like with the oscillations,
it averages at
it averages at
25. The max
Okay. Generally though, we have
Okay. Generally though, we have
reasonable on every single end. And if
reasonable on every single end. And if
this is matches, I'd have to ask a bet
this is matches, I'd have to ask a bet
if 25 is solved because if so, then this
if 25 is solved because if so, then this
is solved right here.
is solved right here.
So, and then this is probably
So, and then this is probably
um well, this could be like slower
um well, this could be like slower
oscillation. We'd have to run it way
oscillation. We'd have to run it way
longer to
see. Uh main thing though for
now, I did have a sweep
running. We do have
Pong. And it looks like the current best
Pong. And it looks like the current best
for Pong is about 22 23 seconds. Does
for Pong is about 22 23 seconds. Does
anybody remember what the previous best
anybody remember what the previous best
time was for
Pong? I tweet about this at
all and I like search my own tweets.
Maybe search Discord. All right.
50 seconds was the original over
here. I thought we had faster than
50. Does anybody
remember? I guess I could go back to
remember? I guess I could go back to
like one of the old sweeps. Oh, your
like one of the old sweeps. Oh, your
pong m is solved in 25 seconds.
There. So then if we had 25 before then
There. So then if we had 25 before then
this is about the same but this is like
this is about the same but this is like
the easiest end.
So maybe that's
fine. We also want Hang
on. Let me try like one or two quick
on. Let me try like one or two quick
things with Pong. I bet I can get it to
things with Pong. I bet I can get it to
run uh just about the same.
25. So this is 20 million steps
25. So this is 20 million steps
is 22
seconds for Okay. So this is 22
seconds. Uh 15. So 16
mil. Does this like have a weird number
mil. Does this like have a weird number
of ms though?
amps to see if there are any weird
amps to see if there are any weird
params in
params in
here. One update
epoch 8192 mini batch
epoch 8192 mini batch
still 131k. Yeah, let me just reduce
still 131k. Yeah, let me just reduce
the size.
You don't get any data from this.
-3. Too many M's.
Maybe this is probably pretty close to
Maybe this is probably pretty close to
what we have in the sweep.
Oh, and then it just jumps to 20. Okay,
cool. Shouldn't be anything else major
cool. Shouldn't be anything else major
in
there. Solved in 30
there. Solved in 30
seconds versus the optimum we get is
seconds versus the optimum we get is
like 22.
And all I did was match num ms I
And all I did was match num ms I
guess and batch
size seems
fair. Cool.
So even though this is like 10 seconds
So even though this is like 10 seconds
more or 9 seconds more than the
more or 9 seconds more than the
optimized one, I'm still going to say
optimized one, I'm still going to say
right like 30 second solve absolutely
right like 30 second solve absolutely
same set of hyperp works. You might have
same set of hyperp works. You might have
to tune batch and end size a little bit
to tune batch and end size a little bit
for the simpler ones, but that's it.
for the simpler ones, but that's it.
So we now literally have except for like
So we now literally have except for like
one gamma tweak that we needed. We have
one gamma tweak that we needed. We have
the same set of hyperparams working on
the same set of hyperparams working on
every single environment in pover
every single environment in pover
um which is something that would uh I
um which is something that would uh I
would have said is like batshit insane
would have said is like batshit insane
if you'd asked me literally yesterday.
if you'd asked me literally yesterday.
And uh I mean anybody who tells you that
And uh I mean anybody who tells you that
that's not insane is just lying or wrong
that's not insane is just lying or wrong
as well because the papers that have
as well because the papers that have
claimed to do that have been borderline
claimed to do that have been borderline
fraud. Um they're like there's one or
fraud. Um they're like there's one or
two in mind I have for
that. So this is an insane result. A
that. So this is an insane result. A
truly truly insane result.
I'm trying to think what I want to do
I'm trying to think what I want to do
next with
next with
this. Let's open up neural MMO
3. So, mincom prof I
believe. How long does 10 billion take?
If I run neural MMO 3 for 10
billing 45 bill an
hour. I'd rather do this though and have
hour. I'd rather do this though and have
the original. I don't know if that'll
the original. I don't know if that'll
screw up the
screw up the
analing, but I think I'd like to just do
analing, but I think I'd like to just do
this.
Where was the environment?
Neural MMO run
Neural MMO run
setup. I mean, this will be the real
setup. I mean, this will be the real
test. And this one might actually take a
test. And this one might actually take a
bit of work. Neural MMO is a hard hard
bit of work. Neural MMO is a hard hard
end. There's a reason I haven't been
end. There's a reason I haven't been
using it. Even though I love this
using it. Even though I love this
environment and put a ton of work into
environment and put a ton of work into
it, it is hard.
I'm going to make sure that this
I'm going to make sure that this
actually gets
actually gets
going. Here's going to be the plan for
going. Here's going to be the plan for
today, though. So, we have all these new
today, though. So, we have all these new
baselines. Um, this is kind of nutty
baselines. Um, this is kind of nutty
that this works. I'm still kind of in
that this works. I'm still kind of in
shock
shock
here. We're going to run neural MMO
here. I might want to hyper pram sweep
here. I might want to hyper pram sweep
this.
Actually on the other
box. I might want to run a hyper pram
box. I might want to run a hyper pram
sweep on the other box for this as well.
sweep on the other box for this as well.
So yeah, let me I'll do a few more
So yeah, let me I'll do a few more
things right now then.
Okay. So, this runs 500k.
Numb is four.
Okay. So up to
8192. Is it one or four by default?
8192. Is it one or four by default?
Should be four by
Should be four by
default I believe.
Total time
steps one E9 should be the
max 2 E8
max 2 E8
min of 5
V8 and I don't think I can use mincom
V8 and I don't think I can use mincom
prof as the metric for sweeps.
Let me go look what I can use for neural
Let me go look what I can use for neural
MMO 3.
I think it's the episode return.
and try
this. Hopefully this does something.
this. Hopefully this does something.
We'll see.
I'd love to get a nice policy on narrow
I'd love to get a nice policy on narrow
MMO 3. That would be like the full
MMO 3. That would be like the full
circle
circle
success cuz that's such a hard end. Like
success cuz that's such a hard end. Like
if you want to get a sense of what
if you want to get a sense of what
Neural MOO 3 is, you can just play it on
Neural MOO 3 is, you can just play it on
Puffer AI. Like that's the best way to
Puffer AI. Like that's the best way to
do it.
do it.
Um it requires a lot of things that are
Um it requires a lot of things that are
intuitive to you because you can see the
intuitive to you because you can see the
textures and say, "Oh, that's a weapon.
textures and say, "Oh, that's a weapon.
I should go get that or whatever." Or
I should go get that or whatever." Or
like, "Oh, I should put this tool on.
like, "Oh, I should put this tool on.
Like I should equip this tool and then
Like I should equip this tool and then
gather stuff." But even then, it's still
gather stuff." But even then, it's still
like the mechanics of it are hard. It
like the mechanics of it are hard. It
requires like longer term planning. It's
requires like longer term planning. It's
just hard.
could have to compile a bunch of stuff,
right? Yeah, this compiles a bunch of
right? Yeah, this compiles a bunch of
stuff. Looks like we have quite a few
stuff. Looks like we have quite a few
folks watching, which of course this
folks watching, which of course this
always happens right when I'm about to
always happens right when I'm about to
pass out from having not eaten anything.
pass out from having not eaten anything.
So I'm going for lunch soon. So we get
So I'm going for lunch soon. So we get
these things done. Uh the plan for the
these things done. Uh the plan for the
rest of today. So quick summary, we have
rest of today. So quick summary, we have
all of the MS and puffer working very
all of the MS and puffer working very
well with basically a single set of
well with basically a single set of
ultraast
hyperparameters. This is with all the
hyperparameters. This is with all the
new tweaks and algorithmic changes we've
new tweaks and algorithmic changes we've
made. We have a clear path for what
made. We have a clear path for what
needs to be done in order to really make
needs to be done in order to really make
a single set of hyperparameters work for
a single set of hyperparameters work for
everything. That's the P30 or GGAE
everything. That's the P30 or GGAE
stuff, the new algorithm I've been
stuff, the new algorithm I've been
developing. Uh, we have the potential
developing. Uh, we have the potential
for the first time now to get some
for the first time now to get some
really impressive results on M like
really impressive results on M like
Neural MMO 3, maybe even impulse wars
Neural MMO 3, maybe even impulse wars
and some of the other complex ones that
and some of the other complex ones that
contributors have
added. Uh, and I have a couple more M's
added. Uh, and I have a couple more M's
to add, uh, to add bindings for. So, I'm
to add, uh, to add bindings for. So, I'm
going to finish this. I'm going to grab
going to finish this. I'm going to grab
lunch. I'm going to get a little bit of
lunch. I'm going to get a little bit of
exercise, do a couple things, and I'm
exercise, do a couple things, and I'm
going to come back, add a binding for a
going to come back, add a binding for a
new environment, see how all this stuff
new environment, see how all this stuff
works on that. Uh, probably clean up
works on that. Uh, probably clean up
another environment. There's like some
another environment. There's like some
client adjacent stuff I have to
do and then we will look at the results
do and then we will look at the results
that hopefully we get some cool results
that hopefully we get some cool results
by then as
by then as
well. And uh, we will proceed from
well. And uh, we will proceed from
there. And I also want to try out the
there. And I also want to try out the
P30 stuff now with all these new
P30 stuff now with all these new
algorithm tweaks because it is quite
algorithm tweaks because it is quite
likely that we're going to get some
likely that we're going to get some
qualitatively new results. And if I can
qualitatively new results. And if I can
get like consistent baselines on neural
get like consistent baselines on neural
MMO 3, that would probably be the best
MMO 3, that would probably be the best
possible setting to try out P30 because
possible setting to try out P30 because
it's an environment that really requires
it's an environment that really requires
you to be able to do credit assignment
you to be able to do credit assignment
over differing horizons uh depending on
over differing horizons uh depending on
what state you are in the N. So that's
what state you are in the N. So that's
promising. Uh this literally just takes
promising. Uh this literally just takes
like a while to start increasing
like a while to start increasing
here. Okay, so this sweep is running.
here. Okay, so this sweep is running.
This baseline longer run is going. Um
This baseline longer run is going. Um
for the folks
watching, all this stuff is open source.
watching, all this stuff is open source.
You can get it at
You can get it at
puffer.ai. Start the repo to help us
puffer.ai. Start the repo to help us
out. Really, really helps. It's free. It
out. Really, really helps. It's free. It
takes like 3 seconds. Uh, and if you
takes like 3 seconds. Uh, and if you
want to get involved with dev and all
want to get involved with dev and all
the exciting RL advancements happening
the exciting RL advancements happening
right now, just join the Discord and
right now, just join the Discord and
click the button or it's
click the button or it's
discord.gg/puffer. If you want more RL
discord.gg/puffer. If you want more RL
content or want to get notified when I'm
content or want to get notified when I'm
live, etc. Uh, I stream like 40 60 hours
live, etc. Uh, I stream like 40 60 hours
a week of dev on X, YouTube, and Twitch.
a week of dev on X, YouTube, and Twitch.
So, you can click the button uh here for
So, you can click the button uh here for
X and more RL content. Thanks. And

Kind: captions
Language: en
Hey, we are
Hey, we are
live.
Hi. Quite a lot to do this
week. Get Reream
week. Get Reream
open and uh we'll go through some of the
open and uh we'll go through some of the
experiments that have run overnight to
experiments that have run overnight to
start with.
and we'll see where we go from
there. Looks like they all ran correctly
there. Looks like they all ran correctly
this
time. Start with Adam.
about 44 second
about 44 second
solve which is better than
solve which is better than
before for
before for
Adam. That's
Adam. That's
solid. That is
solid. Any interesting
solid. Any interesting
uh interesting bits with that? I see we
uh interesting bits with that? I see we
have oh we have higher value function
coefficients. We've got some higher
coefficients. We've got some higher
entropy a little
entropy a little
bit higher BPT. So yeah the uh it's
bit higher BPT. So yeah the uh it's
use all the new uh the new
use all the new uh the new
horizons or the new maximums I set on
horizons or the new maximums I set on
some of these hyperparameters.
some of these hyperparameters.
It's an important thing is um if you're
It's an important thing is um if you're
doing sweeps and you see it butting up
doing sweeps and you see it butting up
the edge of the range of what you've
the edge of the range of what you've
allowed, got to increase the
range. Epsilon doesn't seem to do
range. Epsilon doesn't seem to do
much.
Cool. So now exact same thing but with
Cool. So now exact same thing but with
muon.
31 seconds and down there's a
31 seconds and down there's a
24. It's pretty well a 30 second
24. It's pretty well a 30 second
solve. Definitely
better. That's pretty
nice. I think we will just look
nice. I think we will just look
at 2561.
That's a clean RL
That's a clean RL
curve. That is solid.
You kind of wonder if at the end
um it doesn't
um it doesn't
get it's a little shallower. You almost
get it's a little shallower. You almost
wonder if I want to start sweeping coine
wonder if I want to start sweeping coine
and kneeling params. That would be a bit
and kneeling params. That would be a bit
much.
much.
But you're pretty well solved in 30
seconds. This is a 78 million step run.
Uh, no. This is the final learning
Uh, no. This is the final learning
rate. Don't worry about
rate. Don't worry about
that. 4096 total
that. 4096 total
m, which is what you would expect for a
m, which is what you would expect for a
very efficient run. It's
perfect. Let's look at some of these
perfect. Let's look at some of these
hypers.
hypers.
So I think the default is 0.9 here
So I think the default is 0.9 here
and.999. So actually very close to the
and.999. So actually very close to the
defaults. Adam epsilon has gone all the
defaults. Adam epsilon has gone all the
way
way
down. That's
down. That's
interesting. Neiling the learning rate.
interesting. Neiling the learning rate.
Yes, it increased the maximum batch
Yes, it increased the maximum batch
size. That means I have to up this
size. That means I have to up this
number yet again.
number yet again.
Horizon. Let's actually get the
Horizon. Let's actually get the
um let's get the config window open so I
um let's get the config window open so I
can like tweak some of these
live. This is a really nice result.
Okay. So, for sweep ranges
Okay. So, for sweep ranges
here, I set a max of
here, I set a max of
64 and go up to
64 and go up to
128. I don't know if that will create
128. I don't know if that will create
invalid
shouldn't create invalid uh invalid
shouldn't create invalid uh invalid
settings. So, I think that's
settings. So, I think that's
good. Bat size actually has to go up as
well. It's at the upper end of this. So,
well. It's at the upper end of this. So,
this is
one. Yeah.
Do we increase the
Do we increase the
mean? Think we do increase the
mean. Adam epsilon is
uh is it
Add a couple zeros in there. I think you
Add a couple zeros in there. I think you
can actually just do one
can actually just do one
e minus 12 or
e minus 12 or
whatever. We'll leave it for
now. What else has been swept here?
now. What else has been swept here?
Okay, interestingly, we had a very high
Okay, interestingly, we had a very high
entropy coefficient before. Um, but now
entropy coefficient before. Um, but now
it is not anywhere near that. So, I
it is not anywhere near that. So, I
guess it just found a different
guess it just found a different
setting. Lambda gamma within normal
setting. Lambda gamma within normal
ranges I would
say. Yeah. 9999. Okay. So, within normal
say. Yeah. 9999. Okay. So, within normal
ranges, mini batch size of 8192. I think
ranges, mini batch size of 8192. I think
that's my default.
And the value function coefficient is
And the value function coefficient is
[Music]
2.17 but max grad norm. Did I see that
2.17 but max grad norm. Did I see that
in there? 0.38. So it's interesting that
in there? 0.38. So it's interesting that
it doesn't always find oh wait here
it doesn't always find oh wait here
there's also I missed the learning rate
there's also I missed the learning rate
is very high. So it's interesting it
is very high. So it's interesting it
doesn't always find like the exact same
doesn't always find like the exact same
parameters. That kind of means that
parameters. That kind of means that
either there are like multiple good
either there are like multiple good
regions or that maybe some of these are
regions or that maybe some of these are
just stable across very wide ranges
just stable across very wide ranges
though. I think it's likely the
though. I think it's likely the
former. Okay, let's get these
former. Okay, let's get these
into let's get these into
into let's get these into
breakout. Make sure this
replicates. I'll post this as well cuz
replicates. I'll post this as well cuz
this is a cool result.
You see, one of my contributors has
You see, one of my contributors has
gotten Path of
gotten Path of
Exile. Chat's not up,
Exile. Chat's not up,
FYI. My bad. Morning. Muan seems faster
FYI. My bad. Morning. Muan seems faster
with Breakout at least.
with Breakout at least.
Yep. It's uh I think Muan is going to be
Yep. It's uh I think Muan is going to be
just a good addition overall. How was
just a good addition overall. How was
your run yesterday? Run was pretty good.
your run yesterday? Run was pretty good.
Did about six miles with my
Did about six miles with my
dad. We had to stop for something after
dad. We had to stop for something after
four miles, but then we went fast for
four miles, but then we went fast for
the last two, so it was
the last two, so it was
good. Went to the gym after that.
good. Went to the gym after that.
Haven't been to that gym in a while.
Haven't been to that gym in a while.
I've never been into their big
I've never been into their big
bodybuilding
bodybuilding
section. And
section. And
uh it's actually like a ridiculously
uh it's actually like a ridiculously
ridiculously well equipped gym. It's
ridiculously well equipped gym. It's
like all of the best machines on the
like all of the best machines on the
market and it with a $30 membership.
market and it with a $30 membership.
It's
crazy. I was there doing a little bit of
crazy. I was there doing a little bit of
reconnaissance trying to figure out what
reconnaissance trying to figure out what
I want to
buy. Found a few awesome things. No, I
buy. Found a few awesome things. No, I
am buying equipment cuz this gym is here
am buying equipment cuz this gym is here
in Florida. Equipment's for Maryland.
Yeah, it's like 30 bucks a month and
Yeah, it's like 30 bucks a month and
like it's it's four separate gyms in one
like it's it's four separate gyms in one
gym with like I don't know at least a
gym with like I don't know at least a
hundred different machines. They have
hundred different machines. They have
like probably every Atlantis
like probably every Atlantis
Prime Arsenal
Prime Arsenal
um they've got like every good machine
um they've got like every good machine
that you would want to see. Are you
that you would want to see. Are you
moving or I seasonally? It's going to be
seasonal. Florida's my resident still
seasonal. Florida's my resident still
and I'm here in the
winter. Need a summer home in Colorado.
Yeah, Florida in the summer is just not
Yeah, Florida in the summer is just not
a fun time at
a fun time at
all.
Generally, just really
isn't. So, I spend um the plan is winter
isn't. So, I spend um the plan is winter
in
in
like a couple months in the winter, two,
like a couple months in the winter, two,
three months in the winter here. Uh you
three months in the winter here. Uh you
know, few months in the summer in
know, few months in the summer in
California, depending on what I'm doing
California, depending on what I'm doing
there, and then uh fall and spring in
there, and then uh fall and spring in
uh in Maryland, this is going to be the
uh in Maryland, this is going to be the
most likely
most likely
outcome. And the Maryland one is going
outcome. And the Maryland one is going
to be the best outfitted for all my
to be the best outfitted for all my
work. So, we have the most space by a
work. So, we have the most space by a
mile.
Yep. That it
is. There's a reason I'm not staying in
is. There's a reason I'm not staying in
California year
California year
round. Isn't that
round. Isn't that
funny? That's how badly they [ __ ]
funny? That's how badly they [ __ ]
themselves with uh the
themselves with uh the
current with what they're doing
current with what they're doing
currently.
currently.
If they had no state tax, it'd be pretty
If they had no state tax, it'd be pretty
easy. Like everyone would just be
there.
Moving.
Moving.
Oh, I'm with my family here and kind of
Oh, I'm with my family here and kind of
in Maryland. Not
in Maryland. Not
quite. They paid double for gas. Yeah. I
quite. They paid double for gas. Yeah. I
don't I It's kind of sad. I don't know
don't I It's kind of sad. I don't know
what they're
doing. The economics are totally
doing. The economics are totally
screwed. Um, at least I will say Palo
screwed. Um, at least I will say Palo
Alto is still like it's nice
Alto is still like it's nice
there. SF is a hell hole. Like with some
there. SF is a hell hole. Like with some
of the stuff that's happened in SF
of the stuff that's happened in SF
lately. Uh, I don't think I'm even
lately. Uh, I don't think I'm even
taking business meetings in SF anymore.
taking business meetings in SF anymore.
Like I think I'm just not going to SF.
Like I think I'm just not going to SF.
It's like NAS screw
It's like NAS screw
that. Y'all can come down to Mountain
that. Y'all can come down to Mountain
View or Palo Alto where we're
civilized is run by the VC car. It's
civilized is run by the VC car. It's
certainly run by a
certainly run by a
cartel. I don't know about the VC
cartel. I don't know about the VC
one. You got the first part right.
But yeah, when founders are getting beat
But yeah, when founders are getting beat
over the head with metal pipes, no thank
over the head with metal pipes, no thank
you. I have worked too hard to live
you. I have worked too hard to live
somewhere or to even be somewhere where
somewhere or to even be somewhere where
founders get beat over the head with
founders get beat over the head with
metal
metal
pipes. No thank
pipes. No thank
you. I will be literally anywhere
you. I will be literally anywhere
else. That sounds like a smarter thing
else. That sounds like a smarter thing
to do.
especially in AI. I didn't realize value
especially in AI. I didn't realize value
co function could go above. It's a
co function could go above. It's a
coefficient. It's not like a logic space
coefficient. It's not like a logic space
thing, right? It's just a multiple of a
thing, right? It's just a multiple of a
loss. And it couldn't before in sweeps.
loss. And it couldn't before in sweeps.
I increased the range because I noticed
I increased the range because I noticed
it was always up against
one. That's part of one of the things.
one. That's part of one of the things.
Uh I don't know if you were here for
Uh I don't know if you were here for
when I started stream and said that, but
when I started stream and said that, but
when you see that your sweeps are
when you see that your sweeps are
pushing up against one end of the range,
pushing up against one end of the range,
you got to increase the
you got to increase the
range. You see? Now, obviously, you
range. You see? Now, obviously, you
don't go, "Oh, well, what if we just
don't go, "Oh, well, what if we just
make gamma over one?" Yeah, that doesn't
make gamma over one?" Yeah, that doesn't
make any sense.
I haven't swept any of the clip
I haven't swept any of the clip
coefficients in a while either. We might
coefficients in a while either. We might
go back to doing that again. But yeah,
go back to doing that again. But yeah,
this is kind of cool. Back size 500k
this is kind of cool. Back size 500k
breakout par amps. We can get rid of
breakout par amps. We can get rid of
these now.
That's pretty damn cool,
right? Why is this one 55
seconds? Oh, hold. Hold on.
seconds? Oh, hold. Hold on.
cuz I just ran it for longer to make
cuz I just ran it for longer to make
sure it would be stable. Let's run it a
sure it would be stable. Let's run it a
couple times to see uh if it's, you
couple times to see uh if it's, you
know, needs any tweak. But yeah, this is
know, needs any tweak. But yeah, this is
what I'm saying, right? Like once you
what I'm saying, right? Like once you
get everything lined up
get everything lined up
correctly. Yeah, this is
breakout. I mean, what we're doing here,
breakout. I mean, what we're doing here,
you know, we're kind of using the
you know, we're kind of using the
breakout speedrun as just a benchmark
breakout speedrun as just a benchmark
for general algorithm stuff.
for general algorithm stuff.
It's not like I'm hacking on the reward
It's not like I'm hacking on the reward
function or anything. I haven't touched
function or anything. I haven't touched
it. And we've gone down from 5 minutes
it. And we've gone down from 5 minutes
to damn near 30
seconds. And then the original breakout
seconds. And then the original breakout
like that most of the labs use takes
like that most of the labs use takes
several
hours. What were the changes that made
hours. What were the changes that made
the curves that smooth? So this is just
the curves that smooth? So this is just
running faster uh and with a
running faster uh and with a
substantially larger batch size. So
substantially larger batch size. So
that's going to prevent some of the
that's going to prevent some of the
jaggedness. But then like the big dips
jaggedness. But then like the big dips
in stuff that you were getting
in stuff that you were getting
before, better optimizer, better
before, better optimizer, better
learning rateuler,
learning rateuler,
um actually just improving the speed of
um actually just improving the speed of
some of the stuff allows it to take
some of the stuff allows it to take
advantage of larger batch sizes which
advantage of larger batch sizes which
then translates to smoother curves.
then translates to smoother curves.
Like, yeah, it's kind of magic when you
Like, yeah, it's kind of magic when you
get everything
get everything
right. It just
works. That's another run right
there. And actually, you see how there's
there. And actually, you see how there's
this little like dip, right? Like this.
this little like dip, right? Like this.
Like these dips aren't even from it
Like these dips aren't even from it
being weird. These dips are from the
being weird. These dips are from the
cosine and kneeling learning rate
cosine and kneeling learning rate
scheduling.
scheduling.
Yeah. No, this is literally compared to
Yeah. No, this is literally compared to
like original clean RL speeds. And you
like original clean RL speeds. And you
got to give them a little bit of credit
got to give them a little bit of credit
because I think you know they were doing
because I think you know they were doing
from pixels. So, okay, the net has to be
from pixels. So, okay, the net has to be
a bit bigger. But still, like the
a bit bigger. But still, like the
original
original
there, this is over 1,500 times
there, this is over 1,500 times
faster. And I think even over an
faster. And I think even over an
optimized implementation like the
optimized implementation like the
optimized clean RL or whatever which
optimized clean RL or whatever which
doesn't even have LSTM support I think
doesn't even have LSTM support I think
is like 300 times slower than
this. Like I said this is what we're
this. Like I said this is what we're
doing with RL. Okay. Now imagine this
doing with RL. Okay. Now imagine this
everywhere in RL, right? Imagine this on
everywhere in RL, right? Imagine this on
neural MMO 3 on whatever industry
neural MMO 3 on whatever industry
problem you do everywhere. And we let's
problem you do everywhere. And we let's
imagine that we also figure out the like
imagine that we also figure out the like
roughly out of the box hyperparameters
roughly out of the box hyperparameters
that you're going to get close to this
that you're going to get close to this
before you even
before you even
tune. That's RL back right there, man.
tune. That's RL back right there, man.
That's RL
back. Look at that. Little bit of
back. Look at that. Little bit of
variance. Little bit of variance. Not
variance. Little bit of variance. Not
much though.
I think we can make this even a little
I think we can make this even a little
faster. Hang
on. Yeah, cuz this agent stabs. Hold on.
This is 50 million
steps. Maybe we reduce it to
60. See how that changes the curves.
I always go a little bit above whatever
I always go a little bit above whatever
we got uh in the train run in steps cuz
we got uh in the train run in steps cuz
like even if it's this consistent,
like even if it's this consistent,
right, I'm always going to assume that
right, I'm always going to assume that
we got this run in the training, right?
we got this run in the training, right?
We got a little bit lucky. So I have to
We got a little bit lucky. So I have to
add a few steps in case we get this run
add a few steps in case we get this run
right when we actually go to do it.
Does torch compile help? Let me uh I
Does torch compile help? Let me uh I
will
will
check. Yeah. So that worked perfectly.
Not
noticeably. No noticeable
noticeably. No noticeable
difference though. Possibly, you know,
difference though. Possibly, you know,
there's like the cudigraph stuff that we
there's like the cudigraph stuff that we
could look into that could make a decent
could look into that could make a decent
difference, but there's no noticeable
difference, but there's no noticeable
difference right here with that.
linear. Yes, linear is the default
linear. Yes, linear is the default
captain that we replaced with cosine and
captain that we replaced with cosine and
cosine's better. This is insane. I
cosine's better. This is insane. I
remember training a baseline months ago.
remember training a baseline months ago.
Struggle to get five miss now 30 to 40.
Struggle to get five miss now 30 to 40.
Yeah. Isn't this
Yeah. Isn't this
cool? And look how consistent this is as
cool? And look how consistent this is as
well.
well.
Like this is not just faster, it's also
Like this is not just faster, it's also
like fundamentally this feels like
like fundamentally this feels like
stable. And you look at the hyper pram
stable. And you look at the hyper pram
and they actually make
sense. I mean, yeah, Spencer helped us
sense. I mean, yeah, Spencer helped us
get it to 5 minutes as well. It was way
get it to 5 minutes as well. It was way
longer before that.
That's
what's just see if this does
anything. I don't have remotely good
anything. I don't have remotely good
params. Let's just see if we be a little
cocky. Several hours with high variance
cocky. Several hours with high variance
down to 30 seconds with Yeah, exactly.
down to 30 seconds with Yeah, exactly.
Now, to be fair, a big chunk of the
Now, to be fair, a big chunk of the
initial Perf game there, like we had to
initial Perf game there, like we had to
cut down uh we had to go from the
cut down uh we had to go from the
original Atari M to our version that's
original Atari M to our version that's
way faster cuz the original Atari we
way faster cuz the original Atari we
could only get to run about 30,000 steps
could only get to run about 30,000 steps
per
per
second. I mean, but still, if we have to
second. I mean, but still, if we have to
run 60 million
steps, I think that's still down to like
steps, I think that's still down to like
40 minutes or whatever, uh, with the
40 minutes or whatever, uh, with the
same algorithm. And then the thing is it
same algorithm. And then the thing is it
would tune separately. Like the tuning
would tune separately. Like the tuning
would apply differently. So 40 minutes
would apply differently. So 40 minutes
would be like a high-end. It's probably
would be like a high-end. It's probably
way shorter than
way shorter than
that. And the original ends are in C.
that. And the original ends are in C.
It's just that people decided to train
It's just that people decided to train
on pixels for no damn
reason. Okay, so this is like the
reason. Okay, so this is like the
original uh pong params which are
original uh pong params which are
completely wrong at the moment, right?
completely wrong at the moment, right?
like the pong params are completely
like the pong params are completely
wrong because of all the changes that we
wrong because of all the changes that we
made and um with the new optimizer just
made and um with the new optimizer just
like throwing in muon and the like
like throwing in muon and the like
network changes and cosign and dealing
network changes and cosign and dealing
with whatever the hell hyperps are
there. It still
works. And not only does it still work,
works. And not only does it still work,
it still works with a consistent
it still works with a consistent
training curve. These little jaggies
training curve. These little jaggies
here are just like the batch size being
here are just like the batch size being
slightly smaller. The point is you don't
slightly smaller. The point is you don't
get any like massive dips and then
get any like massive dips and then
recoveries.
So yeah, that's just pong
solved. I was going to try to get it on
solved. I was going to try to get it on
neural MMO and stuff right
neural MMO and stuff right
now, but connect four is also good.
Look at
Look at
that. I think we're going to tune
that. I think we're going to tune
everything, Captain. So, I think what
everything, Captain. So, I think what
we'll do now is let's see if I can go
we'll do now is let's see if I can go
look and uh like look at the
look and uh like look at the
defaults if we can improve some of the
defaults if we can improve some of the
defaults and then see if like you know
defaults and then see if like you know
with the defaults changed if we can like
with the defaults changed if we can like
get better perf like let's see if I can
get better perf like let's see if I can
get Pong to do way better just by
get Pong to do way better just by
changing the defaults and then see if
changing the defaults and then see if
those defaults like just learn anything
those defaults like just learn anything
at all on a harder end. We'll do a lot
at all on a harder end. We'll do a lot
of this type of stuff today. And then
of this type of stuff today. And then
aside from that, the only two things I
aside from that, the only two things I
think I really need to do today, I have
think I really need to do today, I have
uh one client EN that uh needs to be
uh one client EN that uh needs to be
like integrated and we need to throw
like integrated and we need to throw
some puffer stuff on and then I have
some puffer stuff on and then I have
another client and that needs uh me to
another client and that needs uh me to
look at what the hell's wrong with the
look at what the hell's wrong with the
god awful
Python. And other than that, I think
Python. And other than that, I think
we're good. So, I have lots of time now.
we're good. So, I have lots of time now.
This week, we finished one of the uh the
This week, we finished one of the uh the
previous
previous
contracts, which is
great. So, I have a little more
time. Okay, let's look at these in
time. Okay, let's look at these in
comparison to the defaults next.
very high learning rate.
Uh, float 16 is slower for small
Uh, float 16 is slower for small
networks. I tested it. It's faster. It's
networks. I tested it. It's faster. It's
I got like a 15% f boost on neural MMO
I got like a 15% f boost on neural MMO
with a like 1 mil perm net and it was
with a like 1 mil perm net and it was
substantially slower uh on the smaller
substantially slower uh on the smaller
nets that we use normally
700k. It might be a little
faster. Uh, I wouldn't do that though
faster. Uh, I wouldn't do that though
until you've timed it, man.
Also, also I have a way to eliminate
Also, also I have a way to eliminate
copy time. Um, I don't think it works
copy time. Um, I don't think it works
until Python 3.14,
until Python 3.14,
though. Let me show you this real quick
though. Let me show you this real quick
because I thought this was kind of cool.
because I thought this was kind of cool.
I had a really productive
I had a really productive
Saturday. It was hard work. I was like
Saturday. It was hard work. I was like
grinding this stuff out on Saturday. But
grinding this stuff out on Saturday. But
uh
here I made a threading based back end
basically. So this is multi-threading
basically. So this is multi-threading
back
back
end and uh this is kind of cool because
end and uh this is kind of cool because
what you can do here is you can pass
what you can do here is you can pass
stuff in as torch tensors, right? So you
stuff in as torch tensors, right? So you
pass in torch
pass in torch
tensors and then uh on the individual
tensors and then uh on the individual
process, right? or on the thread you can
process, right? or on the thread you can
queue up the transfer directly to the
queue up the transfer directly to the
torch
torch
tensor. So you do the async uh the async
tensor. So you do the async uh the async
memory you do the memory transfers async
memory you do the memory transfers async
which I think depending on how CUDA
which I think depending on how CUDA
works under the hood should actually cut
works under the hood should actually cut
that time out
that time out
completely. Now the problem with this is
completely. Now the problem with this is
I tried to do this with the
I tried to do this with the
multipprocessing version with uh PyTorch
multipprocessing version with uh PyTorch
like shared memory tensors and uh I it's
like shared memory tensors and uh I it's
technically possible but it's really
technically possible but it's really
like a total pain in the ass because of
like a total pain in the ass because of
the way that um you you can't use
the way that um you you can't use
multiprocessing fork with uh with this
multiprocessing fork with uh with this
and we rely heavily on fork in order for
and we rely heavily on fork in order for
this to work. So really, it's just going
this to work. So really, it's just going
to be a lot easier once we get the uh
to be a lot easier once we get the uh
true threading stuff in Python
true threading stuff in Python
314. No
314. No
IPC. Um I mean, no, there's still
IPC. Um I mean, no, there's still
like there's still async shenanigans.
like there's still async shenanigans.
You can't just be totally stupid about
You can't just be totally stupid about
stuff because threads versus
stuff because threads versus
multipprocessing. Like the
multipprocessing. Like the
implementation is actually going to look
implementation is actually going to look
very very similar.
Yeah. Have you set a 2.5 release
Yeah. Have you set a 2.5 release
goal? Not
goal? Not
really. It's kind of just whenever I
really. It's kind of just whenever I
feel like we have enough stuff to merit
feel like we have enough stuff to merit
a big release. I don't like doing short
a big release. I don't like doing short
release cycles cuz like you know there's
release cycles cuz like you know there's
always going to be a certain number of
always going to be a certain number of
bugs that you have to fix with every
bugs that you have to fix with every
release and you have to do a lot of work
release and you have to do a lot of work
to like get everything back stable and
to like get everything back stable and
stuff. So, I kind of like having the
stuff. So, I kind of like having the
longer release cycles where I can really
longer release cycles where I can really
like come up with something really cool
like come up with something really cool
that'll get people excited and then, you
that'll get people excited and then, you
know, if if people want access to stuff
know, if if people want access to stuff
early, they can either very closely
early, they can either very closely
monitor the dev branch or if they're
monitor the dev branch or if they're
companies, you know, they can get a
companies, you know, they can get a
support
contract and then you basically get
contract and then you basically get
access to news on all the developments
access to news on all the developments
up to six months early.
I think that's a pretty good model. It
I think that's a pretty good model. It
saves me
saves me
work and uh you know companies get value
work and uh you know companies get value
out of it
too. I like
this. Don't don't do LLMs, folks.
this. Don't don't do LLMs, folks.
Don't do LLMs. Just say no to
LLM. Just say
no. Just say no to
laws. I like that.
Okay, first thing is what if I just do
Okay, first thing is what if I just do
this?
I it the thing is they're kind of right.
I it the thing is they're kind of right.
Like there's so much stupid hype in LLMs
Like there's so much stupid hype in LLMs
right
right
now. Yeah. Let me show you the latest
now. Yeah. Let me show you the latest
thing that I tried to use LLMs for. It's
thing that I tried to use LLMs for. It's
like I literally regret opening them
like I literally regret opening them
every single time I do.
Go find me a piece of ab equipment from
Go find me a piece of ab equipment from
one of these brands. Okay, try this.
one of these brands. Okay, try this.
Doesn't
Doesn't
exist. Just made up a piece of
exist. Just made up a piece of
equipment. Oh, look. See, I searched all
equipment. Oh, look. See, I searched all
the web pages. I'm going to go actually
the web pages. I'm going to go actually
return search results. Nope. Made it
up. And then I tried chat GPT. And guess
up. And then I tried chat GPT. And guess
what? it
uh it didn't make it up, but it gave me
uh it didn't make it up, but it gave me
a completely stupid suggestion that made
a completely stupid suggestion that made
no sense.
Yeah, exactly. And then and then you
Yeah, exactly. And then and then you
have like the absolute morons who are
have like the absolute morons who are
like, "Hey, you need to learn how to
like, "Hey, you need to learn how to
become the prompt wizard. See, I'm so
become the prompt wizard. See, I'm so
smart. I know how to type things into an
smart. I know how to type things into an
LM even though I can't write any code.
Uhoh, that doesn't look
Uhoh, that doesn't look
right.
Huh?
What object is an art form?
Well, uh, there was something happening
here is
here is
not I'd rather spend my time learning
not I'd rather spend my time learning
how to do the thing rather than learning
how to do the thing rather than learning
how to coax the LLM into figuring out a
how to coax the LLM into figuring out a
thing.
making numerical models. I don't know.
making numerical models. I don't know.
I've tried it in like various different
I've tried it in like various different
capacities in my research and it's
capacities in my research and it's
always been a waste of time. Like it's
always been a waste of time. Like it's
kind of a decent rubber duck that like
kind of a decent rubber duck that like
can kind of spit out some sort of math
can kind of spit out some sort of math
looking
looking
things. You can describe formulas and
things. You can describe formulas and
it'll write them up in Latte like really
it'll write them up in Latte like really
really nice and quick. It's kind of nice
really nice and quick. It's kind of nice
for that.
for that.
But like it can't really it just it's
But like it can't really it just it's
just just not that
smart. Report interval is 128.
I don't know. Maybe you've got a good
I don't know. Maybe you've got a good
use case,
but I think I'm doing even simpler math
but I think I'm doing even simpler math
than you and it's not that
helpful. Something is definitely screwy
helpful. Something is definitely screwy
here that
here that
um we're not getting
um we're not getting
back report results.
Oh, there it is.
What did I have before? Just like really
What did I have before? Just like really
tiny mini batch
tiny mini batch
size. This was what I had before.
Wow. But that's going to make it like
Wow. But that's going to make it like
slower wall
clock. I mean, it
clock. I mean, it
runs is probably faster, too, right?
runs is probably faster, too, right?
Like if I just do like 150
Like if I just do like 150
mil. This is probably still faster than
mil. This is probably still faster than
the
original. Let's not do checkpoint
original. Let's not do checkpoint
interval
25. GPU drive question. Does splitting
25. GPU drive question. Does splitting
each observation
each observation
modality to be
modality to be
processed independently in their own
processed independently in their own
layer make that much of a difference
layer make that much of a difference
versus one layer for all
ops? Does splitting each
observation. I think we've talked
observation. I think we've talked
something about architectures, right,
something about architectures, right,
Spencer? Because the question doesn't
Spencer? Because the question doesn't
make
sense. And this is why I don't want to
sense. And this is why I don't want to
delete
delete
this.
this.
Um, let's find another one.
What's
this? Paint online. Cool. Um, so like
this? Paint online. Cool. Um, so like
you
have
have
like self
So how do you make how does it make
So how do you make how does it make
sense to process these together? Because
sense to process these together? Because
here you have this is a
here you have this is a
vector, right? And like this needs to go
vector, right? And like this needs to go
through a linear
through a linear
layer. Okay? And then this needs to go
layer. Okay? And then this needs to go
this other thing this needs to go like
this other thing this needs to go like
through some linear layers or whatever
through some linear layers or whatever
and then needs to get like maxed
and then needs to get like maxed
right as an embedding. And then this
right as an embedding. And then this
probably needs to go through like you
probably needs to go through like you
know a CNN of some
sort and then go through a linear
sort and then go through a linear
layer. So you can't like concatenate all
layer. So you can't like concatenate all
these together and put them through the
these together and put them through the
same
same
layer, right?
layer, right?
So what's the question
here? It's not whether it makes as much
here? It's not whether it makes as much
of a difference. It's like how do you
of a difference. It's like how do you
even do it the other way? You're not
even do it the other way? You're not
going to flatten all the
data. Well, yeah, but that's kind of
data. Well, yeah, but that's kind of
like saying, okay, an image is a list of
like saying, okay, an image is a list of
floats. Why don't we use flat like why
floats. Why don't we use flat like why
don't we use linear layers for like
don't we use linear layers for like
instead of compat, right?
Do you know
why? I think we've had this conversation
why? I think we've had this conversation
before. It's a very important and
before. It's a very important and
fundamental one to understand. If
fundamental one to understand. If
not, like why do we
not, like why do we
use if you have an image,
use if you have an image,
right? Why do we use a competent instead
right? Why do we use a competent instead
of a linear layer?
It's separation and it's the same it's
It's separation and it's the same it's
the same intuition for everything. It
the same intuition for everything. It
just applies a little differently.
just applies a little differently.
Right? So the idea here is that if you
Right? So the idea here is that if you
were to learn separately a weight for
were to learn separately a weight for
each of these inputs like a linear layer
each of these inputs like a linear layer
does then you have to learn like all
does then you have to learn like all
sorts of different like you have to
sorts of different like you have to
learn a representation for here you have
learn a representation for here you have
to learn a representation here. You have
to learn a representation here. You have
to learn a representation here. Now what
to learn a representation here. Now what
a comm says is hey you probably want to
a comm says is hey you probably want to
learn the same representation over here
learn the same representation over here
right as over here. So no matter where
right as over here. So no matter where
you apply this filter to the image it's
you apply this filter to the image it's
going to do the same thing and you get
going to do the same thing and you get
this automatically just from the
this automatically just from the
structure of the network. Right? That's
structure of the network. Right? That's
why you do it. It's because you assume
why you do it. It's because you assume
that in an image it says hey you know
that in an image it says hey you know
this part of the image over here is
this part of the image over here is
generally going to behave the same as
generally going to behave the same as
over here is over here is over here
over here is over here is over here
right now you can construct a setting in
right now you can construct a setting in
which this doesn't hold true right you
which this doesn't hold true right you
can construct counter examples but
can construct counter examples but
generally this is a pretty darn good
generally this is a pretty darn good
assumption okay now the same thing with
assumption okay now the same thing with
the cars
right if you have like one two three,
right if you have like one two three,
four different cars you can see or
four different cars you can see or
entities. This is an entity encoder,
entities. This is an entity encoder,
right? What happens if I switch the
right? What happens if I switch the
positions of these
positions of these
two, right? What happens if I see the
two, right? What happens if I see the
cars in a different order? I have to
cars in a different order? I have to
learn a representation now with a flat
learn a representation now with a flat
linear layer that is robust to that. And
linear layer that is robust to that. And
that's really hard to do, right? You
that's really hard to do, right? You
have to kind of relearn the same
have to kind of relearn the same
representation many
representation many
times. But if you use an entity style
times. But if you use an entity style
encoder where you just do this in max,
encoder where you just do this in max,
then you can flip these around however
then you can flip these around however
you want, right? And it's invariant. You
you want, right? And it's invariant. You
provably will get the same
output. So that's why you do
output. So that's why you do
this. And now the thing with uh like the
this. And now the thing with uh like the
same thing with attention, right? What
same thing with attention, right? What
is attention? Attention is just a fancy
is attention? Attention is just a fancy
way of doing this this exact operation.
way of doing this this exact operation.
what I just described here. This is an
what I just described here. This is an
attentional encoder, right? A
attentional encoder, right? A
transformer is just a very fancy way of
transformer is just a very fancy way of
doing this operation, but it still has
doing this operation, but it still has
this key property of the order doesn't
this key property of the order doesn't
matter. Now, why you do this for
matter. Now, why you do this for
language is a little bit more
language is a little bit more
complicated because you also have
complicated because you also have
positional encodings. But, you know, for
positional encodings. But, you know, for
this type of case that holds true
precisely. So, very very important to
precisely. So, very very important to
understand that. And also uh we solved
understand that. And also uh we solved
breakout while I was talking which is
breakout while I was talking which is
with like a completely random asset of
with like a completely random asset of
hyperparameters and in less time than
hyperparameters and in less time than
the original. We didn't get like so this
the original. We didn't get like so this
is not even a weird graph. It's just we
is not even a weird graph. It's just we
didn't get enough like data points in
didn't get enough like data points in
it. But uh yeah so there we go. There's
it. But uh yeah so there we go. There's
breakout in a minute. Uh I think the
breakout in a minute. Uh I think the
original was breakout in 30 seconds. So
original was breakout in 30 seconds. So
we'll have to sweep this separately. But
we'll have to sweep this separately. But
it looks like just out of the box those
it looks like just out of the box those
hypers are kind of fine.
hypers are kind of fine.
Moa use one for the ordering issue. MOA
Moa use one for the ordering issue. MOA
doesn't have any sort of entity encoder.
doesn't have any sort of entity encoder.
Um MOA just has a conf
Um MOA just has a conf
encoder. It just has a com encoder, I'm
encoder. It just has a com encoder, I'm
pretty
pretty
sure. So I just packed the entities like
sure. So I just packed the entities like
I picked whatever properties I wanted
I picked whatever properties I wanted
you to be able to see of the other
you to be able to see of the other
agents and I pack them into the
agents and I pack them into the
conf. Same thing with neural MMO.
It's also a perfectly fine
representation. I did that so I wouldn't
representation. I did that so I wouldn't
have to deal with entity
encoders. Okay, so this is pretty sweet.
encoders. Okay, so this is pretty sweet.
Uh, what else can we just insta solve
Uh, what else can we just insta solve
with this?
Enduro.
This doesn't even have optimized
hypers. Easier to see. I'm going to go
hypers. Easier to see. I'm going to go
through
through
them. I'm working my way up.
So the original config here is pretty
fast but days completed is stuck at
fast but days completed is stuck at
zero.
I think this one just takes a little bit
I think this one just takes a little bit
though to uh because like the episodes
though to uh because like the episodes
are really long so you just have to
are really long so you just have to
like Yeah, it's
like Yeah, it's
tough. Past cars is also a decent one I
think. Yeah, there's days completed
think. Yeah, there's days completed
going up.
going up.
I think I got to ask B why cars pass
I think I got to ask B why cars pass
can't be the score because I think past
can't be the score because I think past
car should pretty well just tell you
car should pretty well just tell you
um what is the best
Okay. So, here's your days completed.
Okay. And now what happens if I just get
Okay. And now what happens if I just get
rid of all this?
rid of all this?
So say a 1.1
I mean, this is like the same set of
I mean, this is like the same set of
hypers from everything. Hey, how's it
hypers from everything. Hey, how's it
going,
going,
man? This is the same set of
man? This is the same set of
hypers for three environments so far or
hypers for three environments so far or
whatever. And it's like these are fine
whatever. And it's like these are fine
for everything. This is pretty darn
for everything. This is pretty darn
cool. And we haven't even fixed the GA
cool. And we haven't even fixed the GA
nonsense
yet. It's not
bad. We'll have to sweep it. But I think
bad. We'll have to sweep it. But I think
this is fine for now. I It's like It'll
this is fine for now. I It's like It'll
take off. You give it a little
longer. I mean, that
works. What do we do
works. What do we do
next? Which end? Let me
next? Which end? Let me
see.
see.
Um,
our neural MMO is going to just take
our neural MMO is going to just take
longer.
Is Spencer still here? Let's see. Tower
climb. How long does tower climb take to
climb. How long does tower climb take to
train?
Ah, we got to do the we got to take this
Ah, we got to do the we got to take this
these steps way
down 50
mil. Do you think I should be able to
mil. Do you think I should be able to
pull dev branch? I mean, if you are
pull dev branch? I mean, if you are
going to overwrite your local, I would
going to overwrite your local, I would
make sure you have that saved because
make sure you have that saved because
dev is never like guaranteed stable. But
dev is never like guaranteed stable. But
yeah, we have a whole bunch of cool
yeah, we have a whole bunch of cool
stuff in dev for
stuff in dev for
sure. Adjust the number of PLG
sure. Adjust the number of PLG
maps. All
maps. All
right. What do you think it should be,
Spencer? I
Spencer? I
tried take a few minutes to generate
tried take a few minutes to generate
them all.
It looked like it was only doing 100.
It looked like it was only doing 100.
Oh, is it
more? Isn't the C isn't the generation
more? Isn't the C isn't the generation
code in C? Why does it take so long?
You need to do some fancy
checking
online. Ah, okay. It's verifying.
That has like 50 in
there. Oh, adjust it up. I
see here. Let me get let me fix one
see here. Let me get let me fix one
thing first.
Yeah, I broke uh I broke multilayer LS
Yeah, I broke uh I broke multilayer LS
cam. Doesn't matter.
And does it start learning relatively
And does it start learning relatively
quickly or not
really? Cool. I pretty much just want to
really? Cool. I pretty much just want to
test like our new params versus whatever
test like our new params versus whatever
you swept.
I forgot we had tower climb.
I forgot we had tower climb.
Now that's a nice new
Now that's a nice new
environment for testing things with.
Um, it's whatever the it's just the
Um, it's whatever the it's just the
optimizer. Muon has some stuff set by
optimizer. Muon has some stuff set by
default.
default.
I think we're we're going to like get
I think we're we're going to like get
rid of this in uh whatever version we
rid of this in uh whatever version we
release because it's really
obnoxious, right? I think it should only
obnoxious, right? I think it should only
bother doing this stuff if you set like
bother doing this stuff if you set like
the rest of the optimization flags to
compile. Okay, so this is um your hypers
compile. Okay, so this is um your hypers
with the new
changes. You're at a million steps per
changes. You're at a million steps per
second already. So, I wouldn't be
second already. So, I wouldn't be
surprised that we underperform your
hypers. Oh, well, I didn't even change
hypers. Oh, well, I didn't even change
any of that yet, Spencer. This is just
any of that yet, Spencer. This is just
from like our general purpose
improvements. It'll go faster than this,
improvements. It'll go faster than this,
don't
worry. What is it? Rose cleared.
worry. What is it? Rose cleared.
Uh the one thing I would ask you to do
Uh the one thing I would ask you to do
is I want all of the environments to
is I want all of the environments to
have a variable score which is the thing
have a variable score which is the thing
that you optimize over if possible. I
that you optimize over if possible. I
can hack around it in the meantime. Um I
can hack around it in the meantime. Um I
like yeah I can hack around it in the
like yeah I can hack around it in the
meantime but it is way better if all the
meantime but it is way better if all the
ends have a score
variable. I think that we're going to do
variable. I think that we're going to do
that for everything. We'll go back
that for everything. We'll go back
Yeah. Yeah. Yeah. But I think like there
Yeah. Yeah. Yeah. But I think like there
you even if you just duplicate the same
you even if you just duplicate the same
variable name like I think we need to
variable name like I think we need to
have one named score so that when you
have one named score so that when you
run like a sweep or something and you
run like a sweep or something and you
set up your panels right for whatever
set up your panels right for whatever
environment you're looking at you can
environment you're looking at you can
just look at
score. So here's levels completed.
Presumably this is uh 93% of levels
[Music]
Mhm. And now let's see what happens if I
Mhm. And now let's see what happens if I
do this.
I'm going do 2048 M's as well because of
I'm going do 2048 M's as well because of
uh well because of
uh well because of
reasons. Let me see. What did you have
reasons. Let me see. What did you have
on here? Oh, no. You actually did have
on here? Oh, no. You actually did have
two M's, two
two M's, two
workers. So we can do 4096 for you.
That should have been
That should have been
faster. Unless you had a really big mini
faster. Unless you had a really big mini
batch
batch
before. Yeah, you had a big mini batch
before. Yeah, you had a big mini batch
size before, I
think. Yeah. So, uh, the one whatever
think. Yeah. So, uh, the one whatever
the 1 mill or whatever came from,
the 1 mill or whatever came from,
um, our optimizations to that is still
um, our optimizations to that is still
900k. I mean, we can probably, you know,
900k. I mean, we can probably, you know,
maybe your prams are better in this
maybe your prams are better in this
case. We'll see.
Interesting. So, it levels out a little
Interesting. So, it levels out a little
bit at 80
now. What did we screw with
now. What did we screw with
here? Probably gamma lambda the
here? Probably gamma lambda the
culprits.
Something like
that. Oh, entropy is probably or entropy
that. Oh, entropy is probably or entropy
it could
be. No, your entropy is pretty close.
Easy. Well, yeah, but I'm just doing
Easy. Well, yeah, but I'm just doing
quick little experiments anyways right
quick little experiments anyways right
now. We can run full sweep for
now. We can run full sweep for
you,
right? So, we'll leave your hypers
right? So, we'll leave your hypers
alone, but the key thing that I was
alone, but the key thing that I was
looking for, which we confirmed, um, is
looking for, which we confirmed, um, is
that the defaults just do something,
that the defaults just do something,
right? The defaults get you 80% solve
right? The defaults get you 80% solve
rate before you even sweep.
And also we made yours uh your swept
And also we made yours uh your swept
prams go to a
mill. I want to try mobile.
Yeah, it's buffer fast.
MOA is a lot harder. Let's see. Let's
MOA is a lot harder. Let's see. Let's
see if this does
see if this does
anything. MOA is like a lot
anything. MOA is like a lot
harder. Also, I think it's going to
harder. Also, I think it's going to
break some of our
break some of our
um our slicing optimizations.
Well, I didn't I didn't really do very
Well, I didn't I didn't really do very
many experiments on mobile or on neural
many experiments on mobile or on neural
MMO,
right? I kind of just built them when I
right? I kind of just built them when I
was building cool MS and like ran a few
was building cool MS and like ran a few
things.
Like the bots in MOA at the moment, they
Like the bots in MOA at the moment, they
just know how to run down mid and use
just know how to run down mid and use
their abilities. Yes.
How good are the scripted
How good are the scripted
opponents? Um, they run down mid and
opponents? Um, they run down mid and
spam their abilities, I'm pretty sure.
Why is backwards pass so expensive? Cuz
Why is backwards pass so expensive? Cuz
it's set to three update epochs.
This one has a ton of metrics on
it. It is training though.
See, now it wins all the
games.
Okay. What happens if I do this?
This one I remember being a total pain
This one I remember being a total pain
to tune as
well. So I will be very impressed if
well. So I will be very impressed if
this works.
Why is sweet metric radiant towers alive
Why is sweet metric radiant towers alive
and not win rate? Uh because win rate's
and not win rate? Uh because win rate's
going to be zero a lot of the time.
going to be zero a lot of the time.
So, how many towers you have left just
So, how many towers you have left just
ends up being a pretty darn good one
ends up being a pretty darn good one
because also it's like if you win with
because also it's like if you win with
zero towers taken, like having lost
zero towers taken, like having lost
hero's tower, that's also probably a
hero's tower, that's also probably a
better
policy. You can't use D like you can't
policy. You can't use D like you can't
use dire towers taken or whatever
use dire towers taken or whatever
because you can take all the enemy
because you can take all the enemy
towers and still lose.
towers and still lose.
So, it's a little tricky.
Oh.
Haha. And I
slice another optimization.
I will have to come back to this
I will have to come back to this
particular one. Why is it not working in
particular one. Why is it not working in
the meantime
though? I think there's an optimization
though? I think there's an optimization
missing here.
minor bug
X interesting that the
uh ah the end is the slow thing
uh ah the end is the slow thing
now. That's
now. That's
unfortunate, but I can probably fix that
unfortunate, but I can probably fix that
just with
like Get out of here, bot.
like Get out of here, bot.
I build the box here.
run a PL sweep.
Oh, radiant victory one. And it's
Oh, radiant victory one. And it's
faster. I was just doing this on the
faster. I was just doing this on the
side. Look at
that. That's kind of crazy. So, I just
that. That's kind of crazy. So, I just
deleted all the hyper prams. I made it
faster. And uh yeah, there's their
faster. And uh yeah, there's their
victory
victory
instantly. So, I think it's safe to say
instantly. So, I think it's safe to say
that we've got something
that we've got something
here. I think it's safe to say we've got
here. I think it's safe to say we've got
something
something
here. I'll be back in a few. Got to do a
here. I'll be back in a few. Got to do a
couple quick
couple quick
things and get more tea as well. And
things and get more tea as well. And
then uh I think we're going to see if we
then uh I think we're going to see if we
can get neural MMO working cuz holy hell
can get neural MMO working cuz holy hell
is this good.
is this good.
I mean, I don't think I can even like
I mean, I don't think I can even like
express how crazy it is to just delete
express how crazy it is to just delete
the nicely tuned hyperparameters, throw
the nicely tuned hyperparameters, throw
on a janky set of defaults from
on a janky set of defaults from
Breakout, and then outperform by a mile
Breakout, and then outperform by a mile
like the best thing I previously got
like the best thing I previously got
from tuning on what was already the best
from tuning on what was already the best
PO implementation out there and make it
PO implementation out there and make it
faster. That's insane. So, I'll be back
faster. That's insane. So, I'll be back
soon and we will I think we're going to
soon and we will I think we're going to
make a big dent on RL overall today. Be
make a big dent on RL overall today. Be
back.
Okay,
cool. Oops.
Let me do a thing real quick. One
Let me do a thing real quick. One
second.
Let me send a couple quick messages and
Let me send a couple quick messages and
we're going to run some awesome
we're going to run some awesome
experiments.
send a couple quick messages and then
send a couple quick messages and then
we're going to run MMO
Okay. Um, this is insane right here. I I
Okay. Um, this is insane right here. I I
don't know if I can describe how insane
don't know if I can describe how insane
this is.
So,
um,
um,
yeah, that's
crazy. Neural MMO 3 is up next.
We also have pong sweeps
We also have pong sweeps
running.
So I don't know if you can read this
So I don't know if you can read this
access. Let me add some uh let me add
access. Let me add some uh let me add
this so you can
this so you can
see the original train access for neural
see the original train access for neural
MMO 3
MMO 3
is7 billion time steps.
is7 billion time steps.
Uh, I chose this number because it's
Uh, I chose this number because it's
equal to, I believe,
equal to, I believe,
2,25 years worth of gameplay.
Where's the report?
Interval 120. It's hardcoded.
Oh, wait. Hang on. This one is
Oh, wait. Hang on. This one is
hardcoded. This one is
not. See about this.
There we go. So now we have
There we go. So now we have
stable stable
reporting. And I believe we want to look
reporting. And I believe we want to look
at min.
com
Maybe this one's a little ambitious
Maybe this one's a little ambitious
because this is one
because this is one
where it just took a lot of
training. See what params we
have. Very low learning rate.
What about episode
What about episode
length or
return? Okay. episode length at least is
return? Okay. episode length at least is
increasing. So this is
increasing. So this is
potentially you know the
potentially you know the
signal that at least the agents are
signal that at least the agents are
surviving for
longer and then eventually that
longer and then eventually that
translates into them accomplishing stuff
translates into them accomplishing stuff
in the
in the
environment. We'll let this run for 100
environment. We'll let this run for 100
mil. You can see that the original here
mil. You can see that the original here
was like almost a three-day run.
original was like almost a three-day
original was like almost a three-day
run.
Oh, and this is now with the new
Oh, and this is now with the new
optimizer as
well, just with the old parameters.
There. Okay.
So 100 million ep 100 million agent
steps gives you about a 100ish
steps gives you about a 100ish
uh survival time is what we see here
uh survival time is what we see here
right and I think you disabled a
right and I think you disabled a
kneeling you disabled a ton of other
kneeling you disabled a ton of other
stuff that tends to be important so why
stuff that tends to be important so why
don't we do this is just going to be 100
don't we do this is just going to be 100
mil. It's a tiny number of
mil. It's a tiny number of
steps by comparison for neural
steps by comparison for neural
MMO. And we just get rid of all of
this. How many agents? Five times
this. How many agents? Five times
this. Yeah. So, this is going to be
this. Yeah. So, this is going to be
8192 total agents.
Just get rid of
this. So we will also put compile on
this. So we will also put compile on
because it does make it a little bit
because it does make it a little bit
faster.
for comparison, right? This is what we
for comparison, right? This is what we
had before. It was one update epoch,
had before. It was one update epoch,
which was good. It was good batch sizes.
which was good. It was good batch sizes.
Uh I think the mini batch was kind of
crazy. Okay. Something's wrong with this
crazy. Okay. Something's wrong with this
because it shouldn't be this slow.
Yeah. So, it was compile screwing it
up. Interestingly, it's uh still
up. Interestingly, it's uh still
slightly slower than before. We had a
slightly slower than before. We had a
really big mini batch size, though.
So, here's the new
one. Well, I don't know what happened
one. Well, I don't know what happened
here.
Oh, this is the wrong one here. Yeah,
Oh, this is the wrong one here. Yeah,
there we go. Oh, okay.
there we go. Oh, okay.
Yeah. What?
That's
something.
So,
So,
well, not quite. It's there are a lot of
well, not quite. It's there are a lot of
things that it has to learn. This the
things that it has to learn. This the
original for this is a 107 billion step
original for this is a 107 billion step
run, but I don't think I can emphasize
run, but I don't think I can emphasize
how crazy this is. Okay, I took a random
how crazy this is. Okay, I took a random
set of hyperparameters that I tuned for
set of hyperparameters that I tuned for
breakout. Very simple game, right? I
breakout. Very simple game, right? I
took breakout
took breakout
parameters and I've thrown them on a
parameters and I've thrown them on a
bunch of different environments and they
bunch of different environments and they
do reasonably well in all of them. uh
do reasonably well in all of them. uh
and in half of them they do better than
and in half of them they do better than
the like carefully optimized set of
the like carefully optimized set of
parameters that I hand that I that I
parameters that I hand that I that I
tuned for this specific environment via
tuned for this specific environment via
hand tuning and like uh automated
hand tuning and like uh automated
sweeps.
sweeps.
So yeah, that's kind of something like
So yeah, that's kind of something like
that's not something that happens in
RL. I am curious as to what they're
RL. I am curious as to what they're
doing though because this mid you'd
doing though because this mid you'd
expect one of the other metrics to have
expect one of the other metrics to have
gone up by now.
They're
like just very sparse.
I mean, that's something right there
I mean, that's something right there
though, right? Like
So, this is the crazy part, Captain. I
So, this is the crazy part, Captain. I
deleted the handtuned hyperparameters
deleted the handtuned hyperparameters
from when I was running I did this at
from when I was running I did this at
work
work
originally and I just like used the
originally and I just like used the
defaults that I got from
defaults that I got from
Breakout with the new algorithms and the
Breakout with the new algorithms and the
new tuning and everything.
What's
What's
different? Uh, Muan is a big one. Cosign
different? Uh, Muan is a big one. Cosign
and kneeling is a big
and kneeling is a big
one. I think those are the two main
one. I think those are the two main
ones. I fixed a bug, but that bug wasn't
ones. I fixed a bug, but that bug wasn't
in these like when I ran these original
in these like when I ran these original
experiments. Uh, that bug wasn't there.
experiments. Uh, that bug wasn't there.
So I think it's mainly muon and cosine
So I think it's mainly muon and cosine
and kneeling. I'm trying to think if I
and kneeling. I'm trying to think if I
did anything else
did anything else
major. I think those were the two
major. I think those were the two
biggest ones.
I mean also though the thing is like
I mean also though the thing is like
because of these new uh because of these
because of these new uh because of these
new uh techniques like the
new uh techniques like the
the the hyperparameters are way more
the the hyperparameters are way more
robust and like you can use bigger batch
robust and like you can use bigger batch
sizes and stuff without breaking things
sizes and stuff without breaking things
which is
crazy. Okay. Um I would like to see this
crazy. Okay. Um I would like to see this
number go
number go
up. Muan seems to be just better than
up. Muan seems to be just better than
Adam. Yeah, it is. Well, it's a small
Adam. Yeah, it is. Well, it's a small
modification on top of
modification on top of
Adam from what I understand that
Adam from what I understand that
orthogonalizes u model updates.
Oh, by the way, you can do
this. Let's take Neptune
off. It's actually slower in Bflat
off. It's actually slower in Bflat
16. And then if you do float
16, it's like maybe a little
16, it's like maybe a little
faster. Not great overall though with
faster. Not great overall though with
the
precision.
Okay, these are crazy results. These are
Okay, these are crazy results. These are
really crazy
results. I don't think that's going to
results. I don't think that's going to
do anything. But I'm just going to run
do anything. But I'm just going to run
this while I'm thinking about other
this while I'm thinking about other
stuff.
Um cuz I like where do we go from here?
Um cuz I like where do we go from here?
Right. We kind of we kind of did the
Right. We kind of we kind of did the
thing built in. Okay. So I have to fix
thing built in. Okay. So I have to fix
that
that
one. That's
fine. I think we want to get a really
fine. I think we want to get a really
nice policy on neural MMO 3. We want to
nice policy on neural MMO 3. We want to
get a lot of the tuning stuff
get a lot of the tuning stuff
working. G. It's kind of the same as
working. G. It's kind of the same as
before except now there's more of an
before except now there's more of an
emphasis on baselining
more man
So here's default connect
So here's default connect
4. Actually I want to take this graph.
This is
pong. Oh, okay. So, this is our original
pong. Oh, okay. So, this is our original
connect 4 right here. It works, right?
This is
This is
4096 total
m. So let's just do this is
m. So let's just do this is
four and we just delete this. And what
happens? Well, it's a bit faster.
Yeah, that might have been a little
Yeah, that might have been a little
ambitious for a 10 million step end to
ambitious for a 10 million step end to
train that
fast. It started taking
fast. It started taking
off. Hang on, let me just see what they
off. Hang on, let me just see what they
did. So, batch size 32K.
Yeah, there we go. Just needed the uh
Yeah, there we go. Just needed the uh
the batch size reduced because there's
the batch size reduced because there's
like so few total
steps. Okay. Yeah, Spencer, there's
steps. Okay. Yeah, Spencer, there's
Connect 4 in uh in 20 seconds matching
Connect 4 in uh in 20 seconds matching
previous
baseline with untuned
baseline with untuned
hypers. That's pretty damn
hypers. That's pretty damn
good. If we run it for 20, does it do
good. If we run it for 20, does it do
any better?
Holy.
That gives me a 95 in like 40
seconds. Little
seconds. Little
better. That's kind of
better. That's kind of
crazy. We should definitely use this as
crazy. We should definitely use this as
a baseline.
a baseline.
The only thing that's slightly annoying
The only thing that's slightly annoying
is the
is the
um this M is way too slow. Like the uh
um this M is way too slow. Like the uh
the scripted AI is way too slow in
this. What other
this. What other
apps? Multi- aent snake. I haven't
apps? Multi- aent snake. I haven't
played with this one in a while.
I want to do the uh the fulls size
snake. Let's write this one.
live evals on new
live evals on new
models. Oh yeah. Uh we're going to want
models. Oh yeah. Uh we're going to want
to do that. I have to fix some of the
to do that. I have to fix some of the
eval stuff for
eval stuff for
sure. I think I broke a few things. I
sure. I think I broke a few things. I
want to like at least get these configs
want to like at least get these configs
cleaned up a little bit first.
cleaned up a little bit first.
And then we'll look at
them. And this is going to be just
them. And this is going to be just
amazing for research.
Uh, where did I screw
Uh, where did I screw
up? Oh.
Okay, this Muon autotuning is really
annoying. It also lags everything
annoying. It also lags everything
because it spins everything at max.
Okay. So, this
is Why is this running at 3.8 million
is Why is this running at 3.8 million
steps per
steps per
second? That's a bit much, isn't it?
It's also the snakes aren't very good,
It's also the snakes aren't very good,
are
are
they? The length is
they? The length is
60. Oh, I think I went off of episode
60. Oh, I think I went off of episode
length with snake, didn't
I? Hang
on. Yeah. Yeah, I went off of episode
on. Yeah. Yeah, I went off of episode
length. Okay, so 88 is already better
length. Okay, so 88 is already better
than we had
before. Uh, this is not RLB and cursed.
before. Uh, this is not RLB and cursed.
This is multi-agent dynamics
This is multi-agent dynamics
specifically. So you get a pass on this
one. Yeah, you get a pass on this one
here. My value. Hang on.
What?
What? Wrong
one.
one.
Score. Uh, is this the Yeah, this is the
Score. Uh, is this the Yeah, this is the
wrong
one.
one.
Oh, okay. That was a random sweep. This
Oh, okay. That was a random sweep. This
is actually perfectly
stable. So we have perfectly stable 3.8
stable. So we have perfectly stable 3.8
million step per second training on
snake. We got to figure out what it is
snake. We got to figure out what it is
that makes the snake end so so fast
that makes the snake end so so fast
compared to the other ones.
Oh, and it eval at 109. That's
crazy. And what if I do
crazy. And what if I do
this? This probably actually does make
this? This probably actually does make
it slower to be fair.
Hey, do you have a Neptune fork or just
Hey, do you have a Neptune fork or just
install? You just did pip install it. I
install? You just did pip install it. I
just haven't pinned all the new
just haven't pinned all the new
dependencies to um dev branch yet. You
dependencies to um dev branch yet. You
probably are going to need to install uh
probably are going to need to install uh
well, make sure you do pip install- e
well, make sure you do pip install- e
dot of clean rl. Make sure you add the
dot of clean rl. Make sure you add the
clean rl args. That'll get pyro, which
clean rl args. That'll get pyro, which
you need for hyper pram
you need for hyper pram
sweeps. Is it just an insane number of
sweeps. Is it just an insane number of
agents in a fast? pretty
agents in a fast? pretty
much. But uh honestly here I just set
much. But uh honestly here I just set
these to way more reasonable params and
these to way more reasonable params and
still at
3.4. I had to go back to an old commit
3.4. I had to go back to an old commit
because of CUDA
because of CUDA
stuff. Yikes.
Yeah, CUDA might be AI complete.
So, this just matches perfectly or did I
So, this just matches perfectly or did I
forget to save this
forget to save this
file? I think this just matches
file? I think this just matches
perfectly,
right? Run it
right? Run it
again. Where do I need to put my Neptune
again. Where do I need to put my Neptune
API and variable? Yeah, if you just
API and variable? Yeah, if you just
click the link that's like, you know,
click the link that's like, you know,
get my key or whatever, it'll link you
get my key or whatever, it'll link you
to get your
to get your
key and it'll just say, yeah, paste this
key and it'll just say, yeah, paste this
as an
variable. I mean, as you can see, I've
variable. I mean, as you can see, I've
been using Neptune pretty much
been using Neptune pretty much
exclusively for the last couple of
exclusively for the last couple of
months, and I really like it. like the
months, and I really like it. like the
dashboards are better, the UI is faster,
dashboards are better, the UI is faster,
it displays more data points, uh it's
it displays more data points, uh it's
better for organizing my work, it's just
better for organizing my work, it's just
better
better
overall. We're going to support both.
overall. We're going to support both.
Like I don't see any reason to drop wand
Like I don't see any reason to drop wand
support, especially with the number of
support, especially with the number of
people using it. Uh the only thing we're
people using it. Uh the only thing we're
dropping support for is wand sweeps API.
dropping support for is wand sweeps API.
So you will still be able to do sweeps
So you will still be able to do sweeps
using Wandi, but you're not going to use
using Wandi, but you're not going to use
their sweeps API. You use our sweep
their sweeps API. You use our sweep
tools.
tools.
Never done real sweeps. Now getting
Never done real sweeps. Now getting
Yeah, sweeps are like goated. You need
Yeah, sweeps are like goated. You need
sweeps. Like people not sweeping hyper
sweeps. Like people not sweeping hyper
prams is one of the main reasons RL
prams is one of the main reasons RL
didn't
work. Sweeps are like not
work. Sweeps are like not
optional. It's the first thing people
optional. It's the first thing people
drop and it's like it's so so so
drop and it's like it's so so so
essential. But to be fair, I've been
essential. But to be fair, I've been
using the same set of hyperparameters
using the same set of hyperparameters
for all of these environments now with
for all of these environments now with
the new optimizer stuff, and it kind of
the new optimizer stuff, and it kind of
just works. So,
just works. So,
um, the new puffer update, the next
um, the new puffer update, the next
puffer update that has all this stuff is
puffer update that has all this stuff is
going to reduce the reliance on sweeps
going to reduce the reliance on sweeps
by a good margin. They'll still be good,
by a good margin. They'll still be good,
but it won't be as bad if you don't do
but it won't be as bad if you don't do
them because our defaults will be way
them because our defaults will be way
better.
Okay, I need to change one of these
Okay, I need to change one of these
hyperpar to see
like if I just do this, does it change
like if I just do this, does it change
the
curve? It should.
how the breakout params
how the breakout params
applies. I I think it's just that the
applies. I I think it's just that the
optimizer is way more stable and less
optimizer is way more stable and less
fiddly than before,
fiddly than before,
frankly. Like the main thing with the
frankly. Like the main thing with the
the main thing is that now you can
the main thing is that now you can
actually train at large batch sizes and
actually train at large batch sizes and
the optimizer doesn't just like give
the optimizer doesn't just like give
up. Learning rate scheduler is good as
up. Learning rate scheduler is good as
well. I it's
well. I it's
just better overall. I don't know what
just better overall. I don't know what
to
to
say. Okay, so here I've
say. Okay, so here I've
definitely No, I definitely am using the
definitely No, I definitely am using the
right
right
paramps. Not this
one. I mean, this is just remarkably
one. I mean, this is just remarkably
consistent though. This
graph like snake length with um
with steps
trained. Oh, if you look at score, it's
trained. Oh, if you look at score, it's
a different story though, right? So,
a different story though, right? So,
this was the original and this is my new
this was the original and this is my new
one. So, my new one is
one. So, my new one is
better. Oh, no, it isn't. That's a
better. Oh, no, it isn't. That's a
relative time. Okay, this is the same.
relative time. Okay, this is the same.
This one, you can see, is going to be
This one, you can see, is going to be
stretched out because it takes um
stretched out because it takes um
because it's running
because it's running
slower. But I think in terms of episode
slower. But I think in terms of episode
length, yeah, it's remarkably remarkably
length, yeah, it's remarkably remarkably
consistent of an environment. I mean, it
consistent of an environment. I mean, it
makes sense. It's like
makes sense. It's like
very it's a very self- similar
very it's a very self- similar
environment.
Okay. Uh, I'll let this finish and then
Okay. Uh, I'll let this finish and then
I'm going to do a slightly more
ambitious. I want to see what happens
ambitious. I want to see what happens
over 500 mil with
this.
Crazy
Crazy
progress, man. You know that this was my
progress, man. You know that this was my
goal for the end of the year pretty much
goal for the end of the year pretty much
was like get RL to be stable and
was like get RL to be stable and
consistent and like even last week this
consistent and like even last week this
was still kind of a crazy thing to say
was still kind of a crazy thing to say
and now this week it kind of just works.
and now this week it kind of just works.
This is
nuts. Perfectly stable learning
curves. Many applications. Well, this is
curves. Many applications. Well, this is
the goal, right? If you make RL sane and
the goal, right? If you make RL sane and
consistent, you can throw it on a ton of
consistent, you can throw it on a ton of
problems in
problems in
industry. And hopefully, you know, at
industry. And hopefully, you know, at
least some of them will want to hire
least some of them will want to hire
puffer for
him. At least initially. I don't know
him. At least initially. I don't know
why you wouldn't. We don't charge that
why you wouldn't. We don't charge that
much. Now, eventually we're going to go
much. Now, eventually we're going to go
eventually we will be looking for much
eventually we will be looking for much
higher value contracts, but for now it's
higher value contracts, but for now it's
like it's really really cheap and easy
like it's really really cheap and easy
to get us to look at your
to get us to look at your
problem. It's kind of a no-brainer.
Okay, so now here's my question. Uh,
Okay, so now here's my question. Uh,
when is it going to level
out? It can't go up infinitely, right?
out? It can't go up infinitely, right?
Like at some point the whole screen is
Like at some point the whole screen is
full of
full of
snakes. But does this just zero shot
snakes. But does this just zero shot
beat the previous best thing I've ever
beat the previous best thing I've ever
seen?
What?
Uh, okay. I'm going to have to render
Uh, okay. I'm going to have to render
this to make sure that I'm not like
this to make sure that I'm not like
going insane here.
There's no way that this could be a
There's no way that this could be a
reporting book, though. There's no
reporting book, though. There's no
way.
How? What?
Once I have some time, I need to try
Once I have some time, I need to try
training Impulse Wars.
Yeah.
Yeah.
Um, okay. We need to render this because
Um, okay. We need to render this because
I
I
What? It just keeps going up. Like,
what? What about
score? Well, they're living for 182
score? Well, they're living for 182
freaking time
steps. Okay, look. At least score levels
steps. Okay, look. At least score levels
off. There's only so much
food. What's the previous best length
food. What's the previous best length
you've seen? Like 110, maybe
you've seen? Like 110, maybe
120. And it's still going up in like a
120. And it's still going up in like a
straight
line. And this is one of the M's I
line. And this is one of the M's I
actually spent a good bit of time
actually spent a good bit of time
on. Holy
hell. Gosh.
It's going to take me a second to get
It's going to take me a second to get
render working, I assume.
Maybe they're less janky. Could
Maybe they're less janky. Could
be. I mean, I've I've been saying for
be. I mean, I've I've been saying for
the last two months since I got back
the last two months since I got back
more 3 months, right, exactly how we
more 3 months, right, exactly how we
fixed that, right, with the continuous
fixed that, right, with the continuous
versions of these arcade ads.
I see bed is up.
logits
values. Spencer added.
values. Spencer added.
Yep. Yeah. We can just run those
Yep. Yeah. We can just run those
experiments.
Uh, we'll fix that. I don't know why
Uh, we'll fix that. I don't know why
it's so slow.
There's sleep on
this. Ah, thank you very
much. Wait, but it's 10. That would be
much. Wait, but it's 10. That would be
fine. It's way slower than that, right?
Yeah, that would be fine. 100 ms 10
Yeah, that would be fine. 100 ms 10
steps per second, which is what you
steps per second, which is what you
would want for snake.
That is way too
That is way too
big. Why is the action this big?
Wait. N
Wait. N
bars num ends.
Oh, that's an
Oh, that's an
issue.
issue.
Um, I'm surprised that
works. That's a crazy number of amps.
or
or
something. See what the model
does. I broke the charm.
Okay, here's puffer snake.
They don't seem very
They don't seem very
smart. Don't you need one end if you're
smart. Don't you need one end if you're
going to watch it, not
going to watch it, not
16? Yeah, it doesn't matter. It's it
16? Yeah, it doesn't matter. It's it
like this is running 16 and it's still
like this is running 16 and it's still
like running in real time for watching
like running in real time for watching
it.
it.
So, I don't see um I don't see
So, I don't see um I don't see
like this policy doesn't look good,
right? Maybe it was
right? Maybe it was
score. Maybe score was the uh the
score. Maybe score was the uh the
important one. Hang on.
Yeah, maybe I just screwed up. Okay,
Yeah, maybe I just screwed up. Okay,
maybe maybe this particular end I
maybe maybe this particular end I
screwed up.
screwed up.
Reward food. Reward corpse. Reward
Reward food. Reward corpse. Reward
death.
But I thought there was like a snake
But I thought there was like a snake
length param.
Is score
consistent? Score is also consistent
here.
Couldn't be learning, could it?
Well, that's why it was so fast
actually cuz I was actually saturating
actually cuz I was actually saturating
the
the
GPU massive amounts of
data. Yeah. 1.5 mil.
Oh, it is score is the variable that
Oh, it is score is the variable that
matters. Okay, I'm
dumb. I mean, it immediately jumps
up. And what did I just specify? So, 256
up. And what did I just specify? So, 256
*
*
16 is 4096. So, this is correct.
Yeah.
Yeah.
Okay. So, that particular graph I had
Okay. So, that particular graph I had
was
stupid. Get rid of that one. The rest of
stupid. Get rid of that one. The rest of
them are all correct though.
Yeah, there you
go. So, the real one that we should be
go. So, the real one that we should be
running
running
here, get this
Let's let it run. Let's see if it
Let's let it run. Let's see if it
figures out uh anything
smart. This is the end where um
smart. This is the end where um
diversity is all you need. actually
diversity is all you need. actually
helped. Helped a
lot. Huh.
lot. Huh.
It's actually going back
It's actually going back
up,
but you got 3 mil before by running more
but you got 3 mil before by running more
amps per process, right? Yeah, it was
amps per process, right? Yeah, it was
just like a massive number of amps. So,
just like a massive number of amps. So,
the GPU was The reason that that worked
the GPU was The reason that that worked
is because um Snake has pretty small
is because um Snake has pretty small
compact observations and we were sending
compact observations and we were sending
it like
it like
What the heck even is that? 160k batch
What the heck even is that? 160k batch
size or something
size or something
ridiculous. Maybe it was like
ridiculous. Maybe it was like
40k. It had a big batch size. So yeah,
40k. It had a big batch size. So yeah,
that's what
happened. We should probably play with
happened. We should probably play with
that at some point because it was
that at some point because it was
interesting how well that worked.
Uh this is actually kind of cool that it
Uh this is actually kind of cool that it
is it is now going back
up with default params.
There's some multi-agent like
There's some multi-agent like
competitive
competitive
dynamics going on that make this emble a
dynamics going on that make this emble a
little
little
tricky. It's like very easy to get
tricky. It's like very easy to get
snakes that do something reasonable, but
snakes that do something reasonable, but
then there are like some pitfalls that
then there are like some pitfalls that
you have to avoid to make the policy
you have to avoid to make the policy
really good.
I mean, this is
solid technically competitive selfplay.
solid technically competitive selfplay.
Yes, it
is. It's in fact strict
is. It's in fact strict
strictly competitive softplay.
good
good
policy, cool environment in the sense
policy, cool environment in the sense
that you can train it, you can train
that you can train it, you can train
something reasonable in 10 seconds, but
something reasonable in 10 seconds, but
like it gets meaningfully better if you
like it gets meaningfully better if you
train it for 5 minutes, like 500 mil
train it for 5 minutes, like 500 mil
steps.
So this is what a good snake model looks
So this is what a good snake model looks
like.
It's kind of cool to
watch. I haven't seen a single one die
yet. Oh, there's
yet. Oh, there's
one. Couple died so far.
That's a good policy
That's a good policy
though. It's not like biasing towards
though. It's not like biasing towards
one side
one side
excessively. It's a really cool
excessively. It's a really cool
policy. Yeah, I like this environment.
policy. Yeah, I like this environment.
These like big multi- aent
These like big multi- aent
M. These are
fun.
Cool
Cool
sim. Very very cool
sim. Very very cool
sim. Yeah, this policy is definitely
sim. Yeah, this policy is definitely
better as well than what we've had
better as well than what we've had
before. Like it it figured out. So what
before. Like it it figured out. So what
happened here is like I can guarantee
happened here is like I can guarantee
you it figured out how to kind of like
you it figured out how to kind of like
do some stuff and then the snakes get a
do some stuff and then the snakes get a
directional bias. So like they all go in
directional bias. So like they all go in
one direction and um that works fine
one direction and um that works fine
until they crowd up against one side and
until they crowd up against one side and
then this is them figuring out not to do
that. Uh no it does not outperform the
that. Uh no it does not outperform the
scores on diversity is all you need yet.
scores on diversity is all you need yet.
Uh but I like we'll see what happens
Uh but I like we'll see what happens
when I try it with you know the new
when I try it with you know the new
optimizer with all that. There's more
optimizer with all that. There's more
research to be done. This is I I'm very
research to be done. This is I I'm very
happy with this result. I will say this
happy with this result. I will say this
is very
is very
good for this M
here. Very cool
here. Very cool
M. Cool. I mean, we're through half of
M. Cool. I mean, we're through half of
the puffer lip catalog
already. And like you can
already. And like you can
see this is one set of
see this is one set of
hypers. So the whole puffer catalog so
hypers. So the whole puffer catalog so
far with one set of hypers modulo a
far with one set of hypers modulo a
couple small batch tweaks for the ones
couple small batch tweaks for the ones
that have really short
horizons. See we did this. We did this.
horizons. See we did this. We did this.
We did this. Let's do triple triad real
We did this. Let's do triple triad real
quick.
go might be interesting. Yeah, I think
go might be interesting. Yeah, I think
that that's going to
that that's going to
be that's going to be fiddly regardless
be that's going to be fiddly regardless
just because of the way it's set up, but
just because of the way it's set up, but
we'll see.
Get our baseline
in. A long run.
It's got to redo all the optimizer. I'm
It's got to redo all the optimizer. I'm
going to actually kill this after it's
going to actually kill this after it's
done so that we don't screw up our graph
done so that we don't screw up our graph
axis.
Well, that's nice. Back me to the
Well, that's nice. Back me to the
restroom.
Yep. Well, that's a super clean train
Yep. Well, that's a super clean train
curve with just the uh the default like
curve with just the uh the default like
optimized
ones. I actually don't know what the max
ones. I actually don't know what the max
is on uh on triple triad. I think you
is on uh on triple triad. I think you
can technically get nine points, but I
can technically get nine points, but I
don't know if that's ever
don't know if that's ever
possible. Maybe Spencer knows.
Also, what was the train speed?
Also, what was the train speed?
1.38. That's pretty good.
Okay. So, it's like a little tiny bit
Okay. So, it's like a little tiny bit
worse. It looks
like mini badge.
Yeah, I'm going to guess that this one
Yeah, I'm going to guess that this one
you can probably do way better just with
you can probably do way better just with
like smaller batch or something with the
like smaller batch or something with the
the episode length being that
the episode length being that
short. We'll try that
short. We'll try that
next. Oh, and
also let's do this.
Yeah. So, this more m fewer M's doesn't
Yeah. So, this more m fewer M's doesn't
really matter
really matter
here. It looks like it's probably just
here. It looks like it's probably just
going to be the batch size.
Um probably do this.
Okay, that does weigh worse,
Okay, that does weigh worse,
interestingly
enough. You see what the original was?
enough. You see what the original was?
It was 4096 m
It was 4096 m
total. Bigger mini badge.
Let's try this.
Well, there you
Well, there you
go.
Okay. Is it going to get stuck at the
Okay. Is it going to get stuck at the
lower uh lower max though? Here.
Oh, no. It doesn't get
Oh, no. It doesn't get
stuck.
stuck.
Uh, we'll see if it does seem like it
Uh, we'll see if it does seem like it
flattens, though. Yeah. Okay, it does
flattens, though. Yeah. Okay, it does
flatten more than the other one.
Okay, so this one is somewhere in
between. You only need an episode length
between. You only need an episode length
of like 16, I think, right? So it's like
of like 16, I think, right? So it's like
uh
That's
131K. We'll see. But I think with the
131K. We'll see. But I think with the
way that we handle trajectory segments,
way that we handle trajectory segments,
you might need a little bit of wiggle
you might need a little bit of wiggle
room. We'll
room. We'll
see. This looks worse.
see. This looks worse.
Increase batch size is
Increase batch size is
worse. We had 131
before. If I just do
before. If I just do
131 and I do
131 and I do
m, it's probably pretty good,
m, it's probably pretty good,
right? Of course, it'll take a hit to
right? Of course, it'll take a hit to
the train speed. We don't need to get
the train speed. We don't need to get
these fully optimized. I just want to
these fully optimized. I just want to
have something like pretty good.
Uh, not this one. This one.
So, this the original tuned ones are
So, this the original tuned ones are
still like a little bit better, I think,
still like a little bit better, I think,
in their final
in their final
convergence. Unless this catches up.
Did you try the other optimizer? So, the
Did you try the other optimizer? So, the
other optimizers um have a big
other optimizers um have a big
performance penalty associated with
performance penalty associated with
them. Muon is the one that runs like as
them. Muon is the one that runs like as
fast as Adam and just is like is a free
fast as Adam and just is like is a free
win because right now we have this axis
win because right now we have this axis
in steps but usually we have it in
in steps but usually we have it in
seconds, right?
I don't really care much for this ample
I don't really care much for this ample
efficiency
nerds. Okay, that's cool. So, this is
fine. Triple triad works.
fine. Triple triad works.
Uh, we need to do the grid M's rware and
Uh, we need to do the grid M's rware and
trash pickup real quick. Those should be
trash pickup real quick. Those should be
easy.
Look at
that. This is fast. But does it do
anything? Oh, it's the length is the
anything? Oh, it's the length is the
thing that matters here, right? So lower
thing that matters here, right? So lower
length is better.
Okay. So, this is what we get with the
Okay. So, this is what we get with the
defaults.
Oops.
Okay.
So just out of the box, we just blow the
So just out of the box, we just blow the
previous result out of the water.
Well, we can just reduce the number of
Well, we can just reduce the number of
steps needed for this five to 50 mil,
steps needed for this five to 50 mil,
right? Like there's no reason to have
right? Like there's no reason to have
it. So we just increase sample
it. So we just increase sample
efficiency by a factor
efficiency by a factor
of
of
five, four, whatever.
That just works. Why wouldn't it?
This is just a custom comp. There's like
This is just a custom comp. There's like
not even anything
not even anything
remotely complex
here. We probably have like a ton of M's
here. We probably have like a ton of M's
in this one as well.
Okay, here's a trash
pickup. This one, I believe, is score
pickup. This one, I believe, is score
and um episode length or
and um episode length or
whatever. So, I don't know. We'll just
whatever. So, I don't know. We'll just
pick a metric.
Uh, was this the right
one? Yeah, that's Pong. Okay, this is
one? Yeah, that's Pong. Okay, this is
good.
So previous optin
So previous optin
params 100 mil steps 1.7 mill steps per
second and then what's this? Divide by
second and then what's this? Divide by
numbum agents. Num agents is
numbum agents. Num agents is
four. So I think we literally just
four. So I think we literally just
delete I'm going to leave the batch
delete I'm going to leave the batch
size. Maybe not. Maybe we just do this.
size. Maybe not. Maybe we just do this.
Maybe we just literally do. Hang on.
Maybe we just literally do. Hang on.
Let's do this. You
know. Oh.
Yeah.
Um. Oh, is it going to get stuck though?
Um. Oh, is it going to get stuck though?
Oh,
no. I think it's going to get stuck a
no. I think it's going to get stuck a
little
little
bit. It's so
close. Is it like permanently
close. Is it like permanently
stuck? Wait, it has trash collected at
stuck? Wait, it has trash collected at
max.
max.
But I guess it's the episode length is
But I guess it's the episode length is
too
long. That's
weird. Wait, what about episode return?
Oh, so it broke the end.
I guess it's just like this little
decline. Well, I think it broke the end.
decline. Well, I think it broke the end.
I don't
I don't
know. Here, let's do let's do batch
size. Set the batch size. See if that
size. Set the batch size. See if that
does anything.
Yeah, whatever this score is doesn't
Yeah, whatever this score is doesn't
seem particularly well correlated with
seem particularly well correlated with
uh the
return. So, we got to fix that.
cuz like look right it's like 20 is
cuz like look right it's like 20 is
solved and then it's supposed to I guess
solved and then it's supposed to I guess
get penalized for taking too long but
get penalized for taking too long but
like the score is not very well
like the score is not very well
correlated with the Turn.
It's the episode length, I
guess. That's weird.
Six. Yeah, this is the one you want.
Six. Yeah, this is the one you want.
So, yeah, that's a weird uh that's a
So, yeah, that's a weird uh that's a
weird problem to
have. Let's see if we can uh fix that.
Definitely something
Definitely something
screwy. Oh, you know, it's probably just
screwy. Oh, you know, it's probably just
a discount
factor. Would that make
sense? Maybe it is the discount factor
sense? Maybe it is the discount factor
here, right?
Let's try one more thing.
So one other
So one other
like you see anything else weird
like you see anything else weird
here? I see like the lower
gamma one mini
gamma one mini
batch 01 learning rate.
Yep, that was
Yep, that was
it. So, it's this
freaking the episode length here,
right? It's gamma.
Yeah. So that's a
gigasolve. That's gigasolved.
What else do we have
What else do we have
left? We did everything but go,
right? Let's get go running.
Also, we really would like to have like
Also, we really would like to have like
a much longer benchmark on Neural MMO 3.
a much longer benchmark on Neural MMO 3.
That's the cool end. I mean, not that's
That's the cool end. I mean, not that's
the hardest end. I will say neural MMO 3
the hardest end. I will say neural MMO 3
is definitely the hardest
is definitely the hardest
end. All
right, there's the restroom again. I'll
right, there's the restroom again. I'll
be right back.
All
right.
That does not appear to be doing
That does not appear to be doing
anything
good. Also, why is this training at
good. Also, why is this training at
50,000 steps per second?
Hello. What is wrong with go?
Why is Why is it like
this? Why is the mini batch size 131K?
this? Why is the mini batch size 131K?
Who did this?
That is not how GPUs
work. Don't do that ever. Thank you very
work. Don't do that ever. Thank you very
much.
Is it still slow? No, no, no, no, no. If
Is it still slow? No, no, no, no, no. If
it's still slow, then we've got issues.
This has got to be like the stupid uh
This has got to be like the stupid uh
action space, right?
model's really slow.
model's really slow.
What is the
model comp
2D
2D
two channels three stride Oh,
Is it the logic somehow? Hang on.
500,000
steps. That's what's wrong with this,
steps. That's what's wrong with this,
right?
There we go.
Yeah. So, it's all in the
network and we
network and we
have no not high GPU
utilization. Hang
on. Let me see if the batch size is what
on. Let me see if the batch size is what
we think it is.
This is what we think it
is. This is all zeros. I guess that's
is. This is all zeros. I guess that's
fine for the
start. 48
Default policy is much faster, but still
Default policy is much faster, but still
ways slower than
expected. Is it the action space being
expected. Is it the action space being
weird?
That doesn't seem to be it.
That doesn't seem to be it.
Right. Still slow.
fact that there was 17% forward.
How is there
How is there
17% in just this of
that default not
work. I just want to make doubly sure
work. I just want to make doubly sure
that this is
that this is
actually getting applied.
Yeah. So this is getting applied
Yeah. So this is getting applied
right policy is just super basic same as
right policy is just super basic same as
we use everywhere
else not
continuous and somehow this is slow
really
Uh device equals
CPU. Yeah.
CPU. Yeah.
Okay. Okay, buddy.
1.4 mil. And now let's rerun again with
1.4 mil. And now let's rerun again with
the bigger action space.
1.0 mil. Okay. So, there is actually
1.0 mil. Okay. So, there is actually
some sort of perf penalty it seems
some sort of perf penalty it seems
uh associated with that. We should look
uh associated with that. We should look
into that more the action
into that more the action
size. Um but for the meantime, this is
size. Um but for the meantime, this is
good and we can actually run this
This is also this is too many
This is also this is too many
steps to give
it. We'll give it 250.
it. We'll give it 250.
That's not going to matter for this
That's not going to matter for this
because there's no nailing
on. So what point does the learning
on. So what point does the learning
start?
the episode returns increasing. So it's
the episode returns increasing. So it's
I think this is the part where it takes
I think this is the part where it takes
forever to learn action masking.
You can see the episode return is
You can see the episode return is
actually optimizing
though. And now score starts to increase
though. And now score starts to increase
very rapidly.
And now it's winning almost all the
And now it's winning almost all the
games and only 100 mil
steps. So 100 million steps should be
steps. So 100 million steps should be
fine for uh for
this now.
this now.
We uh we do the exact same thing as
We uh we do the exact same thing as
before, but we delete all of
before, but we delete all of
this and we see how the defaults
work. Oh, N91 win rate actually. So 99%
work. Oh, N91 win rate actually. So 99%
of games won.
And then we will see whether our new
And then we will see whether our new
params
params
uh are any better at getting
unstuck. Oh yeah, look at that. The
unstuck. Oh yeah, look at that. The
episode
episode
return that is optimizing much
return that is optimizing much
faster. The uh the steps per second have
faster. The uh the steps per second have
taken a big hit for some reason. Let me
taken a big hit for some reason. Let me
see.
You see anything that would cause that
here? Size mini badge
here? Size mini badge
size. I don't see anything that should
size. I don't see anything that should
cause that, which is a little
cause that, which is a little
weird. Oh, actually, hold on. Maybe uh I
weird. Oh, actually, hold on. Maybe uh I
wasn't I didn't see these steps. Yeah.
wasn't I didn't see these steps. Yeah.
Yeah. No, it's it gets slower as you get
Yeah. No, it's it gets slower as you get
better at the game.
There we
There we
go. There's the
go. There's the
jump.
jump.
So, be better than previous
Yeah, better than
previous. That's crazy.
So, we've pretty much just shredded
So, we've pretty much just shredded
every single benchmark in
every single benchmark in
Puffer. I guess we can try Blastar real
Puffer. I guess we can try Blastar real
quick. Since Bet went through the effort
quick. Since Bet went through the effort
of making it, we may as well include it,
of making it, we may as well include it,
right? It's a fine N. It's a little
right? It's a fine N. It's a little
silly of an arcade N.
What did he set the total time steps
What did he set the total time steps
to? A
lot. Okay.
Bet invalid environment named Puffer
Blaster. I literally not even included
Blaster. I literally not even included
in uh
Welcome YouTube folks. Today is a very
Welcome YouTube folks. Today is a very
good day for
RL. If we can just finish this last M,
RL. If we can just finish this last M,
then pretty much we have one set of
then pretty much we have one set of
hyperpar that works for all but one of
hyperpar that works for all but one of
the Ms. And in the cases where it's like
the Ms. And in the cases where it's like
slightly suboptimal,
slightly suboptimal,
uh we know that the last impediment is
uh we know that the last impediment is
generalized advantage estimation because
generalized advantage estimation because
you cannot
you cannot
use you just cannot use the same gamma
use you just cannot use the same gamma
and lambda pms for all
and lambda pms for all
Ms. I think once we have that set we
Ms. I think once we have that set we
should be good to go. Maybe
should be good to go. Maybe
entropy entropy might be a little nsp
entropy entropy might be a little nsp
specific. We should be able to make that
specific. We should be able to make that
adaptive though pretty easily, much more
adaptive though pretty easily, much more
easily than the other
ones. So, a massive episode length
ones. So, a massive episode length
here. I wish I knew. So, this is
go. I wish I knew what
um score we could
um score we could
get. What's the max
score? But I guess what I'll do since
score? But I guess what I'll do since
this is he has it set for way too long,
this is he has it set for way too long,
I'll just let this run
I'll just let this run
for a little bit.
for a little bit.
Actually, this might be good right here.
Actually, this might be good right here.
mil. Yeah, because it starts
mil. Yeah, because it starts
oscillating. Cool. Um, and that's just
oscillating. Cool. Um, and that's just
from the long episodes, I assume. I
from the long episodes, I assume. I
assume num m is 4096 and batch size is
assume num m is 4096 and batch size is
one numm. So, we're going to change this
one numm. So, we're going to change this
to
2048. And we'll just we'll just do this.
Actually, hold on. It's You want to get
Actually, hold on. It's You want to get
rid of everything except total time
rid of everything except total time
steps there.
And the score is already way higher than
And the score is already way higher than
it
it
was. Yeah. Look at
that. Yeah. Massively better. Now, these
that. Yeah. Massively better. Now, these
could start at the same point, mind you,
could start at the same point, mind you,
but still like
but still like
Massively
Massively
better. Just make sure it doesn't get
better. Just make sure it doesn't get
caught at
21. Is it stuck?
Oh, it's still going back
up. What was his original gamma and
up. What was his original gamma and
lambda in
this? Nothing crazy.
Okay. I mean,
so it gets to there
so it gets to there
immediately, which 25 is max
immediately, which 25 is max
4. Yeah, I wouldn't be surprised. This
4. Yeah, I wouldn't be surprised. This
is just like a weird episode length
is just like a weird episode length
smoothing thing because 25, if you look
smoothing thing because 25, if you look
here, right, like with the oscillations,
here, right, like with the oscillations,
it averages at
it averages at
25. The max
Okay. Generally though, we have
Okay. Generally though, we have
reasonable on every single end. And if
reasonable on every single end. And if
this is matches, I'd have to ask a bet
this is matches, I'd have to ask a bet
if 25 is solved because if so, then this
if 25 is solved because if so, then this
is solved right here.
is solved right here.
So, and then this is probably
So, and then this is probably
um well, this could be like slower
um well, this could be like slower
oscillation. We'd have to run it way
oscillation. We'd have to run it way
longer to
see. Uh main thing though for
now, I did have a sweep
running. We do have
Pong. And it looks like the current best
Pong. And it looks like the current best
for Pong is about 22 23 seconds. Does
for Pong is about 22 23 seconds. Does
anybody remember what the previous best
anybody remember what the previous best
time was for
Pong? I tweet about this at
all and I like search my own tweets.
Maybe search Discord. All right.
50 seconds was the original over
here. I thought we had faster than
50. Does anybody
remember? I guess I could go back to
remember? I guess I could go back to
like one of the old sweeps. Oh, your
like one of the old sweeps. Oh, your
pong m is solved in 25 seconds.
There. So then if we had 25 before then
There. So then if we had 25 before then
this is about the same but this is like
this is about the same but this is like
the easiest end.
So maybe that's
fine. We also want Hang
on. Let me try like one or two quick
on. Let me try like one or two quick
things with Pong. I bet I can get it to
things with Pong. I bet I can get it to
run uh just about the same.
25. So this is 20 million steps
25. So this is 20 million steps
is 22
seconds for Okay. So this is 22
seconds. Uh 15. So 16
mil. Does this like have a weird number
mil. Does this like have a weird number
of ms though?
amps to see if there are any weird
amps to see if there are any weird
params in
params in
here. One update
epoch 8192 mini batch
epoch 8192 mini batch
still 131k. Yeah, let me just reduce
still 131k. Yeah, let me just reduce
the size.
You don't get any data from this.
-3. Too many M's.
Maybe this is probably pretty close to
Maybe this is probably pretty close to
what we have in the sweep.
Oh, and then it just jumps to 20. Okay,
cool. Shouldn't be anything else major
cool. Shouldn't be anything else major
in
there. Solved in 30
there. Solved in 30
seconds versus the optimum we get is
seconds versus the optimum we get is
like 22.
And all I did was match num ms I
And all I did was match num ms I
guess and batch
size seems
fair. Cool.
So even though this is like 10 seconds
So even though this is like 10 seconds
more or 9 seconds more than the
more or 9 seconds more than the
optimized one, I'm still going to say
optimized one, I'm still going to say
right like 30 second solve absolutely
right like 30 second solve absolutely
same set of hyperp works. You might have
same set of hyperp works. You might have
to tune batch and end size a little bit
to tune batch and end size a little bit
for the simpler ones, but that's it.
for the simpler ones, but that's it.
So we now literally have except for like
So we now literally have except for like
one gamma tweak that we needed. We have
one gamma tweak that we needed. We have
the same set of hyperparams working on
the same set of hyperparams working on
every single environment in pover
every single environment in pover
um which is something that would uh I
um which is something that would uh I
would have said is like batshit insane
would have said is like batshit insane
if you'd asked me literally yesterday.
if you'd asked me literally yesterday.
And uh I mean anybody who tells you that
And uh I mean anybody who tells you that
that's not insane is just lying or wrong
that's not insane is just lying or wrong
as well because the papers that have
as well because the papers that have
claimed to do that have been borderline
claimed to do that have been borderline
fraud. Um they're like there's one or
fraud. Um they're like there's one or
two in mind I have for
that. So this is an insane result. A
that. So this is an insane result. A
truly truly insane result.
I'm trying to think what I want to do
I'm trying to think what I want to do
next with
next with
this. Let's open up neural MMO
3. So, mincom prof I
believe. How long does 10 billion take?
If I run neural MMO 3 for 10
billing 45 bill an
hour. I'd rather do this though and have
hour. I'd rather do this though and have
the original. I don't know if that'll
the original. I don't know if that'll
screw up the
screw up the
analing, but I think I'd like to just do
analing, but I think I'd like to just do
this.
Where was the environment?
Neural MMO run
Neural MMO run
setup. I mean, this will be the real
setup. I mean, this will be the real
test. And this one might actually take a
test. And this one might actually take a
bit of work. Neural MMO is a hard hard
bit of work. Neural MMO is a hard hard
end. There's a reason I haven't been
end. There's a reason I haven't been
using it. Even though I love this
using it. Even though I love this
environment and put a ton of work into
environment and put a ton of work into
it, it is hard.
I'm going to make sure that this
I'm going to make sure that this
actually gets
actually gets
going. Here's going to be the plan for
going. Here's going to be the plan for
today, though. So, we have all these new
today, though. So, we have all these new
baselines. Um, this is kind of nutty
baselines. Um, this is kind of nutty
that this works. I'm still kind of in
that this works. I'm still kind of in
shock
shock
here. We're going to run neural MMO
here. I might want to hyper pram sweep
here. I might want to hyper pram sweep
this.
Actually on the other
box. I might want to run a hyper pram
box. I might want to run a hyper pram
sweep on the other box for this as well.
sweep on the other box for this as well.
So yeah, let me I'll do a few more
So yeah, let me I'll do a few more
things right now then.
Okay. So, this runs 500k.
Numb is four.
Okay. So up to
8192. Is it one or four by default?
8192. Is it one or four by default?
Should be four by
Should be four by
default I believe.
Total time
steps one E9 should be the
max 2 E8
max 2 E8
min of 5
V8 and I don't think I can use mincom
V8 and I don't think I can use mincom
prof as the metric for sweeps.
Let me go look what I can use for neural
Let me go look what I can use for neural
MMO 3.
I think it's the episode return.
and try
this. Hopefully this does something.
this. Hopefully this does something.
We'll see.
I'd love to get a nice policy on narrow
I'd love to get a nice policy on narrow
MMO 3. That would be like the full
MMO 3. That would be like the full
circle
circle
success cuz that's such a hard end. Like
success cuz that's such a hard end. Like
if you want to get a sense of what
if you want to get a sense of what
Neural MOO 3 is, you can just play it on
Neural MOO 3 is, you can just play it on
Puffer AI. Like that's the best way to
Puffer AI. Like that's the best way to
do it.
do it.
Um it requires a lot of things that are
Um it requires a lot of things that are
intuitive to you because you can see the
intuitive to you because you can see the
textures and say, "Oh, that's a weapon.
textures and say, "Oh, that's a weapon.
I should go get that or whatever." Or
I should go get that or whatever." Or
like, "Oh, I should put this tool on.
like, "Oh, I should put this tool on.
Like I should equip this tool and then
Like I should equip this tool and then
gather stuff." But even then, it's still
gather stuff." But even then, it's still
like the mechanics of it are hard. It
like the mechanics of it are hard. It
requires like longer term planning. It's
requires like longer term planning. It's
just hard.
could have to compile a bunch of stuff,
right? Yeah, this compiles a bunch of
right? Yeah, this compiles a bunch of
stuff. Looks like we have quite a few
stuff. Looks like we have quite a few
folks watching, which of course this
folks watching, which of course this
always happens right when I'm about to
always happens right when I'm about to
pass out from having not eaten anything.
pass out from having not eaten anything.
So I'm going for lunch soon. So we get
So I'm going for lunch soon. So we get
these things done. Uh the plan for the
these things done. Uh the plan for the
rest of today. So quick summary, we have
rest of today. So quick summary, we have
all of the MS and puffer working very
all of the MS and puffer working very
well with basically a single set of
well with basically a single set of
ultraast
hyperparameters. This is with all the
hyperparameters. This is with all the
new tweaks and algorithmic changes we've
new tweaks and algorithmic changes we've
made. We have a clear path for what
made. We have a clear path for what
needs to be done in order to really make
needs to be done in order to really make
a single set of hyperparameters work for
a single set of hyperparameters work for
everything. That's the P30 or GGAE
everything. That's the P30 or GGAE
stuff, the new algorithm I've been
stuff, the new algorithm I've been
developing. Uh, we have the potential
developing. Uh, we have the potential
for the first time now to get some
for the first time now to get some
really impressive results on M like
really impressive results on M like
Neural MMO 3, maybe even impulse wars
Neural MMO 3, maybe even impulse wars
and some of the other complex ones that
and some of the other complex ones that
contributors have
added. Uh, and I have a couple more M's
added. Uh, and I have a couple more M's
to add, uh, to add bindings for. So, I'm
to add, uh, to add bindings for. So, I'm
going to finish this. I'm going to grab
going to finish this. I'm going to grab
lunch. I'm going to get a little bit of
lunch. I'm going to get a little bit of
exercise, do a couple things, and I'm
exercise, do a couple things, and I'm
going to come back, add a binding for a
going to come back, add a binding for a
new environment, see how all this stuff
new environment, see how all this stuff
works on that. Uh, probably clean up
works on that. Uh, probably clean up
another environment. There's like some
another environment. There's like some
client adjacent stuff I have to
do and then we will look at the results
do and then we will look at the results
that hopefully we get some cool results
that hopefully we get some cool results
by then as
by then as
well. And uh, we will proceed from
well. And uh, we will proceed from
there. And I also want to try out the
there. And I also want to try out the
P30 stuff now with all these new
P30 stuff now with all these new
algorithm tweaks because it is quite
algorithm tweaks because it is quite
likely that we're going to get some
likely that we're going to get some
qualitatively new results. And if I can
qualitatively new results. And if I can
get like consistent baselines on neural
get like consistent baselines on neural
MMO 3, that would probably be the best
MMO 3, that would probably be the best
possible setting to try out P30 because
possible setting to try out P30 because
it's an environment that really requires
it's an environment that really requires
you to be able to do credit assignment
you to be able to do credit assignment
over differing horizons uh depending on
over differing horizons uh depending on
what state you are in the N. So that's
what state you are in the N. So that's
promising. Uh this literally just takes
promising. Uh this literally just takes
like a while to start increasing
like a while to start increasing
here. Okay, so this sweep is running.
here. Okay, so this sweep is running.
This baseline longer run is going. Um
This baseline longer run is going. Um
for the folks
watching, all this stuff is open source.
watching, all this stuff is open source.
You can get it at
You can get it at
puffer.ai. Start the repo to help us
puffer.ai. Start the repo to help us
out. Really, really helps. It's free. It
out. Really, really helps. It's free. It
takes like 3 seconds. Uh, and if you
takes like 3 seconds. Uh, and if you
want to get involved with dev and all
want to get involved with dev and all
the exciting RL advancements happening
the exciting RL advancements happening
right now, just join the Discord and
right now, just join the Discord and
click the button or it's
click the button or it's
discord.gg/puffer. If you want more RL
discord.gg/puffer. If you want more RL
content or want to get notified when I'm
content or want to get notified when I'm
live, etc. Uh, I stream like 40 60 hours
live, etc. Uh, I stream like 40 60 hours
a week of dev on X, YouTube, and Twitch.
a week of dev on X, YouTube, and Twitch.
So, you can click the button uh here for
So, you can click the button uh here for
X and more RL content. Thanks. And
