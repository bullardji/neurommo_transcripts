Kind: captions
Language: en
Okay, we are
Okay, we are
live.
Hi. I am quite tired, but I figured I
Hi. I am quite tired, but I figured I
would come back and do just a short
would come back and do just a short
evening stream
evening stream
tonight. Probably just work on a couple
tonight. Probably just work on a couple
of experiments, see if I can clean up a
of experiments, see if I can clean up a
few small
few small
things, and then yeah, we'll call it a
things, and then yeah, we'll call it a
night early. That is the plan.
Okay. So,
um first of all, let me just change
this 48.
Just do a couple quick things on this.
Just do a couple quick things on this.
And then the main thing I want to fix is
And then the main thing I want to fix is
the grid
environment. Main thing is the grid
environment. Main thing is the grid
environment.
That doesn't work at all. So, we'll just
That doesn't work at all. So, we'll just
leave it as as it was like this
before. Try grid again.
said to go back a few commits.
Okay, so this is how
Okay, so this is how
I
I
8192 problem is I'm pretty sure that
8192 problem is I'm pretty sure that
this thing just like crashes,
right? I think you at least
1024. Wait, you shouldn't need at least
1024. Wait, you shouldn't need at least
1024 ends,
1024 ends,
right? You know, this works.
right? You know, this works.
Okay, so this does
Okay, so this does
run and this gives you max
size and then do we just plateau at 2?
size and then do we just plateau at 2?
Is that what happens?
600k. It's kind of slow as well. Oh, I
600k. It's kind of slow as well. Oh, I
guess it's because the low batch
size and but this is not learning
size and but this is not learning
anywhere near as quickly as
this. I guess I could do like this kind
this. I guess I could do like this kind
of a
thing and I could
thing and I could
see if this is better or not.
I think this fails though,
right? Oh, no. That
runs not much slower either.
So the tricky thing here, right,
So the tricky thing here, right,
is I don't know if I broke training or
is I don't know if I broke training or
the
end. The easiest thing to
end. The easiest thing to
do would be to go get the old end files,
do would be to go get the old end files,
I
guess. Unless this just runs, but I
guess. Unless this just runs, but I
doubt
doubt
it. Yeah, I think the easiest thing to
it. Yeah, I think the easiest thing to
do is going to be to go get the old end
do is going to be to go get the old end
files, test versus
files, test versus
those and uh then see from
those and uh then see from
there because this definitely doesn't
work. Okay.
I don't know why that happens where I
I don't know why that happens where I
just randomly delete stuff.
just randomly delete stuff.
Weird hot cake.
no
attribute. How the hell did this happen?
Um what I
thought this is side
grid. I guess we just do this.
Max
Max
size. Max map
size. Yeah. Yeah. Yeah.
See, there
Heck is wrong with this?
Huh?
Oh.
Uh, I see.
Hope that works.
That doesn't seem to work, does
it? But this is also not the version I
it? But this is also not the version I
was
was
using. Do I just go to the first version
using. Do I just go to the first version
before I did all this stuff?
Damn
Damn
it.
Mess. Can I just use this?
I thought I did this
I thought I did this
more. I didn't do this five months ago,
right? Yeah. No, I didn't do this five
right? Yeah. No, I didn't do this five
months ago.
Okay. So, it's this one, I guess.
See?
Okay. So, this doesn't train
Okay. So, this doesn't train
either, it seems to me.
And I
And I
have yeah all the same
hypers.
Now I mean stuff is different since I
Now I mean stuff is different since I
did this.
If I just delete the param that I don't
If I just delete the param that I don't
think makes
sense. I should probably let this run a
sense. I should probably let this run a
little longer to be sure
though. Pretty damn sure though that I
though. Pretty damn sure though that I
had it working way quicker than this. It
had it working way quicker than this. It
was working.
The BPT horizon's definitely wrong.
It's 256 Verizon would be
What do I think the odds are? It's the
What do I think the odds are? It's the
horizon.
This is probably crashing,
right?
right?
No. Oh, cuz you're editing the wrong
No. Oh, cuz you're editing the wrong
file, [ __ ]
Okay.
Are you on a desktop or is this a
Are you on a desktop or is this a
laptop? This is definitely a
laptop? This is definitely a
desktop. I have two very nice desktops
desktop. I have two very nice desktops
next to me and another eight out in the
garage. Okay, that at least does
garage. Okay, that at least does
something.
So, we'll let this train and we'll
So, we'll let this train and we'll
see. That'd be funny if it were
see. That'd be funny if it were
literally just the horizon that I messed
up. I would have better lighting here as
up. I would have better lighting here as
well, but I'm kind of sick of staring at
well, but I'm kind of sick of staring at
this ring light at night. This freaking
this ring light at night. This freaking
white themed dashboard is bad enough as
white themed dashboard is bad enough as
is.
Okay. So, this is this is where it
Okay. So, this is this is where it
was. So, now I try this
was. So, now I try this
on the new version of the env. I see if
on the new version of the env. I see if
they
they
match. I'm going to let this run a
match. I'm going to let this run a
little though. At least run a little
longer. That's the play.
And then if this works, I'll be pretty
And then if this works, I'll be pretty
confident that the new experience buffer
confident that the new experience buffer
is
good. Yeah, cuz
good. Yeah, cuz
um we have a little write up on the
um we have a little write up on the
hardware for this as
hardware for this as
well. Right
well. Right
here, hover stack.
Okay. 76
Okay. 76
79. This gets like 80%ish and 63
79. This gets like 80%ish and 63
mil. It's pretty
good. So then for grid, I just remove
good. So then for grid, I just remove
this and then I try this on grid and I
this and then I try this on grid and I
see if this works.
Okay. Well, this will be a relief if
Okay. Well, this will be a relief if
this is all I had to
fix. And then I get to just I guess it's
fix. And then I get to just I guess it's
8:24, so I'll just spend like half an
8:24, so I'll just spend like half an
hour ablading out what actually matters
hour ablading out what actually matters
with this grid environment.
with this grid environment.
We'll have a decent
We'll have a decent
baseline and then uh I'll be able to do
baseline and then uh I'll be able to do
the new curriculum learning stuff on
the new curriculum learning stuff on
this just
fine. I mean, it makes sense. It really
fine. I mean, it makes sense. It really
should work.
should work.
made so many
made so many
improvements in the last two weeks.
close
enough. It does eventually get better,
enough. It does eventually get better,
right?
8. Yeah, there it goes.
Perfect.
Let's see if batch and mini batch
mattered. Oh, that's unbearably slow.
mattered. Oh, that's unbearably slow.
We're not doing that
one. We'll change more things than I
one. We'll change more things than I
probably
probably
should. It's my better judgment.
No, that's unbearably slow as
well. So, we'll keep this one. What if
well. So, we'll keep this one. What if
we just keep
we just keep
this bigger
this bigger
batch? Try this next.
Speed's not bad.
Oh yeah, I forgot this
is Okay, these are all the same
is Okay, these are all the same
speed, so this didn't
speed, so this didn't
help. It doesn't seem like it hurt too
help. It doesn't seem like it hurt too
badly, but uh it's not great.
That's not
great. Okay. So, let's
do if we're going to 4x the batch size
do if we're going to 4x the batch size
like that, we should
like that, we should
4x the
4x the
ends and see if that helps because that
ends and see if that helps because that
at least that goes faster maybe.
Yeah, there you go. That's at least
Yeah, there you go. That's at least
faster
faster
now. So, if we do this in wall clock, we
now. So, if we do this in wall clock, we
might actually win.
It's not bad.
Why is offline RL all the rage
Why is offline RL all the rage
nowadays? Because people gave up on
nowadays? Because people gave up on
online because they couldn't figure it
online because they couldn't figure it
out. We're still doing
out. We're still doing
online. Offline only works if you have a
online. Offline only works if you have a
data
data
set. It's also a misnomer. A better name
set. It's also a misnomer. A better name
for offline RL would be supervised
for offline RL would be supervised
learning. It's not really RL.
learning. It's not really RL.
The entire point and the entire
The entire point and the entire
difficulty of RL is that you are
difficulty of RL is that you are
learning interactively from an
learning interactively from an
everchanging environment. Offline is not
that. Hey,
welcome. So, yeah, we're not really
welcome. So, yeah, we're not really
doing offline at the moment because
doing offline at the moment because
there's no point. It's just easy. And um
there's no point. It's just easy. And um
that's not to say we won't mix in data
that's not to say we won't mix in data
if we have it. It's just the thing is we
if we have it. It's just the thing is we
don't really need to study it because
don't really need to study it because
it's just easy. It's just imitation
it's just easy. It's just imitation
learning. Okay. So, this works. What I'm
learning. Okay. So, this works. What I'm
doing here, by the way. So, this is the
doing here, by the way. So, this is the
maze environment. I can show it real
maze environment. I can show it real
quick. Why don't I just show it? So,
quick. Why don't I just show it? So,
this is our uh our maze environment.
this is our uh our maze environment.
Looks like this. Just you make different
Looks like this. Just you make different
size mazes. You have to solve the maze.
size mazes. You have to solve the maze.
Uh you only get a reward for solving the
Uh you only get a reward for solving the
entire maze. So, it's very very sparse.
entire maze. So, it's very very sparse.
It's pretty much a pure exploration
It's pretty much a pure exploration
task. And we use this for research on,
task. And we use this for research on,
as you'd imagine, exploration, but also
as you'd imagine, exploration, but also
curriculum learning because you can like
curriculum learning because you can like
make maps that are smaller and maps that
make maps that are smaller and maps that
are larger. And you can like learn the
are larger. And you can like learn the
smaller maps first and stuff like that.
smaller maps first and stuff like that.
Um, so I'm currently trying to make sure
Um, so I'm currently trying to make sure
that this is in good shape because we
that this is in good shape because we
have active research that depends on
have active research that depends on
this end. And uh, this one's actually a
this end. And uh, this one's actually a
little tricky
little tricky
infrastructure-wise, but yeah, there you
infrastructure-wise, but yeah, there you
go.
Oh, I bet I know why it got slower as
Oh, I bet I know why it got slower as
well. Yeah, I know how to fix that.
Okay, I do want to try
Try
Try
this. See if that works. Active research
this. See if that works. Active research
with mazees involve scaling laws. Uh,
with mazees involve scaling laws. Uh,
no, that's something quite separate. Um
no, that's something quite separate. Um
that is something that we probably
that is something that we probably
should be doing at some point. But
um the scaling laws thing is more like
um the scaling laws thing is more like
predict results of from small experiment
predict results of from small experiment
on n of large experiment on n. We kind
on n of large experiment on n. We kind
of just try to solve a lot of different
of just try to solve a lot of different
ms with the same methods for the most
ms with the same methods for the most
part.
part.
There's definitely a place for scaling
There's definitely a place for scaling
law research. We don't do a ton of stuff
law research. We don't do a ton of stuff
with that right
with that right
now. We do get predictably better
now. We do get predictably better
results though uh with larger models on
results though uh with larger models on
at least one of the m the bigger M's
at least one of the m the bigger M's
neural MMO
3. Okay, if this just stopped working
3. Okay, if this just stopped working
that will be very interesting to
that will be very interesting to
know. I wonder which parameter it was
know. I wonder which parameter it was
that mattered.
Huh? That just totally broke it,
huh? Okay, let's try these
huh? Okay, let's try these
um one at a time.
I mean, pretty much not all of our
I mean, pretty much not all of our
research, but most of our research
research, but most of our research
happens right here on stream. Obviously,
happens right here on stream. Obviously,
we have other collaborators doing other
we have other collaborators doing other
stuff, and not everybody streams
stuff, and not everybody streams
everything, but I pretty much stream all
everything, but I pretty much stream all
of my
of my
work. Tomorrow is probably going to be a
work. Tomorrow is probably going to be a
deep dive into modelbased
deep dive into modelbased
RL potentially.
RL potentially.
At least I'm going to start doing that
At least I'm going to start doing that
in the morning and we're going to see
in the morning and we're going to see
how it
goes. I don't really want to like rip
goes. I don't really want to like rip
out PO and put in a whole another
out PO and put in a whole another
algorithm. I kind of just want like a
algorithm. I kind of just want like a
model based AUGs objective that I can
model based AUGs objective that I can
use. Hey bet. What do you mean finally
use. Hey bet. What do you mean finally
streaming? I've been streaming like
streaming? I've been streaming like
various chunks of the whole day. Model
various chunks of the whole day. Model
based RL's hard.
based RL's hard.
No, people are just bad at
it. It's not really
it. It's not really
like if anything it should be
like if anything it should be
easier because you burn stupid amounts
easier because you burn stupid amounts
of compute on uh relatively simple
problems. I mean we have this
problems. I mean we have this
paper ski it is literally skill issue
paper ski it is literally skill issue
here. Let me show you this.
here. Let me show you this.
So, Dreamer V3 made it into
So, Dreamer V3 made it into
uh Dreamer V3 recently made it to
nature. Well, here's our ner paper
nature. Well, here's our ner paper
showing that half of it's
wrong. All the like the paper itself
wrong. All the like the paper itself
works, but all the tricks they said are
works, but all the tricks they said are
the reason it works, the tricks all
the reason it works, the tricks all
suck. So,
suck. So,
Yeah, it's it's literally just people
Yeah, it's it's literally just people
are
bad. It's mostly just nobody taking the
bad. It's mostly just nobody taking the
time to do engineering correctly really.
time to do engineering correctly really.
It's like a bunch of scientists without
It's like a bunch of scientists without
proper engineering support who don't
proper engineering support who don't
really know how to code properly
really know how to code properly
themselves. Interesting that this
themselves. Interesting that this
actually made a difference
here. It's a big difference.
here. It's a big difference.
Oh, hang on. There's a time
axis. Okay, so still worse.
Uh we believe that dreamer does work
Uh we believe that dreamer does work
just not for the reasons
stated. Like the thing is that they kind
stated. Like the thing is that they kind
of gloss over the fact that dreamer v3
of gloss over the fact that dreamer v3
is a 10 times larger model than dreamer
is a 10 times larger model than dreamer
v2.
v2.
So they like they train a 10x larger
So they like they train a 10x larger
model and then they like say, "Oh, look,
model and then they like say, "Oh, look,
we came up with all these clever tricks
we came up with all these clever tricks
when it seems like really the most
when it seems like really the most
important thing is the fact that they
important thing is the fact that they
trained a 10x larger
trained a 10x larger
model." And then maybe like a few small
model." And then maybe like a few small
things like layer actually helped them
things like layer actually helped them
train the bigger model. I don't know. It
train the bigger model. I don't know. It
was very very weird, I will say.
Okay. So, it's interesting that the
Okay. So, it's interesting that the
hyperparameters here actually do seem to
hyperparameters here actually do seem to
make a
make a
difference. The higher entropy actually
difference. The higher entropy actually
hurts. Like
really hurts a little
really hurts a little
bit. We have this
one. The [ __ ] did they not do ablations?
one. The [ __ ] did they not do ablations?
Well, the thing is they did ablations,
Well, the thing is they did ablations,
right? But they did like add one drop
right? But they did like add one drop
one. The thing is they like used
one. The thing is they like used
reinforce instead of using like a
reinforce instead of using like a
reasonable algorithm. And then because
reasonable algorithm. And then because
they didn't use a reasonable algorithm,
they didn't use a reasonable algorithm,
they like had to come up with all these
they like had to come up with all these
hacky tricks that just kind of do what
hacky tricks that just kind of do what
PO does but worse.
So, and the thing is like you know if
So, and the thing is like you know if
this is a well-known uh deep mind
this is a well-known uh deep mind
researcher doing this, right? Like you
researcher doing this, right? Like you
know that the average random PhD student
know that the average random PhD student
doing RL is putting out way worse crap.
doing RL is putting out way worse crap.
Like yeah, RL is not impossible. It's
Like yeah, RL is not impossible. It's
just like people were really really bad.
just like people were really really bad.
Nobody bothered to put in the
Nobody bothered to put in the
engineering. RL takes way more
engineering. RL takes way more
engineering to do well than any other
engineering to do well than any other
area of ML other than like large scale
area of ML other than like large scale
like the people who actually scale
like the people who actually scale
training of LLMs like those engineers
training of LLMs like those engineers
not the researchers who don't touch
not the researchers who don't touch
that. Um yeah and like nobody did the
that. Um yeah and like nobody did the
engineering.
engineering.
So all we're doing all we are doing that
So all we're doing all we are doing that
makes us able to do this we're just
makes us able to do this we're just
doing the
doing the
engineering and that's all we're
doing with this learning rate.
These prams actually seem to matter
These prams actually seem to matter
which is
surprising. How about learning rate?
surprising. How about learning rate?
Learning rate was like tuned with Adam,
Learning rate was like tuned with Adam,
right? Surely this is better.
I mean, to their credit, right, I'm
I mean, to their credit, right, I'm
probably going to be looking at Dreamer
probably going to be looking at Dreamer
V3 as a reference tomorrow, but not for
V3 as a reference tomorrow, but not for
those components, not for any of those
those components, not for any of those
tricks, just for the the core world
tricks, just for the the core world
model setup and whether it's like
model setup and whether it's like
actually compatible and useful with what
actually compatible and useful with what
we
want. Okay, so this is interesting. The
want. Okay, so this is interesting. The
hypers actually seem to matter here.
hypers actually seem to matter here.
Oh, you know what? I wonder if the
Oh, you know what? I wonder if the
hypers matter here because update epox
hypers matter here because update epox
is set way too
is set way too
high. If update epox is set like to
high. If update epox is set like to
four, then this is off policy,
four, then this is off policy,
right? Hang
right? Hang
on. What if we just do this one? What
on. What if we just do this one? What
happens?
the ablations that I'm kind of just like
the ablations that I'm kind of just like
sleepily hacking out right now. Uh each
sleepily hacking out right now. Uh each
of these runs would be like 2 hours plus
of these runs would be like 2 hours plus
if we were using
if we were using
conventional environments and
conventional environments and
infrastructure. So like there's just a
infrastructure. So like there's just a
very large difference in the speed with
very large difference in the speed with
which we can do
which we can do
things. Okay, that's a respectable
things. Okay, that's a respectable
speed. See, now we're at 1.5 million
speed. See, now we're at 1.5 million
steps per
second. We change value to relative
second. We change value to relative
time. That's
nice. So then we'll redo the parameter
nice. So then we'll redo the parameter
ablations.
ablations.
with this because now we're no longer so
with this because now we're no longer so
off policy provided that this actually
off policy provided that this actually
does
does
decently. This seems
decently. This seems
good. Yeah, this is decent so far.
kind of fell off like a little
bit, but also like the learning rate
bit, but also like the learning rate
kind
dropped. What happens if we do this?
dropped. What happens if we do this?
This is better or worse now. Check both
This is better or worse now. Check both
of these
It actually is worse, isn't
It actually is worse, isn't
it? Crazy. That makes a difference.
What if I do
this
this
point? What do you mean
bad? Oh, did you see? You should check
bad? Oh, did you see? You should check
my latest commit because I changed the
my latest commit because I changed the
logs and
logs and
everything. It's just an unused
variable that shouldn't break compile.
variable that shouldn't break compile.
Just a
warning. It
does. I'll look at it at some point, but
does. I'll look at it at some point, but
it's Do I need to like if you link it to
it's Do I need to like if you link it to
me, I'll go tell you what's
me, I'll go tell you what's
wrong. I changed. So all of the M's now
wrong. I changed. So all of the M's now
have a PF variable, which is a
have a PF variable, which is a
normalized single metric that goes from
normalized single metric that goes from
zero to
zero to
one. I did that
one. I did that
today. I left uh I didn't do any new
today. I left uh I didn't do any new
bindings though, like new I didn't do
bindings though, like new I didn't do
new bindings. C. I left that for
new bindings. C. I left that for
you to finish.
It's just single me. It's single metric
It's just single me. It's single metric
that is relevant to the
that is relevant to the
M. It's 0 to one
normalized. The point is that you can
normalized. The point is that you can
put all the M's on the same graph.
This does substantially worse as well,
This does substantially worse as well,
doesn't
doesn't
it?
it?
Okay, so this does substantially
worse. So except for the So I was going
worse. So except for the So I was going
to call it normalized or except for the
to call it normalized or except for the
fact that not all the M's have a score
fact that not all the M's have a score
that makes sense.
So in some it's like normal, some of
So in some it's like normal, some of
them it's win rate, some of them it's a
them it's win rate, some of them it's a
score. It's normalized whichever metric
score. It's normalized whichever metric
the N
the N
has. No, because not all the M's have a
has. No, because not all the M's have a
completion
completion
condition. So I intentionally named it
condition. So I intentionally named it
something else. So you wouldn't assume
something else. So you wouldn't assume
it's just like you know one variable or
it's just like you know one variable or
another.
Uh, okay. This is actually
something. Yeah, this is actually
something. Yeah, this is actually
something.
I'm just fiddling with this so that
I'm just fiddling with this so that
like we have something to go off of for
like we have something to go off of for
our curriculum learning work.
learning rate was 06 or
something 025. So crazy high learning
something 025. So crazy high learning
rate by comparison. Let's see what this
rate by comparison. Let's see what this
does.
Oh, wait. Hang on. Wrong wrong wrong
file
there. I'm going to send air on one of
there. I'm going to send air on one of
these runs and he's going to be like,
these runs and he's going to be like,
"What the h That takes me an hour to
"What the h That takes me an hour to
do. Like, yeah, well, it rains in two
do. Like, yeah, well, it rains in two
minutes
now. Did you know that puffer limits
fast? Fastest possible.
fast? Fastest possible.
Puffer. Puffer.
I'm interested to see here because this
I'm interested to see here because this
learning rate
O4. Yeah. So, it seems like
O4. Yeah. So, it seems like
um the harder M's need like lower learn
rates. Make sure this doesn't take off
rates. Make sure this doesn't take off
or some
or some
[ __ ] But, you know, we could try a
[ __ ] But, you know, we could try a
layer norm.
That is so stupid.
Is this
Is this
better? Oh, yeah, it
better? Oh, yeah, it
is. So, learning rate does actually need
is. So, learning rate does actually need
uh tuning. What did I do? It was
255. So we'll try 05 next.
honestly solid. I don't know why I'm
honestly solid. I don't know why I'm
manually tuning [ __ ] right now. I'm just
manually tuning [ __ ] right now. I'm just
trying to like smash the baseline on
trying to like smash the baseline on
this and give Aaron something
this and give Aaron something
to look at.
I think this is too high
potentially. Yeah, it's too
potentially. Yeah, it's too
high. We can do 25 like
high. We can do 25 like
this. And then that's going to be the
this. And then that's going to be the
last tune.
Oh, there. That's
interesting. Quite good, actually.
Okay, we'll keep this.
And
then my gamma is
already try.99.
Fine. How funny is it going to be if I
Fine. How funny is it going to be if I
like mostly solve this task?
We've been trying to solve this for a
We've been trying to solve this for a
while. Can solve it with hyperparameter
while. Can solve it with hyperparameter
tuning in the new advantage
stuff. 20 minutes more max on this. I'm
stuff. 20 minutes more max on this. I'm
going to bed.
Is this actually like
worse? You got to be kidding
worse? You got to be kidding
me. This is actually
me. This is actually
worse. You give it like
Still going up pretty
Still going up pretty
steep. 99
steep. 99
gamma. You're telling me if I put 999
gamma. You're telling me if I put 999
gamma, it's better. Mhm.
gamma, it's better. Mhm.
Is that how it
works? Yeah. And because I know the math
works? Yeah. And because I know the math
is why I'm
surprised
surprised
because.995 gamma is a very long
because.995 gamma is a very long
horizon.
You do realize though that
You do realize though that
like learning over that
is okay. So, it's actually it's pretty
is okay. So, it's actually it's pretty
close, right? It actually catches up
close, right? It actually catches up
pretty
pretty
well. But I will go the other way.
well. But I will go the other way.
We'll see.
We'll see.
9999 999
gamma. I like the shape of the green
curve. Purple curve best
curve. You don't want it round. Round
curve. You don't want it round. Round
means level. You I want a log. You want
means level. You I want a log. You want
log linear always.
Okay,
Okay,
thankfully there appears to be
sanity, but I'm going to let it run
sanity, but I'm going to let it run
because it's only a minute and it seems
because it's only a minute and it seems
like
like
um there is a bit of steepness to it.
I
mean, it's still kind of
linear. Still kind of linear.
linear. Still kind of linear.
[Music]
Okay, there it
goes.
Yeah, original hypers for these are
good. Low entropy is kind of weird.
Let's try layer norm.
Did that make it not learn
Did that make it not learn
anything? Something seems very off about
anything? Something seems very off about
that. Hang on.
Oh, it just doesn't
Oh, it just doesn't
learn. Okay.
Is it learning right now? Is to
Oh, you know what it is? It's that I'm
Oh, you know what it is? It's that I'm
really
dumb. It's that I'm really really
dumb. It's that I'm really really
stupid and I forgot to
stupid and I forgot to
uncomment the thingy and now it probably
uncomment the thingy and now it probably
everything because I hate Layer Norm and
everything because I hate Layer Norm and
Larorm hates Okay.
Is this still not work?
Really?
The one good thing about X is that when
The one good thing about X is that when
it has all this stupid content,
it has all this stupid content,
occasionally it has
seals. And that's pretty good.
There's even an entire part
There's even an entire part
of there's even an entire part of
of there's even an entire part of
uh X devoted to seals. Isn't that
uh X devoted to seals. Isn't that
lovely?
I don't any more of them.
There are no more seals on the
There are no more seals on the
timeline. I'm
timeline. I'm
stuck watching the grass, it seems.
This thing had a
This thing had a
crash. Oh no, it's just
um Maybe we have to go back to steps for
this. It's including the compile in it.
Oh. Oh.9. Cool. We're just We're just
Oh. Oh.9. Cool. We're just We're just
solving [ __ ] now, I
guess. Oh, there are more seals I have
guess. Oh, there are more seals I have
found.
This one is
good. All right, I guess we just solve
good. All right, I guess we just solve
everything tonight, huh?
I think this is good enough to
I think this is good enough to
call 98%.
this no longer exists. We get rid of
this no longer exists. We get rid of
this
I should probably just run neural MMO 3
I should probably just run neural MMO 3
as is on the new version to be honest.
It's funny as
hell. You going to be like,
"What?" Well, mine's still better.
Mine's still
better. No LP.
This is our
This is our
latest
latest
experiment. It was quite good.
Well, apparently there have been a lot
Well, apparently there have been a lot
of changes.
No coded GPUs
available. Reboot container.
Uh, I don't know how it got
Uh, I don't know how it got
faster. That seems
faster. That seems
weird that it would get
faster, but whatever. We will see if it
faster, but whatever. We will see if it
works.
I don't think it's actually faster. I
I don't think it's actually faster. I
think it's a reporting error, but
whatever. Okay, we'll see whether that
whatever. Okay, we'll see whether that
does
anything. Did I log a napkin there? No,
anything. Did I log a napkin there? No,
I didn't like a dummy.
There we go.
We have an extra box, don't we?
I have some
boxes. I always keep a couple for myself
boxes. I always keep a couple for myself
just so I have them so I can run my own
just so I have them so I can run my own
stuff on my own
boxes. I don't load them 100%, but it's
boxes. I don't load them 100%, but it's
better that I have them when I need
better that I have them when I need
them.
Cool. We have
Cool. We have
uh here we are.
uh here we are.
What happened to
this filters?
I'm still marching
I'm still marching
along doing
along doing
fine. It's layer
fine. It's layer
norm. Not
norm. Not
magic, but
magic, but
um does give you a little bit of perf.
um does give you a little bit of perf.
It looks like they still learn a lot
It looks like they still learn a lot
faster at the start as well. So that is
something. Okay, this is
something. Okay, this is
cool. This already does something,
right? That's fine.
right? That's fine.
So, we'll let these be for
So, we'll let these be for
now. Um, seems good to
now. Um, seems good to
me. And we have stuff nicely queued up
me. And we have stuff nicely queued up
for
for
tomorrow. We will run new ablations. We
tomorrow. We will run new ablations. We
will run lots of new stuff tomorrow.
will run lots of new stuff tomorrow.
9:30. Good time to call it. Get some
9:30. Good time to call it. Get some
sleep. Trying to put in a full
sleep. Trying to put in a full
day tomorrow.
day tomorrow.
Uh, so for the couple folks here, thanks
Uh, so for the couple folks here, thanks
for tuning
for tuning
in. More stream tomorrow. Should be some
in. More stream tomorrow. Should be some
pretty cool algorithm
dev. All my stuff's at puffer.ai. It's
dev. All my stuff's at puffer.ai. It's
all open source. If you want to come
all open source. If you want to come
support me for free, start the GitHub
support me for free, start the GitHub
almost at
almost at
2K. You can join the Discord to get
2K. You can join the Discord to get
involved with open source dev. You can
involved with open source dev. You can
follow me on X for more content.
follow me on X for more content.
We are currently
at 1948. Two more before it should round
at 1948. Two more before it should round
to
to
2K. So, thank you. And uh yeah, I'll
2K. So, thank you. And uh yeah, I'll
merge

Kind: captions
Language: en
Okay, we are
Okay, we are
live.
Hi. I am quite tired, but I figured I
Hi. I am quite tired, but I figured I
would come back and do just a short
would come back and do just a short
evening stream
evening stream
tonight. Probably just work on a couple
tonight. Probably just work on a couple
of experiments, see if I can clean up a
of experiments, see if I can clean up a
few small
few small
things, and then yeah, we'll call it a
things, and then yeah, we'll call it a
night early. That is the plan.
Okay. So,
um first of all, let me just change
this 48.
Just do a couple quick things on this.
Just do a couple quick things on this.
And then the main thing I want to fix is
And then the main thing I want to fix is
the grid
environment. Main thing is the grid
environment. Main thing is the grid
environment.
That doesn't work at all. So, we'll just
That doesn't work at all. So, we'll just
leave it as as it was like this
before. Try grid again.
said to go back a few commits.
Okay, so this is how
Okay, so this is how
I
I
8192 problem is I'm pretty sure that
8192 problem is I'm pretty sure that
this thing just like crashes,
right? I think you at least
1024. Wait, you shouldn't need at least
1024. Wait, you shouldn't need at least
1024 ends,
1024 ends,
right? You know, this works.
right? You know, this works.
Okay, so this does
Okay, so this does
run and this gives you max
size and then do we just plateau at 2?
size and then do we just plateau at 2?
Is that what happens?
600k. It's kind of slow as well. Oh, I
600k. It's kind of slow as well. Oh, I
guess it's because the low batch
size and but this is not learning
size and but this is not learning
anywhere near as quickly as
this. I guess I could do like this kind
this. I guess I could do like this kind
of a
thing and I could
thing and I could
see if this is better or not.
I think this fails though,
right? Oh, no. That
runs not much slower either.
So the tricky thing here, right,
So the tricky thing here, right,
is I don't know if I broke training or
is I don't know if I broke training or
the
end. The easiest thing to
end. The easiest thing to
do would be to go get the old end files,
do would be to go get the old end files,
I
guess. Unless this just runs, but I
guess. Unless this just runs, but I
doubt
doubt
it. Yeah, I think the easiest thing to
it. Yeah, I think the easiest thing to
do is going to be to go get the old end
do is going to be to go get the old end
files, test versus
files, test versus
those and uh then see from
those and uh then see from
there because this definitely doesn't
work. Okay.
I don't know why that happens where I
I don't know why that happens where I
just randomly delete stuff.
just randomly delete stuff.
Weird hot cake.
no
attribute. How the hell did this happen?
Um what I
thought this is side
grid. I guess we just do this.
Max
Max
size. Max map
size. Yeah. Yeah. Yeah.
See, there
Heck is wrong with this?
Huh?
Oh.
Uh, I see.
Hope that works.
That doesn't seem to work, does
it? But this is also not the version I
it? But this is also not the version I
was
was
using. Do I just go to the first version
using. Do I just go to the first version
before I did all this stuff?
Damn
Damn
it.
Mess. Can I just use this?
I thought I did this
I thought I did this
more. I didn't do this five months ago,
right? Yeah. No, I didn't do this five
right? Yeah. No, I didn't do this five
months ago.
Okay. So, it's this one, I guess.
See?
Okay. So, this doesn't train
Okay. So, this doesn't train
either, it seems to me.
And I
And I
have yeah all the same
hypers.
Now I mean stuff is different since I
Now I mean stuff is different since I
did this.
If I just delete the param that I don't
If I just delete the param that I don't
think makes
sense. I should probably let this run a
sense. I should probably let this run a
little longer to be sure
though. Pretty damn sure though that I
though. Pretty damn sure though that I
had it working way quicker than this. It
had it working way quicker than this. It
was working.
The BPT horizon's definitely wrong.
It's 256 Verizon would be
What do I think the odds are? It's the
What do I think the odds are? It's the
horizon.
This is probably crashing,
right?
right?
No. Oh, cuz you're editing the wrong
No. Oh, cuz you're editing the wrong
file, [ __ ]
Okay.
Are you on a desktop or is this a
Are you on a desktop or is this a
laptop? This is definitely a
laptop? This is definitely a
desktop. I have two very nice desktops
desktop. I have two very nice desktops
next to me and another eight out in the
garage. Okay, that at least does
garage. Okay, that at least does
something.
So, we'll let this train and we'll
So, we'll let this train and we'll
see. That'd be funny if it were
see. That'd be funny if it were
literally just the horizon that I messed
up. I would have better lighting here as
up. I would have better lighting here as
well, but I'm kind of sick of staring at
well, but I'm kind of sick of staring at
this ring light at night. This freaking
this ring light at night. This freaking
white themed dashboard is bad enough as
white themed dashboard is bad enough as
is.
Okay. So, this is this is where it
Okay. So, this is this is where it
was. So, now I try this
was. So, now I try this
on the new version of the env. I see if
on the new version of the env. I see if
they
they
match. I'm going to let this run a
match. I'm going to let this run a
little though. At least run a little
longer. That's the play.
And then if this works, I'll be pretty
And then if this works, I'll be pretty
confident that the new experience buffer
confident that the new experience buffer
is
good. Yeah, cuz
good. Yeah, cuz
um we have a little write up on the
um we have a little write up on the
hardware for this as
hardware for this as
well. Right
well. Right
here, hover stack.
Okay. 76
Okay. 76
79. This gets like 80%ish and 63
79. This gets like 80%ish and 63
mil. It's pretty
good. So then for grid, I just remove
good. So then for grid, I just remove
this and then I try this on grid and I
this and then I try this on grid and I
see if this works.
Okay. Well, this will be a relief if
Okay. Well, this will be a relief if
this is all I had to
fix. And then I get to just I guess it's
fix. And then I get to just I guess it's
8:24, so I'll just spend like half an
8:24, so I'll just spend like half an
hour ablading out what actually matters
hour ablading out what actually matters
with this grid environment.
with this grid environment.
We'll have a decent
We'll have a decent
baseline and then uh I'll be able to do
baseline and then uh I'll be able to do
the new curriculum learning stuff on
the new curriculum learning stuff on
this just
fine. I mean, it makes sense. It really
fine. I mean, it makes sense. It really
should work.
should work.
made so many
made so many
improvements in the last two weeks.
close
enough. It does eventually get better,
enough. It does eventually get better,
right?
8. Yeah, there it goes.
Perfect.
Let's see if batch and mini batch
mattered. Oh, that's unbearably slow.
mattered. Oh, that's unbearably slow.
We're not doing that
one. We'll change more things than I
one. We'll change more things than I
probably
probably
should. It's my better judgment.
No, that's unbearably slow as
well. So, we'll keep this one. What if
well. So, we'll keep this one. What if
we just keep
we just keep
this bigger
this bigger
batch? Try this next.
Speed's not bad.
Oh yeah, I forgot this
is Okay, these are all the same
is Okay, these are all the same
speed, so this didn't
speed, so this didn't
help. It doesn't seem like it hurt too
help. It doesn't seem like it hurt too
badly, but uh it's not great.
That's not
great. Okay. So, let's
do if we're going to 4x the batch size
do if we're going to 4x the batch size
like that, we should
like that, we should
4x the
4x the
ends and see if that helps because that
ends and see if that helps because that
at least that goes faster maybe.
Yeah, there you go. That's at least
Yeah, there you go. That's at least
faster
faster
now. So, if we do this in wall clock, we
now. So, if we do this in wall clock, we
might actually win.
It's not bad.
Why is offline RL all the rage
Why is offline RL all the rage
nowadays? Because people gave up on
nowadays? Because people gave up on
online because they couldn't figure it
online because they couldn't figure it
out. We're still doing
out. We're still doing
online. Offline only works if you have a
online. Offline only works if you have a
data
data
set. It's also a misnomer. A better name
set. It's also a misnomer. A better name
for offline RL would be supervised
for offline RL would be supervised
learning. It's not really RL.
learning. It's not really RL.
The entire point and the entire
The entire point and the entire
difficulty of RL is that you are
difficulty of RL is that you are
learning interactively from an
learning interactively from an
everchanging environment. Offline is not
that. Hey,
welcome. So, yeah, we're not really
welcome. So, yeah, we're not really
doing offline at the moment because
doing offline at the moment because
there's no point. It's just easy. And um
there's no point. It's just easy. And um
that's not to say we won't mix in data
that's not to say we won't mix in data
if we have it. It's just the thing is we
if we have it. It's just the thing is we
don't really need to study it because
don't really need to study it because
it's just easy. It's just imitation
it's just easy. It's just imitation
learning. Okay. So, this works. What I'm
learning. Okay. So, this works. What I'm
doing here, by the way. So, this is the
doing here, by the way. So, this is the
maze environment. I can show it real
maze environment. I can show it real
quick. Why don't I just show it? So,
quick. Why don't I just show it? So,
this is our uh our maze environment.
this is our uh our maze environment.
Looks like this. Just you make different
Looks like this. Just you make different
size mazes. You have to solve the maze.
size mazes. You have to solve the maze.
Uh you only get a reward for solving the
Uh you only get a reward for solving the
entire maze. So, it's very very sparse.
entire maze. So, it's very very sparse.
It's pretty much a pure exploration
It's pretty much a pure exploration
task. And we use this for research on,
task. And we use this for research on,
as you'd imagine, exploration, but also
as you'd imagine, exploration, but also
curriculum learning because you can like
curriculum learning because you can like
make maps that are smaller and maps that
make maps that are smaller and maps that
are larger. And you can like learn the
are larger. And you can like learn the
smaller maps first and stuff like that.
smaller maps first and stuff like that.
Um, so I'm currently trying to make sure
Um, so I'm currently trying to make sure
that this is in good shape because we
that this is in good shape because we
have active research that depends on
have active research that depends on
this end. And uh, this one's actually a
this end. And uh, this one's actually a
little tricky
little tricky
infrastructure-wise, but yeah, there you
infrastructure-wise, but yeah, there you
go.
Oh, I bet I know why it got slower as
Oh, I bet I know why it got slower as
well. Yeah, I know how to fix that.
Okay, I do want to try
Try
Try
this. See if that works. Active research
this. See if that works. Active research
with mazees involve scaling laws. Uh,
with mazees involve scaling laws. Uh,
no, that's something quite separate. Um
no, that's something quite separate. Um
that is something that we probably
that is something that we probably
should be doing at some point. But
um the scaling laws thing is more like
um the scaling laws thing is more like
predict results of from small experiment
predict results of from small experiment
on n of large experiment on n. We kind
on n of large experiment on n. We kind
of just try to solve a lot of different
of just try to solve a lot of different
ms with the same methods for the most
ms with the same methods for the most
part.
part.
There's definitely a place for scaling
There's definitely a place for scaling
law research. We don't do a ton of stuff
law research. We don't do a ton of stuff
with that right
with that right
now. We do get predictably better
now. We do get predictably better
results though uh with larger models on
results though uh with larger models on
at least one of the m the bigger M's
at least one of the m the bigger M's
neural MMO
3. Okay, if this just stopped working
3. Okay, if this just stopped working
that will be very interesting to
that will be very interesting to
know. I wonder which parameter it was
know. I wonder which parameter it was
that mattered.
Huh? That just totally broke it,
huh? Okay, let's try these
huh? Okay, let's try these
um one at a time.
I mean, pretty much not all of our
I mean, pretty much not all of our
research, but most of our research
research, but most of our research
happens right here on stream. Obviously,
happens right here on stream. Obviously,
we have other collaborators doing other
we have other collaborators doing other
stuff, and not everybody streams
stuff, and not everybody streams
everything, but I pretty much stream all
everything, but I pretty much stream all
of my
of my
work. Tomorrow is probably going to be a
work. Tomorrow is probably going to be a
deep dive into modelbased
deep dive into modelbased
RL potentially.
RL potentially.
At least I'm going to start doing that
At least I'm going to start doing that
in the morning and we're going to see
in the morning and we're going to see
how it
goes. I don't really want to like rip
goes. I don't really want to like rip
out PO and put in a whole another
out PO and put in a whole another
algorithm. I kind of just want like a
algorithm. I kind of just want like a
model based AUGs objective that I can
model based AUGs objective that I can
use. Hey bet. What do you mean finally
use. Hey bet. What do you mean finally
streaming? I've been streaming like
streaming? I've been streaming like
various chunks of the whole day. Model
various chunks of the whole day. Model
based RL's hard.
based RL's hard.
No, people are just bad at
it. It's not really
it. It's not really
like if anything it should be
like if anything it should be
easier because you burn stupid amounts
easier because you burn stupid amounts
of compute on uh relatively simple
problems. I mean we have this
problems. I mean we have this
paper ski it is literally skill issue
paper ski it is literally skill issue
here. Let me show you this.
here. Let me show you this.
So, Dreamer V3 made it into
So, Dreamer V3 made it into
uh Dreamer V3 recently made it to
nature. Well, here's our ner paper
nature. Well, here's our ner paper
showing that half of it's
wrong. All the like the paper itself
wrong. All the like the paper itself
works, but all the tricks they said are
works, but all the tricks they said are
the reason it works, the tricks all
the reason it works, the tricks all
suck. So,
suck. So,
Yeah, it's it's literally just people
Yeah, it's it's literally just people
are
bad. It's mostly just nobody taking the
bad. It's mostly just nobody taking the
time to do engineering correctly really.
time to do engineering correctly really.
It's like a bunch of scientists without
It's like a bunch of scientists without
proper engineering support who don't
proper engineering support who don't
really know how to code properly
really know how to code properly
themselves. Interesting that this
themselves. Interesting that this
actually made a difference
here. It's a big difference.
here. It's a big difference.
Oh, hang on. There's a time
axis. Okay, so still worse.
Uh we believe that dreamer does work
Uh we believe that dreamer does work
just not for the reasons
stated. Like the thing is that they kind
stated. Like the thing is that they kind
of gloss over the fact that dreamer v3
of gloss over the fact that dreamer v3
is a 10 times larger model than dreamer
is a 10 times larger model than dreamer
v2.
v2.
So they like they train a 10x larger
So they like they train a 10x larger
model and then they like say, "Oh, look,
model and then they like say, "Oh, look,
we came up with all these clever tricks
we came up with all these clever tricks
when it seems like really the most
when it seems like really the most
important thing is the fact that they
important thing is the fact that they
trained a 10x larger
trained a 10x larger
model." And then maybe like a few small
model." And then maybe like a few small
things like layer actually helped them
things like layer actually helped them
train the bigger model. I don't know. It
train the bigger model. I don't know. It
was very very weird, I will say.
Okay. So, it's interesting that the
Okay. So, it's interesting that the
hyperparameters here actually do seem to
hyperparameters here actually do seem to
make a
make a
difference. The higher entropy actually
difference. The higher entropy actually
hurts. Like
really hurts a little
really hurts a little
bit. We have this
one. The [ __ ] did they not do ablations?
one. The [ __ ] did they not do ablations?
Well, the thing is they did ablations,
Well, the thing is they did ablations,
right? But they did like add one drop
right? But they did like add one drop
one. The thing is they like used
one. The thing is they like used
reinforce instead of using like a
reinforce instead of using like a
reasonable algorithm. And then because
reasonable algorithm. And then because
they didn't use a reasonable algorithm,
they didn't use a reasonable algorithm,
they like had to come up with all these
they like had to come up with all these
hacky tricks that just kind of do what
hacky tricks that just kind of do what
PO does but worse.
So, and the thing is like you know if
So, and the thing is like you know if
this is a well-known uh deep mind
this is a well-known uh deep mind
researcher doing this, right? Like you
researcher doing this, right? Like you
know that the average random PhD student
know that the average random PhD student
doing RL is putting out way worse crap.
doing RL is putting out way worse crap.
Like yeah, RL is not impossible. It's
Like yeah, RL is not impossible. It's
just like people were really really bad.
just like people were really really bad.
Nobody bothered to put in the
Nobody bothered to put in the
engineering. RL takes way more
engineering. RL takes way more
engineering to do well than any other
engineering to do well than any other
area of ML other than like large scale
area of ML other than like large scale
like the people who actually scale
like the people who actually scale
training of LLMs like those engineers
training of LLMs like those engineers
not the researchers who don't touch
not the researchers who don't touch
that. Um yeah and like nobody did the
that. Um yeah and like nobody did the
engineering.
engineering.
So all we're doing all we are doing that
So all we're doing all we are doing that
makes us able to do this we're just
makes us able to do this we're just
doing the
doing the
engineering and that's all we're
doing with this learning rate.
These prams actually seem to matter
These prams actually seem to matter
which is
surprising. How about learning rate?
surprising. How about learning rate?
Learning rate was like tuned with Adam,
Learning rate was like tuned with Adam,
right? Surely this is better.
I mean, to their credit, right, I'm
I mean, to their credit, right, I'm
probably going to be looking at Dreamer
probably going to be looking at Dreamer
V3 as a reference tomorrow, but not for
V3 as a reference tomorrow, but not for
those components, not for any of those
those components, not for any of those
tricks, just for the the core world
tricks, just for the the core world
model setup and whether it's like
model setup and whether it's like
actually compatible and useful with what
actually compatible and useful with what
we
want. Okay, so this is interesting. The
want. Okay, so this is interesting. The
hypers actually seem to matter here.
hypers actually seem to matter here.
Oh, you know what? I wonder if the
Oh, you know what? I wonder if the
hypers matter here because update epox
hypers matter here because update epox
is set way too
is set way too
high. If update epox is set like to
high. If update epox is set like to
four, then this is off policy,
four, then this is off policy,
right? Hang
right? Hang
on. What if we just do this one? What
on. What if we just do this one? What
happens?
the ablations that I'm kind of just like
the ablations that I'm kind of just like
sleepily hacking out right now. Uh each
sleepily hacking out right now. Uh each
of these runs would be like 2 hours plus
of these runs would be like 2 hours plus
if we were using
if we were using
conventional environments and
conventional environments and
infrastructure. So like there's just a
infrastructure. So like there's just a
very large difference in the speed with
very large difference in the speed with
which we can do
which we can do
things. Okay, that's a respectable
things. Okay, that's a respectable
speed. See, now we're at 1.5 million
speed. See, now we're at 1.5 million
steps per
second. We change value to relative
second. We change value to relative
time. That's
nice. So then we'll redo the parameter
nice. So then we'll redo the parameter
ablations.
ablations.
with this because now we're no longer so
with this because now we're no longer so
off policy provided that this actually
off policy provided that this actually
does
does
decently. This seems
decently. This seems
good. Yeah, this is decent so far.
kind of fell off like a little
bit, but also like the learning rate
bit, but also like the learning rate
kind
dropped. What happens if we do this?
dropped. What happens if we do this?
This is better or worse now. Check both
This is better or worse now. Check both
of these
It actually is worse, isn't
It actually is worse, isn't
it? Crazy. That makes a difference.
What if I do
this
this
point? What do you mean
bad? Oh, did you see? You should check
bad? Oh, did you see? You should check
my latest commit because I changed the
my latest commit because I changed the
logs and
logs and
everything. It's just an unused
variable that shouldn't break compile.
variable that shouldn't break compile.
Just a
warning. It
does. I'll look at it at some point, but
does. I'll look at it at some point, but
it's Do I need to like if you link it to
it's Do I need to like if you link it to
me, I'll go tell you what's
me, I'll go tell you what's
wrong. I changed. So all of the M's now
wrong. I changed. So all of the M's now
have a PF variable, which is a
have a PF variable, which is a
normalized single metric that goes from
normalized single metric that goes from
zero to
zero to
one. I did that
one. I did that
today. I left uh I didn't do any new
today. I left uh I didn't do any new
bindings though, like new I didn't do
bindings though, like new I didn't do
new bindings. C. I left that for
new bindings. C. I left that for
you to finish.
It's just single me. It's single metric
It's just single me. It's single metric
that is relevant to the
that is relevant to the
M. It's 0 to one
normalized. The point is that you can
normalized. The point is that you can
put all the M's on the same graph.
This does substantially worse as well,
This does substantially worse as well,
doesn't
doesn't
it?
it?
Okay, so this does substantially
worse. So except for the So I was going
worse. So except for the So I was going
to call it normalized or except for the
to call it normalized or except for the
fact that not all the M's have a score
fact that not all the M's have a score
that makes sense.
So in some it's like normal, some of
So in some it's like normal, some of
them it's win rate, some of them it's a
them it's win rate, some of them it's a
score. It's normalized whichever metric
score. It's normalized whichever metric
the N
the N
has. No, because not all the M's have a
has. No, because not all the M's have a
completion
completion
condition. So I intentionally named it
condition. So I intentionally named it
something else. So you wouldn't assume
something else. So you wouldn't assume
it's just like you know one variable or
it's just like you know one variable or
another.
Uh, okay. This is actually
something. Yeah, this is actually
something. Yeah, this is actually
something.
I'm just fiddling with this so that
I'm just fiddling with this so that
like we have something to go off of for
like we have something to go off of for
our curriculum learning work.
learning rate was 06 or
something 025. So crazy high learning
something 025. So crazy high learning
rate by comparison. Let's see what this
rate by comparison. Let's see what this
does.
Oh, wait. Hang on. Wrong wrong wrong
file
there. I'm going to send air on one of
there. I'm going to send air on one of
these runs and he's going to be like,
these runs and he's going to be like,
"What the h That takes me an hour to
"What the h That takes me an hour to
do. Like, yeah, well, it rains in two
do. Like, yeah, well, it rains in two
minutes
now. Did you know that puffer limits
fast? Fastest possible.
fast? Fastest possible.
Puffer. Puffer.
I'm interested to see here because this
I'm interested to see here because this
learning rate
O4. Yeah. So, it seems like
O4. Yeah. So, it seems like
um the harder M's need like lower learn
rates. Make sure this doesn't take off
rates. Make sure this doesn't take off
or some
or some
[ __ ] But, you know, we could try a
[ __ ] But, you know, we could try a
layer norm.
That is so stupid.
Is this
Is this
better? Oh, yeah, it
better? Oh, yeah, it
is. So, learning rate does actually need
is. So, learning rate does actually need
uh tuning. What did I do? It was
255. So we'll try 05 next.
honestly solid. I don't know why I'm
honestly solid. I don't know why I'm
manually tuning [ __ ] right now. I'm just
manually tuning [ __ ] right now. I'm just
trying to like smash the baseline on
trying to like smash the baseline on
this and give Aaron something
this and give Aaron something
to look at.
I think this is too high
potentially. Yeah, it's too
potentially. Yeah, it's too
high. We can do 25 like
high. We can do 25 like
this. And then that's going to be the
this. And then that's going to be the
last tune.
Oh, there. That's
interesting. Quite good, actually.
Okay, we'll keep this.
And
then my gamma is
already try.99.
Fine. How funny is it going to be if I
Fine. How funny is it going to be if I
like mostly solve this task?
We've been trying to solve this for a
We've been trying to solve this for a
while. Can solve it with hyperparameter
while. Can solve it with hyperparameter
tuning in the new advantage
stuff. 20 minutes more max on this. I'm
stuff. 20 minutes more max on this. I'm
going to bed.
Is this actually like
worse? You got to be kidding
worse? You got to be kidding
me. This is actually
me. This is actually
worse. You give it like
Still going up pretty
Still going up pretty
steep. 99
steep. 99
gamma. You're telling me if I put 999
gamma. You're telling me if I put 999
gamma, it's better. Mhm.
gamma, it's better. Mhm.
Is that how it
works? Yeah. And because I know the math
works? Yeah. And because I know the math
is why I'm
surprised
surprised
because.995 gamma is a very long
because.995 gamma is a very long
horizon.
You do realize though that
You do realize though that
like learning over that
is okay. So, it's actually it's pretty
is okay. So, it's actually it's pretty
close, right? It actually catches up
close, right? It actually catches up
pretty
pretty
well. But I will go the other way.
well. But I will go the other way.
We'll see.
We'll see.
9999 999
gamma. I like the shape of the green
curve. Purple curve best
curve. You don't want it round. Round
curve. You don't want it round. Round
means level. You I want a log. You want
means level. You I want a log. You want
log linear always.
Okay,
Okay,
thankfully there appears to be
sanity, but I'm going to let it run
sanity, but I'm going to let it run
because it's only a minute and it seems
because it's only a minute and it seems
like
like
um there is a bit of steepness to it.
I
mean, it's still kind of
linear. Still kind of linear.
linear. Still kind of linear.
[Music]
Okay, there it
goes.
Yeah, original hypers for these are
good. Low entropy is kind of weird.
Let's try layer norm.
Did that make it not learn
Did that make it not learn
anything? Something seems very off about
anything? Something seems very off about
that. Hang on.
Oh, it just doesn't
Oh, it just doesn't
learn. Okay.
Is it learning right now? Is to
Oh, you know what it is? It's that I'm
Oh, you know what it is? It's that I'm
really
dumb. It's that I'm really really
dumb. It's that I'm really really
stupid and I forgot to
stupid and I forgot to
uncomment the thingy and now it probably
uncomment the thingy and now it probably
everything because I hate Layer Norm and
everything because I hate Layer Norm and
Larorm hates Okay.
Is this still not work?
Really?
The one good thing about X is that when
The one good thing about X is that when
it has all this stupid content,
it has all this stupid content,
occasionally it has
seals. And that's pretty good.
There's even an entire part
There's even an entire part
of there's even an entire part of
of there's even an entire part of
uh X devoted to seals. Isn't that
uh X devoted to seals. Isn't that
lovely?
I don't any more of them.
There are no more seals on the
There are no more seals on the
timeline. I'm
timeline. I'm
stuck watching the grass, it seems.
This thing had a
This thing had a
crash. Oh no, it's just
um Maybe we have to go back to steps for
this. It's including the compile in it.
Oh. Oh.9. Cool. We're just We're just
Oh. Oh.9. Cool. We're just We're just
solving [ __ ] now, I
guess. Oh, there are more seals I have
guess. Oh, there are more seals I have
found.
This one is
good. All right, I guess we just solve
good. All right, I guess we just solve
everything tonight, huh?
I think this is good enough to
I think this is good enough to
call 98%.
this no longer exists. We get rid of
this no longer exists. We get rid of
this
I should probably just run neural MMO 3
I should probably just run neural MMO 3
as is on the new version to be honest.
It's funny as
hell. You going to be like,
"What?" Well, mine's still better.
Mine's still
better. No LP.
This is our
This is our
latest
latest
experiment. It was quite good.
Well, apparently there have been a lot
Well, apparently there have been a lot
of changes.
No coded GPUs
available. Reboot container.
Uh, I don't know how it got
Uh, I don't know how it got
faster. That seems
faster. That seems
weird that it would get
faster, but whatever. We will see if it
faster, but whatever. We will see if it
works.
I don't think it's actually faster. I
I don't think it's actually faster. I
think it's a reporting error, but
whatever. Okay, we'll see whether that
whatever. Okay, we'll see whether that
does
anything. Did I log a napkin there? No,
anything. Did I log a napkin there? No,
I didn't like a dummy.
There we go.
We have an extra box, don't we?
I have some
boxes. I always keep a couple for myself
boxes. I always keep a couple for myself
just so I have them so I can run my own
just so I have them so I can run my own
stuff on my own
boxes. I don't load them 100%, but it's
boxes. I don't load them 100%, but it's
better that I have them when I need
better that I have them when I need
them.
Cool. We have
Cool. We have
uh here we are.
uh here we are.
What happened to
this filters?
I'm still marching
I'm still marching
along doing
along doing
fine. It's layer
fine. It's layer
norm. Not
norm. Not
magic, but
magic, but
um does give you a little bit of perf.
um does give you a little bit of perf.
It looks like they still learn a lot
It looks like they still learn a lot
faster at the start as well. So that is
something. Okay, this is
something. Okay, this is
cool. This already does something,
right? That's fine.
right? That's fine.
So, we'll let these be for
So, we'll let these be for
now. Um, seems good to
now. Um, seems good to
me. And we have stuff nicely queued up
me. And we have stuff nicely queued up
for
for
tomorrow. We will run new ablations. We
tomorrow. We will run new ablations. We
will run lots of new stuff tomorrow.
will run lots of new stuff tomorrow.
9:30. Good time to call it. Get some
9:30. Good time to call it. Get some
sleep. Trying to put in a full
sleep. Trying to put in a full
day tomorrow.
day tomorrow.
Uh, so for the couple folks here, thanks
Uh, so for the couple folks here, thanks
for tuning
for tuning
in. More stream tomorrow. Should be some
in. More stream tomorrow. Should be some
pretty cool algorithm
dev. All my stuff's at puffer.ai. It's
dev. All my stuff's at puffer.ai. It's
all open source. If you want to come
all open source. If you want to come
support me for free, start the GitHub
support me for free, start the GitHub
almost at
almost at
2K. You can join the Discord to get
2K. You can join the Discord to get
involved with open source dev. You can
involved with open source dev. You can
follow me on X for more content.
follow me on X for more content.
We are currently
at 1948. Two more before it should round
at 1948. Two more before it should round
to
to
2K. So, thank you. And uh yeah, I'll
2K. So, thank you. And uh yeah, I'll
merge
