Kind: captions
Language: en
okay we should be
okay we should be
live
hello got lots of stuff to do
today timeline is a
today timeline is a
mess all
mess all
right let's um let's get some stuff done
right let's um let's get some stuff done
we have a lot of interesting things to
we have a lot of interesting things to
do today
do today
so let me go over just for a moment what
so let me go over just for a moment what
I've been working on
I've been working on
and uh some of my plans going forward so
and uh some of my plans going forward so
uh as I said before on
stream as a company puffers officially
stream as a company puffers officially
open for
open for
business uh all that means is that you
business uh all that means is that you
know I'm going to be spending a little
know I'm going to be spending a little
of my time looking for and hopefully uh
of my time looking for and hopefully uh
acquiring and doing some work for some
acquiring and doing some work for some
clients uh but everything's open source
clients uh but everything's open source
I'm still going to be streaming lots of
I'm still going to be streaming lots of
Dev and I've got lots of cool stuff
Dev and I've got lots of cool stuff
coming for everyone as
coming for everyone as
well speaking of
which we have these
which we have these
two games right now right you can play
two games right now right you can play
snake in your browser these snakes are
snake in your browser these snakes are
kind of dumb but they are running
kind of dumb but they are running
reinforcement learned policies in your
reinforcement learned policies in your
browser which is pretty cool and then we
browser which is pretty cool and then we
have this which we don't have the RL
have this which we don't have the RL
policies in here yet right but we have
policies in here yet right but we have
this this mobile game that runs in your
this this mobile game that runs in your
browser you know and it plays reasonably
browser you know and it plays reasonably
well maybe we have a few bugs to fix in
well maybe we have a few bugs to fix in
it since this is a new Port since we had
it since this is a new Port since we had
to Port it in order to get it to run
to Port it in order to get it to run
like
this company page no longer
this company page no longer
secret
secret
um but what I want to really really
um but what I want to really really
build out over the next week or so so as
build out over the next week or so so as
I said I've had one more big simulator
I said I've had one more big simulator
that's in the works it's going to take
that's in the works it's going to take
me a little longer to finish that I
me a little longer to finish that I
ported 2,000 lines of stuff to see over
ported 2,000 lines of stuff to see over
Saturday how are you running inference
Saturday how are you running inference
on web Onyx web runtime ho ho ho no no
on web Onyx web runtime ho ho ho no no
no no no Onyx web we don't need any of
no no no Onyx web we don't need any of
that where we're going my friend let me
that where we're going my friend let me
show
show
you that's actually what we're going to
you that's actually what we're going to
be working on today is improving that
snake
snake what is it snake.
h pure C
h pure C
implementation of the neural net and we
implementation of the neural net and we
load the weights from P
load the weights from P
torch that's what we're
torch that's what we're
doing so now this is not very impressive
doing so now this is not very impressive
on its own right it's kind of cool that
on its own right it's kind of cool that
you can do this but it's just an MLP now
you can do this but it's just an MLP now
the thing that I'm working on now which
the thing that I'm working on now which
is what we're going to be doing today
okay oops wrong
okay oops wrong
one puffer
net takes my hands a little bit to warm
net takes my hands a little bit to warm
up
up
typing we have linear layers comms lstm
typing we have linear layers comms lstm
and a few other utility functions all in
and a few other utility functions all in
pure C so we're actually going to be
pure C so we're actually going to be
able to upgrade our web AI uh to be able
able to upgrade our web AI uh to be able
to run pretty reasonably sophisticated
to run pretty reasonably sophisticated
Networks
Networks
so the goal is going to be to finish
so the goal is going to be to finish
this puffer net thing get it running the
this puffer net thing get it running the
MOBA Network get it running the much
MOBA Network get it running the much
better snake Network and then the
better snake Network and then the
network for the secret project as
network for the secret project as
well and if we can do all of
well and if we can do all of
that then we'll have some pretty crazy
that then we'll have some pretty crazy
demos that will just run in your
demos that will just run in your
browser I think that'd be pretty
browser I think that'd be pretty
cool also um folks if you have not
cool also um folks if you have not
started the
started the
repository we are two stars off of
repository we are two stars off of
1K it's all free and open source right
1K it's all free and open source right
here so if you want to help me out get
here so if you want to help me out get
us to a th000 today that would be
us to a th000 today that would be
awesome I really didn't know if we were
awesome I really didn't know if we were
going to be able to hit this over the
going to be able to hit this over the
summer this is crazy the amount of
summer this is crazy the amount of
growth and I appreciate all the support
growth and I appreciate all the support
on this as well it helps to get the uh
on this as well it helps to get the uh
the word out about this so that puffer
the word out about this so that puffer
can get a little bit of Revenue and uh
can get a little bit of Revenue and uh
hopefully we can do some good work for
hopefully we can do some good work for
some
some
companies and we can start investing
companies and we can start investing
more in our own infrastructure I'd
more in our own infrastructure I'd
really like to start upgrading the
really like to start upgrading the
puffer cluster and start uh putting up
puffer cluster and start uh putting up
some bounties for you know open source
some bounties for you know open source
contributors contributors as
contributors contributors as
well 1K 100 is awesome 10K
well 1K 100 is awesome 10K
next I mean maybe I don't know if there
next I mean maybe I don't know if there
is an RL repo like an RL Library type
is an RL repo like an RL Library type
thing with 10K on it
but that's enough yapping for now I
but that's enough yapping for now I
should
uh interesting okay uh I should actually
uh interesting okay uh I should actually
start working on some of this stuff so
start working on some of this stuff so
you can see what's going
on I can't
type whoops
it's Monday this is what I get for
it's Monday this is what I get for
taking a half day off for once
taking a half day off for once
yesterday I needed a little bit of a
break all right so we go to perer
lib ocean porch okay so this is the
lib ocean porch okay so this is the
network that we need to Port today it's
network that we need to Port today it's
a little bit of cuz this network is a
a little bit of cuz this network is a
lot more complicated than I originally
lot more complicated than I originally
thought know this is a pretty
thought know this is a pretty
complicated thing
here um but we're going to see what I
here um but we're going to see what I
can get done on it
we have
puffet and then we have this network
puffet and then we have this network
that I started working on
that I started working on
here and I think that the big issue if I
here and I think that the big issue if I
recall was just the
data they're getting the data into a
data they're getting the data into a
reasonable format
right I think I figured out a workaround
right I think I figured out a workaround
though I I think I figured out a good
though I I think I figured out a good
workaround so
workaround so
um CNN
um CNN
features yeah so the way we're going to
features yeah so the way we're going to
we're going to cheat this a little bit
we're going to cheat this a little bit
obviously these are all
obviously these are all
hardcoded but what I'm going to do is
hardcoded but what I'm going to do is
plus three and this is
plus three and this is
cheat um continuous
features at the end
and then I need to do a little bit of
and then I need to do a little bit of
custom logic here I
custom logic here I
believe because we
take o that's harder than I thought
take o that's harder than I thought
actually now that I'm looking at
it I wouldn't mind just doing this
it I wouldn't mind just doing this
completely custom for right now because
completely custom for right now because
if I just do it completely custom I'm
if I just do it completely custom I'm
going to get something that's pretty
going to get something that's pretty
simple I would
simple I would
think it's going to be a little trickier
think it's going to be a little trickier
to test
it so let me explain what's going on
it so let me explain what's going on
through my head here
through my head here
um how's your weekend weekend's going
um how's your weekend weekend's going
good weekend went
good weekend went
well I should be a little bit more
well I should be a little bit more
rested then I uh I appear at the moment
rested then I uh I appear at the moment
I'm like all messed up just need my
I'm like all messed up just need my
coffee
but I did get some rest so as soon as I
but I did get some rest so as soon as I
warm up here I should be uh cranking
warm up here I should be uh cranking
some good
some good
stuff let me explain a little bit of
stuff let me explain a little bit of
what's going through my head here and
what's going through my head here and
why this is actually kind of difficult
why this is actually kind of difficult
so essentially in pytorch you have this
so essentially in pytorch you have this
slice operation here right where I can
slice operation here right where I can
slice tensors along various dimensions
slice tensors along various dimensions
and it makes it very easy
and it makes it very easy
um now I'd have to double check this
um now I'd have to double check this
because it's it's possible they have
because it's it's possible they have
some operations but what you have to
some operations but what you have to
understand is that um if you're slicing
understand is that um if you're slicing
anything except the First
anything except the First
Dimension depending on the memory format
Dimension depending on the memory format
but usually depending hey
but usually depending hey
welcome uh usually if you slice anything
welcome uh usually if you slice anything
except the First Dimension you're
except the First Dimension you're
actually going to incur a copy of the
actually going to incur a copy of the
data and you actually have to do some
data and you actually have to do some
complicated operations behind the scene
complicated operations behind the scene
in order to copy the data along the
in order to copy the data along the
specific Dimension that you want now I
specific Dimension that you want now I
could Implement that similar slice logic
could Implement that similar slice logic
in C and maybe it would be even a good
in C and maybe it would be even a good
idea to do that but at the same time
idea to do that but at the same time
this is kind of an opportunity for me to
this is kind of an opportunity for me to
rethink a little bit how I'm making
rethink a little bit how I'm making
these networks because this is slow
these networks because this is slow
right this is really slow
right this is really slow
um and ideally what we should be able to
um and ideally what we should be able to
do here is rewrite this network a little
do here is rewrite this network a little
bit to just be faster and not to have
bit to just be faster and not to have
these copy op operations which would
these copy op operations which would
then make the C code a little bit
simpler so I'm trying to decide if I
simpler so I'm trying to decide if I
want to like mess
want to like mess
with the puffer lib Network code first
with the puffer lib Network code first
or if I want to mess with the c
or if I want to mess with the c
code or how I want to do
code or how I want to do
this because the more I look at this
this because the more I look at this
right the less I like it
right the less I like it
like the observations are stored as flat
like the observations are stored as flat
data
data
so this last these last 26 elements here
so this last these last 26 elements here
this gets your memory to be
this gets your memory to be
non-contiguous so right here this is a
non-contiguous so right here this is a
copy this view is fine and
then one hotting so this is at
then one hotting so this is at
least right here this is a copy and then
least right here this is a copy and then
this is another
this is another
copy and then this is a copy like you
copy and then this is a copy like you
can see we're just copying the data all
can see we're just copying the data all
over the place
that's a big
that's a big
problem that's a very big
problem that's a very big
problem the thing that's tricky about
problem the thing that's tricky about
this is that there's pretty much always
this is that there's pretty much always
a way to do it where you're not going to
a way to do it where you're not going to
be copying all the data all over the
be copying all the data all over the
place um but it's almost always going to
place um but it's almost always going to
write uh require you to write like
write uh require you to write like
custom
custom
kernels which I know how to do in
kernels which I know how to do in
C I don't know the I
C I don't know the I
wouldn't I mean I could look at doing my
wouldn't I mean I could look at doing my
own Cuda konel for this I'd rather not
own Cuda konel for this I'd rather not
have to do
have to do
that but um
yeah I really do want this network to be
efficient I'm trying to think how
yeah like there's no way that that's
yeah like there's no way that that's
contiguous
right it's actually funny because now
right it's actually funny because now
that I'm looking at this I know how to
that I'm looking at this I know how to
do it in C I don't know how to know I
do it in C I don't know how to know I
don't even know how to do it in P torch
you need to be able to write
Loops
right I was thinking about over the
right I was thinking about over the
weekend as well whether it's actually
weekend as well whether it's actually
possible to uh come up with just a more
possible to uh come up with just a more
efficient Network design so I don't have
efficient Network design so I don't have
to do all of this but that seems
to do all of this but that seems
unlikely to
unlikely to
me because like you're pretty much the
me because like you're pretty much the
reason that the data looks like this is
reason that the data looks like this is
that I'm going to bring up since I see
that I'm going to bring up since I see
we have people joining here let me uh
we have people joining here let me uh
let me just bring up the diagrams here
let me just bring up the diagrams here
let me just write this out real quick so
let me just write this out real quick so
you can understand the problem and maybe
you can understand the problem and maybe
this will get me to uh understand a
this will get me to uh understand a
little
little
better
better
online let me show you what uh what the
online let me show you what uh what the
problem is
problem is
here oh okay perfect it saved our image
here oh okay perfect it saved our image
so if you look at this as being like a
so if you look at this as being like a
2d block of memory where like
um if you look at this as a 2d block of
um if you look at this as a 2d block of
memory where like this way is the
memory where like this way is the
columns right and this is your batch
columns right and this is your batch
size so this like first row here is your
size so this like first row here is your
first
first
observation then what ends up happening
observation then what ends up happening
is like we have in this data this last
is like we have in this data this last
chunk right here is going to be equal to
chunk right here is going to be equal to
extra data which is data that is
extra data which is data that is
gathered uh from your specific agent
gathered uh from your specific agent
right so it's like hidden stuff that
right so it's like hidden stuff that
your agent knows about itself the other
your agent knows about itself the other
agents don't know about it you're pretty
agents don't know about it you're pretty
much always going to need some data of
much always going to need some data of
that type and then what this chunk is at
that type and then what this chunk is at
the start is uh local 2D map data which
the start is uh local 2D map data which
is data that is the agent can see from
is data that is the agent can see from
nearby right and I specifically I have
nearby right and I specifically I have
two different types of data in there we
two different types of data in there we
can kind of ignore that as n mentation
can kind of ignore that as n mentation
detail for now uh but technically there
detail for now uh but technically there
are two different types of this data in
are two different types of this data in
these blocks now the problem is this is
these blocks now the problem is this is
not how contiguous memory works right
not how contiguous memory works right
this is contiguous this chunk here is
this is contiguous this chunk here is
not so if I want to split these out I
not so if I want to split these out I
have to do a copy of the
have to do a copy of the
data and then you know whatever I do
data and then you know whatever I do
with
with
it depending on how I do that can incur
it depending on how I do that can incur
additional
additional
copies um and we have this long
copies um and we have this long
pre-processing process where eventually
pre-processing process where eventually
we just want to convert all this data
we just want to convert all this data
into a nice contiguous block
into a nice contiguous block
and the issue is that like I know how to
and the issue is that like I know how to
do this if I'm going to write custom
do this if I'm going to write custom
Loops for everything I know how to do
Loops for everything I know how to do
that um so I can do that in C and make
that um so I can do that in C and make
sure that the web networks are
sure that the web networks are
reasonably efficient but then the P
reasonably efficient but then the P
torch networks which are more important
torch networks which are more important
that they be fast are
that they be fast are
harder can you help me I want to
harder can you help me I want to
implement RL for simulation RL with some
implement RL for simulation RL with some
pre-train model and use the knowledge to
pre-train model and use the knowledge to
explore similar to
explore similar to
humans that is hard
humans that is hard
uh all PO
uh all PO
is it depends what simulation like are
is it depends what simulation like are
you building a simulation for this are
you building a simulation for this are
you using an existing one it depends
you using an existing one it depends
what you're doing
here
uh well I think that the the most
uh well I think that the the most
practical way of doing this assuming
practical way of doing this assuming
that I don't want to start writing my
that I don't want to start writing my
own custom kernels for networks just yet
own custom kernels for networks just yet
that seems a bit
that seems a bit
Overkill is going to be to look at the
Overkill is going to be to look at the
design of this P torch Network and see
design of this P torch Network and see
where I can cut out some of these copies
potentially
so I have to just confirm
slicing creates a view
right tensor
views do they actually have some
views do they actually have some
efficient stuff on this
uh okay I
uh okay I
see
see
so maybe I don't have to worry too much
so maybe I don't have to worry too much
about this where should I look for that
about this where should I look for that
um I mean neural MMO is kind of one it's
um I mean neural MMO is kind of one it's
a more complicated environment you can
a more complicated environment you can
look at like if you want inspiration for
look at like if you want inspiration for
stuff you can look at works like
stuff you can look at works like
xland
xland
um I'm trying to think of other ones
um I'm trying to think of other ones
people did like this xland minig grid
people did like this xland minig grid
thing that's like not really all that
thing that's like not really all that
complicated but it's has some of those
complicated but it's has some of those
properties um new Solutions in
properties um new Solutions in
simulation similar to humans I mean that
simulation similar to humans I mean that
kind of
kind of
happens if you run it for long enough
happens if you run it for long enough
though typically if you want it to keep
though typically if you want it to keep
exploring and keep developing new things
exploring and keep developing new things
it needs to be able to update its model
it needs to be able to update its model
because like RL models don't have we
because like RL models don't have we
don't have amazing methods of memory at
don't have amazing methods of memory at
the moment so like you kind of need to
the moment so like you kind of need to
keep
keep
learning right so if you think about it
learning right so if you think about it
like the thing that's similar to humans
like the thing that's similar to humans
is actually kind of just doing online RL
is actually kind of just doing online RL
in the first place right like humans
in the first place right like humans
aren't fixed we're allowed to learn so
aren't fixed we're allowed to learn so
it's like the more realistic thing if
it's like the more realistic thing if
you want to look at it that way is to
you want to look at it that way is to
just keep training and look for stuff
just keep training and look for stuff
where it can keep finding new Solutions
where it can keep finding new Solutions
which is the definition of
open-endedness so it does look like
open-endedness so it does look like
pytorch has some operations
pytorch has some operations
here
uh outputs are unne avoid unnecessary
uh outputs are unne avoid unnecessary
data okay
yeah this is very odd because you
yeah this is very odd because you
actually I can't tell
here this is interesting that they say
here this is interesting that they say
their split operation does not like
their split operation does not like
their split operations don't actually um
their split operations don't actually um
affect memory they don't actually
copy but I think that as soon as you go
copy but I think that as soon as you go
to do anything with that data right of
to do anything with that data right of
course it has to copy it
anyway
anyway
so let's say that I split
so let's say that I split
this and then I one hot it
split view
split view
split one
split one
hun that's so freaking complicated
though really don't like
that you know I really want to be able
that you know I really want to be able
to
to
have an architecture here that isn't
have an architecture here that isn't
like this crazy Beast of a thing to
like this crazy Beast of a thing to
optimize
and this is adding complexity complexity
and this is adding complexity complexity
to stuff I guess technically there is
to stuff I guess technically there is
another format I can consider though I
another format I can consider though I
don't know if it makes it any
don't know if it makes it any
easier I guess it kind of makes it
easier I guess it kind of makes it
easier in the sense that like if I
easier in the sense that like if I
commit to this type of an architecture
commit to this type of an architecture
then I only ever have one thing to
then I only ever have one thing to
optimize but I don't know if the
optimize but I don't know if the
architecture itself is very good um if
architecture itself is very good um if
you commit to either having everything
you commit to either having everything
be discrete or discretizing everything
be discrete or discretizing everything
so that like each type of observation
so that like each type of observation
you have is discrete in some way
you have is discrete in some way
then you can pack everything into an
then you can pack everything into an
integer I don't know if that's
integer I don't know if that's
better I should probably also make this
better I should probably also make this
in view can we use the same network to
in view can we use the same network to
train on multiple different
train on multiple different
simulations build up some general
simulations build up some general
knowledge
knowledge
so the general rule on that is you can
so the general rule on that is you can
probably train on different simulations
probably train on different simulations
but only if you have a lot of different
but only if you have a lot of different
simulations if you have like n equals 2
simulations if you have like n equals 2
simulations that's very difficult to do
simulations that's very difficult to do
generally like when you want to learn
generally like when you want to learn
when you want to learn General patterns
when you want to learn General patterns
you need a lot of different type of data
you need a lot of different type of data
and we're mostly missing the we're
and we're mostly missing the we're
missing simulations to do that the
missing simulations to do that the
easiest way at the moment is to train
easiest way at the moment is to train
within like one big simulator that has
within like one big simulator that has
lots of different tasks or lots of
lots of different tasks or lots of
different things you can do just a
different things you can do just a
beginner doing some important work talk
beginner doing some important work talk
about it later yeah sure it's uh yeah
about it later yeah sure it's uh yeah
let me get some of this stuff done I
let me get some of this stuff done I
will tell you you're trying to dive in
will tell you you're trying to dive in
at the deep end as a beginner like
at the deep end as a beginner like
you're going immediately from like
you're going immediately from like
you're going immediately to like The
you're going immediately to like The
Cutting Edge of RL in which we don't
Cutting Edge of RL in which we don't
know necessarily how stuff is working so
know necessarily how stuff is working so
that's not necessarily a bad thing but I
that's not necessarily a bad thing but I
would suggest that you try working like
would suggest that you try working like
you're going to have more fun working on
you're going to have more fun working on
areas where you can at least see some
areas where you can at least see some
consistent progress and work towards
consistent progress and work towards
that if you just try to do that one shot
that if you just try to do that one shot
right now you're going to end up with a
right now you're going to end up with a
lot of
difficulty it's a bit unfortunate how
difficulty it's a bit unfortunate how
stuck I am on this network
architecture like it seems so good in
architecture like it seems so good in
theory
I mean It's just tough to come up with
I mean It's just tough to come up with
like
like
good reusable Network architectures I
suppose like I guess the ideal one
suppose like I guess the ideal one
right the best way of doing stuff if you
right the best way of doing stuff if you
can get away with
can get away with
it is to just like have all your data be
it is to just like have all your data be
flat and then just do coms over it
that's not bad hold on let me think
that's not bad hold on let me think
about that let me think about
that
that
so the tricky portion with that is
so the tricky portion with that is
like your data can blow up quite a
lot maybe it will help me to try to if I
lot maybe it will help me to try to if I
explain this more thoroughly maybe I'll
explain this more thoroughly maybe I'll
get some ideas is and then folks can
get some ideas is and then folks can
actually learn some stuff in the process
actually learn some stuff in the process
let's do that so
um
okay okay so there are a couple
okay okay so there are a couple
different ways you can treat your
different ways you can treat your
data and encode
data and encode
data for Ultra highper reinforcement
data for Ultra highper reinforcement
learning
learning
right let's say that you have multiple
right let's say that you have multiple
different features
different features
like let's say that you have like an
like let's say that you have like an
agent has a type that can be zero 1 2
agent has a type that can be zero 1 2
3 and then maybe it has like
3 and then maybe it has like
HP which is like 0 to
HP which is like 0 to
100 and then maybe it has like some
100 and then maybe it has like some
other variables right like you know 0 to
five 0 to
five 0 to
10 and some of these might be discret
10 and some of these might be discret
some of them might be continuous
some of them might be continuous
so there are a few ways you can deal
so there are a few ways you can deal
with this the first and the easiest is
with this the first and the easiest is
you can just pack
you can just pack
everything into like multiple
channels so you just pack everything
channels so you just pack everything
like this what the heck is that yeah
like this what the heck is that yeah
there we go you just pack everything
there we go you just pack everything
like this and if we just like slice it
like this and if we just like slice it
this
this
way right then this one goes there this
way right then this one goes there this
one goes to here this one goes to here
one goes to here this one goes to here
right
right
that's one way of doing it now there are
that's one way of doing it now there are
some limitations with this first of
all this
all this
is discrete
is discrete
data it's not continuous so we don't
data it's not continuous so we don't
want to put it into one com Channel
want to put it into one com Channel
actually what this needs is
this needs a one hot
this needs a one hot
embedding right so you can do like one
embedding right so you can do like one
hot like
this this needs a one hot embedding so
this this needs a one hot embedding so
this block of data needs to become four
this block of data needs to become four
channels but then maybe HP doesn't need
channels but then maybe HP doesn't need
to become four channels right maybe you
to become four channels right maybe you
do want the continuous value of HP but
do want the continuous value of HP but
then that is difficult because now if
then that is difficult because now if
you want this to be continuous but this
you want this to be continuous but this
to be discrete so you have to normalize
to be discrete so you have to normalize
this which is kind of fine but now you
this which is kind of fine but now you
have to know which channels need to be
have to know which channels need to be
one hotted and which ones don't which is
one hotted and which ones don't which is
a bit
tricky there's also the question of how
tricky there's also the question of how
much we want to commit to a
much we want to commit to a
convolutional representation in the
convolutional representation in the
first place because like this makes
first place because like this makes
sense for the grid environments that I'm
sense for the grid environments that I'm
doing now so like if I wanted to right I
doing now so like if I wanted to right I
could invest a bunch of time and coming
could invest a bunch of time and coming
up with a really nice fancy encoder for
up with a really nice fancy encoder for
this cuz if I were given enough time
this cuz if I were given enough time
right I could come up with a really
right I could come up with a really
sweet like 2D mixed discreet and
sweet like 2D mixed discreet and
continuous encoder and maybe I should do
continuous encoder and maybe I should do
that cuz that would be a really useful
that cuz that would be a really useful
tool to have it's just a bit tricky
tool to have it's just a bit tricky
because i' probably I'd have to like
because i' probably I'd have to like
write the kernels for it which I can do
write the kernels for it which I can do
that in C but then doing that for GPU
that in C but then doing that for GPU
for p torch would be really uh really a
for p torch would be really uh really a
lot more difficult
but it's doable but then the question is
but it's doable but then the question is
you know is this even a good
you know is this even a good
representation at all
representation at all
because this is very specific to grid
because this is very specific to grid
like grid type environments right you
like grid type environments right you
might not want to always have grid type
might not want to always have grid type
environments right maybe the majority of
environments right maybe the majority of
this data is actually going to be entity
this data is actually going to be entity
based so if you know you have your agent
based so if you know you have your agent
on your map here
on your map here
right and you have like other
stuff then like the the one way of
stuff then like the the one way of
handling it is to do a grid based
handling it is to do a grid based
representation like this so it observes
representation like this so it observes
the stuff around it this is not Tic Tac
the stuff around it this is not Tic Tac
Toe but it looks like
Toe but it looks like
it um but then the other way of doing
it um but then the other way of doing
this is you could
instead if I just draw the same thing
right you can get an entity based
right you can get an entity based
encoding instead and there's been some
encoding instead and there's been some
work on
work on
that this tends to be kind of difficult
that this tends to be kind of difficult
but you can do
but you can do
it cuz like you need to encode position
it cuz like you need to encode position
data in here and then your agent needs
data in here and then your agent needs
to learn like relative position type
to learn like relative position type
stuff and also generally like making
stuff and also generally like making
relativizing the position is
relativizing the position is
difficult not that difficult
though actually really not that
though actually really not that
difficult now that I think about it
difficult now that I think about it
because I'm writing the environment in
because I'm writing the environment in
freaking C
anyways graph neural network
anyways graph neural network
simpler entity neural network I highly
simpler entity neural network I highly
recommend I highly highly recommend this
recommend I highly highly recommend this
blog post by
blog post by
Clemens um just if you look up entity
Clemens um just if you look up entity
based RL he has this really nice blog
based RL he has this really nice blog
post on this architecture and it's a
post on this architecture and it's a
good architecture and I do think it's
good architecture and I do think it's
interesting that he uses like
interesting that he uses like
Transformer type blocks and he gets high
Transformer type blocks and he gets high
performance but he gets high performance
performance but he gets high performance
for like back then standards right like
for like back then standards right like
the stuff I'm doing with puffer now is
the stuff I'm doing with puffer now is
so much faster than this it's not even
funny he's got a bunch of fun
posts he also has this one
posts he also has this one
one I really like this one
one I really like this one
here maybe I should get
here maybe I should get
um maybe I should ask him about this
um maybe I should ask him about this
environment and if he has the code for
environment and if he has the code for
this open source cuz like adding an RTS
this open source cuz like adding an RTS
to puffer would be really
cool I wonder how he did all this online
cool I wonder how he did all this online
as well
I don't know if this is anywhere near
I don't know if this is anywhere near
high as high perf
though yeah this is very cool though
what did he use for
what did he use for
this yeah he's always doing entity based
this yeah he's always doing entity based
stuff
here this is kind of nice in a
here this is kind of nice in a
way that like
H I actually don't know if these are
H I actually don't know if these are
nice in a
way having all these separate different
way having all these separate different
little networks is very
inefficient I wouldn't be surprised that
inefficient I wouldn't be surprised that
this ends up being very
this ends up being very
slow it does seem dumb ultimately to bet
slow it does seem dumb ultimately to bet
against this architecture this does seem
against this architecture this does seem
like a good architecture but like this
like a good architecture but like this
is just a tiny number of
is just a tiny number of
samples training takes over a 2 Days 12
hours just over two days about 12 okay
hours just over two days about 12 okay
so 36 hours for 125 million samples like
so 36 hours for 125 million samples like
125 million samples in puffer lib for
125 million samples in puffer lib for
some of our stuff is like 2 to 5
minutes and he has more cores
and he's yeah and he's using multi-gpu
and he's yeah and he's using multi-gpu
as
well I do very much like this project
well I do very much like this project
though and looking at this is actually a
though and looking at this is actually a
kind of a good thing for like how I'm
kind of a good thing for like how I'm
thinking about architectures now
got very good work on
this value
function omnicient value function
function omnicient value function
essential is annoying
appendex hold
appendex hold
on so much stuff
did he open source this environment
this demo site no longer
works I don't know if he actually open
works I don't know if he actually open
sourced the environment
ever I got to make some decisions here
ever I got to make some decisions here
and the thing is the tough thing is like
and the thing is the tough thing is like
I'm generally of the camp of just like
I'm generally of the camp of just like
just coat it and you know you'll figure
just coat it and you know you'll figure
stuff out
stuff out
afterwards but this is one of the places
afterwards but this is one of the places
where it's like I can save myself a lot
where it's like I can save myself a lot
of headache if I get it right on the
of headache if I get it right on the
first
try well I think that regardless like
you definitely want your network
you definitely want your network
operations to be
shared so that thing that he had with
shared so that thing that he had with
all those different embeddings you
all those different embeddings you
really don't want to have
happen the same time the entity
happen the same time the entity
architecture is so nice conceptually
is it
is it
though
though
wait I don't actually even know if the
wait I don't actually even know if the
embeding network architecture is nice
embeding network architecture is nice
conceptually now that I'm thinking about
it cuz embedding each feature separately
it cuz embedding each feature separately
like that's expensive very very
expensive there are definitely some
expensive there are definitely some
things that need to be one hotted there
things that need to be one hotted there
definitely some things that need to be
definitely some things that need to be
one
hotted
like the observation map is a really
like the observation map is a really
good example of this
good example of this
all right I'll draw up another thing
all right I'll draw up another thing
here real
here real
quick so what I'm doing right now with
quick so what I'm doing right now with
the Moa and I use this approach in a lot
the Moa and I use this approach in a lot
of places right I have a core map that
of places right I have a core map that
looks like
this and like you know you could have
this and like you know you could have
different entity Types on here right
different entity Types on here right
like I can have like
right I can have like all these
right I can have like all these
different entity types and then the way
different entity types and then the way
that you actually process these this is
that you actually process these this is
going to be like one 0 0 0 2 3 3
going to be like one 0 0 0 2 3 3
Z 1
Z 1
to
Z okay so this is what the network
Z okay so this is what the network
actually sees this is how one hot
actually sees this is how one hot
encoding
encoding
works and then specifically when we
works and then specifically when we
encode this right like the way that this
encode this right like the way that this
one would get encoded this is the one
one would get encoded this is the one
hot
hot
representation so there are 0 1 2 3 so
representation so there are 0 1 2 3 so
four different element types
four different element types
right and then what we do is we go to
right and then what we do is we go to
the first one and we shade this one
the first one and we shade this one
in and this is your like your 1D
in and this is your like your 1D
depthwise Network
depthwise Network
here right so this is your one hot
here right so this is your one hot
representation
is this
is this
good the
question I'm trying to think about if
question I'm trying to think about if
this is good or
not is this the replayer Tic Tac to no
not is this the replayer Tic Tac to no
this is me trying to explain so Nathan
this is me trying to explain so Nathan
um actually maybe your thoughts will be
um actually maybe your thoughts will be
good on this as well because well
good on this as well because well
actually hold on did you finish your uh
actually hold on did you finish your uh
did you finish your
thesis oh man the YouTube delay
in the meantime so this is not three
in the meantime so this is not three
player Tic Tac Toe this is me explaining
player Tic Tac Toe this is me explaining
um encodings of
observations and I'm actually trying to
observations and I'm actually trying to
think about this here because
think about this here because
like oh you finished
like oh you finished
it Round of Applause for this man please
it Round of Applause for this man please
folks heck
folks heck
yeah hey Nathan if you're down to work
yeah hey Nathan if you're down to work
on uh environment stuff at all you know
on uh environment stuff at all you know
throughout this week or whatever I am
throughout this week or whatever I am
absolutely 100% available to help you
absolutely 100% available to help you
with that stuff I would love to see that
with that stuff I would love to see that
environment come to uh to fruition that
environment come to uh to fruition that
looks awesome what I'm trying to do
looks awesome what I'm trying to do
right now so I've got the Moa I've got
right now so I've got the Moa I've got
my secret side project right I've got
my secret side project right I've got
additional stuff that I'm working on I
additional stuff that I'm working on I
also just announced puffer officially
also just announced puffer officially
open for business as well today uh so
open for business as well today uh so
you know there's going to be some stuff
you know there's going to be some stuff
holy people are actually uh supporting
holy people are actually uh supporting
this thank you
um but uh the thing that I want to do
um but uh the thing that I want to do
and that I think it's going to support
and that I think it's going to support
your stuff and it's going to support all
your stuff and it's going to support all
the stuff that we're trying to do so so
the stuff that we're trying to do so so
much right
much right
now this is the problem that caused me
now this is the problem that caused me
so much grief throughout my whole PhD
so much grief throughout my whole PhD
getting good observation representations
getting good observation representations
in RL is so hard like coming up with a
in RL is so hard like coming up with a
good way to format your observation data
good way to format your observation data
such that it it's easy to put into
such that it it's easy to put into
networks and make fast is really
networks and make fast is really
hard so like okay I have some thoughts
hard so like okay I have some thoughts
on this and folks maybe you guys will
on this and folks maybe you guys will
have some input because this is really
have some input because this is really
this is not a super technical
this is not a super technical
area this is relatively
area this is relatively
accessible
accessible
so this is the data
so this is the data
um right now you have 1 Z 0 023 right so
um right now you have 1 Z 0 023 right so
I can encode this the most efficient way
I can encode this the most efficient way
to encode this typically is this is just
to encode this typically is this is just
going to be U and eight right so this is
going to be U and eight right so this is
now bytes technically I can compress
now bytes technically I can compress
this even more if I want to do custom
this even more if I want to do custom
compression uh I only need let's see
compression uh I only need let's see
there are four different values I only
there are four different values I only
need two bits per item here uh so I can
need two bits per item here uh so I can
technically compress this even more but
technically compress this even more but
then I've got to uncompress it which is
then I've got to uncompress it which is
you know potentially difficult maybe
you know potentially difficult maybe
once I start writing like custom kernels
once I start writing like custom kernels
for networks uh for puffer once we get
for networks uh for puffer once we get
into that level of optimization then we
into that level of optimization then we
can start looking at that but for now
can start looking at that but for now
this is bites okay and this is not bad
this is bites okay and this is not bad
right this is fine but what happens is
right this is fine but what happens is
you can see that when I expand this here
you can see that when I expand this here
not only do I have to have all this
not only do I have to have all this
memory available right because now I
memory available right because now I
have four times this amount of memory I
have four times this amount of memory I
have four of these grids and if I have
have four of these grids and if I have
like 10 or 15 different object types
like 10 or 15 different object types
what ends up happening is you get this
what ends up happening is you get this
giant ass block of memory
right you get 15 of these going this way
right you get 15 of these going this way
15 different layers now that's not a ton
15 different layers now that's not a ton
of uh that's not a ton because we'll
of uh that's not a ton because we'll
typically have 32 or 64 con filters
typically have 32 or 64 con filters
anyways so this is not bad on its own
anyways so this is not bad on its own
but having to unpack data like this is
but having to unpack data like this is
slightly annoying now if you just have
slightly annoying now if you just have
one of these it's not that bad if this
one of these it's not that bad if this
is all you need to do I'm happy but the
is all you need to do I'm happy but the
problem is that this is very rarely the
problem is that this is very rarely the
case right this is very rarely the thing
case right this is very rarely the thing
on its own because what'll happen is you
on its own because what'll happen is you
end up having like multiple layers of
end up having like multiple layers of
this stuff right this just says okay
this stuff right this just says okay
this is you know this type of entity is
this is you know this type of entity is
in this cell I have like an O here an X
in this cell I have like an O here an X
here a triangle here well what if they
here a triangle here well what if they
have health values right maybe this
have health values right maybe this
has pick another color right maybe we
has pick another color right maybe we
have like
have like
HP and now this has like three HP this
HP and now this has like three HP this
has 5 HP five you know maybe this one
has 5 HP five you know maybe this one
has 2 Hp maybe this one's been hit it
has 2 Hp maybe this one's been hit it
has one HP and this one has three right
has one HP and this one has three right
like now I have to
like now I have to
add channels here and I either have to
add channels here and I either have to
add one channel if I want to just put
add one channel if I want to just put
this in as a continuous value and then I
this in as a continuous value and then I
have to handle mix continuous and
have to handle mix continuous and
discret in the encoder
discret in the encoder
or uh I have to discretize this right
or uh I have to discretize this right
and then I lose
and then I lose
Precision so this is kind of hard
Precision so this is kind of hard
this is kind of hard
right like
technically
uh the mixing of different data types
uh the mixing of different data types
like this some of which require discret
like this some of which require discret
and some of which require continuous is
and some of which require continuous is
hard
hard
and also if you have multiple different
and also if you have multiple different
discreet types you end up having to have
discreet types you end up having to have
like this multi hot embedding layer that
like this multi hot embedding layer that
like Stacks a whole bunch of layers and
like Stacks a whole bunch of layers and
it's gotten up to be like 60 before I've
it's gotten up to be like 60 before I've
done I've had to
do and you lose
Precision I don't know if there's a way
Precision I don't know if there's a way
around it
though representing this date is hard
you really want the con layer coner
you really want the con layer coner
gives you a ton of good priors about
gives you a ton of good priors about
local uh spatial locality
right entity based embedding doesn't buy
right entity based embedding doesn't buy
you anything if you were to do entity
you anything if you were to do entity
based that does not buy you
based that does not buy you
anything entity base means that you just
anything entity base means that you just
record an entry for each of these
record an entry for each of these
instead of recording like the whole cell
instead of recording like the whole cell
the whole grid but that really doesn't
the whole grid but that really doesn't
do anything for
you I mean it's less data
you I mean it's less data
actually but you still have to you still
actually but you still have to you still
have all the same technical problem so I
have all the same technical problem so I
think that that's
think that that's
orthogonal yeah it's the mix continuous
orthogonal yeah it's the mix continuous
and discreet embedding is the problem
doing that really fast and
simple I mean technically I can punt on
simple I mean technically I can punt on
it and say that I'm going to have to
it and say that I'm going to have to
write a custom kernel at some point
write a custom kernel at some point
right I actually have not done that
right I actually have not done that
before I have not had to write custom
before I have not had to write custom
GPU kernels I've done you know I've done
GPU kernels I've done you know I've done
lowlevel CPU stuff but not
lowlevel CPU stuff but not
GPU I could do that
GPU I could do that
though I mean it's probably nowhere near
though I mean it's probably nowhere near
as bad now that I've been doing all this
as bad now that I've been doing all this
C it's probably going to be relatively
easy technically it's pretty easy Once
easy technically it's pretty easy Once
you write it as well cuz it just Cuda
you write it as well cuz it just Cuda
you can bind it to anything else right
you can bind it to anything else right
so I can have it Bound for p torch and
so I can have it Bound for p torch and
then if I need it in another framework I
then if I need it in another framework I
can use the same
thing so that's
nice com layers still learn well on
nice com layers still learn well on
sparse grids yep they can learn on
sparse grids yep they can learn on
sparse grids what they can't learn on is
sparse grids what they can't learn on is
if I were to just input this whole thing
if I were to just input this whole thing
into a con like 1 0 2 3 it can't learn
into a con like 1 0 2 3 it can't learn
that because the con it's going to treat
that because the con it's going to treat
each of those values as continuous right
each of those values as continuous right
so these are discret values not
so these are discret values not
continuous values right one corresponds
continuous values right one corresponds
to something completely different from
to something completely different from
two like one is not any closer to two
two like one is not any closer to two
than it is to three in this space so
than it is to three in this space so
conv is going to be bad for that which
conv is going to be bad for that which
is why you have to one hot it like
this now technically you don't have to
this now technically you don't have to
one hot it right there other encodings
one hot it right there other encodings
you could use like for instance I drew
you could use like for instance I drew
these in color right I could have unique
these in color right I could have unique
colors for every different type of
colors for every different type of
entity here and then I could just use a
entity here and then I could just use a
fix three channels and RGB it or I could
fix three channels and RGB it or I could
come up with any number of other
come up with any number of other
different embeddings right I can use a
different embeddings right I can use a
fixed embedding instead of a learned
fixed embedding instead of a learned
embedding which you'd think like well
embedding which you'd think like well
isn't a learned embedding always going
isn't a learned embedding always going
to be better yeah technically it is
to be better yeah technically it is
possible to always get a better learned
possible to always get a better learned
one but you save on memory and therefore
one but you save on memory and therefore
you can save on
you can save on
performance by doing it this
way I mean this whole thing started just
way I mean this whole thing started just
because
because
like one the networks are not performing
like one the networks are not performing
fast enough right now in uh in pytorch
fast enough right now in uh in pytorch
they need to be about twice as fast as
they need to be about twice as fast as
they are now in order to match like the
they are now in order to match like the
snaket
snaket
performance and
performance and
two is that I don't want to have to
two is that I don't want to have to
implement all this one off stuff and
implement all this one off stuff and
see if it's going to be like if I'm
see if it's going to be like if I'm
going to just be changing
it I want have to implement all this
it I want have to implement all this
oneoff stuff and see if I'm just going
oneoff stuff and see if I'm just going
to be changing it
right like what's the simplest thing I
right like what's the simplest thing I
can do for now what is the simplest
can do for now what is the simplest
thing I can do and I'm trying to I'm
thing I can do and I'm trying to I'm
always thinking about it that way and
always thinking about it that way and
there's like sometimes there's just not
there's like sometimes there's just not
a simple thing to
do I mean I could just like try to
do I mean I could just like try to
implement all these same concatenate and
implement all these same concatenate and
split in whatever operations that I have
split in whatever operations that I have
in py torch and c and I could just like
in py torch and c and I could just like
do it that way but that's not great
do it that way but that's not great
that's just bringing all the Jank from
that's just bringing all the Jank from
pytorch into
pytorch into
C e
[Music]
it's funny because like this is also
it's funny because like this is also
like this is exactly the problem that
like this is exactly the problem that
puffer lib kind of solves
puffer lib kind of solves
right like we technically have we have
right like we technically have we have
offthe shelf solutions to all of this
offthe shelf solutions to all of this
and like if you're a company doing
and like if you're a company doing
RL and you're like using stable
RL and you're like using stable
baselines or whatever yeah puffer is
baselines or whatever yeah puffer is
going to be more than 10 times faster
going to be more than 10 times faster
just for free and it'll be easier but
just for free and it'll be easier but
like what I'm doing now is like I'm
like what I'm doing now is like I'm
essentially this is the next version
essentially this is the next version
right I'm trying to solve this problem
right I'm trying to solve this problem
in a way that's just so much
in a way that's just so much
fundamentally
fundamentally
faster that just never going to
faster that just never going to
bottleneck you no matter what
that's hard that is
that's hard that is
hard
um if let me go let me look down uh one
um if let me go let me look down uh one
one more Rabbit
one more Rabbit
Hole so if I were to
Hole so if I were to
commit to entity based
commit to entity based
data if I were were to commit to entity
data if I were were to commit to entity
based
data entity based
data looks like this now
right so we had like the X's before
right so we had like the X's before
right so you have one here you have one
right so you have one here you have one
here you have like your what was this no
here you have like your what was this no
I forget what this was O
I forget what this was O
oh yeah and I forget the exact number
oh yeah and I forget the exact number
that we had before but like the idea is
that we had before but like the idea is
that
that
like you have like the observations for
like you have like the observations for
your different
your different
shapes and then you just put them all
shapes and then you just put them all
into a struct so they have the same
shapes this is very easy to
code it's outside of very Niche
code it's outside of very Niche
circumstances it's incredibly efficient
and
and
then then this type of thing would be at
then then this type of thing would be at
least easier to write an encoder for
right yeah CU I wouldn't have to deal
right yeah CU I wouldn't have to deal
with the additional structured
with the additional structured
format I would be able to write an
format I would be able to write an
encoder for this much much more easily
encoder for this much much more easily
and that would be fully General I could
and that would be fully General I could
use that encoder
use that encoder
anywhere how much less data would this
anywhere how much less data would this
be
quite substantially less
quite substantially less
right order of magnitude
right order of magnitude
maybe at least 80% less
data if it were 80% less
data if it were 80% less
data I could probably get away with a
data I could probably get away with a
bite for each Channel instead of having
bite for each Channel instead of having
to do anything fancier
um observation en coding function gets a
um observation en coding function gets a
little more
little more
complicated I mean the observation
complicated I mean the observation
computation function but it's not that
computation function but it's not that
bad I
think yeah it's not that that
think yeah it's not that that
bad not contiguous memory anyways
there's potentially a distance
check or not I could just be fancy with
check or not I could just be fancy with
the
the
iteration that's actually very
iteration that's actually very
nice and then what's the network look
nice and then what's the network look
like if I had this type of data let's
like if I had this type of data let's
say that I get these vectors into
say that I get these vectors into
something that can go into a neural
something that can go into a neural
network then
I think it looks something like
um this just goes into a Transformer
um this just goes into a Transformer
doesn't
doesn't
it multi-headed
it multi-headed
detention or if you don't want to do
detention or if you don't want to do
multi-headed detention it can go into a
multi-headed detention it can go into a
Max function that's a fast
alternative so it can go wide and then
alternative so it can go wide and then
into a Max I've seen that done before
this is such a good representation isn't
this is such a good representation isn't
it okay I think what I'll commit to is
it okay I think what I'll commit to is
I'm going to say that uh in the
I'm going to say that uh in the
relatively near future I'm going to
relatively near future I'm going to
experiment with this type of
experiment with this type of
encoding and you know one of the really
encoding and you know one of the really
cool things about deving these high perf
cool things about deving these high perf
Sims is um I will be able to get
Sims is um I will be able to get
conclusive
conclusive
evidence on this type of a thing because
evidence on this type of a thing because
I just the Sims are so fast I can run
I just the Sims are so fast I can run
stuff for so
long I will be able to solve this
problem in the relatively near
problem in the relatively near
future so what do I do for
today I honestly think the easiest thing
today I honestly think the easiest thing
to do for today is to just write it
to do for today is to just write it
single purpose to neural uh not to
single purpose to neural uh not to
neural it's uh the single purpose to
neural it's uh the single purpose to
puffer
mooba we write it single purpose to
mooba we write it single purpose to
puffer
puffer
mooba and we just copy the operation
mooba and we just copy the operation
exactly as it
exactly as it
happens and we see what goes from
happens and we see what goes from
there it'll it'll still be a cool
there it'll it'll still be a cool
exercise and then I'll have to think
exercise and then I'll have to think
about
about
this I like that blog post by Clemens
this I like that blog post by Clemens
I should meet up with him I think he's
I should meet up with him I think he's
still an SF probably opening eyes
still an SF probably opening eyes
working him half to death getting uh gp5
working him half to death getting uh gp5
released or whatever
released or whatever
but he's doing
well
fun let's uh let's try that cuz I think
fun let's uh let's try that cuz I think
it's not that bad if I just do it C
right I think it's not that
bad net con one
bad net con one
input yeah so let's
do uh float what is it float
star load
star pre-processed
size of
float
oops now we actually get to start
oops now we actually get to start
writing some cool
writing some cool
code this goes at the top
so we
so we
do where's batch
size wait where's batch size oh numb
size wait where's batch size oh numb
agents yeah
agents yeah
okay let's just do numb agents
I forgot I had to do
I forgot I had to do
that so let's just write this uh
that so let's just write this uh
explicitly so what we're going to do is
explicitly so what we're going to do is
going to
going to
be we're going to go over the batch size
be we're going to go over the batch size
which is going to be the number of
which is going to be the number of
Agents we're only doing this for a
Agents we're only doing this for a
single environment and see there's no
single environment and see there's no
reason to do more than that and then
reason to do more than that and then
what we have to do
is the first 11 by 11 right
one
one
hun this the correct memory format I
hun this the correct memory format I
believe
believe
so 11 by
so 11 by
11 and we don't need this
11 and we don't need this
J we just need to
do there four input channels
so we one
so we one
hot so let's do in in
Adder bat size time 11 *
Adder bat size time 11 *
11 plus I
* not times
* not times
19 they're four input channels
again I should I always forget to sketch
again I should I always forget to sketch
this stuff so people can follow my
this stuff so people can follow my
convoluted thought
convoluted thought
process
process
um Let me let me sketch this out for you
um Let me let me sketch this out for you
guys real quick just so you can follow
guys real quick just so you can follow
my I'm going to do this once so that
my I'm going to do this once so that
people can follow this uh and actually
people can follow this uh and actually
learn something from this uh this
learn something from this uh this
exercise
exercise
so right now the input looks like
this okay this is
this okay this is
uh 11 by 11x 4 which means that in the
uh 11 by 11x 4 which means that in the
memory layout hold on let me
think yes so this is
think yes so this is
11 11 and this is going to be the uh
11 11 and this is going to be the uh
grid data this is
grid data this is
grid and then what we have
grid and then what we have
here had a step away definitely work on
here had a step away definitely work on
dope this week hey you know Nathan like
dope this week hey you know Nathan like
you swing by and let me know if I can
you swing by and let me know if I can
help you out okay I've been doing lots
help you out okay I've been doing lots
of stuff with this I've written so much
of stuff with this I've written so much
low-l code in the last few weeks I've I
low-l code in the last few weeks I've I
so let me put it this way the next
so let me put it this way the next
update to puffer lib is going to be
update to puffer lib is going to be
bigger than the current size of puffer
bigger than the current size of puffer
lib and it's like all this C environment
lib and it's like all this C environment
SIM code so we're going to have Ultra
SIM code so we're going to have Ultra
fast environments like literally like
fast environments like literally like
the MOBA is going to be 2,000 plus and
the MOBA is going to be 2,000 plus and
then the other environment I have looks
then the other environment I have looks
like it's going to be
like it's going to be
3,000 uh not to mention that we're going
3,000 uh not to mention that we're going
to Port like your y andoa Atari games
to Port like your y andoa Atari games
I'm going to help you guys Port those to
I'm going to help you guys Port those to
Native C so that we can have them on web
Native C so that we can have them on web
and of course you'll get the credits on
and of course you'll get the credits on
the website as
well if you want to contribute them that
well if you want to contribute them that
is
C makes it nope C doesn't make it any
C makes it nope C doesn't make it any
faster you're a okay to write in scon um
faster you're a okay to write in scon um
C is just for web
C is just for web
assembly so if it's easier for you to
assembly so if it's easier for you to
Dev in scon keep deving in scon I don't
Dev in scon keep deving in scon I don't
want to make your life any harder uh
want to make your life any harder uh
it's gotten to the point where for me
it's gotten to the point where for me
it's just as easy to write c as it is to
it's just as easy to write c as it is to
write cython uh and web assembly right
write cython uh and web assembly right
play
online plus where I'm like I'm writing
online plus where I'm like I'm writing
these networks and C so it's literally
these networks and C so it's literally
we can do inference online
we can do inference online
too okay let me let me finish my thought
too okay let me let me finish my thought
process though CU I was explaining how
process though CU I was explaining how
the encoder that I'm writing has to work
the encoder that I'm writing has to work
here so this is grid this is
here so this is grid this is
continuous data that's an n and then
continuous data that's an n and then
this is
extra and this is just 26 features so
extra and this is just 26 features so
what I have to
what I have to
do is I have this big block of memory
do is I have this big block of memory
that this is going to get written into
that this is going to get written into
um it has to be 11 by 11
by go
on do I have this
right ah linear memory layout is so
right ah linear memory layout is so
difficult to keep in your head
I think I have it
right because it goes
right because it goes
row and then it goes
row and then it goes
yeah okay this is not as bad as I
thought yeah this is not as bad as I
thought yeah this is not as bad as I
thought so here this 11 by1
thought so here this 11 by1
grid this is what's going to happen this
grid this is what's going to happen this
is going to become
is going to become
11 11 * 16
11 11 * 16
here and this is one
hot and then this gets
normed and then this is going to just
stay three and then this gets
stay three and then this gets
normed
normed
Norm I can't write and this goes here 26
Norm I can't write and this goes here 26
okay so this is what we're writing is
okay so this is what we're writing is
that we have to take this and do these
that we have to take this and do these
operations very
operations very
efficiently make
sense that actually did help me for once
sense that actually did help me for once
to think about what I wanted to do
to think about what I wanted to do
because now I actually know how this
because now I actually know how this
should work um because I I just this is
should work um because I I just this is
going to just be plus
going to just be plus
I out
I out
Adder 11 * 11 * 19
Adder 11 * 11 * 19
plus
plus
I uh now this one is I * 19
right uh except it's not 19 right is
right uh except it's not 19 right is
it * 11 *
it * 11 *
19 wait in
address plus 26 we'll make sure all
address plus 26 we'll make sure all
these numbers are not hardcoded you know
these numbers are not hardcoded you know
once I finish this plus 26 so this is
once I finish this plus 26 so this is
the size your ins size your out size
the size your ins size your out size
here right and then the out address does
have do the out address have things to
have do the out address have things to
worry
worry
about plus I * 19
it's 11 *
11 I
11 I
* 11 *
* 11 *
11 I
believe is it 19
believe is it 19
here I it is 19
here man it is hard to do this in your
here man it is hard to do this in your
head without messing this
up and then you
up and then you
do preprocessed of in
do preprocessed of in
address which
address which
is wait
is wait
what uh yeah net
what uh yeah net
pre-processed net pre-processed out
pre-processed net pre-processed out
address
no out would
address
address
wait
equals
equals
one
one
Adder input
right this is your one hot
address out address plus one hot
address out address plus one hot
Adder
Adder
one is this how it
works you have to clear your
works you have to clear your
pre-processed buffer
and then you set one
hot okay so if this is
hot okay so if this is
correct
then from here
wait
wait
four out address
four out address
plus and then you do
plus and then you do
net out
address why is this so
hard it's hard because of the way that
hard it's hard because of the way that
the layers are ordered it's difficult to
the layers are ordered it's difficult to
think
about I should make some tool that just
about I should make some tool that just
like you know takes all your memory and
like you know takes all your memory and
then like just colors it differently so
then like just colors it differently so
you can see where stuff
you can see where stuff
is that'd be really easy actually to do
wait wouldn't the easier
thing you know I've actually been
thing you know I've actually been
wondering
like maybe this is me being dumb but can
like maybe this is me being dumb but can
I just cast this to be like a 4D
I just cast this to be like a 4D
tensor and then just directly index
that should be the same
right well I still have to do the
right well I still have to do the
input but like the output address can I
input but like the output address can I
just cast this to be a 4D
tensor I think I can right
let me go find the Syntax for
that because I don't think that there is
that because I don't think that there is
a reason not to do it like
a reason not to do it like
this hold on I always forget the cast
this hold on I always forget the cast
intact this is a cool trick but uh I
intact this is a cool trick but uh I
always forget the syntax because it's
always forget the syntax because it's
very obnoxious
very obnoxious
syntax I did I not even use it in here
syntax I did I not even use it in here
once I know I used it in the Mobis
once I know I used it in the Mobis
source
code yeah right
here float star
here float star
preprocessed and then you get to you
preprocessed and then you get to you
just shave off the batch Dimension and
just shave off the batch Dimension and
then you do 11 by 11
by4 oh and it is an unsigned charar
by4 oh and it is an unsigned charar
isn't
it that was almost bad unsigned
it that was almost bad unsigned
Char
Char
and net
pre-processed no is float what am I
pre-processed no is float what am I
doing
float
float
that technically I can just do all of it
that technically I can just do all of it
this way can't
this way can't
I or
I or
no no the memory is not contiguous okay
no no the memory is not contiguous okay
I can still do this though so by doing
I can still do this though so by doing
this now I have
this now I have
11 by 11 it's not by four right it's
by oh no now I remember why I can't
by oh no now I remember why I can't
do this God damn
it cuz of the 26 at the end is the
it cuz of the 26 at the end is the
problem the 26 at the end is the
problem the 26 at the end is the
problem well hang on though I need two
problem well hang on though I need two
different tensors anyways don't
I I literally need two different tensors
anyways
so I can do
this
map so this is like OBS
2D OBS 1D like this right 1D 2D 2D 1
OBS
OBS
2D OBS 1D is going to
2D OBS 1D is going to
be
26 yeah so now what I can do is I can do
26 yeah so now what I can do is I can do
float star OBS 2D
and then this is going to be size
19 this net is going to be OBS 2D then
19 this net is going to be OBS 2D then
we do float OBS
we do float OBS
1D Now isn't that
1D Now isn't that
nice now we actually can index things
nice now we actually can index things
without going
without going
insane because I no longer need to care
insane because I no longer need to care
about this out address
about this out address
right I literally can just
right I literally can just
do bi I
do bi I
okay I need to do for J now instead I
okay I need to do for J now instead I
write an extra Loop but that's
write an extra Loop but that's
fine
fine
oops okay so we do
oops okay so we do
J whatever this is what tab tab we're
J whatever this is what tab tab we're
going to fix these addresses and then
going to fix these addresses and then
batch i
batch i
j and then this here is going to be like
j and then this here is going to be like
one
one
hot one
hot one
hot idx
hot idx
equal to
equal to
one and then all I have to do is figure
one and then all I have to do is figure
out the uh in
out the uh in
address which is going to be batch * 11
address which is going to be batch * 11
* 11 *
plus I
* hold
* hold
on I * 11 plus J I think this is correct
right
right
yeah and this is one hot
idx
almost this tells you the
almost this tells you the
value
Adder if only C had passed by reference
Adder if only C had passed by reference
the syntax so
the syntax so
clean pointers aren't bad took data
clean pointers aren't bad took data
struction 2012 the pointers actually are
struction 2012 the pointers actually are
not
not
bad
bad
um the one thing I really hated in C is
um the one thing I really hated in C is
the pass by value by
the pass by value by
default right now I just use pointers
default right now I just use pointers
everywhere I just use pointers
everywhere I just use pointers
everywhere and I I don't think I have a
everywhere and I I don't think I have a
single place in my code mode where I do
single place in my code mode where I do
like Star thing dot like I don't have I
like Star thing dot like I don't have I
don't have a single place where I'm ever
don't have a single place where I'm ever
like directly D referencing something
like directly D referencing something
ever right so once I realize that it's
ever right so once I realize that it's
actually not bad at all like when I make
actually not bad at all like when I make
strs my
strs my
strs well I guess for performance this
strs well I guess for performance this
is maybe a problem so I might actually
is maybe a problem so I might actually
have to revisit this but like I pretty
have to revisit this but like I pretty
much never will make a struct
much never will make a struct
uh that
uh that
contains a specific thing it'll contain
contains a specific thing it'll contain
a pointer to a
a pointer to a
thing that's actually kind of bad for
thing that's actually kind of bad for
perf now that I'm thinking about
it
yeah but not
really we'll be able to make it fast
really we'll be able to make it fast
either way
hi okay so here's your one
hot and then
then you got to do some more iterating
then you got to do some more iterating
don't
you I got to figure out how to copy the
you I got to figure out how to copy the
last
layers where this is laid out in
layers where this is laid out in
memory trying to think where I put this
memory trying to think where I put this
in the
loop
uh int back
off this is going to
be cuz we're going to need this anyways
actually this offset is
good so we'll just make this extra thing
good so we'll just make this extra thing
and then I think what we can do is
am I crazy or can I just do this OBS
2D so this is going to be 16 plus
well this is just wait
well this is just wait
16 and then this is going to be
16 and then this is going to be
input
no two
times three
they're four layers so
they're four layers so
it's four
yeah does this not just do it
and then at the very end you have to
do 11 plus yeah then you have to copy
do 11 plus yeah then you have to copy
the 1D
the 1D
data so I think that this does it and we
data so I think that this does it and we
have to add some uh we have to add some
have to add some uh we have to add some
stuff to this but I think that this is
stuff to this but I think that this is
it so I think that we just basically
it so I think that we just basically
basically obviously we have to clean
basically obviously we have to clean
this up obviously there a bunch of
this up obviously there a bunch of
hardcoded constants but in what is this
hardcoded constants but in what is this
like 10 15 lines of C I think we have
like 10 15 lines of C I think we have
this entire preprocessing mess done and
this entire preprocessing mess done and
done like Ultra efficiently without
done like Ultra efficiently without
doing any extra
copies now this is incredibly aor prone
copies now this is incredibly aor prone
it needs to be tested and all that
it needs to be tested and all that
but I mean if this works right it's is
solid so I think that what we do it's
solid so I think that what we do it's
this one is divide
this one is divide
by 25.0 F that's what we have on the
by 25.0 F that's what we have on the
right screen here divide by
right screen here divide by
255 and then these are also divide by
255 so that's the
255 so that's the
pre-processing fuel
pre-processing fuel
and then what we do is we can do con
2D this is going to be
2D this is going to be
net oops net
pre-processed
2D OBS 2D because you need the raw
2D OBS 2D because you need the raw
pointer for
this and then we do
this and then we do
reu con
reu con
output con
2D
2D
linear
linear
plat this is your whole
thing so right now we are
thing so right now we are
at
Latin and and
Latin and and
then flat is going to be
oops this net flat here is actually OBS
oops this net flat here is actually OBS
1D OBS
1D OBS
1D and then we have to do
1D and then we have to do
concat on dim
one oh we uh we copied this into the
one oh we uh we copied this into the
wrong Channel didn't we that's all
award but is it cat 1D hold
on yeah it is cat it's cat with him
on yeah it is cat it's cat with him
one map stack
[Music]
cat dim one
layer oh I see cuz it's preallocated
layer oh I see cuz it's preallocated
like this
so it's net OBS
so it's net OBS
1D which is not what we want this should
1D which is not what we want this should
be
net um to Output that flat output right
net um to Output that flat output right
like
like
this so these get
this so these get
stacked and then
and that's not map stack is it what's
and that's not map stack is it what's
the
concatenator that one
be
128 and 26 is
128 and 26 is
it no 3
too oh wait is this
too oh wait is this
actually um no it's CNN channels is
actually um no it's CNN channels is
32 this is 32
and then this is net
cat this is net
cat and
then what do we do from here
R I
think it's
think it's
PR oh it's
PR oh it's
reu it's reu PR reu
is there a thing for re with why is re a
is there a thing for re with why is re a
layer like
this ah because it has an output buffer
this ah because it has an output buffer
that's fine
okay so now we
do and then we
do and then we
do
linear and then we do Rel
and
then and then this gets lstm
right we have the lstm in here
thought we have a wrapper for
this yeah input here
and now we do
and now we do
lstm and then the decode
lstm and then the decode
right which is the discrete decode for
now linear net actor
value
function and then what is the multi-
discreete ARG Max multi
discreete I don't think that signature
discreete I don't think that signature
is right yeah argmax multi discreet just
is right yeah argmax multi discreet just
takes the
input
input
cre uh net
actor
actor
output okay and then that gives you your
actions forward
and this gives you
and this gives you
instar I
instar I
believe instar
forward you actually don't even need the
forward you actually don't even need the
value function but we'll leave it in
value function but we'll leave it in
there for
now that multi discreet
now that multi discreet
output so we're going to have to debug
output so we're going to have to debug
all this but um
this is the basic form of what we're
this is the basic form of what we're
going
for and yeah there's some housekeeping
for and yeah there's some housekeeping
and stuff but if you look at the code
and stuff but if you look at the code
it's not really any
it's not really any
longer I mean obviously like they use
longer I mean obviously like they use
the one hot and stuff here but there's
the one hot and stuff here but there's
like all this indexing mess it's really
like all this indexing mess it's really
not that much longer or more
not that much longer or more
ridiculous compared to the uh the torch
ridiculous compared to the uh the torch
code which I find kind of funny
holy he done pretty
well what on Earth are they doing
no
idea oh I've totally missed messages
idea oh I've totally missed messages
from them haven't I that's
from them haven't I that's
okay I got to finish this
okay I got to finish this
first got to get
first got to get
the the code really am I
right okay so let's see what is
right okay so let's see what is
potentially missing from this
potentially missing from this
if I think I have this remotely
correct well first of all we got to get
correct well first of all we got to get
the layers cleaned
the layers cleaned
up so we have
up so we have
net so we have con re
con you don't need a
flatten and then what do we do we do
linear flatten
linear flatten
conat dim one
conat dim one
cat and then you do reu FR
cat and then you do reu FR
reu and then you do
lstm like
lstm like
this we don't use one hot
this we don't use one hot
now so we'll ignore
now so we'll ignore
this so numb agents OBS 2D is going to
this so numb agents OBS 2D is going to
have 19
have 19
channels OBS 1D has
26 you do this Con 2D B
con
con
con
yeah
flat
flat
cat two P re accurate okay looks good to
me and then the one thing I know I
me and then the one thing I know I
definitely did wrong here is I have the
definitely did wrong here is I have the
channels in the wrong uh
channels in the wrong uh
order
order
so it's channels first right is that how
so it's channels first right is that how
I implemented
I implemented
it tell me that's how I implemented
it tell me that's how I implemented
it did I do channels last or channels
it did I do channels last or channels
first wait
yeah I did channels
first so this just needs to be one
first so this just needs to be one
hot man it's so nice to have this
hot man it's so nice to have this
indexing like
this this is 17
okay yeah that's
okay yeah that's
good so if I can clean this up a little
good so if I can clean this up a little
bit we have it's conu con
bit we have it's conu con
and there's the linear
and there's the linear
layer and then it's cat re linear
layer and then it's cat re linear
reu and there's the
lstm and then it's an actor value and
lstm and then it's an actor value and
then we have oh I need our multi-
then we have oh I need our multi-
discreet that's what I was
missing okay we got multi discreet and I
missing okay we got multi discreet and I
think it's a
think it's a
23 hi why do you have an lstm in your
23 hi why do you have an lstm in your
Moet and what is Moet
Moet and what is Moet
purpose so the purpose of it is to
run this
run this
environment these guys don't move at the
environment these guys don't move at the
moment they need to be uh they need
moment they need to be uh they need
their policies and the policies are
their policies and the policies are
trained with a con and an
trained with a con and an
lstm so if I want them to actually be
lstm so if I want them to actually be
able to play this game and do cool stuff
able to play this game and do cool stuff
then uh yeah we need to actually get
then uh yeah we need to actually get
this running and now it does work in
this running and now it does work in
pytorch but uh in order to run this
pytorch but uh in order to run this
online we want to have like a little C
online we want to have like a little C
only
only
demo so that's what we're doing at the
moment this is somewhat more complicated
moment this is somewhat more complicated
than I expected it would be but
than I expected it would be but
hopefully not that
hopefully not that
bad we'll see how bad it is to
debug we'll see how bad it is to
debug we'll see how bad it is to
debug the only thing I'm missing is
debug the only thing I'm missing is
loading this loading the weights here so
loading this loading the weights here so
why don't we
why don't we
um step
and let's do MOA
and let's do MOA
net do I need do I have all this
stuff literally I don't need any of this
stuff literally I don't need any of this
right it's num creeps num
right it's num creeps num
neutrals literally the only thing I need
neutrals literally the only thing I need
here is num agents I don't know why it
here is num agents I don't know why it
did all this autocomplete on the
did all this autocomplete on the
signature
yeah so num
yeah so num
agents we end it in mobet Num
agents we end it in mobet Num
agents then this will be free
mobet
mobet
and then I have to do forward
right where's
right where's
obs uh I need n it's like n OBS or
something oops
something oops
it's
m.h
OBS oh do I literally have these storage
OBS oh do I literally have these storage
separately I literally have these stored
separately I literally have these stored
separately don't I N observations map
separately don't I N observations map
and observations extra
and observations extra
that's super
nice and is it unsign
nice and is it unsign
charar I believe it
charar I believe it
is
charar 2
charar 2
D Bobs One
D Bobs One
D D D
D D D
zero and then
zero and then
float this does not need to have OBS 2D
float this does not need to have OBS 2D
like
this does
this does
it uh oh no it
it uh oh no it
does it
does so this right
does so this right
here input this is n OBS
here input this is n OBS
2D 2D
3D OBS
3D OBS
1D
1D
cool now you can pass
cool now you can pass
this and then you can
this and then you can
do oh
welcome and then this is now forward
welcome and then this is now forward
this is net this is
this is net this is
n
OBS is this what they were
OBS is this what they were
named
named
view no it's observations map and
view no it's observations map and
observations
extra there we go so now we have these
extra there we go so now we have these
forward functions right
and uh is there
and uh is there
a do I have to write these into the
a do I have to write these into the
environment
environment
actions I think I do have to write this
actions I think I do have to write this
into the actions buffer so let's do
into the actions buffer so let's do
that then this has to
that then this has to
be instar
actions ARG Max multi-
discreet well maybe I'll just copy
them for
them for
now we'll just copy him from uh
now we'll just copy him from uh
here
copy test going to
be yeah now this is going to give me
be yeah now this is going to give me
garbage I don't really want to do a raw
garbage I don't really want to do a raw
M Copy
there I know what I can do
so instead of giving this an
output let's just comment
output let's just comment
this for
this for
now and what we'll
now and what we'll
do we'll do inst star output
do we'll do inst star output
okay uh nope you don't don't need to
okay uh nope you don't don't need to
free it wrong one do against star
free it wrong one do against star
output argmax and instead of layer
output argmax and instead of layer
output this will just be
output this will just be
output right and now what I can
output right and now what I can
do is when we init the melti discreete
do is when we init the melti discreete
here we go to use
it this will be
it this will be
actions
actions this becomes
void this gives you inar actions
and now all I have to
and now all I have to
do is now uh this will write directly
do is now uh this will write directly
into my buffer into the actions buffer
into my buffer into the actions buffer
and then you can step the environment
and then you can step the environment
you can render your
you can render your
game and you're good to
game and you're good to
go now we have to fix all this and get
go now we have to fix all this and get
it to
it to
work let me make sure I'm not missing
work let me make sure I'm not missing
anything important
anything important
here uh hold on
H people are saying my puffer boxes are
H people are saying my puffer boxes are
down let me go check the puffer
boxes that would be
boxes that would be
unfortunate I have this like mini
unfortunate I have this like mini
cluster for
cluster for
uh for puffer but uh it's like literally
uh for puffer but uh it's like literally
in the
garage uh well none of them came
garage uh well none of them came
back
up that's
bad that's real
bad that kind of throws a wrench in
bad that kind of throws a wrench in
everything now doesn't
it I'll have to deal with that
later for
well let's start testing this at least
okay
uh let's figure out what's wrong here
incompatible what
okay multi
okay multi
discreete come on this shouldn't be that
discreete come on this shouldn't be that
long to
long to
debug wake up
here where's
the arc Max multi discreet
one warnings two
one warnings two
errors no member name
reprocessed one
H so somehow
it's make not a
net I use make when I return the struck
net I use make when I return the struck
and a knit when I give it the struck
okay make
relu batch size input
dim uh what is this
three 32 * 3 *
3 three
maybe and then this one
maybe and then this one
here
here
32 28
make multi this is make argmax multi-
discreete what in the
discreete what in the
hell Auto completes
man in logic
sizes um hold
sizes um hold
on int logic sizes
yeah that's
fine batch size logic
fine batch size logic
size
actions this and I need to I need to
actions this and I need to I need to
actually get this
from where is
from where is
it actually what am I doing
here I have the sizes
here 7 seven okay here it is so in logic
here 7 seven okay here it is so in logic
sizes of
six 7 7 and now this is on the stack but
six 7 7 and now this is on the stack but
the thing is it gets copied to here so
the thing is it gets copied to here so
we have it done very
we have it done very
nicely and then did I get to 23 right
nicely and then did I get to 23 right
this is 14
this is 14
17 23 yeah
perfect and then this is going to be
perfect and then this is going to be
logic sizes
like
this oh and then the number of actions
um this is seven this or this is six
um this is seven this or this is six
right you have to give it the six
Max is there an
Max is there an
underscore I think there probably is
right
right
okay five we allocated this the wrong
okay five we allocated this the wrong
way this needs to be 19
like
so
compiles and and we get a SE B of
course right here
okay so we have the one hot index
here
255 so 255 is not a valid one hot index
255 so 255 is not a valid one hot index
um yep that'll do it
so either the data is wrong or the
so either the data is wrong or the
offsets are wrong and either could be
offsets are wrong and either could be
the case because we haven't tested the
the case because we haven't tested the
we have not aggressively enough tested
we have not aggressively enough tested
the compute observations function since
the compute observations function since
we changed
stuff
for e
wait a
wait a
second bat offsets
wrong yeah cuz the input's four chance
okay bch
offset yeah know this batch offsets
offset yeah know this batch offsets
wrong
this is simply uh 26 time or B
this is simply uh 26 time or B
* 26 + I
still wrong
huh are you sure about
that
yeah batch offset looks
yeah batch offset looks
good element offset is
also
good what about the 2D
good what about the 2D
one
19 11 by yeah the issue is that 255 in
there that should not be able to be
there that should not be able to be
255 somehow that's a Max
255 somehow that's a Max
bite I
bite I
wonder hold on a
second now it is an unsigned
Char 11 by 11 by4 the bat
size you're not zeroing the map right
size you're not zeroing the map right
now
now
which is probably really
bad
bad
zero I less than
plus extra zero
yeah same
yeah same
memory it's
memory it's
fine okay so
now okay so now we should be

Kind: captions
Language: en
okay we should be
okay we should be
live
hello got lots of stuff to do
today timeline is a
today timeline is a
mess all
mess all
right let's um let's get some stuff done
right let's um let's get some stuff done
we have a lot of interesting things to
we have a lot of interesting things to
do today
do today
so let me go over just for a moment what
so let me go over just for a moment what
I've been working on
I've been working on
and uh some of my plans going forward so
and uh some of my plans going forward so
uh as I said before on
stream as a company puffers officially
stream as a company puffers officially
open for
open for
business uh all that means is that you
business uh all that means is that you
know I'm going to be spending a little
know I'm going to be spending a little
of my time looking for and hopefully uh
of my time looking for and hopefully uh
acquiring and doing some work for some
acquiring and doing some work for some
clients uh but everything's open source
clients uh but everything's open source
I'm still going to be streaming lots of
I'm still going to be streaming lots of
Dev and I've got lots of cool stuff
Dev and I've got lots of cool stuff
coming for everyone as
coming for everyone as
well speaking of
which we have these
which we have these
two games right now right you can play
two games right now right you can play
snake in your browser these snakes are
snake in your browser these snakes are
kind of dumb but they are running
kind of dumb but they are running
reinforcement learned policies in your
reinforcement learned policies in your
browser which is pretty cool and then we
browser which is pretty cool and then we
have this which we don't have the RL
have this which we don't have the RL
policies in here yet right but we have
policies in here yet right but we have
this this mobile game that runs in your
this this mobile game that runs in your
browser you know and it plays reasonably
browser you know and it plays reasonably
well maybe we have a few bugs to fix in
well maybe we have a few bugs to fix in
it since this is a new Port since we had
it since this is a new Port since we had
to Port it in order to get it to run
to Port it in order to get it to run
like
this company page no longer
this company page no longer
secret
secret
um but what I want to really really
um but what I want to really really
build out over the next week or so so as
build out over the next week or so so as
I said I've had one more big simulator
I said I've had one more big simulator
that's in the works it's going to take
that's in the works it's going to take
me a little longer to finish that I
me a little longer to finish that I
ported 2,000 lines of stuff to see over
ported 2,000 lines of stuff to see over
Saturday how are you running inference
Saturday how are you running inference
on web Onyx web runtime ho ho ho no no
on web Onyx web runtime ho ho ho no no
no no no Onyx web we don't need any of
no no no Onyx web we don't need any of
that where we're going my friend let me
that where we're going my friend let me
show
show
you that's actually what we're going to
you that's actually what we're going to
be working on today is improving that
snake
snake what is it snake.
h pure C
h pure C
implementation of the neural net and we
implementation of the neural net and we
load the weights from P
load the weights from P
torch that's what we're
torch that's what we're
doing so now this is not very impressive
doing so now this is not very impressive
on its own right it's kind of cool that
on its own right it's kind of cool that
you can do this but it's just an MLP now
you can do this but it's just an MLP now
the thing that I'm working on now which
the thing that I'm working on now which
is what we're going to be doing today
okay oops wrong
okay oops wrong
one puffer
net takes my hands a little bit to warm
net takes my hands a little bit to warm
up
up
typing we have linear layers comms lstm
typing we have linear layers comms lstm
and a few other utility functions all in
and a few other utility functions all in
pure C so we're actually going to be
pure C so we're actually going to be
able to upgrade our web AI uh to be able
able to upgrade our web AI uh to be able
to run pretty reasonably sophisticated
to run pretty reasonably sophisticated
Networks
Networks
so the goal is going to be to finish
so the goal is going to be to finish
this puffer net thing get it running the
this puffer net thing get it running the
MOBA Network get it running the much
MOBA Network get it running the much
better snake Network and then the
better snake Network and then the
network for the secret project as
network for the secret project as
well and if we can do all of
well and if we can do all of
that then we'll have some pretty crazy
that then we'll have some pretty crazy
demos that will just run in your
demos that will just run in your
browser I think that'd be pretty
browser I think that'd be pretty
cool also um folks if you have not
cool also um folks if you have not
started the
started the
repository we are two stars off of
repository we are two stars off of
1K it's all free and open source right
1K it's all free and open source right
here so if you want to help me out get
here so if you want to help me out get
us to a th000 today that would be
us to a th000 today that would be
awesome I really didn't know if we were
awesome I really didn't know if we were
going to be able to hit this over the
going to be able to hit this over the
summer this is crazy the amount of
summer this is crazy the amount of
growth and I appreciate all the support
growth and I appreciate all the support
on this as well it helps to get the uh
on this as well it helps to get the uh
the word out about this so that puffer
the word out about this so that puffer
can get a little bit of Revenue and uh
can get a little bit of Revenue and uh
hopefully we can do some good work for
hopefully we can do some good work for
some
some
companies and we can start investing
companies and we can start investing
more in our own infrastructure I'd
more in our own infrastructure I'd
really like to start upgrading the
really like to start upgrading the
puffer cluster and start uh putting up
puffer cluster and start uh putting up
some bounties for you know open source
some bounties for you know open source
contributors contributors as
contributors contributors as
well 1K 100 is awesome 10K
well 1K 100 is awesome 10K
next I mean maybe I don't know if there
next I mean maybe I don't know if there
is an RL repo like an RL Library type
is an RL repo like an RL Library type
thing with 10K on it
but that's enough yapping for now I
but that's enough yapping for now I
should
uh interesting okay uh I should actually
uh interesting okay uh I should actually
start working on some of this stuff so
start working on some of this stuff so
you can see what's going
on I can't
type whoops
it's Monday this is what I get for
it's Monday this is what I get for
taking a half day off for once
taking a half day off for once
yesterday I needed a little bit of a
break all right so we go to perer
lib ocean porch okay so this is the
lib ocean porch okay so this is the
network that we need to Port today it's
network that we need to Port today it's
a little bit of cuz this network is a
a little bit of cuz this network is a
lot more complicated than I originally
lot more complicated than I originally
thought know this is a pretty
thought know this is a pretty
complicated thing
here um but we're going to see what I
here um but we're going to see what I
can get done on it
we have
puffet and then we have this network
puffet and then we have this network
that I started working on
that I started working on
here and I think that the big issue if I
here and I think that the big issue if I
recall was just the
data they're getting the data into a
data they're getting the data into a
reasonable format
right I think I figured out a workaround
right I think I figured out a workaround
though I I think I figured out a good
though I I think I figured out a good
workaround so
workaround so
um CNN
um CNN
features yeah so the way we're going to
features yeah so the way we're going to
we're going to cheat this a little bit
we're going to cheat this a little bit
obviously these are all
obviously these are all
hardcoded but what I'm going to do is
hardcoded but what I'm going to do is
plus three and this is
plus three and this is
cheat um continuous
features at the end
and then I need to do a little bit of
and then I need to do a little bit of
custom logic here I
custom logic here I
believe because we
take o that's harder than I thought
take o that's harder than I thought
actually now that I'm looking at
it I wouldn't mind just doing this
it I wouldn't mind just doing this
completely custom for right now because
completely custom for right now because
if I just do it completely custom I'm
if I just do it completely custom I'm
going to get something that's pretty
going to get something that's pretty
simple I would
simple I would
think it's going to be a little trickier
think it's going to be a little trickier
to test
it so let me explain what's going on
it so let me explain what's going on
through my head here
through my head here
um how's your weekend weekend's going
um how's your weekend weekend's going
good weekend went
good weekend went
well I should be a little bit more
well I should be a little bit more
rested then I uh I appear at the moment
rested then I uh I appear at the moment
I'm like all messed up just need my
I'm like all messed up just need my
coffee
but I did get some rest so as soon as I
but I did get some rest so as soon as I
warm up here I should be uh cranking
warm up here I should be uh cranking
some good
some good
stuff let me explain a little bit of
stuff let me explain a little bit of
what's going through my head here and
what's going through my head here and
why this is actually kind of difficult
why this is actually kind of difficult
so essentially in pytorch you have this
so essentially in pytorch you have this
slice operation here right where I can
slice operation here right where I can
slice tensors along various dimensions
slice tensors along various dimensions
and it makes it very easy
and it makes it very easy
um now I'd have to double check this
um now I'd have to double check this
because it's it's possible they have
because it's it's possible they have
some operations but what you have to
some operations but what you have to
understand is that um if you're slicing
understand is that um if you're slicing
anything except the First
anything except the First
Dimension depending on the memory format
Dimension depending on the memory format
but usually depending hey
but usually depending hey
welcome uh usually if you slice anything
welcome uh usually if you slice anything
except the First Dimension you're
except the First Dimension you're
actually going to incur a copy of the
actually going to incur a copy of the
data and you actually have to do some
data and you actually have to do some
complicated operations behind the scene
complicated operations behind the scene
in order to copy the data along the
in order to copy the data along the
specific Dimension that you want now I
specific Dimension that you want now I
could Implement that similar slice logic
could Implement that similar slice logic
in C and maybe it would be even a good
in C and maybe it would be even a good
idea to do that but at the same time
idea to do that but at the same time
this is kind of an opportunity for me to
this is kind of an opportunity for me to
rethink a little bit how I'm making
rethink a little bit how I'm making
these networks because this is slow
these networks because this is slow
right this is really slow
right this is really slow
um and ideally what we should be able to
um and ideally what we should be able to
do here is rewrite this network a little
do here is rewrite this network a little
bit to just be faster and not to have
bit to just be faster and not to have
these copy op operations which would
these copy op operations which would
then make the C code a little bit
simpler so I'm trying to decide if I
simpler so I'm trying to decide if I
want to like mess
want to like mess
with the puffer lib Network code first
with the puffer lib Network code first
or if I want to mess with the c
or if I want to mess with the c
code or how I want to do
code or how I want to do
this because the more I look at this
this because the more I look at this
right the less I like it
right the less I like it
like the observations are stored as flat
like the observations are stored as flat
data
data
so this last these last 26 elements here
so this last these last 26 elements here
this gets your memory to be
this gets your memory to be
non-contiguous so right here this is a
non-contiguous so right here this is a
copy this view is fine and
then one hotting so this is at
then one hotting so this is at
least right here this is a copy and then
least right here this is a copy and then
this is another
this is another
copy and then this is a copy like you
copy and then this is a copy like you
can see we're just copying the data all
can see we're just copying the data all
over the place
that's a big
that's a big
problem that's a very big
problem that's a very big
problem the thing that's tricky about
problem the thing that's tricky about
this is that there's pretty much always
this is that there's pretty much always
a way to do it where you're not going to
a way to do it where you're not going to
be copying all the data all over the
be copying all the data all over the
place um but it's almost always going to
place um but it's almost always going to
write uh require you to write like
write uh require you to write like
custom
custom
kernels which I know how to do in
kernels which I know how to do in
C I don't know the I
C I don't know the I
wouldn't I mean I could look at doing my
wouldn't I mean I could look at doing my
own Cuda konel for this I'd rather not
own Cuda konel for this I'd rather not
have to do
have to do
that but um
yeah I really do want this network to be
efficient I'm trying to think how
yeah like there's no way that that's
yeah like there's no way that that's
contiguous
right it's actually funny because now
right it's actually funny because now
that I'm looking at this I know how to
that I'm looking at this I know how to
do it in C I don't know how to know I
do it in C I don't know how to know I
don't even know how to do it in P torch
you need to be able to write
Loops
right I was thinking about over the
right I was thinking about over the
weekend as well whether it's actually
weekend as well whether it's actually
possible to uh come up with just a more
possible to uh come up with just a more
efficient Network design so I don't have
efficient Network design so I don't have
to do all of this but that seems
to do all of this but that seems
unlikely to
unlikely to
me because like you're pretty much the
me because like you're pretty much the
reason that the data looks like this is
reason that the data looks like this is
that I'm going to bring up since I see
that I'm going to bring up since I see
we have people joining here let me uh
we have people joining here let me uh
let me just bring up the diagrams here
let me just bring up the diagrams here
let me just write this out real quick so
let me just write this out real quick so
you can understand the problem and maybe
you can understand the problem and maybe
this will get me to uh understand a
this will get me to uh understand a
little
little
better
better
online let me show you what uh what the
online let me show you what uh what the
problem is
problem is
here oh okay perfect it saved our image
here oh okay perfect it saved our image
so if you look at this as being like a
so if you look at this as being like a
2d block of memory where like
um if you look at this as a 2d block of
um if you look at this as a 2d block of
memory where like this way is the
memory where like this way is the
columns right and this is your batch
columns right and this is your batch
size so this like first row here is your
size so this like first row here is your
first
first
observation then what ends up happening
observation then what ends up happening
is like we have in this data this last
is like we have in this data this last
chunk right here is going to be equal to
chunk right here is going to be equal to
extra data which is data that is
extra data which is data that is
gathered uh from your specific agent
gathered uh from your specific agent
right so it's like hidden stuff that
right so it's like hidden stuff that
your agent knows about itself the other
your agent knows about itself the other
agents don't know about it you're pretty
agents don't know about it you're pretty
much always going to need some data of
much always going to need some data of
that type and then what this chunk is at
that type and then what this chunk is at
the start is uh local 2D map data which
the start is uh local 2D map data which
is data that is the agent can see from
is data that is the agent can see from
nearby right and I specifically I have
nearby right and I specifically I have
two different types of data in there we
two different types of data in there we
can kind of ignore that as n mentation
can kind of ignore that as n mentation
detail for now uh but technically there
detail for now uh but technically there
are two different types of this data in
are two different types of this data in
these blocks now the problem is this is
these blocks now the problem is this is
not how contiguous memory works right
not how contiguous memory works right
this is contiguous this chunk here is
this is contiguous this chunk here is
not so if I want to split these out I
not so if I want to split these out I
have to do a copy of the
have to do a copy of the
data and then you know whatever I do
data and then you know whatever I do
with
with
it depending on how I do that can incur
it depending on how I do that can incur
additional
additional
copies um and we have this long
copies um and we have this long
pre-processing process where eventually
pre-processing process where eventually
we just want to convert all this data
we just want to convert all this data
into a nice contiguous block
into a nice contiguous block
and the issue is that like I know how to
and the issue is that like I know how to
do this if I'm going to write custom
do this if I'm going to write custom
Loops for everything I know how to do
Loops for everything I know how to do
that um so I can do that in C and make
that um so I can do that in C and make
sure that the web networks are
sure that the web networks are
reasonably efficient but then the P
reasonably efficient but then the P
torch networks which are more important
torch networks which are more important
that they be fast are
that they be fast are
harder can you help me I want to
harder can you help me I want to
implement RL for simulation RL with some
implement RL for simulation RL with some
pre-train model and use the knowledge to
pre-train model and use the knowledge to
explore similar to
explore similar to
humans that is hard
humans that is hard
uh all PO
uh all PO
is it depends what simulation like are
is it depends what simulation like are
you building a simulation for this are
you building a simulation for this are
you using an existing one it depends
you using an existing one it depends
what you're doing
here
uh well I think that the the most
uh well I think that the the most
practical way of doing this assuming
practical way of doing this assuming
that I don't want to start writing my
that I don't want to start writing my
own custom kernels for networks just yet
own custom kernels for networks just yet
that seems a bit
that seems a bit
Overkill is going to be to look at the
Overkill is going to be to look at the
design of this P torch Network and see
design of this P torch Network and see
where I can cut out some of these copies
potentially
so I have to just confirm
slicing creates a view
right tensor
views do they actually have some
views do they actually have some
efficient stuff on this
uh okay I
uh okay I
see
see
so maybe I don't have to worry too much
so maybe I don't have to worry too much
about this where should I look for that
about this where should I look for that
um I mean neural MMO is kind of one it's
um I mean neural MMO is kind of one it's
a more complicated environment you can
a more complicated environment you can
look at like if you want inspiration for
look at like if you want inspiration for
stuff you can look at works like
stuff you can look at works like
xland
xland
um I'm trying to think of other ones
um I'm trying to think of other ones
people did like this xland minig grid
people did like this xland minig grid
thing that's like not really all that
thing that's like not really all that
complicated but it's has some of those
complicated but it's has some of those
properties um new Solutions in
properties um new Solutions in
simulation similar to humans I mean that
simulation similar to humans I mean that
kind of
kind of
happens if you run it for long enough
happens if you run it for long enough
though typically if you want it to keep
though typically if you want it to keep
exploring and keep developing new things
exploring and keep developing new things
it needs to be able to update its model
it needs to be able to update its model
because like RL models don't have we
because like RL models don't have we
don't have amazing methods of memory at
don't have amazing methods of memory at
the moment so like you kind of need to
the moment so like you kind of need to
keep
keep
learning right so if you think about it
learning right so if you think about it
like the thing that's similar to humans
like the thing that's similar to humans
is actually kind of just doing online RL
is actually kind of just doing online RL
in the first place right like humans
in the first place right like humans
aren't fixed we're allowed to learn so
aren't fixed we're allowed to learn so
it's like the more realistic thing if
it's like the more realistic thing if
you want to look at it that way is to
you want to look at it that way is to
just keep training and look for stuff
just keep training and look for stuff
where it can keep finding new Solutions
where it can keep finding new Solutions
which is the definition of
open-endedness so it does look like
open-endedness so it does look like
pytorch has some operations
pytorch has some operations
here
uh outputs are unne avoid unnecessary
uh outputs are unne avoid unnecessary
data okay
yeah this is very odd because you
yeah this is very odd because you
actually I can't tell
here this is interesting that they say
here this is interesting that they say
their split operation does not like
their split operation does not like
their split operations don't actually um
their split operations don't actually um
affect memory they don't actually
copy but I think that as soon as you go
copy but I think that as soon as you go
to do anything with that data right of
to do anything with that data right of
course it has to copy it
anyway
anyway
so let's say that I split
so let's say that I split
this and then I one hot it
split view
split view
split one
split one
hun that's so freaking complicated
though really don't like
that you know I really want to be able
that you know I really want to be able
to
to
have an architecture here that isn't
have an architecture here that isn't
like this crazy Beast of a thing to
like this crazy Beast of a thing to
optimize
and this is adding complexity complexity
and this is adding complexity complexity
to stuff I guess technically there is
to stuff I guess technically there is
another format I can consider though I
another format I can consider though I
don't know if it makes it any
don't know if it makes it any
easier I guess it kind of makes it
easier I guess it kind of makes it
easier in the sense that like if I
easier in the sense that like if I
commit to this type of an architecture
commit to this type of an architecture
then I only ever have one thing to
then I only ever have one thing to
optimize but I don't know if the
optimize but I don't know if the
architecture itself is very good um if
architecture itself is very good um if
you commit to either having everything
you commit to either having everything
be discrete or discretizing everything
be discrete or discretizing everything
so that like each type of observation
so that like each type of observation
you have is discrete in some way
you have is discrete in some way
then you can pack everything into an
then you can pack everything into an
integer I don't know if that's
integer I don't know if that's
better I should probably also make this
better I should probably also make this
in view can we use the same network to
in view can we use the same network to
train on multiple different
train on multiple different
simulations build up some general
simulations build up some general
knowledge
knowledge
so the general rule on that is you can
so the general rule on that is you can
probably train on different simulations
probably train on different simulations
but only if you have a lot of different
but only if you have a lot of different
simulations if you have like n equals 2
simulations if you have like n equals 2
simulations that's very difficult to do
simulations that's very difficult to do
generally like when you want to learn
generally like when you want to learn
when you want to learn General patterns
when you want to learn General patterns
you need a lot of different type of data
you need a lot of different type of data
and we're mostly missing the we're
and we're mostly missing the we're
missing simulations to do that the
missing simulations to do that the
easiest way at the moment is to train
easiest way at the moment is to train
within like one big simulator that has
within like one big simulator that has
lots of different tasks or lots of
lots of different tasks or lots of
different things you can do just a
different things you can do just a
beginner doing some important work talk
beginner doing some important work talk
about it later yeah sure it's uh yeah
about it later yeah sure it's uh yeah
let me get some of this stuff done I
let me get some of this stuff done I
will tell you you're trying to dive in
will tell you you're trying to dive in
at the deep end as a beginner like
at the deep end as a beginner like
you're going immediately from like
you're going immediately from like
you're going immediately to like The
you're going immediately to like The
Cutting Edge of RL in which we don't
Cutting Edge of RL in which we don't
know necessarily how stuff is working so
know necessarily how stuff is working so
that's not necessarily a bad thing but I
that's not necessarily a bad thing but I
would suggest that you try working like
would suggest that you try working like
you're going to have more fun working on
you're going to have more fun working on
areas where you can at least see some
areas where you can at least see some
consistent progress and work towards
consistent progress and work towards
that if you just try to do that one shot
that if you just try to do that one shot
right now you're going to end up with a
right now you're going to end up with a
lot of
difficulty it's a bit unfortunate how
difficulty it's a bit unfortunate how
stuck I am on this network
architecture like it seems so good in
architecture like it seems so good in
theory
I mean It's just tough to come up with
I mean It's just tough to come up with
like
like
good reusable Network architectures I
suppose like I guess the ideal one
suppose like I guess the ideal one
right the best way of doing stuff if you
right the best way of doing stuff if you
can get away with
can get away with
it is to just like have all your data be
it is to just like have all your data be
flat and then just do coms over it
that's not bad hold on let me think
that's not bad hold on let me think
about that let me think about
that
that
so the tricky portion with that is
so the tricky portion with that is
like your data can blow up quite a
lot maybe it will help me to try to if I
lot maybe it will help me to try to if I
explain this more thoroughly maybe I'll
explain this more thoroughly maybe I'll
get some ideas is and then folks can
get some ideas is and then folks can
actually learn some stuff in the process
actually learn some stuff in the process
let's do that so
um
okay okay so there are a couple
okay okay so there are a couple
different ways you can treat your
different ways you can treat your
data and encode
data and encode
data for Ultra highper reinforcement
data for Ultra highper reinforcement
learning
learning
right let's say that you have multiple
right let's say that you have multiple
different features
different features
like let's say that you have like an
like let's say that you have like an
agent has a type that can be zero 1 2
agent has a type that can be zero 1 2
3 and then maybe it has like
3 and then maybe it has like
HP which is like 0 to
HP which is like 0 to
100 and then maybe it has like some
100 and then maybe it has like some
other variables right like you know 0 to
five 0 to
five 0 to
10 and some of these might be discret
10 and some of these might be discret
some of them might be continuous
some of them might be continuous
so there are a few ways you can deal
so there are a few ways you can deal
with this the first and the easiest is
with this the first and the easiest is
you can just pack
you can just pack
everything into like multiple
channels so you just pack everything
channels so you just pack everything
like this what the heck is that yeah
like this what the heck is that yeah
there we go you just pack everything
there we go you just pack everything
like this and if we just like slice it
like this and if we just like slice it
this
this
way right then this one goes there this
way right then this one goes there this
one goes to here this one goes to here
one goes to here this one goes to here
right
right
that's one way of doing it now there are
that's one way of doing it now there are
some limitations with this first of
all this
all this
is discrete
is discrete
data it's not continuous so we don't
data it's not continuous so we don't
want to put it into one com Channel
want to put it into one com Channel
actually what this needs is
this needs a one hot
this needs a one hot
embedding right so you can do like one
embedding right so you can do like one
hot like
this this needs a one hot embedding so
this this needs a one hot embedding so
this block of data needs to become four
this block of data needs to become four
channels but then maybe HP doesn't need
channels but then maybe HP doesn't need
to become four channels right maybe you
to become four channels right maybe you
do want the continuous value of HP but
do want the continuous value of HP but
then that is difficult because now if
then that is difficult because now if
you want this to be continuous but this
you want this to be continuous but this
to be discrete so you have to normalize
to be discrete so you have to normalize
this which is kind of fine but now you
this which is kind of fine but now you
have to know which channels need to be
have to know which channels need to be
one hotted and which ones don't which is
one hotted and which ones don't which is
a bit
tricky there's also the question of how
tricky there's also the question of how
much we want to commit to a
much we want to commit to a
convolutional representation in the
convolutional representation in the
first place because like this makes
first place because like this makes
sense for the grid environments that I'm
sense for the grid environments that I'm
doing now so like if I wanted to right I
doing now so like if I wanted to right I
could invest a bunch of time and coming
could invest a bunch of time and coming
up with a really nice fancy encoder for
up with a really nice fancy encoder for
this cuz if I were given enough time
this cuz if I were given enough time
right I could come up with a really
right I could come up with a really
sweet like 2D mixed discreet and
sweet like 2D mixed discreet and
continuous encoder and maybe I should do
continuous encoder and maybe I should do
that cuz that would be a really useful
that cuz that would be a really useful
tool to have it's just a bit tricky
tool to have it's just a bit tricky
because i' probably I'd have to like
because i' probably I'd have to like
write the kernels for it which I can do
write the kernels for it which I can do
that in C but then doing that for GPU
that in C but then doing that for GPU
for p torch would be really uh really a
for p torch would be really uh really a
lot more difficult
but it's doable but then the question is
but it's doable but then the question is
you know is this even a good
you know is this even a good
representation at all
representation at all
because this is very specific to grid
because this is very specific to grid
like grid type environments right you
like grid type environments right you
might not want to always have grid type
might not want to always have grid type
environments right maybe the majority of
environments right maybe the majority of
this data is actually going to be entity
this data is actually going to be entity
based so if you know you have your agent
based so if you know you have your agent
on your map here
on your map here
right and you have like other
stuff then like the the one way of
stuff then like the the one way of
handling it is to do a grid based
handling it is to do a grid based
representation like this so it observes
representation like this so it observes
the stuff around it this is not Tic Tac
the stuff around it this is not Tic Tac
Toe but it looks like
Toe but it looks like
it um but then the other way of doing
it um but then the other way of doing
this is you could
instead if I just draw the same thing
right you can get an entity based
right you can get an entity based
encoding instead and there's been some
encoding instead and there's been some
work on
work on
that this tends to be kind of difficult
that this tends to be kind of difficult
but you can do
but you can do
it cuz like you need to encode position
it cuz like you need to encode position
data in here and then your agent needs
data in here and then your agent needs
to learn like relative position type
to learn like relative position type
stuff and also generally like making
stuff and also generally like making
relativizing the position is
relativizing the position is
difficult not that difficult
though actually really not that
though actually really not that
difficult now that I think about it
difficult now that I think about it
because I'm writing the environment in
because I'm writing the environment in
freaking C
anyways graph neural network
anyways graph neural network
simpler entity neural network I highly
simpler entity neural network I highly
recommend I highly highly recommend this
recommend I highly highly recommend this
blog post by
blog post by
Clemens um just if you look up entity
Clemens um just if you look up entity
based RL he has this really nice blog
based RL he has this really nice blog
post on this architecture and it's a
post on this architecture and it's a
good architecture and I do think it's
good architecture and I do think it's
interesting that he uses like
interesting that he uses like
Transformer type blocks and he gets high
Transformer type blocks and he gets high
performance but he gets high performance
performance but he gets high performance
for like back then standards right like
for like back then standards right like
the stuff I'm doing with puffer now is
the stuff I'm doing with puffer now is
so much faster than this it's not even
funny he's got a bunch of fun
posts he also has this one
posts he also has this one
one I really like this one
one I really like this one
here maybe I should get
here maybe I should get
um maybe I should ask him about this
um maybe I should ask him about this
environment and if he has the code for
environment and if he has the code for
this open source cuz like adding an RTS
this open source cuz like adding an RTS
to puffer would be really
cool I wonder how he did all this online
cool I wonder how he did all this online
as well
I don't know if this is anywhere near
I don't know if this is anywhere near
high as high perf
though yeah this is very cool though
what did he use for
what did he use for
this yeah he's always doing entity based
this yeah he's always doing entity based
stuff
here this is kind of nice in a
here this is kind of nice in a
way that like
H I actually don't know if these are
H I actually don't know if these are
nice in a
way having all these separate different
way having all these separate different
little networks is very
inefficient I wouldn't be surprised that
inefficient I wouldn't be surprised that
this ends up being very
this ends up being very
slow it does seem dumb ultimately to bet
slow it does seem dumb ultimately to bet
against this architecture this does seem
against this architecture this does seem
like a good architecture but like this
like a good architecture but like this
is just a tiny number of
is just a tiny number of
samples training takes over a 2 Days 12
hours just over two days about 12 okay
hours just over two days about 12 okay
so 36 hours for 125 million samples like
so 36 hours for 125 million samples like
125 million samples in puffer lib for
125 million samples in puffer lib for
some of our stuff is like 2 to 5
minutes and he has more cores
and he's yeah and he's using multi-gpu
and he's yeah and he's using multi-gpu
as
well I do very much like this project
well I do very much like this project
though and looking at this is actually a
though and looking at this is actually a
kind of a good thing for like how I'm
kind of a good thing for like how I'm
thinking about architectures now
got very good work on
this value
function omnicient value function
function omnicient value function
essential is annoying
appendex hold
appendex hold
on so much stuff
did he open source this environment
this demo site no longer
works I don't know if he actually open
works I don't know if he actually open
sourced the environment
ever I got to make some decisions here
ever I got to make some decisions here
and the thing is the tough thing is like
and the thing is the tough thing is like
I'm generally of the camp of just like
I'm generally of the camp of just like
just coat it and you know you'll figure
just coat it and you know you'll figure
stuff out
stuff out
afterwards but this is one of the places
afterwards but this is one of the places
where it's like I can save myself a lot
where it's like I can save myself a lot
of headache if I get it right on the
of headache if I get it right on the
first
try well I think that regardless like
you definitely want your network
you definitely want your network
operations to be
shared so that thing that he had with
shared so that thing that he had with
all those different embeddings you
all those different embeddings you
really don't want to have
happen the same time the entity
happen the same time the entity
architecture is so nice conceptually
is it
is it
though
though
wait I don't actually even know if the
wait I don't actually even know if the
embeding network architecture is nice
embeding network architecture is nice
conceptually now that I'm thinking about
it cuz embedding each feature separately
it cuz embedding each feature separately
like that's expensive very very
expensive there are definitely some
expensive there are definitely some
things that need to be one hotted there
things that need to be one hotted there
definitely some things that need to be
definitely some things that need to be
one
hotted
like the observation map is a really
like the observation map is a really
good example of this
good example of this
all right I'll draw up another thing
all right I'll draw up another thing
here real
here real
quick so what I'm doing right now with
quick so what I'm doing right now with
the Moa and I use this approach in a lot
the Moa and I use this approach in a lot
of places right I have a core map that
of places right I have a core map that
looks like
this and like you know you could have
this and like you know you could have
different entity Types on here right
different entity Types on here right
like I can have like
right I can have like all these
right I can have like all these
different entity types and then the way
different entity types and then the way
that you actually process these this is
that you actually process these this is
going to be like one 0 0 0 2 3 3
going to be like one 0 0 0 2 3 3
Z 1
Z 1
to
Z okay so this is what the network
Z okay so this is what the network
actually sees this is how one hot
actually sees this is how one hot
encoding
encoding
works and then specifically when we
works and then specifically when we
encode this right like the way that this
encode this right like the way that this
one would get encoded this is the one
one would get encoded this is the one
hot
hot
representation so there are 0 1 2 3 so
representation so there are 0 1 2 3 so
four different element types
four different element types
right and then what we do is we go to
right and then what we do is we go to
the first one and we shade this one
the first one and we shade this one
in and this is your like your 1D
in and this is your like your 1D
depthwise Network
depthwise Network
here right so this is your one hot
here right so this is your one hot
representation
is this
is this
good the
question I'm trying to think about if
question I'm trying to think about if
this is good or
not is this the replayer Tic Tac to no
not is this the replayer Tic Tac to no
this is me trying to explain so Nathan
this is me trying to explain so Nathan
um actually maybe your thoughts will be
um actually maybe your thoughts will be
good on this as well because well
good on this as well because well
actually hold on did you finish your uh
actually hold on did you finish your uh
did you finish your
thesis oh man the YouTube delay
in the meantime so this is not three
in the meantime so this is not three
player Tic Tac Toe this is me explaining
player Tic Tac Toe this is me explaining
um encodings of
observations and I'm actually trying to
observations and I'm actually trying to
think about this here because
think about this here because
like oh you finished
like oh you finished
it Round of Applause for this man please
it Round of Applause for this man please
folks heck
folks heck
yeah hey Nathan if you're down to work
yeah hey Nathan if you're down to work
on uh environment stuff at all you know
on uh environment stuff at all you know
throughout this week or whatever I am
throughout this week or whatever I am
absolutely 100% available to help you
absolutely 100% available to help you
with that stuff I would love to see that
with that stuff I would love to see that
environment come to uh to fruition that
environment come to uh to fruition that
looks awesome what I'm trying to do
looks awesome what I'm trying to do
right now so I've got the Moa I've got
right now so I've got the Moa I've got
my secret side project right I've got
my secret side project right I've got
additional stuff that I'm working on I
additional stuff that I'm working on I
also just announced puffer officially
also just announced puffer officially
open for business as well today uh so
open for business as well today uh so
you know there's going to be some stuff
you know there's going to be some stuff
holy people are actually uh supporting
holy people are actually uh supporting
this thank you
um but uh the thing that I want to do
um but uh the thing that I want to do
and that I think it's going to support
and that I think it's going to support
your stuff and it's going to support all
your stuff and it's going to support all
the stuff that we're trying to do so so
the stuff that we're trying to do so so
much right
much right
now this is the problem that caused me
now this is the problem that caused me
so much grief throughout my whole PhD
so much grief throughout my whole PhD
getting good observation representations
getting good observation representations
in RL is so hard like coming up with a
in RL is so hard like coming up with a
good way to format your observation data
good way to format your observation data
such that it it's easy to put into
such that it it's easy to put into
networks and make fast is really
networks and make fast is really
hard so like okay I have some thoughts
hard so like okay I have some thoughts
on this and folks maybe you guys will
on this and folks maybe you guys will
have some input because this is really
have some input because this is really
this is not a super technical
this is not a super technical
area this is relatively
area this is relatively
accessible
accessible
so this is the data
so this is the data
um right now you have 1 Z 0 023 right so
um right now you have 1 Z 0 023 right so
I can encode this the most efficient way
I can encode this the most efficient way
to encode this typically is this is just
to encode this typically is this is just
going to be U and eight right so this is
going to be U and eight right so this is
now bytes technically I can compress
now bytes technically I can compress
this even more if I want to do custom
this even more if I want to do custom
compression uh I only need let's see
compression uh I only need let's see
there are four different values I only
there are four different values I only
need two bits per item here uh so I can
need two bits per item here uh so I can
technically compress this even more but
technically compress this even more but
then I've got to uncompress it which is
then I've got to uncompress it which is
you know potentially difficult maybe
you know potentially difficult maybe
once I start writing like custom kernels
once I start writing like custom kernels
for networks uh for puffer once we get
for networks uh for puffer once we get
into that level of optimization then we
into that level of optimization then we
can start looking at that but for now
can start looking at that but for now
this is bites okay and this is not bad
this is bites okay and this is not bad
right this is fine but what happens is
right this is fine but what happens is
you can see that when I expand this here
you can see that when I expand this here
not only do I have to have all this
not only do I have to have all this
memory available right because now I
memory available right because now I
have four times this amount of memory I
have four times this amount of memory I
have four of these grids and if I have
have four of these grids and if I have
like 10 or 15 different object types
like 10 or 15 different object types
what ends up happening is you get this
what ends up happening is you get this
giant ass block of memory
right you get 15 of these going this way
right you get 15 of these going this way
15 different layers now that's not a ton
15 different layers now that's not a ton
of uh that's not a ton because we'll
of uh that's not a ton because we'll
typically have 32 or 64 con filters
typically have 32 or 64 con filters
anyways so this is not bad on its own
anyways so this is not bad on its own
but having to unpack data like this is
but having to unpack data like this is
slightly annoying now if you just have
slightly annoying now if you just have
one of these it's not that bad if this
one of these it's not that bad if this
is all you need to do I'm happy but the
is all you need to do I'm happy but the
problem is that this is very rarely the
problem is that this is very rarely the
case right this is very rarely the thing
case right this is very rarely the thing
on its own because what'll happen is you
on its own because what'll happen is you
end up having like multiple layers of
end up having like multiple layers of
this stuff right this just says okay
this stuff right this just says okay
this is you know this type of entity is
this is you know this type of entity is
in this cell I have like an O here an X
in this cell I have like an O here an X
here a triangle here well what if they
here a triangle here well what if they
have health values right maybe this
have health values right maybe this
has pick another color right maybe we
has pick another color right maybe we
have like
have like
HP and now this has like three HP this
HP and now this has like three HP this
has 5 HP five you know maybe this one
has 5 HP five you know maybe this one
has 2 Hp maybe this one's been hit it
has 2 Hp maybe this one's been hit it
has one HP and this one has three right
has one HP and this one has three right
like now I have to
like now I have to
add channels here and I either have to
add channels here and I either have to
add one channel if I want to just put
add one channel if I want to just put
this in as a continuous value and then I
this in as a continuous value and then I
have to handle mix continuous and
have to handle mix continuous and
discret in the encoder
discret in the encoder
or uh I have to discretize this right
or uh I have to discretize this right
and then I lose
and then I lose
Precision so this is kind of hard
Precision so this is kind of hard
this is kind of hard
right like
technically
uh the mixing of different data types
uh the mixing of different data types
like this some of which require discret
like this some of which require discret
and some of which require continuous is
and some of which require continuous is
hard
hard
and also if you have multiple different
and also if you have multiple different
discreet types you end up having to have
discreet types you end up having to have
like this multi hot embedding layer that
like this multi hot embedding layer that
like Stacks a whole bunch of layers and
like Stacks a whole bunch of layers and
it's gotten up to be like 60 before I've
it's gotten up to be like 60 before I've
done I've had to
do and you lose
Precision I don't know if there's a way
Precision I don't know if there's a way
around it
though representing this date is hard
you really want the con layer coner
you really want the con layer coner
gives you a ton of good priors about
gives you a ton of good priors about
local uh spatial locality
right entity based embedding doesn't buy
right entity based embedding doesn't buy
you anything if you were to do entity
you anything if you were to do entity
based that does not buy you
based that does not buy you
anything entity base means that you just
anything entity base means that you just
record an entry for each of these
record an entry for each of these
instead of recording like the whole cell
instead of recording like the whole cell
the whole grid but that really doesn't
the whole grid but that really doesn't
do anything for
you I mean it's less data
you I mean it's less data
actually but you still have to you still
actually but you still have to you still
have all the same technical problem so I
have all the same technical problem so I
think that that's
think that that's
orthogonal yeah it's the mix continuous
orthogonal yeah it's the mix continuous
and discreet embedding is the problem
doing that really fast and
simple I mean technically I can punt on
simple I mean technically I can punt on
it and say that I'm going to have to
it and say that I'm going to have to
write a custom kernel at some point
write a custom kernel at some point
right I actually have not done that
right I actually have not done that
before I have not had to write custom
before I have not had to write custom
GPU kernels I've done you know I've done
GPU kernels I've done you know I've done
lowlevel CPU stuff but not
lowlevel CPU stuff but not
GPU I could do that
GPU I could do that
though I mean it's probably nowhere near
though I mean it's probably nowhere near
as bad now that I've been doing all this
as bad now that I've been doing all this
C it's probably going to be relatively
easy technically it's pretty easy Once
easy technically it's pretty easy Once
you write it as well cuz it just Cuda
you write it as well cuz it just Cuda
you can bind it to anything else right
you can bind it to anything else right
so I can have it Bound for p torch and
so I can have it Bound for p torch and
then if I need it in another framework I
then if I need it in another framework I
can use the same
thing so that's
nice com layers still learn well on
nice com layers still learn well on
sparse grids yep they can learn on
sparse grids yep they can learn on
sparse grids what they can't learn on is
sparse grids what they can't learn on is
if I were to just input this whole thing
if I were to just input this whole thing
into a con like 1 0 2 3 it can't learn
into a con like 1 0 2 3 it can't learn
that because the con it's going to treat
that because the con it's going to treat
each of those values as continuous right
each of those values as continuous right
so these are discret values not
so these are discret values not
continuous values right one corresponds
continuous values right one corresponds
to something completely different from
to something completely different from
two like one is not any closer to two
two like one is not any closer to two
than it is to three in this space so
than it is to three in this space so
conv is going to be bad for that which
conv is going to be bad for that which
is why you have to one hot it like
this now technically you don't have to
this now technically you don't have to
one hot it right there other encodings
one hot it right there other encodings
you could use like for instance I drew
you could use like for instance I drew
these in color right I could have unique
these in color right I could have unique
colors for every different type of
colors for every different type of
entity here and then I could just use a
entity here and then I could just use a
fix three channels and RGB it or I could
fix three channels and RGB it or I could
come up with any number of other
come up with any number of other
different embeddings right I can use a
different embeddings right I can use a
fixed embedding instead of a learned
fixed embedding instead of a learned
embedding which you'd think like well
embedding which you'd think like well
isn't a learned embedding always going
isn't a learned embedding always going
to be better yeah technically it is
to be better yeah technically it is
possible to always get a better learned
possible to always get a better learned
one but you save on memory and therefore
one but you save on memory and therefore
you can save on
you can save on
performance by doing it this
way I mean this whole thing started just
way I mean this whole thing started just
because
because
like one the networks are not performing
like one the networks are not performing
fast enough right now in uh in pytorch
fast enough right now in uh in pytorch
they need to be about twice as fast as
they need to be about twice as fast as
they are now in order to match like the
they are now in order to match like the
snaket
snaket
performance and
performance and
two is that I don't want to have to
two is that I don't want to have to
implement all this one off stuff and
implement all this one off stuff and
see if it's going to be like if I'm
see if it's going to be like if I'm
going to just be changing
it I want have to implement all this
it I want have to implement all this
oneoff stuff and see if I'm just going
oneoff stuff and see if I'm just going
to be changing it
right like what's the simplest thing I
right like what's the simplest thing I
can do for now what is the simplest
can do for now what is the simplest
thing I can do and I'm trying to I'm
thing I can do and I'm trying to I'm
always thinking about it that way and
always thinking about it that way and
there's like sometimes there's just not
there's like sometimes there's just not
a simple thing to
do I mean I could just like try to
do I mean I could just like try to
implement all these same concatenate and
implement all these same concatenate and
split in whatever operations that I have
split in whatever operations that I have
in py torch and c and I could just like
in py torch and c and I could just like
do it that way but that's not great
do it that way but that's not great
that's just bringing all the Jank from
that's just bringing all the Jank from
pytorch into
pytorch into
C e
[Music]
it's funny because like this is also
it's funny because like this is also
like this is exactly the problem that
like this is exactly the problem that
puffer lib kind of solves
puffer lib kind of solves
right like we technically have we have
right like we technically have we have
offthe shelf solutions to all of this
offthe shelf solutions to all of this
and like if you're a company doing
and like if you're a company doing
RL and you're like using stable
RL and you're like using stable
baselines or whatever yeah puffer is
baselines or whatever yeah puffer is
going to be more than 10 times faster
going to be more than 10 times faster
just for free and it'll be easier but
just for free and it'll be easier but
like what I'm doing now is like I'm
like what I'm doing now is like I'm
essentially this is the next version
essentially this is the next version
right I'm trying to solve this problem
right I'm trying to solve this problem
in a way that's just so much
in a way that's just so much
fundamentally
fundamentally
faster that just never going to
faster that just never going to
bottleneck you no matter what
that's hard that is
that's hard that is
hard
um if let me go let me look down uh one
um if let me go let me look down uh one
one more Rabbit
one more Rabbit
Hole so if I were to
Hole so if I were to
commit to entity based
commit to entity based
data if I were were to commit to entity
data if I were were to commit to entity
based
data entity based
data looks like this now
right so we had like the X's before
right so we had like the X's before
right so you have one here you have one
right so you have one here you have one
here you have like your what was this no
here you have like your what was this no
I forget what this was O
I forget what this was O
oh yeah and I forget the exact number
oh yeah and I forget the exact number
that we had before but like the idea is
that we had before but like the idea is
that
that
like you have like the observations for
like you have like the observations for
your different
your different
shapes and then you just put them all
shapes and then you just put them all
into a struct so they have the same
shapes this is very easy to
code it's outside of very Niche
code it's outside of very Niche
circumstances it's incredibly efficient
and
and
then then this type of thing would be at
then then this type of thing would be at
least easier to write an encoder for
right yeah CU I wouldn't have to deal
right yeah CU I wouldn't have to deal
with the additional structured
with the additional structured
format I would be able to write an
format I would be able to write an
encoder for this much much more easily
encoder for this much much more easily
and that would be fully General I could
and that would be fully General I could
use that encoder
use that encoder
anywhere how much less data would this
anywhere how much less data would this
be
quite substantially less
quite substantially less
right order of magnitude
right order of magnitude
maybe at least 80% less
data if it were 80% less
data if it were 80% less
data I could probably get away with a
data I could probably get away with a
bite for each Channel instead of having
bite for each Channel instead of having
to do anything fancier
um observation en coding function gets a
um observation en coding function gets a
little more
little more
complicated I mean the observation
complicated I mean the observation
computation function but it's not that
computation function but it's not that
bad I
think yeah it's not that that
think yeah it's not that that
bad not contiguous memory anyways
there's potentially a distance
check or not I could just be fancy with
check or not I could just be fancy with
the
the
iteration that's actually very
iteration that's actually very
nice and then what's the network look
nice and then what's the network look
like if I had this type of data let's
like if I had this type of data let's
say that I get these vectors into
say that I get these vectors into
something that can go into a neural
something that can go into a neural
network then
I think it looks something like
um this just goes into a Transformer
um this just goes into a Transformer
doesn't
doesn't
it multi-headed
it multi-headed
detention or if you don't want to do
detention or if you don't want to do
multi-headed detention it can go into a
multi-headed detention it can go into a
Max function that's a fast
alternative so it can go wide and then
alternative so it can go wide and then
into a Max I've seen that done before
this is such a good representation isn't
this is such a good representation isn't
it okay I think what I'll commit to is
it okay I think what I'll commit to is
I'm going to say that uh in the
I'm going to say that uh in the
relatively near future I'm going to
relatively near future I'm going to
experiment with this type of
experiment with this type of
encoding and you know one of the really
encoding and you know one of the really
cool things about deving these high perf
cool things about deving these high perf
Sims is um I will be able to get
Sims is um I will be able to get
conclusive
conclusive
evidence on this type of a thing because
evidence on this type of a thing because
I just the Sims are so fast I can run
I just the Sims are so fast I can run
stuff for so
long I will be able to solve this
problem in the relatively near
problem in the relatively near
future so what do I do for
today I honestly think the easiest thing
today I honestly think the easiest thing
to do for today is to just write it
to do for today is to just write it
single purpose to neural uh not to
single purpose to neural uh not to
neural it's uh the single purpose to
neural it's uh the single purpose to
puffer
mooba we write it single purpose to
mooba we write it single purpose to
puffer
puffer
mooba and we just copy the operation
mooba and we just copy the operation
exactly as it
exactly as it
happens and we see what goes from
happens and we see what goes from
there it'll it'll still be a cool
there it'll it'll still be a cool
exercise and then I'll have to think
exercise and then I'll have to think
about
about
this I like that blog post by Clemens
this I like that blog post by Clemens
I should meet up with him I think he's
I should meet up with him I think he's
still an SF probably opening eyes
still an SF probably opening eyes
working him half to death getting uh gp5
working him half to death getting uh gp5
released or whatever
released or whatever
but he's doing
well
fun let's uh let's try that cuz I think
fun let's uh let's try that cuz I think
it's not that bad if I just do it C
right I think it's not that
bad net con one
bad net con one
input yeah so let's
do uh float what is it float
star load
star pre-processed
size of
float
oops now we actually get to start
oops now we actually get to start
writing some cool
writing some cool
code this goes at the top
so we
so we
do where's batch
size wait where's batch size oh numb
size wait where's batch size oh numb
agents yeah
agents yeah
okay let's just do numb agents
I forgot I had to do
I forgot I had to do
that so let's just write this uh
that so let's just write this uh
explicitly so what we're going to do is
explicitly so what we're going to do is
going to
going to
be we're going to go over the batch size
be we're going to go over the batch size
which is going to be the number of
which is going to be the number of
Agents we're only doing this for a
Agents we're only doing this for a
single environment and see there's no
single environment and see there's no
reason to do more than that and then
reason to do more than that and then
what we have to do
is the first 11 by 11 right
one
one
hun this the correct memory format I
hun this the correct memory format I
believe
believe
so 11 by
so 11 by
11 and we don't need this
11 and we don't need this
J we just need to
do there four input channels
so we one
so we one
hot so let's do in in
Adder bat size time 11 *
Adder bat size time 11 *
11 plus I
* not times
* not times
19 they're four input channels
again I should I always forget to sketch
again I should I always forget to sketch
this stuff so people can follow my
this stuff so people can follow my
convoluted thought
convoluted thought
process
process
um Let me let me sketch this out for you
um Let me let me sketch this out for you
guys real quick just so you can follow
guys real quick just so you can follow
my I'm going to do this once so that
my I'm going to do this once so that
people can follow this uh and actually
people can follow this uh and actually
learn something from this uh this
learn something from this uh this
exercise
exercise
so right now the input looks like
this okay this is
this okay this is
uh 11 by 11x 4 which means that in the
uh 11 by 11x 4 which means that in the
memory layout hold on let me
think yes so this is
think yes so this is
11 11 and this is going to be the uh
11 11 and this is going to be the uh
grid data this is
grid data this is
grid and then what we have
grid and then what we have
here had a step away definitely work on
here had a step away definitely work on
dope this week hey you know Nathan like
dope this week hey you know Nathan like
you swing by and let me know if I can
you swing by and let me know if I can
help you out okay I've been doing lots
help you out okay I've been doing lots
of stuff with this I've written so much
of stuff with this I've written so much
low-l code in the last few weeks I've I
low-l code in the last few weeks I've I
so let me put it this way the next
so let me put it this way the next
update to puffer lib is going to be
update to puffer lib is going to be
bigger than the current size of puffer
bigger than the current size of puffer
lib and it's like all this C environment
lib and it's like all this C environment
SIM code so we're going to have Ultra
SIM code so we're going to have Ultra
fast environments like literally like
fast environments like literally like
the MOBA is going to be 2,000 plus and
the MOBA is going to be 2,000 plus and
then the other environment I have looks
then the other environment I have looks
like it's going to be
like it's going to be
3,000 uh not to mention that we're going
3,000 uh not to mention that we're going
to Port like your y andoa Atari games
to Port like your y andoa Atari games
I'm going to help you guys Port those to
I'm going to help you guys Port those to
Native C so that we can have them on web
Native C so that we can have them on web
and of course you'll get the credits on
and of course you'll get the credits on
the website as
well if you want to contribute them that
well if you want to contribute them that
is
C makes it nope C doesn't make it any
C makes it nope C doesn't make it any
faster you're a okay to write in scon um
faster you're a okay to write in scon um
C is just for web
C is just for web
assembly so if it's easier for you to
assembly so if it's easier for you to
Dev in scon keep deving in scon I don't
Dev in scon keep deving in scon I don't
want to make your life any harder uh
want to make your life any harder uh
it's gotten to the point where for me
it's gotten to the point where for me
it's just as easy to write c as it is to
it's just as easy to write c as it is to
write cython uh and web assembly right
write cython uh and web assembly right
play
online plus where I'm like I'm writing
online plus where I'm like I'm writing
these networks and C so it's literally
these networks and C so it's literally
we can do inference online
we can do inference online
too okay let me let me finish my thought
too okay let me let me finish my thought
process though CU I was explaining how
process though CU I was explaining how
the encoder that I'm writing has to work
the encoder that I'm writing has to work
here so this is grid this is
here so this is grid this is
continuous data that's an n and then
continuous data that's an n and then
this is
extra and this is just 26 features so
extra and this is just 26 features so
what I have to
what I have to
do is I have this big block of memory
do is I have this big block of memory
that this is going to get written into
that this is going to get written into
um it has to be 11 by 11
by go
on do I have this
right ah linear memory layout is so
right ah linear memory layout is so
difficult to keep in your head
I think I have it
right because it goes
right because it goes
row and then it goes
row and then it goes
yeah okay this is not as bad as I
thought yeah this is not as bad as I
thought yeah this is not as bad as I
thought so here this 11 by1
thought so here this 11 by1
grid this is what's going to happen this
grid this is what's going to happen this
is going to become
is going to become
11 11 * 16
11 11 * 16
here and this is one
hot and then this gets
normed and then this is going to just
stay three and then this gets
stay three and then this gets
normed
normed
Norm I can't write and this goes here 26
Norm I can't write and this goes here 26
okay so this is what we're writing is
okay so this is what we're writing is
that we have to take this and do these
that we have to take this and do these
operations very
operations very
efficiently make
sense that actually did help me for once
sense that actually did help me for once
to think about what I wanted to do
to think about what I wanted to do
because now I actually know how this
because now I actually know how this
should work um because I I just this is
should work um because I I just this is
going to just be plus
going to just be plus
I out
I out
Adder 11 * 11 * 19
Adder 11 * 11 * 19
plus
plus
I uh now this one is I * 19
right uh except it's not 19 right is
right uh except it's not 19 right is
it * 11 *
it * 11 *
19 wait in
address plus 26 we'll make sure all
address plus 26 we'll make sure all
these numbers are not hardcoded you know
these numbers are not hardcoded you know
once I finish this plus 26 so this is
once I finish this plus 26 so this is
the size your ins size your out size
the size your ins size your out size
here right and then the out address does
have do the out address have things to
have do the out address have things to
worry
worry
about plus I * 19
it's 11 *
11 I
11 I
* 11 *
* 11 *
11 I
believe is it 19
believe is it 19
here I it is 19
here man it is hard to do this in your
here man it is hard to do this in your
head without messing this
up and then you
up and then you
do preprocessed of in
do preprocessed of in
address which
address which
is wait
is wait
what uh yeah net
what uh yeah net
pre-processed net pre-processed out
pre-processed net pre-processed out
address
no out would
address
address
wait
equals
equals
one
one
Adder input
right this is your one hot
address out address plus one hot
address out address plus one hot
Adder
Adder
one is this how it
works you have to clear your
works you have to clear your
pre-processed buffer
and then you set one
hot okay so if this is
hot okay so if this is
correct
then from here
wait
wait
four out address
four out address
plus and then you do
plus and then you do
net out
address why is this so
hard it's hard because of the way that
hard it's hard because of the way that
the layers are ordered it's difficult to
the layers are ordered it's difficult to
think
about I should make some tool that just
about I should make some tool that just
like you know takes all your memory and
like you know takes all your memory and
then like just colors it differently so
then like just colors it differently so
you can see where stuff
you can see where stuff
is that'd be really easy actually to do
wait wouldn't the easier
thing you know I've actually been
thing you know I've actually been
wondering
like maybe this is me being dumb but can
like maybe this is me being dumb but can
I just cast this to be like a 4D
I just cast this to be like a 4D
tensor and then just directly index
that should be the same
right well I still have to do the
right well I still have to do the
input but like the output address can I
input but like the output address can I
just cast this to be a 4D
tensor I think I can right
let me go find the Syntax for
that because I don't think that there is
that because I don't think that there is
a reason not to do it like
a reason not to do it like
this hold on I always forget the cast
this hold on I always forget the cast
intact this is a cool trick but uh I
intact this is a cool trick but uh I
always forget the syntax because it's
always forget the syntax because it's
very obnoxious
very obnoxious
syntax I did I not even use it in here
syntax I did I not even use it in here
once I know I used it in the Mobis
once I know I used it in the Mobis
source
code yeah right
here float star
here float star
preprocessed and then you get to you
preprocessed and then you get to you
just shave off the batch Dimension and
just shave off the batch Dimension and
then you do 11 by 11
by4 oh and it is an unsigned charar
by4 oh and it is an unsigned charar
isn't
it that was almost bad unsigned
it that was almost bad unsigned
Char
Char
and net
pre-processed no is float what am I
pre-processed no is float what am I
doing
float
float
that technically I can just do all of it
that technically I can just do all of it
this way can't
this way can't
I or
I or
no no the memory is not contiguous okay
no no the memory is not contiguous okay
I can still do this though so by doing
I can still do this though so by doing
this now I have
this now I have
11 by 11 it's not by four right it's
by oh no now I remember why I can't
by oh no now I remember why I can't
do this God damn
it cuz of the 26 at the end is the
it cuz of the 26 at the end is the
problem the 26 at the end is the
problem the 26 at the end is the
problem well hang on though I need two
problem well hang on though I need two
different tensors anyways don't
I I literally need two different tensors
anyways
so I can do
this
map so this is like OBS
2D OBS 1D like this right 1D 2D 2D 1
OBS
OBS
2D OBS 1D is going to
2D OBS 1D is going to
be
26 yeah so now what I can do is I can do
26 yeah so now what I can do is I can do
float star OBS 2D
and then this is going to be size
19 this net is going to be OBS 2D then
19 this net is going to be OBS 2D then
we do float OBS
we do float OBS
1D Now isn't that
1D Now isn't that
nice now we actually can index things
nice now we actually can index things
without going
without going
insane because I no longer need to care
insane because I no longer need to care
about this out address
about this out address
right I literally can just
right I literally can just
do bi I
do bi I
okay I need to do for J now instead I
okay I need to do for J now instead I
write an extra Loop but that's
write an extra Loop but that's
fine
fine
oops okay so we do
oops okay so we do
J whatever this is what tab tab we're
J whatever this is what tab tab we're
going to fix these addresses and then
going to fix these addresses and then
batch i
batch i
j and then this here is going to be like
j and then this here is going to be like
one
one
hot one
hot one
hot idx
hot idx
equal to
equal to
one and then all I have to do is figure
one and then all I have to do is figure
out the uh in
out the uh in
address which is going to be batch * 11
address which is going to be batch * 11
* 11 *
plus I
* hold
* hold
on I * 11 plus J I think this is correct
right
right
yeah and this is one hot
idx
almost this tells you the
almost this tells you the
value
Adder if only C had passed by reference
Adder if only C had passed by reference
the syntax so
the syntax so
clean pointers aren't bad took data
clean pointers aren't bad took data
struction 2012 the pointers actually are
struction 2012 the pointers actually are
not
not
bad
bad
um the one thing I really hated in C is
um the one thing I really hated in C is
the pass by value by
the pass by value by
default right now I just use pointers
default right now I just use pointers
everywhere I just use pointers
everywhere I just use pointers
everywhere and I I don't think I have a
everywhere and I I don't think I have a
single place in my code mode where I do
single place in my code mode where I do
like Star thing dot like I don't have I
like Star thing dot like I don't have I
don't have a single place where I'm ever
don't have a single place where I'm ever
like directly D referencing something
like directly D referencing something
ever right so once I realize that it's
ever right so once I realize that it's
actually not bad at all like when I make
actually not bad at all like when I make
strs my
strs my
strs well I guess for performance this
strs well I guess for performance this
is maybe a problem so I might actually
is maybe a problem so I might actually
have to revisit this but like I pretty
have to revisit this but like I pretty
much never will make a struct
much never will make a struct
uh that
uh that
contains a specific thing it'll contain
contains a specific thing it'll contain
a pointer to a
a pointer to a
thing that's actually kind of bad for
thing that's actually kind of bad for
perf now that I'm thinking about
it
yeah but not
really we'll be able to make it fast
really we'll be able to make it fast
either way
hi okay so here's your one
hot and then
then you got to do some more iterating
then you got to do some more iterating
don't
you I got to figure out how to copy the
you I got to figure out how to copy the
last
layers where this is laid out in
layers where this is laid out in
memory trying to think where I put this
memory trying to think where I put this
in the
loop
uh int back
off this is going to
be cuz we're going to need this anyways
actually this offset is
good so we'll just make this extra thing
good so we'll just make this extra thing
and then I think what we can do is
am I crazy or can I just do this OBS
2D so this is going to be 16 plus
well this is just wait
well this is just wait
16 and then this is going to be
16 and then this is going to be
input
no two
times three
they're four layers so
they're four layers so
it's four
yeah does this not just do it
and then at the very end you have to
do 11 plus yeah then you have to copy
do 11 plus yeah then you have to copy
the 1D
the 1D
data so I think that this does it and we
data so I think that this does it and we
have to add some uh we have to add some
have to add some uh we have to add some
stuff to this but I think that this is
stuff to this but I think that this is
it so I think that we just basically
it so I think that we just basically
basically obviously we have to clean
basically obviously we have to clean
this up obviously there a bunch of
this up obviously there a bunch of
hardcoded constants but in what is this
hardcoded constants but in what is this
like 10 15 lines of C I think we have
like 10 15 lines of C I think we have
this entire preprocessing mess done and
this entire preprocessing mess done and
done like Ultra efficiently without
done like Ultra efficiently without
doing any extra
copies now this is incredibly aor prone
copies now this is incredibly aor prone
it needs to be tested and all that
it needs to be tested and all that
but I mean if this works right it's is
solid so I think that what we do it's
solid so I think that what we do it's
this one is divide
this one is divide
by 25.0 F that's what we have on the
by 25.0 F that's what we have on the
right screen here divide by
right screen here divide by
255 and then these are also divide by
255 so that's the
255 so that's the
pre-processing fuel
pre-processing fuel
and then what we do is we can do con
2D this is going to be
2D this is going to be
net oops net
pre-processed
2D OBS 2D because you need the raw
2D OBS 2D because you need the raw
pointer for
this and then we do
this and then we do
reu con
reu con
output con
2D
2D
linear
linear
plat this is your whole
thing so right now we are
thing so right now we are
at
Latin and and
Latin and and
then flat is going to be
oops this net flat here is actually OBS
oops this net flat here is actually OBS
1D OBS
1D OBS
1D and then we have to do
1D and then we have to do
concat on dim
one oh we uh we copied this into the
one oh we uh we copied this into the
wrong Channel didn't we that's all
award but is it cat 1D hold
on yeah it is cat it's cat with him
on yeah it is cat it's cat with him
one map stack
[Music]
cat dim one
layer oh I see cuz it's preallocated
layer oh I see cuz it's preallocated
like this
so it's net OBS
so it's net OBS
1D which is not what we want this should
1D which is not what we want this should
be
net um to Output that flat output right
net um to Output that flat output right
like
like
this so these get
this so these get
stacked and then
and that's not map stack is it what's
and that's not map stack is it what's
the
concatenator that one
be
128 and 26 is
128 and 26 is
it no 3
too oh wait is this
too oh wait is this
actually um no it's CNN channels is
actually um no it's CNN channels is
32 this is 32
and then this is net
cat this is net
cat and
then what do we do from here
R I
think it's
think it's
PR oh it's
PR oh it's
reu it's reu PR reu
is there a thing for re with why is re a
is there a thing for re with why is re a
layer like
this ah because it has an output buffer
this ah because it has an output buffer
that's fine
okay so now we
do and then we
do and then we
do
linear and then we do Rel
and
then and then this gets lstm
right we have the lstm in here
thought we have a wrapper for
this yeah input here
and now we do
and now we do
lstm and then the decode
lstm and then the decode
right which is the discrete decode for
now linear net actor
value
function and then what is the multi-
discreete ARG Max multi
discreete I don't think that signature
discreete I don't think that signature
is right yeah argmax multi discreet just
is right yeah argmax multi discreet just
takes the
input
input
cre uh net
actor
actor
output okay and then that gives you your
actions forward
and this gives you
and this gives you
instar I
instar I
believe instar
forward you actually don't even need the
forward you actually don't even need the
value function but we'll leave it in
value function but we'll leave it in
there for
now that multi discreet
now that multi discreet
output so we're going to have to debug
output so we're going to have to debug
all this but um
this is the basic form of what we're
this is the basic form of what we're
going
for and yeah there's some housekeeping
for and yeah there's some housekeeping
and stuff but if you look at the code
and stuff but if you look at the code
it's not really any
it's not really any
longer I mean obviously like they use
longer I mean obviously like they use
the one hot and stuff here but there's
the one hot and stuff here but there's
like all this indexing mess it's really
like all this indexing mess it's really
not that much longer or more
not that much longer or more
ridiculous compared to the uh the torch
ridiculous compared to the uh the torch
code which I find kind of funny
holy he done pretty
well what on Earth are they doing
no
idea oh I've totally missed messages
idea oh I've totally missed messages
from them haven't I that's
from them haven't I that's
okay I got to finish this
okay I got to finish this
first got to get
first got to get
the the code really am I
right okay so let's see what is
right okay so let's see what is
potentially missing from this
potentially missing from this
if I think I have this remotely
correct well first of all we got to get
correct well first of all we got to get
the layers cleaned
the layers cleaned
up so we have
up so we have
net so we have con re
con you don't need a
flatten and then what do we do we do
linear flatten
linear flatten
conat dim one
conat dim one
cat and then you do reu FR
cat and then you do reu FR
reu and then you do
lstm like
lstm like
this we don't use one hot
this we don't use one hot
now so we'll ignore
now so we'll ignore
this so numb agents OBS 2D is going to
this so numb agents OBS 2D is going to
have 19
have 19
channels OBS 1D has
26 you do this Con 2D B
con
con
con
yeah
flat
flat
cat two P re accurate okay looks good to
me and then the one thing I know I
me and then the one thing I know I
definitely did wrong here is I have the
definitely did wrong here is I have the
channels in the wrong uh
channels in the wrong uh
order
order
so it's channels first right is that how
so it's channels first right is that how
I implemented
I implemented
it tell me that's how I implemented
it tell me that's how I implemented
it did I do channels last or channels
it did I do channels last or channels
first wait
yeah I did channels
first so this just needs to be one
first so this just needs to be one
hot man it's so nice to have this
hot man it's so nice to have this
indexing like
this this is 17
okay yeah that's
okay yeah that's
good so if I can clean this up a little
good so if I can clean this up a little
bit we have it's conu con
bit we have it's conu con
and there's the linear
and there's the linear
layer and then it's cat re linear
layer and then it's cat re linear
reu and there's the
lstm and then it's an actor value and
lstm and then it's an actor value and
then we have oh I need our multi-
then we have oh I need our multi-
discreet that's what I was
missing okay we got multi discreet and I
missing okay we got multi discreet and I
think it's a
think it's a
23 hi why do you have an lstm in your
23 hi why do you have an lstm in your
Moet and what is Moet
Moet and what is Moet
purpose so the purpose of it is to
run this
run this
environment these guys don't move at the
environment these guys don't move at the
moment they need to be uh they need
moment they need to be uh they need
their policies and the policies are
their policies and the policies are
trained with a con and an
trained with a con and an
lstm so if I want them to actually be
lstm so if I want them to actually be
able to play this game and do cool stuff
able to play this game and do cool stuff
then uh yeah we need to actually get
then uh yeah we need to actually get
this running and now it does work in
this running and now it does work in
pytorch but uh in order to run this
pytorch but uh in order to run this
online we want to have like a little C
online we want to have like a little C
only
only
demo so that's what we're doing at the
moment this is somewhat more complicated
moment this is somewhat more complicated
than I expected it would be but
than I expected it would be but
hopefully not that
hopefully not that
bad we'll see how bad it is to
debug we'll see how bad it is to
debug we'll see how bad it is to
debug the only thing I'm missing is
debug the only thing I'm missing is
loading this loading the weights here so
loading this loading the weights here so
why don't we
why don't we
um step
and let's do MOA
and let's do MOA
net do I need do I have all this
stuff literally I don't need any of this
stuff literally I don't need any of this
right it's num creeps num
right it's num creeps num
neutrals literally the only thing I need
neutrals literally the only thing I need
here is num agents I don't know why it
here is num agents I don't know why it
did all this autocomplete on the
did all this autocomplete on the
signature
yeah so num
yeah so num
agents we end it in mobet Num
agents we end it in mobet Num
agents then this will be free
mobet
mobet
and then I have to do forward
right where's
right where's
obs uh I need n it's like n OBS or
something oops
something oops
it's
m.h
OBS oh do I literally have these storage
OBS oh do I literally have these storage
separately I literally have these stored
separately I literally have these stored
separately don't I N observations map
separately don't I N observations map
and observations extra
and observations extra
that's super
nice and is it unsign
nice and is it unsign
charar I believe it
charar I believe it
is
charar 2
charar 2
D Bobs One
D Bobs One
D D D
D D D
zero and then
zero and then
float this does not need to have OBS 2D
float this does not need to have OBS 2D
like
this does
this does
it uh oh no it
it uh oh no it
does it
does so this right
does so this right
here input this is n OBS
here input this is n OBS
2D 2D
3D OBS
3D OBS
1D
1D
cool now you can pass
cool now you can pass
this and then you can
this and then you can
do oh
welcome and then this is now forward
welcome and then this is now forward
this is net this is
this is net this is
n
OBS is this what they were
OBS is this what they were
named
named
view no it's observations map and
view no it's observations map and
observations
extra there we go so now we have these
extra there we go so now we have these
forward functions right
and uh is there
and uh is there
a do I have to write these into the
a do I have to write these into the
environment
environment
actions I think I do have to write this
actions I think I do have to write this
into the actions buffer so let's do
into the actions buffer so let's do
that then this has to
that then this has to
be instar
actions ARG Max multi-
discreet well maybe I'll just copy
them for
them for
now we'll just copy him from uh
now we'll just copy him from uh
here
copy test going to
be yeah now this is going to give me
be yeah now this is going to give me
garbage I don't really want to do a raw
garbage I don't really want to do a raw
M Copy
there I know what I can do
so instead of giving this an
output let's just comment
output let's just comment
this for
this for
now and what we'll
now and what we'll
do we'll do inst star output
do we'll do inst star output
okay uh nope you don't don't need to
okay uh nope you don't don't need to
free it wrong one do against star
free it wrong one do against star
output argmax and instead of layer
output argmax and instead of layer
output this will just be
output this will just be
output right and now what I can
output right and now what I can
do is when we init the melti discreete
do is when we init the melti discreete
here we go to use
it this will be
it this will be
actions
actions this becomes
void this gives you inar actions
and now all I have to
and now all I have to
do is now uh this will write directly
do is now uh this will write directly
into my buffer into the actions buffer
into my buffer into the actions buffer
and then you can step the environment
and then you can step the environment
you can render your
you can render your
game and you're good to
game and you're good to
go now we have to fix all this and get
go now we have to fix all this and get
it to
it to
work let me make sure I'm not missing
work let me make sure I'm not missing
anything important
anything important
here uh hold on
H people are saying my puffer boxes are
H people are saying my puffer boxes are
down let me go check the puffer
boxes that would be
boxes that would be
unfortunate I have this like mini
unfortunate I have this like mini
cluster for
cluster for
uh for puffer but uh it's like literally
uh for puffer but uh it's like literally
in the
garage uh well none of them came
garage uh well none of them came
back
up that's
bad that's real
bad that kind of throws a wrench in
bad that kind of throws a wrench in
everything now doesn't
it I'll have to deal with that
later for
well let's start testing this at least
okay
uh let's figure out what's wrong here
incompatible what
okay multi
okay multi
discreete come on this shouldn't be that
discreete come on this shouldn't be that
long to
long to
debug wake up
here where's
the arc Max multi discreet
one warnings two
one warnings two
errors no member name
reprocessed one
H so somehow
it's make not a
net I use make when I return the struck
net I use make when I return the struck
and a knit when I give it the struck
okay make
relu batch size input
dim uh what is this
three 32 * 3 *
3 three
maybe and then this one
maybe and then this one
here
here
32 28
make multi this is make argmax multi-
discreete what in the
discreete what in the
hell Auto completes
man in logic
sizes um hold
sizes um hold
on int logic sizes
yeah that's
fine batch size logic
fine batch size logic
size
actions this and I need to I need to
actions this and I need to I need to
actually get this
from where is
from where is
it actually what am I doing
here I have the sizes
here 7 seven okay here it is so in logic
here 7 seven okay here it is so in logic
sizes of
six 7 7 and now this is on the stack but
six 7 7 and now this is on the stack but
the thing is it gets copied to here so
the thing is it gets copied to here so
we have it done very
we have it done very
nicely and then did I get to 23 right
nicely and then did I get to 23 right
this is 14
this is 14
17 23 yeah
perfect and then this is going to be
perfect and then this is going to be
logic sizes
like
this oh and then the number of actions
um this is seven this or this is six
um this is seven this or this is six
right you have to give it the six
Max is there an
Max is there an
underscore I think there probably is
right
right
okay five we allocated this the wrong
okay five we allocated this the wrong
way this needs to be 19
like
so
compiles and and we get a SE B of
course right here
okay so we have the one hot index
here
255 so 255 is not a valid one hot index
255 so 255 is not a valid one hot index
um yep that'll do it
so either the data is wrong or the
so either the data is wrong or the
offsets are wrong and either could be
offsets are wrong and either could be
the case because we haven't tested the
the case because we haven't tested the
we have not aggressively enough tested
we have not aggressively enough tested
the compute observations function since
the compute observations function since
we changed
stuff
for e
wait a
wait a
second bat offsets
wrong yeah cuz the input's four chance
okay bch
offset yeah know this batch offsets
offset yeah know this batch offsets
wrong
this is simply uh 26 time or B
this is simply uh 26 time or B
* 26 + I
still wrong
huh are you sure about
that
yeah batch offset looks
yeah batch offset looks
good element offset is
also
good what about the 2D
good what about the 2D
one
19 11 by yeah the issue is that 255 in
there that should not be able to be
there that should not be able to be
255 somehow that's a Max
255 somehow that's a Max
bite I
bite I
wonder hold on a
second now it is an unsigned
Char 11 by 11 by4 the bat
size you're not zeroing the map right
size you're not zeroing the map right
now
now
which is probably really
bad
bad
zero I less than
plus extra zero
yeah same
yeah same
memory it's
memory it's
fine okay so
now okay so now we should be
