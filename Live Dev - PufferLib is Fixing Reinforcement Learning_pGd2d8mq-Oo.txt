Kind: captions
Language: en
We're live. Good
We're live. Good
morning. Seems like it's
morning. Seems like it's
moved. Put this
hereish. Plan right now is get meta
hereish. Plan right now is get meta
working. See if we can figure out that
working. See if we can figure out that
environment. We will see from
environment. We will see from
here. No attribute render.
here. No attribute render.
I believe I was sent instructions on how
I believe I was sent instructions on how
to fix
this. Oh, actually I was sent uh was
this. Oh, actually I was sent uh was
sent something. Hang on.
Perfect. So, let me see what I was
sent.
sent.
Ah, it
is it is this I believe.
No, hang
on.
This. Yeah. So, it is pretty close to
This. Yeah. So, it is pretty close to
what we were
what we were
seeing. We just need this wrapper.
I grab these
I grab these
additional additional bits
out.
Think that should be
it. Oh, there we go. Uh, there
it. Oh, there we go. Uh, there
are two of
are two of
them, but this
them, but this
does actually seem to do stuff.
doesn't have scaling or
anything. Oh, it does have zoom though.
Perfect. Okay, so I'm noticing these
Perfect. Okay, so I'm noticing these
guys mostly not doing much.
Let's uh let's just train something and
Let's uh let's just train something and
see what they
do. And I think actually the way to do
do. And I think actually the way to do
this we'll do like this,
right? Client
whatever.
That doesn't seem like it
works. So, we'll do it this
works. So, we'll do it this
way and we'll just
do Hey, welcome
do Hey, welcome
Adrian. Okay, let's just uh figure out
I just have to make sure I can get it to
I just have to make sure I can get it to
both run and
both run and
render. Then we can get some experiments
going. I train with it.
Okay, that should do it. And then we'll
Okay, that should do it. And then we'll
just have to specify render mode,
just have to specify render mode,
right? Cuz so this won't do anything.
right? Cuz so this won't do anything.
And
And
then render mode.
There we go. So now this does seem to
render.
render.
Okay, these guys don't really move
Okay, these guys don't really move
around very much.
800k
800k
per.
per.
Okay, so this now
Okay, so this now
runs 500
runs 500
kPS. We will see what this does.
I
I
actually want to do a full run of just
actually want to do a full run of just
mil. Yeah, let's do this. We'll let this
mil. Yeah, let's do this. We'll let this
fully run. Uh, and then we will see what
fully run. Uh, and then we will see what
this thing has learned. I'm going to try
this thing has learned. I'm going to try
to learn a little bit more about the
to learn a little bit more about the
environment. I might look through the
environment. I might look through the
end code. We'll go with that.
With this config, the end is actually
With this config, the end is actually
pretty decently uh fast.
pretty decently uh fast.
Not optimal batching,
but
but
decent fair bit of copy
decent fair bit of copy
overhead. Forward is higher than it
overhead. Forward is higher than it
should be because of the quad
buffering. I guess we could try
buffering. I guess we could try
um we could try like double buffered or
um we could try like double buffered or
something with this.
something with this.
Technically, I haven't done that. We can
Technically, I haven't done that. We can
maybe try that
next. The issue here, right, is like
next. The issue here, right, is like
this M should be fast, but it's not like
this M should be fast, but it's not like
quite as fast as they would like it to
be. So, um that's why it's running on 16
be. So, um that's why it's running on 16
cores. And that is actually why I have
cores. And that is actually why I have
these machines spec 16 cores. It's for
these machines spec 16 cores. It's for
when people Sims are not as fast as they
when people Sims are not as fast as they
should
should
be. All right. So, here we go. This
is these were just some older random
is these were just some older random
curves I had from
curves I had from
this. Seems like it is
this. Seems like it is
training. Uh, I believe that like the
training. Uh, I believe that like the
standard on what is good is quite high
standard on what is good is quite high
here though, but that is in a separate
here though, but that is in a separate
custom training repo that's forked from
custom training repo that's forked from
Puffer and they've been like iterating
Puffer and they've been like iterating
on it
on it
forever.
forever.
So, we'll get it to that in Puffer quite
So, we'll get it to that in Puffer quite
quickly, I assume.
Oh, one thing. Let me answer one DM
Oh, one thing. Let me answer one DM
while we're doing this.
I swear I had a piece of code for this
I swear I had a piece of code for this
like a long time
like a long time
ago for saving
videos. I thought it was like an FFI
videos. I thought it was like an FFI
function or something.
Well, I can find uh they just wanted
Well, I can find uh they just wanted
some people wanted to save
some people wanted to save
uh stuff to video actually. I think do I
uh stuff to video actually. I think do I
have on my
have on my
personal is Neural MMO 3 in here?
personal is Neural MMO 3 in here?
I think Neural MMO 3 is on my
I think Neural MMO 3 is on my
personal like the old Syon
version. You see
it? I know I wouldn't have removed it.
H weird.
Well, I don't know where I had the
Well, I don't know where I had the
function
function
then. We haven't like done video saving
then. We haven't like done video saving
in a while. That would actually be
in a while. That would actually be
useful to
do. And I remember it being like really
do. And I remember it being like really
annoying. I would like to link them some
annoying. I would like to link them some
code.
This is almost trained. Well, I will
This is almost trained. Well, I will
come back to
come back to
this. There was a function I had at some
this. There was a function I had at some
point.
point.
Okay. So, this gets like 6 or
Okay. So, this gets like 6 or
something which I assume is not very
something which I assume is not very
good but uh this is something.
So, we should be able to watch
it.
Yes. Okay. They are all standing
still. They're all stuck
still. They're all stuck
because
Presumably they have no energy or
something. So wait, they are
There's got to be like some penalty,
There's got to be like some penalty,
right? Preventing them from
moving cuz they're spamming everything
moving cuz they're spamming everything
but move.
Let's see what is in the
um in the config.
No energy stats. That seems
suspicious. Think they have some sort of
suspicious. Think they have some sort of
docks.
All right, let's actually talk about
All right, let's actually talk about
what this environment is.
what this environment is.
So,
So,
um, this is, uh, an environment that I,
um, this is, uh, an environment that I,
I don't know, I didn't I wouldn't say I
I don't know, I didn't I wouldn't say I
helped design it. I helped with a little
helped design it. I helped with a little
bit of like the infra setup for it over
bit of like the infra setup for it over
the summer. And, uh, this has now been
the summer. And, uh, this has now been
like a longunning project. There's
like a longunning project. There's
several people on this.
several people on this.
Um, not a Puffer project, but Puffer
Um, not a Puffer project, but Puffer
affiliated, I guess,
is. And it's like this procedural grid
is. And it's like this procedural grid
environment that's aiming to be really
environment that's aiming to be really
really complicated uh and have like a
really complicated uh and have like a
lot of room for learning and skill
lot of room for learning and skill
expression. It's aiming to be very
open-ended. You can check it out right
here.
Now the key mechanics here and this is
Now the key mechanics here and this is
what I was looking for is the latest
what I was looking for is the latest
version of this. So agents can see a
version of this. So agents can see a
limited number of squares around them.
limited number of squares around them.
Agents harvest diamonds, convert them to
Agents harvest diamonds, convert them to
energy at charger stations, and use the
energy at charger stations, and use the
energy power the hold alter for rewards.
energy power the hold alter for rewards.
All actions cost energy, so agents learn
All actions cost energy, so agents learn
to manage their energy budgets
to manage their energy budgets
efficiently. Agents can attack others,
efficiently. Agents can attack others,
temporarily freezing the target and
temporarily freezing the target and
stealing resources. Agents can toggle
stealing resources. Agents can toggle
shields, which drain energy but absorb
shields, which drain energy but absorb
attacks. Agents can share energy or
attacks. Agents can share energy or
resources and use markers to
resources and use markers to
communicate.
And then there's a whole bunch of like
And then there's a whole bunch of like
open-ended a lifey style stuff in
here. So, I'm guessing that there's some
here. So, I'm guessing that there's some
screwy thing with the energy mechanic
screwy thing with the energy mechanic
because that's
because that's
like
like
Yeah. Okay. So, here is their latest
Yeah. Okay. So, here is their latest
thing. This is what it's supposed to
thing. This is what it's supposed to
look
look
like. Oh, no. This is really old
actually. Was cool to
watch. Yeah. So, clearly they're not
watch. Yeah. So, clearly they're not
like running around and actually
like running around and actually
doing
things. See if we can see anything about
things. See if we can see anything about
this model.
Okay, there like a bunch of different
Okay, there like a bunch of different
objects and things in here. Now, if we
objects and things in here. Now, if we
look at like the
agents, I mean, they're just
agents, I mean, they're just
like kind of spamming random
like kind of spamming random
stuff except movement.
Frozen is
Frozen is
zero. Why don't I see energy on
these? Click an agent to select it.
Interesting. Let's see some of the
Interesting. Let's see some of the
confict stuff they have in here.
So action failure
penalty. They have some very small
penalty. They have some very small
rewards here. And then this is the big
rewards here. And then this is the big
one, I
guess. Is there an episode length or is
guess. Is there an episode length or is
this thing just never reset?
alter. Okay. So, they have like
alter. Okay. So, they have like
configurable everything here.
I think I just have to start reading the
I think I just have to start reading the
end code honestly because
like I wouldn't be surprised that it's
like I wouldn't be surprised that it's
like this thing just preventing learning
like this thing just preventing learning
or some weirdo
shenanigans. Is this easier or harder to
shenanigans. Is this easier or harder to
learn than neural MMO 3?
would think it should probably be
would think it should probably be
easier. This should probably be easier.
Okay. So, here's their end. It's
Okay. So, here's their end. It's
tiny. They just have this little binding
tiny. They just have this little binding
which falls the siphon.
This is 228
This is 228
lines of
Syon. Okay, this is map
Syon. Okay, this is map
gen right here.
gen right here.
This is like C++ Sython map
gen. you happen to watch? I don't really
gen. you happen to watch? I don't really
watch much like TV to be honest with
watch much like TV to be honest with
you. Like I actually don't remember the
you. Like I actually don't remember the
last time I've really watched
last time I've really watched
TV.
TV.
Um, and I also really don't watch like
Um, and I also really don't watch like
AI related anything in media. Like
AI related anything in media. Like
actually knowing AI kind of ruins it all
actually knowing AI kind of ruins it all
for me.
Honestly, I'm happiest when I just
Honestly, I'm happiest when I just
freaking completely mute the Twitter
freaking completely mute the Twitter
feed, the like dumb like whatever
feed, the like dumb like whatever
popular media feed on like anything AI
popular media feed on like anything AI
and tech adjacent. I just kind of grind
and tech adjacent. I just kind of grind
out
work. You don't have to imagine what the
work. You don't have to imagine what the
future might look like when you can
future might look like when you can
create it and in the image that you
create it and in the image that you
want.
like here. Technically, what am I doing
like here. Technically, what am I doing
with this? Wasn't a simulated agent. So,
with this? Wasn't a simulated agent. So,
that was fun to watch. I don't know. We
that was fun to watch. I don't know. We
have lots of simulated agents here. So,
have lots of simulated agents here. So,
this end looks kind of toy because they
this end looks kind of toy because they
put very little effort into the graphics
put very little effort into the graphics
of it. But like even me doing stuff like
of it. But like even me doing stuff like
this, like if I can get this thing
this, like if I can get this thing
working better for them, this will
working better for them, this will
actually be a major powerhouse for a lot
actually be a major powerhouse for a lot
of like a lifestyle inspired research uh
of like a lifestyle inspired research uh
way way faster than most of that
way way faster than most of that
community is doing work and also with a
community is doing work and also with a
bit more practical RL stuff around it as
bit more practical RL stuff around it as
well. Like there's a a huge potential to
well. Like there's a a huge potential to
move very very quickly with all this
move very very quickly with all this
tech stuff right now. So I'm pretty
tech stuff right now. So I'm pretty
focused on that.
I did take like most of last night off
I did take like most of last night off
after 4,000 calorie Easter dinner, but
after 4,000 calorie Easter dinner, but
that doesn't happen too often.
Um, is this shared? Wait,
Um, is this shared? Wait,
share. This is false, right?
Okay, that looks
sketchy. Can they make new tools in the
sketchy. Can they make new tools in the
Sims? They don't talk to you, but like
Sims? They don't talk to you, but like
yeah, they like depending on the end.
yeah, they like depending on the end.
Tool use is not really anything special
Tool use is not really anything special
from an RL perspective. It kind of just
works. I don't know. Have you seen some
works. I don't know. Have you seen some
of the uh the stuff that we do around
of the uh the stuff that we do around
here? So like this, we have all our
here? So like this, we have all our
demos on puffer.ai. You can play them
demos on puffer.ai. You can play them
and you can watch agents play them. So
and you can watch agents play them. So
like this is this is probably my
like this is this is probably my
favorite M because this is based off of
favorite M because this is based off of
my thesis. So I can take over this guy
my thesis. So I can take over this guy
just by hitting control. And now I can
just by hitting control. And now I can
walk around and I can do
walk around and I can do
stuff. Um so these guys can like they
stuff. Um so these guys can like they
can
can
fight and then like oh look this guy
fight and then like oh look this guy
drops a tool. So, I can actually like
drops a tool. So, I can actually like
equip this tool. I can use this to now
equip this tool. I can use this to now
harvest materials that I wouldn't have
harvest materials that I wouldn't have
been able to get before. And like they
been able to get before. And like they
do different
do different
things. I can probably find like some
things. I can probably find like some
armor and
stuff. And now I have a helmet on. And
stuff. And now I have a helmet on. And
you can pick up weapons and all sorts of
you can pick up weapons and all sorts of
things. And you can actually buy and
things. And you can actually buy and
sell these things with all the other
sell these things with all the other
agents on a global marketplace. So like
agents on a global marketplace. So like
if I want to sell this leaf, I can hit
if I want to sell this leaf, I can hit
V, enter sell mode and then I can select
V, enter sell mode and then I can select
a price and now this will be offered on
a price and now this will be offered on
a market and any other agent can buy it.
a market and any other agent can buy it.
And if I hit
And if I hit
B and I look for this, you can see that
B and I look for this, you can see that
this thing is
this thing is
$4 because I put it on the market. So,
$4 because I put it on the market. So,
like we can build all sorts of fun
like we can build all sorts of fun
things for agents to play
things for agents to play
with. And the key about like this versus
with. And the key about like this versus
like this type of work versus the stuff
like this type of work versus the stuff
of like a lot of the other stuff that
of like a lot of the other stuff that
you see right now is how fast this stuff
you see right now is how fast this stuff
is. Um, like we can make these Sims run
is. Um, like we can make these Sims run
more than 10,000x real time on one CPU
more than 10,000x real time on one CPU
core. This thing right here, we've
core. This thing right here, we've
trained agents on like like thousands of
trained agents on like like thousands of
years worth of data. They've played like
years worth of data. They've played like
thousands of years worth of this. Um, so
thousands of years worth of this. Um, so
yeah, that's what I do around
here. I think they will wake
up. I mean, I'm going to be honest with
up. I mean, I'm going to be honest with
you, that type of stuff is like I spend
you, that type of stuff is like I spend
zero time thinking about.
And it's not like, oh, you should think
And it's not like, oh, you should think
about it. It's like it's kind of the
opposite. Like there's a lot of people
opposite. Like there's a lot of people
thinking about implausible AI safety
thinking about implausible AI safety
situations now and like zero people
situations now and like zero people
thinking about, but what if nanobots
thinking about, but what if nanobots
take over the world or like what are all
take over the world or like what are all
the other like classic
the other like classic
sci-fi disasters?
Like
Like
realistically, AI hasn't developed in
realistically, AI hasn't developed in
remotely the same way um that a lot of
remotely the same way um that a lot of
the like the older Hollywood films have
the like the older Hollywood films have
come up
come up
with. You notice the button to pick up
with. You notice the button to pick up
an item wasn't on the demo page.
Jason always posts things that don't
Jason always posts things that don't
really make sense. I have a suspicion
really make sense. I have a suspicion
that Jason, are you a large language
that Jason, are you a large language
model that is like working off of very
model that is like working off of very
janky audio like audio transcripts from
janky audio like audio transcripts from
the
video by chance?
Some of these posts don't make
sense. All
sense. All
right. Um, is this thing on by default?
right. Um, is this thing on by default?
self agents
self agents
size rewards of agent index is not zero
size rewards of agent index is not zero
then you share
rewards. Okay, so this whole freaking
rewards. Okay, so this whole freaking
thing is just sketchy,
right? Let me just like
Okay. I just want to see if that results
Okay. I just want to see if that results
in like a substantial change.
Oh, I got to wait for it to
Oh, I got to wait for it to
finish. Holy, that takes forever to
finish. Holy, that takes forever to
compile.
assumes the
assumes the
similar maybe not that specific
question. I don't know. I really don't
question. I don't know. I really don't
think too much about like
think too much about like
these I really don't take this
these I really don't take this
perspective on a lot of like tech and AI
perspective on a lot of like tech and AI
stuff.
stuff.
Because
Because
like a lot of these scenarios, you can
like a lot of these scenarios, you can
kind of just run off with
kind of just run off with
them and like you can come up with
them and like you can come up with
completely implausible things or not
completely implausible things or not
even necessarily implausible, but things
even necessarily implausible, but things
that just have no basis for
that just have no basis for
evidence. They're like not just based on
evidence. They're like not just based on
any evidence. And
any evidence. And
like there's been like a lot of caution
like there's been like a lot of caution
and hesitancy and fear I think around a
and hesitancy and fear I think around a
lot of AI lately in certain
lot of AI lately in certain
circles
circles
and it's not grounded but what is
and it's not grounded but what is
grounded is the like tremendous benefit
grounded is the like tremendous benefit
coming from AI right now.
coming from AI right now.
Um, so until there's like clear
Um, so until there's like clear
demonstrable
demonstrable
danger, right, I'm going to focus on
danger, right, I'm going to focus on
building the benefits, right? Building
building the benefits, right? Building
the the stuff that actually
the the stuff that actually
is quite
is quite
transformative, optimizing for
engagement. Well, that that's what I
engagement. Well, that that's what I
think that a lot of the fear-mongering
think that a lot of the fear-mongering
is for, though, right?
is for, though, right?
I mean, there was this post recently
I mean, there was this post recently
that I wrote like a long critique of
that I wrote like a long critique of
where they like they got like a
where they like they got like a
professional blogger involved like like
professional blogger involved like like
a like a well-known
a like a well-known
uh writer and they basically wrote this
uh writer and they basically wrote this
sci-fi fanfic on like how AI is going to
sci-fi fanfic on like how AI is going to
kill everyone and destroy the world or
kill everyone and destroy the world or
whatever. And like they got actual
whatever. And like they got actual
legitimate researchers to engage with it
legitimate researchers to engage with it
seriously. And I kind of just went like,
seriously. And I kind of just went like,
"No, these guys are just writing fanfic
"No, these guys are just writing fanfic
in order to like try to bait people into
in order to like try to bait people into
discussing stuff that doesn't make sense
discussing stuff that doesn't make sense
seriously with them. Like they've
seriously with them. Like they've
clearly wrote this entire thing through
clearly wrote this entire thing through
just one lens like they always do." Like
just one lens like they always do." Like
it has it's not even aligned with what's
it has it's not even aligned with what's
happened in AI already. So like I see a
happened in AI already. So like I see a
lot of this type of
lot of this type of
stuff. Friendship is optimal.
What? Friendship with
what? You definitely shouldn't like
what? You definitely shouldn't like
think of the AI the way you think of a
think of the AI the way you think of a
person. That would be a
mistake. Okay. How's this doing here?
friendship is optimal. Was that Oh, no.
friendship is optimal. Was that Oh, no.
It was the I don't even want to like
It was the I don't even want to like
link the thing cuz it's like I don't
link the thing cuz it's like I don't
want to give them more engagement, but
want to give them more engagement, but
it like flew around like I This is cuz
it like flew around like I This is cuz
the thing is this isn't even the first
the thing is this isn't even the first
time this has happened, right? There's
time this has happened, right? There's
like this group of people. It's like the
like this group of people. It's like the
less wrong crowd or like the effective
less wrong crowd or like the effective
altruism crowd or the whatever. It's
altruism crowd or the whatever. It's
like this weird SF cult.
like this weird SF cult.
Um, and they're also the ones that are
Um, and they're also the ones that are
involved in a lot of like the really
involved in a lot of like the really
really shitty lobbying to like shut down
really shitty lobbying to like shut down
all USI progress and stuff like that.
Um, it's a mistake to like engage with
Um, it's a mistake to like engage with
these people as if it's to engage with
these people as if it's to engage with
them honestly, so to speak, because
them honestly, so to speak, because
they're not engaging honestly. And I
they're not engaging honestly. And I
think that's where like a lot of the
think that's where like a lot of the
misguided attitudes around AI come from
misguided attitudes around AI come from
today is that they're optimized, right,
today is that they're optimized, right,
for like convincing non-technical
for like convincing non-technical
people, mostly non-technical people.
people, mostly non-technical people.
They get a few technicals as well um of
They get a few technicals as well um of
this like
this like
And I'm not here I'm not here
And I'm not here I'm not here
spending my time trying to counteract
spending my time trying to counteract
that for the most part, right? I'm here
that for the most part, right? I'm here
spending my time actually building the
spending my time actually building the
tech. So, when you're engaging in bad
tech. So, when you're engaging in bad
faith and you're not trying to build
faith and you're not trying to build
anything and you're just trying to like
anything and you're just trying to like
fearmonger, it's actually very easy to
fearmonger, it's actually very easy to
gain a lot of traction even if what
gain a lot of traction even if what
you're selling is complete
Um, because the people like there's not
Um, because the people like there's not
a counterparty, right?
Like my goal is to spend as little of my
Like my goal is to spend as little of my
time as possible on socials in the most
time as possible on socials in the most
amount of time possible building cool
Really, I'm only on socials at
Really, I'm only on socials at
all. Um because it helps me like grow
all. Um because it helps me like grow
the open source stuff and potentially
the open source stuff and potentially
get clients and
get clients and
stuff mostly for molecular dynamics.
stuff mostly for molecular dynamics.
See, now that's cool. That's cool stuff.
I don't know how like what the case I
I don't know how like what the case I
actually don't I didn't follow the alpha
actually don't I didn't follow the alpha
fold stuff even though it's really
fold stuff even though it's really
really cool but I don't know what the
really cool but I don't know what the
use case is for RL
use case is for RL
in like that level of sim. It really
in like that level of sim. It really
depends how fast the sims are. I know
depends how fast the sims are. I know
that they're very heavy, but uh in
that they're very heavy, but uh in
general
general
like RL is kind of the area of AI to
like RL is kind of the area of AI to
think about around hyperf
sim. Okay, so this doesn't seem like it
sim. Okay, so this doesn't seem like it
does worse.
So, I was just afraid that they could
So, I was just afraid that they could
This is like a really sketchy technique,
This is like a really sketchy technique,
but it doesn't seem to do anything in
but it doesn't seem to do anything in
this case. So, we'll leave that leave
this case. So, we'll leave that leave
that alone.
one is predicting experimental
one is predicting experimental
measurements from alpha pole structures.
measurements from alpha pole structures.
That's what I'm doing. That's
That's what I'm doing. That's
awesome. I actually like a lot of the
awesome. I actually like a lot of the
bioside sim stuff. there is a very real
bioside sim stuff. there is a very real
chance that that is what I get into uh
chance that that is what I get into uh
once I have well I say once I've solved
once I have well I say once I've solved
RL but realistically right once I've
RL but realistically right once I've
gotten RL into a place where everything
gotten RL into a place where everything
is stable and seems like it works which
is stable and seems like it works which
I actually do think is a realistic goal
I actually do think is a realistic goal
um like my longer term aspirations for a
um like my longer term aspirations for a
lot of this AI stuff like the my first
lot of this AI stuff like the my first
sort of wish list for Santa item here
sort of wish list for Santa item here
from AI is can we use AI to reverse
from AI is can we use AI to reverse
aging and like cure disease. Basically,
aging and like cure disease. Basically,
can
can
we I don't even want to say extend. I
we I don't even want to say extend. I
wanted I'd really just say can we like
wanted I'd really just say can we like
fix human
fix human
mortality? Like I see that as a problem
mortality? Like I see that as a problem
we can potentially fix. That's like the
we can potentially fix. That's like the
wacko crazy side thing that I think
wacko crazy side thing that I think
about. But I don't know. It seems like
about. But I don't know. It seems like
it is a solvable
it is a solvable
problem. I don't think there's anything
problem. I don't think there's anything
that's physically making it impossible.
So, that's about as sci-fi as we
get. So much low hanging fruit.
get. So much low hanging fruit.
Really, my my impression of a lot of the
Really, my my impression of a lot of the
um like molecular sim is it's very hard
um like molecular sim is it's very hard
to do stuff in because like the sims are
to do stuff in because like the sims are
so high fidelity that they're very slow.
so high fidelity that they're very slow.
Is that not the case?
Where is this
thing? Okay, so there these actions,
thing? Okay, so there these actions,
there's agent and then there's like n.
there's agent and then there's like n.
Okay, this is like super heavily
Okay, this is like super heavily
modularized, which is a little
modularized, which is a little
unfortunate.
also. Do I have a meeting today? Let me
also. Do I have a meeting today? Let me
see. I might have some meetings
today. Anytime after 1 p.m. So, we're
today. Anytime after 1 p.m. So, we're
good on that. Meeting is tomorrow, I
good on that. Meeting is tomorrow, I
believe. Other one
I'm trying to think
I'm trying to think
where this like freeze thing is. I
where this like freeze thing is. I
should just start grapping for stuff,
should just start grapping for stuff,
shouldn't
shouldn't
I? Like stuff that seems
suspicious. Depends how big your system
suspicious. Depends how big your system
is. Romax is pretty quick as well as
is. Romax is pretty quick as well as
Open MM huge opportunity to make these
Open MM huge opportunity to make these
better. Yeah. So, that's like stuff that
better. Yeah. So, that's like stuff that
I would actually seriously be interested
I would actually seriously be interested
in being involved in. I don't know if
in being involved in. I don't know if
you have RL use cases for any of this.
you have RL use cases for any of this.
Um, but if you think that you might or
Um, but if you think that you might or
even if you're just interested in like
hyperfac out some of the stuff in the
hyperfac out some of the stuff in the
Puffer Discord and some of the stuff
Puffer Discord and some of the stuff
we're doing,
we're doing,
um, we're pretty good at making stuff
um, we're pretty good at making stuff
fast. I will
fast. I will
say we uh we haven't really done super
say we uh we haven't really done super
highfidelity stuff yet like we haven't
highfidelity stuff yet like we haven't
done Perf engineering on that yet but if
done Perf engineering on that yet but if
our other work has any indication like
our other work has any indication like
people in RL generally write really slow
people in RL generally write really slow
bad SIM code and ours are up to 10,000x
bad SIM code and ours are up to 10,000x
faster I think actually some of them are
faster I think actually some of them are
even more than
even more than
that we're just like writing stuff in a
that we're just like writing stuff in a
really simple C with uh no dynamic
really simple C with uh no dynamic
memory allocations
memory allocations
And we've had a lot of success doing
And we've had a lot of success doing
that.
So this is not in here unless I'm doing
So this is not in here unless I'm doing
this
wrong. Machinele learn force
fields background is in chemistry. I
fields background is in chemistry. I
don't know if I'll be able to understand
don't know if I'll be able to understand
what's going on. So, one of the cool
what's going on. So, one of the cool
things, right, about what we do is it's
things, right, about what we do is it's
very, very accessible. We do stuff in a
very, very accessible. We do stuff in a
way that's way simpler and way more
way that's way simpler and way more
accessible than most other things. And
accessible than most other things. And
let's keep up the work. Good work. Nice
let's keep up the work. Good work. Nice
chatting. Nice chatting with you, too.
chatting. Nice chatting with you, too.
Always cool to see uh people doing
Always cool to see uh people doing
interesting stuff dropping by stream.
Okay, so these are just in the configs
Okay, so these are just in the configs
it looks
it looks
like. Do these not do anything?
So there are teams
Oh, this does have a max steps. Hang
Oh, this does have a max steps. Hang
on. I think what we're going to do, let
on. I think what we're going to do, let
me just try some of my
me just try some of my
usual my usual tricks, right? Like
usual my usual tricks, right? Like
things that usually screw with RL
things that usually screw with RL
dynamics.
Can we even Hang
on. I think we'll do 128 steps. Then it
on. I think we'll do 128 steps. Then it
should line up
should line up
nicely. Try this.
If it doesn't change the curves, then
If it doesn't change the curves, then
I'm going to get like start getting
I'm going to get like start getting
suspicious about whether this config
suspicious about whether this config
does anything, right?
Okay, this is maybe doing something a
Okay, this is maybe doing something a
bit different. We'll see.
It's also possible the act the uh the
It's also possible the act the uh the
model and hypers are just like not good.
model and hypers are just like not good.
So that could just make the curve
So that could just make the curve
slower. I guess we really just care
slower. I guess we really just care
about the shape,
right? It would be very weird if
um if this didn't m change
um if this didn't m change
anything, right?
Okay. Yeah, there's something weird here
Okay. Yeah, there's something weird here
for
for
sure. Max
steps. I suspect some of these just
steps. I suspect some of these just
aren't getting used.
Okay, so there's no max steps in meta.
Okay, so there's no max steps in meta.
What about in meta grid?
Config.max
steps fourth param grid
steps fourth param grid
end grid
end metagrid grid
This doesn't trigger a
reset. This doesn't appear to trigger a
reset. This doesn't appear to trigger a
reset.
so this is just calling metag
Stop. Is this the init? This is the
Stop. Is this the init? This is the
init render grid
init render grid
objects. Here's step.
objects. Here's step.
So, this doesn't have a
reset. There's also
reset. There's also
this. Does this have a
this. Does this have a
reset? This has a step.
reset? This has a step.
Uh this does have a
Uh this does have a
reset. Cannot reset after. Okay. So this
reset. Cannot reset after. Okay. So this
thing cannot be
thing cannot be
reset after
reset after
stepping. It's
interesting. So yeah, what's happening
interesting. So yeah, what's happening
is it's not getting used.
I think we need to just like
inject some sort of thing into Yes.
So I guess this is
um Where's D.Pi?
Reset
See if this does
See if this does
anything. Yeah, definitely nothing is
anything. Yeah, definitely nothing is
happening with a lot of these
params. Ah, okay. Okay. So, we do
params. Ah, okay. Okay. So, we do
actually
get Yeah. So, that actually did hit
But there was an episode length before,
But there was an episode length before,
wasn't
there? That just kept going straight up.
there? That just kept going straight up.
It was never getting
reset. So possibly This is going to be
reset. So possibly This is going to be
lower, but the policy might be
better. Okay, what stats do we have in
here? Let's actually see.
here? Let's actually see.
Let's see what stats we get of
Let's see what stats we get of
this. So, attack
action. First use
So much stuff.
Yeah, there are just too many damn uh
Yeah, there are just too many damn uh
too many damn metrics.
Okay, here's something. I think that
Okay, here's something. I think that
this one's important.
that this one matches.
cosine and kneeling
here. It shouldn't be cosine and
here. It shouldn't be cosine and
kneeling back up to
kneeling back up to
uh the star. That's kind of weird.
loss is very
different.
So this
Trying to think what are good
metrics. Isn't it like convert or
metrics. Isn't it like convert or
something?
There's this
sum which is also
lower. Hang on. Isn't the sum is over
lower. Hang on. Isn't the sum is over
the whole episode? So, this episode is
the whole episode? So, this episode is
way
way
shorter and it's getting the same reward
presumably and the end is now slower.
presumably and the end is now slower.
So, it is resetting.
Maybe this does
Maybe this does
something. We will see.
What's the meta m? Hey captain, how's
What's the meta m? Hey captain, how's
impulse Impulse 4 is uh going by the
impulse Impulse 4 is uh going by the
way? We would love to have some more
way? We would love to have some more
complex M benchmarks pretty soon
complex M benchmarks pretty soon
here. It' be nice to get that
here. It' be nice to get that
integrated.
Um, so this is
Um, so this is
meta. This is third partyish. I mean, it
meta. This is third partyish. I mean, it
is a native puffer m, so we'll call it a
is a native puffer m, so we'll call it a
collaboration environment, though.
collaboration environment, though.
Really, they're doing the end and we
Really, they're doing the end and we
just have puffer.
Um, it is like
Um, it is like
this not really factorioesque, but it's
this not really factorioesque, but it's
like this like factoryish type end thing
like this like factoryish type end thing
where it's supposed to be open-ended and
where it's supposed to be open-ended and
like their different resources and
like their different resources and
resource converters and energy and
resource converters and energy and
things. Um, and the agents are just
things. Um, and the agents are just
supposed to come up with a bunch of
supposed to come up with a bunch of
interesting
interesting
strategies. We're currently trying to
strategies. We're currently trying to
see if I can get it to learn something
see if I can get it to learn something
interesting.
busy all weekend. Now I'm going to start
busy all weekend. Now I'm going to start
sweep with basic CL.
Cool. Ah, these actually do something
now. Like these guys actually do
now. Like these guys actually do
something.
Oh yeah, he just used the
converter. If it help you. I could try
converter. If it help you. I could try
to get impulse for soon before I have a
to get impulse for soon before I have a
good
good
baseline. Well, I just generally think
baseline. Well, I just generally think
that getting it merged is going to help
that getting it merged is going to help
you overall because you can test like
you overall because you can test like
whatever you're trying to test. It's
whatever you're trying to test. It's
generally a bad thing to just test it on
generally a bad thing to just test it on
the one end, right? Like the whole point
the one end, right? Like the whole point
of puff is you have access to all these
of puff is you have access to all these
different ends. So when you're trying
different ends. So when you're trying
stuff, you can see does it work on every
stuff, you can see does it work on every
end except impulse wars, right? Does it
end except impulse wars, right? Does it
work only on impulse wars? like you can
work only on impulse wars? like you can
get a a much better feel for things.
C policy code. It doesn't need the C
C policy code. It doesn't need the C
policy code before we put it to dev,
policy code before we put it to dev,
man. It's
man. It's
fine. We're also I there's one thing
fine. We're also I there's one thing
that I want to look into. So apparently
that I want to look into. So apparently
Tinyrad has a um Tiny has a
Tinyrad has a um Tiny has a
C backend for PyTorch where you can
C backend for PyTorch where you can
generate C code from PyTorch models. If
generate C code from PyTorch models. If
that works, we could potentially jam
that works, we could potentially jam
that
thumb is the There.
Okay, so this does something
What's the policy on this
thing? Pretty similar to neural MMO, I
thing? Pretty similar to neural MMO, I
guess.
This does
five. So we'll use Bur
MMO.
Could this be? This should be like 3.1
Could this be? This should be like 3.1
mil, right?
mil, right?
Is
Is
2.4. Is that
correct? Should that be smaller?
does have a current on
it. I guess there's a big linear layer
it. I guess there's a big linear layer
channel difference.
because you do this hidden size over two
because you do this hidden size over two
thing. Okay.
So that's like running at the same speed
So that's like running at the same speed
pretty much, right?
It's running the same
speed. We'll see if it does
worse. I believe I put the layer norm
worse. I believe I put the layer norm
after
after
uh this hidden here as
uh this hidden here as
well for nurmo3. Great.
very low entropy.
You know, I bet you that there is
You know, I bet you that there is
um a pretty
um a pretty
substantial shift in param optimals now
substantial shift in param optimals now
that I screwed with the
that I screwed with the
horizon. I bet you that gamma goes down
horizon. I bet you that gamma goes down
to something that you would expect it to
to something that you would expect it to
be.
Let's just like comment all these neural
Let's just like comment all these neural
MMO crs and let's work off of these. I
MMO crs and let's work off of these. I
think we can probably make some uh some
think we can probably make some uh some
progress now way way faster.
Interestingly, is the episode reward
Interestingly, is the episode reward
mean just like
stuck? Yeah. So, it doesn't train with
stuck? Yeah. So, it doesn't train with
the bigger
model.
Probably try learning rate fix real
Probably try learning rate fix real
quick.
Okay, they definitely need to fix the
Okay, they definitely need to fix the
freaking mu on thing. So, um, optimal
freaking mu on thing. So, um, optimal
learning rate stays. Can I just go check
learning rate stays. Can I just go check
zero shot hyper param transfer thing?
zero shot hyper param transfer thing?
What is the rough expected
change? Optimum
shifts. Is it
linear? It looks to be roughly linear,
linear? It looks to be roughly linear,
right? Factor of twoish.
So what I did should be roughly
correct. Okay, that looks reasonable,
correct. Okay, that looks reasonable,
right?
Oh yeah, that's
good. Yeah, I think if I just kind of
good. Yeah, I think if I just kind of
sit here for another hour and like
sit here for another hour and like
fiddle with this, I think I'll get
fiddle with this, I think I'll get
something reasonable out of this
something reasonable out of this
end as like a starting point.
Okay. So, this is about on par with the
Okay. So, this is about on par with the
current one so
far. Oh, it's better. Okay. So, yeah,
far. Oh, it's better. Okay. So, yeah,
the learning rate thing actually does
the learning rate thing actually does
need to be tuned annoyingly.
Um, yeah, it does need to be
tuned. Yell the optimizer, guys.
Oh, this is actually quite good,
Oh, this is actually quite good,
right? So, this is compared to these.
right? So, this is compared to these.
This is like
This is like
a 128 length episode or
whatever. This seems good.
and then likely plateaus off here.
Next up to try will
Next up to try will
be I want to see if this looks like it's
be I want to see if this looks like it's
doing anything
doing anything
first and then I guess we can try like
first and then I guess we can try like
layer
layer
shenanigans. Um what other things do I
shenanigans. Um what other things do I
have? We could try longer episode
have? We could try longer episode
lengths. 128 could be too short I would
lengths. 128 could be too short I would
think.
think.
[Music]
[Music]
Probably the best thing is to line it up
Probably the best thing is to line it up
with the uh the actual batch,
with the uh the actual batch,
right? Line it up with the batch size
maybe, which I think is only 64 right
maybe, which I think is only 64 right
now, isn't
it? So, it's like
it? So, it's like
256 M* 16 agents.
4096. So we have like was
4096. So we have like was
it this our batch size by
it this our batch size by
23? Oh no it is 128 perfectly. So yeah
23? Oh no it is 128 perfectly. So yeah
this does already then line up uh
this does already then line up uh
perfectly. So we could do the BPT
perfectly. So we could do the BPT
horizon. I think gamma probably gamma is
horizon. I think gamma probably gamma is
going to
going to
be a good param to
be a good param to
change.97's not terrible
actually could be too
actually could be too
high. I think 97 should be fine.
high. I think 97 should be fine.
can change the BPT horizon
potentially. Uh mini batch size
potentially. Uh mini batch size
potentially can be
upped. We have some stuff to try here
upped. We have some stuff to try here
for
for
sure. How's this
doing? Kind of goes down towards the
doing? Kind of goes down towards the
end. The cosine and kneeling might be
end. The cosine and kneeling might be
screwing with it to be
screwing with it to be
honest. Cosine and kneeling might need
honest. Cosine and kneeling might need
uh some
uh some
tuning. This probably what it is frankly
Okay, this is at least like a nice
Okay, this is at least like a nice
consistent
curve. Bigger model does better. Good.
curve. Bigger model does better. Good.
That is what we want.
128 steps should kind of be fine to
128 steps should kind of be fine to
learn dynamics in this
end. Three
Okay. Agents running around doing stuff.
I do want to throw a layer norm in real
I do want to throw a layer norm in real
quick just to see because it was a
quick just to see because it was a
pretty decent bump for neural MMO
3. We did it right here, right?
decode
actions. See if this does
actions. See if this does
anything. We have to change
We try
this other things that help neural MMO.
this other things that help neural MMO.
I'm
thinking self
encoder probably this is already going
encoder probably this is already going
to be a decent start.
Now the one thing we don't like to see
Now the one thing we don't like to see
here is the uh the curves seem kind of
here is the uh the curves seem kind of
flat. I do wonder if this is the cosine
flat. I do wonder if this is the cosine
and kneeling being weird
though. This could very well be cosign
though. This could very well be cosign
and just being screwy.
We will deal with
that. I might just disable it
that. I might just disable it
temporarily to be honest.
substantially
worse. Interesting.
Well, curvature is still convex, so
Well, curvature is still convex, so
we'll let it go a bit.
I suspect
I suspect
um we're going to have to for these
um we're going to have to for these
shorter runs disable the annealing
Yeah, that's going to
level that ought to do something. You
level that ought to do something. You
would
think this
No
annealing. Make sure this is
running. Okay, be right back. I'm going
running. Okay, be right back. I'm going
to use the restroom. We will continue
to use the restroom. We will continue
experiments.
Okay, that looks promising,
right? It's on par with the current the
right? It's on par with the current the
uh the previous one. Right now we will
uh the previous one. Right now we will
see whether uh the thing I want to know
see whether uh the thing I want to know
basically is whether this ends up
basically is whether this ends up
getting a more log like curve as a
getting a more log like curve as a
result because
result because
uh because it doesn't like screw with
uh because it doesn't like screw with
the learning rate at the end. That's
the learning rate at the end. That's
what I want to
what I want to
know. And then let me think what else we
know. And then let me think what else we
can potentially do with this thing other
can potentially do with this thing other
than just keep increasing policy size
than just keep increasing policy size
and whatnot.
I guess we can start looking at these
I guess we can start looking at these
metrics and trying to like the thing is
metrics and trying to like the thing is
they log way too much crap, right? They
they log way too much crap, right? They
log like way too much crap. There is
log like way too much crap. There is
such a thing as too much
such a thing as too much
logging. So I think this green
logging. So I think this green
[Music]
curve. Okay, here's the attack. first
curve. Okay, here's the attack. first
use
use
whatever. Not really attacking stuff.
Yeah. So like these metrics go up over
Yeah. So like these metrics go up over
time because like the agent just they
time because like the agent just they
can't not go up. Like the agent has
can't not go up. Like the agent has
infinite time to do
infinite time to do
stuff. So the only thing I can
stuff. So the only thing I can
potentially think is
potentially think is
that 128 steps might be too
that 128 steps might be too
short. We might have to go to like 256
short. We might have to go to like 256
or
or
something. So this is nice and
something. So this is nice and
consistent, right? This this is actually
consistent, right? This this is actually
where the reward comes from. It seems is
where the reward comes from. It seems is
this part
conversion, but doesn't
conversion, but doesn't
really do this step of the
really do this step of the
conversion. It's got to get this step
next. And then a red or
next. And then a red or
doesn't really bother with this,
doesn't really bother with this,
right? This is
like might need some rewards for this or
whatever. I have really small rewards on
whatever. I have really small rewards on
some of this right
now. The approach scale is crazy.
Okay.
Well, I'll stick to this for
now and uh we will basically
now and uh we will basically
see what happens towards the end of this
see what happens towards the end of this
graph. I believe it anneals the learning
graph. I believe it anneals the learning
rate down to like zero at and a
rate down to like zero at and a
half and then it anneals it back
half and then it anneals it back
up. So if this gives us like a cleaner
up. So if this gives us like a cleaner
log curve then that's what we will be
log curve then that's what we will be
looking
looking
for. If it's flat as well then well I
for. If it's flat as well then well I
don't
know. But this so far looks a little
know. But this so far looks a little
better maybe.
I think 256 steps would be the next
I think 256 steps would be the next
thing to try
maybe. Let me
see. I mean, we can try 56
steps. Yeah, I think that's the most
reasonable of the things that we can
reasonable of the things that we can
try.
And then there are the conversion
rewards. Probably those just need to be
given. Okay. So, it still levels off
given. Okay. So, it still levels off
pretty well
here, but it's also like out of time to
here, but it's also like out of time to
do actions. Though, to be fair, it's
do actions. Though, to be fair, it's
almost certainly can do better than
this. So, we'll give it twice as long to
this. So, we'll give it twice as long to
do action. We'll see if it
do action. We'll see if it
gets
gets
[Music]
[Music]
well. Hang
well. Hang
on. This is all coming just from the
on. This is all coming just from the
heart. Right. So, like if it knows how
heart. Right. So, like if it knows how
to do that one thing, it's not going to
to do that one thing, it's not going to
get any better because that's the only
get any better because that's the only
thing that's being
rewarded. But there was a gap from here
rewarded. But there was a gap from here
to here. So maybe there is still some
room. I think I can go to what's
room. I think I can go to what's
this 75 mil at
this 75 mil at
least or 75
least or 75
mil slightly shorter experiments
If this does not do substantially
If this does not do substantially
better, then we'll just go back to 128
better, then we'll just go back to 128
and assume that there's not that much
and assume that there's not that much
that it can learn to do uh in 256 steps,
that it can learn to do uh in 256 steps,
but not in
but not in
128. Horizon is usually a major thing
128. Horizon is usually a major thing
though, like with new RLMs. It's like
though, like with new RLMs. It's like
one of the most common things people get
one of the most common things people get
wrong.
wrong.
So, I figured that this was a good one
So, I figured that this was a good one
to start
with. Okay, this red curve is pretty
with. Okay, this red curve is pretty
decent.
This has got to be
This has got to be
like the things respawn eventually or
like the things respawn eventually or
something,
something,
right? Like what else would it
right? Like what else would it
be? Where's like
be? Where's like
heart? Is this a
thing
objects red
objects red
generator? Okay. Input battery
generator? Okay. Input battery
three. Output heart
one. Part
one. Part
one. Max five.
These rewards seem really
small. I'm going to mess with those
small. I'm going to mess with those
next.
Okay, so so far this curve just matches
Okay, so so far this curve just matches
and doesn't do any better with 256 than
and doesn't do any better with 256 than
with
128. We'll see whether this trend
continues. We would expect it to do a
continues. We would expect it to do a
bit better. If it doesn't do
bit better. If it doesn't do
better, then that would imply that
better, then that would imply that
basically there's not much for these
basically there's not much for these
guys to do
guys to do
uh with 128 versus
uh with 128 versus
otherwise. And then these things like
otherwise. And then these things like
yeah, eventually items will respawn and
yeah, eventually items will respawn and
stuff like that, I guess. But I mean,
stuff like that, I guess. But I mean,
these guys have like ludicrous amounts
these guys have like ludicrous amounts
of time to do whatever and they still
of time to do whatever and they still
are not like going up linearly.
Okay, so this seems pretty
damning. We will let it keep running a
damning. We will let it keep running a
bit,
bit,
but so far no
but so far no
difference with
Let's just check these fit like
Let's just check these fit like
perfectly. They're just scaled, right?
perfectly. They're just scaled, right?
Yeah, these fit perfectly. They're just
Yeah, these fit perfectly. They're just
scaled.
This probably just isn't an end where
This probably just isn't an end where
there's like much to do for very long,
there's like much to do for very long,
right? At least in the current
right? At least in the current
form. You kind of just chuck all your uh
form. You kind of just chuck all your uh
your stuff in the altar or whatever and
your stuff in the altar or whatever and
you call it a day.
Let's add them like some real rewards
Let's add them like some real rewards
for stuff.
So, this should just have a higher
So, this should just have a higher
curve, but that's not what we're after
curve, but that's not what we're after
here, right? The thing that we're going
here, right? The thing that we're going
to be after is whether the curve uh
to be after is whether the curve uh
stays flat for the same time or if it
stays flat for the same time or if it
like if it keeps learning for longer.
basically. Okay. So
basically. Okay. So
immediately this is going to be way
immediately this is going to be way
steeper
How to tackle building impulse
wars. Jeez,
man. Come up with something for now and
man. Come up with something for now and
then we'll figure out what the heck to
then we'll figure out what the heck to
do from there.
Okay, so this is like crazy higher
curve, but this is the magnitude doesn't
curve, but this is the magnitude doesn't
tell us anything, right? We need to know
tell us anything, right? We need to know
the the slope
can just commit the
cmake. Can you commit the cmake without
cmake. Can you commit the cmake without
breaking the build stuff or all the
breaking the build stuff or all the
other MS that are like the way they are
other MS that are like the way they are
at the
moment? Is that a thing?
and then we figure out what we do later
and then we figure out what we do later
for
this something dirty. I can commit cmake
this something dirty. I can commit cmake
without touching setup.py. So build.
without touching setup.py. So build.
Yeah, just do that. That's
fine. That's fine.
fine. That's fine.
As long as we can run it and actually
As long as we can run it and actually
like get experiments on this Okay.
need to double check site buying still
need to double check site buying still
working on dev tip. Gotcha.
This has got to be a new capability
This has got to be a new capability
right here, right? This like divot
about
here. So extends the learning process
here. So extends the learning process
like 50%age.
Yeah, they seem to be running around and
Yeah, they seem to be running around and
doing
something. I think these are alters or
something. I think these are alters or
whatever.
Where are the batteries? Is this a
Where are the batteries? Is this a
battery? Yeah, this is the
battery. And this is armor.
I mean, they're doing
I mean, they're doing
something. I don't know the game well
something. I don't know the game well
enough yet.
probably red ore or whatever, right? Oh,
probably red ore or whatever, right? Oh,
no. This is a
no. This is a
heart. So, they go collect this
heart. So, they go collect this
thing. Yep. So, this is going to collect
thing. Yep. So, this is going to collect
this.
So they know to collect the
hearts, the batteries, I
suppose. I don't know what to do after
suppose. I don't know what to do after
that really.
I mean, I'm seeing them running around
I mean, I'm seeing them running around
and doing stuff now, right? Collecting
and doing stuff now, right? Collecting
stuff or whatever.
Okay. Anything else I can do right now?
Okay. Anything else I can do right now?
I'm thinking
Let's just do something
like should do like this.
probably this breaks it,
probably this breaks it,
right? I want to see
Probably this just doesn't burn,
right? Yeah, it's just going to stand
right? Yeah, it's just going to stand
there and not do anything.
Okay. Anything else I can do on this at
Okay. Anything else I can do on this at
the moment? I guess I can check the
the moment? I guess I can check the
policy.
See uh does this
See uh does this
code do anything?
Is this already one
hot or is this
hot or is this
already? Yeah, these are already like
already? Yeah, these are already like
one hot I think.
for the most
for the most
part. So then this should be
part. So then this should be
okay the way that this is
I think that this should be okay the way
I think that this should be okay the way
this is. There's nothing like getting
this is. There's nothing like getting
encoded
weirdly. Okay. I think what we're going
weirdly. Okay. I think what we're going
to do then is I'm just going to guess
to do then is I'm just going to guess
one more. I'll just guess some params
one more. I'll just guess some params
based on the neural MMO ones. We'll do
based on the neural MMO ones. We'll do
one more experiment and then we'll see
one more experiment and then we'll see
uh we'll see what we do after. And we'll
uh we'll see what we do after. And we'll
do this. I'll get some food. I'll get
do this. I'll get some food. I'll get
some exercise. And then I'll see what I
some exercise. And then I'll see what I
do after for the rest of the
day. Bigger mini batch
size. Lower lambda
gamma entropy.
I guess the only thing I kind of want to
I guess the only thing I kind of want to
try is the mini
try is the mini
batch. Mini batches being like really
batch. Mini batches being like really
really low is kind of
awkward. So we'll try the neural MMO
awkward. So we'll try the neural MMO
mini batch
mini batch
size. And uh I maybe this does
size. And uh I maybe this does
something. Probably not.
something. Probably not.
We'll just give it a little bit of time
We'll just give it a little bit of time
on the early
curve. Is the gamma really
high? It's probably like Okay.
probably just learn slower, right?
Yeah, we'll give it like extra 10 mil or
Yeah, we'll give it like extra 10 mil or
whatever.
If it has a different shape, then
If it has a different shape, then
that'll be interesting.
that'll be interesting.
But other than that,
um probably nothing to see.
It seems like it is going to have the
It seems like it is going to have the
same like tapered shape
though. It's kind of
though. It's kind of
screwy. It's a pretty batch size for
screwy. It's a pretty batch size for
learning something like this.
Okay, this is what we were hoping for.
Even if it just matches, it's better
Even if it just matches, it's better
because this is a faster training
because this is a faster training
config.
Don't tell me this actually levels out
Don't tell me this actually levels out
lower.
kind of a weird
result. Would that imply that this thing
result. Would that imply that this thing
needs more
needs more
entropy? Actually, entropy is very low
entropy? Actually, entropy is very low
in
this which would make it quite difficult
this which would make it quite difficult
for it to learn
for it to learn
much because this is entropy over like a
much because this is entropy over like a
big multi-discretet.
It's just about on
par. Okay. like very slightly lower, but
par. Okay. like very slightly lower, but
we are going to need the bigger mini
we are going to need the bigger mini
batch if we try bigger horizons.
batch if we try bigger horizons.
The one thing I did want to try next was
The one thing I did want to try next was
longer
horizons. This I'm not going to give as
horizons. This I'm not going to give as
much time to. This is not better
much time to. This is not better
early. It's probably not better. I still
early. It's probably not better. I still
want to try a couple things with the
want to try a couple things with the
gamma and whatever.
This is going to
break. Thought we had uh I thought we
break. Thought we had uh I thought we
had this fine.
And imagine that helps
actually. We could just yolo the magic
actually. We could just yolo the magic
neural MMO parameters onto
it. Might
it. Might
work. And then presumably
859. Yeah.
859. Yeah.
Okay. You can try
that. I actually do kind of just want to
that. I actually do kind of just want to
yellow onto it and
see. Okay. So, that's worse.
Undo
Undo
that. Keep this as
is. Lay num m is
is. Lay num m is
two. Does this not work? This should
two. Does this not work? This should
work, right?
This breaks. Interesting enough. Do I
This breaks. Interesting enough. Do I
not have as many as I think I
do? Because of XP buffer bug. Ah, so I
do? Because of XP buffer bug. Ah, so I
have half the number of M's right
now. Okay.
now. Okay.
So we have to do was
it if I do
it if I do
this how's this work
It's fast.
some is stuck
low. There we go.
If it can match this blue curve, I think
If it can match this blue curve, I think
that would be
good. So far it does.
This gives you more frequent logging as
This gives you more frequent logging as
well. Just a nice little
bonus. Okay, we're at 12, which is like
bonus. Okay, we're at 12, which is like
the
the
first block.
If this performs decently enough, we
If this performs decently enough, we
yolo the rest of the params
yolo the rest of the params
on and then that will be last experiment
on and then that will be last experiment
for morning.
Okay. So, slightly worse than the larger
Okay. So, slightly worse than the larger
batch, smaller mini batch
batch, smaller mini batch
seems, but not by much.
Well, it works okay enough that I kind
Well, it works okay enough that I kind
of just want to try this real quick.
of just want to try this real quick.
It would kind of be a miracle if it did
It would kind of be a miracle if it did
anything, but uh you
anything, but uh you
know, we can try it.
The gamma from neural3 in particular
The gamma from neural3 in particular
makes no
makes no
sense,
but it works. And like the design of the
but it works. And like the design of the
MS is not that different.
The question is going to be which one of
The question is going to be which one of
these actually mattered
these actually mattered
um and does this actually get the same
convergence and also if we go back to
convergence and also if we go back to
the original batch and mini batch the
the original batch and mini batch the
better
We could kind of just sweep this,
We could kind of just sweep this,
right? We just do like a 75 mil
sweep. What is score in here?
score is a nice
variable. Just normalized whatever one
variable. Just normalized whatever one
of the other ones
of the other ones
is. So, this actually
is. So, this actually
does collide with this at some point. It
seems kind of
expected. Okay. Well, this is what we'll
expected. Okay. Well, this is what we'll
do. We'll go back to
this. I think this was our
favorite. But then we will start a short
favorite. But then we will start a short
sweep.
So, these are a bunch of reasonable
So, these are a bunch of reasonable
params. Oh, I bet that uh sweeps are
params. Oh, I bet that uh sweeps are
going to be totally screwed up though
going to be totally screwed up though
with the latest uh yeah, the
with the latest uh yeah, the
CUDA. So, what we'll do is we'll leave
Why don't we just leave batch and mini
Why don't we just leave batch and mini
batch
alone? We leave these like well enough
alone? We leave these like well enough
alone,
right? Just see if there's like any
right? Just see if there's like any
output in the rest of these.
admittedly is not very many but learning
admittedly is not very many but learning
rate entropy gamma
lambda we don't want this
lambda we don't want this
either just some of the coefficients I
either just some of the coefficients I
Yes.
Yeah, I'll just do
this. Okay, this one fails.
I think that this should
I think that this should
work. So, I go get
work. So, I go get
breakfast. I do a few things. These
breakfast. I do a few things. These
should take like 5 minutes a piece. So,
should take like 5 minutes a piece. So,
we should
get some reasonable number of
get some reasonable number of
experiments.
Make sure this actually
runs there. Okay, so this
runs there. Okay, so this
runs. So now we should have the sweep
runs. So now we should have the sweep
going. If I open this
tab, yep, we got this sweep
tab, yep, we got this sweep
going. So we will be able to see where
going. So we will be able to see where
this goes from here. And then uh I will
this goes from here. And then uh I will
be back later today probably working on
be back later today probably working on
poor puffer, other things around
poor puffer, other things around
that. Um yeah.
that. Um yeah.
This will be a nice end once we start to
This will be a nice end once we start to
get some really like decent results on
get some really like decent results on
it. So, uh, thanks for tuning in, folks.
it. So, uh, thanks for tuning in, folks.
All my stuff's at
All my stuff's at
puffer.ai. If you want to help the
puffer.ai. If you want to help the
project for free, start the GitHub.
project for free, start the GitHub.
Other than that, you can get involved
Other than that, you can get involved
with Dev on the Discord or follow me on
with Dev on the Discord or follow me on
X for more RL content. Thanks. And I
X for more RL content. Thanks. And I
will be back later

Kind: captions
Language: en
We're live. Good
We're live. Good
morning. Seems like it's
morning. Seems like it's
moved. Put this
hereish. Plan right now is get meta
hereish. Plan right now is get meta
working. See if we can figure out that
working. See if we can figure out that
environment. We will see from
environment. We will see from
here. No attribute render.
here. No attribute render.
I believe I was sent instructions on how
I believe I was sent instructions on how
to fix
this. Oh, actually I was sent uh was
this. Oh, actually I was sent uh was
sent something. Hang on.
Perfect. So, let me see what I was
sent.
sent.
Ah, it
is it is this I believe.
No, hang
on.
This. Yeah. So, it is pretty close to
This. Yeah. So, it is pretty close to
what we were
what we were
seeing. We just need this wrapper.
I grab these
I grab these
additional additional bits
out.
Think that should be
it. Oh, there we go. Uh, there
it. Oh, there we go. Uh, there
are two of
are two of
them, but this
them, but this
does actually seem to do stuff.
doesn't have scaling or
anything. Oh, it does have zoom though.
Perfect. Okay, so I'm noticing these
Perfect. Okay, so I'm noticing these
guys mostly not doing much.
Let's uh let's just train something and
Let's uh let's just train something and
see what they
do. And I think actually the way to do
do. And I think actually the way to do
this we'll do like this,
right? Client
whatever.
That doesn't seem like it
works. So, we'll do it this
works. So, we'll do it this
way and we'll just
do Hey, welcome
do Hey, welcome
Adrian. Okay, let's just uh figure out
I just have to make sure I can get it to
I just have to make sure I can get it to
both run and
both run and
render. Then we can get some experiments
going. I train with it.
Okay, that should do it. And then we'll
Okay, that should do it. And then we'll
just have to specify render mode,
just have to specify render mode,
right? Cuz so this won't do anything.
right? Cuz so this won't do anything.
And
And
then render mode.
There we go. So now this does seem to
render.
render.
Okay, these guys don't really move
Okay, these guys don't really move
around very much.
800k
800k
per.
per.
Okay, so this now
Okay, so this now
runs 500
runs 500
kPS. We will see what this does.
I
I
actually want to do a full run of just
actually want to do a full run of just
mil. Yeah, let's do this. We'll let this
mil. Yeah, let's do this. We'll let this
fully run. Uh, and then we will see what
fully run. Uh, and then we will see what
this thing has learned. I'm going to try
this thing has learned. I'm going to try
to learn a little bit more about the
to learn a little bit more about the
environment. I might look through the
environment. I might look through the
end code. We'll go with that.
With this config, the end is actually
With this config, the end is actually
pretty decently uh fast.
pretty decently uh fast.
Not optimal batching,
but
but
decent fair bit of copy
decent fair bit of copy
overhead. Forward is higher than it
overhead. Forward is higher than it
should be because of the quad
buffering. I guess we could try
buffering. I guess we could try
um we could try like double buffered or
um we could try like double buffered or
something with this.
something with this.
Technically, I haven't done that. We can
Technically, I haven't done that. We can
maybe try that
next. The issue here, right, is like
next. The issue here, right, is like
this M should be fast, but it's not like
this M should be fast, but it's not like
quite as fast as they would like it to
be. So, um that's why it's running on 16
be. So, um that's why it's running on 16
cores. And that is actually why I have
cores. And that is actually why I have
these machines spec 16 cores. It's for
these machines spec 16 cores. It's for
when people Sims are not as fast as they
when people Sims are not as fast as they
should
should
be. All right. So, here we go. This
is these were just some older random
is these were just some older random
curves I had from
curves I had from
this. Seems like it is
this. Seems like it is
training. Uh, I believe that like the
training. Uh, I believe that like the
standard on what is good is quite high
standard on what is good is quite high
here though, but that is in a separate
here though, but that is in a separate
custom training repo that's forked from
custom training repo that's forked from
Puffer and they've been like iterating
Puffer and they've been like iterating
on it
on it
forever.
forever.
So, we'll get it to that in Puffer quite
So, we'll get it to that in Puffer quite
quickly, I assume.
Oh, one thing. Let me answer one DM
Oh, one thing. Let me answer one DM
while we're doing this.
I swear I had a piece of code for this
I swear I had a piece of code for this
like a long time
like a long time
ago for saving
videos. I thought it was like an FFI
videos. I thought it was like an FFI
function or something.
Well, I can find uh they just wanted
Well, I can find uh they just wanted
some people wanted to save
some people wanted to save
uh stuff to video actually. I think do I
uh stuff to video actually. I think do I
have on my
have on my
personal is Neural MMO 3 in here?
personal is Neural MMO 3 in here?
I think Neural MMO 3 is on my
I think Neural MMO 3 is on my
personal like the old Syon
version. You see
it? I know I wouldn't have removed it.
H weird.
Well, I don't know where I had the
Well, I don't know where I had the
function
function
then. We haven't like done video saving
then. We haven't like done video saving
in a while. That would actually be
in a while. That would actually be
useful to
do. And I remember it being like really
do. And I remember it being like really
annoying. I would like to link them some
annoying. I would like to link them some
code.
This is almost trained. Well, I will
This is almost trained. Well, I will
come back to
come back to
this. There was a function I had at some
this. There was a function I had at some
point.
point.
Okay. So, this gets like 6 or
Okay. So, this gets like 6 or
something which I assume is not very
something which I assume is not very
good but uh this is something.
So, we should be able to watch
it.
Yes. Okay. They are all standing
still. They're all stuck
still. They're all stuck
because
Presumably they have no energy or
something. So wait, they are
There's got to be like some penalty,
There's got to be like some penalty,
right? Preventing them from
moving cuz they're spamming everything
moving cuz they're spamming everything
but move.
Let's see what is in the
um in the config.
No energy stats. That seems
suspicious. Think they have some sort of
suspicious. Think they have some sort of
docks.
All right, let's actually talk about
All right, let's actually talk about
what this environment is.
what this environment is.
So,
So,
um, this is, uh, an environment that I,
um, this is, uh, an environment that I,
I don't know, I didn't I wouldn't say I
I don't know, I didn't I wouldn't say I
helped design it. I helped with a little
helped design it. I helped with a little
bit of like the infra setup for it over
bit of like the infra setup for it over
the summer. And, uh, this has now been
the summer. And, uh, this has now been
like a longunning project. There's
like a longunning project. There's
several people on this.
several people on this.
Um, not a Puffer project, but Puffer
Um, not a Puffer project, but Puffer
affiliated, I guess,
is. And it's like this procedural grid
is. And it's like this procedural grid
environment that's aiming to be really
environment that's aiming to be really
really complicated uh and have like a
really complicated uh and have like a
lot of room for learning and skill
lot of room for learning and skill
expression. It's aiming to be very
open-ended. You can check it out right
here.
Now the key mechanics here and this is
Now the key mechanics here and this is
what I was looking for is the latest
what I was looking for is the latest
version of this. So agents can see a
version of this. So agents can see a
limited number of squares around them.
limited number of squares around them.
Agents harvest diamonds, convert them to
Agents harvest diamonds, convert them to
energy at charger stations, and use the
energy at charger stations, and use the
energy power the hold alter for rewards.
energy power the hold alter for rewards.
All actions cost energy, so agents learn
All actions cost energy, so agents learn
to manage their energy budgets
to manage their energy budgets
efficiently. Agents can attack others,
efficiently. Agents can attack others,
temporarily freezing the target and
temporarily freezing the target and
stealing resources. Agents can toggle
stealing resources. Agents can toggle
shields, which drain energy but absorb
shields, which drain energy but absorb
attacks. Agents can share energy or
attacks. Agents can share energy or
resources and use markers to
resources and use markers to
communicate.
And then there's a whole bunch of like
And then there's a whole bunch of like
open-ended a lifey style stuff in
here. So, I'm guessing that there's some
here. So, I'm guessing that there's some
screwy thing with the energy mechanic
screwy thing with the energy mechanic
because that's
because that's
like
like
Yeah. Okay. So, here is their latest
Yeah. Okay. So, here is their latest
thing. This is what it's supposed to
thing. This is what it's supposed to
look
look
like. Oh, no. This is really old
actually. Was cool to
watch. Yeah. So, clearly they're not
watch. Yeah. So, clearly they're not
like running around and actually
like running around and actually
doing
things. See if we can see anything about
things. See if we can see anything about
this model.
Okay, there like a bunch of different
Okay, there like a bunch of different
objects and things in here. Now, if we
objects and things in here. Now, if we
look at like the
agents, I mean, they're just
agents, I mean, they're just
like kind of spamming random
like kind of spamming random
stuff except movement.
Frozen is
Frozen is
zero. Why don't I see energy on
these? Click an agent to select it.
Interesting. Let's see some of the
Interesting. Let's see some of the
confict stuff they have in here.
So action failure
penalty. They have some very small
penalty. They have some very small
rewards here. And then this is the big
rewards here. And then this is the big
one, I
guess. Is there an episode length or is
guess. Is there an episode length or is
this thing just never reset?
alter. Okay. So, they have like
alter. Okay. So, they have like
configurable everything here.
I think I just have to start reading the
I think I just have to start reading the
end code honestly because
like I wouldn't be surprised that it's
like I wouldn't be surprised that it's
like this thing just preventing learning
like this thing just preventing learning
or some weirdo
shenanigans. Is this easier or harder to
shenanigans. Is this easier or harder to
learn than neural MMO 3?
would think it should probably be
would think it should probably be
easier. This should probably be easier.
Okay. So, here's their end. It's
Okay. So, here's their end. It's
tiny. They just have this little binding
tiny. They just have this little binding
which falls the siphon.
This is 228
This is 228
lines of
Syon. Okay, this is map
Syon. Okay, this is map
gen right here.
gen right here.
This is like C++ Sython map
gen. you happen to watch? I don't really
gen. you happen to watch? I don't really
watch much like TV to be honest with
watch much like TV to be honest with
you. Like I actually don't remember the
you. Like I actually don't remember the
last time I've really watched
last time I've really watched
TV.
TV.
Um, and I also really don't watch like
Um, and I also really don't watch like
AI related anything in media. Like
AI related anything in media. Like
actually knowing AI kind of ruins it all
actually knowing AI kind of ruins it all
for me.
Honestly, I'm happiest when I just
Honestly, I'm happiest when I just
freaking completely mute the Twitter
freaking completely mute the Twitter
feed, the like dumb like whatever
feed, the like dumb like whatever
popular media feed on like anything AI
popular media feed on like anything AI
and tech adjacent. I just kind of grind
and tech adjacent. I just kind of grind
out
work. You don't have to imagine what the
work. You don't have to imagine what the
future might look like when you can
future might look like when you can
create it and in the image that you
create it and in the image that you
want.
like here. Technically, what am I doing
like here. Technically, what am I doing
with this? Wasn't a simulated agent. So,
with this? Wasn't a simulated agent. So,
that was fun to watch. I don't know. We
that was fun to watch. I don't know. We
have lots of simulated agents here. So,
have lots of simulated agents here. So,
this end looks kind of toy because they
this end looks kind of toy because they
put very little effort into the graphics
put very little effort into the graphics
of it. But like even me doing stuff like
of it. But like even me doing stuff like
this, like if I can get this thing
this, like if I can get this thing
working better for them, this will
working better for them, this will
actually be a major powerhouse for a lot
actually be a major powerhouse for a lot
of like a lifestyle inspired research uh
of like a lifestyle inspired research uh
way way faster than most of that
way way faster than most of that
community is doing work and also with a
community is doing work and also with a
bit more practical RL stuff around it as
bit more practical RL stuff around it as
well. Like there's a a huge potential to
well. Like there's a a huge potential to
move very very quickly with all this
move very very quickly with all this
tech stuff right now. So I'm pretty
tech stuff right now. So I'm pretty
focused on that.
I did take like most of last night off
I did take like most of last night off
after 4,000 calorie Easter dinner, but
after 4,000 calorie Easter dinner, but
that doesn't happen too often.
Um, is this shared? Wait,
Um, is this shared? Wait,
share. This is false, right?
Okay, that looks
sketchy. Can they make new tools in the
sketchy. Can they make new tools in the
Sims? They don't talk to you, but like
Sims? They don't talk to you, but like
yeah, they like depending on the end.
yeah, they like depending on the end.
Tool use is not really anything special
Tool use is not really anything special
from an RL perspective. It kind of just
works. I don't know. Have you seen some
works. I don't know. Have you seen some
of the uh the stuff that we do around
of the uh the stuff that we do around
here? So like this, we have all our
here? So like this, we have all our
demos on puffer.ai. You can play them
demos on puffer.ai. You can play them
and you can watch agents play them. So
and you can watch agents play them. So
like this is this is probably my
like this is this is probably my
favorite M because this is based off of
favorite M because this is based off of
my thesis. So I can take over this guy
my thesis. So I can take over this guy
just by hitting control. And now I can
just by hitting control. And now I can
walk around and I can do
walk around and I can do
stuff. Um so these guys can like they
stuff. Um so these guys can like they
can
can
fight and then like oh look this guy
fight and then like oh look this guy
drops a tool. So, I can actually like
drops a tool. So, I can actually like
equip this tool. I can use this to now
equip this tool. I can use this to now
harvest materials that I wouldn't have
harvest materials that I wouldn't have
been able to get before. And like they
been able to get before. And like they
do different
do different
things. I can probably find like some
things. I can probably find like some
armor and
stuff. And now I have a helmet on. And
stuff. And now I have a helmet on. And
you can pick up weapons and all sorts of
you can pick up weapons and all sorts of
things. And you can actually buy and
things. And you can actually buy and
sell these things with all the other
sell these things with all the other
agents on a global marketplace. So like
agents on a global marketplace. So like
if I want to sell this leaf, I can hit
if I want to sell this leaf, I can hit
V, enter sell mode and then I can select
V, enter sell mode and then I can select
a price and now this will be offered on
a price and now this will be offered on
a market and any other agent can buy it.
a market and any other agent can buy it.
And if I hit
And if I hit
B and I look for this, you can see that
B and I look for this, you can see that
this thing is
this thing is
$4 because I put it on the market. So,
$4 because I put it on the market. So,
like we can build all sorts of fun
like we can build all sorts of fun
things for agents to play
things for agents to play
with. And the key about like this versus
with. And the key about like this versus
like this type of work versus the stuff
like this type of work versus the stuff
of like a lot of the other stuff that
of like a lot of the other stuff that
you see right now is how fast this stuff
you see right now is how fast this stuff
is. Um, like we can make these Sims run
is. Um, like we can make these Sims run
more than 10,000x real time on one CPU
more than 10,000x real time on one CPU
core. This thing right here, we've
core. This thing right here, we've
trained agents on like like thousands of
trained agents on like like thousands of
years worth of data. They've played like
years worth of data. They've played like
thousands of years worth of this. Um, so
thousands of years worth of this. Um, so
yeah, that's what I do around
here. I think they will wake
up. I mean, I'm going to be honest with
up. I mean, I'm going to be honest with
you, that type of stuff is like I spend
you, that type of stuff is like I spend
zero time thinking about.
And it's not like, oh, you should think
And it's not like, oh, you should think
about it. It's like it's kind of the
opposite. Like there's a lot of people
opposite. Like there's a lot of people
thinking about implausible AI safety
thinking about implausible AI safety
situations now and like zero people
situations now and like zero people
thinking about, but what if nanobots
thinking about, but what if nanobots
take over the world or like what are all
take over the world or like what are all
the other like classic
the other like classic
sci-fi disasters?
Like
Like
realistically, AI hasn't developed in
realistically, AI hasn't developed in
remotely the same way um that a lot of
remotely the same way um that a lot of
the like the older Hollywood films have
the like the older Hollywood films have
come up
come up
with. You notice the button to pick up
with. You notice the button to pick up
an item wasn't on the demo page.
Jason always posts things that don't
Jason always posts things that don't
really make sense. I have a suspicion
really make sense. I have a suspicion
that Jason, are you a large language
that Jason, are you a large language
model that is like working off of very
model that is like working off of very
janky audio like audio transcripts from
janky audio like audio transcripts from
the
video by chance?
Some of these posts don't make
sense. All
sense. All
right. Um, is this thing on by default?
right. Um, is this thing on by default?
self agents
self agents
size rewards of agent index is not zero
size rewards of agent index is not zero
then you share
rewards. Okay, so this whole freaking
rewards. Okay, so this whole freaking
thing is just sketchy,
right? Let me just like
Okay. I just want to see if that results
Okay. I just want to see if that results
in like a substantial change.
Oh, I got to wait for it to
Oh, I got to wait for it to
finish. Holy, that takes forever to
finish. Holy, that takes forever to
compile.
assumes the
assumes the
similar maybe not that specific
question. I don't know. I really don't
question. I don't know. I really don't
think too much about like
think too much about like
these I really don't take this
these I really don't take this
perspective on a lot of like tech and AI
perspective on a lot of like tech and AI
stuff.
stuff.
Because
Because
like a lot of these scenarios, you can
like a lot of these scenarios, you can
kind of just run off with
kind of just run off with
them and like you can come up with
them and like you can come up with
completely implausible things or not
completely implausible things or not
even necessarily implausible, but things
even necessarily implausible, but things
that just have no basis for
that just have no basis for
evidence. They're like not just based on
evidence. They're like not just based on
any evidence. And
any evidence. And
like there's been like a lot of caution
like there's been like a lot of caution
and hesitancy and fear I think around a
and hesitancy and fear I think around a
lot of AI lately in certain
lot of AI lately in certain
circles
circles
and it's not grounded but what is
and it's not grounded but what is
grounded is the like tremendous benefit
grounded is the like tremendous benefit
coming from AI right now.
coming from AI right now.
Um, so until there's like clear
Um, so until there's like clear
demonstrable
demonstrable
danger, right, I'm going to focus on
danger, right, I'm going to focus on
building the benefits, right? Building
building the benefits, right? Building
the the stuff that actually
the the stuff that actually
is quite
is quite
transformative, optimizing for
engagement. Well, that that's what I
engagement. Well, that that's what I
think that a lot of the fear-mongering
think that a lot of the fear-mongering
is for, though, right?
is for, though, right?
I mean, there was this post recently
I mean, there was this post recently
that I wrote like a long critique of
that I wrote like a long critique of
where they like they got like a
where they like they got like a
professional blogger involved like like
professional blogger involved like like
a like a well-known
a like a well-known
uh writer and they basically wrote this
uh writer and they basically wrote this
sci-fi fanfic on like how AI is going to
sci-fi fanfic on like how AI is going to
kill everyone and destroy the world or
kill everyone and destroy the world or
whatever. And like they got actual
whatever. And like they got actual
legitimate researchers to engage with it
legitimate researchers to engage with it
seriously. And I kind of just went like,
seriously. And I kind of just went like,
"No, these guys are just writing fanfic
"No, these guys are just writing fanfic
in order to like try to bait people into
in order to like try to bait people into
discussing stuff that doesn't make sense
discussing stuff that doesn't make sense
seriously with them. Like they've
seriously with them. Like they've
clearly wrote this entire thing through
clearly wrote this entire thing through
just one lens like they always do." Like
just one lens like they always do." Like
it has it's not even aligned with what's
it has it's not even aligned with what's
happened in AI already. So like I see a
happened in AI already. So like I see a
lot of this type of
lot of this type of
stuff. Friendship is optimal.
What? Friendship with
what? You definitely shouldn't like
what? You definitely shouldn't like
think of the AI the way you think of a
think of the AI the way you think of a
person. That would be a
mistake. Okay. How's this doing here?
friendship is optimal. Was that Oh, no.
friendship is optimal. Was that Oh, no.
It was the I don't even want to like
It was the I don't even want to like
link the thing cuz it's like I don't
link the thing cuz it's like I don't
want to give them more engagement, but
want to give them more engagement, but
it like flew around like I This is cuz
it like flew around like I This is cuz
the thing is this isn't even the first
the thing is this isn't even the first
time this has happened, right? There's
time this has happened, right? There's
like this group of people. It's like the
like this group of people. It's like the
less wrong crowd or like the effective
less wrong crowd or like the effective
altruism crowd or the whatever. It's
altruism crowd or the whatever. It's
like this weird SF cult.
like this weird SF cult.
Um, and they're also the ones that are
Um, and they're also the ones that are
involved in a lot of like the really
involved in a lot of like the really
really shitty lobbying to like shut down
really shitty lobbying to like shut down
all USI progress and stuff like that.
Um, it's a mistake to like engage with
Um, it's a mistake to like engage with
these people as if it's to engage with
these people as if it's to engage with
them honestly, so to speak, because
them honestly, so to speak, because
they're not engaging honestly. And I
they're not engaging honestly. And I
think that's where like a lot of the
think that's where like a lot of the
misguided attitudes around AI come from
misguided attitudes around AI come from
today is that they're optimized, right,
today is that they're optimized, right,
for like convincing non-technical
for like convincing non-technical
people, mostly non-technical people.
people, mostly non-technical people.
They get a few technicals as well um of
They get a few technicals as well um of
this like
this like
And I'm not here I'm not here
And I'm not here I'm not here
spending my time trying to counteract
spending my time trying to counteract
that for the most part, right? I'm here
that for the most part, right? I'm here
spending my time actually building the
spending my time actually building the
tech. So, when you're engaging in bad
tech. So, when you're engaging in bad
faith and you're not trying to build
faith and you're not trying to build
anything and you're just trying to like
anything and you're just trying to like
fearmonger, it's actually very easy to
fearmonger, it's actually very easy to
gain a lot of traction even if what
gain a lot of traction even if what
you're selling is complete
Um, because the people like there's not
Um, because the people like there's not
a counterparty, right?
Like my goal is to spend as little of my
Like my goal is to spend as little of my
time as possible on socials in the most
time as possible on socials in the most
amount of time possible building cool
Really, I'm only on socials at
Really, I'm only on socials at
all. Um because it helps me like grow
all. Um because it helps me like grow
the open source stuff and potentially
the open source stuff and potentially
get clients and
get clients and
stuff mostly for molecular dynamics.
stuff mostly for molecular dynamics.
See, now that's cool. That's cool stuff.
I don't know how like what the case I
I don't know how like what the case I
actually don't I didn't follow the alpha
actually don't I didn't follow the alpha
fold stuff even though it's really
fold stuff even though it's really
really cool but I don't know what the
really cool but I don't know what the
use case is for RL
use case is for RL
in like that level of sim. It really
in like that level of sim. It really
depends how fast the sims are. I know
depends how fast the sims are. I know
that they're very heavy, but uh in
that they're very heavy, but uh in
general
general
like RL is kind of the area of AI to
like RL is kind of the area of AI to
think about around hyperf
sim. Okay, so this doesn't seem like it
sim. Okay, so this doesn't seem like it
does worse.
So, I was just afraid that they could
So, I was just afraid that they could
This is like a really sketchy technique,
This is like a really sketchy technique,
but it doesn't seem to do anything in
but it doesn't seem to do anything in
this case. So, we'll leave that leave
this case. So, we'll leave that leave
that alone.
one is predicting experimental
one is predicting experimental
measurements from alpha pole structures.
measurements from alpha pole structures.
That's what I'm doing. That's
That's what I'm doing. That's
awesome. I actually like a lot of the
awesome. I actually like a lot of the
bioside sim stuff. there is a very real
bioside sim stuff. there is a very real
chance that that is what I get into uh
chance that that is what I get into uh
once I have well I say once I've solved
once I have well I say once I've solved
RL but realistically right once I've
RL but realistically right once I've
gotten RL into a place where everything
gotten RL into a place where everything
is stable and seems like it works which
is stable and seems like it works which
I actually do think is a realistic goal
I actually do think is a realistic goal
um like my longer term aspirations for a
um like my longer term aspirations for a
lot of this AI stuff like the my first
lot of this AI stuff like the my first
sort of wish list for Santa item here
sort of wish list for Santa item here
from AI is can we use AI to reverse
from AI is can we use AI to reverse
aging and like cure disease. Basically,
aging and like cure disease. Basically,
can
can
we I don't even want to say extend. I
we I don't even want to say extend. I
wanted I'd really just say can we like
wanted I'd really just say can we like
fix human
fix human
mortality? Like I see that as a problem
mortality? Like I see that as a problem
we can potentially fix. That's like the
we can potentially fix. That's like the
wacko crazy side thing that I think
wacko crazy side thing that I think
about. But I don't know. It seems like
about. But I don't know. It seems like
it is a solvable
it is a solvable
problem. I don't think there's anything
problem. I don't think there's anything
that's physically making it impossible.
So, that's about as sci-fi as we
get. So much low hanging fruit.
get. So much low hanging fruit.
Really, my my impression of a lot of the
Really, my my impression of a lot of the
um like molecular sim is it's very hard
um like molecular sim is it's very hard
to do stuff in because like the sims are
to do stuff in because like the sims are
so high fidelity that they're very slow.
so high fidelity that they're very slow.
Is that not the case?
Where is this
thing? Okay, so there these actions,
thing? Okay, so there these actions,
there's agent and then there's like n.
there's agent and then there's like n.
Okay, this is like super heavily
Okay, this is like super heavily
modularized, which is a little
modularized, which is a little
unfortunate.
also. Do I have a meeting today? Let me
also. Do I have a meeting today? Let me
see. I might have some meetings
today. Anytime after 1 p.m. So, we're
today. Anytime after 1 p.m. So, we're
good on that. Meeting is tomorrow, I
good on that. Meeting is tomorrow, I
believe. Other one
I'm trying to think
I'm trying to think
where this like freeze thing is. I
where this like freeze thing is. I
should just start grapping for stuff,
should just start grapping for stuff,
shouldn't
shouldn't
I? Like stuff that seems
suspicious. Depends how big your system
suspicious. Depends how big your system
is. Romax is pretty quick as well as
is. Romax is pretty quick as well as
Open MM huge opportunity to make these
Open MM huge opportunity to make these
better. Yeah. So, that's like stuff that
better. Yeah. So, that's like stuff that
I would actually seriously be interested
I would actually seriously be interested
in being involved in. I don't know if
in being involved in. I don't know if
you have RL use cases for any of this.
you have RL use cases for any of this.
Um, but if you think that you might or
Um, but if you think that you might or
even if you're just interested in like
hyperfac out some of the stuff in the
hyperfac out some of the stuff in the
Puffer Discord and some of the stuff
Puffer Discord and some of the stuff
we're doing,
we're doing,
um, we're pretty good at making stuff
um, we're pretty good at making stuff
fast. I will
fast. I will
say we uh we haven't really done super
say we uh we haven't really done super
highfidelity stuff yet like we haven't
highfidelity stuff yet like we haven't
done Perf engineering on that yet but if
done Perf engineering on that yet but if
our other work has any indication like
our other work has any indication like
people in RL generally write really slow
people in RL generally write really slow
bad SIM code and ours are up to 10,000x
bad SIM code and ours are up to 10,000x
faster I think actually some of them are
faster I think actually some of them are
even more than
even more than
that we're just like writing stuff in a
that we're just like writing stuff in a
really simple C with uh no dynamic
really simple C with uh no dynamic
memory allocations
memory allocations
And we've had a lot of success doing
And we've had a lot of success doing
that.
So this is not in here unless I'm doing
So this is not in here unless I'm doing
this
wrong. Machinele learn force
fields background is in chemistry. I
fields background is in chemistry. I
don't know if I'll be able to understand
don't know if I'll be able to understand
what's going on. So, one of the cool
what's going on. So, one of the cool
things, right, about what we do is it's
things, right, about what we do is it's
very, very accessible. We do stuff in a
very, very accessible. We do stuff in a
way that's way simpler and way more
way that's way simpler and way more
accessible than most other things. And
accessible than most other things. And
let's keep up the work. Good work. Nice
let's keep up the work. Good work. Nice
chatting. Nice chatting with you, too.
chatting. Nice chatting with you, too.
Always cool to see uh people doing
Always cool to see uh people doing
interesting stuff dropping by stream.
Okay, so these are just in the configs
Okay, so these are just in the configs
it looks
it looks
like. Do these not do anything?
So there are teams
Oh, this does have a max steps. Hang
Oh, this does have a max steps. Hang
on. I think what we're going to do, let
on. I think what we're going to do, let
me just try some of my
me just try some of my
usual my usual tricks, right? Like
usual my usual tricks, right? Like
things that usually screw with RL
things that usually screw with RL
dynamics.
Can we even Hang
on. I think we'll do 128 steps. Then it
on. I think we'll do 128 steps. Then it
should line up
should line up
nicely. Try this.
If it doesn't change the curves, then
If it doesn't change the curves, then
I'm going to get like start getting
I'm going to get like start getting
suspicious about whether this config
suspicious about whether this config
does anything, right?
Okay, this is maybe doing something a
Okay, this is maybe doing something a
bit different. We'll see.
It's also possible the act the uh the
It's also possible the act the uh the
model and hypers are just like not good.
model and hypers are just like not good.
So that could just make the curve
So that could just make the curve
slower. I guess we really just care
slower. I guess we really just care
about the shape,
right? It would be very weird if
um if this didn't m change
um if this didn't m change
anything, right?
Okay. Yeah, there's something weird here
Okay. Yeah, there's something weird here
for
for
sure. Max
steps. I suspect some of these just
steps. I suspect some of these just
aren't getting used.
Okay, so there's no max steps in meta.
Okay, so there's no max steps in meta.
What about in meta grid?
Config.max
steps fourth param grid
steps fourth param grid
end grid
end metagrid grid
This doesn't trigger a
reset. This doesn't appear to trigger a
reset. This doesn't appear to trigger a
reset.
so this is just calling metag
Stop. Is this the init? This is the
Stop. Is this the init? This is the
init render grid
init render grid
objects. Here's step.
objects. Here's step.
So, this doesn't have a
reset. There's also
reset. There's also
this. Does this have a
this. Does this have a
reset? This has a step.
reset? This has a step.
Uh this does have a
Uh this does have a
reset. Cannot reset after. Okay. So this
reset. Cannot reset after. Okay. So this
thing cannot be
thing cannot be
reset after
reset after
stepping. It's
interesting. So yeah, what's happening
interesting. So yeah, what's happening
is it's not getting used.
I think we need to just like
inject some sort of thing into Yes.
So I guess this is
um Where's D.Pi?
Reset
See if this does
See if this does
anything. Yeah, definitely nothing is
anything. Yeah, definitely nothing is
happening with a lot of these
params. Ah, okay. Okay. So, we do
params. Ah, okay. Okay. So, we do
actually
get Yeah. So, that actually did hit
But there was an episode length before,
But there was an episode length before,
wasn't
there? That just kept going straight up.
there? That just kept going straight up.
It was never getting
reset. So possibly This is going to be
reset. So possibly This is going to be
lower, but the policy might be
better. Okay, what stats do we have in
here? Let's actually see.
here? Let's actually see.
Let's see what stats we get of
Let's see what stats we get of
this. So, attack
action. First use
So much stuff.
Yeah, there are just too many damn uh
Yeah, there are just too many damn uh
too many damn metrics.
Okay, here's something. I think that
Okay, here's something. I think that
this one's important.
that this one matches.
cosine and kneeling
here. It shouldn't be cosine and
here. It shouldn't be cosine and
kneeling back up to
kneeling back up to
uh the star. That's kind of weird.
loss is very
different.
So this
Trying to think what are good
metrics. Isn't it like convert or
metrics. Isn't it like convert or
something?
There's this
sum which is also
lower. Hang on. Isn't the sum is over
lower. Hang on. Isn't the sum is over
the whole episode? So, this episode is
the whole episode? So, this episode is
way
way
shorter and it's getting the same reward
presumably and the end is now slower.
presumably and the end is now slower.
So, it is resetting.
Maybe this does
Maybe this does
something. We will see.
What's the meta m? Hey captain, how's
What's the meta m? Hey captain, how's
impulse Impulse 4 is uh going by the
impulse Impulse 4 is uh going by the
way? We would love to have some more
way? We would love to have some more
complex M benchmarks pretty soon
complex M benchmarks pretty soon
here. It' be nice to get that
here. It' be nice to get that
integrated.
Um, so this is
Um, so this is
meta. This is third partyish. I mean, it
meta. This is third partyish. I mean, it
is a native puffer m, so we'll call it a
is a native puffer m, so we'll call it a
collaboration environment, though.
collaboration environment, though.
Really, they're doing the end and we
Really, they're doing the end and we
just have puffer.
Um, it is like
Um, it is like
this not really factorioesque, but it's
this not really factorioesque, but it's
like this like factoryish type end thing
like this like factoryish type end thing
where it's supposed to be open-ended and
where it's supposed to be open-ended and
like their different resources and
like their different resources and
resource converters and energy and
resource converters and energy and
things. Um, and the agents are just
things. Um, and the agents are just
supposed to come up with a bunch of
supposed to come up with a bunch of
interesting
interesting
strategies. We're currently trying to
strategies. We're currently trying to
see if I can get it to learn something
see if I can get it to learn something
interesting.
busy all weekend. Now I'm going to start
busy all weekend. Now I'm going to start
sweep with basic CL.
Cool. Ah, these actually do something
now. Like these guys actually do
now. Like these guys actually do
something.
Oh yeah, he just used the
converter. If it help you. I could try
converter. If it help you. I could try
to get impulse for soon before I have a
to get impulse for soon before I have a
good
good
baseline. Well, I just generally think
baseline. Well, I just generally think
that getting it merged is going to help
that getting it merged is going to help
you overall because you can test like
you overall because you can test like
whatever you're trying to test. It's
whatever you're trying to test. It's
generally a bad thing to just test it on
generally a bad thing to just test it on
the one end, right? Like the whole point
the one end, right? Like the whole point
of puff is you have access to all these
of puff is you have access to all these
different ends. So when you're trying
different ends. So when you're trying
stuff, you can see does it work on every
stuff, you can see does it work on every
end except impulse wars, right? Does it
end except impulse wars, right? Does it
work only on impulse wars? like you can
work only on impulse wars? like you can
get a a much better feel for things.
C policy code. It doesn't need the C
C policy code. It doesn't need the C
policy code before we put it to dev,
policy code before we put it to dev,
man. It's
man. It's
fine. We're also I there's one thing
fine. We're also I there's one thing
that I want to look into. So apparently
that I want to look into. So apparently
Tinyrad has a um Tiny has a
Tinyrad has a um Tiny has a
C backend for PyTorch where you can
C backend for PyTorch where you can
generate C code from PyTorch models. If
generate C code from PyTorch models. If
that works, we could potentially jam
that works, we could potentially jam
that
thumb is the There.
Okay, so this does something
What's the policy on this
thing? Pretty similar to neural MMO, I
thing? Pretty similar to neural MMO, I
guess.
This does
five. So we'll use Bur
MMO.
Could this be? This should be like 3.1
Could this be? This should be like 3.1
mil, right?
mil, right?
Is
Is
2.4. Is that
correct? Should that be smaller?
does have a current on
it. I guess there's a big linear layer
it. I guess there's a big linear layer
channel difference.
because you do this hidden size over two
because you do this hidden size over two
thing. Okay.
So that's like running at the same speed
So that's like running at the same speed
pretty much, right?
It's running the same
speed. We'll see if it does
worse. I believe I put the layer norm
worse. I believe I put the layer norm
after
after
uh this hidden here as
uh this hidden here as
well for nurmo3. Great.
very low entropy.
You know, I bet you that there is
You know, I bet you that there is
um a pretty
um a pretty
substantial shift in param optimals now
substantial shift in param optimals now
that I screwed with the
that I screwed with the
horizon. I bet you that gamma goes down
horizon. I bet you that gamma goes down
to something that you would expect it to
to something that you would expect it to
be.
Let's just like comment all these neural
Let's just like comment all these neural
MMO crs and let's work off of these. I
MMO crs and let's work off of these. I
think we can probably make some uh some
think we can probably make some uh some
progress now way way faster.
Interestingly, is the episode reward
Interestingly, is the episode reward
mean just like
stuck? Yeah. So, it doesn't train with
stuck? Yeah. So, it doesn't train with
the bigger
model.
Probably try learning rate fix real
Probably try learning rate fix real
quick.
Okay, they definitely need to fix the
Okay, they definitely need to fix the
freaking mu on thing. So, um, optimal
freaking mu on thing. So, um, optimal
learning rate stays. Can I just go check
learning rate stays. Can I just go check
zero shot hyper param transfer thing?
zero shot hyper param transfer thing?
What is the rough expected
change? Optimum
shifts. Is it
linear? It looks to be roughly linear,
linear? It looks to be roughly linear,
right? Factor of twoish.
So what I did should be roughly
correct. Okay, that looks reasonable,
correct. Okay, that looks reasonable,
right?
Oh yeah, that's
good. Yeah, I think if I just kind of
good. Yeah, I think if I just kind of
sit here for another hour and like
sit here for another hour and like
fiddle with this, I think I'll get
fiddle with this, I think I'll get
something reasonable out of this
something reasonable out of this
end as like a starting point.
Okay. So, this is about on par with the
Okay. So, this is about on par with the
current one so
far. Oh, it's better. Okay. So, yeah,
far. Oh, it's better. Okay. So, yeah,
the learning rate thing actually does
the learning rate thing actually does
need to be tuned annoyingly.
Um, yeah, it does need to be
tuned. Yell the optimizer, guys.
Oh, this is actually quite good,
Oh, this is actually quite good,
right? So, this is compared to these.
right? So, this is compared to these.
This is like
This is like
a 128 length episode or
whatever. This seems good.
and then likely plateaus off here.
Next up to try will
Next up to try will
be I want to see if this looks like it's
be I want to see if this looks like it's
doing anything
doing anything
first and then I guess we can try like
first and then I guess we can try like
layer
layer
shenanigans. Um what other things do I
shenanigans. Um what other things do I
have? We could try longer episode
have? We could try longer episode
lengths. 128 could be too short I would
lengths. 128 could be too short I would
think.
think.
[Music]
[Music]
Probably the best thing is to line it up
Probably the best thing is to line it up
with the uh the actual batch,
with the uh the actual batch,
right? Line it up with the batch size
maybe, which I think is only 64 right
maybe, which I think is only 64 right
now, isn't
it? So, it's like
it? So, it's like
256 M* 16 agents.
4096. So we have like was
4096. So we have like was
it this our batch size by
it this our batch size by
23? Oh no it is 128 perfectly. So yeah
23? Oh no it is 128 perfectly. So yeah
this does already then line up uh
this does already then line up uh
perfectly. So we could do the BPT
perfectly. So we could do the BPT
horizon. I think gamma probably gamma is
horizon. I think gamma probably gamma is
going to
going to
be a good param to
be a good param to
change.97's not terrible
actually could be too
actually could be too
high. I think 97 should be fine.
high. I think 97 should be fine.
can change the BPT horizon
potentially. Uh mini batch size
potentially. Uh mini batch size
potentially can be
upped. We have some stuff to try here
upped. We have some stuff to try here
for
for
sure. How's this
doing? Kind of goes down towards the
doing? Kind of goes down towards the
end. The cosine and kneeling might be
end. The cosine and kneeling might be
screwing with it to be
screwing with it to be
honest. Cosine and kneeling might need
honest. Cosine and kneeling might need
uh some
uh some
tuning. This probably what it is frankly
Okay, this is at least like a nice
Okay, this is at least like a nice
consistent
curve. Bigger model does better. Good.
curve. Bigger model does better. Good.
That is what we want.
128 steps should kind of be fine to
128 steps should kind of be fine to
learn dynamics in this
end. Three
Okay. Agents running around doing stuff.
I do want to throw a layer norm in real
I do want to throw a layer norm in real
quick just to see because it was a
quick just to see because it was a
pretty decent bump for neural MMO
3. We did it right here, right?
decode
actions. See if this does
actions. See if this does
anything. We have to change
We try
this other things that help neural MMO.
this other things that help neural MMO.
I'm
thinking self
encoder probably this is already going
encoder probably this is already going
to be a decent start.
Now the one thing we don't like to see
Now the one thing we don't like to see
here is the uh the curves seem kind of
here is the uh the curves seem kind of
flat. I do wonder if this is the cosine
flat. I do wonder if this is the cosine
and kneeling being weird
though. This could very well be cosign
though. This could very well be cosign
and just being screwy.
We will deal with
that. I might just disable it
that. I might just disable it
temporarily to be honest.
substantially
worse. Interesting.
Well, curvature is still convex, so
Well, curvature is still convex, so
we'll let it go a bit.
I suspect
I suspect
um we're going to have to for these
um we're going to have to for these
shorter runs disable the annealing
Yeah, that's going to
level that ought to do something. You
level that ought to do something. You
would
think this
No
annealing. Make sure this is
running. Okay, be right back. I'm going
running. Okay, be right back. I'm going
to use the restroom. We will continue
to use the restroom. We will continue
experiments.
Okay, that looks promising,
right? It's on par with the current the
right? It's on par with the current the
uh the previous one. Right now we will
uh the previous one. Right now we will
see whether uh the thing I want to know
see whether uh the thing I want to know
basically is whether this ends up
basically is whether this ends up
getting a more log like curve as a
getting a more log like curve as a
result because
result because
uh because it doesn't like screw with
uh because it doesn't like screw with
the learning rate at the end. That's
the learning rate at the end. That's
what I want to
what I want to
know. And then let me think what else we
know. And then let me think what else we
can potentially do with this thing other
can potentially do with this thing other
than just keep increasing policy size
than just keep increasing policy size
and whatnot.
I guess we can start looking at these
I guess we can start looking at these
metrics and trying to like the thing is
metrics and trying to like the thing is
they log way too much crap, right? They
they log way too much crap, right? They
log like way too much crap. There is
log like way too much crap. There is
such a thing as too much
such a thing as too much
logging. So I think this green
logging. So I think this green
[Music]
curve. Okay, here's the attack. first
curve. Okay, here's the attack. first
use
use
whatever. Not really attacking stuff.
Yeah. So like these metrics go up over
Yeah. So like these metrics go up over
time because like the agent just they
time because like the agent just they
can't not go up. Like the agent has
can't not go up. Like the agent has
infinite time to do
infinite time to do
stuff. So the only thing I can
stuff. So the only thing I can
potentially think is
potentially think is
that 128 steps might be too
that 128 steps might be too
short. We might have to go to like 256
short. We might have to go to like 256
or
or
something. So this is nice and
something. So this is nice and
consistent, right? This this is actually
consistent, right? This this is actually
where the reward comes from. It seems is
where the reward comes from. It seems is
this part
conversion, but doesn't
conversion, but doesn't
really do this step of the
really do this step of the
conversion. It's got to get this step
next. And then a red or
next. And then a red or
doesn't really bother with this,
doesn't really bother with this,
right? This is
like might need some rewards for this or
whatever. I have really small rewards on
whatever. I have really small rewards on
some of this right
now. The approach scale is crazy.
Okay.
Well, I'll stick to this for
now and uh we will basically
now and uh we will basically
see what happens towards the end of this
see what happens towards the end of this
graph. I believe it anneals the learning
graph. I believe it anneals the learning
rate down to like zero at and a
rate down to like zero at and a
half and then it anneals it back
half and then it anneals it back
up. So if this gives us like a cleaner
up. So if this gives us like a cleaner
log curve then that's what we will be
log curve then that's what we will be
looking
looking
for. If it's flat as well then well I
for. If it's flat as well then well I
don't
know. But this so far looks a little
know. But this so far looks a little
better maybe.
I think 256 steps would be the next
I think 256 steps would be the next
thing to try
maybe. Let me
see. I mean, we can try 56
steps. Yeah, I think that's the most
reasonable of the things that we can
reasonable of the things that we can
try.
And then there are the conversion
rewards. Probably those just need to be
given. Okay. So, it still levels off
given. Okay. So, it still levels off
pretty well
here, but it's also like out of time to
here, but it's also like out of time to
do actions. Though, to be fair, it's
do actions. Though, to be fair, it's
almost certainly can do better than
this. So, we'll give it twice as long to
this. So, we'll give it twice as long to
do action. We'll see if it
do action. We'll see if it
gets
gets
[Music]
[Music]
well. Hang
well. Hang
on. This is all coming just from the
on. This is all coming just from the
heart. Right. So, like if it knows how
heart. Right. So, like if it knows how
to do that one thing, it's not going to
to do that one thing, it's not going to
get any better because that's the only
get any better because that's the only
thing that's being
rewarded. But there was a gap from here
rewarded. But there was a gap from here
to here. So maybe there is still some
room. I think I can go to what's
room. I think I can go to what's
this 75 mil at
this 75 mil at
least or 75
least or 75
mil slightly shorter experiments
If this does not do substantially
If this does not do substantially
better, then we'll just go back to 128
better, then we'll just go back to 128
and assume that there's not that much
and assume that there's not that much
that it can learn to do uh in 256 steps,
that it can learn to do uh in 256 steps,
but not in
but not in
128. Horizon is usually a major thing
128. Horizon is usually a major thing
though, like with new RLMs. It's like
though, like with new RLMs. It's like
one of the most common things people get
one of the most common things people get
wrong.
wrong.
So, I figured that this was a good one
So, I figured that this was a good one
to start
with. Okay, this red curve is pretty
with. Okay, this red curve is pretty
decent.
This has got to be
This has got to be
like the things respawn eventually or
like the things respawn eventually or
something,
something,
right? Like what else would it
right? Like what else would it
be? Where's like
be? Where's like
heart? Is this a
thing
objects red
objects red
generator? Okay. Input battery
generator? Okay. Input battery
three. Output heart
one. Part
one. Part
one. Max five.
These rewards seem really
small. I'm going to mess with those
small. I'm going to mess with those
next.
Okay, so so far this curve just matches
Okay, so so far this curve just matches
and doesn't do any better with 256 than
and doesn't do any better with 256 than
with
128. We'll see whether this trend
continues. We would expect it to do a
continues. We would expect it to do a
bit better. If it doesn't do
bit better. If it doesn't do
better, then that would imply that
better, then that would imply that
basically there's not much for these
basically there's not much for these
guys to do
guys to do
uh with 128 versus
uh with 128 versus
otherwise. And then these things like
otherwise. And then these things like
yeah, eventually items will respawn and
yeah, eventually items will respawn and
stuff like that, I guess. But I mean,
stuff like that, I guess. But I mean,
these guys have like ludicrous amounts
these guys have like ludicrous amounts
of time to do whatever and they still
of time to do whatever and they still
are not like going up linearly.
Okay, so this seems pretty
damning. We will let it keep running a
damning. We will let it keep running a
bit,
bit,
but so far no
but so far no
difference with
Let's just check these fit like
Let's just check these fit like
perfectly. They're just scaled, right?
perfectly. They're just scaled, right?
Yeah, these fit perfectly. They're just
Yeah, these fit perfectly. They're just
scaled.
This probably just isn't an end where
This probably just isn't an end where
there's like much to do for very long,
there's like much to do for very long,
right? At least in the current
right? At least in the current
form. You kind of just chuck all your uh
form. You kind of just chuck all your uh
your stuff in the altar or whatever and
your stuff in the altar or whatever and
you call it a day.
Let's add them like some real rewards
Let's add them like some real rewards
for stuff.
So, this should just have a higher
So, this should just have a higher
curve, but that's not what we're after
curve, but that's not what we're after
here, right? The thing that we're going
here, right? The thing that we're going
to be after is whether the curve uh
to be after is whether the curve uh
stays flat for the same time or if it
stays flat for the same time or if it
like if it keeps learning for longer.
basically. Okay. So
basically. Okay. So
immediately this is going to be way
immediately this is going to be way
steeper
How to tackle building impulse
wars. Jeez,
man. Come up with something for now and
man. Come up with something for now and
then we'll figure out what the heck to
then we'll figure out what the heck to
do from there.
Okay, so this is like crazy higher
curve, but this is the magnitude doesn't
curve, but this is the magnitude doesn't
tell us anything, right? We need to know
tell us anything, right? We need to know
the the slope
can just commit the
cmake. Can you commit the cmake without
cmake. Can you commit the cmake without
breaking the build stuff or all the
breaking the build stuff or all the
other MS that are like the way they are
other MS that are like the way they are
at the
moment? Is that a thing?
and then we figure out what we do later
and then we figure out what we do later
for
this something dirty. I can commit cmake
this something dirty. I can commit cmake
without touching setup.py. So build.
without touching setup.py. So build.
Yeah, just do that. That's
fine. That's fine.
fine. That's fine.
As long as we can run it and actually
As long as we can run it and actually
like get experiments on this Okay.
need to double check site buying still
need to double check site buying still
working on dev tip. Gotcha.
This has got to be a new capability
This has got to be a new capability
right here, right? This like divot
about
here. So extends the learning process
here. So extends the learning process
like 50%age.
Yeah, they seem to be running around and
Yeah, they seem to be running around and
doing
something. I think these are alters or
something. I think these are alters or
whatever.
Where are the batteries? Is this a
Where are the batteries? Is this a
battery? Yeah, this is the
battery. And this is armor.
I mean, they're doing
I mean, they're doing
something. I don't know the game well
something. I don't know the game well
enough yet.
probably red ore or whatever, right? Oh,
probably red ore or whatever, right? Oh,
no. This is a
no. This is a
heart. So, they go collect this
heart. So, they go collect this
thing. Yep. So, this is going to collect
thing. Yep. So, this is going to collect
this.
So they know to collect the
hearts, the batteries, I
suppose. I don't know what to do after
suppose. I don't know what to do after
that really.
I mean, I'm seeing them running around
I mean, I'm seeing them running around
and doing stuff now, right? Collecting
and doing stuff now, right? Collecting
stuff or whatever.
Okay. Anything else I can do right now?
Okay. Anything else I can do right now?
I'm thinking
Let's just do something
like should do like this.
probably this breaks it,
probably this breaks it,
right? I want to see
Probably this just doesn't burn,
right? Yeah, it's just going to stand
right? Yeah, it's just going to stand
there and not do anything.
Okay. Anything else I can do on this at
Okay. Anything else I can do on this at
the moment? I guess I can check the
the moment? I guess I can check the
policy.
See uh does this
See uh does this
code do anything?
Is this already one
hot or is this
hot or is this
already? Yeah, these are already like
already? Yeah, these are already like
one hot I think.
for the most
for the most
part. So then this should be
part. So then this should be
okay the way that this is
I think that this should be okay the way
I think that this should be okay the way
this is. There's nothing like getting
this is. There's nothing like getting
encoded
weirdly. Okay. I think what we're going
weirdly. Okay. I think what we're going
to do then is I'm just going to guess
to do then is I'm just going to guess
one more. I'll just guess some params
one more. I'll just guess some params
based on the neural MMO ones. We'll do
based on the neural MMO ones. We'll do
one more experiment and then we'll see
one more experiment and then we'll see
uh we'll see what we do after. And we'll
uh we'll see what we do after. And we'll
do this. I'll get some food. I'll get
do this. I'll get some food. I'll get
some exercise. And then I'll see what I
some exercise. And then I'll see what I
do after for the rest of the
day. Bigger mini batch
size. Lower lambda
gamma entropy.
I guess the only thing I kind of want to
I guess the only thing I kind of want to
try is the mini
try is the mini
batch. Mini batches being like really
batch. Mini batches being like really
really low is kind of
awkward. So we'll try the neural MMO
awkward. So we'll try the neural MMO
mini batch
mini batch
size. And uh I maybe this does
size. And uh I maybe this does
something. Probably not.
something. Probably not.
We'll just give it a little bit of time
We'll just give it a little bit of time
on the early
curve. Is the gamma really
high? It's probably like Okay.
probably just learn slower, right?
Yeah, we'll give it like extra 10 mil or
Yeah, we'll give it like extra 10 mil or
whatever.
If it has a different shape, then
If it has a different shape, then
that'll be interesting.
that'll be interesting.
But other than that,
um probably nothing to see.
It seems like it is going to have the
It seems like it is going to have the
same like tapered shape
though. It's kind of
though. It's kind of
screwy. It's a pretty batch size for
screwy. It's a pretty batch size for
learning something like this.
Okay, this is what we were hoping for.
Even if it just matches, it's better
Even if it just matches, it's better
because this is a faster training
because this is a faster training
config.
Don't tell me this actually levels out
Don't tell me this actually levels out
lower.
kind of a weird
result. Would that imply that this thing
result. Would that imply that this thing
needs more
needs more
entropy? Actually, entropy is very low
entropy? Actually, entropy is very low
in
this which would make it quite difficult
this which would make it quite difficult
for it to learn
for it to learn
much because this is entropy over like a
much because this is entropy over like a
big multi-discretet.
It's just about on
par. Okay. like very slightly lower, but
par. Okay. like very slightly lower, but
we are going to need the bigger mini
we are going to need the bigger mini
batch if we try bigger horizons.
batch if we try bigger horizons.
The one thing I did want to try next was
The one thing I did want to try next was
longer
horizons. This I'm not going to give as
horizons. This I'm not going to give as
much time to. This is not better
much time to. This is not better
early. It's probably not better. I still
early. It's probably not better. I still
want to try a couple things with the
want to try a couple things with the
gamma and whatever.
This is going to
break. Thought we had uh I thought we
break. Thought we had uh I thought we
had this fine.
And imagine that helps
actually. We could just yolo the magic
actually. We could just yolo the magic
neural MMO parameters onto
it. Might
it. Might
work. And then presumably
859. Yeah.
859. Yeah.
Okay. You can try
that. I actually do kind of just want to
that. I actually do kind of just want to
yellow onto it and
see. Okay. So, that's worse.
Undo
Undo
that. Keep this as
is. Lay num m is
is. Lay num m is
two. Does this not work? This should
two. Does this not work? This should
work, right?
This breaks. Interesting enough. Do I
This breaks. Interesting enough. Do I
not have as many as I think I
do? Because of XP buffer bug. Ah, so I
do? Because of XP buffer bug. Ah, so I
have half the number of M's right
now. Okay.
now. Okay.
So we have to do was
it if I do
it if I do
this how's this work
It's fast.
some is stuck
low. There we go.
If it can match this blue curve, I think
If it can match this blue curve, I think
that would be
good. So far it does.
This gives you more frequent logging as
This gives you more frequent logging as
well. Just a nice little
bonus. Okay, we're at 12, which is like
bonus. Okay, we're at 12, which is like
the
the
first block.
If this performs decently enough, we
If this performs decently enough, we
yolo the rest of the params
yolo the rest of the params
on and then that will be last experiment
on and then that will be last experiment
for morning.
Okay. So, slightly worse than the larger
Okay. So, slightly worse than the larger
batch, smaller mini batch
batch, smaller mini batch
seems, but not by much.
Well, it works okay enough that I kind
Well, it works okay enough that I kind
of just want to try this real quick.
of just want to try this real quick.
It would kind of be a miracle if it did
It would kind of be a miracle if it did
anything, but uh you
anything, but uh you
know, we can try it.
The gamma from neural3 in particular
The gamma from neural3 in particular
makes no
makes no
sense,
but it works. And like the design of the
but it works. And like the design of the
MS is not that different.
The question is going to be which one of
The question is going to be which one of
these actually mattered
these actually mattered
um and does this actually get the same
convergence and also if we go back to
convergence and also if we go back to
the original batch and mini batch the
the original batch and mini batch the
better
We could kind of just sweep this,
We could kind of just sweep this,
right? We just do like a 75 mil
sweep. What is score in here?
score is a nice
variable. Just normalized whatever one
variable. Just normalized whatever one
of the other ones
of the other ones
is. So, this actually
is. So, this actually
does collide with this at some point. It
seems kind of
expected. Okay. Well, this is what we'll
expected. Okay. Well, this is what we'll
do. We'll go back to
this. I think this was our
favorite. But then we will start a short
favorite. But then we will start a short
sweep.
So, these are a bunch of reasonable
So, these are a bunch of reasonable
params. Oh, I bet that uh sweeps are
params. Oh, I bet that uh sweeps are
going to be totally screwed up though
going to be totally screwed up though
with the latest uh yeah, the
with the latest uh yeah, the
CUDA. So, what we'll do is we'll leave
Why don't we just leave batch and mini
Why don't we just leave batch and mini
batch
alone? We leave these like well enough
alone? We leave these like well enough
alone,
right? Just see if there's like any
right? Just see if there's like any
output in the rest of these.
admittedly is not very many but learning
admittedly is not very many but learning
rate entropy gamma
lambda we don't want this
lambda we don't want this
either just some of the coefficients I
either just some of the coefficients I
Yes.
Yeah, I'll just do
this. Okay, this one fails.
I think that this should
I think that this should
work. So, I go get
work. So, I go get
breakfast. I do a few things. These
breakfast. I do a few things. These
should take like 5 minutes a piece. So,
should take like 5 minutes a piece. So,
we should
get some reasonable number of
get some reasonable number of
experiments.
Make sure this actually
runs there. Okay, so this
runs there. Okay, so this
runs. So now we should have the sweep
runs. So now we should have the sweep
going. If I open this
tab, yep, we got this sweep
tab, yep, we got this sweep
going. So we will be able to see where
going. So we will be able to see where
this goes from here. And then uh I will
this goes from here. And then uh I will
be back later today probably working on
be back later today probably working on
poor puffer, other things around
poor puffer, other things around
that. Um yeah.
that. Um yeah.
This will be a nice end once we start to
This will be a nice end once we start to
get some really like decent results on
get some really like decent results on
it. So, uh, thanks for tuning in, folks.
it. So, uh, thanks for tuning in, folks.
All my stuff's at
All my stuff's at
puffer.ai. If you want to help the
puffer.ai. If you want to help the
project for free, start the GitHub.
project for free, start the GitHub.
Other than that, you can get involved
Other than that, you can get involved
with Dev on the Discord or follow me on
with Dev on the Discord or follow me on
X for more RL content. Thanks. And I
X for more RL content. Thanks. And I
will be back later
