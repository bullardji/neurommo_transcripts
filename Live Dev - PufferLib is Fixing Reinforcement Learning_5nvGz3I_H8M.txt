Kind: captions
Language: en
live. A few things to do here.
Okay. Nurmo is running here.
This one looks good,
right? Dip
there. I don't think that this one works
there. I don't think that this one works
because um there are different
because um there are different
coefficients,
right? Yeah. I don't know.
right? Yeah. I don't know.
Um I don't know if this works because I
Um I don't know if this works because I
think they're different coefficients on
think they're different coefficients on
the reward.
the reward.
Hard to say.
Guess we do a couple quick things on
Guess we do a couple quick things on
meta.
policy.
Looks like it goes
There you go.
and policy is too complicated. Amen.
Which of these policies is actually
Which of these policies is actually
uh which of these policies actually
uh which of these policies actually
matters?
I think that this is just a common
I think that this is just a common
encoder is all we need for this.
Let's see if I can start making him a
policy.
Think the neural MMO 3 policy is good,
Think the neural MMO 3 policy is good,
right?
Obs are not just one hot, he
Obs are not just one hot, he
says. Okay.
feature set encoders. This is so
feature set encoders. This is so
freaking complicated.
Config items. Yes.
It's like
almost. Oh, so I can probably just comp
almost. Oh, so I can probably just comp
this thing.
this thing.
probably just calm this
thing. Let's just get the snake
thing. Let's just get the snake
policy. Basically, just the snake
policy. Basically, just the snake
policy.
What feature should give you a list?
34 input channels.
Multi-discreet has no object and lovely
Let's see what this
does. And after this we'll have to do
does. And after this we'll have to do
normalization probably.
570k
570k
train about the same as
before. There's some data.
Is there a way to get the maxes?
That's should be able to do something
That's should be able to do something
with this,
with this,
right? We can just normalize the data a
right? We can just normalize the data a
little bit.
Wait for this and then I'll uh have a
Wait for this and then I'll uh have a
little model to
little model to
run. Nice and easy. Pure convolutional.
And then we'll see whether it's actually
And then we'll see whether it's actually
all that hard to learn.
Not
Not
bad. Good job, man. That's hilarious.
run this the main not in the
run this the main not in the
meanwhile. See if I totally broke it
meanwhile. See if I totally broke it
with um the coms.
Oops. Oh, wait. Here's the
normalizer. Lovely.
Let's see if this actually copied
correctly.
correctly.
255 100 100
100. There's seven of these. So, this is
100. There's seven of these. So, this is
three, four, five, six,
three, four, five, six,
seven. Seven of
seven. Seven of
those. Wait. 1 2 3 4 5 6
7 8 9 10 11 12 13 14 15
16 I don't want to mess this up. Let me
16 I don't want to mess this up. Let me
just let me just write this out.
There we go.
What was it? A buffer or something?
register
buffer. Okay.
Now we're cooking with
Now we're cooking with
uh what's the stupid expression? Now
uh what's the stupid expression? Now
we're cooking with
oil. Couldn't find your API
to It's
a size
42. That sir has 42 elements.
driving me crazy
here. Things don't match.
Agent lib.
God
damn. Okay, let's do it like
damn. Okay, let's do it like
this. And do it like this.
Okay, there we go.
You should be able to compare this
You should be able to compare this
one directly to the other
one directly to the other
one. We will see.
We'll see whether that helps at all with
We'll see whether that helps at all with
the
uh
uh
optim. Looks like it might. This is
optim. Looks like it might. This is
already higher.
Oh yeah, that's
helping. There we go.
helping. There we go.
I'll give this a minute to run and then
I'll give this a minute to run and then
I'll send over these results and we'll
I'll send over these results and we'll
see what this does.
Uhoh. Well, we'll see if this hits a
Uhoh. Well, we'll see if this hits a
capacity
capacity
issue. Looks like it
might, but only the encoder layer was
might, but only the encoder layer was
way wider.
Everything else was uh
worse. So that's not
great. See if it's a capacity
issue
or actually I think the thing that you
or actually I think the thing that you
would change first is
would change first is
64 here, wouldn't you?
234K
params might help a bit.
There it goes. So, that's already a
There it goes. So, that's already a
little better than the uh the previous
All right, that still goes straight
up. And we'll just see how capacity is
up. And we'll just see how capacity is
compared to the original. Original was a
compared to the original. Original was a
way larger net. So like we might have to
way larger net. So like we might have to
up the size a fair bit before we hit
up the size a fair bit before we hit
that.
Seems like that's still leveling
off.
off.
Yeah. All right. Next up is going to be
128 56.
This is like a reasonable model I would
This is like a reasonable model I would
say for like a
say for like a
medium complexity problem. You got 256
medium complexity problem. You got 256
hidden block
hidden block
size, 128 stack of
size, 128 stack of
coms. Should be decent enough.
Oh, yeah. And the baseline's only 0.1
Oh, yeah. And the baseline's only 0.1
and 100 mil. So, we're doing just fine
and 100 mil. So, we're doing just fine
here.
Okay. And yeah, here's our new one.
still transit
400k 820,000 perm model. That's a pretty
400k 820,000 perm model. That's a pretty
decent size
decent size
model. I'd be surprised if the problem's
model. I'd be surprised if the problem's
too hard for
too hard for
that. Like you can do a lot with a model
that. Like you can do a lot with a model
that size.
What did they do for their uh their
What did they do for their uh their
trainer?
50 billion time
steps mini batch one up to
steps mini batch one up to
epoch. I mean those aren't horribly far
epoch. I mean those aren't horribly far
away from ours.
All our other prams are going to be
All our other prams are going to be
different,
but interesting that this does worse.
I mean, this is these are such like a
I mean, this is these are such like a
different net size. We might have to
different net size. We might have to
retune
I don't see anything in here that would
I don't see anything in here that would
be
um anything in here that would be
um anything in here that would be
screwy. This all seems reasonable to me.
We'll let this run for a little
bit. But uh I think that the best one
bit. But uh I think that the best one
they linked to me
was they got like 0.5 in 400 million
was they got like 0.5 in 400 million
steps.
I think that's with a bigger model as
I think that's with a bigger model as
well. We've done seven
minutes. No, it's about the same size
minutes. No, it's about the same size
model, I guess. Same speed model at
model, I guess. Same speed model at
least.
think there should be anything missing
think there should be anything missing
from the
from the
conf other than maybe the self features
conf other than maybe the self features
would be
important. Probably it can't see itself.
Yeah, this is leveling out.
Torch empty. What I do here?
Close division.
and we'll see how this does. This should
and we'll see how this does. This should
be better.
surprised if this is not like
surprised if this is not like
immediately and massively
better. It's 11 by 11, right? So, isn't
better. It's 11 by 11, right? So, isn't
five the middle one?
five the middle one?
should
be. Oh yeah, there we
be. Oh yeah, there we
go. That's something.
I mean, we can easily sweep this now,
I mean, we can easily sweep this now,
right?
Okay, that'll be easy to sweep.
I hope this is this looks like it's
I hope this is this looks like it's
better than the previous one. Yeah.
And we'll see if we get the plateau if
And we'll see if we get the plateau if
it gets to 0.4, which is the best on
it gets to 0.4, which is the best on
this
end. Smooth curve.
his
best. Let's see if I'm beating his best
result. So far, yes, he got to 2 at like
result. So far, yes, he got to 2 at like
150.
I think he has a steeper slope on his
I think he has a steeper slope on his
though,
though,
maybe. Hard to
say. Is a pretty clean learning
say. Is a pretty clean learning
curve. Actually, he is. That was with
curve. Actually, he is. That was with
smoothing. He does have it
smoothing. He does have it
higher. Oh, we'll
higher. Oh, we'll
see. I don't I also don't know what
see. I don't I also don't know what
model this is with. I think this is with
model this is with. I think this is with
like um comparably sized but different
like um comparably sized but different
architecture model.
It's a clean curve at the least. Okay,
It's a clean curve at the least. Okay,
let's uh let's commit this up.
no space left on device.
no space left on device.
Really? Well, that's an interesting one.
What's the damned command? Freaking
LVM. Yeah, this is stupid.
Not this one. Where is
it? Should be a buntu
it? Should be a buntu
mapper. Yep.
I'm blindly pasting these because I've
I'm blindly pasting these because I've
done this
before. It's just the same exact setup.
before. It's just the same exact setup.
It's freaking
There we go.
Wonder if that was screwing anything
Wonder if that was screwing anything
up with the the previous
up with the the previous
run. Could have been.
Okay.
config. I hate
config. I hate
hydra. I don't know why people use
this. Failed to build
this. Failed to build
hydra. What Python are we on? 312.
The hell.
I have this running on Python 312
I have this running on Python 312
though, don't I?
stupid obsolete
package. Well, that's not getting a a
package. Well, that's not getting a a
sweep
sweep
then tonight. That's what you get for
then tonight. That's what you get for
using shitty config packages that don't
using shitty config packages that don't
[ __ ] work.
just like so incredibly
obnoxious. It didn't work because the
obnoxious. It didn't work because the
config is
broken. Yes, this is no
And how about our latest
sweeps? Yeah. So, these are still
sweeps? Yeah. So, these are still
running, which is good.
Best one so far here is this blue one.
How wacky are these hyper
prams? 2 M's is pretty
wacky. Not that bad, though.
wacky. Not that bad, though.
Not that
bad. Presumably, this is sweeping these
bad. Presumably, this is sweeping these
rewards as well.
So I guess if we just uh do
this call copy these params in and run
this call copy these params in and run
it for a long Huh?
Funny that this sound like virtually
Funny that this sound like virtually
identical to the
original. These have been increased a
original. These have been increased a
lot.
That did not copy
correctly. Copy the negative sign.
correctly. Copy the negative sign.
That's horid.
Anything I
missed? Learning rate, gamma, lambda,
missed? Learning rate, gamma, lambda,
learning
learning
rate. Think that's
rate. Think that's
everything. Oh, the betas obviously.
Cool. Let's see if this works.
Okay. And then we have the other sweep
Okay. And then we have the other sweep
running which is
solid. Oh, we got a little bit of growth
solid. Oh, we got a little bit of growth
there.
All I see so far. Whoops.
Oh five I
like we're stuck at
like we're stuck at
0.3. There might be some like semantic
0.3. There might be some like semantic
meaning to that.
Not
bad. I'll have to look at their
bad. I'll have to look at their
architecture and stuff,
but it's not like fully stuck at 3
but it's not like fully stuck at 3
either. It looks like it's still going
either. It looks like it's still going
up just slowly.
There we
go. So that is training.
That's kind of flattened
That's kind of flattened
out. That is okay. There will be more
out. That is okay. There will be more
time tomorrow.
Heck is going on in here.
What time is it? 900 p.m.
is a hell of a successful
day. I'm trying to think if there's
day. I'm trying to think if there's
anything else we can do to like make
anything else we can do to like make
sure the neural MMO stuff works well
sure the neural MMO stuff works well
overnight.
I think it is to be fair more likely at
I think it is to be fair more likely at
this point.
this point.
Like if those hypers work so well on
Like if those hypers work so well on
just about
just about
everything, it's probably just a matter
everything, it's probably just a matter
of like MUP for the learning
of like MUP for the learning
rate and
then getting the correct model size for
then getting the correct model size for
the problem.
the problem.
is probably all it is to it. I mean,
is probably all it is to it. I mean,
that's what we'll do next, right? With
that's what we'll do next, right? With
um some of these harder tasks we have
um some of these harder tasks we have
access to, it'll be worth getting up
access to, it'll be worth getting up
working and worth be getting that
working and worth be getting that
working with
working with
Muan. We'll try a few other things as
Muan. We'll try a few other things as
well, I'm sure.
I mean, there are a couple remaining
I mean, there are a couple remaining
hiccups with
hiccups with
um generalized advantage estimation that
um generalized advantage estimation that
we were still targeting, but I think
we were still targeting, but I think
overall we should
overall we should
be we should be pretty well
set. Let's take a quick look one more at
set. Let's take a quick look one more at
my
my
um MMO three runs.
so the magnitudes are clearly not
so the magnitudes are clearly not
comparable
here. There's like a step change in it.
here. There's like a step change in it.
is very sort of
is very sort of
slow
learning. Let me go check the wi result
learning. Let me go check the wi result
because I think we had a uh we have a
because I think we had a uh we have a
puffer wand result in
puffer wand result in
here. Let's look for
um so I mean here right this
um so I mean here right this
This just took a while to take off
This just took a while to take off
initially, didn't it? Like this part of
initially, didn't it? Like this part of
the curve. What is
this? So, the best one here is like 300
this? So, the best one here is like 300
mil to get 1.05, I
believe. If we look at some of these.
believe. If we look at some of these.
Yeah, because I think these were
Yeah, because I think these were
different maps. I think this is the new
different maps. I think this is the new
map. So, like you're looking for
map. So, like you're looking for
in 300 mil like only
1.05. How are we doing if uh if we take
1.05. How are we doing if uh if we take
that into
account? Still not
great. We're only at We're still under
great. We're only at We're still under
1.01.
What hyper
What hyper
prams did uh did we use for
this? I'm sure that I had them in the uh
this? I'm sure that I had them in the uh
the
the
previous version,
previous version,
but we had these rewards,
but we had these rewards,
right? And then
Big batch
Big batch
size. Little bit of
size. Little bit of
entropy. Very weird
gamma. Very weird mini
batch. Nothing much else.
probably just a matter of running the uh
probably just a matter of running the uh
the sweeps
the sweeps
then there's no reason we shouldn't be
then there's no reason we shouldn't be
able to do um you know at least this
able to do um you know at least this
well we should be totally fine I think
well we should be totally fine I think
we only had two M's as
we only had two M's as
well what was the training speed of
well what was the training speed of
this did train at
this did train at
500k which makes sense with that big
500k which makes sense with that big
mini batch
mini batch
size all right Well, I mean, I'm sure
size all right Well, I mean, I'm sure
we'll be able to get this if we want to
we'll be able to get this if we want to
get to
this. Go back to these
params. I think we'll just let uh we'll
params. I think we'll just let uh we'll
just let stuff run for
just let stuff run for
tonight and not worry too much about
it. Unless this thing has already
it. Unless this thing has already
failed.
And I might want to run the original
And I might want to run the original
config.
config.
Honestly, maybe we go run the original
config. Night, man. See you
config. Night, man. See you
around. Thanks for stopping by.
Why don't we just do something like this
Why don't we just do something like this
real
quick? Puffer box
quick? Puffer box
4. It should be puffer box
4. It should be puffer box
zero, right?
Hey, start contributing to Puffer. It's
Hey, start contributing to Puffer. It's
it's a great way to do some RL. And I
it's a great way to do some RL. And I
mean, this is really where this is where
mean, this is really where this is where
RL is getting
RL is getting
solved. I mean, you see the progress
solved. I mean, you see the progress
here. It's like this is where RL will be
here. It's like this is where RL will be
solved.
We just set up a little yolo run.
People call them yolo runs when you just
People call them yolo runs when you just
change a bunch of [ __ ] based on your own
change a bunch of [ __ ] based on your own
intuitions and uh try to just like make
intuitions and uh try to just like make
something work.
I mean, we've kind of crushed all the
I mean, we've kind of crushed all the
easier
easier
ends as of
today. Little more than trial and
today. Little more than trial and
error. Little
error. Little
more. Yeah. So, this is 4 m. So it's
more. Yeah. So, this is 4 m. So it's
nums is equal to
four. Okay. So let's see if this works.
This is like the
This is like the
originalish params with the new
originalish params with the new
optimizer and some of the nice new
optimizer and some of the nice new
goodies. And we'll see how this
works. Or it doesn't.
works. Or it doesn't.
If a run like that works, do you ever
If a run like that works, do you ever
try to figure out why by looking at the
try to figure out why by looking at the
math? So, up until
math? So, up until
today, it's just a bunch of nons. It was
today, it's just a bunch of nons. It was
just a bunch of nonsensical garbage
just a bunch of nonsensical garbage
basically every time. Today is the first
basically every time. Today is the first
day where the good uh params and the
day where the good uh params and the
good settings actually line up with what
good settings actually line up with what
you expect in RL
you expect in RL
generally. Uh this was the major
generally. Uh this was the major
breakthrough today.
breakthrough today.
RL is no longer
cursed. So really, this is
cursed. So really, this is
probably in terms of terms of just pure
probably in terms of terms of just pure
capabilities, this is probably the
capabilities, this is probably the
biggest single day advancement I've seen
biggest single day advancement I've seen
since I started working on
Puffer. So I will rest well today.
Okay.
Okay.
Well, that's about all I can do for
Well, that's about all I can do for
today. What do you do when they don't
today. What do you do when they don't
line up? How do you debug something like
line up? How do you debug something like
that? There are traces. Clear error
that? There are traces. Clear error
messages. Not in RL. There aren't
messages. Not in RL. There aren't
because there's no actual error in the
because there's no actual error in the
code, right? algorithm is implemented
code, right? algorithm is implemented
correctly, right? The algorithm is
correctly, right? The algorithm is
implemented
implemented
correctly. You've tested it against a
correctly. You've tested it against a
bunch of other stuff. You know how
bunch of other stuff. You know how
hyperparameters are supposed to scale.
hyperparameters are supposed to scale.
You know model size is supposed to
You know model size is supposed to
scale. You know all these things and
scale. You know all these things and
none of them actually happen or work the
none of them actually happen or work the
way that you expect.
That has been the problem with RL more
That has been the problem with RL more
than
than
anything because RL could since like
anything because RL could since like
2017 RL could be made to work on
2017 RL could be made to work on
virtually any problem but it was always
virtually any problem but it was always
like so janky and so difficult. So today
like so janky and so difficult. So today
is the first day where it actually works
is the first day where it actually works
roughly out of the box on like a dozen
roughly out of the box on like a dozen
different
different
environments. Where do you go from
environments. Where do you go from
there? Pain and suffering and lots of
there? Pain and suffering and lots of
trial and error like guided by your
trial and error like guided by your
intuitions, right? and like by what
intuitions, right? and like by what
knowledge you have over how these things
knowledge you have over how these things
are supposed to behave, but often you're
are supposed to behave, but often you're
just wrong. And even like the best
just wrong. And even like the best
person in the world in RL is going to
person in the world in RL is going to
just be wrong cuz they just don't make
just be wrong cuz they just don't make
any bloody
sense. So today is the first day where
sense. So today is the first day where
RL is not like
RL is not like
that. That's why this is such a big
that. That's why this is such a big
deal.
deal.
There's still some small limitations,
There's still some small limitations,
but now we pretty much know what we have
but now we pretty much know what we have
to do. And the parts that like were
to do. And the parts that like were
completely unexplainable
completely unexplainable
uh have now been explained and now
work. I mean, I said my goal for the
work. I mean, I said my goal for the
year, right, is we want to make RL 10
year, right, is we want to make RL 10
times easier to get up and running on a
times easier to get up and running on a
new problem.
If we were like, you know, maybe we were
If we were like, you know, maybe we were
30% of the way there yesterday. Today
30% of the way there yesterday. Today
we're like 70% of the way
we're like 70% of the way
there. Where do you go from here?
there. Where do you go from here?
There's still a few things that we need
There's still a few things that we need
to do. I think we need MUP so that uh
to do. I think we need MUP so that uh
learning rate actually behaves the way
learning rate actually behaves the way
that we
that we
expect. And then the new algorithm is
expect. And then the new algorithm is
going to handle gamma and lambda being
going to handle gamma and lambda being
weird and we should be
weird and we should be
good. Do you build tools for easier
good. Do you build tools for easier
debugging more environments more? Well,
debugging more environments more? Well,
I mean, you see what I've done, right? I
I mean, you see what I've done, right? I
said, "Okay, none of this stuff makes
said, "Okay, none of this stuff makes
any sense, and we're going to have to
any sense, and we're going to have to
run thousands of experiments to figure
run thousands of experiments to figure
it out." So, I made a bunch of
it out." So, I made a bunch of
environments that run really, really,
environments that run really, really,
really fast, right? Like, you know how
really fast, right? Like, you know how
many experiments have taken me to get to
many experiments have taken me to get to
here? Here, these are all experiments
from 25,000 experiments from the last
from 25,000 experiments from the last
like three months.
These are just like my personal
These are just like my personal
experiments for fiddling with
experiments for fiddling with
stuff.
Yeah, this is probably
like I don't know order of like 10
like I don't know order of like 10
trillion steps worth of experiments.
So the data scale that's involved here
So the data scale that's involved here
to make this stuff work, uh, this right
to make this stuff work, uh, this right
here would be like without puffer libs
here would be like without puffer libs
environments, this would be like a,000
environments, this would be like a,000
GPU years worth of compute or
GPU years worth of compute or
more, probably a lot
more. So that's how we got here, right?
more. So that's how we got here, right?
We made a bunch of environments. We made
We made a bunch of environments. We made
them really fast. We use the
them really fast. We use the
environments to figure out what the heck
environments to figure out what the heck
is
is
wrong since Puffer lo. Yeah, the
wrong since Puffer lo. Yeah, the
environments are
environments are
fast. So, we run more
fast. So, we run more
experiments. Of course, our trainer is
experiments. Of course, our trainer is
also
faster. We've kind of optimized the full
faster. We've kind of optimized the full
stack.
I mean, you can see what these are as
I mean, you can see what these are as
well because they're
grouped. So, most of these are like
grouped. So, most of these are like
groups of 200 experiment hyperparam
groups of 200 experiment hyperparam
sweeps. So, it's not just 25
sweeps. So, it's not just 25
experiments,
experiments,
uh, 25,000 experiments. It's groups of
uh, 25,000 experiments. It's groups of
like a couple
like a couple
hundred intelligently optimized
hundred intelligently optimized
experiments using methods I developed
experiments using methods I developed
that didn't exist
that didn't exist
before. So, it's been this whole massive
before. So, it's been this whole massive
massive process to get
here. But
here. But
now we have uh RL just working out of
now we have uh RL just working out of
the box on
the box on
all the M's in puffer with the exception
all the M's in puffer with the exception
of a couple tweaks being needed for
of a couple tweaks being needed for
neural MMO which we're doing right now
neural MMO which we're doing right now
because that M's are really really
hard. But yeah, this is this was the
hard. But yeah, this is this was the
goal with Puffer, right? We've got a few
goal with Puffer, right? We've got a few
things left, a few things that are still
things left, a few things that are still
one thing that's pretty easy and one
one thing that's pretty easy and one
thing that's pretty hard, I think.
thing that's pretty hard, I think.
Um, and then we just kind of got RL
Um, and then we just kind of got RL
working and we'll see where we go from
working and we'll see where we go from
there. I think I'm going to want to take
there. I think I'm going to want to take
this stuff and like throw it on, you
this stuff and like throw it on, you
know, hard RL problems in
know, hard RL problems in
industry. Um, we're going to make some
industry. Um, we're going to make some
really awesome
really awesome
demos. We're going to release some
demos. We're going to release some
really clean and really fast tools.
really clean and really fast tools.
We'll see from there.
We'll see from there.
Uh bet it's currently the there's a dev
Uh bet it's currently the there's a dev
branch in puffer tank that we were
branch in puffer tank that we were
using. Wasn't Puffer's goal to make a
using. Wasn't Puffer's goal to make a
framework to make RL I wouldn't say
framework to make RL I wouldn't say
framework but yes the goal was to make
framework but yes the goal was to make
RL advancements easier. Here you
RL advancements easier. Here you
go.
Right. Tools. Yeah. Lighter weight
Right. Tools. Yeah. Lighter weight
tools.
It's hardly a framework when you have
It's hardly a framework when you have
like a single file trainer,
right? There's
right? There's
like probably like three or four times
like probably like three or four times
more code in the environments versus the
more code in the environments versus the
uh the rest of puffer lip together.
Like with all the newest environments
Like with all the newest environments
being PR, it'll be about 30,000 lines of
being PR, it'll be about 30,000 lines of
environments and maybe like a few
environments and maybe like a few
thousand poor lines of uh of Python that
thousand poor lines of uh of Python that
we're actually
we're actually
using. Yeah, framework's bad.
using. Yeah, framework's bad.
Framework's never good.
Framework's never good.
I really don't like big clunky heavily
I really don't like big clunky heavily
abstracted stuff, especially not in
Python, but not really
anywhere. So, neural MMO 3 is going to
anywhere. So, neural MMO 3 is going to
be the real
be the real
test. Neural MMO 3 is
test. Neural MMO 3 is
hard. We should be able to beat the
hard. We should be able to beat the
previous baseline, but then we'll see
previous baseline, but then we'll see
where we go from there.
If I were an undergrad, I'd be I would
If I were an undergrad, I'd be I would
so just puffer live.
Yeah. Well, just contribute,
Yeah. Well, just contribute,
right? Come build some cool
stuff. Yeah. I mean, I I usually stream
stuff. Yeah. I mean, I I usually stream
all day Saturday. So, if you get
all day Saturday. So, if you get
stuck, I usually I stream all day s
stuck, I usually I stream all day s
Saturday and then Sunday I like go and
Saturday and then Sunday I like go and
do a bunch of exercise and like not code
do a bunch of exercise and like not code
a
a
ton. Job search
ton. Job search
sucks. Job search is
rough. But hey, you know, our best
rough. But hey, you know, our best
contributors are people here that have
contributors are people here that have
came in with zero RL experience.
So you can kind of do a lot of stuff
So you can kind of do a lot of stuff
quite quickly
quite quickly
now. Awesome. Look forward to
now. Awesome. Look forward to
it. There's really not that much uh
it. There's really not that much uh
puffer lip specific to learn cuz like
puffer lip specific to learn cuz like
it's really a thin piece of software.
it's really a thin piece of software.
The dev branch has some clunk to it just
The dev branch has some clunk to it just
because like you know there are flags
because like you know there are flags
for all the new like algorithmic tidbits
for all the new like algorithmic tidbits
that we're testing. But generally puffer
that we're testing. But generally puffer
is really
is really
thin. There's not a ton to learn. RL
thin. There's not a ton to learn. RL
generally yeah there's a fair bit to
generally yeah there's a fair bit to
learn but not puffer
learn but not puffer
lib. It's just CMS with some RL Python
lib. It's just CMS with some RL Python
algos. It's just CMS with
algos. It's just CMS with
uh there's one very nice like few
uh there's one very nice like few
hundred line piece of code that does
hundred line piece of code that does
very fast multipprocessing and then
very fast multipprocessing and then
there's one like
there's one like
roughly,500ish line piece of code that
roughly,500ish line piece of code that
is our entire algorithm and trainer
is our entire algorithm and trainer
implementation. That is
implementation. That is
it. Sython's just like a trivial little
it. Sython's just like a trivial little
binding to
binding to
see. That's all there is.
see. That's all there is.
You know, we have some other tools for
You know, we have some other tools for
nonpuffer ends if you want to wrap third
nonpuffer ends if you want to wrap third
party stuff quickly, but generally
party stuff quickly, but generally
that's all it
is. I mean, there are a few nice things
is. I mean, there are a few nice things
I came up with, right, to make this
I came up with, right, to make this
fast. Like the C writes uh the C code
fast. Like the C writes uh the C code
writes observations directly into shared
writes observations directly into shared
memory buffers that are in contiguous
memory buffers that are in contiguous
memory.
memory.
But I have all that set up for you and
But I have all that set up for you and
it's very easy to use. And the actual
it's very easy to use. And the actual
thing that implements it is like a few
thing that implements it is like a few
dozen lines of code. You just kind of
dozen lines of code. You just kind of
have to understand it
all. That's
all. We're very much looking for new
all. We're very much looking for new
contributors, by the way. Like the way
contributors, by the way. Like the way
it works around here, and I think you've
it works around here, and I think you've
seen if you've been on uh many of these
seen if you've been on uh many of these
streams, right, is anybody who actually
streams, right, is anybody who actually
puts effort into like building M's,
puts effort into like building M's,
helping with buffer lip, uh I put effort
helping with buffer lip, uh I put effort
back into them, you
back into them, you
know, you know, the people who've been
know, you know, the people who've been
building M. I code review every single
building M. I code review every single
line of the contributions. We go through
line of the contributions. We go through
I try to share some like insights on how
I try to share some like insights on how
to think about RL and try to get people
to think about RL and try to get people
doing stuff that will help them learn
doing stuff that will help them learn
and push puffer
forward. Jose painstakingly put this
forward. Jose painstakingly put this
together. Yeah, I'm a little tiny bit
together. Yeah, I'm a little tiny bit
um I'm a bit pigantic on trying to keep
um I'm a bit pigantic on trying to keep
the code like brain dead
the code like brain dead
simple, but that's about it. It's like
simple, but that's about it. It's like
if anybody uses like any remotely fancy
if anybody uses like any remotely fancy
abstractions, I'm just like get that out
abstractions, I'm just like get that out
of
here. This code should be brain dead
here. This code should be brain dead
simple. But hey, you know, there's a
simple. But hey, you know, there's a
reason for it. No
reason for it. No
decorators. I think we have a couple at
decorators. I think we have a couple at
property decorators and that's about it,
property decorators and that's about it,
honestly.
honestly.
I mean, we don't
I mean, we don't
have I think there's like one place I
have I think there's like one place I
couldn't get away from having an
couldn't get away from having an
inherited class, but other than that,
inherited class, but other than that,
like very like try to not
like very like try to not
object-orient like functional dog. It's
object-orient like functional dog. It's
just like brain dead simple code on
data. That's the
data. That's the
goal. No mixins. [ __ ] that.
But, you know, I get on people's case
But, you know, I get on people's case
over dumb stuff, right? Like, I don't
over dumb stuff, right? Like, I don't
let people use double pointers. Like, I
let people use double pointers. Like, I
don't let people do like double
don't let people do like double
pointers. I don't let people be um doing
pointers. I don't let people be um doing
even freaking union types most of the
even freaking union types most of the
time. Um, what
time. Um, what
else? What are the other ones? Oh, yeah.
else? What are the other ones? Oh, yeah.
No dynamic memory allocation. Screw
No dynamic memory allocation. Screw
that. Like, it's just very, very simple
that. Like, it's just very, very simple
code. It's like look, you write if
code. It's like look, you write if
statements, you write some loops, you
statements, you write some loops, you
write some assignments. That's all you
write some assignments. That's all you
need. You don't believe me? Look at the
need. You don't believe me? Look at the
neural MMO code. That's all I
use. Oh yeah, and don't write too many
use. Oh yeah, and don't write too many
damn functions.
Sometimes you need dynamic outlets, but
Sometimes you need dynamic outlets, but
like I think there's maybe two places
like I think there's maybe two places
total uh that we needed them in the
total uh that we needed them in the
environments that we have. I think I
environments that we have. I think I
needed them in neural MMO just for the
needed them in neural MMO just for the
map generation because the maps can be
map generation because the maps can be
like 4096 x
4096. Ah yeah, but you introduced an
4096. Ah yeah, but you introduced an
arena, right? And now you have this
arena, right? And now you have this
other abstraction. It's like you don't
other abstraction. It's like you don't
need the dynamic Alex most of the time.
need the dynamic Alex most of the time.
Believe me. What we actually do is we
Believe me. What we actually do is we
allocate a lot of memory from Python
allocate a lot of memory from Python
because it needs to be a shared buffer
because it needs to be a shared buffer
anyways. You'll
anyways. You'll
see there is still a little bit of
see there is still a little bit of
boiler plate which I'm not happy
boiler plate which I'm not happy
with. Like the boiler plate's mostly
with. Like the boiler plate's mostly
because you have to go it's not because
because you have to go it's not because
of the C. It's because you have to go
of the C. It's because you have to go
through Syon to get to Python. So, you
through Syon to get to Python. So, you
know, there's a little bit of boiler
know, there's a little bit of boiler
plate associated with uh going from C to
plate associated with uh going from C to
Syon to Python, but it's not
bad and it's like really really easy and
bad and it's like really really easy and
self-explanatory.
figure Python types can be used function
figure Python types can be used function
args. No, actually that's the one thing
args. No, actually that's the one thing
that Sython does for us. But the problem
that Sython does for us. But the problem
with Python is you kind of have to redo
with Python is you kind of have to redo
the whole
the whole
header. Like you have it, you already
header. Like you have it, you already
have the def the function definitions in
have the def the function definitions in
um in C, but then Syon makes you redo a
um in C, but then Syon makes you redo a
header anyways. And then like you know
header anyways. And then like you know
you have your step method in C and you
you have your step method in C and you
have your step method in Syon and you
have your step method in Syon and you
have your step method in Python. So it's
have your step method in Python. So it's
a little
a little
stupid but um that's more of like a
stupid but um that's more of like a
language interoperability limitation
language interoperability limitation
than anything. That's kind of the worst
than anything. That's kind of the worst
bit at the
bit at the
moment. Nothing else is really a
moment. Nothing else is really a
problem. The one other thing is like you
problem. The one other thing is like you
know it's designed to work in pure C but
know it's designed to work in pure C but
also in Python. So like Python is going
also in Python. So like Python is going
to pass you your observation buffers and
to pass you your observation buffers and
then you're just going to init whatever
then you're just going to init whatever
other variables you need. But if you're
other variables you need. But if you're
going to try to like demo the envure C
going to try to like demo the envure C
which is how we run it on the website uh
which is how we run it on the website uh
then you need to allocate your own
then you need to allocate your own
buffer. So there are two different init
buffer. So there are two different init
functions. One for allocate your
functions. One for allocate your
yourself and the other for pass in
pre-allocated. And the other thing which
pre-allocated. And the other thing which
is not which is not hard but is actually
is not which is not hard but is actually
really cool is we have our own neural
really cool is we have our own neural
net library in pure C that we use for
net library in pure C that we use for
the web
the web
demos. It's like I don't know I was
demos. It's like I don't know I was
pretty proud of
pretty proud of
this. It's just really simple. There's a
this. It's just really simple. There's a
pufferet.h. So this is less than 600
pufferet.h. So this is less than 600
lines of real code. No backward pass
lines of real code. No backward pass
just forward mode for um for web demos.
just forward mode for um for web demos.
So you see like it's like here's a
So you see like it's like here's a
matrix multiply. Here's with
matrix multiply. Here's with
accumulation. Here's a 2D
accumulation. Here's a 2D
conf. I don't actually use that arena
conf. I don't actually use that arena
actually. I was playing with it but I
actually. I was playing with it but I
didn't. We don't actually use
didn't. We don't actually use
it. Here's an LSTM. So this is a this
it. Here's an LSTM. So this is a this
function right here. This is an LSTM and
function right here. This is an LSTM and
C,
C,
right? It's really
right? It's really
simple. Making the com sim. I mean, we
simple. Making the com sim. I mean, we
could. You'd also want to tile it and
could. You'd also want to tile it and
stuff. Um, the only thing that it would
stuff. Um, the only thing that it would
kind of do is maybe let us run slightly
kind of do is maybe let us run slightly
larger networks on our web demos though
larger networks on our web demos though
because like all of these are running in
because like all of these are running in
C and they like they already work,
C and they like they already work,
right? This is the neural MMO policy,
right? This is the neural MMO policy,
you know, this is the breakout
you know, this is the breakout
policy little triad.
policy little triad.
Like these are all just running train
Like these are all just running train
neural nets. And
see some of them are super human. It's
see some of them are super human. It's
pretty
cool. I really like this enduro
one. Bet worked really hard on this.
This was kind of funny because um see I
This was kind of funny because um see I
gave bet this project thinking it was a
gave bet this project thinking it was a
lot simpler than it
lot simpler than it
is. So like Bet is still pretty new and
is. So like Bet is still pretty new and
was even newer when I gave him this
was even newer when I gave him this
project to programming in general. So I
project to programming in general. So I
kind of gave him like too big of a
kind of gave him like too big of a
project but he did it
project but he did it
anyways. At first, like the first time
anyways. At first, like the first time
he did it with like two to three times
he did it with like two to three times
too much code, but he paired it down and
too much code, but he paired it down and
now it's pretty
decent. Yeah. Well, I mean, bet you
decent. Yeah. Well, I mean, bet you
should see some of the [ __ ] that I wrote
should see some of the [ __ ] that I wrote
when I was new. I've written some like
when I was new. I've written some like
ridiculously over verbose
code. Like I've written some truly awful
code. Like I've written some truly awful
things.
I think I had in my thesis.
Um, do I actually have this on
my I think I probably do have this on my
my I think I probably do have this on my
uh on my GitHub.
This was an early attempt at neural MMO
This was an early attempt at neural MMO
before I knew what the hell I was
doing. Do you guys type in?
doing. Do you guys type in?
Nope. I actually that's a pet peeve of
Nope. I actually that's a pet peeve of
mine. I hate typed
Python. The reason being that the types
Python. The reason being that the types
are not actually enforced.
Instead, we just write less
Python. The thing is that people think
Python. The thing is that people think
that they're enforced and they're not.
Oh yeah, this thing. This is a Panda's
Oh yeah, this thing. This is a Panda's
3D visualizer I wrote uh I wrote this
3D visualizer I wrote uh I wrote this
the week I discovered Monster Energy in
the week I discovered Monster Energy in
college. I think this was like two
college. I think this was like two
nights up until 4 in the morning to make
nights up until 4 in the morning to make
this thing work.
Oh, now yeah, college was a crazy
Yeah, I think I had a screenshot in my
Yeah, I think I had a screenshot in my
defense of
defense of
this. Okay, so welcome everyone.
There were a lot of systems in here. So
There were a lot of systems in here. So
this is the super early screenshot from
this is the super early screenshot from
open
open
AI discover built this
in
in
that. So this early version of neural
that. So this early version of neural
combat
screen by continuing to make the
screen by continuing to make the
problemer.
So if we could figure out how to fix
So if we could figure out how to fix
that, then I think you'd probably be
that, then I think you'd probably be
able to get cooperation before
able to get cooperation before
cooperation with all the new mechanics
cooperation with all the new mechanics
on reasonably small scale. And after
on reasonably small scale. And after
that, you need more game mechanics.
that, you need more game mechanics.
Well, okay. Um,
that was a cool thing with
it. Basically, I interviewed there to
it. Basically, I interviewed there to
build neural
MMO. The idea didn't come after
Oh yeah, this is super
old. So this is like some of the
old. So this is like some of the
oldest. This was like when I was just
oldest. This was like when I was just
like using really crappy genetic
like using really crappy genetic
algorithms on stuff.
Here it
Here it
is. This is the uh I remember exactly
is. This is the uh I remember exactly
where I was when I built this. I was in
where I was when I built this. I was in
a hotel with my family on Thanksgiving
a hotel with my family on Thanksgiving
break. I just discovered monster and was
break. I just discovered monster and was
downing like two or three of them a
day and I wrote this like shitty
day and I wrote this like shitty
Minecraft knockoff client
Minecraft knockoff client
um in Pandas
um in Pandas
3D. It ran like 15 fps, but it ran and I
3D. It ran like 15 fps, but it ran and I
was like trying to get agents to run
was like trying to get agents to run
around and learn how to cut down trees.
You can see like the awful terrain gen.
You can see like the awful terrain gen.
It's This is literally like breath first
It's This is literally like breath first
search filling in diamonds with
search filling in diamonds with
different
different
squares. You see this like terrible ore
squares. You see this like terrible ore
generation at the
bottom. But yeah, this is this is the
bottom. But yeah, this is this is the
second time I tried neural MMO. I don't
second time I tried neural MMO. I don't
think I have code from before this, but
think I have code from before this, but
there was even an earlier version of
there was even an earlier version of
this when I tried to do this when I was
this when I tried to do this when I was
even younger and knew even less than
this. This was
this. This was
probably if you look at the code, the
probably if you look at the code, the
code is awful, but this was like kind of
code is awful, but this was like kind of
the first time. So, I started coding at
the first time. So, I started coding at
14, right? And then like that project
14, right? And then like that project
there, that's probably the most complex
there, that's probably the most complex
thing that I'd built up until that time.
thing that I'd built up until that time.
So I was I think
19. I was probably 19 at the time. 18 or
19. I was probably 19 at the time. 18 or
19. So it
19. So it
took a good four years of like
took a good four years of like
continuous programming before I could
continuous programming before I could
like kind of do a small project even if
like kind of do a small project even if
I was making a total mess of
it. And then I'd
it. And then I'd
say another four
say another four
years. Is it another four years? No,
years. Is it another four years? No,
another two years before I was writing
another two years before I was writing
code that was better than the majority
code that was better than the majority
of
of
researchers, which is a very low bar.
two years after that for like doing
two years after that for like doing
competent
competent
midscale projects like you know sort of
midscale projects like you know sort of
middle stage versions of neural MMO 2 or
middle stage versions of neural MMO 2 or
neural MMO one
neural MMO one
rather and then the
rather and then the
last over the last few years really
last over the last few years really
being able to build
whatever in the last year in particular
whatever in the last year in particular
I've actually gotten I think I've gotten
I've actually gotten I think I've gotten
at least twice as good at what I do just
at least twice as good at what I do just
in the last year alone
mainly just from having the freedom to
mainly just from having the freedom to
like do stuff the way I want without the
like do stuff the way I want without the
academic constraints, you
academic constraints, you
know. But hey, I guess this is supposed
know. But hey, I guess this is supposed
to be kind of motivational in the sense
to be kind of motivational in the sense
that it takes some time. It takes some
that it takes some time. It takes some
hard work. But hey, if any of you folks
hard work. But hey, if any of you folks
want to get into RL and want to help me
want to get into RL and want to help me
build some awesome stuff, Discord's
build some awesome stuff, Discord's
open. Come drop by.
Yeah, it's
Yeah, it's
been it's been a pretty singular focus
been it's been a pretty singular focus
and star puffer li on GitHub. That
and star puffer li on GitHub. That
actually does help us a lot. Sometimes
actually does help us a lot. Sometimes
the star chart figure breaks, but here
the star chart figure breaks, but here
it
it
is.
is.
1779. That's pretty damn good for an RL
1779. That's pretty damn good for an RL
library. That's like one of the bigger
library. That's like one of the bigger
ones at this point.
It's funny how whenever I start talking
It's funny how whenever I start talking
about stuff like this you like the
about stuff like this you like the
viewer count just pops up on YouTube and
viewer count just pops up on YouTube and
Twitch. Hi
folks. Do you think we've gotten any
folks. Do you think we've gotten any
cool experiments done in the meantime?
cool experiments done in the meantime?
Well, I've been
reminiscing. Yeah, I mean there are a
reminiscing. Yeah, I mean there are a
few. It's very hard to learn this
few. It's very hard to learn this
end. It was very
end. It was very
hard. Does this
hard. Does this
work? Oh, this does work. This one works
work? Oh, this does work. This one works
though. These are the original params
though. These are the original params
that we tuned for uh for neural
that we tuned for uh for neural
MMO. So this
is 1.15 at a
is 1.15 at a
billion. What was the
original? Yeah, it works. So it does
original? Yeah, it works. So it does
train
doesn't train as well as this
doesn't train as well as this
though. Wait, hang
though. Wait, hang
on. Something seems weird to me. This is
on. Something seems weird to me. This is
a 10 billion
run. Three. Three.
Three. This is the run right here. I was
Three. This is the run right here. I was
looking at the wrong
one. See there? This one actually has
one. See there? This one actually has
1.4 at 1
billion. So, something
changed. PieTorch.
Uh yeah, SP3
is by modern standards. There's some
is by modern standards. There's some
needs some work. What's the reward for
needs some work. What's the reward for
neural MMO? Well, this is the new neural
neural MMO? Well, this is the new neural
MMO, which is actually kind of kind of
MMO, which is actually kind of kind of
complicated, right? And there's no
complicated, right? And there's no
population
population
size. Oops.
So, this is this game right
So, this is this game right
here. And uh it's kind of
here. And uh it's kind of
big. And this isn't even the fullsize
big. And this isn't even the fullsize
map. This is just the one that we throw
map. This is just the one that we throw
on the
on the
web. But these are enemies. They come in
web. But these are enemies. They come in
different levels. All these are
different levels. All these are
different items you can collect with
different items you can collect with
different
different
tools. This is running. Yeah, this is
tools. This is running. Yeah, this is
running in my client right here in my
running in my client right here in my
browser on one core.
It's only running a few neural nets,
though. It's only running a few neural
though. It's only running a few neural
nets cuz the uh the network
nets cuz the uh the network
implementation isn't optimized. So, the
implementation isn't optimized. So, the
red ones are hostile NPCs. This is a
red ones are hostile NPCs. This is a
neural net. Now, this guy doesn't seem
neural net. Now, this guy doesn't seem
to be doing anything because the
to be doing anything because the
policyy's not amazing. It will just stop
policyy's not amazing. It will just stop
doing stuff for a while. But, if an
doing stuff for a while. But, if an
enemy comes over, it will like run away
enemy comes over, it will like run away
from the enemy and start doing stuff
from the enemy and start doing stuff
again.
again.
You context switch between NPCs. You can
You context switch between NPCs. You can
just scroll around. Here's an NPC.
just scroll around. Here's an NPC.
Here's an NPC.
Right? You can play this on the website.
Right? You can play this on the website.
If you just hit control, you'll see
If you just hit control, you'll see
it'll stop. And now this is me
it'll stop. And now this is me
playing. And I can like move this guy
playing. And I can like move this guy
around and like I can go find an enemy
around and like I can go find an enemy
that I think he can beat. for
that I think he can beat. for
instance. Let me see if I can find He
instance. Let me see if I can find He
can't win against any of these
can't win against any of these
guys. Okay, he can beat this level one
guys. Okay, he can beat this level one
if he's if he's
if he's if he's
smart. So
smart. So
here there, this is no longer me
playing. And he just he misguided that
playing. And he just he misguided that
one by one hit. So we
one by one hit. So we
lost. Uh the NPCs are not controlled by
lost. Uh the NPCs are not controlled by
neural nets. The players are controlled
neural nets. The players are controlled
by neural
maps. The NPCs have like basic path
maps. The NPCs have like basic path
finding and like basic scripted AI. Uh
finding and like basic scripted AI. Uh
these guys are controlled by neural nets
these guys are controlled by neural nets
and they don't look like much, but if
and they don't look like much, but if
you watch them for long enough, they
you watch them for long enough, they
will actually do some pretty impressive
will actually do some pretty impressive
stuff. It's just like they don't really
stuff. It's just like they don't really
have any motivation to do it. So,
have any motivation to do it. So,
they'll kind of just wander around for a
they'll kind of just wander around for a
bit. But, if you watch these guys for
bit. But, if you watch these guys for
long enough, they will actually like get
long enough, they will actually like get
a whole bunch of levels, collect and
a whole bunch of levels, collect and
equip a bunch of different items, avoid
equip a bunch of different items, avoid
some enemies reasonably well. Um, like
some enemies reasonably well. Um, like
they actually learn a lot of interesting
they actually learn a lot of interesting
stuff if you watch them for long enough.
stuff if you watch them for long enough.
Now, my goal with this now that we've
Now, my goal with this now that we've
made the algorithm so much better is to
made the algorithm so much better is to
get some like really impressive policies
get some like really impressive policies
on neural MMO 3. I think that would be
on neural MMO 3. I think that would be
fun because this is really like way more
fun because this is really like way more
complex of an end than pretty much
complex of an end than pretty much
everything else out
everything else out
there. Is it super complicated? It's not
there. Is it super complicated? It's not
super complicated. I think it has like
super complicated. I think it has like
four components right now. So, I'll show
four components right now. So, I'll show
you how I I deal with it.
It's like really easy to make these.
It's like really easy to make these.
So, they get a reward every time they
So, they get a reward every time they
level up in combat. They get a reward
level up in combat. They get a reward
every time they level up uh a
every time they level up uh a
profession. They get a reward for
profession. They get a reward for
getting better quality
getting better quality
items. There's a reward for using the
items. There's a reward for using the
market, which is currently set to zero.
market, which is currently set to zero.
And there's a reward for dying. I don't
And there's a reward for dying. I don't
set these coefficients manually. I sweep
set these coefficients manually. I sweep
over these. I treat these as
over these. I treat these as
hyperparameters and optimize them with
hyperparameters and optimize them with
the hyperparam sweep
the hyperparam sweep
algo. So you see I don't actually have
algo. So you see I don't actually have
to know how important each of these are.
to know how important each of these are.
I just had to pick like five important
I just had to pick like five important
things in the environment. So I just
things in the environment. So I just
picked five important things. I added
picked five important things. I added
them into the reward code and then I let
them into the reward code and then I let
the uh the hyperparam sweep optimize the
the uh the hyperparam sweep optimize the
coefficients. Pretty cool, right?
This is the sweep config and it just
This is the sweep config and it just
sweeps over
them. We'll see what this guy does.
Maybe this ends up doing better. We'll
Maybe this ends up doing better. We'll
see longer
see longer
term. It's cool though either
term. It's cool though either
way. Swap the neuronetypers.
way. Swap the neuronetypers.
Yep, we
Yep, we
did. And it was actually very fiddly to
did. And it was actually very fiddly to
get the uh the original policies to
get the uh the original policies to
work. But here's the thing. As of today,
work. But here's the thing. As of today,
we now have roughly one set of
we now have roughly one set of
hyperparameters that works for every
hyperparameters that works for every
single environment in Puffer Lib except
single environment in Puffer Lib except
neural
neural
MMO. Neural MMO is the hard
MMO. Neural MMO is the hard
one, but I'm guessing that we probably
one, but I'm guessing that we probably
only have to fiddle a couple we only
only have to fiddle a couple we only
have to fiddle with a couple of those
have to fiddle with a couple of those
hyperparameters to get neural MMO to
hyperparameters to get neural MMO to
work as well. It's going to be my
work as well. It's going to be my
guess and we're going to understand why.
guess and we're going to understand why.
That's going to be the next
thing. This is the major breakthrough
thing. This is the major breakthrough
today. Right before today, every single
today. Right before today, every single
environment needed like a 200 parameter,
environment needed like a 200 parameter,
a 200 experiment hyperparameter sweep to
a 200 experiment hyperparameter sweep to
even do something remotely
even do something remotely
reasonable. Now we have one set of
reasonable. Now we have one set of
hypers, pretty much one set of hypers.
hypers, pretty much one set of hypers.
Couple small tweaks. It didn't take very
Couple small tweaks. It didn't take very
long at all. Solves everything.
long at all. Solves everything.
does better than the original
does better than the original
hyperparameters in the majority of the
hyperparameters in the majority of the
environments and does at least
environments and does at least
reasonably well in the
reasonably well in the
rest. I checked all the
rest. I checked all the
MS. I did check all the
ends. It's pretty
cool.
cool.
Well, it depends which parameters change
Well, it depends which parameters change
in neural MMO,
in neural MMO,
right? If the batch size changes a
right? If the batch size changes a
little bit, that's
little bit, that's
understandable, right? If we just need
understandable, right? If we just need
to increase the mini batch size for
to increase the mini batch size for
example, okay, you know, a neural MMO is
example, okay, you know, a neural MMO is
a hard M. There's too much variance to
a hard M. There's too much variance to
do small mini batches on neural
do small mini batches on neural
MMO. If we have to change the learning
MMO. If we have to change the learning
rate, that's also understandable. It's a
rate, that's also understandable. It's a
larger network than uh in the other MS.
larger network than uh in the other MS.
Larger networks need lower learning
Larger networks need lower learning
rates, at least if you're not using
rates, at least if you're not using
MUP, which we don't have integrated yet.
MUP, which we don't have integrated yet.
Now, if everything needs to be changed,
Now, if everything needs to be changed,
yeah, then there's an
yeah, then there's an
issue. But the ones that I will say I'm
issue. But the ones that I will say I'm
a little suspicious of, this gamma and
a little suspicious of, this gamma and
lambda, I have a separate effort to
lambda, I have a separate effort to
delete
delete
these. The other algorithm I've been
these. The other algorithm I've been
working on, if it works, it will delete
working on, if it works, it will delete
these two parameters
these two parameters
entirely. So, there is good stuff
entirely. So, there is good stuff
coming. Definitely good stuff coming.
go back to work. See you this Saturday.
go back to work. See you this Saturday.
Sounds good. I think I'm going to go to
Sounds good. I think I'm going to go to
bed. Uh I'm going to go to bed and get
bed. Uh I'm going to go to bed and get
started first thing in the morning.
started first thing in the morning.
Well, after I run in the
morning. So, for folks watching, all my
morning. So, for folks watching, all my
stuff's here. Puffer.ai. I it's all open
stuff's here. Puffer.ai. I it's all open
source including all the new
source including all the new
advancements there in
advancements there in
dev. You want to support the project for
dev. You want to support the project for
free? Start the
free? Start the
repository. You work at a company and
repository. You work at a company and
you want to get the latest in
you want to get the latest in
reinforcement learning working directly
reinforcement learning working directly
on your stuff and want to get my eyes on
on your stuff and want to get my eyes on
your
your
project. Check out our service tab. We
project. Check out our service tab. We
do offer support contracts.
Other than that, you can join the
Other than that, you can join the
Discord to get involved with
Discord to get involved with
development and you can follow me on X
development and you can follow me on X
for more reinforcement learning content.

Kind: captions
Language: en
live. A few things to do here.
Okay. Nurmo is running here.
This one looks good,
right? Dip
there. I don't think that this one works
there. I don't think that this one works
because um there are different
because um there are different
coefficients,
right? Yeah. I don't know.
right? Yeah. I don't know.
Um I don't know if this works because I
Um I don't know if this works because I
think they're different coefficients on
think they're different coefficients on
the reward.
the reward.
Hard to say.
Guess we do a couple quick things on
Guess we do a couple quick things on
meta.
policy.
Looks like it goes
There you go.
and policy is too complicated. Amen.
Which of these policies is actually
Which of these policies is actually
uh which of these policies actually
uh which of these policies actually
matters?
I think that this is just a common
I think that this is just a common
encoder is all we need for this.
Let's see if I can start making him a
policy.
Think the neural MMO 3 policy is good,
Think the neural MMO 3 policy is good,
right?
Obs are not just one hot, he
Obs are not just one hot, he
says. Okay.
feature set encoders. This is so
feature set encoders. This is so
freaking complicated.
Config items. Yes.
It's like
almost. Oh, so I can probably just comp
almost. Oh, so I can probably just comp
this thing.
this thing.
probably just calm this
thing. Let's just get the snake
thing. Let's just get the snake
policy. Basically, just the snake
policy. Basically, just the snake
policy.
What feature should give you a list?
34 input channels.
Multi-discreet has no object and lovely
Let's see what this
does. And after this we'll have to do
does. And after this we'll have to do
normalization probably.
570k
570k
train about the same as
before. There's some data.
Is there a way to get the maxes?
That's should be able to do something
That's should be able to do something
with this,
with this,
right? We can just normalize the data a
right? We can just normalize the data a
little bit.
Wait for this and then I'll uh have a
Wait for this and then I'll uh have a
little model to
little model to
run. Nice and easy. Pure convolutional.
And then we'll see whether it's actually
And then we'll see whether it's actually
all that hard to learn.
Not
Not
bad. Good job, man. That's hilarious.
run this the main not in the
run this the main not in the
meanwhile. See if I totally broke it
meanwhile. See if I totally broke it
with um the coms.
Oops. Oh, wait. Here's the
normalizer. Lovely.
Let's see if this actually copied
correctly.
correctly.
255 100 100
100. There's seven of these. So, this is
100. There's seven of these. So, this is
three, four, five, six,
three, four, five, six,
seven. Seven of
seven. Seven of
those. Wait. 1 2 3 4 5 6
7 8 9 10 11 12 13 14 15
16 I don't want to mess this up. Let me
16 I don't want to mess this up. Let me
just let me just write this out.
There we go.
What was it? A buffer or something?
register
buffer. Okay.
Now we're cooking with
Now we're cooking with
uh what's the stupid expression? Now
uh what's the stupid expression? Now
we're cooking with
oil. Couldn't find your API
to It's
a size
42. That sir has 42 elements.
driving me crazy
here. Things don't match.
Agent lib.
God
damn. Okay, let's do it like
damn. Okay, let's do it like
this. And do it like this.
Okay, there we go.
You should be able to compare this
You should be able to compare this
one directly to the other
one directly to the other
one. We will see.
We'll see whether that helps at all with
We'll see whether that helps at all with
the
uh
uh
optim. Looks like it might. This is
optim. Looks like it might. This is
already higher.
Oh yeah, that's
helping. There we go.
helping. There we go.
I'll give this a minute to run and then
I'll give this a minute to run and then
I'll send over these results and we'll
I'll send over these results and we'll
see what this does.
Uhoh. Well, we'll see if this hits a
Uhoh. Well, we'll see if this hits a
capacity
capacity
issue. Looks like it
might, but only the encoder layer was
might, but only the encoder layer was
way wider.
Everything else was uh
worse. So that's not
great. See if it's a capacity
issue
or actually I think the thing that you
or actually I think the thing that you
would change first is
would change first is
64 here, wouldn't you?
234K
params might help a bit.
There it goes. So, that's already a
There it goes. So, that's already a
little better than the uh the previous
All right, that still goes straight
up. And we'll just see how capacity is
up. And we'll just see how capacity is
compared to the original. Original was a
compared to the original. Original was a
way larger net. So like we might have to
way larger net. So like we might have to
up the size a fair bit before we hit
up the size a fair bit before we hit
that.
Seems like that's still leveling
off.
off.
Yeah. All right. Next up is going to be
128 56.
This is like a reasonable model I would
This is like a reasonable model I would
say for like a
say for like a
medium complexity problem. You got 256
medium complexity problem. You got 256
hidden block
hidden block
size, 128 stack of
size, 128 stack of
coms. Should be decent enough.
Oh, yeah. And the baseline's only 0.1
Oh, yeah. And the baseline's only 0.1
and 100 mil. So, we're doing just fine
and 100 mil. So, we're doing just fine
here.
Okay. And yeah, here's our new one.
still transit
400k 820,000 perm model. That's a pretty
400k 820,000 perm model. That's a pretty
decent size
decent size
model. I'd be surprised if the problem's
model. I'd be surprised if the problem's
too hard for
too hard for
that. Like you can do a lot with a model
that. Like you can do a lot with a model
that size.
What did they do for their uh their
What did they do for their uh their
trainer?
50 billion time
steps mini batch one up to
steps mini batch one up to
epoch. I mean those aren't horribly far
epoch. I mean those aren't horribly far
away from ours.
All our other prams are going to be
All our other prams are going to be
different,
but interesting that this does worse.
I mean, this is these are such like a
I mean, this is these are such like a
different net size. We might have to
different net size. We might have to
retune
I don't see anything in here that would
I don't see anything in here that would
be
um anything in here that would be
um anything in here that would be
screwy. This all seems reasonable to me.
We'll let this run for a little
bit. But uh I think that the best one
bit. But uh I think that the best one
they linked to me
was they got like 0.5 in 400 million
was they got like 0.5 in 400 million
steps.
I think that's with a bigger model as
I think that's with a bigger model as
well. We've done seven
minutes. No, it's about the same size
minutes. No, it's about the same size
model, I guess. Same speed model at
model, I guess. Same speed model at
least.
think there should be anything missing
think there should be anything missing
from the
from the
conf other than maybe the self features
conf other than maybe the self features
would be
important. Probably it can't see itself.
Yeah, this is leveling out.
Torch empty. What I do here?
Close division.
and we'll see how this does. This should
and we'll see how this does. This should
be better.
surprised if this is not like
surprised if this is not like
immediately and massively
better. It's 11 by 11, right? So, isn't
better. It's 11 by 11, right? So, isn't
five the middle one?
five the middle one?
should
be. Oh yeah, there we
be. Oh yeah, there we
go. That's something.
I mean, we can easily sweep this now,
I mean, we can easily sweep this now,
right?
Okay, that'll be easy to sweep.
I hope this is this looks like it's
I hope this is this looks like it's
better than the previous one. Yeah.
And we'll see if we get the plateau if
And we'll see if we get the plateau if
it gets to 0.4, which is the best on
it gets to 0.4, which is the best on
this
end. Smooth curve.
his
best. Let's see if I'm beating his best
result. So far, yes, he got to 2 at like
result. So far, yes, he got to 2 at like
150.
I think he has a steeper slope on his
I think he has a steeper slope on his
though,
though,
maybe. Hard to
say. Is a pretty clean learning
say. Is a pretty clean learning
curve. Actually, he is. That was with
curve. Actually, he is. That was with
smoothing. He does have it
smoothing. He does have it
higher. Oh, we'll
higher. Oh, we'll
see. I don't I also don't know what
see. I don't I also don't know what
model this is with. I think this is with
model this is with. I think this is with
like um comparably sized but different
like um comparably sized but different
architecture model.
It's a clean curve at the least. Okay,
It's a clean curve at the least. Okay,
let's uh let's commit this up.
no space left on device.
no space left on device.
Really? Well, that's an interesting one.
What's the damned command? Freaking
LVM. Yeah, this is stupid.
Not this one. Where is
it? Should be a buntu
it? Should be a buntu
mapper. Yep.
I'm blindly pasting these because I've
I'm blindly pasting these because I've
done this
before. It's just the same exact setup.
before. It's just the same exact setup.
It's freaking
There we go.
Wonder if that was screwing anything
Wonder if that was screwing anything
up with the the previous
up with the the previous
run. Could have been.
Okay.
config. I hate
config. I hate
hydra. I don't know why people use
this. Failed to build
this. Failed to build
hydra. What Python are we on? 312.
The hell.
I have this running on Python 312
I have this running on Python 312
though, don't I?
stupid obsolete
package. Well, that's not getting a a
package. Well, that's not getting a a
sweep
sweep
then tonight. That's what you get for
then tonight. That's what you get for
using shitty config packages that don't
using shitty config packages that don't
[ __ ] work.
just like so incredibly
obnoxious. It didn't work because the
obnoxious. It didn't work because the
config is
broken. Yes, this is no
And how about our latest
sweeps? Yeah. So, these are still
sweeps? Yeah. So, these are still
running, which is good.
Best one so far here is this blue one.
How wacky are these hyper
prams? 2 M's is pretty
wacky. Not that bad, though.
wacky. Not that bad, though.
Not that
bad. Presumably, this is sweeping these
bad. Presumably, this is sweeping these
rewards as well.
So I guess if we just uh do
this call copy these params in and run
this call copy these params in and run
it for a long Huh?
Funny that this sound like virtually
Funny that this sound like virtually
identical to the
original. These have been increased a
original. These have been increased a
lot.
That did not copy
correctly. Copy the negative sign.
correctly. Copy the negative sign.
That's horid.
Anything I
missed? Learning rate, gamma, lambda,
missed? Learning rate, gamma, lambda,
learning
learning
rate. Think that's
rate. Think that's
everything. Oh, the betas obviously.
Cool. Let's see if this works.
Okay. And then we have the other sweep
Okay. And then we have the other sweep
running which is
solid. Oh, we got a little bit of growth
solid. Oh, we got a little bit of growth
there.
All I see so far. Whoops.
Oh five I
like we're stuck at
like we're stuck at
0.3. There might be some like semantic
0.3. There might be some like semantic
meaning to that.
Not
bad. I'll have to look at their
bad. I'll have to look at their
architecture and stuff,
but it's not like fully stuck at 3
but it's not like fully stuck at 3
either. It looks like it's still going
either. It looks like it's still going
up just slowly.
There we
go. So that is training.
That's kind of flattened
That's kind of flattened
out. That is okay. There will be more
out. That is okay. There will be more
time tomorrow.
Heck is going on in here.
What time is it? 900 p.m.
is a hell of a successful
day. I'm trying to think if there's
day. I'm trying to think if there's
anything else we can do to like make
anything else we can do to like make
sure the neural MMO stuff works well
sure the neural MMO stuff works well
overnight.
I think it is to be fair more likely at
I think it is to be fair more likely at
this point.
this point.
Like if those hypers work so well on
Like if those hypers work so well on
just about
just about
everything, it's probably just a matter
everything, it's probably just a matter
of like MUP for the learning
of like MUP for the learning
rate and
then getting the correct model size for
then getting the correct model size for
the problem.
the problem.
is probably all it is to it. I mean,
is probably all it is to it. I mean,
that's what we'll do next, right? With
that's what we'll do next, right? With
um some of these harder tasks we have
um some of these harder tasks we have
access to, it'll be worth getting up
access to, it'll be worth getting up
working and worth be getting that
working and worth be getting that
working with
working with
Muan. We'll try a few other things as
Muan. We'll try a few other things as
well, I'm sure.
I mean, there are a couple remaining
I mean, there are a couple remaining
hiccups with
hiccups with
um generalized advantage estimation that
um generalized advantage estimation that
we were still targeting, but I think
we were still targeting, but I think
overall we should
overall we should
be we should be pretty well
set. Let's take a quick look one more at
set. Let's take a quick look one more at
my
my
um MMO three runs.
so the magnitudes are clearly not
so the magnitudes are clearly not
comparable
here. There's like a step change in it.
here. There's like a step change in it.
is very sort of
is very sort of
slow
learning. Let me go check the wi result
learning. Let me go check the wi result
because I think we had a uh we have a
because I think we had a uh we have a
puffer wand result in
puffer wand result in
here. Let's look for
um so I mean here right this
um so I mean here right this
This just took a while to take off
This just took a while to take off
initially, didn't it? Like this part of
initially, didn't it? Like this part of
the curve. What is
this? So, the best one here is like 300
this? So, the best one here is like 300
mil to get 1.05, I
believe. If we look at some of these.
believe. If we look at some of these.
Yeah, because I think these were
Yeah, because I think these were
different maps. I think this is the new
different maps. I think this is the new
map. So, like you're looking for
map. So, like you're looking for
in 300 mil like only
1.05. How are we doing if uh if we take
1.05. How are we doing if uh if we take
that into
account? Still not
great. We're only at We're still under
great. We're only at We're still under
1.01.
What hyper
What hyper
prams did uh did we use for
this? I'm sure that I had them in the uh
this? I'm sure that I had them in the uh
the
the
previous version,
previous version,
but we had these rewards,
but we had these rewards,
right? And then
Big batch
Big batch
size. Little bit of
size. Little bit of
entropy. Very weird
gamma. Very weird mini
batch. Nothing much else.
probably just a matter of running the uh
probably just a matter of running the uh
the sweeps
the sweeps
then there's no reason we shouldn't be
then there's no reason we shouldn't be
able to do um you know at least this
able to do um you know at least this
well we should be totally fine I think
well we should be totally fine I think
we only had two M's as
we only had two M's as
well what was the training speed of
well what was the training speed of
this did train at
this did train at
500k which makes sense with that big
500k which makes sense with that big
mini batch
mini batch
size all right Well, I mean, I'm sure
size all right Well, I mean, I'm sure
we'll be able to get this if we want to
we'll be able to get this if we want to
get to
this. Go back to these
params. I think we'll just let uh we'll
params. I think we'll just let uh we'll
just let stuff run for
just let stuff run for
tonight and not worry too much about
it. Unless this thing has already
it. Unless this thing has already
failed.
And I might want to run the original
And I might want to run the original
config.
config.
Honestly, maybe we go run the original
config. Night, man. See you
config. Night, man. See you
around. Thanks for stopping by.
Why don't we just do something like this
Why don't we just do something like this
real
quick? Puffer box
quick? Puffer box
4. It should be puffer box
4. It should be puffer box
zero, right?
Hey, start contributing to Puffer. It's
Hey, start contributing to Puffer. It's
it's a great way to do some RL. And I
it's a great way to do some RL. And I
mean, this is really where this is where
mean, this is really where this is where
RL is getting
RL is getting
solved. I mean, you see the progress
solved. I mean, you see the progress
here. It's like this is where RL will be
here. It's like this is where RL will be
solved.
We just set up a little yolo run.
People call them yolo runs when you just
People call them yolo runs when you just
change a bunch of [ __ ] based on your own
change a bunch of [ __ ] based on your own
intuitions and uh try to just like make
intuitions and uh try to just like make
something work.
I mean, we've kind of crushed all the
I mean, we've kind of crushed all the
easier
easier
ends as of
today. Little more than trial and
today. Little more than trial and
error. Little
error. Little
more. Yeah. So, this is 4 m. So it's
more. Yeah. So, this is 4 m. So it's
nums is equal to
four. Okay. So let's see if this works.
This is like the
This is like the
originalish params with the new
originalish params with the new
optimizer and some of the nice new
optimizer and some of the nice new
goodies. And we'll see how this
works. Or it doesn't.
works. Or it doesn't.
If a run like that works, do you ever
If a run like that works, do you ever
try to figure out why by looking at the
try to figure out why by looking at the
math? So, up until
math? So, up until
today, it's just a bunch of nons. It was
today, it's just a bunch of nons. It was
just a bunch of nonsensical garbage
just a bunch of nonsensical garbage
basically every time. Today is the first
basically every time. Today is the first
day where the good uh params and the
day where the good uh params and the
good settings actually line up with what
good settings actually line up with what
you expect in RL
you expect in RL
generally. Uh this was the major
generally. Uh this was the major
breakthrough today.
breakthrough today.
RL is no longer
cursed. So really, this is
cursed. So really, this is
probably in terms of terms of just pure
probably in terms of terms of just pure
capabilities, this is probably the
capabilities, this is probably the
biggest single day advancement I've seen
biggest single day advancement I've seen
since I started working on
Puffer. So I will rest well today.
Okay.
Okay.
Well, that's about all I can do for
Well, that's about all I can do for
today. What do you do when they don't
today. What do you do when they don't
line up? How do you debug something like
line up? How do you debug something like
that? There are traces. Clear error
that? There are traces. Clear error
messages. Not in RL. There aren't
messages. Not in RL. There aren't
because there's no actual error in the
because there's no actual error in the
code, right? algorithm is implemented
code, right? algorithm is implemented
correctly, right? The algorithm is
correctly, right? The algorithm is
implemented
implemented
correctly. You've tested it against a
correctly. You've tested it against a
bunch of other stuff. You know how
bunch of other stuff. You know how
hyperparameters are supposed to scale.
hyperparameters are supposed to scale.
You know model size is supposed to
You know model size is supposed to
scale. You know all these things and
scale. You know all these things and
none of them actually happen or work the
none of them actually happen or work the
way that you expect.
That has been the problem with RL more
That has been the problem with RL more
than
than
anything because RL could since like
anything because RL could since like
2017 RL could be made to work on
2017 RL could be made to work on
virtually any problem but it was always
virtually any problem but it was always
like so janky and so difficult. So today
like so janky and so difficult. So today
is the first day where it actually works
is the first day where it actually works
roughly out of the box on like a dozen
roughly out of the box on like a dozen
different
different
environments. Where do you go from
environments. Where do you go from
there? Pain and suffering and lots of
there? Pain and suffering and lots of
trial and error like guided by your
trial and error like guided by your
intuitions, right? and like by what
intuitions, right? and like by what
knowledge you have over how these things
knowledge you have over how these things
are supposed to behave, but often you're
are supposed to behave, but often you're
just wrong. And even like the best
just wrong. And even like the best
person in the world in RL is going to
person in the world in RL is going to
just be wrong cuz they just don't make
just be wrong cuz they just don't make
any bloody
sense. So today is the first day where
sense. So today is the first day where
RL is not like
RL is not like
that. That's why this is such a big
that. That's why this is such a big
deal.
deal.
There's still some small limitations,
There's still some small limitations,
but now we pretty much know what we have
but now we pretty much know what we have
to do. And the parts that like were
to do. And the parts that like were
completely unexplainable
completely unexplainable
uh have now been explained and now
work. I mean, I said my goal for the
work. I mean, I said my goal for the
year, right, is we want to make RL 10
year, right, is we want to make RL 10
times easier to get up and running on a
times easier to get up and running on a
new problem.
If we were like, you know, maybe we were
If we were like, you know, maybe we were
30% of the way there yesterday. Today
30% of the way there yesterday. Today
we're like 70% of the way
we're like 70% of the way
there. Where do you go from here?
there. Where do you go from here?
There's still a few things that we need
There's still a few things that we need
to do. I think we need MUP so that uh
to do. I think we need MUP so that uh
learning rate actually behaves the way
learning rate actually behaves the way
that we
that we
expect. And then the new algorithm is
expect. And then the new algorithm is
going to handle gamma and lambda being
going to handle gamma and lambda being
weird and we should be
weird and we should be
good. Do you build tools for easier
good. Do you build tools for easier
debugging more environments more? Well,
debugging more environments more? Well,
I mean, you see what I've done, right? I
I mean, you see what I've done, right? I
said, "Okay, none of this stuff makes
said, "Okay, none of this stuff makes
any sense, and we're going to have to
any sense, and we're going to have to
run thousands of experiments to figure
run thousands of experiments to figure
it out." So, I made a bunch of
it out." So, I made a bunch of
environments that run really, really,
environments that run really, really,
really fast, right? Like, you know how
really fast, right? Like, you know how
many experiments have taken me to get to
many experiments have taken me to get to
here? Here, these are all experiments
from 25,000 experiments from the last
from 25,000 experiments from the last
like three months.
These are just like my personal
These are just like my personal
experiments for fiddling with
experiments for fiddling with
stuff.
Yeah, this is probably
like I don't know order of like 10
like I don't know order of like 10
trillion steps worth of experiments.
So the data scale that's involved here
So the data scale that's involved here
to make this stuff work, uh, this right
to make this stuff work, uh, this right
here would be like without puffer libs
here would be like without puffer libs
environments, this would be like a,000
environments, this would be like a,000
GPU years worth of compute or
GPU years worth of compute or
more, probably a lot
more. So that's how we got here, right?
more. So that's how we got here, right?
We made a bunch of environments. We made
We made a bunch of environments. We made
them really fast. We use the
them really fast. We use the
environments to figure out what the heck
environments to figure out what the heck
is
is
wrong since Puffer lo. Yeah, the
wrong since Puffer lo. Yeah, the
environments are
environments are
fast. So, we run more
fast. So, we run more
experiments. Of course, our trainer is
experiments. Of course, our trainer is
also
faster. We've kind of optimized the full
faster. We've kind of optimized the full
stack.
I mean, you can see what these are as
I mean, you can see what these are as
well because they're
grouped. So, most of these are like
grouped. So, most of these are like
groups of 200 experiment hyperparam
groups of 200 experiment hyperparam
sweeps. So, it's not just 25
sweeps. So, it's not just 25
experiments,
experiments,
uh, 25,000 experiments. It's groups of
uh, 25,000 experiments. It's groups of
like a couple
like a couple
hundred intelligently optimized
hundred intelligently optimized
experiments using methods I developed
experiments using methods I developed
that didn't exist
that didn't exist
before. So, it's been this whole massive
before. So, it's been this whole massive
massive process to get
here. But
here. But
now we have uh RL just working out of
now we have uh RL just working out of
the box on
the box on
all the M's in puffer with the exception
all the M's in puffer with the exception
of a couple tweaks being needed for
of a couple tweaks being needed for
neural MMO which we're doing right now
neural MMO which we're doing right now
because that M's are really really
hard. But yeah, this is this was the
hard. But yeah, this is this was the
goal with Puffer, right? We've got a few
goal with Puffer, right? We've got a few
things left, a few things that are still
things left, a few things that are still
one thing that's pretty easy and one
one thing that's pretty easy and one
thing that's pretty hard, I think.
thing that's pretty hard, I think.
Um, and then we just kind of got RL
Um, and then we just kind of got RL
working and we'll see where we go from
working and we'll see where we go from
there. I think I'm going to want to take
there. I think I'm going to want to take
this stuff and like throw it on, you
this stuff and like throw it on, you
know, hard RL problems in
know, hard RL problems in
industry. Um, we're going to make some
industry. Um, we're going to make some
really awesome
really awesome
demos. We're going to release some
demos. We're going to release some
really clean and really fast tools.
really clean and really fast tools.
We'll see from there.
We'll see from there.
Uh bet it's currently the there's a dev
Uh bet it's currently the there's a dev
branch in puffer tank that we were
branch in puffer tank that we were
using. Wasn't Puffer's goal to make a
using. Wasn't Puffer's goal to make a
framework to make RL I wouldn't say
framework to make RL I wouldn't say
framework but yes the goal was to make
framework but yes the goal was to make
RL advancements easier. Here you
RL advancements easier. Here you
go.
Right. Tools. Yeah. Lighter weight
Right. Tools. Yeah. Lighter weight
tools.
It's hardly a framework when you have
It's hardly a framework when you have
like a single file trainer,
right? There's
right? There's
like probably like three or four times
like probably like three or four times
more code in the environments versus the
more code in the environments versus the
uh the rest of puffer lip together.
Like with all the newest environments
Like with all the newest environments
being PR, it'll be about 30,000 lines of
being PR, it'll be about 30,000 lines of
environments and maybe like a few
environments and maybe like a few
thousand poor lines of uh of Python that
thousand poor lines of uh of Python that
we're actually
we're actually
using. Yeah, framework's bad.
using. Yeah, framework's bad.
Framework's never good.
Framework's never good.
I really don't like big clunky heavily
I really don't like big clunky heavily
abstracted stuff, especially not in
Python, but not really
anywhere. So, neural MMO 3 is going to
anywhere. So, neural MMO 3 is going to
be the real
be the real
test. Neural MMO 3 is
test. Neural MMO 3 is
hard. We should be able to beat the
hard. We should be able to beat the
previous baseline, but then we'll see
previous baseline, but then we'll see
where we go from there.
If I were an undergrad, I'd be I would
If I were an undergrad, I'd be I would
so just puffer live.
Yeah. Well, just contribute,
Yeah. Well, just contribute,
right? Come build some cool
stuff. Yeah. I mean, I I usually stream
stuff. Yeah. I mean, I I usually stream
all day Saturday. So, if you get
all day Saturday. So, if you get
stuck, I usually I stream all day s
stuck, I usually I stream all day s
Saturday and then Sunday I like go and
Saturday and then Sunday I like go and
do a bunch of exercise and like not code
do a bunch of exercise and like not code
a
a
ton. Job search
ton. Job search
sucks. Job search is
rough. But hey, you know, our best
rough. But hey, you know, our best
contributors are people here that have
contributors are people here that have
came in with zero RL experience.
So you can kind of do a lot of stuff
So you can kind of do a lot of stuff
quite quickly
quite quickly
now. Awesome. Look forward to
now. Awesome. Look forward to
it. There's really not that much uh
it. There's really not that much uh
puffer lip specific to learn cuz like
puffer lip specific to learn cuz like
it's really a thin piece of software.
it's really a thin piece of software.
The dev branch has some clunk to it just
The dev branch has some clunk to it just
because like you know there are flags
because like you know there are flags
for all the new like algorithmic tidbits
for all the new like algorithmic tidbits
that we're testing. But generally puffer
that we're testing. But generally puffer
is really
is really
thin. There's not a ton to learn. RL
thin. There's not a ton to learn. RL
generally yeah there's a fair bit to
generally yeah there's a fair bit to
learn but not puffer
learn but not puffer
lib. It's just CMS with some RL Python
lib. It's just CMS with some RL Python
algos. It's just CMS with
algos. It's just CMS with
uh there's one very nice like few
uh there's one very nice like few
hundred line piece of code that does
hundred line piece of code that does
very fast multipprocessing and then
very fast multipprocessing and then
there's one like
there's one like
roughly,500ish line piece of code that
roughly,500ish line piece of code that
is our entire algorithm and trainer
is our entire algorithm and trainer
implementation. That is
implementation. That is
it. Sython's just like a trivial little
it. Sython's just like a trivial little
binding to
binding to
see. That's all there is.
see. That's all there is.
You know, we have some other tools for
You know, we have some other tools for
nonpuffer ends if you want to wrap third
nonpuffer ends if you want to wrap third
party stuff quickly, but generally
party stuff quickly, but generally
that's all it
is. I mean, there are a few nice things
is. I mean, there are a few nice things
I came up with, right, to make this
I came up with, right, to make this
fast. Like the C writes uh the C code
fast. Like the C writes uh the C code
writes observations directly into shared
writes observations directly into shared
memory buffers that are in contiguous
memory buffers that are in contiguous
memory.
memory.
But I have all that set up for you and
But I have all that set up for you and
it's very easy to use. And the actual
it's very easy to use. And the actual
thing that implements it is like a few
thing that implements it is like a few
dozen lines of code. You just kind of
dozen lines of code. You just kind of
have to understand it
all. That's
all. We're very much looking for new
all. We're very much looking for new
contributors, by the way. Like the way
contributors, by the way. Like the way
it works around here, and I think you've
it works around here, and I think you've
seen if you've been on uh many of these
seen if you've been on uh many of these
streams, right, is anybody who actually
streams, right, is anybody who actually
puts effort into like building M's,
puts effort into like building M's,
helping with buffer lip, uh I put effort
helping with buffer lip, uh I put effort
back into them, you
back into them, you
know, you know, the people who've been
know, you know, the people who've been
building M. I code review every single
building M. I code review every single
line of the contributions. We go through
line of the contributions. We go through
I try to share some like insights on how
I try to share some like insights on how
to think about RL and try to get people
to think about RL and try to get people
doing stuff that will help them learn
doing stuff that will help them learn
and push puffer
forward. Jose painstakingly put this
forward. Jose painstakingly put this
together. Yeah, I'm a little tiny bit
together. Yeah, I'm a little tiny bit
um I'm a bit pigantic on trying to keep
um I'm a bit pigantic on trying to keep
the code like brain dead
the code like brain dead
simple, but that's about it. It's like
simple, but that's about it. It's like
if anybody uses like any remotely fancy
if anybody uses like any remotely fancy
abstractions, I'm just like get that out
abstractions, I'm just like get that out
of
here. This code should be brain dead
here. This code should be brain dead
simple. But hey, you know, there's a
simple. But hey, you know, there's a
reason for it. No
reason for it. No
decorators. I think we have a couple at
decorators. I think we have a couple at
property decorators and that's about it,
property decorators and that's about it,
honestly.
honestly.
I mean, we don't
I mean, we don't
have I think there's like one place I
have I think there's like one place I
couldn't get away from having an
couldn't get away from having an
inherited class, but other than that,
inherited class, but other than that,
like very like try to not
like very like try to not
object-orient like functional dog. It's
object-orient like functional dog. It's
just like brain dead simple code on
data. That's the
data. That's the
goal. No mixins. [ __ ] that.
But, you know, I get on people's case
But, you know, I get on people's case
over dumb stuff, right? Like, I don't
over dumb stuff, right? Like, I don't
let people use double pointers. Like, I
let people use double pointers. Like, I
don't let people do like double
don't let people do like double
pointers. I don't let people be um doing
pointers. I don't let people be um doing
even freaking union types most of the
even freaking union types most of the
time. Um, what
time. Um, what
else? What are the other ones? Oh, yeah.
else? What are the other ones? Oh, yeah.
No dynamic memory allocation. Screw
No dynamic memory allocation. Screw
that. Like, it's just very, very simple
that. Like, it's just very, very simple
code. It's like look, you write if
code. It's like look, you write if
statements, you write some loops, you
statements, you write some loops, you
write some assignments. That's all you
write some assignments. That's all you
need. You don't believe me? Look at the
need. You don't believe me? Look at the
neural MMO code. That's all I
use. Oh yeah, and don't write too many
use. Oh yeah, and don't write too many
damn functions.
Sometimes you need dynamic outlets, but
Sometimes you need dynamic outlets, but
like I think there's maybe two places
like I think there's maybe two places
total uh that we needed them in the
total uh that we needed them in the
environments that we have. I think I
environments that we have. I think I
needed them in neural MMO just for the
needed them in neural MMO just for the
map generation because the maps can be
map generation because the maps can be
like 4096 x
4096. Ah yeah, but you introduced an
4096. Ah yeah, but you introduced an
arena, right? And now you have this
arena, right? And now you have this
other abstraction. It's like you don't
other abstraction. It's like you don't
need the dynamic Alex most of the time.
need the dynamic Alex most of the time.
Believe me. What we actually do is we
Believe me. What we actually do is we
allocate a lot of memory from Python
allocate a lot of memory from Python
because it needs to be a shared buffer
because it needs to be a shared buffer
anyways. You'll
anyways. You'll
see there is still a little bit of
see there is still a little bit of
boiler plate which I'm not happy
boiler plate which I'm not happy
with. Like the boiler plate's mostly
with. Like the boiler plate's mostly
because you have to go it's not because
because you have to go it's not because
of the C. It's because you have to go
of the C. It's because you have to go
through Syon to get to Python. So, you
through Syon to get to Python. So, you
know, there's a little bit of boiler
know, there's a little bit of boiler
plate associated with uh going from C to
plate associated with uh going from C to
Syon to Python, but it's not
bad and it's like really really easy and
bad and it's like really really easy and
self-explanatory.
figure Python types can be used function
figure Python types can be used function
args. No, actually that's the one thing
args. No, actually that's the one thing
that Sython does for us. But the problem
that Sython does for us. But the problem
with Python is you kind of have to redo
with Python is you kind of have to redo
the whole
the whole
header. Like you have it, you already
header. Like you have it, you already
have the def the function definitions in
have the def the function definitions in
um in C, but then Syon makes you redo a
um in C, but then Syon makes you redo a
header anyways. And then like you know
header anyways. And then like you know
you have your step method in C and you
you have your step method in C and you
have your step method in Syon and you
have your step method in Syon and you
have your step method in Python. So it's
have your step method in Python. So it's
a little
a little
stupid but um that's more of like a
stupid but um that's more of like a
language interoperability limitation
language interoperability limitation
than anything. That's kind of the worst
than anything. That's kind of the worst
bit at the
bit at the
moment. Nothing else is really a
moment. Nothing else is really a
problem. The one other thing is like you
problem. The one other thing is like you
know it's designed to work in pure C but
know it's designed to work in pure C but
also in Python. So like Python is going
also in Python. So like Python is going
to pass you your observation buffers and
to pass you your observation buffers and
then you're just going to init whatever
then you're just going to init whatever
other variables you need. But if you're
other variables you need. But if you're
going to try to like demo the envure C
going to try to like demo the envure C
which is how we run it on the website uh
which is how we run it on the website uh
then you need to allocate your own
then you need to allocate your own
buffer. So there are two different init
buffer. So there are two different init
functions. One for allocate your
functions. One for allocate your
yourself and the other for pass in
pre-allocated. And the other thing which
pre-allocated. And the other thing which
is not which is not hard but is actually
is not which is not hard but is actually
really cool is we have our own neural
really cool is we have our own neural
net library in pure C that we use for
net library in pure C that we use for
the web
the web
demos. It's like I don't know I was
demos. It's like I don't know I was
pretty proud of
pretty proud of
this. It's just really simple. There's a
this. It's just really simple. There's a
pufferet.h. So this is less than 600
pufferet.h. So this is less than 600
lines of real code. No backward pass
lines of real code. No backward pass
just forward mode for um for web demos.
just forward mode for um for web demos.
So you see like it's like here's a
So you see like it's like here's a
matrix multiply. Here's with
matrix multiply. Here's with
accumulation. Here's a 2D
accumulation. Here's a 2D
conf. I don't actually use that arena
conf. I don't actually use that arena
actually. I was playing with it but I
actually. I was playing with it but I
didn't. We don't actually use
didn't. We don't actually use
it. Here's an LSTM. So this is a this
it. Here's an LSTM. So this is a this
function right here. This is an LSTM and
function right here. This is an LSTM and
C,
C,
right? It's really
right? It's really
simple. Making the com sim. I mean, we
simple. Making the com sim. I mean, we
could. You'd also want to tile it and
could. You'd also want to tile it and
stuff. Um, the only thing that it would
stuff. Um, the only thing that it would
kind of do is maybe let us run slightly
kind of do is maybe let us run slightly
larger networks on our web demos though
larger networks on our web demos though
because like all of these are running in
because like all of these are running in
C and they like they already work,
C and they like they already work,
right? This is the neural MMO policy,
right? This is the neural MMO policy,
you know, this is the breakout
you know, this is the breakout
policy little triad.
policy little triad.
Like these are all just running train
Like these are all just running train
neural nets. And
see some of them are super human. It's
see some of them are super human. It's
pretty
cool. I really like this enduro
one. Bet worked really hard on this.
This was kind of funny because um see I
This was kind of funny because um see I
gave bet this project thinking it was a
gave bet this project thinking it was a
lot simpler than it
lot simpler than it
is. So like Bet is still pretty new and
is. So like Bet is still pretty new and
was even newer when I gave him this
was even newer when I gave him this
project to programming in general. So I
project to programming in general. So I
kind of gave him like too big of a
kind of gave him like too big of a
project but he did it
project but he did it
anyways. At first, like the first time
anyways. At first, like the first time
he did it with like two to three times
he did it with like two to three times
too much code, but he paired it down and
too much code, but he paired it down and
now it's pretty
decent. Yeah. Well, I mean, bet you
decent. Yeah. Well, I mean, bet you
should see some of the [ __ ] that I wrote
should see some of the [ __ ] that I wrote
when I was new. I've written some like
when I was new. I've written some like
ridiculously over verbose
code. Like I've written some truly awful
code. Like I've written some truly awful
things.
I think I had in my thesis.
Um, do I actually have this on
my I think I probably do have this on my
my I think I probably do have this on my
uh on my GitHub.
This was an early attempt at neural MMO
This was an early attempt at neural MMO
before I knew what the hell I was
doing. Do you guys type in?
doing. Do you guys type in?
Nope. I actually that's a pet peeve of
Nope. I actually that's a pet peeve of
mine. I hate typed
Python. The reason being that the types
Python. The reason being that the types
are not actually enforced.
Instead, we just write less
Python. The thing is that people think
Python. The thing is that people think
that they're enforced and they're not.
Oh yeah, this thing. This is a Panda's
Oh yeah, this thing. This is a Panda's
3D visualizer I wrote uh I wrote this
3D visualizer I wrote uh I wrote this
the week I discovered Monster Energy in
the week I discovered Monster Energy in
college. I think this was like two
college. I think this was like two
nights up until 4 in the morning to make
nights up until 4 in the morning to make
this thing work.
Oh, now yeah, college was a crazy
Yeah, I think I had a screenshot in my
Yeah, I think I had a screenshot in my
defense of
defense of
this. Okay, so welcome everyone.
There were a lot of systems in here. So
There were a lot of systems in here. So
this is the super early screenshot from
this is the super early screenshot from
open
open
AI discover built this
in
in
that. So this early version of neural
that. So this early version of neural
combat
screen by continuing to make the
screen by continuing to make the
problemer.
So if we could figure out how to fix
So if we could figure out how to fix
that, then I think you'd probably be
that, then I think you'd probably be
able to get cooperation before
able to get cooperation before
cooperation with all the new mechanics
cooperation with all the new mechanics
on reasonably small scale. And after
on reasonably small scale. And after
that, you need more game mechanics.
that, you need more game mechanics.
Well, okay. Um,
that was a cool thing with
it. Basically, I interviewed there to
it. Basically, I interviewed there to
build neural
MMO. The idea didn't come after
Oh yeah, this is super
old. So this is like some of the
old. So this is like some of the
oldest. This was like when I was just
oldest. This was like when I was just
like using really crappy genetic
like using really crappy genetic
algorithms on stuff.
Here it
Here it
is. This is the uh I remember exactly
is. This is the uh I remember exactly
where I was when I built this. I was in
where I was when I built this. I was in
a hotel with my family on Thanksgiving
a hotel with my family on Thanksgiving
break. I just discovered monster and was
break. I just discovered monster and was
downing like two or three of them a
day and I wrote this like shitty
day and I wrote this like shitty
Minecraft knockoff client
Minecraft knockoff client
um in Pandas
um in Pandas
3D. It ran like 15 fps, but it ran and I
3D. It ran like 15 fps, but it ran and I
was like trying to get agents to run
was like trying to get agents to run
around and learn how to cut down trees.
You can see like the awful terrain gen.
You can see like the awful terrain gen.
It's This is literally like breath first
It's This is literally like breath first
search filling in diamonds with
search filling in diamonds with
different
different
squares. You see this like terrible ore
squares. You see this like terrible ore
generation at the
bottom. But yeah, this is this is the
bottom. But yeah, this is this is the
second time I tried neural MMO. I don't
second time I tried neural MMO. I don't
think I have code from before this, but
think I have code from before this, but
there was even an earlier version of
there was even an earlier version of
this when I tried to do this when I was
this when I tried to do this when I was
even younger and knew even less than
this. This was
this. This was
probably if you look at the code, the
probably if you look at the code, the
code is awful, but this was like kind of
code is awful, but this was like kind of
the first time. So, I started coding at
the first time. So, I started coding at
14, right? And then like that project
14, right? And then like that project
there, that's probably the most complex
there, that's probably the most complex
thing that I'd built up until that time.
thing that I'd built up until that time.
So I was I think
19. I was probably 19 at the time. 18 or
19. I was probably 19 at the time. 18 or
19. So it
19. So it
took a good four years of like
took a good four years of like
continuous programming before I could
continuous programming before I could
like kind of do a small project even if
like kind of do a small project even if
I was making a total mess of
it. And then I'd
it. And then I'd
say another four
say another four
years. Is it another four years? No,
years. Is it another four years? No,
another two years before I was writing
another two years before I was writing
code that was better than the majority
code that was better than the majority
of
of
researchers, which is a very low bar.
two years after that for like doing
two years after that for like doing
competent
competent
midscale projects like you know sort of
midscale projects like you know sort of
middle stage versions of neural MMO 2 or
middle stage versions of neural MMO 2 or
neural MMO one
neural MMO one
rather and then the
rather and then the
last over the last few years really
last over the last few years really
being able to build
whatever in the last year in particular
whatever in the last year in particular
I've actually gotten I think I've gotten
I've actually gotten I think I've gotten
at least twice as good at what I do just
at least twice as good at what I do just
in the last year alone
mainly just from having the freedom to
mainly just from having the freedom to
like do stuff the way I want without the
like do stuff the way I want without the
academic constraints, you
academic constraints, you
know. But hey, I guess this is supposed
know. But hey, I guess this is supposed
to be kind of motivational in the sense
to be kind of motivational in the sense
that it takes some time. It takes some
that it takes some time. It takes some
hard work. But hey, if any of you folks
hard work. But hey, if any of you folks
want to get into RL and want to help me
want to get into RL and want to help me
build some awesome stuff, Discord's
build some awesome stuff, Discord's
open. Come drop by.
Yeah, it's
Yeah, it's
been it's been a pretty singular focus
been it's been a pretty singular focus
and star puffer li on GitHub. That
and star puffer li on GitHub. That
actually does help us a lot. Sometimes
actually does help us a lot. Sometimes
the star chart figure breaks, but here
the star chart figure breaks, but here
it
it
is.
is.
1779. That's pretty damn good for an RL
1779. That's pretty damn good for an RL
library. That's like one of the bigger
library. That's like one of the bigger
ones at this point.
It's funny how whenever I start talking
It's funny how whenever I start talking
about stuff like this you like the
about stuff like this you like the
viewer count just pops up on YouTube and
viewer count just pops up on YouTube and
Twitch. Hi
folks. Do you think we've gotten any
folks. Do you think we've gotten any
cool experiments done in the meantime?
cool experiments done in the meantime?
Well, I've been
reminiscing. Yeah, I mean there are a
reminiscing. Yeah, I mean there are a
few. It's very hard to learn this
few. It's very hard to learn this
end. It was very
end. It was very
hard. Does this
hard. Does this
work? Oh, this does work. This one works
work? Oh, this does work. This one works
though. These are the original params
though. These are the original params
that we tuned for uh for neural
that we tuned for uh for neural
MMO. So this
is 1.15 at a
is 1.15 at a
billion. What was the
original? Yeah, it works. So it does
original? Yeah, it works. So it does
train
doesn't train as well as this
doesn't train as well as this
though. Wait, hang
though. Wait, hang
on. Something seems weird to me. This is
on. Something seems weird to me. This is
a 10 billion
run. Three. Three.
Three. This is the run right here. I was
Three. This is the run right here. I was
looking at the wrong
one. See there? This one actually has
one. See there? This one actually has
1.4 at 1
billion. So, something
changed. PieTorch.
Uh yeah, SP3
is by modern standards. There's some
is by modern standards. There's some
needs some work. What's the reward for
needs some work. What's the reward for
neural MMO? Well, this is the new neural
neural MMO? Well, this is the new neural
MMO, which is actually kind of kind of
MMO, which is actually kind of kind of
complicated, right? And there's no
complicated, right? And there's no
population
population
size. Oops.
So, this is this game right
So, this is this game right
here. And uh it's kind of
here. And uh it's kind of
big. And this isn't even the fullsize
big. And this isn't even the fullsize
map. This is just the one that we throw
map. This is just the one that we throw
on the
on the
web. But these are enemies. They come in
web. But these are enemies. They come in
different levels. All these are
different levels. All these are
different items you can collect with
different items you can collect with
different
different
tools. This is running. Yeah, this is
tools. This is running. Yeah, this is
running in my client right here in my
running in my client right here in my
browser on one core.
It's only running a few neural nets,
though. It's only running a few neural
though. It's only running a few neural
nets cuz the uh the network
nets cuz the uh the network
implementation isn't optimized. So, the
implementation isn't optimized. So, the
red ones are hostile NPCs. This is a
red ones are hostile NPCs. This is a
neural net. Now, this guy doesn't seem
neural net. Now, this guy doesn't seem
to be doing anything because the
to be doing anything because the
policyy's not amazing. It will just stop
policyy's not amazing. It will just stop
doing stuff for a while. But, if an
doing stuff for a while. But, if an
enemy comes over, it will like run away
enemy comes over, it will like run away
from the enemy and start doing stuff
from the enemy and start doing stuff
again.
again.
You context switch between NPCs. You can
You context switch between NPCs. You can
just scroll around. Here's an NPC.
just scroll around. Here's an NPC.
Here's an NPC.
Right? You can play this on the website.
Right? You can play this on the website.
If you just hit control, you'll see
If you just hit control, you'll see
it'll stop. And now this is me
it'll stop. And now this is me
playing. And I can like move this guy
playing. And I can like move this guy
around and like I can go find an enemy
around and like I can go find an enemy
that I think he can beat. for
that I think he can beat. for
instance. Let me see if I can find He
instance. Let me see if I can find He
can't win against any of these
can't win against any of these
guys. Okay, he can beat this level one
guys. Okay, he can beat this level one
if he's if he's
if he's if he's
smart. So
smart. So
here there, this is no longer me
playing. And he just he misguided that
playing. And he just he misguided that
one by one hit. So we
one by one hit. So we
lost. Uh the NPCs are not controlled by
lost. Uh the NPCs are not controlled by
neural nets. The players are controlled
neural nets. The players are controlled
by neural
maps. The NPCs have like basic path
maps. The NPCs have like basic path
finding and like basic scripted AI. Uh
finding and like basic scripted AI. Uh
these guys are controlled by neural nets
these guys are controlled by neural nets
and they don't look like much, but if
and they don't look like much, but if
you watch them for long enough, they
you watch them for long enough, they
will actually do some pretty impressive
will actually do some pretty impressive
stuff. It's just like they don't really
stuff. It's just like they don't really
have any motivation to do it. So,
have any motivation to do it. So,
they'll kind of just wander around for a
they'll kind of just wander around for a
bit. But, if you watch these guys for
bit. But, if you watch these guys for
long enough, they will actually like get
long enough, they will actually like get
a whole bunch of levels, collect and
a whole bunch of levels, collect and
equip a bunch of different items, avoid
equip a bunch of different items, avoid
some enemies reasonably well. Um, like
some enemies reasonably well. Um, like
they actually learn a lot of interesting
they actually learn a lot of interesting
stuff if you watch them for long enough.
stuff if you watch them for long enough.
Now, my goal with this now that we've
Now, my goal with this now that we've
made the algorithm so much better is to
made the algorithm so much better is to
get some like really impressive policies
get some like really impressive policies
on neural MMO 3. I think that would be
on neural MMO 3. I think that would be
fun because this is really like way more
fun because this is really like way more
complex of an end than pretty much
complex of an end than pretty much
everything else out
everything else out
there. Is it super complicated? It's not
there. Is it super complicated? It's not
super complicated. I think it has like
super complicated. I think it has like
four components right now. So, I'll show
four components right now. So, I'll show
you how I I deal with it.
It's like really easy to make these.
It's like really easy to make these.
So, they get a reward every time they
So, they get a reward every time they
level up in combat. They get a reward
level up in combat. They get a reward
every time they level up uh a
every time they level up uh a
profession. They get a reward for
profession. They get a reward for
getting better quality
getting better quality
items. There's a reward for using the
items. There's a reward for using the
market, which is currently set to zero.
market, which is currently set to zero.
And there's a reward for dying. I don't
And there's a reward for dying. I don't
set these coefficients manually. I sweep
set these coefficients manually. I sweep
over these. I treat these as
over these. I treat these as
hyperparameters and optimize them with
hyperparameters and optimize them with
the hyperparam sweep
the hyperparam sweep
algo. So you see I don't actually have
algo. So you see I don't actually have
to know how important each of these are.
to know how important each of these are.
I just had to pick like five important
I just had to pick like five important
things in the environment. So I just
things in the environment. So I just
picked five important things. I added
picked five important things. I added
them into the reward code and then I let
them into the reward code and then I let
the uh the hyperparam sweep optimize the
the uh the hyperparam sweep optimize the
coefficients. Pretty cool, right?
This is the sweep config and it just
This is the sweep config and it just
sweeps over
them. We'll see what this guy does.
Maybe this ends up doing better. We'll
Maybe this ends up doing better. We'll
see longer
see longer
term. It's cool though either
term. It's cool though either
way. Swap the neuronetypers.
way. Swap the neuronetypers.
Yep, we
Yep, we
did. And it was actually very fiddly to
did. And it was actually very fiddly to
get the uh the original policies to
get the uh the original policies to
work. But here's the thing. As of today,
work. But here's the thing. As of today,
we now have roughly one set of
we now have roughly one set of
hyperparameters that works for every
hyperparameters that works for every
single environment in Puffer Lib except
single environment in Puffer Lib except
neural
neural
MMO. Neural MMO is the hard
MMO. Neural MMO is the hard
one, but I'm guessing that we probably
one, but I'm guessing that we probably
only have to fiddle a couple we only
only have to fiddle a couple we only
have to fiddle with a couple of those
have to fiddle with a couple of those
hyperparameters to get neural MMO to
hyperparameters to get neural MMO to
work as well. It's going to be my
work as well. It's going to be my
guess and we're going to understand why.
guess and we're going to understand why.
That's going to be the next
thing. This is the major breakthrough
thing. This is the major breakthrough
today. Right before today, every single
today. Right before today, every single
environment needed like a 200 parameter,
environment needed like a 200 parameter,
a 200 experiment hyperparameter sweep to
a 200 experiment hyperparameter sweep to
even do something remotely
even do something remotely
reasonable. Now we have one set of
reasonable. Now we have one set of
hypers, pretty much one set of hypers.
hypers, pretty much one set of hypers.
Couple small tweaks. It didn't take very
Couple small tweaks. It didn't take very
long at all. Solves everything.
long at all. Solves everything.
does better than the original
does better than the original
hyperparameters in the majority of the
hyperparameters in the majority of the
environments and does at least
environments and does at least
reasonably well in the
reasonably well in the
rest. I checked all the
rest. I checked all the
MS. I did check all the
ends. It's pretty
cool.
cool.
Well, it depends which parameters change
Well, it depends which parameters change
in neural MMO,
in neural MMO,
right? If the batch size changes a
right? If the batch size changes a
little bit, that's
little bit, that's
understandable, right? If we just need
understandable, right? If we just need
to increase the mini batch size for
to increase the mini batch size for
example, okay, you know, a neural MMO is
example, okay, you know, a neural MMO is
a hard M. There's too much variance to
a hard M. There's too much variance to
do small mini batches on neural
do small mini batches on neural
MMO. If we have to change the learning
MMO. If we have to change the learning
rate, that's also understandable. It's a
rate, that's also understandable. It's a
larger network than uh in the other MS.
larger network than uh in the other MS.
Larger networks need lower learning
Larger networks need lower learning
rates, at least if you're not using
rates, at least if you're not using
MUP, which we don't have integrated yet.
MUP, which we don't have integrated yet.
Now, if everything needs to be changed,
Now, if everything needs to be changed,
yeah, then there's an
yeah, then there's an
issue. But the ones that I will say I'm
issue. But the ones that I will say I'm
a little suspicious of, this gamma and
a little suspicious of, this gamma and
lambda, I have a separate effort to
lambda, I have a separate effort to
delete
delete
these. The other algorithm I've been
these. The other algorithm I've been
working on, if it works, it will delete
working on, if it works, it will delete
these two parameters
these two parameters
entirely. So, there is good stuff
entirely. So, there is good stuff
coming. Definitely good stuff coming.
go back to work. See you this Saturday.
go back to work. See you this Saturday.
Sounds good. I think I'm going to go to
Sounds good. I think I'm going to go to
bed. Uh I'm going to go to bed and get
bed. Uh I'm going to go to bed and get
started first thing in the morning.
started first thing in the morning.
Well, after I run in the
morning. So, for folks watching, all my
morning. So, for folks watching, all my
stuff's here. Puffer.ai. I it's all open
stuff's here. Puffer.ai. I it's all open
source including all the new
source including all the new
advancements there in
advancements there in
dev. You want to support the project for
dev. You want to support the project for
free? Start the
free? Start the
repository. You work at a company and
repository. You work at a company and
you want to get the latest in
you want to get the latest in
reinforcement learning working directly
reinforcement learning working directly
on your stuff and want to get my eyes on
on your stuff and want to get my eyes on
your
your
project. Check out our service tab. We
project. Check out our service tab. We
do offer support contracts.
Other than that, you can join the
Other than that, you can join the
Discord to get involved with
Discord to get involved with
development and you can follow me on X
development and you can follow me on X
for more reinforcement learning content.
