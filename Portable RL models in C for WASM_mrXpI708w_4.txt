Kind: captions
Language: en
how's it going I got to get a quicker
how's it going I got to get a quicker
start on these streams I'd like to be on
start on these streams I'd like to be on
like a good hour or two earlier but we
like a good hour or two earlier but we
move slow once in a while we move
slow but here we are set and we have a
slow but here we are set and we have a
pretty concrete set of stuff to get done
today oops
cool so uh where we left this off
cool so uh where we left this off
yesterday why why am I sitting in green
yesterday why why am I sitting in green
Haze like do I have to make this any
Haze like do I have to make this any
brighter really all right fine I'll
brighter really all right fine I'll
stare into this all day sure
stare into this all day sure
um so where we left this off yesterday
um so where we left this off yesterday
we had some pretty good
progress where the heck is this
puffer Leb environments ocean MOA and
puffer Leb environments ocean MOA and
then MOA Doh here no
then MOA Doh here no
M.C okay so
M.C okay so
here we were implementing a few
here we were implementing a few
different layer types uh in C here so we
different layer types uh in C here so we
have this lstm we got the full
have this lstm we got the full
implementation done but it needs to be
implementation done but it needs to be
uh error checked and the like we also
uh error checked and the like we also
have the com done yesterday and pretty
have the com done yesterday and pretty
much all I have to do is uh finish this
much all I have to do is uh finish this
today make sure that this is correct I
today make sure that this is correct I
have to write some sort of better test
have to write some sort of better test
on this uh and
then probably from there we're going to
then probably from there we're going to
figure out a way to clean this up a
figure out a way to clean this up a
little bit so we can have like a
little bit so we can have like a
portable little
portable little
Standalone and then we'll go from there
Standalone and then we'll go from there
but that should be enough to get our RL
but that should be enough to get our RL
models onto the
web for sure
let me remember where we were how we
let me remember where we were how we
were doing this hold
on
it's right so we have this
it's right so we have this
here where we can look at the individual
here where we can look at the individual
weights in the lstm here right
uh this is garbage
uh this is garbage
right oh no that's old okay here it
right oh no that's old okay here it
is yeah
is yeah
so we have our break point here and then
so we have our break point here and then
here we're going to need to put a GDB
here we're going to need to put a GDB
breakpoint of some type I
breakpoint of some type I
assume and we're going to have to look
assume and we're going to have to look
at the individual outputs of
at the individual outputs of
stuff right
stuff right
yeah I think that's where we left
yeah I think that's where we left
off so in order to do that let me see
off so in order to do that let me see
where we want
where we want
to start probably like here
103 and then hold on
103 and then hold on
export how you doing doing well thank
export how you doing doing well thank
you
you
oh thank you for making me notice I have
oh thank you for making me notice I have
to rearrange this little little
to rearrange this little little
bit uh we
bit uh we
are doing some cool stuff at least this
are doing some cool stuff at least this
will be cool when it works cuz we'll be
will be cool when it works cuz we'll be
able to run really nice networks in the
browser okay so here we we are in uh the
browser okay so here we we are in uh the
start of the lstm layer right and
start of the lstm layer right and
then I run this flat that
thing and we have this
thing and we have this
buffer so let's see if the linear layer
buffer so let's see if the linear layer
is correct do you stream daily usually
is correct do you stream daily usually
like five days a week Monday through
like five days a week Monday through
Friday and then I do solo Dev on
Saturday usually somewhere around 100
Saturday usually somewhere around 100
p.m. Pacific to like 8 or something like
p.m. Pacific to like 8 or something like
that I've been trying to get on earlier
that I've been trying to get on earlier
um I don't know just me being lazy
um I don't know just me being lazy
taking too long to like get my exercise
taking too long to like get my exercise
done and get food and all that stuff in
done and get food and all that stuff in
the mornings
okay this gets saved
into
into
buffer
right
so oh there you
so oh there you
go you can see right there that we match
go you can see right there that we match
here
here
and like if I do buffer of
10 this matches and now we should check
10 this matches and now we should check
to make sure that this is correct across
to make sure that this is correct across
everything so
everything so
like uh I don't know
1024 which
1024 which
is to
is to
zero
zero
yeah isn't it difficult to to reply to
yeah isn't it difficult to to reply to
chat and focus
chat and focus
on the game what game game here is
on the game what game game here is
writing
code are you a language model is this an
code are you a language model is this an
automated bot say something if you're
automated bot say something if you're
actually a person here
H twitch
H twitch
Bots that's so
obnoxious well our linear layer is
correct hi sir welcome hold on let me
correct hi sir welcome hold on let me
ban this
bot there we
go literally an advertising
go literally an advertising
bot welcome back
okay so this is now
okay so this is now
at
at
buffer
buffer
right we should be able to see
like oh that's going to be hard to
like oh that's going to be hard to
figure out if this is correct isn't it
yeah this is all
yeah this is all
one okay we'll have to do something
one okay we'll have to do something
about
about
that yeah all of these gates are all
one I think we need to just like divide
one I think we need to just like divide
by 10,000 or something in all of our
by 10,000 or something in all of our
input
data
yeah that's obnoxious but at least we
yeah that's obnoxious but at least we
know that our input layers are correct
know that our input layers are correct
right
yeah so just all of these places where
yeah so just all of these places where
we are doing uh a range let's just do
we are doing uh a range let's just do
over
over
10,000 over
10,000
oops and this will uh this will get us
oops and this will uh this will get us
into a data regime where essentially
into a data regime where essentially
these sigmoids and these canes these
these sigmoids and these canes these
functions here will not always give the
functions here will not always give the
same result we should actually be able
same result we should actually be able
to get something done there I would
hope that might actually still not be
hope that might actually still not be
enough but we'll
see because all the weights are positive
see because all the weights are positive
right wait a second all the weights are
right wait a second all the weights are
positive
uh well we'll see what this does on its
uh well we'll see what this does on its
own
welcome YouTube
welcome YouTube
folks we're currently fixing the lstm
folks we're currently fixing the lstm
layer
layer
here uh and we are testing to make sure
here uh and we are testing to make sure
that this performs exactly the same as P
torch so what we're doing is we're
torch so what we're doing is we're
getting a little bit of synthetic
getting a little bit of synthetic
data and then we're going to test to
data and then we're going to test to
make sure that at every portion of this
make sure that at every portion of this
function we match the uh the P torch
function we match the uh the P torch
reference
reference
okay recompile
okay recompile
this where did my commands
go
cool and now 103 we have buff for
zero and here we should have
zero and here we should have
[Music]
[Music]
buffer
buffer
oops zero and these match as you can see
oops zero and these match as you can see
and we can do like buffer of like
and we can do like buffer of like
1024 which I believe corresponds to
1024 which I believe corresponds to
buffer two and these match exactly
buffer two and these match exactly
perfect so our linear layers are correct
perfect so our linear layers are correct
uh as we suspected 20
uh as we suspected 20
so now we go down to the bottom of the
so now we go down to the bottom of the
gates
right and perfect so now we actually
right and perfect so now we actually
have applied the gates
here what are we searching for today yes
here what are we searching for today yes
so uh the goal here is to
so uh the goal here is to
get these models which is hold on let me
get these models which is hold on let me
show you
so I have this uh this MOA that I've
so I have this uh this MOA that I've
been coding for RL work you can actually
been coding for RL work you can actually
play it online here this runs in a
play it online here this runs in a
browser you can like run around it's a
browser you can like run around it's a
basic little MOA here's a speed buff
basic little MOA here's a speed buff
right it's got like an assassinate
right it's got like an assassinate
ability on
ability on
stuff so on and so forth um yeah so and
stuff so on and so forth um yeah so and
what we're trying to do with this thing
if we go to the GitHub
here we have these models that we're
here we have these models that we're
using for the RL agents and they're all
using for the RL agents and they're all
pretty similar they basically they all
pretty similar they basically they all
are going to use
are going to use
convolutions uh they're going to
convolutions uh they're going to
use linear layers a few activations and
use linear layers a few activations and
an lstm
an lstm
so here's the network for the Moa so
so here's the network for the Moa so
basically if I can just Implement all
basically if I can just Implement all
these layers for uh the Inc I'll be able
these layers for uh the Inc I'll be able
to compile them and run them on the web
to compile them and run them on the web
and Noah how's it going we're uh we're
and Noah how's it going we're uh we're
porting models to see so that we can run
porting models to see so that we can run
them
them
online speaking of
online speaking of
which if your breakout environment is uh
which if your breakout environment is uh
is done we should get that integrated
is done we should get that integrated
because we're starting to have some cool
because we're starting to have some cool
demos around here here's the mobo being
demos around here here's the mobo being
run browser right lots of cool stuff
run browser right lots of cool stuff
going
on that's what we're doing for the time
on that's what we're doing for the time
being
being
here and it looks like it's going fairly
here and it looks like it's going fairly
well
513 yeah that's
513 yeah that's
correct no time to work on it start next
correct no time to work on it start next
month sounds
good yeah Nathan is also currently
good yeah Nathan is also currently
writing his thesis and he says he's
writing his thesis and he says he's
going to be working on some cool
going to be working on some cool
environments next week so cool
environments next week so cool
stuff but for the time
stuff but for the time
being I will handle all these nets and
being I will handle all these nets and
will actually be able to run stuff on
will actually be able to run stuff on
the web it would be very cool
the web it would be very cool
uh let me see how I want to check this
uh let me see how I want to check this
so hang on I
times hidden
times hidden
size wait
buffer right so this buffer is of size
1024 let me just make sure I understand
1024 let me just make sure I understand
this
yeah yeah okay so I here is 500 what is
yeah yeah okay so I here is 500 what is
this 128
elements and
elements and
then yeah this is correct and now we
then yeah this is correct and now we
need to
need to
check I mean the other one should be
check I mean the other one should be
right shouldn't
right shouldn't
they like if I do buffer of 120 of what
they like if I do buffer of 120 of what
is
is
0128 this should
0128 this should
be well not buffer it should be I here
be well not buffer it should be I here
I'm getting confused with
I'm getting confused with
indexing okay F of Z 0 should be
indexing okay F of Z 0 should be
buffer
128 is that not correct
sigmoid of
f ifg
o did I mess this up somehow let me
o did I mess this up somehow let me
see ifg o is split the
see ifg o is split the
buffer and then
I did I get the dimensions wrong
somehow 16 by
128 I might be interpreting the
128 I might be interpreting the
dimensions wrong
because we just put a broke we put a
because we just put a broke we put a
break point down to
break point down to
here
right wait does this make
right wait does this make
sense no this logic is wrong right two
sense no this logic is wrong right two
times hidden size
wait batch
wait batch
offset
is four times the batch times the hidden
is four times the batch times the hidden
size and then you do the buffer address
size and then you do the buffer address
B offset plus
B offset plus
I equal to
I equal to
sigmoid that looks good to me
okay maybe we figure something out
okay maybe we figure something out
here buffer of
one this
matches this also matches
matches this also matches
right about
127 also matches
what's I of one
what's I of one
Z
5087 is that
5087 is that
correct I guess it would be
so F of Z
Z I fail to see how this happens
128 is equal to
0.5 somehow these gates are not lined up
0.5 somehow these gates are not lined up
the way I think that they are I guess
so what I think should be happening here
so what I think should be happening here
right is that there are four different
right is that there are four different
Gates you can see them here I F uh go
Gates you can see them here I F uh go
four different activations I guess and
four different activations I guess and
these are each 128 Dimensions so I want
these are each 128 Dimensions so I want
to check that the values that are
to check that the values that are
computed in C for these are equal to the
computed in C for these are equal to the
values in pi torch and it looks like the
values in pi torch and it looks like the
first set matches and the second set
first set matches and the second set
doesn't which is very bizarre
because literally I just go through and
because literally I just go through and
set the
set the
first however many this is right
tch. sigmoid of f
right you split it into size of hidden
right you split it into size of hidden
chunks
yeah and we know that the sigmoid
yeah and we know that the sigmoid
function matches because it matched for
function matches because it matched for
I so why does it magically not match for
I so why does it magically not match for
this what am I not seeing here
this what am I not seeing here
sigmoid buffer buff
sigmoid buffer buff
address offset is equal to four time the
address offset is equal to four time the
batch times the hidden size this is zero
batch times the hidden size this is zero
for the first Loop
for the first Loop
right and then hidden size is 128 so
right and then hidden size is 128 so
this is the first 256
this is the first 256
elements and then you just go through 0
elements and then you just go through 0
to
to
256 you set the buffer equal
256 you set the buffer equal
to sigmoid here
let's rerun
this so buffer
zero8
right 0
0 oh
0 oh
well hold
well hold
on Match is
on Match is
there but
there but
[Music]
[Music]
127 you
get let's just take a look at what our
get let's just take a look at what our
data is
data is
here maybe the test case is weird
because there's nothing that should go
because there's nothing that should go
like should be cyclical like that oh
like should be cyclical like that oh
wait am I just not hold on num
buffer input is numb input buffer num
buffer input is numb input buffer num
buffer output num
buffer output num
output and we have hidden
output and we have hidden
size the weights input
this should be four shouldn't
this should be four shouldn't
it four times hidden
it four times hidden
size yeah so your test the test case is
size yeah so your test the test case is
just
wrong so we have buffer of zero
uh that's a little
uh that's a little
suspicious oh no wait because it's
suspicious oh no wait because it's
already yeah yeah yeah this is fine
already yeah yeah yeah this is fine
so okay so I still
so okay so I still
matches let's check 127 which is buffer
matches let's check 127 which is buffer
127 this matches which it did before and
127 this matches which it did before and
now this looks better this looks way
now this looks better this looks way
better uh because if I
do this doesn't work work here right
do this doesn't work work here right
because it's
because it's
F
F
Z
Z
93 that's a little bit off
9372 I don't know if that's within I
9372 I don't know if that's within I
don't know if that's within numerical
don't know if that's within numerical
Precision I would doubt
it yeah no in the third digit I I don't
it yeah no in the third digit I I don't
believe
believe
that let let's check the next one what
that let let's check the next one what
copile are you using super Maven it's
copile are you using super Maven it's
great I highly recommend
it it gives me very fast on line
it it gives me very fast on line
completions which is all I
want it'll do multi-line as well but
want it'll do multi-line as well but
typically I just want really fast one
typically I just want really fast one
line completion save typing not
thinking okay so something is screwy
thinking okay so something is screwy
here because
do I believe that it's that far
off no I don't believe it's that far off
off no I don't believe it's that far off
because if you look at the 127th element
because if you look at the 127th element
9359 9359 they match
perfectly plus this is um 0o to one data
perfectly plus this is um 0o to one data
is where the high float Precision lives
so what happened
here are you essentially flattening
here are you essentially flattening
arrays kind of yeah I have on the right
arrays kind of yeah I have on the right
side I have a pie torch implementation
side I have a pie torch implementation
which is like just going through the
which is like just going through the
different operations in the lstm and on
different operations in the lstm and on
the left I have GDB over the C
the left I have GDB over the C
implementation that operates on flat
implementation that operates on flat
buffers and I'm trying to make my C
buffers and I'm trying to make my C
impementation match the pytorch
impementation match the pytorch
implementation exactly because if it
implementation exactly because if it
does then I can load uh weights from
does then I can load uh weights from
pre-trained pytorch networks into it and
pre-trained pytorch networks into it and
I can run them on the web because I can
I can run them on the web because I can
compile the web
compile the web
assembly and then I'll end up with like
assembly and then I'll end up with like
this 300 line file that lets me just run
this 300 line file that lets me just run
whatever I want on the web
but you know you have to get them to
but you know you have to get them to
match
exactly is super Maven free there's a
exactly is super Maven free there's a
free version but I highly recommend the
free version but I highly recommend the
paid
one e
this is very weird because it looks
this is very weird because it looks
like the sigmoid should be
good are my weights somehow being set
good are my weights somehow being set
differently they shouldn't be
we should probably make sure that um the
we should probably make sure that um the
linear layers match before we commit to
linear layers match before we commit to
all this
right
right
so
so
here buffer zero buffer 12.7 buffer 128
here buffer zero buffer 12.7 buffer 128
right I can do
right I can do
buffer 0
buffer 0
0 that
0 that
matches
matches
6817 yep that
6817 yep that
matches and then
0128 okay this does not quite
0128 okay this does not quite
match right here so it might not it's
match right here so it might not it's
probably not the error in the gates it
probably not the error in the gates it
looks like there's something wrong
looks like there's something wrong
with our linear which is very weird
with our linear which is very weird
because we have that tested
because we have that tested
independently
independently
so I think that what we're going to have
so I think that what we're going to have
to do is we're going to have to make
to do is we're going to have to make
first of all we got to make sure our
first of all we got to make sure our
test date is actually what we think it
test date is actually what we think it
is was actually the same
is was actually the same
um and if it is then we'll have to look
um and if it is then we'll have to look
at the linear layer because maybe maybe
at the linear layer because maybe maybe
I missed something earlier I didn't
I missed something earlier I didn't
think that I did but we'll
think that I did but we'll
see welcome to all the YouTube folks oh
see welcome to all the YouTube folks oh
yeah by the way very quick plug all this
yeah by the way very quick plug all this
stuff is free and open source in puffer
stuff is free and open source in puffer
lib all the RL stuff we're 16 Stars off
lib all the RL stuff we're 16 Stars off
of 1K so if you want to help me out for
of 1K so if you want to help me out for
free star the repo to feed the
free star the repo to feed the
puffer thank you back to
Dev maybe too basic too much data do
Dev maybe too basic too much data do
difficult to print start of each your
difficult to print start of each your
segments aren't in CL well that's what
segments aren't in CL well that's what
I'm doing right I'm print I am doing
I'm doing right I'm print I am doing
that that's what I'm I'm printing out
that that's what I'm I'm printing out
these elements here I'm just doing it
these elements here I'm just doing it
interactively as
interactively as
all um you know because it's obnoxious
all um you know because it's obnoxious
to write test scripts that are like
to write test scripts that are like
across Python and C at the same time I'd
across Python and C at the same time I'd
have to write
bindings well they definitely mismatch
bindings well they definitely mismatch
here though so let's take a quick look
here though so let's take a quick look
at
at
the we'll look at the code side by side
okay so here's the code in
okay so here's the code in
pytorch and here is the code in
C and we're going to want to look at the
C and we're going to want to look at the
data going into these to start
data going into these to start
with so this is where I make the test
data and then let's see what I do over
data and then let's see what I do over
here so
here so
input num input
input num input
is batch size times input size these
is batch size times input size these
shapes look
shapes look
good and then the state
data batch size times hidden
size I'm output batch size yep that
size I'm output batch size yep that
looks
looks
good and then buffers four * batch times
good and then buffers four * batch times
hidden
hidden
just hold on are the weights
just hold on are the weights
wrong wait
four times
four times
hidden no that's correct right four
hidden no that's correct right four
times hidden times input four times
times hidden times input four times
hidden times hidden
hidden times hidden
yeah
yeah
right oh look right here it was just
right oh look right here it was just
ever so slightly off because we forgot
ever so slightly off because we forgot
to add the test data
to add the test data
to be the correct shape for the bias hey
to be the correct shape for the bias hey
man what are you up to I currently
man what are you up to I currently
making this C implementation of comet
making this C implementation of comet
plus lstm match the P torch version so
plus lstm match the P torch version so
that we can compile it to wasam and run
that we can compile it to wasam and run
it on the web so that we can actually
it on the web so that we can actually
demo our cool RL agents online
I bet it's going to match
now grab some sample
points o for 0 0 matches
points o for 0 0 matches
perfectly we didn't do one
perfectly we didn't do one
1.7 matches perfectly right down to the
1.7 matches perfectly right down to the
last significant
digit perfect now it
matches okay so now we are at we just
matches okay so now we are at we just
went past the activation function
went past the activation function
so where's the pie torch math on
so where's the pie torch math on
this if I just look up the
this if I just look up the
docks I'll show you what part we've been
docks I'll show you what part we've been
doing so we just confirmed that all
doing so we just confirmed that all
these map moles are correct in here all
these map moles are correct in here all
these arcs and now we're going to do
these arcs and now we're going to do
these individual activations we're going
these individual activations we're going
to make sure that the code is correct
to make sure that the code is correct
for
this nice to catch you live welcome
this nice to catch you live welcome
we're doing some crazy stuff today
okay so the first element matches
okay so the first element matches
here let's try
127 matches and now here I have it
127 matches and now here I have it
organized a little differently so it
organized a little differently so it
should be
should be
one
one
zero and then this is going to be
buffer it's flat
buffer it's flat
actually 512
actually 512
matches I've had good experience using
matches I've had good experience using
Onyx I've like I tried Onyx and it
Onyx I've like I tried Onyx and it
didn't work it was a pain so if you have
didn't work it was a pain so if you have
an easy way to get this working with
an easy way to get this working with
Onyx and CI all years but I have not
Onyx and CI all years but I have not
found an easy way of doing
found an easy way of doing
it there was like a massive chain of
it there was like a massive chain of
dependencies in build and it was
dependencies in build and it was
such a pain that I was like well I can
such a pain that I was like well I can
just write 300 lines of C
like And subscribe because it's hard
like And subscribe because it's hard
work yeah thank you and honestly like
work yeah thank you and honestly like
folks just St the repository we're so so
folks just St the repository we're so so
close to hitting a thousand
close to hitting a thousand
now
984 new to ml stuff and only started my
984 new to ml stuff and only started my
first research project surrounding the
first research project surrounding the
topic a month and a half ago think can
topic a month and a half ago think can
join a
join a
competition surrounding degenerative
competition surrounding degenerative
lumbar spine
lumbar spine
disease more experience in the field of
disease more experience in the field of
on High level what would you be your
on High level what would you be your
steps to
steps to
tackle to just
tackle to just
testing CNN V implementations and hyp
testing CNN V implementations and hyp
and doing pram
and doing pram
sweeps
sweeps
um well it depends how much compute you
um well it depends how much compute you
have access to
have access to
right a lot of stuff can
right a lot of stuff can
be a lot of stuff actually is going to
be a lot of stuff actually is going to
depend a lot more on the data than on
depend a lot more on the data than on
the models so you definitely are going
the models so you definitely are going
to want to spend more you're going to
to want to spend more you're going to
spend a lot of time massaging the data
spend a lot of time massaging the data
it depends how much of it is is as well
it depends how much of it is is as well
usually with stuff like that you don't
usually with stuff like that you don't
have that many like you don't have that
have that many like you don't have that
many images or that many samples of
many images or that many samples of
stuff so uh yeah that's usually you end
stuff so uh yeah that's usually you end
up spending a lot of time on the
data like architecture will matter
data like architecture will matter
matter a little bit parameter sweeps
matter a little bit parameter sweeps
will matter a little bit but probably
will matter a little bit but probably
just getting better data is
just getting better data is
when or like figure out like ways to
when or like figure out like ways to
augment the data or something like
that okay so
that okay so
here buffer
128 I did it on Jaz on
128 I did it on Jaz on
phones yeah if you want to do it with
phones yeah if you want to do it with
JavaScript then sure
JavaScript then sure
I was looking for a Capi to uh to Onyx
I was looking for a Capi to uh to Onyx
right cuz like if I do it in JavaScript
right cuz like if I do it in JavaScript
then I have to figure out how to get the
then I have to figure out how to get the
stupid like actions from JavaScript back
stupid like actions from JavaScript back
into the C environment and stuff it's
into the C environment and stuff it's
just such a
just such a
pain all the like multi language
stuff this is going to literally end up
stuff this is going to literally end up
being like a C file that just works
mhm yeah like people will see this and
mhm yeah like people will see this and
they'll think I'm just Ming like why the
they'll think I'm just Ming like why the
hell are you doing this in C it's like
hell are you doing this in C it's like
no I'm not I'm doing this in C because
no I'm not I'm doing this in C because
it's literally
it's literally
easier it's literally
easier and like doing this is kind of
easier and like doing this is kind of
cool um like make it like trying to get
cool um like make it like trying to get
this working in the JavaScript
this working in the JavaScript
ecosystem is going to make me
ecosystem is going to make me
demonetized
demonetized
[Laughter]
right let's check the tan H gate
is the whole tan H gate going to be like
this ah so the whole tan H is like
this ah so the whole tan H is like
this
really yeah because the numbers are too
really yeah because the numbers are too
big kage goes to one very
quickly I think we have to uh scale the
quickly I think we have to uh scale the
data down a little bit
data down a little bit
more in order to make sure that we can
more in order to make sure that we can
test this
test this
correctly thanks for the answer comp
correctly thanks for the answer comp
does mention using other publicly
does mention using other publicly
available data sets is allowed haven't
available data sets is allowed haven't
thought of much regarding
thought of much regarding
augmentation a new model or an existing
augmentation a new model or an existing
classifier for an unrelated but similar
classifier for an unrelated but similar
type of class probably fine tune
type of class probably fine tune
something
something
it's kind of difficult when you don't
it's kind of difficult when you don't
have compute for stuff right it's just
have compute for stuff right it's just
like it's so much harder to do anything
like it's so much harder to do anything
in these spaces when you like you have
in these spaces when you like you have
big models that actually require compute
big models that actually require compute
to
train we're going to add a zero here
and this what this is going to do is
and this what this is going to do is
this is going to get us into the regime
this is going to get us into the regime
where uh t h will not just always be one
where uh t h will not just always be one
so I'll actually be able to test to make
so I'll actually be able to test to make
sure that uh we match
correctly he's not joking writing it in
correctly he's not joking writing it in
C is literally
C is literally
easier I'm not doing this just because
easier I'm not doing this just because
I'm a masochist I'm not denying that I'm
I'm a masochist I'm not denying that I'm
a masochist but like I'm not doing it
a masochist but like I'm not doing it
just for the sake of masochism here
just for the sake of masochism here
right I have I have limitations there uh
right I have I have limitations there uh
it's because it is actually easier
honestly this is pretty
comfortable let me make sure we didn't
comfortable let me make sure we didn't
mess anything
up
oops
okay that's good and now we need
okay that's good and now we need
v00 which is going to be
buffer uh 256
buffer uh 256
right and does that look
right and does that look
good I think so the Precision does a
good I think so the Precision does a
little
iffy yeah no that's definitely
iffy yeah no that's definitely
correct so perfect so now we know that
correct so perfect so now we know that
these layers work let's just for the
these layers work let's just for the
just to be thorough uh let's do
just to be thorough uh let's do
like
384 uh oh wait did I do this
384 uh oh wait did I do this
wrong no no no no no fig G what's the
wrong no no no no no fig G what's the
other gate called is it
other gate called is it
o I think it's
o I think it's
O there you go okay so all the gates are
O there you go okay so all the gates are
good we now know that the lstm
good we now know that the lstm
implementation is correct all the way
implementation is correct all the way
through to here oops through like to
through to here oops through like to
here now we just need the last two lines
here now we just need the last two lines
of
of
it currently learning
DSA
DSA
[Music]
domain
domain
[Music]
[Music]
domain I literally don't know what this
domain I literally don't know what this
is I literally don't know what this is
people be the you'll be very surprised
people be the you'll be very surprised
about like the number of standard things
about like the number of standard things
that I just don't know what they are or
that I just don't know what they are or
haven't used
oh
okay well that one is definitely
useful I'm not a fan of teaching
useful I'm not a fan of teaching
beginners JavaScript Frameworks but yes
beginners JavaScript Frameworks but yes
core data structures and algorithms you
core data structures and algorithms you
definitely need to know I don't know if
definitely need to know I don't know if
that's a specific book or just like the
that's a specific book or just like the
abbreviation in general but yeah your
abbreviation in general but yeah your
first course in data structures is very
first course in data structures is very
important
it's actually very funny I think that if
it's actually very funny I think that if
I wanted to apply for like a traditional
I wanted to apply for like a traditional
software engineering job I probably
software engineering job I probably
would have been more qualified by
would have been more qualified by
interview standards after my freshman
interview standards after my freshman
year of undergrad because like they just
year of undergrad because like they just
ask you all the random basic data
ask you all the random basic data
structures
structures
crap and you don't remember the Stu like
crap and you don't remember the Stu like
the portions of that that you don't use
the portions of that that you don't use
for 10 years
let's
see I mean Stanford we just have course
see I mean Stanford we just have course
numbers on stuff
right please
guide trying to train a custom
aec two agent
environment oh a okay yeah two agent
environment oh a okay yeah two agent
environment by a see you just mean
environment by a see you just mean
turn-based
turn-based
observation space being the same and the
observation space being the same and the
actions being
actions being
different would you be willing to point
different would you be willing to point
me in the right
me in the right
direction um ah geez
direction um ah geez
so
so
yes
um I can show you how to hack
um I can show you how to hack
it so here most things don't handle a I
it so here most things don't handle a I
can make that work with
can make that work with
puffer um action spaces being different
puffer um action spaces being different
basically nothing supports
basically nothing supports
correctly
correctly
so you're going to have to like pad your
so you're going to have to like pad your
action spaces or
action spaces or
whatever in like an environment
whatever in like an environment
wrapper um with
wrapper um with
puffer there is a mask output an
puffer there is a mask output an
optional mask output that you can return
optional mask output that you can return
and what you will do is you'll basically
and what you will do is you'll basically
just set the mask to like mask out the
just set the mask to like mask out the
agent whose turn it isn't does that make
agent whose turn it isn't does that make
sense so you can just mask out whatever
sense so you can just mask out whatever
agent is not doesn't have their turn
agent is not doesn't have their turn
currently and then puffer will just work
currently and then puffer will just work
you will still have to write a rapper
you will still have to write a rapper
though to like match the action spaces
though to like match the action spaces
that is one of the very few features
that is one of the very few features
that I haven't done in puffer and like
that I haven't done in puffer and like
it's a real pain to do that like it's
it's a real pain to do that like it's
very very difficult to do that
very very difficult to do that
efficiently without messing up the whole
efficiently without messing up the whole
rest of the
rest of the
stack welcome as well
can you explain what puffer
can you explain what puffer
is
is
MHM
so I mean broadly speaking
so I mean broadly speaking
puffer is my attempt to fix all the
puffer is my attempt to fix all the
stuff that's currently wrong with
stuff that's currently wrong with
reinforcement learning so it contains a
reinforcement learning so it contains a
bunch of different
bunch of different
stuff but the high level of it is from
stuff but the high level of it is from
the uh the iceberg video which I'd
the uh the iceberg video which I'd
recommend if you haven't watched that
recommend if you haven't watched that
full thing
full thing
um it's generally low-level tools and
um it's generally low-level tools and
infrastructure to make it easy to work
infrastructure to make it easy to work
with lots of different types of
with lots of different types of
simulations and to do very fast
simulations and to do very fast
simulation as well as fast parallel
simulation as well as fast parallel
simulation
simulation
on top of that we have like sane
on top of that we have like sane
training libraries sane training
training libraries sane training
Integrations uh nice hyper parameter
Integrations uh nice hyper parameter
sweeps and other utilities that just
sweeps and other utilities that just
make it really easy to automate a lot of
make it really easy to automate a lot of
experimental research
experimental research
work so that is what puffer does
work so that is what puffer does
um Iceberg vid open will watch yeah the
um Iceberg vid open will watch yeah the
iceberg vid will really do a better job
iceberg vid will really do a better job
than I can do just off the cuff here um
than I can do just off the cuff here um
I mean that video I made it for this
I mean that video I made it for this
reason it's like 26 minutes for a
reason it's like 26 minutes for a
complete overview of the whole stack of
complete overview of the whole stack of
reinforcement learning my thoughts at
reinforcement learning my thoughts at
every single layer of the experimental
every single layer of the experimental
and infrastructure stack and what I am
and infrastructure stack and what I am
currently doing about it in
currently doing about it in
puffer what you're watching right here
puffer what you're watching right here
is a very specific small portion where
is a very specific small portion where
I'm looking at fast environments and uh
I'm looking at fast environments and uh
I'm just porting a couple like a couple
I'm just porting a couple like a couple
inference things to see so that we can
inference things to see so that we can
run demos on the web um and so that we
run demos on the web um and so that we
can have like nice contain
can have like nice contain
stuff but yeah nice haircut I did not
stuff but yeah nice haircut I did not
get a haircut nice try
though I was going to go get it cut it's
though I was going to go get it cut it's
too
too
long it gets in the way
long it gets in the way
running it's too darn hot outside
well we have the lstm matching up to the
gates so what do we think the odds are
gates so what do we think the odds are
that if I just put a breako at the end
that if I just put a breako at the end
of the
of the
function that this will
work let's try
this did you try just copy pasting code
this did you try just copy pasting code
to an l and ask it to convert to C no um
to an l and ask it to convert to C no um
that route leads to much pain and
that route leads to much pain and
suffering because I would rather just
suffering because I would rather just
write the code than and like spend my
write the code than and like spend my
time understanding the things that I've
time understanding the things that I've
done wrong and fixing those rather than
done wrong and fixing those rather than
not writing the code and spending the
not writing the code and spending the
same amount of time fixing dumb bugs
same amount of time fixing dumb bugs
that an llm has written where I have
that an llm has written where I have
like no understanding of what the hell
like no understanding of what the hell
it's trying to
it's trying to
do I generally suggest using language
do I generally suggest using language
models to save typing not thinking
okay so we have is there an output here
okay so we have is there an output here
bias
buffer what is this thing writing
buffer what is this thing writing
into wait what the heck did I make this
into wait what the heck did I make this
thing right
thing right
into oh State C State H that's
fine pain and suffering gp2 report
fine pain and suffering gp2 report
yeah VI LM is refreshing God or the
yeah VI LM is refreshing God or the
answer it's not it's really not and it's
answer it's not it's really not and it's
mostly dumb Junior developers uh who
mostly dumb Junior developers uh who
think that they can like get out of
think that they can like get out of
learning how to code
learning how to code
it's a really really dumb thing to be
it's a really really dumb thing to be
doing like here's here's the like here's
doing like here's here's the like here's
the really obvious way of putting it
the really obvious way of putting it
right like if you think that you're
right like if you think that you're
going to have value just by typing
going to have value just by typing
prompts into an llm like everybody can
prompts into an llm like everybody can
freaking do that okay so yeah you're
freaking do that okay so yeah you're
potentially right now in the next couple
potentially right now in the next couple
of years maybe you can build some cool
of years maybe you can build some cool
applications and make some money but
applications and make some money but
like thereafter you will have zero
like thereafter you will have zero
skills and zero value
skills and zero value
whatsoever like you're guaranteeing that
whatsoever like you're guaranteeing that
you will replace your so not because the
you will replace your so not because the
AI is good but because you have
AI is good but because you have
literally zero skills that's like this
literally zero skills that's like this
is why I suggest not doing
this yeah
it still will make it still will write
it still will make it still will write
tons of bugs converting languages I
tons of bugs converting languages I
tried that before um with some C code
tried that before um with some C code
and it was literally it was worse than
and it was literally it was worse than
me just writing it myself because like
me just writing it myself because like
here this is how you use language models
here this is how you use language models
to write to convert code faster I use
to write to convert code faster I use
super Maven it gives me on Line Auto
super Maven it gives me on Line Auto
completes so basically I'm tabbing on
completes so basically I'm tabbing on
line completions making sure that each
line completions making sure that each
line is exactly as I want it so it's
line is exactly as I want it so it's
like I can type 200 wpm I'm still doing
like I can type 200 wpm I'm still doing
all the thinking but it's like I no
all the thinking but it's like I no
longer am limited by me only being able
longer am limited by me only being able
to type 80 wpm or whatever and I get
to type 80 wpm or whatever and I get
like a 30 40% productivity boost out of
like a 30 40% productivity boost out of
it that is what I
it that is what I
recommend that is how you actually use
recommend that is how you actually use
AI to increase productivity without like
AI to increase productivity without like
reduce like without rotting your brain
basically you written inside see wait
basically you written inside see wait
did I miss a
message did I miss a me wait I think I
message did I miss a me wait I think I
missed a couple messages here would it
missed a couple messages here would it
even be smart to do
that is it Poss okay I miss some stuff
that is it Poss okay I miss some stuff
is it possible to build the environment
is it possible to build the environment
entirely in puffer or should I use
entirely in puffer or should I use
petting zoo and wrap it with puffer um
petting zoo and wrap it with puffer um
you can do either uh pu puffer supports
you can do either uh pu puffer supports
petting zoo and petting zoo parallel API
petting zoo and petting zoo parallel API
mind you and um um gymnasium natively so
mind you and um um gymnasium natively so
we have support for that there's also an
we have support for that there's also an
advanced thing you can do with puffer if
advanced thing you can do with puffer if
you really want extra speed so like the
you really want extra speed so like the
new environments I'm working on use the
new environments I'm working on use the
advanced API because we want a million
advanced API because we want a million
plus STS per second per
core my environment is very simple it
core my environment is very simple it
depends how fast you want to train on it
depends how fast you want to train on it
right like even for very simple
right like even for very simple
environments I can get simple
environments I can get simple
environment is training at over a
environment is training at over a
million steps per second so when you can
million steps per second so when you can
do that you can basically automate
do that you can basically automate
everything what is the mini grid M I'm
everything what is the mini grid M I'm
trying puffer lip for the first
trying puffer lip for the first
time um if you look up minig Grid it's
time um if you look up minig Grid it's
like a commonly used very simple
like a commonly used very simple
learning Benchmark we have Integrations
learning Benchmark we have Integrations
for that we have Atari we've got proc
for that we have Atari we've got proc
genen um I mean they're like a dozen
genen um I mean they're like a dozen
plus standard environments with puffer
plus standard environments with puffer
Li bindings for
it we basically like we have all the
it we basically like we have all the
standard stuff in puffer our goal is not
standard stuff in puffer our goal is not
to make your life more complicated by
to make your life more complicated by
introducing a bunch of new stuff you
introducing a bunch of new stuff you
don't need right we have all the
don't need right we have all the
standard tools exactly the way that
standard tools exactly the way that
you'd want them and they're faster than
you'd want them and they're faster than
the Alternatives that's what puffer lip
the Alternatives that's what puffer lip
gives you now if once you've done that
gives you now if once you've done that
right if you want to go a little bit
right if you want to go a little bit
deeper if you want to use our custom
deeper if you want to use our custom
environments if you want to write Ultra
environments if you want to write Ultra
ultra high performance simulations in
ultra high performance simulations in
order to make your research or your work
order to make your research or your work
even if you're an industry go a hundred
even if you're an industry go a hundred
times faster we have stuff for that as
times faster we have stuff for that as
well but it's not required you can get
well but it's not required you can get
benefit out of puffer lib immediately
benefit out of puffer lib immediately
without having to learn basically any
without having to learn basically any
new stuff if you've already done a
new stuff if you've already done a
little
RL and in case there are any industry
RL and in case there are any industry
folks here we do have support packages
co-pilot is fine just don't use it to
co-pilot is fine just don't use it to
write huge chunks of code for
you let's see
is this
is this
right
153 that looks good to
153 that looks good to
me um let's do
me um let's do
like
like
129 which should be I think like one
129 which should be I think like one
one well that doesn't work
oh one one yeah okay so the actually
oh one one yeah okay so the actually
this is complete this is completely
this is complete this is completely
correct which is kind of
correct which is kind of
cool let's do like what's this
cool let's do like what's this
257 no not yeah that's perfect
Joseph had trouble with Pip install d e
Joseph had trouble with Pip install d e
dot on
dev I probably broke the mooba build on
dev I probably broke the mooba build on
dev is what probably happened is that
dev is what probably happened is that
what is that what was it is that what it
was yeah okay I'll fix that my
bad let me fix this thing here it's just
bad let me fix this thing here it's just
I I put it in the same file I should
I I put it in the same file I should
have made a different
file I am allowed to break things on the
file I am allowed to break things on the
dev
Branch you can you can yell at me if I
Branch you can you can yell at me if I
break things on like on the stable
break things on like on the stable
branches on the dev Branch this is how
branches on the dev Branch this is how
it is supposed to work if I break a
it is supposed to work if I break a
thing by doing Dev fast you just come
thing by doing Dev fast you just come
here and tell
me I will fix that as soon as I as soon
me I will fix that as soon as I as soon
as I finish checking this one little
as I finish checking this one little
thing
here I want to contribute and want to
here I want to contribute and want to
break some stuff great let me uh here
break some stuff great let me uh here
let me just open real quick for folks
let me just open real quick for folks
watching
watching
if you're like either maybe new to
if you're like either maybe new to
reinforcement learning new to ml as a
reinforcement learning new to ml as a
whole whatever as long as you have some
whole whatever as long as you have some
development experience um building some
development experience um building some
cool RL environments is a really good
cool RL environments is a really good
way to get
way to get
involved now you can of course make
involved now you can of course make
contributions to the infrastructure and
contributions to the infrastructure and
stuff that's a lot harder but um if
stuff that's a lot harder but um if
you're just looking for like a fun way
you're just looking for like a fun way
to get into some RL let me see if I can
to get into some RL let me see if I can
find some of these environments in
find some of these environments in
here some of you might have uh might be
here some of you might have uh might be
familiar with this somebody's been
familiar with this somebody's been
building um like a Ultra ultra high
building um like a Ultra ultra high
performance uh clone of this old MMO
performance uh clone of this old MMO
called
called
dopus the combat system from it for an
dopus the combat system from it for an
environment we also have a few Atari
environment we also have a few Atari
environments that people have been
environments that people have been
making so like I think Noah might even
making so like I think Noah might even
still be around
still be around
here he's got pong no he's got breakout
here he's got pong no he's got breakout
and
and
then let's see yeah so so here is
then let's see yeah so so here is
stupidly high performance version of
stupidly high performance version of
pong we're going to try to replace some
pong we're going to try to replace some
of the Atari
of the Atari
environments here's like stupidly high
environments here's like stupidly high
performance version of
performance version of
breakout goal is going to be to replace
breakout goal is going to be to replace
tons and tons of environments with ultra
tons and tons of environments with ultra
ultra high performance
versions train and evalu on minig grid
versions train and evalu on minig grid
looks cool seeing the agent complete the
looks cool seeing the agent complete the
tasks yeah it should it's uh that's a
tasks yeah it should it's uh that's a
pretty simple task set also mini grid
pretty simple task set also mini grid
that is uh it would probably only take
that is uh it would probably only take
me a couple days to restructure the grid
me a couple days to restructure the grid
environment that I have to do all of
environment that I have to do all of
mini Rd at a million plus STS per second
mini Rd at a million plus STS per second
probably could get more than
that sioning space from
that sioning space from
o yo
o yo
bet that's a test environment that one
bet that's a test environment that one
doesn't have to be any faster that one's
doesn't have to be any faster that one's
literally like a 10sec test environment
literally like a 10sec test environment
anyways
like if you want to be building stuff
like if you want to be building stuff
like build some cool game environments
like build some cool game environments
right or or other types of environments
right or or other types of environments
right just like build some cool high
right just like build some cool high
perf
perf
simulators baby steps syon is really
simulators baby steps syon is really
easy to get used to so you don't have to
easy to get used to so you don't have to
be writing C to contribute to puffer at
be writing C to contribute to puffer at
all um probably you'll want to write in
all um probably you'll want to write in
like scyon or something because python
like scyon or something because python
itself is slow but if you haven't used
itself is slow but if you haven't used
python before it's literally you just
python before it's literally you just
write python add some types and boom now
write python add some types and boom now
it runs 100 times faster it's that
easy and the C is nowhere near as bad as
easy and the C is nowhere near as bad as
it looks if you're not used to
it looks if you're not used to
that but that's not required
28 lstm
28 lstm
Works would you be open to an aec
Works would you be open to an aec
implementation PR uh of course but I
implementation PR uh of course but I
don't know if you know how I don't know
don't know if you know how I don't know
if you know what you're getting yourself
if you know what you're getting yourself
into there is the thing um the reason
into there is the thing um the reason
that aec is hard is because well think
that aec is hard is because well think
about it right like you're getting
about it right like you're getting
observations from different agents at
observations from different agents at
different time steps so like if you're
different time steps so like if you're
going to use an lstm policy or even just
going to use an lstm policy or even just
for generalized Advantage estimation and
for generalized Advantage estimation and
such you need to keep track of which
such you need to keep track of which
agent comes from which environment aec
agent comes from which environment aec
is this it's basically turn-based um
is this it's basically turn-based um
it's like petting Zoo's name for
it's like petting Zoo's name for
turn-based environments so I've been
turn-based environments so I've been
thinking about that quite a bit Cole and
thinking about that quite a bit Cole and
the solution that I have in puffer lib
the solution that I have in puffer lib
is quite good I think it's going to be a
is quite good I think it's going to be a
lot faster than a lot faster and a lot
lot faster than a lot faster and a lot
less error prone then unless you have a
less error prone then unless you have a
really good idea in mind for it let me
really good idea in mind for it let me
explain how puffer lib does this real
quick I heard turnbas yeah so Nathan
quick I heard turnbas yeah so Nathan
this is relevant to for you as well for
this is relevant to for you as well for
your um your like dopus
your um your like dopus
environment God can I find okay here
environment God can I find okay here
so this is why turnbas is hard right so
so this is why turnbas is hard right so
normally when you get an environment
normally when you get an environment
right you have like agent One agent
right you have like agent One agent
two dot dot dot right and then this is
two dot dot dot right and then this is
going to give you
OBS and then these are going to go into
OBS and then these are going to go into
your model right which is like I don't
your model right which is like I don't
know some Com or whatever um and this
know some Com or whatever um and this
this one goes in this one goes in but
this one goes in this one goes in but
then also you have an lstm state right
and you need to grab like the state
and you need to grab like the state
variables right S1 S2 and these need to
variables right S1 S2 and these need to
go into here as
go into here as
well um even if you don't have an lstm
well um even if you don't have an lstm
you still need to keep track of which
you still need to keep track of which
OBS comes from which agent because then
OBS comes from which agent because then
what's going to happen is you're going
what's going to happen is you're going
to save this into a buffer right so you
to save this into a buffer right so you
have like A1 and you have like 01
have like A1 and you have like 01
o02 03
o02 03
and then you're going to do generalized
and then you're going to do generalized
Advantage estimation over
this which is very important but like if
this which is very important but like if
you're going to take away one of these
you're going to take away one of these
at a time then what happens well now you
at a time then what happens well now you
mess up all your indexing and you mess
mess up all your indexing and you mess
up your ability to like pack batches of
up your ability to like pack batches of
data so what puffer does for this is we
data so what puffer does for this is we
have a mask variable this is already
have a mask variable this is already
integrated with um our default training
integrated with um our default training
implementation what we do is we give you
implementation what we do is we give you
the option to return like a
the option to return like a
mask and then what happens when you do
mask and then what happens when you do
that is uh this observation just never
that is uh this observation just never
gets into the buffer so we actually have
gets into the buffer so we actually have
buffers that support
buffers that support
this but you still need to have like
this but you still need to have like
this mask essentially which is a little
this mask essentially which is a little
bit
bit
inefficient but um there's not really a
inefficient but um there's not really a
clear way to do this
clear way to do this
otherwise at least without massively
otherwise at least without massively
degrading the performance of vector
degrading the performance of vector
ation so I hope that gives you a rough
ation so I hope that gives you a rough
answer call like like you can already do
answer call like like you can already do
it in puffer and it's probably going to
it in puffer and it's probably going to
be way faster than anything else out
be way faster than anything else out
there just if you use this mask variable
there just if you use this mask variable
and the algorithm will be
correct I mean if you just want to look
correct I mean if you just want to look
at like our
vectorization just to show you what a
vectorization just to show you what a
massive difference that we have in
massive difference that we have in
performance and this is dated it's even
performance and this is dated it's even
faster
now you know we take a car Atari up from
now you know we take a car Atari up from
4.8k to 25k proen from 40K to 150 the
4.8k to 25k proen from 40K to 150 the
really fast environments go from 100K to
really fast environments go from 100K to
Millions right even for environments
Millions right even for environments
where like they're pretty slow and
where like they're pretty slow and
there's it's really easy to make them
there's it's really easy to make them
fast uh it's really hard to make them
fast uh it's really hard to make them
any faster like we go from 5 to 7.2
any faster like we go from 5 to 7.2
right we can run environments like
right we can run environments like
neural MMO that just gymnasium will
neural MMO that just gymnasium will
straight up fail on for
straight up fail on for
multi-agent um we've got like net hack
multi-agent um we've got like net hack
over 10x faster Mini grid 4X faster so
over 10x faster Mini grid 4X faster so
the perf is
there yeah Splinter check um the link
there yeah Splinter check um the link
the snake
link and for
reference on my way to Iceberg see you
thanks and for reference up until a few
thanks and for reference up until a few
days
days
ago this like entire MOA
ago this like entire MOA
EnV was uh implemented in pure
EnV was uh implemented in pure
syon so like this whole game was
syon so like this whole game was
implemented in
implemented in
syon only reason I'm doing C now is so I
syon only reason I'm doing C now is so I
can put it on the
can put it on the
web zon's plenty
web zon's plenty
fast do you do a masking for open Spiel
fast do you do a masking for open Spiel
Ms yeah so I think I only ever
Ms yeah so I think I only ever
integrated uh Connect 4 with that cuz I
integrated uh Connect 4 with that cuz I
had somebody that was trying to do
had somebody that was trying to do
Connect 4 but yeah you would mask for
Connect 4 but yeah you would mask for
that that's how we that's how we were
that that's how we that's how we were
handling it for um for open
Spiel I actually don't know how fast the
Spiel I actually don't know how fast the
open Spiel ends are they might already
open Spiel ends are they might already
be faster they might not
I'll see what I can come up with doesn't
I'll see what I can come up with doesn't
seem like anything implements turn based
seem like anything implements turn based
because I've thought about it a lot Cole
because I've thought about it a lot Cole
and the infrastructure for it is just
and the infrastructure for it is just
like it doesn't make sense with
like it doesn't make sense with
vectorization
vectorization
because you would have to change the
because you would have to change the
whole
whole
API you'd essentially have to change the
API you'd essentially have to change the
whole API and like the way that we get
whole API and like the way that we get
our vectorization fast is by passing
our vectorization fast is by passing
around like static chunks of
around like static chunks of
memory um and it's very difficult to do
memory um and it's very difficult to do
that when you have
that when you have
variable like variable agent turns and
variable like variable agent turns and
stuff but I don't think that there's a
stuff but I don't think that there's a
really good way of doing that any faster
really good way of doing that any faster
than we have it right
now
now
yeah I mean there are a couple
yeah I mean there are a couple
relatively easy optimizations that I can
relatively easy optimizations that I can
potentially think of but uh for the time
potentially think of but uh for the time
being you're we're probably like I would
being you're we're probably like I would
just use the puffer version for now and
just use the puffer version for now and
if you have a relatively simple
if you have a relatively simple
environment like puffer will probably
environment like puffer will probably
just Auto solve it in less than a
minute this is not a problem of um
minute this is not a problem of um
Nathan this is not a problem of
Nathan this is not a problem of
like there's no algorithmic problem here
like there's no algorithmic problem here
it's just literally like you have to be
it's just literally like you have to be
careful with the way that you're storing
careful with the way that you're storing
agent observations and the like if
agent observations and the like if
they're going to come from variable
sources so somehow while answering all
sources so somehow while answering all
these questions um I think we actually
these questions um I think we actually
got somewhere here
got somewhere here
because this is correct so we now have
because this is correct so we now have
an lstm implemented in C so that's
an lstm implemented in C so that's
cool
cool
right yeah this is now correct
so let's let's look at how cool this is
so let's let's look at how cool this is
real quick let's just take a moment to
real quick let's just take a moment to
appreciate how cool this is um from the
appreciate how cool this is um from the
top I guess from right here
top I guess from right here
21 down to
134 so like literally 100 lines of code
134 so like literally 100 lines of code
for an lstm convolution reu sigmoid T
for an lstm convolution reu sigmoid T
linear layers in C so literally it's 100
linear layers in C so literally it's 100
lines of code to just do all of this
lines of code to just do all of this
stuff so now it's compatible with web
stuff so now it's compatible with web
and we can run it
and we can run it
anywhere right we didn't need some crazy
anywhere right we didn't need some crazy
heavy framework we didn't need to deal
heavy framework we didn't need to deal
with like figuring out how to force onx
with like figuring out how to force onx
to work in C we didn't need to do any of
to work in C we didn't need to do any of
that it's 100 lines of C code
and we can probably make this shorter
and we can probably make this shorter
too
if anybody knows how to combine these
if anybody knows how to combine these
two functions into one function without
two functions into one function without
me having to put an if right here let me
me having to put an if right here let me
know are you still in the Academia
know are you still in the Academia
space are you commercial
space are you commercial
now um I'm not in Academia puffer is
now um I'm not in Academia puffer is
technically a startup we just launched
technically a startup we just launched
just a couple days ago officially um so
just a couple days ago officially um so
this is a company and we do offer
this is a company and we do offer
support packages so you know if you're
support packages so you know if you're
an Academia if you know fol in Academia
an Academia if you know fol in Academia
who could benefit from having RL not be
who could benefit from having RL not be
just a complete pain to work with and do
just a complete pain to work with and do
anything let me know but all of our
anything let me know but all of our
stuff is free and open source we're
stuff is free and open source we're
pretty much just selling extended
pretty much just selling extended
support and priority features and a
support and priority features and a
couple extra services around
that and I will say that the progress in
that and I will say that the progress in
the last few months has been very very
the last few months has been very very
rapid compared to Academia here it's
rapid compared to Academia here it's
been very very rapid progress
so the one thing I'd really like to have
so the one thing I'd really like to have
here is I'd like to have a test in C
here is I'd like to have a test in C
somehow I mean not in C I'd like to have
somehow I mean not in C I'd like to have
like an automated test for this I'm
like an automated test for this I'm
trying to think how we can do that
trying to think how we can do that
though
can you get detailed profiling like in
can you get detailed profiling like in
scyon yeah I'm sure I
can I only asked because I watched your
can I only asked because I watched your
thesis defense wondered what your next
thesis defense wondered what your next
thing was cool puffers fulltime nicely
thing was cool puffers fulltime nicely
thank you yeah no puffer is I think that
thank you yeah no puffer is I think that
this is going to change the whole field
this is going to change the whole field
very very quickly I mean when you can
very very quickly I mean when you can
just run like tens of billions of steps
just run like tens of billions of steps
worth of experiments per GPU per day
worth of experiments per GPU per day
field is a whole different place right
field is a whole different place right
it's like I said in the iceberg video If
it's like I said in the iceberg video If
you haven't seen that one I highly
you haven't seen that one I highly
recommend that seems like YouTube has
recommend that seems like YouTube has
not picked up on this video yet but uh
not picked up on this video yet but uh
at least I personally I thought I did I
at least I personally I thought I did I
thought the delivery was way better than
thought the delivery was way better than
my thesis we'll see if people agree with
my thesis we'll see if people agree with
that and if it just takes a little while
that and if it just takes a little while
to get into the algorithm but yeah yeah
to get into the algorithm but yeah yeah
okay be quiet you but yeah this I posted
okay be quiet you but yeah this I posted
this a few days ago now
has all my thoughts on RL in the
field all in one
place let me figure out how we're going
place let me figure out how we're going
to write this test because kind of what
to write this test because kind of what
I want to get done today um what I want
I want to get done today um what I want
to get done
to get done
today I have the working lstm I have
today I have the working lstm I have
working linear layer I have working comp
working linear layer I have working comp
layer which is technically enough to
layer which is technically enough to
build whatever I want um but these
build whatever I want um but these
functions are kind of Jank I want to at
functions are kind of Jank I want to at
least add like a a little bit of
least add like a a little bit of
structure to this just a tiny
bit and I don't want to break them in
bit and I don't want to break them in
the process so I'd like to figure out
the process so I'd like to figure out
how to have an automated
how to have an automated
test
um it's just a little bit obnoxious
um it's just a little bit obnoxious
because I'm technically relying on P
because I'm technically relying on P
torch and uh C code I guess technically
torch and uh C code I guess technically
I can just write the outputs to a right
I can just write the outputs to a right
and just compare the two
and just compare the two
files clicked on your thesis video cuz I
files clicked on your thesis video cuz I
saw a game in the thumbnail yeah fair
saw a game in the thumbnail yeah fair
enough we talk about lots of like RL and
enough we talk about lots of like RL and
game stuff in uh the puffer video it's a
game stuff in uh the puffer video it's a
very good overview of like the field hey
very good overview of like the field hey
Tenny
Tenny
welcome we're working on some stuff here
welcome we're working on some stuff here
I think what we're going to do is we're
I think what we're going to do is we're
going to take the next little bit to
going to take the next little bit to
build out some tests for this
what's bet what
what's bet what
is problem with views is the iceberg is
is problem with views is the iceberg is
not Normie friendly no the iceberg video
not Normie friendly no the iceberg video
is actually way more accessible than my
is actually way more accessible than my
thesis like the stuff in the iceberg
thesis like the stuff in the iceberg
video is actually like I threaded it
video is actually like I threaded it
through with like higher level stuff
through with like higher level stuff
that should be more
that should be more
accessible writing to two files and
accessible writing to two files and
comparing yeah it is kind of Jang but
comparing yeah it is kind of Jang but
what else would you have me do right
what else would you have me do right
like I have to have like otherwise I
like I have to have like otherwise I
have to bind this
I would I could write like a scon
I would I could write like a scon
binding for this and then call it from
binding for this and then call it from
python I guess
python I guess
right maybe that's
better I mean how bad would that
better I mean how bad would that
be let's say that I just take all these
be let's say that I just take all these
I put these into like puffer net. C or
I put these into like puffer net. C or
whatever I make like Puffer net. I make
whatever I make like Puffer net. I make
a scon
a scon
binding I import that into a python test
binding I import that into a python test
file that could work
file that could work
right maybe we will just do
right maybe we will just do
that that would be cleaner and I
that that would be cleaner and I
wouldn't have to do like the right
wouldn't have to do like the right
function and
see
see
yeah you've convinced
me what the heck is
me what the heck is
this oh yeah we don't need
this upper.
this upper.
C we don't need the
MOBA load weights can go at the bottom
MOBA load weights can go at the bottom
right so we'll just clean this up oops
right so we'll just clean this up oops
not
not
below the main file but we're not going
below the main file but we're not going
to even need a main
to even need a main
function and this is actually just going
function and this is actually just going
to be a h not a
c what are you working
c what are you working
on since we have some more people I'll
on since we have some more people I'll
go over quickly
go over quickly
so right now my main thing with puffer
so right now my main thing with puffer
lib for the next few weeks is ultra high
lib for the next few weeks is ultra high
performance simulation just making lots
performance simulation just making lots
of really good environments so that we
of really good environments so that we
can get experiments going in RL um part
can get experiments going in RL um part
of that is making it accessible so that
of that is making it accessible so that
people can actually see these
people can actually see these
environments and play around with them
environments and play around with them
and see what's going on so I have these
and see what's going on so I have these
running in the web like this is a MOBA
running in the web like this is a MOBA
that I wrote we're going to get more
that I wrote we're going to get more
environments into web soon this is
environments into web soon this is
written 100% in C compiles to web
written 100% in C compiles to web
assembly runs it a million steps per
assembly runs it a million steps per
second so it's very very efficient to
second so it's very very efficient to
play around with this thing and all
play around with this thing and all
different characters and whatever it's a
different characters and whatever it's a
very efficient environment for research
very efficient environment for research
it's a very efficient environment for um
it's a very efficient environment for um
testing out your RL methods it's great
testing out your RL methods it's great
but in order to actually have these guys
but in order to actually have these guys
do something and not just have me
do something and not just have me
controlling them right I want to have my
controlling them right I want to have my
RL bot actually control them so that you
RL bot actually control them so that you
can watch what the RL agents do and you
can watch what the RL agents do and you
can play around against the RL agents
can play around against the RL agents
and stuff like that and generally that's
and stuff like that and generally that's
just a really useful route to go and
just a really useful route to go and
it's not that hard all I have to do is
it's not that hard all I have to do is
make a few of the P torch layers work in
make a few of the P torch layers work in
C and then I can compile them to web
C and then I can compile them to web
assembly and then we can run them in
assembly and then we can run them in
browser so that's what I'm doing now
browser so that's what I'm doing now
that might sound kind of crazy but it's
that might sound kind of crazy but it's
only like 100 lines of C for linear lstm
only like 100 lines of C for linear lstm
convolution it's already done now all I
convolution it's already done now all I
have to do is make sure I don't break
have to do is make sure I don't break
this stuff because it's very easy to
this stuff because it's very easy to
break it write a couple quick
break it write a couple quick
tests I've already man manually tested
tests I've already man manually tested
it but I need to have like an automatic
it but I need to have like an automatic
test so that when I go to refactor this
test so that when I go to refactor this
a little bit in an hour or so as soon as
a little bit in an hour or so as soon as
I finish that I don't break it by
I finish that I don't break it by
mistake because like right now I've done
mistake because like right now I've done
all of this stuff with just like raw
all of this stuff with just like raw
pointers and it works but you have to be
pointers and it works but you have to be
very very careful about like you know
very very careful about like you know
making sure that you compute the offset
making sure that you compute the offset
in memory to your bias term correctly
in memory to your bias term correctly
and things like that and some of this I
and things like that and some of this I
can just make a lot easier so I want to
can just make a lot easier so I want to
do that refactor but not until I have a
do that refactor but not until I have a
quality test so yeah
quality test so yeah
you
could equally fast if factor is
const
um I don't know if that quite works
um I don't know if that quite works
because we need to use both of these
because we need to use both of these
functions
Stein but actually just reading your
Stein but actually just reading your
thing I got an idea as to how we can do
thing I got an idea as to how we can do
this with one function uh one function
this with one function uh one function
up here so you've jogged my memory so
up here so you've jogged my memory so
thanks for that do you think RL is
thanks for that do you think RL is
superior to evolutionary
superior to evolutionary
strategies
um if we're speaking generally then yes
um if we're speaking generally then yes
because the problem with es is that it
because the problem with es is that it
bets against Hardware like the classic
bets against Hardware like the classic
implementation of es um doesn't really
implementation of es um doesn't really
benefit from GPU it it really is like a
benefit from GPU it it really is like a
CPU type implement mentation it's a
CPU type implement mentation it's a
really bad idea to bet against advances
really bad idea to bet against advances
in
in
Hardware um it's also like you're not
Hardware um it's also like you're not
actually getting a good gradient signal
actually getting a good gradient signal
you need a ton of samples to approximate
you need a ton of samples to approximate
gradients
gradients
uh so it's very difficult to scale that
uh so it's very difficult to scale that
stuff and we just generally we haven't
stuff and we just generally we haven't
seen anything crazy come out of es
seen anything crazy come out of es
yet yeah I haven't really seen any super
yet yeah I haven't really seen any super
crazy results come out of es there was
crazy results come out of es there was
some cool stuff from like Ken and Jeff's
some cool stuff from like Ken and Jeff's
Uber group several years back but uh I
Uber group several years back but uh I
haven't seen anything since
then let's get puffer net. C written
then let's get puffer net. C written
real quick holy viewers welcome
real quick holy viewers welcome
everybody I promise we're going to
everybody I promise we're going to
actually like Buckle in and like write
actually like Buckle in and like write
these tests in a second so we can get
these tests in a second so we can get
some more stuff happening but I will
some more stuff happening but I will
just one last time since we're so close
just one last time since we're so close
to hitting this milestone
to hitting this milestone
like 15 stars to go until a th on puffer
like 15 stars to go until a th on puffer
so you want to make that happen help me
so you want to make that happen help me
out
guys okay so we don't really need any of
guys okay so we don't really need any of
this this stuff in here right all this
this this stuff in here right all this
stuff is just
Jank at least we don't need this stuff
we'll consider whether we need the rest
we'll consider whether we need the rest
of this test to be here or we're going
of this test to be here or we're going
to put this portion of the test in
to put this portion of the test in
Python uh get out what's this we don't
Python uh get out what's this we don't
use
use
this so lstm con sigmoid re linear okay
this so lstm con sigmoid re linear okay
so this is
good buffet. c
good buffet. c
buffet. h
now we need to make a a puffet scon file
now we need to make a a puffet scon file
right in order to make a python
binding hello this is Amos
binding hello this is Amos
welcome we're writing some C
Nets uh I'm going to want just the
Nets uh I'm going to want just the
prototypes of all these
prototypes of all these
functions right
which is if I wrote If I actually wrote
which is if I wrote If I actually wrote
a proper. h file you know
but we don't really do that
but we don't really do that
much maybe I should consider doing it I
much maybe I should consider doing it I
don't
don't
know the only thing that's making me
know the only thing that's making me
tempted to write proper. H files is that
tempted to write proper. H files is that
um you know H and C instead of just all
um you know H and C instead of just all
H is that you end up needing the
H is that you end up needing the
prototypes for scon anyways though I
prototypes for scon anyways though I
think they we still need it you'd like
think they we still need it you'd like
need like another set of
need like another set of
them only 14 to go to 1K thank you for
them only 14 to go to 1K thank you for
your support it helps a
your support it helps a
ton it really helps a
ton it really helps a
ton Factor should be an argument to
ton Factor should be an argument to
function I'mma head out till next week
function I'mma head out till next week
see you
see you
around thanks for dropping
by I already grabbed this
by I already grabbed this
one so we just need the LS M
one so we just need the LS M
right yeah look at that mess of a
right yeah look at that mess of a
signature okay so these are our
signature okay so these are our
functions and I need to go just grab a
functions and I need to go just grab a
little bit of
um what is it
simoa yeah so I just want to grab this
simoa yeah so I just want to grab this
just boiler
plate so we have all these flags on oop
plate so we have all these flags on oop
profile should be
false and we don't we do we need any of
false and we don't we do we need any of
this stuff I think we do need the numpy
this stuff I think we do need the numpy
apis we're not going to need all the
apis we're not going to need all the
other
stuff uh I think I need all of the
stuff uh I think I need all of the
function prototypes right so we'll
function prototypes right so we'll
do I can literally just copy these in
do I can literally just copy these in
can I like this
this
work and then if I can get a binding for
work and then if I can get a binding for
this going hold on I'm trying to
this going hold on I'm trying to
remember how I did this in the scon
remember how I did this in the scon
version here
version here
so I defined all these types right and
so I defined all these types right and
then how did I bind
then how did I bind
them
them
knit yeah I need this I need this logic
knit yeah I need this I need this logic
here to remind me how to do the casts
here to remind me how to do the casts
from uh from scyon
from uh from scyon
side I think that what you do
is we're going to end up with name
is we're going to end up with name
complex right
well I think this does
it yeah you just need like these wrapper
it yeah you just need like these wrapper
type things
type things
right and then
right and then
right
right
here you need to
here you need to
cast I think I think you need explicit
cast I think I think you need explicit
cast on stuff and they're formatted a
cast on stuff and they're formatted a
little weird so it's like bloat
little weird so it's like bloat
star input data looat star weight
star input data looat star weight
data uh looat
data uh looat
star this cast in tax is uh weird in
star this cast in tax is uh weird in
syon but the alternative Buy that I
syon but the alternative Buy that I
found for C like I think syon is
found for C like I think syon is
generally the easiest for numerical
generally the easiest for numerical
Computing at least I haven't found
Computing at least I haven't found
anything that I like more than cython so
anything that I like more than cython so
far uh we'll clean up the Syntax for
far uh we'll clean up the Syntax for
this in a bit but yeah I think now this
this in a bit but yeah I think now this
should auto complete right yeah this
should auto complete right yeah this
will just auto
complete let me make sure that this
complete let me make sure that this
didn't mess anything
didn't mess anything
up looks fine
okay so now we have a 50 line scon
okay so now we have a 50 line scon
binding for puffer net
binding for puffer net
and now what we do is we make a python
and now what we do is we make a python
file called test puffet
file called test puffet
right oops
and we don't need
this I want to figure out
this I want to figure out
there's there's a scyth online to like
there's there's a scyth online to like
one line pix import or
one line pix import or
whatever I guess for now we'll just do
whatever I guess for now we'll just do
from
from
puffer lib environment oceans
MOA puffer
net puffer
net and
net and
then
then
yeah death test
yeah death test
puffet linear player
we'll just make some like batch size is
we'll just make some like batch size is
16 hidden size input size
16 hidden size input size
right the test linear
right the test linear
layer uh and then we'll just
do data
a
range
range
space something like
space something like
this I know if it needs to be
reshaped pull this up on the side
ceret do c
ceret do c
oops H I
oops H I
guess so we have linear
guess so we have linear
layer and now we need to
layer and now we need to
do
do
p make dummy
p make dummy
data Waits
and this needs to take args
right inputs num Pi is going to
right inputs num Pi is going to
be input
be input
size uh weight NP is going to be input
size uh weight NP is going to be input
size times hidden size hidden size
size times hidden size hidden size
output
output
NP
NP
puts
puts
equals
equals
zeros size times hidden size
rightee
rightee
to okay so now we have this data right
to okay so now we have this data right
and we do Huffer
and we do Huffer
net. Huffer net linear layer
and now we have to do the torch
data
data
TCH it's going to
TCH it's going to
be this and then we do want separate
be this and then we do want separate
zero function like
zero function like
this and then we just
do uh
do uh
torch linear equal
torch linear equal
torch. nn.
linear we don't need this output because
linear we don't need this output because
torch is not in
place we do like this right and then
place we do like this right and then
what we have to do is we need to have
what we have to do is we need to have
like an assert all near like
like an assert all near like
so
so
assert
assert
near a b
oh I think you can just do
oh I think you can just do
this
right yeah but let's do it let's do it
right yeah but let's do it let's do it
this way so that we can do have the
this way so that we can do have the
shapes match uh
numpy we'll just do both numpy
right
right
yeah assert near a b so assert a do
yeah assert near a b so assert a do
shape is B do shape and then assert NP
shape is B do shape and then assert NP
all less than 1 minus
all less than 1 minus
6 okay and now we'll do assert
6 okay and now we'll do assert
near
near
numpy
numpy
perfect so this is the basic form of our
perfect so this is the basic form of our
tests right is that we
tests right is that we
have some dummy
data and then we have the same dummy
data and then we have the same dummy
data and we want to make sure that our
data and we want to make sure that our
uh our two things match
has offer net
linear puffer net. pyx
right this compile
uh
yeah I see your error bet let me fix
yeah I see your error bet let me fix
that real
quick what happened here expected zero
quick what happened here expected zero
got
11 what the heck
do we use this file we do right this is
do we use this file we do right this is
our main
binding well this definitely
binding well this definitely
takes
margs MOBA
star expected zero args
yeah that's really weird this was
yeah that's really weird this was
working
before oh uh I think I
before oh uh I think I
know yeah I think I know so
let's just change I think that we just
let's just change I think that we just
forgot to change
this
no okay we're going to comment this for
no okay we're going to comment this for
now but I will fix this today
now but I will fix this today
bet you can yell at me if I
bet you can yell at me if I
don't I think that we just were defining
don't I think that we just were defining
the same thing multiple I think that
the same thing multiple I think that
it's CU I have multiple different scon
it's CU I have multiple different scon
things I need to fully Port from the old
things I need to fully Port from the old
version to the new version is
version to the new version is
all uh so let's see what do we have
all uh so let's see what do we have
here Huffer net.
here Huffer net.
H apparently we use a couple
depths is it do we need standard
depths is it do we need standard
IO I think we need standard bull
why can't I
type we need math as
well MOA star in it MOA and puffer tank
well MOA star in it MOA and puffer tank
has empty
parenthesis I don't know scyon
oh I think you're
right hold
on
on
ah yeah this is you're right
here thank
you I forgot cuz I was just adding like
you I forgot cuz I was just adding like
a prototype or something so I forgot
a prototype or something so I forgot
that I actually had to like yeah it's
that I actually had to like yeah it's
one really obnoxious thing about scyon
one really obnoxious thing about scyon
is that you have to give it the whole
is that you have to give it the whole
signature for everything even though
signature for everything even though
it's already defined in C I don't know
it's already defined in C I don't know
why but it's really
why but it's really
obnoxious so like the fact that syon
obnoxious so like the fact that syon
essentially makes you do header files
essentially makes you do header files
anyways makes it really really redundant
anyways makes it really really redundant
to have to split your code into headers
to have to split your code into headers
and the source c as
well thanks for the fix
comparison
of we don't need this
right um agents we don't need any of
right um agents we don't need any of
this crap in puffer
net we have one warning here
net we have one warning here
different
signedness
Waits good by me what are the craziest
Waits good by me what are the craziest
RL simulations you've
RL simulations you've
seen well it depends what you mean like
seen well it depends what you mean like
they didn't rewrite DOTA for RL or
they didn't rewrite DOTA for RL or
anything for uh open A5 right like it's
anything for uh open A5 right like it's
the craziest use of RL I've ever seen
the craziest use of RL I've ever seen
and in fact in my video I say that I
and in fact in my video I say that I
consider DOTA to be the top result ever
consider DOTA to be the top result ever
in all of RL um but as for like people
in all of RL um but as for like people
who've coded up some crazy
who've coded up some crazy
simulations I think I'm at least in the
simulations I think I'm at least in the
top five there with the stuff that I've
top five there with the stuff that I've
done um the other one I know is craft ax
done um the other one I know is craft ax
is a crazy project
is a crazy project
that's a crazy project um madron is a
that's a crazy project um madron is a
really cool thing it's like a an engine
really cool thing it's like a an engine
for GPU simulation I don't know if I
for GPU simulation I don't know if I
like it generally but it definitely has
like it generally but it definitely has
some really cool
some really cool
uses
uses
yeah and stuff like that
test
puffet simulation of plasma infusion
puffet simulation of plasma infusion
rectors ah yeah that was in my video as
rectors ah yeah that was in my video as
well that one's pretty darn
well that one's pretty darn
cool see that's the type of thing that I
cool see that's the type of thing that I
would love to help out with with puffer
would love to help out with with puffer
right I just like to provide people
right I just like to provide people
infrastructure in order to solve all the
infrastructure in order to solve all the
cool industry problems with RL
hey we do have support contract now
hey we do have support contract now
support packages really more than
contracts that is newly
launched seven arguments were
launched seven arguments were
given okay
what do we need here we need input
what do we need here we need input
weights bias
output batch size input
output batch size input
size hidden
size hidden
size this I
believe must be Matrix got 1 D tensor
believe must be Matrix got 1 D tensor
okay
dot invalid input for size
128 question mark
128 question mark
oh input
oh input
NP bat size
right got one DET
right got one DET
tensor input torch
okay that looks
good Matt 2 must be Matrix got one deter
good Matt 2 must be Matrix got one deter
oh you didn't reshape the
oh you didn't reshape the
weights yeah I forgot about this um I'm
weights yeah I forgot about this um I'm
actually wondering
actually wondering
like can't I just reshape
these can I just do like
these can I just do like
this and then I can make the I can just
this and then I can make the I can just
make this in the shape that I want it
make this in the shape that I want it
it's still contiguous data
it's still contiguous data
right
right
5p and then I don't have to do this view
here probably don't need this float
here probably don't need this float
either we want it already to be in float
either we want it already to be in float
right cannot interpret 128 as data type
right
okay still cannot be multiplied well
okay still cannot be multiplied well
they're the right shapes now at
they're the right shapes now at
least
uh the weights get transp or something
uh the weights get transp or something
don't
they hold on do the weights have to get
transposed ye
all right let's see what's
wrong this
wrong this
looks oh totally
looks oh totally
wrong
whoops yeah there we go
output NP
output NP
output this is
output this is
oops
puffer cool so a certain here output
puffer cool so a certain here output
Puffer
Puffer
and we also need to
and we also need to
know uh because I see some of these
know uh because I see some of these
don't look quite quite
don't look quite quite
correct let's just do this break point
here these are
good um but these are totally
good um but these are totally
different so we'll have to figure out
different so we'll have to figure out
what's going on
what's going on
here because we tested that these are
here because we tested that these are
correct so now we know it's that the
correct so now we know it's that the
test is wrong right we know it's the
test is wrong right we know it's the
test is wrong not the code is
wrong let's see
uh up
uh up
N.H linear layer input
N.H linear layer input
weights bias
weights bias
output bat size input dim output
dimm right
okay well we don't know about the
okay well we don't know about the
weights yet it could be that the weights
weights yet it could be that the weights
need to be transposed right
let's see what the weight dimensions
are oh well it's 128 128
are oh well it's 128 128
obviously still doing doing the DOTA RL
obviously still doing doing the DOTA RL
and C yep in fact we're doing something
and C yep in fact we're doing something
that is going to benefit both that
that is going to benefit both that
project and a ton of others at the
project and a ton of others at the
moment um I'm writing a very small uh in
moment um I'm writing a very small uh in
inference library in C for just all
inference library in C for just all
sorts of different types of neuron Nets
sorts of different types of neuron Nets
that we're going to use uh so we have
that we're going to use uh so we have
comms linear layers lstms and a few
comms linear layers lstms and a few
activations so far uh I'm writing the
activations so far uh I'm writing the
test for those right now and the hope is
test for those right now and the hope is
that what we're going to be able to do
that what we're going to be able to do
is we're going to be able to upgrade our
is we're going to be able to upgrade our
agents on the
agents on the
web so like these guys here we're going
web so like these guys here we're going
to be able to give all of our different
to be able to give all of our different
AIS some like really nice policies and
AIS some like really nice policies and
they're going to run on the web and it's
they're going to run on the web and it's
going to be very easy to play around
going to be very easy to play around
with them it's going to be very easy for
with them it's going to be very easy for
people to like see whether they're good
people to like see whether they're good
like give feedback and stuff um so we're
like give feedback and stuff um so we're
going to just finish all this up right
going to just finish all this up right
now cuz it turned out to not be anywhere
now cuz it turned out to not be anywhere
near as hard as you would have
near as hard as you would have
thought it's basically like a 100 lines
thought it's basically like a 100 lines
of code in C for lstm convolution and
of code in C for lstm convolution and
linear
layer right in the test
layer right in the test
though let's modify this so that we can
though let's modify this so that we can
at least see if we have the shapes right
another cool example are bots in rocket
another cool example are bots in rocket
League yeah I've seen that that's also
League yeah I've seen that that's also
pretty cool
64 by
128 it's
128 it's
backwards this needs to be
transposed I don't know why but
transposed I don't know why but
apparently they do uh transpose
weights cannot call
ATT
ATT
okay output
okay output
puffer output
forch still completely
different still completely different and
different still completely different and
we know that the implementation is
we know that the implementation is
corrected as
well
well
yeah I'm trying to think what else it
yeah I'm trying to think what else it
could
be well hold on why don't we do
this I to see what this looks
this I to see what this looks
like possible that I only have it
like possible that I only have it
correct for square
correct for square
layers I would doubt that but it's
layers I would doubt that but it's
possible
okay
okay
uh tch. matat
mole weights torch input torch
shape 16 by
128 plus
bias
bias
torch what is it torch bias torch
torch what is it torch bias torch
T
TCH three yeah so this is consistent
TCH three yeah so this is consistent
here right with the linear layer their
here right with the linear layer their
linear layer is
consistent with
consistent with
this so this is the
right input weights bias output
okay where else could I have messed this
up is it possible that like by reshaping
up is it possible that like by reshaping
this data it's like not contiguous or
something is there no like do contiguous
reshaping torch is
reshaping torch is
weird it shouldn't be
yeah no so this is still way
off trying to think what it would
be it could be the binding is off hold
on uh puffet
on uh puffet
pix so here we do puffer linear right
pix so here we do puffer linear right
input weight bi output batch size input
input weight bi output batch size input
output
output
input weights bias output bch
input weights bias output bch
size put
size put
output all look good to me
tensor flow over torch is a very weird
tensor flow over torch is a very weird
take generally people like pie torch way
take generally people like pie torch way
more than tensor flow
well to be fair torch torch becomes very
well to be fair torch torch becomes very
bad very quickly once you go into the
bad very quickly once you go into the
internals but at a high level it's very
nice that's it tensor flow is equally
nice that's it tensor flow is equally
horrible with the internals if not worse
horrible with the internals if not worse
so
I'm trying to think what this would
be batch size times input
size input
weights hold on
weights hold on
here no because I
have I did make sure to zero the output
right yeah the output is
zeroed do I need to transpose the
zeroed do I need to transpose the
weights that go into
weights that go into
um do I need to transpose the weights
um do I need to transpose the weights
that go into puffer as
that go into puffer as
well would that do it
that could do it
right using tens ah and I did that way
right using tens ah and I did that way
back in the day and it was not
fun maybe the map Mo I had the thing is
fun maybe the map Mo I had the thing is
I've tested the M
independently so it's possible but I
independently so it's possible but I
would consider it very
unlikely I think it's more likely that
unlikely I think it's more likely that
I'm putting the data in
wrong let's just do hidden size input
wrong let's just do hidden size input
size like this right what if I do this
how big should I expect the outputs from
how big should I expect the outputs from
this thing to
be it's also very concerning here that
be it's also very concerning here that
um a lot of the entries in the puffer
um a lot of the entries in the puffer
output are
output are
zero
right M Mo yeah I did that
right M Mo yeah I did that
already it matches the torch
already it matches the torch
implementation matches
implementation matches
it is definitely an issue with the way
it is definitely an issue with the way
the data is getting loaded but the
the data is getting loaded but the
question is
question is
what the question is like what
what the question is like what
issue I think this is probably closer
because this should be closer though
because this should be closer though
because now I'm not having to transpose
because now I'm not having to transpose
anymore and this should be the order in
anymore and this should be the order in
which the data is written out to disk
which the data is written out to disk
which is how I tested the linear layer
dummy
dummy
inputs input
numpy wait
numai Puffer
let's just do a quick little test to
let's just do a quick little test to
make sure that I'm not totally wrong
make sure that I'm not totally wrong
about the puffer layer being
correct uh one
correct uh one
one 2
two or
be three
four
four
bias I'll
bias I'll
put upper is going to be four and then
put upper is going to be four and then
hidden size is
two upper net hold on let me do one
two upper net hold on let me do one
thing real quick be right back
okay uh
okay uh
is the repo open for contributions yes
is the repo open for contributions yes
it is all uh this is all open source it
it is all uh this is all open source it
is ater
is ater
AI puffer lib right here start the repo
AI puffer lib right here start the repo
on your way in we're almost at a
on your way in we're almost at a
thousand helps us out a lot nice 14 to
thousand helps us out a lot nice 14 to
go
so it's four two and
so it's four two and
two let's see if I'm wrong about this
two let's see if I'm wrong about this
being correct
here ye well that's not
good yeah that makes no sense
it could be an issue with the binding
though could be the pointer is not
though could be the pointer is not
getting passed
getting passed
correctly could it be SC yes it could
be that's what I'm trying to figure
out any issue when data is getting
out any issue when data is getting
converted from numpy to torch well here
converted from numpy to torch well here
right now we're doing numpy only and
right now we're doing numpy only and
it's the data is clearly wrong yeah you
it's the data is clearly wrong yeah you
tested and see and it see yeah exactly
tested and see and it see yeah exactly
so there's something weird about how the
so there's something weird about how the
data is getting passed I
data is getting passed I
think
think
um because if we look
right this data is
reasonable
hidden put output yeah so something is
hidden put output yeah so something is
definitely weird with how the data is
definitely weird with how the data is
getting passed I'm trying to think what
getting passed I'm trying to think what
that would
be the types are all hold on is it could
be the types are all hold on is it could
it is it
this huh
this huh
gotcha
gotcha does anybody want to guess why
gotcha does anybody want to guess why
this happened before I uh I
explain that's evil that is evil
holy was it 16 bit close 16 64
holy was it 16 bit close 16 64
bit wrong bit
Precision God
damn absolutely
evil I damn
evil I damn
yeah I was like what the heck am I dumb
yeah I was like what the heck am I dumb
did I test it wrong no you just put the
did I test it wrong no you just put the
wrong data into
it output
it output
puffer ah now all our data is
populated look at
that I think one e minus 6 is a little
that I think one e minus 6 is a little
bit ambitious
oneus
oneus
four yeah there you
four yeah there you
go so we match to one e minus 4 on the
go so we match to one e minus 4 on the
outputs of a linear
layer that's perfect I'm going to take
layer that's perfect I'm going to take
this out of here just so we don't have
this out of here just so we don't have
it but I'll save this just in case we
it but I'll save this just in case we
need it and down
there so all we do here
there so all we do here
is
is
we we write
the convolution lstm and the activation
the convolution lstm and the activation
tests which should be quite
easy and then we uh we will clean up the
easy and then we uh we will clean up the
puffer net it's 3:25 p.m. so I think we
puffer net it's 3:25 p.m. so I think we
should be able to get all that done
should be able to get all that done
today and probably even get these onto
today and probably even get these onto
the web that might be a little ambitious
the web that might be a little ambitious
but at the least we'll try to start
but at the least we'll try to start
building some real networks today with
this TBH first time I'm enjoying my 400
this TBH first time I'm enjoying my 400
a.m. noodles and coffee
a.m. noodles and coffee
breakfast
breakfast
gez that's
rough I spent many years in college like
rough I spent many years in college like
you know dinner would be like the fourth
you know dinner would be like the fourth
Monster Energy of the day and ramen or
Monster Energy of the day and ramen or
whatever next to the lava lamp and like
whatever next to the lava lamp and like
the super try hard Arch desktop in
college I was like Giga cringe
can
can
you explain why it's not able to assert
you explain why it's not able to assert
1 E minus 6
1 E minus 6
prision
prision
um frankly I don't know
um frankly I don't know
there's probably just a difference in
there's probably just a difference in
the compilation settings like I don't
the compilation settings like I don't
know maybe torch is compiled with like
know maybe torch is compiled with like
fast math or something on we'll have to
fast math or something on we'll have to
mess around with the compilation
mess around with the compilation
settings and see if we can figure out
settings and see if we can figure out
what torch uses because it should really
what torch uses because it should really
be the same like it should literally be
be the same like it should literally be
the same operations but um you know
the same operations but um you know
there are different compilation settings
there are different compilation settings
that could screw with stuff they could
that could screw with stuff they could
be doing some weird things I don't
be doing some weird things I don't
know it's to within one minus 4 in the
know it's to within one minus 4 in the
outputs which is pretty
outputs which is pretty
decent we should look at that though
decent we should look at that though
because yeah technically even if this is
because yeah technically even if this is
like even if ours is correct and theirs
like even if ours is correct and theirs
is correct we do want to match them
is correct we do want to match them
pretty
pretty
closely I also think that we probably
closely I also think that we probably
don't want to have constants hardcoded
don't want to have constants hardcoded
up
up
[Music]
here out of my element here just enough
here out of my element here just enough
to really show
to really show
ah you'd be be surprised how quickly you
ah you'd be be surprised how quickly you
can pick this up um I haven't programmed
can pick this up um I haven't programmed
in C for 10 years I'd only really
in C for 10 years I'd only really
briefly used it in undergrad a little
briefly used it in undergrad a little
bit and I've been doing this for the
bit and I've been doing this for the
last week and a half no not even like
last week and a half no not even like
the last week pretty much
the last week pretty much
so yeah it's not that
hard I mean of course like you got to
hard I mean of course like you got to
keep in mind I've done this type of work
keep in mind I've done this type of work
for the last 10 ear as well so I kind of
for the last 10 ear as well so I kind of
know I know all of the possible errors
know I know all of the possible errors
already so that
helps but hey if you're trying to do
helps but hey if you're trying to do
like some lower level stuff and get into
like some lower level stuff and get into
RL make some cool environments
RL make some cool environments
right we can always use uh we could
right we can always use uh we could
always use some contributions
I've got if I've got to learn something
I've got if I've got to learn something
new either way why scon over
new either way why scon over
Mojo Mojo is a random new language
Mojo Mojo is a random new language
designed by a company that I don't know
designed by a company that I don't know
what's happening to right scon is an
what's happening to right scon is an
extension language that's just an
extension language that's just an
intermediate layer between Python and C
intermediate layer between Python and C
that com that transpiles directly to C
that com that transpiles directly to C
and is also a Gateway for you you know
and is also a Gateway for you you know
going from python to scon 2C directly
going from python to scon 2C directly
it's like a bridge layer anyways so
it's like a bridge layer anyways so
that's
that's
why also some of the stuff that Mojo
why also some of the stuff that Mojo
gives you is just like it has like weird
gives you is just like it has like weird
rust inspiration that's completely
irrelevant I do like they have uh
irrelevant I do like they have uh
they've got like some simd support and
they've got like some simd support and
stuff that's kind of nice but I'm not
stuff that's kind of nice but I'm not
I'm not using some company's random
I'm not using some company's random
language that's like for all I know
language that's like for all I know
company will be bankrupt next year right
okay
uhet so you can see here
uhet so you can see here
like I could have written all of this
like I could have written all of this
code in scon like I could have written
code in scon like I could have written
all the C code in scon here and it would
all the C code in scon here and it would
look almost the same it would just be
look almost the same it would just be
like slightly more python syntax and it
like slightly more python syntax and it
would be just as fast I pushed it one
would be just as fast I pushed it one
layer deeper into C so that I can use it
layer deeper into C so that I can use it
independently and see and compile it for
independently and see and compile it for
web but you see how it's like you're not
web but you see how it's like you're not
even really learning something new with
even really learning something new with
scon it's just like an intermediate
scon it's just like an intermediate
between between two things that you
between between two things that you
should know anyways
okay we have B size input size hidden
size in wi
channels out
channels out
channels Fel
channels Fel
size
ride and let me find where I how I did
ride and let me find where I how I did
this test in see
I believe I have this somewhere uh
I believe I have this somewhere uh
here
here
yeah so now what we're going to do
is python probably uses double loading
is python probably uses double loading
point in its math Cort using 32 no pytor
point in its math Cort using 32 no pytor
should not be using precision and it's
should not be using precision and it's
math P torch is using float 32 I think
math P torch is using float 32 I think
it's compilation
it's compilation
settings I think it's like the thing is
settings I think it's like the thing is
their settings like you can compile with
their settings like you can compile with
like Dash like Dash fast math or
like Dash like Dash fast math or
whatever um yeah I don't know like
whatever um yeah I don't know like
they're probably just some different
they're probably just some different
compilation settings or something there
compilation settings or something there
could be really any number of things it
could be really any number of things it
could be like the order in which you're
could be like the order in which you're
adding the numbers it could literally be
adding the numbers it could literally be
that right like Loop order will matter I
that right like Loop order will matter I
I can also basically guarantee you that
I can also basically guarantee you that
like here the order that you add the
like here the order that you add the
numbers matters um and uh P torch is
numbers matters um and uh P torch is
almost certainly doing like a tiled mat
almost certainly doing like a tiled mat
mole instead of a standard mat mole
mole instead of a standard mat mole
right so that's going to be different
right so that's going to be different
that's going to change the order there
that's going to change the order there
are lots of optimizations here like the
are lots of optimizations here like the
puffer one right now is just a very
puffer one right now is just a very
boring simple C implementation with zero
boring simple C implementation with zero
optimization so far we might end up
optimization so far we might end up
optimizing it a little bit we're not
optimizing it a little bit we're not
going to try to ever make it as fast as
going to try to ever make it as fast as
p torch it's just for like testing an
p torch it's just for like testing an
inference in the web um but yeah that's
inference in the web um but yeah that's
like that gives you a little bit of an
like that gives you a little bit of an
idea not a bad guess though
Waits
oops okay and then we do
oops okay and then we do
input input
input input
torch and now what we do is we see
torch and now what we do is we see
whether this thing actually did
whether this thing actually did
something reasonable because I suspect
something reasonable because I suspect
it
it
didn't usually llm slop that's why I
didn't usually llm slop that's why I
don't auto complete sections that large
usually we forgot to run
it the cool thing about this is we can
it the cool thing about this is we can
also do like a perf test with
also do like a perf test with
this so we can see like how low ours is
this so we can see like how low ours is
compared to torch and we could actually
compared to torch and we could actually
like build this out if we wanted to
okay
so okay we got our weights the same
this actually looks
good maybe we got the output shape
good maybe we got the output shape
wrong
wrong
output for
shape right so the output is totally the
shape right so the output is totally the
wrong
wrong
shape so uh we have to do
there's a
formula yeah this formula right here
so we'll
do uh out
height in height minus
kernel that should be good
watch
uper okay so let's see what's
uper okay so let's see what's
wrong uh well first of all these values
wrong uh well first of all these values
are
massive I think we're going to want to
massive I think we're going to want to
adjust our data function
two
P let me see if we can just get
P let me see if we can just get
ourselves some better condition data
yeah you can't do like
that yeah so this does this does
float let's do like
this okay so that's actually works
now we just had to get our data to be
now we just had to get our data to be
better conditioned so floating Point
better conditioned so floating Point
Precision right is most accurate um with
Precision right is most accurate um with
like small values around zero so when we
like small values around zero so when we
have massive numbers because like the
have massive numbers because like the
coms keep accumulating more data right
coms keep accumulating more data right
so we were getting numbers in the
so we were getting numbers in the
thousands like you're not going to be
thousands like you're not going to be
able to have 1 E minus 4 when they're
able to have 1 E minus 4 when they're
like thousands you get like four
like thousands you get like four
significant figures not
significant figures not
0.0011 worth of accuracy you get four
0.0011 worth of accuracy you get four
significant figures
maybe python standard
float but this shouldn't be python
float but this shouldn't be python
standard float
standard float
because this is p torch and the P torch
because this is p torch and the P torch
is calling into
is calling into
C++ right which is then calling into qnn
C++ right which is then calling into qnn
or you know whatever the CPU
or you know whatever the CPU
implementation is so there's kind of a
implementation is so there's kind of a
big stack
there hence why I said it's like
there hence why I said it's like
potentially more complicated right
tab tab tab
tab tab tab
tab so the reason I'm tabbing all this
tab so the reason I'm tabbing all this
is because I actually have the same test
is because I actually have the same test
down here already so just should need to
down here already so just should need to
refactor a little as
well we'll see if it if it instantly
well we'll see if it if it instantly
works but I doubt
works but I doubt
it maybe super maven's goated
yep there you go
issue how often do you stream usually
issue how often do you stream usually
Monday through
Monday through
Friday sometimes I'm doing other stuff
Friday sometimes I'm doing other stuff
like yesterday I had a co-working thing
like yesterday I had a co-working thing
so uh I was only on for a short stream
so uh I was only on for a short stream
in the evening but I'm usually just like
in the evening but I'm usually just like
streaming my work you know when I'm
streaming my work you know when I'm
working except Saturday I take off to
working except Saturday I take off to
just do solo Dev all day um like
just do solo Dev all day um like
Saturday for instance last Saturday I
Saturday for instance last Saturday I
ported the entire MOA to see in like
ported the entire MOA to see in like
just8 hours of just frantic coding um at
just8 hours of just frantic coding um at
least the initial pass of it so like
least the initial pass of it so like
stuff like that occasionally I'll just
stuff like that occasionally I'll just
do off
do off
stream but I stream most of my work
I also ped I don't think that's correct
I also ped I don't think that's correct
it's I don't think it's 32 decimal
it's I don't think it's 32 decimal
digits of precision it's Python's 15
digits of precision it's Python's 15
decimal digits maybe is like the best it
decimal digits maybe is like the best it
could represent but you don't get all
could represent but you don't get all
the values there and then for C it's 32
the values there and then for C it's 32
bits which should be the same possibly
bits which should be the same possibly
there's some difference but I would
there's some difference but I would
doubt
it uper
N.H okay
lstm input
[Music]
[Music]
weights what happened
here weights
here weights
input how did they even mess it up this
input how did they even mess it up this
bad like I literally have the correct
bad like I literally have the correct
code down here don't
I yeah you need State what the hell is
I yeah you need State what the hell is
it
doing oops in here
right input
right input
State
State
h
h
p and then we have weights input
p and then we have weights input
wait State bias input bias
wait State bias input bias
State uh we also
State uh we also
need buffer
numpy need a
buffer which is this
buffer which is this
size and then you need uh bad size input
size and then you need uh bad size input
size hidden size okay so and then the
size hidden size okay so and then the
signature here is
signature here is
input uh
input uh
State
State
H State C
numpy then we have weight
State weight input weight State bias
State weight input weight State bias
input by state
input by state
buffer
buffer unfortunately uh funny story I
buffer unfortunately uh funny story I
was I tried to get the ppie package
was I tried to get the ppie package
named puffer and I couldn't because
named puffer and I couldn't because
there's a python buffer that somebody
there's a python buffer that somebody
named
puffer if anybody wants to get me that
puffer if anybody wants to get me that
package name but I think that's actually
package name but I think that's actually
something that gets used
I still mess this
up I think I counted wrong
up I think I counted wrong
right or maybe The Binding is wrong
what's the origin of the name almost get
what's the origin of the name almost get
killed by a
killed by a
puffer no man puffers are friendly it's
puffer no man puffers are friendly it's
literally as simple as just like hey uh
literally as simple as just like hey uh
I'm writing like infrastructure in
I'm writing like infrastructure in
middleware I have no visual depiction of
middleware I have no visual depiction of
my work for you whatsoever so screw it
my work for you whatsoever so screw it
we're going to have a fun mascot here
we're going to have a fun mascot here
have a puffer fish it's very memeable
like look at this guy he's very memeable
like look at this guy he's very memeable
right up
there I don't know more companies should
there I don't know more companies should
have mascots they're
funny
yeah he's
yeah he's
nice I mean puffer fish are not going to
nice I mean puffer fish are not going to
kill you either unless you try to eat
kill you either unless you try to eat
them like they're not like they're not
them like they're not like they're not
going to poison you if you it like by
going to poison you if you it like by
biting you it's just if you try to eat
them though so though the bigger ones
them though so though the bigger ones
will take your finger off if you wave it
will take your finger off if you wave it
too close to
them but if you piss me off I'll do that
them but if you piss me off I'll do that
too
take you out will take your finger
off well was so will
Li
buffer you don't need this output puffer
buffer you don't need this output puffer
variable
variable
that's what it
was
yeah now we do actually have to make a
yeah now we do actually have to make a
little change here though
because puffer will mess with the data
so we have to do state H torch State
so we have to do state H torch State
C
C
bias and
bias and
then what we do
then what we do
here this output torch
here this output torch
um State H torch state see
um State H torch state see
torch okay and
then GL drop
then GL drop
by be back in Future thanks for dropping
by be back in Future thanks for dropping
by cheers
come
come
on not enough values to unpack
Vape
error let's see what's
wrong Ah that's weird
wrong Ah that's weird
right that's real
weird so close to having this done the
weird so close to having this done the
activation functions are going to be
activation functions are going to be
super easy to test and then we'll
super easy to test and then we'll
basically be able to just refactor
basically be able to just refactor
however we want very nicely we can perf
however we want very nicely we can perf
optimize whatever we can build some
optimize whatever we can build some
networks we can put it on the web we can
networks we can put it on the web we can
literally do everything once we have
literally do everything once we have
this
test and I like the way that I did this
test and I like the way that I did this
as well where like I manually tested in
as well where like I manually tested in
order to make sure that it was correct
order to make sure that it was correct
right like I just did a bunch of
right like I just did a bunch of
interactive testing and then I wrote the
interactive testing and then I wrote the
formal test in order to allow me to
formal test in order to allow me to
refactor the known good code and the
refactor the known good code and the
reason I did that is because just like a
reason I did that is because just like a
test like this wouldn't even help me um
test like this wouldn't even help me um
before I had it correct because I need
before I had it correct because I need
to check like at every stage of the
to check like at every stage of the
operations right just having like binary
operations right just having like binary
yes no isn't correct isn't helpful from
this at least not
earlier so why do the H State like this
I think it's because you need to have
I think it's because you need to have
this like extra obnoxious layer variable
this like extra obnoxious layer variable
right well first of all this needs
State
State
view one bad size Hidden size.
view one bad size Hidden size.
View this maybe
is it
obnoxious for unbathed
input how did I test this before
one batch
one batch
size minus
one state one batch size minus one
okay SE
okay SE
Arrow
Arrow
H
H those look the same to me
those look the same to
me
me
TCH ah you got to strip the
um yeah got do
this well
this well
then oh well then
oh
hum that feels
good puffer net. C
definitely cleaner than comparing to
definitely cleaner than comparing to
files yeah that was kind of a dumb idea
files yeah that was kind of a dumb idea
but to be fair like it does mean that I
but to be fair like it does mean that I
have to have this annoying scyon binding
have to have this annoying scyon binding
which isn't bad I
which isn't bad I
guess I don't know I'm really surprised
guess I don't know I'm really surprised
that nobody's done this like why the
that nobody's done this like why the
hell doesn't this already
hell doesn't this already
exist like it's not that crazy of a
exist like it's not that crazy of a
project right to just like write a
project right to just like write a
little neuronet library and see and then
little neuronet library and see and then
like add some python
like add some python
bindings not that
hard and
testu what we
testu what we
think uh this is an in place
oops we think
assertion
assertion
error
error
really oh
really I'll put
really I'll put
puffer ah because
puffer ah because
it's for
there we
go now we
go now we
do uh test copper net sigmoid I think
do uh test copper net sigmoid I think
this is the last
this is the last
one probably literally will auto
one probably literally will auto
complete for us because it's like this
complete for us because it's like this
code is very
Samy and that is crazy that it's still
what takes one
what takes one
argument
argument
oh uh
oh uh
okay yeah I forgot that I did this as a
uh
huh
well input no
I did this for a single element so I
I did this for a single element so I
want to just have uh a nice test like
want to just have uh a nice test like
this
really oh
-
-
four by
four by
this okay there we
this okay there we
go here are all of our
go here are all of our
tests
tests
uh so now we can get rid of the rest of
uh so now we can get rid of the rest of
this stuff
this stuff
right now we can get rid of the rest of
right now we can get rid of the rest of
this still need an Epsilon tolerance
this still need an Epsilon tolerance
yeah
you fixed now my comments have
latency
latency
H it's
good I tend to
good I tend to
um I tend to like program very
um I tend to like program very
reactively so like I won't bother to
reactively so like I won't bother to
like think in order to prevent a bunch
like think in order to prevent a bunch
of bugs what I'll do is I'll just get my
of bugs what I'll do is I'll just get my
Dev Loop to be really really fast and
Dev Loop to be really really fast and
then it'll be like see a bug think about
then it'll be like see a bug think about
bug fix bug see a bug think about bug
bug fix bug see a bug think about bug
fix bug instead of like trying to fix
fix bug instead of like trying to fix
five bugs at the same time or trying to
five bugs at the same time or trying to
anticipate
anticipate
stuff I don't know maybe that just makes
stuff I don't know maybe that just makes
me really brain dead but it's very
me really brain dead but it's very
effective
and now you guys can have this in Dev as
and now you guys can have this in Dev as
well I'm going to use the restroom real
well I'm going to use the restroom real
quick and uh then I'm going to be back
quick and uh then I'm going to be back
in a couple minutes and what we will get
in a couple minutes and what we will get
to do is we'll actually get to take
to do is we'll actually get to take
these things we're going to refactor the
these things we're going to refactor the
Capi just a little bit and then we're
Capi just a little bit and then we're
going to start putting together some
going to start putting together some
actual real like good neuronet
actual real like good neuronet
architectures and uh trying to load
architectures and uh trying to load
pre-trained models into them like we're
pre-trained models into them like we're
going to have like com uh MLP lstm type
going to have like com uh MLP lstm type
architectures and then that'll let us
architectures and then that'll let us
like have that run on web so I'll be
like have that run on web so I'll be
right back and then we'll get doing
that
e e
okay
presenting puffer net.
presenting puffer net.
C this is so cool that this was like
C this is so cool that this was like
this quick to build
I think what we're going to do now is
I think what we're going to do now is
we'll just go
into I'm me grab one other thing real
into I'm me grab one other thing real
quick and then I have an idea well I
quick and then I have an idea well I
know what we're going to do
so I don't want to introduce too much
so I don't want to introduce too much
overhead into this stuff right like I
overhead into this stuff right like I
don't know if I want to have like a
don't know if I want to have like a
general tensor class or anything like
that I don't think I want to get that
that I don't think I want to get that
much I don't want to get into it that
much I don't want to get into it that
much
much
but you know potentially just having
H I'm trying to think if I want strs for
H I'm trying to think if I want strs for
the layers
actually let me think about that
well we can definitely remove this
well we can definitely remove this
linear layer accumulate if I'm a little
clever it's stuff like this H out this W
clever it's stuff like this H out this W
out right like technically I could do
out right like technically I could do
like struct com
like struct com
2D and you would initialize it with like
2D and you would initialize it with like
batch size in width and height you'd
batch size in width and height you'd
initialize it with all this stuff right
initialize it with all this stuff right
and then the com channel would be the
and then the com channel would be the
com layer would be easier
maybe do I like that
well yeah I think I do because otherwise
well yeah I think I do because otherwise
when I'm building
when I'm building
networks I need to
networks I need to
have the pointers to
have the pointers to
everything which brand is this committed
everything which brand is this committed
I'll show you right I'll link it to you
I'll show you right I'll link it to you
remember to Star the
remember to Star the
puffer helps out a
puffer helps out a
ton I'll link you the
ton I'll link you the
file so the test is just in the the base
file so the test is just in the the base
right here and then it's in puffer lib
right here and then it's in puffer lib
environments
environments
it's going to get moved into like you
it's going to get moved into like you
know a more General thing um but for now
know a more General thing um but for now
it's in it's in
it's in it's in
here MOA where is it puffer net
dot huh where is
dot huh where is
this it should be in
here puffer
here puffer
net. I I committed it
right okay there it
is I don't really understand why you
is I don't really understand why you
need these relatively small operations
need these relatively small operations
to implement an RL mod
to implement an RL mod
on the de where do these math layers or
on the de where do these math layers or
steps
steps
reside in a full so because I don't need
reside in a full so because I don't need
to train on the web right I just need to
to train on the web right I just need to
like load I have all of puffer lib for
like load I have all of puffer lib for
training right all I need is I need to
training right all I need is I need to
be able to load the weights of a p torch
be able to load the weights of a p torch
model into a c model that behaves
model into a c model that behaves
exactly the same way and then I can run
exactly the same way and then I can run
that on the web that's all I need and uh
that on the web that's all I need and uh
you can see like let me give you an
you can see like let me give you an
example so this snake game
example so this snake game
here this is RL agents running in your
here this is RL agents running in your
browser um but this is just like if you
browser um but this is just like if you
saw I already had like an MLP
saw I already had like an MLP
implemented I already had the linear
implemented I already had the linear
layer implemented so I can only make
layer implemented so I can only make
these like an MLP which is not a really
these like an MLP which is not a really
great architecture so by adding the lstm
great architecture so by adding the lstm
and the com layers I can Implement way
and the com layers I can Implement way
stronger models which are going to be
stronger models which are going to be
needed for honestly even the snakes
needed for honestly even the snakes
would be better with that but uh Ely for
would be better with that but uh Ely for
the
the
Moa
yeah yeah there's no reason to train on
yeah yeah there's no reason to train on
the web right that's just
dumb I mean you could kind of do an
dumb I mean you could kind of do an
interactive thing if you really wanted
interactive thing if you really wanted
to but
like way more effort than it's
worth this is not that bad right like
worth this is not that bad right like
look at this this is frankly and we're
look at this this is frankly and we're
going to get rid of this main as well so
going to get rid of this main as well so
130 lines of code we're going to
130 lines of code we're going to
actually there a few other things we can
actually there a few other things we can
clean up this will end up being a total
clean up this will end up being a total
of like 150
Max I think that that's a
win I think that's a huge win
okay so let's
do type
do type
death
struct do I want to type death struck
struct do I want to type death struck
hold
on typ
obstruct I think you
obstruct I think you
do struct
linear then you do type
linear then you do type
death is it no it's type
death is it no it's type
def linear and then you need to
def linear and then you need to
do there's like a weird um scon thing I
do there's like a weird um scon thing I
think we have to do it this
way
linear and then when you do your linear
linear and then when you do your linear
layer right now you have weights bias
layer right now you have weights bias
input dim output
input dim output
dim
um you still need to know your batch
um you still need to know your batch
size
do I want to have a tensor
class or tensor struct I
class or tensor struct I
mean I'm trying to think how silly I
mean I'm trying to think how silly I
want this to
be okay this is important
be okay this is important
so I have to patch B pass batch size
explicitly if
um if I just pass a tenser
then the tensor will have all the
then the tensor will have all the
dimensions I need
right it's so funny how you see like
right it's so funny how you see like
basically as soon as you go to introduce
basically as soon as you go to introduce
any amount of abstraction you just
any amount of abstraction you just
realize that there's a cost immediately
right well this is RA this at least this
right well this is RA this at least this
is very free so let's do this first and
is very free so let's do this first and
let's see if I like
let's see if I like
it this is this is like pretty easy for
it this is this is like pretty easy for
me
me
to uh to stomach here CU now all I need
to uh to stomach here CU now all I need
to do
to do
is linear layer of uh struct where is it
linear uh
layer near layer load
layer near layer load
input and then you don't need any of
this all you need is the B
and then this is a
and then this is a
linear star
linear star
layer
layer
linear input dim like
this or you can just do int input dim is
this or you can just do int input dim is
in layer input dim
in layer input dim
then in output
G
Waits is this better though
doing this way you should always be able
doing this way you should always be able
to create a tensor wrapping in
to create a tensor wrapping in
future without having to do all of your
future without having to do all of your
flattening work at the
moment well yeah no I'm fine like I
moment well yeah no I'm fine like I
don't have to redo any of the crazy work
don't have to redo any of the crazy work
it's just a question of what I want the
it's just a question of what I want the
code to look like so
code to look like so
like every time you roduce a piece of
like every time you roduce a piece of
abstraction it's never free there's a
abstraction it's never free there's a
cost right so like I can add this linear
cost right so like I can add this linear
layer operation or this linear layer
layer operation or this linear layer
struct here and if I do that then I get
struct here and if I do that then I get
to have the weights and the input dims
to have the weights and the input dims
taken care of so I don't have to keep
taken care of so I don't have to keep
around wherever I'm calling this I don't
around wherever I'm calling this I don't
have to have a ton of different
have to have a ton of different
variables to represent you know to make
variables to represent you know to make
sure I know where the weights and stuff
sure I know where the weights and stuff
are for this um but the cost is now I
are for this um but the cost is now I
have to you know get these variables
have to you know get these variables
from the struct and now now I have you
from the struct and now now I have you
know these pointer opts here cluttering
know these pointer opts here cluttering
the code where it's not quite as easy as
before and I mean you can go really
before and I mean you can go really
crazy with this right like I could
crazy with this right like I could
decide that the weights are a tensor the
decide that the weights are a tensor the
bias is a tensor like it's done in in a
bias is a tensor like it's done in in a
p torch and then the input is a tensor
p torch and then the input is a tensor
so now everything's a freaking tensor
so now everything's a freaking tensor
and now like this thing is suddenly
and now like this thing is suddenly
going to blow up and be 30 lines of code
going to blow up and be 30 lines of code
for a linear layer
so let me think about that
[Music]
well here's another
well here's another
question do I actually need the batch
question do I actually need the batch
size to
size to
be no I do want the the bat size to be
be no I do want the the bat size to be
part of it otherwise I end up with a
part of it otherwise I end up with a
whole bunch of additional
functions welcome
functions welcome
making a few decisions about how I want
making a few decisions about how I want
this to
this to
look so essentially let me let me just
look so essentially let me let me just
like walk through my uh my reasoning
like walk through my uh my reasoning
process right now so I have this very
process right now so I have this very
very nice and simple uh pure C library
very nice and simple uh pure C library
right it's got conf flayers it has lstms
right it's got conf flayers it has lstms
it's got all this stuff but if you look
it's got all this stuff but if you look
at the function
at the function
signatures you have to pass everything
signatures you have to pass everything
to these
to these
functions so like when I go to implement
functions so like when I go to implement
an actual neuronet right
an actual neuronet right
think about how I would have to do that
think about how I would have to do that
right now I'd have to make like a giant
right now I'd have to make like a giant
struct that's going to contain like you
struct that's going to contain like you
know linear layer one in like linear
know linear layer one in like linear
layer one weight linear Layer Two bias
layer one weight linear Layer Two bias
no C layer one uh weight conve layer one
no C layer one uh weight conve layer one
bias
bias
whereas if I introduce some layer types
whereas if I introduce some layer types
at the very
at the very
least
least
then all I have to do is allocate these
then all I have to do is allocate these
in the um
in the um
I all I have to do is allocate like a
I all I have to do is allocate like a
much smaller number of
much smaller number of
layers is it hard to Crate and see nope
layers is it hard to Crate and see nope
not at all this was actually very
not at all this was actually very
comfortable this was a total of like two
comfortable this was a total of like two
days of
work and I have not written C in 10
years you've been lied to C is very
years you've been lied to C is very
comfortable and very
easy frankly stuff like this figuring
easy frankly stuff like this figuring
stuff like this out annoys me a lot more
stuff like this out annoys me a lot more
than just writing basic
than just writing basic
functions um the design portion is the
functions um the design portion is the
obnoxious bit cuz you're always wrong no
obnoxious bit cuz you're always wrong no
matter what you do you're always wrong
oh wait I think I've got a genius
idea hold
on y guys I think I figured it
out you always hated a year later is it
out you always hated a year later is it
scyon no this is C we also have scyon
scyon no this is C we also have scyon
around and for contributors to puffer Li
around and for contributors to puffer Li
your perfectly welcome to write stuff in
your perfectly welcome to write stuff in
scon it'll be just as fast the reason
scon it'll be just as fast the reason
I'm doing this in purec is because this
I'm doing this in purec is because this
is going to run on the
is going to run on the
web that's why I'm writing this right
web that's why I'm writing this right
now is um I'm going to put this on the
now is um I'm going to put this on the
web and you're going to be able to play
web and you're going to be able to play
games with and against reinforcement
games with and against reinforcement
learned agents that are just running in
learned agents that are just running in
pure C which is pretty cool so here's
pure C which is pretty cool so here's
what I want to do I think that we're
what I want to do I think that we're
going to be a little smarter about this
going to be a little smarter about this
so
we keep the struct okay and we'll we'll
we keep the struct okay and we'll we'll
rename this stuff in a bit but like what
rename this stuff in a bit but like what
about
about
void
void
uh let's say like linear layer from
uh let's say like linear layer from
struct and then we
struct and then we
[Music]
[Music]
do into batch
do into batch
size and then what we do
size and then what we do
we autoc complete
that what do we think about something
that what do we think about something
like
that so we keep our very nice C
that so we keep our very nice C
functions right but then in order to
functions right but then in order to
maintain all the data that we need for
maintain all the data that we need for
the layers we have a struct and then we
the layers we have a struct and then we
have something that calls the method on
have something that calls the method on
this with the
struct what do we think about this
and then if I inlined this it would be
and then if I inlined this it would be
the exact same code so there wouldn't
the exact same code so there wouldn't
even be any
overhead I think it's
nice I still don't like the batch size
it will Ava be
it will Ava be
available on your YouTube well I'm
available on your YouTube well I'm
streaming like the streams are available
streaming like the streams are available
on YouTube the vods are all on my
on YouTube the vods are all on my
YouTube they're like I don't know
YouTube they're like I don't know
probably a 100 plus hours of vods on my
probably a 100 plus hours of vods on my
YouTube at this point occasionally they
YouTube at this point occasionally they
get broken up by Internet outages but if
get broken up by Internet outages but if
you just like click through them you'll
you just like click through them you'll
see all of them there um the code is
see all of them there um the code is
free the free it's free and open open
free the free it's free and open open
source like here you can play around
source like here you can play around
with it right here and I'm updating it
with it right here and I'm updating it
Live Well frequently not directly
live but yeah this is all stuff that
live but yeah this is all stuff that
we've built today and
yesterday what do we think about
this the batch size is a little awkward
this the batch size is a little awkward
isn't it
so technically I could remove the batch
so technically I could remove the batch
size portion from this and I could do
size portion from this and I could do
the batch size as an external Loop but I
the batch size as an external Loop but I
don't know if I want to do that I think
don't know if I want to do that I think
that their
optimizations
optimizations
yeah I don't think I want to do
that let me just really
that let me just really
quick because I forget let me just
jippy there any common
optimizations for cons that's uh
optimizations for cons that's uh
involve pushing
involve pushing
specifically the
specifically the
batch
batch
Loop batch
Loop batch
size from the
outermost inner
yeah that's what I
thought so I think we want to keep the
thought so I think we want to keep the
batch size Loop here because there are
batch size Loop here because there are
optimizations we might want to do that
optimizations we might want to do that
will involve pushing this Loop into the
middle how optimized does this have to
middle how optimized does this have to
be for now it doesn't have to be very
be for now it doesn't have to be very
optimized at all but like I don't want
optimized at all but like I don't want
to do stuff specifically that's going to
to do stuff specifically that's going to
our ability to make improvements to
our ability to make improvements to
it
right so like if I were to take this
right so like if I were to take this
batch Loop out of this function then I
batch Loop out of this function then I
wouldn't be able to push it like right
wouldn't be able to push it like right
now I can just move this down lower
now I can just move this down lower
right and the code will still
right and the code will still
work and that can improve cash locality
work and that can improve cash locality
and
and
such depending on how we optimize
uh this batch size parameter is going to
uh this batch size parameter is going to
bother
me I guess the only reason that this bad
me I guess the only reason that this bad
size parameter is here right is because
size parameter is here right is because
we don't have an input
tensor I'm having the output tensor be
separate in
fact in fact
fact in fact
um I could make the output part of the
um I could make the output part of the
linear layer
right that wouldn't be
right that wouldn't be
bad can you explain functions for one
bad can you explain functions for one
minute yeah so I'm implementing
minute yeah so I'm implementing
here this is a linear layer this is like
here this is a linear layer this is like
your like nn. linear and P torch I've
your like nn. linear and P torch I've
got re and sigmoids I've got a
got re and sigmoids I've got a
convolution layer I've got long
convolution layer I've got long
short-term memory I've got common neural
short-term memory I've got common neural
net layers here except that they're
net layers here except that they're
implemented in pure
implemented in pure
c um I have a test for these that
c um I have a test for these that
ensures that these functions
ensures that these functions
exactly match the pytorch
exactly match the pytorch
implementations so if you run the in
implementations so if you run the in
pytorch if you write like nn. linear L
pytorch if you write like nn. linear L
nn.com whatever they work exactly the
nn.com whatever they work exactly the
same way as my functions do which means
same way as my functions do which means
that I can load the weights from a
that I can load the weights from a
pytorch model into this and I can
pytorch model into this and I can
replicate the functionality exactly um
replicate the functionality exactly um
now all I'm
now all I'm
doing is I'm trying to clean this up a
doing is I'm trying to clean this up a
little bit because uh we're going to
little bit because uh we're going to
have to use this to build some actual
have to use this to build some actual
neural Nets and like right now you see
neural Nets and like right now you see
how many args these fun fun take right
how many args these fun fun take right
like I have tons of different pointers
like I have tons of different pointers
to different weights and things that
to different weights and things that
I'll have to keep
around but you can see how simple this
around but you can see how simple this
is like okay like don't even look at the
is like okay like don't even look at the
stuff at the bottom that's
stuff at the bottom that's
outdated that's a load function so 130
outdated that's a load function so 130
lines of
lines of
code for basically all the stuff that
code for basically all the stuff that
you will need for lots of different
you will need for lots of different
types of neuron
types of neuron
Nets 30 lines of C it'll probably be 150
Nets 30 lines of C it'll probably be 150
lines once I add some strs but still
uh
I guess the one other thing that would
I guess the one other thing that would
be really nice is
um
um
well no it really doesn't help us to
well no it really doesn't help us to
have like a tensor class at all does it
have like a tensor class at all does it
tensor class literally just gives us bat
size can anybody else see like an easy
size can anybody else see like an easy
way to like have batch size be somewhere
way to like have batch size be somewhere
like linear layer shouldn't take B size
like linear layer shouldn't take B size
right input shouldn't take batch
size you'd have to make a tensor class
size you'd have to make a tensor class
is what I think or tensor struct I mean
and like is there really a point of
and like is there really a point of
doing
that I think that's too much
abstraction I don't mind this linear
abstraction I don't mind this linear
layer because it just lets us group some
layer because it just lets us group some
data together
data together
together and like realistically right
together and like realistically right
when we implement this the the names are
when we implement this the the names are
going to be like
going to be like
this it's going to be like underscore
this it's going to be like underscore
linear and then this will just be like
linear and then this will just be like
linear
right something like
right something like
this layer
so that's not
so that's not
bad I think we don't overthink
bad I think we don't overthink
it I think that we uh we do it this way
it I think that we uh we do it this way
and I think this is pretty
good uh we'll be able to delete this
good uh we'll be able to delete this
linear layer accumulate in a moment
linear layer accumulate in a moment
you'll
see is nice as is think you may be
see is nice as is think you may be
worrying too
worrying too
much yeah I think this is good I I was
much yeah I think this is good I I was
just not sure if like I wanted to add a
just not sure if like I wanted to add a
tensor
tensor
struct I think it's good I think I'm
struct I think it's good I think I'm
happy with
happy with
this
so I'm off UK have good coding thank
so I'm off UK have good coding thank
you I mean the one thing is like if we
you I mean the one thing is like if we
had a tensor size right like stuff like
had a tensor size right like stuff like
this
this
we would be able to um have the size
we would be able to um have the size
peram come from
there that's kind of awkward isn't
it the alternative thing that we could
it the alternative thing that we could
do
do
here okay here's another thing we could
here okay here's another thing we could
do
do
right do we really need this thing to
right do we really need this thing to
work for different batch
sizes we don't need this to work for
sizes we don't need this to work for
different batch sizes
right what if we just made the batch
right what if we just made the batch
size part of the layer right when you
size part of the layer right when you
create the
create the
layer um the layer has a specific batch
layer um the layer has a specific batch
size and then everything should be good
everything should be good right
I'm trying to think if that's smarter
I'm trying to think if that's smarter
that's dumb
sometimes I like thinking about these
sometimes I like thinking about these
like design things but sometimes I hate
like design things but sometimes I hate
it cuz like no matter what you do you're
it cuz like no matter what you do you're
almost always going to be dumb
right what would it look like if we made
right what would it look like if we made
batch size a part of
batch size a part of
this well the linear layer wouldn't have
this well the linear layer wouldn't have
a bat size foram which would be cool it
a bat size foram which would be cool it
wouldn't need an output foram because
wouldn't need an output foram because
we'd be able to just have it be part
we'd be able to just have it be part
part of
part of
linear
linear
right we could have like a nice
right we could have like a nice
allocator for
allocator for
linear um we could have like an a make
linear um we could have like an a make
linear or whatever that is going to
linear or whatever that is going to
allocate us our output data
but things start to get very complicated
but things start to get very complicated
very quickly like I can look I can see
very quickly like I can look I can see
down that
down that
path but the thing is if we don't do
path but the thing is if we don't do
this then it's going to be very
this then it's going to be very
complicated for us to actually Implement
complicated for us to actually Implement
any cool neuron Nets because we're going
any cool neuron Nets because we're going
to have to keep around tons of
to have to keep around tons of
different weight pointers and
things but maybe that's okay maybe I'm
things but maybe that's okay maybe I'm
stuck on the pie torch design right I
stuck on the pie torch design right I
don't
know it does actually seem kind of
know it does actually seem kind of
obnoxious to have
um batch size be limited like the layer
um batch size be limited like the layer
to have to know the batch size
h
I'm trying to think how I can avoid
I'm trying to think how I can avoid
staring at this forever because this is
staring at this forever because this is
going to get very boring very quickly if
going to get very boring very quickly if
I just have to stare at this forever
I just have to stare at this forever
right
like it's tough
like it's tough
because I don't want to have like a
because I don't want to have like a
bunch of dynamic memory floating
bunch of dynamic memory floating
around I like having the output buffers
around I like having the output buffers
where it's
where it's
static technically I probably won't need
static technically I probably won't need
to have um batch size be
to have um batch size be
variable I might but probably
variable I might but probably
not it is just very gross to have the
not it is just very gross to have the
batch size be part of the layer
though okay let me think about let's
though okay let me think about let's
okay so here's what let me give you my
okay so here's what let me give you my
thoughts
thoughts
right I can leave it as this with no
right I can leave it as this with no
structs nothing and then what'll happen
structs nothing and then what'll happen
is when I have to implement like you
is when I have to implement like you
know CNN lstm MLP for the MOBA game or
know CNN lstm MLP for the MOBA game or
whatever it's going to be like 100 lines
whatever it's going to be like 100 lines
of allocations because I'm going to have
of allocations because I'm going to have
to take all the different weight
to take all the different weight
variables and stuff and I'm going to
variables and stuff and I'm going to
have to keep them around and I'm going
have to keep them around and I'm going
to have to manually make sure I'm
to have to manually make sure I'm
calling you know each layer with the
calling you know each layer with the
appropriate
appropriate
weights
right and then there's also if I'm going
right and then there's also if I'm going
to read stuff from a file right if I'm
to read stuff from a file right if I'm
going to like read from a file it's
going to like read from a file it's
going to be very difficult as well for
going to be very difficult as well for
me
me
to it's going to be very difficult for
to it's going to be very difficult for
me to like write a
function it's tough to visualize what
function it's tough to visualize what
the code is going to look like
the code is going to look like
right okay so the main thing let me
right okay so the main thing let me
think about it this way the main thing I
think about it this way the main thing I
need to do is I need to read a model in
need to do is I need to read a model in
from a file
from a file
right
right
so we have a function that does that
so we have a function that does that
it's right
here this gives you your weights
here this gives you your weights
technically I could just return uh I can
technically I could just return uh I can
just return right here I can return
this and then your architecture
it's going to have to tell you the
it's going to have to tell you the
number of btes or something
yeah you're definitely going to need
yeah you're definitely going to need
something to tell you the number of
something to tell you the number of
bites regardless that you need to be
bites regardless that you need to be
reading
so I'm going to just start coding on
so I'm going to just start coding on
something here and we're going to see if
something here and we're going to see if
it's stupid right and you guys can tell
it's stupid right and you guys can tell
me if I'm over complicating it but I'm
me if I'm over complicating it but I'm
going to just like the dumbest simplest
going to just like the dumbest simplest
thing I can think to do at the moment
thing I can think to do at the moment
with my very limited capabil ities
here just add
here just add
output and add batch size all
output and add batch size all
right we keep linear as
is underscore linear at least and then
is underscore linear at least and then
linear here takes a layer and it takes
linear here takes a layer and it takes
an input it doesn't need to take
an input it doesn't need to take
anything
else then this becomes layer output and
else then this becomes layer output and
this becomes layer batch size so you
this becomes layer batch size so you
have this very nice nice function
have this very nice nice function
signature that is what this buys you
signature that is what this buys you
okay this linear layer accumulation is
okay this linear layer accumulation is
going to go away in a second and then
going to go away in a second and then
we're going to do do I make one for reu
we're going to do do I make one for reu
I think I do make one for reu so we do
I think I do make one for reu so we do
struct type def struct re struct
struct type def struct re struct
re in
re in
data uh what is it float star data or
data uh what is it float star data or
float star
no
output in batch
output in batch
size in input
dim okay and then this is now underscore
relu this becomes data
input load star output
input load star output
in
size
right I less than side and then this
right I less than side and then this
becomes
becomes
output of I equal to F Max input of I
output of I equal to F Max input of I
okay and now we do void reu which takes
okay and now we do void reu which takes
a reu layer in an
a reu layer in an
input and now it looks like this very
input and now it looks like this very
clean thing right you take the input you
clean thing right you take the input you
take layer output you have batch size
take layer output you have batch size
and then you have input size and the
and then you have input size and the
only thing that we need is this needs to
only thing that we need is this needs to
be underscore reu not reu layer dummy
and uh layer B size times layer input
dim sigmoid is just an activation this
dim sigmoid is just an activation this
does not need a layer this is just
does not need a layer this is just
defined for a single
defined for a single
float this is not a layer yet since we
float this is not a layer yet since we
don't actually use a a sigmoid layer
don't actually use a a sigmoid layer
anywhere
and then this is going to
and then this is going to
beore com
2D let's make
our we'll decide how we want to
our we'll decide how we want to
structure these in a moment
structure these in a moment
type def stru com
type def stru com
2D it's going to have Lo output batch
2D it's going to have Lo output batch
size in kernel yeah there you
go then we
go then we
do void uh com 2D which is now just
do void uh com 2D which is now just
takes this and it's just going to call
function and then we have type Def
function and then we have type Def
struct and it's literally so brain dead
struct and it's literally so brain dead
that this can just be autoc
that this can just be autoc
completed right it just takes all of our
completed right it just takes all of our
data this is now underscore
data this is now underscore
lstm and then we do void
lstm and then we do void
lstm like
lstm like
this
this
okay and I think I want to group all
okay and I think I want to group all
this a little
differently cuz I think I want
differently cuz I think I want
the I think I want like this at the
top re
linear bmid
um
um
2D because this is really the the
2D because this is really the the
portion of the code that's
portion of the code that's
actually you know
matters and then I put the API at the
bottom okay so as I promised
bottom okay so as I promised
right literally this is 100 lines of
right literally this is 100 lines of
code not even 100 lines of code and then
code not even 100 lines of code and then
for The
for The
Binding
so internal uh layers
we'll like do that and then down here
we'll like do that and then down here
we
do user
do user
API
um provided to help
um provided to help
organize
layers I don't know something like that
layers I don't know something like that
right
and then do I want all the strs or all
and then do I want all the strs or all
of
of
the
impulse I think I like it like
impulse I think I like it like
this which like struct implementation
this which like struct implementation
struct implementation I think this is
struct implementation I think this is
good this is very easy to edit like
this so we added by doing this right
this so we added by doing this right
we add 100 no we add 80 lines of
code to have this
wrapper actually less because this thing
wrapper actually less because this thing
is going to go away in a second I'll put
is going to go away in a second I'll put
it up here for now but this is going to
it up here for now but this is going to
go away in a second so we add like
go away in a second so we add like
probably what's that uh 70 lines for
probably what's that uh 70 lines for
this user
this user
API and I think it's worth that
yeah and then we have load weights and
yeah and then we have load weights and
we have this main
we have this main
function like this which we can now get
function like this which we can now get
rid of this main this no longer is
rid of this main this no longer is
needed
oh and we can also do uh linear
oh and we can also do uh linear
accumulate
accumulate
right we can also add a linear
right we can also add a linear
accumulate
here void linear
here void linear
accumulate
wait is this actually valid hold on
I was thinking here that uh we could
I was thinking here that uh we could
just zero the
just zero the
memory but that's not actually efficient
memory but that's not actually efficient
is
it yeah that's not actually efficient
it yeah that's not actually efficient
damn it
well that sucks we'll just do linear
well that sucks we'll just do linear
accumulate like
this and then we'll uh we'll put this
this and then we'll uh we'll put this
down to
here until I figure out a better
here until I figure out a better
way to handle
it so maybe we'll find a better way of
it so maybe we'll find a better way of
doing that but for now yeah not bad
doing that but for now yeah not bad
so 200 Total
so 200 Total
Lines uh and then what we're going to do
Lines uh and then what we're going to do
is we
is we
will we'll have this like load weights
will we'll have this like load weights
thing we'll have a few other things and
thing we'll have a few other things and
that'll be
that'll be
good let me use a restroom real quick
good let me use a restroom real quick
and we'll then we'll test this we'll
and we'll then we'll test this we'll
make sure I didn't break stuff and we'll
make sure I didn't break stuff and we'll
implement the actual uh the actual CNN
implement the actual uh the actual CNN
lstm layers like CNN lstm uh networks
lstm layers like CNN lstm uh networks
right
right
back
e e
okay it occurred to me that we also have
okay it occurred to me that we also have
to make allocators and destru for these
right let me just look something
up I want to see if there's a style
up I want to see if there's a style
thing on
this
for for
not actually sure that this answer is
correct because now that I'm thinking
correct because now that I'm thinking
about
this we'll go with this for now I
this we'll go with this for now I
actually don't know if this is correct
actually don't know if this is correct
but
have you tried perplexity it can give
have you tried perplexity it can give
you
you
sources there not really any sources on
sources there not really any sources on
that though
right it's like the actual thing that
right it's like the actual thing that
llms are intended for which is a general
llms are intended for which is a general
amalgamation of
amalgamation of
Knowledge from a bajillion different
things so this is what uh this is what I
things so this is what uh this is what I
was thinking for the make right
calic
calic
it and then output is going to
be this
so this gives you your
sizes and then you do void free linear
sizes and then you do void free linear
and then this is linear
and then this is linear
star
star what we think about
star what we think about
that allocate you your memory
do make reu and then this is like
do make reu and then this is like
actually brain dead
actually brain dead
code right here this is very
easy um what is it
easy um what is it
comp 2D make comp
comp 2D make comp
2D just going to give you all this
garbage to
day yeah and the reason we can actually
day yeah and the reason we can actually
tab this is hopefully just like this is
tab this is hopefully just like this is
actually brain dead if you're looking at
actually brain dead if you're looking at
it right the only thing I'm not sure
it right the only thing I'm not sure
about here is if we want all these
about here is if we want all these
different calics instead of just like
different calics instead of just like
one big block of
memory but we that's an optimization we
memory but we that's an optimization we
could look at
later I mean that actually gives you a
later I mean that actually gives you a
pretty substantial
pretty substantial
API ask what is puffer
API ask what is puffer
lib I mean is it going to do anything
lib I mean is it going to do anything
other than just going to the site and
other than just going to the site and
then giving me this for
this is actually pretty good I will
say that's actually pretty
good I might consider using that
right so here are all the layers right
actually give you sources yeah that's
actually give you sources yeah that's
important that's fair I mean I could see
important that's fair I mean I could see
that replacing like traditional search
that replacing like traditional search
engines just because the traditional
engines just because the traditional
search engines have become so garbage
search engines have become so garbage
with all the
ads I'd always always always rather pay
ads I'd always always always rather pay
a subscription fee and just not have
a subscription fee and just not have
ads everywhere always
okay so MOBA doc
okay so MOBA doc
here uh this has a bunch of stuff we no
here uh this has a bunch of stuff we no
longer
longer
need this is now in
need this is now in
puffer
right yeah but we need some of this hold
on yeah we don't need
on yeah we don't need
this we don't need any of this
we don't need this so this was the Moa
we don't need this so this was the Moa
demo that we had from before
demo that we had from before
right let's make sure that this thing
right let's make sure that this thing
still
works okay now we
works okay now we
include puffer
include puffer
net. and we go fix some puffet errors
type death struct linear
that syntax has always been weird to
me I don't even know if this is fully
me I don't even know if this is fully
required to be fair I think I was just
required to be fair I think I was just
doing this because the scon layers are
doing this because the scon layers are
like weird about
like weird about
bindings might be able to clean that up
no member named
awaits well that's
awaits well that's
dumb
output start bias
output start bias
output weights by that's so weird that
output weights by that's so weird that
it didn't add that
in yeah so that actually builds
now and uh now what we get to do is we
now and uh now what we get to do is we
get to init some puffer net stuff
get to init some puffer net stuff
right uh so let us
just that. h
go down to our user
API uh we need a few different Windows
API uh we need a few different Windows
here don't
here don't
we anything how I'm going to do
this I think we'll just grab the
browser torch
we're going to try to implement this
we're going to try to implement this
network
network
now is not a trivial Network to be
now is not a trivial Network to be
fair so we're going to have to do this
fair so we're going to have to do this
piece by piece
let's do
let's do
type
struck open
struck open
that openet
that openet
Moet we're going to
do com
do com
2D star com
2D star com
one um
one um
2D two we'll do
2D two we'll do
reu
one linear St
one linear St
flat linear star
flat linear star
[Music]
FR and
FR and
then what is it linear
linear star
linear star
actor L linear star value
function all
right interesting
see what it gives us
here layer
here layer
init we don't care about the init
init we don't care about the init
functions here we just have to get the
functions here we just have to get the
dimensions right
um one is going to
um one is going to
be in
it see
so this is going to be numb
agents uh in width is going to be
agents uh in width is going to be
11 and height is 11 in
11 and height is 11 in
channels it's going to be 19 out
channels it's going to be 19 out
channels is 32 kernel size and stride
channels is 32 kernel size and stride
this is now
this is now
correct right and while we're here let's
correct right and while we're here let's
do comp 2 which is num
do comp 2 which is num
agents uh 32
no wait in width in height
no wait in width in height
still uh we have to compute this
still uh we have to compute this
ourselves don't
we I believe this was
we I believe this was
3x3 yeah I'm pretty sure this is
3x3 channels
3x3 channels
32 32
32 32
one and then
flat it's going to be batch size num
flat it's going to be batch size num
agents
agents
oh I don't know why it does
oh I don't know why it does
this agents and
this agents and
then
then
32 and then we have the
32 and then we have the
projection which is 64 it looks like
32 oh hidden size
s then
s then
actor is going to be hidden size which
actor is going to be hidden size which
is
28 we need numb agents
28 and then uh I believe this is
28 and then uh I believe this is
six no sum of self. action
six no sum of self. action
Dimension we'll need to find that
so 14 17 19 21 23 it looks like we'll be
so 14 17 19 21 23 it looks like we'll be
able to verify all this stuff so it's
able to verify all this stuff so it's
not going to be that
bad
bad
agents value function is
agents value function is
one so there are a few obnoxious things
one so there are a few obnoxious things
here right like uh needing to know the
here right like uh needing to know the
con input size and stuff like
con input size and stuff like
that versus Computing
that versus Computing
it it's not that bad
it it's not that bad
though yeah that's what you would need
though yeah that's what you would need
like a tensor class
for so if we wanted that we would need
for so if we wanted that we would need
like a tensor
struct it's not that bad as
struct it's not that bad as
this do we have multiple reers
there's an additional couple of re here
there's an additional couple of re here
at the bottom it looks
at the bottom it looks
like and there's one
like and there's one
hot quite a bit of encoding
hot quite a bit of encoding
actually we still have to get
actually we still have to get
right I mean it's a substantial
project but at least this gives us our
project but at least this gives us our
Network
now we'll have to load the weights in
now we'll have to load the weights in
which will be a
pain one thing we could do is we could
pain one thing we could do is we could
make like um
we could make it have like a file
we could make it have like a file
pointer of some
type so like when you load in a file
type so like when you load in a file
right you give the file to the init
function something like
that kind of complicated honestly
well we need the Ford
function uh sure we can have the
function uh sure we can have the
free and then
forward value
forward value
function this is not
yeah so this is not
yeah so this is not
remotely uh what we need
here
layer oh yeah this is fine because we
layer oh yeah this is fine because we
get the output of the previous layers
get the output of the previous layers
like this
like this
right so this is fine actually and then
right so this is fine actually and then
the only things we needed are uh
the only things we needed are uh
there're like a few different operations
there're like a few different operations
Maybe
that we didn't think
about in the
Moet let's see what it
Moet let's see what it
is I mean the big ones here are um
one hotting the data like
this there's a little bit of
this there's a little bit of
pre-processing which is no big deal
these concatenates
like this is fine this portion here is
fine but these concatenates are
fine but these concatenates are
obnoxious
I mean not really I can Implement a
I mean not really I can Implement a
concatenate
concatenate
function let me just think about this
function let me just think about this
network architecture if there's a better
network architecture if there's a better
way of doing this stuff
um
I mean I guess you just have to I just
I mean I guess you just have to I just
have to implement one hot and concat
right flatten I actually don't need to
right flatten I actually don't need to
do anything I don't
do anything I don't
think yeah flatten is it's like the data
think yeah flatten is it's like the data
is already flat so I don't need to do
is already flat so I don't need to do
that but I do need to implement
that but I do need to implement
one hot and conat I
believe I mean that's not
terrible and then what'll this look
like it actually won't look that much
like it actually won't look that much
more complicated than the python if I do
more complicated than the python if I do
that right
yeah what about this do
permute I'll just not implement it in
permute I'll just not implement it in
the way that you need the permute right
yeah do Prem is
silly time is it
silly time is it
5:18 I think I can probably implement
5:18 I think I can probably implement
these
these
two and have like something of a network
two and have like something of a network
working in the next couple hours if I
working in the next couple hours if I
buckle down and do it
it's a little
it's a little
tricky let me make sure I'm not missing
tricky let me make sure I'm not missing
anything start
split what about the action selection
split what about the action selection
mechanism it's just a Max isn't
it yeah they'll have to be something for
it yeah they'll have to be something for
multi- discreet selection though
though I mean it is it's literally
though I mean it is it's literally
puffer Doh is what it is it's just I
puffer Doh is what it is it's just I
need like more stuff in there it's not a
need like more stuff in there it's not a
huge deal I just have to implement a few
huge deal I just have to implement a few
more things than I thought I
more things than I thought I
would and there's not really any way
would and there's not really any way
around it right like you kind of just
around it right like you kind of just
need all these
Ops this will be a really sweet demo
Ops this will be a really sweet demo
though if you think about it right like
though if you think about it right like
being able to run a net of this
being able to run a net of this
complexity in your
complexity in your
browser that's pretty
sweet so let's uh let's start on that
1: a.m. stepping out see you around
1: a.m. stepping out see you around
thanks for dropping
by I want to make sure I understand how
by I want to make sure I understand how
how the one hot works
how the one hot works
in
Python great to have the background
Python great to have the background
while working thank you
put like
put like
um the breako right here
all right we had that issue
right we should probably fix that
what the
heck oh yeah we're going to have some
heck oh yeah we're going to have some
issues
here I'm trying to think what the
here I'm trying to think what the
easiest thing for me to do to fix some
easiest thing for me to do to fix some
stuff here
stuff here
is I think for now I'll just write a
is I think for now I'll just write a
quick quick
test
batch do
batch do
like 5 three three
like this
e
533 dude why do I not know the API for
533 dude why do I not know the API for
this
this
uh low high size okay what did he
uh low high size okay what did he
do
f. one hot
a
10 okay so it puts it at the very
10 okay so it puts it at the very
end whereas you want it on the second
end whereas you want it on the second
axis
axis
right always always on the second
right always always on the second
axis so that's
axis so that's
fine yeah we can we can work with that
input output batch
size uh input
size uh input
size size in input
size size in input
size in number classes
size in number classes
right batch size input size
yes oh man the memory is going to be
yes oh man the memory is going to be
tricky
tricky
here but I think I can do it
going be batch
going be batch
times now this is bad
right bad
times input s
batch times input
batch times input
size Plus
what was the first one num
what was the first one num
classes
no the memory addresses for these are so
tricky let's skip batch elements and
tricky let's skip batch elements and
then you have
plus I
plus I
time what is it input size times num
time what is it input size times num
classes I
believe wait batch times input size
believe wait batch times input size
times numb
times numb
classes
classes
plus I * num classes
plus
input what's the input
input what's the input
address there's also the input address
address there's also the input address
to handle
right which has to be
right which has to be
not * num classes batch time input size
not * num classes batch time input size
plus is it just
I I think it is just
I I think it is just
I plus I like this and then I * gome
I plus I like this and then I * gome
[Music]
[Music]
classes this is plus
classes this is plus
input yeah in Adder so this was correct
okay and then you set the output address
okay and then you set the output address
to
one that should be one
hot
hot
void concat
that them
one one
two what
size
one I can just do X and Y right
in y
size is this
correct let's see what it says
here e
well this code doesn't make any sense
right it's batch time X size plus
right it's batch time X size plus
I right
yeah this wrote to nutty
yeah this wrote to nutty
code
code
um the X address is just going to be
um the X address is just going to be
batch time X size plus
batch time X size plus
I and then out
I and then out
address not batch time X size plus
I
I
right it's batch
right it's batch
times X size plus y size plus
I and then
I and then
here y address is going to be batch time
here y address is going to be batch time
y size plus X size plus
y size plus X size plus
I and then the out
I and then the out
address is going to be B
address is going to be B
* B * X size
* B * X size
plus y
plus y
size oh wait wait wait hold on
size oh wait wait wait hold on
no no no no no no batch time y size plus
no no no no no no batch time y size plus
I is good batch time X size plus y
size now this is where you get plus X
size now this is where you get plus X
size plus I so it was almost correct
I think that's
right so the way that you look at this
right so the way that you look at this
right you go through the batch and you
right you go through the batch and you
have these two separate tensors so you
have these two separate tensors so you
go through the first row you grab all
go through the first row you grab all
the X Elements which are B * x i plus I
the X Elements which are B * x i plus I
and then you put them
and then you put them
into this is the row offset of your
into this is the row offset of your
output tensor
uh plus I so you put them into the first
uh plus I so you put them into the first
Slots of that tensor and then here for
Slots of that tensor and then here for
the next one the address index into Y is
the next one the address index into Y is
going to be the same but then in the
going to be the same but then in the
output you also have to add the X offset
output you also have to add the X offset
because it slides over to the
because it slides over to the
right that should be
right and then we also need um
didn't we need like a Max or
something I believe there was a Max
something I believe there was a Max
operation that we used for snake
there's a Max operation right yeah right
there's a Max operation right yeah right
here
and this will be Lo
and this will be Lo
star
input bat
size what is it in load star
in
in
Star
output looat no int bat
output looat no int bat
size
int input
size for match size
index yeah this actually is this auto
index yeah this actually is this auto
complete was good because I have
complete was good because I have
basically the same logic down here that
basically the same logic down here that
I had already
I had already
written um you get the first logic right
written um you get the first logic right
Max index is
Max index is
zero if it's
zero if it's
bigger yeah this just duplicated my
bigger yeah this just duplicated my
exact same logic here
and then output of B is equal to
Maxx
Maxx
yes but now the thing is if you do it
yes but now the thing is if you do it
this way hold
this way hold
on this is not going to work this way
right because you need to have this is
right because you need to have this is
going to be for multi- discreet as well
yeah this is going to be from multi topr
yeah this is going to be from multi topr
this is
this is
bad um
this is actually trickier to implement
this is actually trickier to implement
than I thought let me think
so the problem here that you can have a
so the problem here that you can have a
variable number of action uh of actions
variable number of action uh of actions
types that you
want I mean I know how to do it I'm just
want I mean I know how to do it I'm just
trying to think if there's a simpler way
we'll do it like
we'll do it like
this into batch size
uh is this how you do it for a
uh is this how you do it for a
list something like
list something like
this
in
inputs so four batch like this and then
inputs so four batch like this and then
what we do is
or yeah like this
this is one of these cases I think where
this is one of these cases I think where
we want to have a
we want to have a
uh an index that just keeps accumulating
right we'll see
logic sizes
yeah so loged
address there's no way to get the logit
address there's no way to get the logit
address without just doing index because
address without just doing index because
you have a variable number of size so
you have a variable number of size so
logit
address
address
put in address
and then the output address that we can
and then the output address that we can
do the output
do the output
address batch size times num
address batch size times num
actions
plus
I now plus
yeah this it just wrote garbage code
yeah this it just wrote garbage code
this doesn't make sense here because you
this doesn't make sense here because you
have to go
over so this needs to be I less num
over so this needs to be I less num
actions
i++ num actions plus I this is the
i++ num actions plus I this is the
output
output
address and now what we do is float Max
address and now what we do is float Max
logit is going to be the input of the in
logit is going to be the input of the in
address
here this should be a I
guess and
I okay we'll let this tab complete and
I okay we'll let this tab complete and
then we'll fix
so I actually like this implementation
so I actually like this implementation
because it doesn't end up with anything
because it doesn't end up with anything
super
super
janky um you go over the batch you go
janky um you go over the batch you go
over the number of different types of
over the number of different types of
actions
actions
here your out address is going to be
here your out address is going to be
equal to the batch size times the number
equal to the batch size times the number
of
actions no not bat size times number of
actions no not bat size times number of
actions B times number of actions
actions B times number of actions
plus a
plus a
yes and then your logic
yes and then your logic
here is going to
be input of in
address okay
I can just do in Adder
Plus+ no
in add plus I this is
good Max logic it's overwritten
good Max logic it's overwritten
here and then the output of output
here and then the output of output
address gets set to
address gets set to
I and then you get add the logic size
a so
in Num action
types then this is num action
types something like this we'll have to
types something like this we'll have to
validate all of this
stuff but that's not bad for a a quick
stuff but that's not bad for a a quick
draft of three functions right one hot
draft of three functions right one hot
cat and dim one and argmax on multi-
discreete uh we'll have to make layers
discreete uh we'll have to make layers
for these as well
for these as well
right we don't want to allocate yeah the
memory these will tab complete though
memory these will tab complete though
these are super brain
these are super brain
dead not MLP hi mate can I know what
dead not MLP hi mate can I know what
you're doing yeah so I've got this P
you're doing yeah so I've got this P
torch net here it's fairly sophisticated
torch net here it's fairly sophisticated
it has linear layers it has concats it
it has linear layers it has concats it
has one hot it has CNN's it has an lstm
has one hot it has CNN's it has an lstm
in it has a bunch of stuff and I'm
in it has a bunch of stuff and I'm
currently porting all of this stuff to
currently porting all of this stuff to
work directly in C in like a little 350
work directly in C in like a little 350
line file whatever this ends up
line file whatever this ends up
being so so that I can compile this to
being so so that I can compile this to
web assembly and run it
online that is what we are currently
doing now I might have underestimated
doing now I might have underestimated
the complexity of this project just a
the complexity of this project just a
little bit but uh at this point we're
little bit but uh at this point we're
mostly done
mostly done
so it's not that bad
I mean really the only thing I
I mean really the only thing I
underestimated was I forgot that I would
underestimated was I forgot that I would
have to add like these last three
have to add like these last three
operations in
operations in
here but we'll test these no
worries let's just do type
depu one hot one
hot yeah that's this is this is dumb
hot yeah that's this is this is dumb
easy we can just tab complete this it'll
easy we can just tab complete this it'll
probably be
right I don't know why this
is new and
is new and
CS
CS
senior advise something can be
senior advise something can be
helpful I it depends on where you're
helpful I it depends on where you're
coming
coming
from and what you're trying to do
I can't just give like anything General
I can't just give like anything General
that'll just help everyone in all
that'll just help everyone in all
situations right
yeah I'm we'll see if these Auto
yeah I'm we'll see if these Auto
completes are
completes are
correct but okay 418 lines now we ended
correct but okay 418 lines now we ended
up with a
lot like if you're brand new brand
lot like if you're brand new brand
new um you're going to need to like
new um you're going to need to like
there are some Basics like basic data
there are some Basics like basic data
structures and algorithms you will need
structures and algorithms you will need
to know they're not going toach how to
to know they're not going toach how to
build stuff but it will prevent you from
build stuff but it will prevent you from
doing a lot of dumb
doing a lot of dumb
things
things
um I mean experience just building stuff
um I mean experience just building stuff
is very important um I would advise you
is very important um I would advise you
to
to
not try to build like try to build stuff
not try to build like try to build stuff
not around gigantic Frameworks and tools
not around gigantic Frameworks and tools
that are like doing a lot of stuff like
that are like doing a lot of stuff like
try to like actually learn to build
try to like actually learn to build
stuff try not to just learn a specific
stuff try not to just learn a specific
framework I would say
okay we're going to have to
but yeah if you give me some context I
but yeah if you give me some context I
can maybe give you something more
useful ceret
here I think we just make the test for
here I think we just make the test for
this
this
already DS and what is a DS is that a
already DS and what is a DS is that a
bachelor's or um
where should we
where should we
connect you're free to chat here I just
connect you're free to chat here I just
what is a
DS oh working on data structures in C
DS oh working on data structures in C
okay sure yeah that's fine that's that's
okay sure yeah that's fine that's that's
what I learned that's how I learned as
what I learned that's how I learned as
well
well
um from there let's
see I mean from there you can pretty
see I mean from there you can pretty
much already just start building stuff
much already just start building stuff
um you know try building some like
um you know try building some like
simple projects like building most of
simple projects like building most of
this stuff yourself without using super
this stuff yourself without using super
heavy Frameworks for things it's a good
heavy Frameworks for things it's a good
way to
way to
learn I will recommend to you I mean
learn I will recommend to you I mean
like building simple games and things
like building simple games and things
are a great is a great way to learn I'll
are a great is a great way to learn I'll
recommend do you something I've been
recommend do you something I've been
enjoying a lot
lately this is a really nice library for
lately this is a really nice library for
graphics it's very
graphics it's very
lowlevel um but it just makes it very
lowlevel um but it just makes it very
easy to like it's fun to work on stuff
easy to like it's fun to work on stuff
that you can actually see um but this
that you can actually see um but this
will let you do you know a lot of like
will let you do you know a lot of like
heavy St and logic stuff right like I
heavy St and logic stuff right like I
have I've got like little demos that
have I've got like little demos that
I've built with this where I have like
I've built with this where I have like
pathfinding for instance where to like
pathfinding for instance where to like
you know you can just can I run it
you know you can just can I run it
actually real
actually real
quick I don't know if I have it compiled
quick I don't know if I have it compiled
anywhere
here uh let me see
here let me see if this
works
WS I think this maybe works yeah cool so
WS I think this maybe works yeah cool so
here's like a little thing that I built
here's like a little thing that I built
like this is a type of thing that you
like this is a type of thing that you
could totally build um as somebody
could totally build um as somebody
relative new to CS to get some
relative new to CS to get some
experience with stuff like I built this
experience with stuff like I built this
cool Pathfinder
cool Pathfinder
where you know wherever I'm pressed
where you know wherever I'm pressed
wherever I have the mouse here it's
wherever I have the mouse here it's
doing pathf finding to my current
location and you know it's a nice little
location and you know it's a nice little
visual demo so you can very easily tell
visual demo so you can very easily tell
if it's correct or not because you can
if it's correct or not because you can
see exactly how everything is
see exactly how everything is
pointing it involves a little bit of you
pointing it involves a little bit of you
know a little bit of algorithm stuff
know a little bit of algorithm stuff
little bit of UI
a little bit of design in there
a little bit of design in there
right things like this are fun and these
right things like this are fun and these
are a good way to learn no this took me
are a good way to learn no this took me
like a
day but yeah that's like the level of
day but yeah that's like the level of
stuff I would recommend
6:30 good luck man good luck
we want to add some test
we want to add some test
here so let's
do grette one
do grette one
hot batch size num
hot batch size num
classes we need input
classes we need input
size uh we also if I recall we changed a
size uh we also if I recall we changed a
lot lot of stuff didn't we Social
lot lot of stuff didn't we Social
account yeah I've got a Twitter
account yeah I've got a Twitter
Twitter's the main
thing why do I have a million
thing why do I have a million
notifications blowing
up for
the hell is
this now ignore
this now ignore
Twitter gotta get stuff done
what the heck is
what the heck is
this mixing C and python okay hold on
this mixing C and python okay hold on
here I need to I forgot I needed to fix
here I need to I forgot I needed to fix
a few things here um
a few things here um
because I need to
test actually shoot I need to expose a
test actually shoot I need to expose a
lot of stuff don't
I well technically I could still test it
I well technically I could still test it
this way for now yeah I think I'm
this way for now yeah I think I'm
actually fine here we'll do it like this
actually fine here we'll do it like this
so test puffer at one
hot input size BS
uh what is this
uh what is this
128 num classes
equal this then we'll do input it's
equal this then we'll do input it's
going to
going to
be make dummy
be make dummy
data for one
hun
hun
okay now we need to write The Binding
okay we need to add these B mins
here
here
okay go grab the Prototype from
here where it
go for
uh I forgot the hold
uh I forgot the hold
on losing a little steam here but we'll
on losing a little steam here but we'll
finish this today at least I hope we'll
finish this today at least I hope we'll
be able to test like these functions
be able to test like these functions
today
okay so we have these guys like
okay so we have these guys like
this uh we also need to
this uh we also need to
[Music]
[Music]
expose no wait
that underscore linear like
that underscore linear like
this yeah we want the
underscores linear like this
so we're just exposing the functional
so we're just exposing the functional
API for testing for now I might regret
API for testing for now I might regret
that we'll
that we'll
see
but
okay now we need to put these things up
okay now we need to put these things up
here
okay so now we
okay so now we
have all of our various
have all of our various
different function prototypes or
different function prototypes or
[Music]
whatever one
whatever one
hot now this should get it right we'll
hot now this should get it right we'll
see if it does we can let this auto
see if it does we can let this auto
complete don't need this
sure cool
sure cool
um we actually have to get this thing to
um we actually have to get this thing to
compile now
canot
canot
[Music]
convert cannot convert float star to
convert cannot convert float star to
python object
what
oh okay we actually didn't make very
oh okay we actually didn't make very
many errors
what is
what is
this puff argmax oh puff
this puff argmax oh puff
argmax into logic
sizes oh it just totally got the API
sizes oh it just totally got the API
wrong didn't it
wait
no wait multi discreete oh okay it's
no wait multi discreete oh okay it's
down here int logit
sizes yeah you can't do this this has to
sizes yeah you can't do this this has to
be like list logic sizes or something
be like list logic sizes or something
right
oh no you know what we can
oh no you know what we can
do c np. ND array loget sizes that'll do
do c np. ND array loget sizes that'll do
it and we'll do instar loget sizes like
it and we'll do instar loget sizes like
this okay so now we have all of the data
this okay so now we have all of the data
types exposed
types exposed
from C to
from C to
python apparently this
python apparently this
disagrees not be cast to pointers
beta okay I guess there are some errors
beta okay I guess there are some errors
in Puffer net.
this is supposed to be
a
flexible not at end of
struct fa you're allowed to do this I
struct fa you're allowed to do this I
remember
now invalid use
of do this for
invalid use of flexible array member
size of the entire structure is
size of the entire structure is
[Music]
unknown okay I didn't think I was doing
unknown okay I didn't think I was doing
that though right
M I know what we're going to do this is
M I know what we're going to do this is
obnoxious we're just going to
obnoxious we're just going to
[Music]
[Music]
do we're just going to do this
assignment to
expression do I just mem copy
it yeah that seems to work
work. what's wrong
work. what's wrong
here argument is of
type argument is of type
int po
int po
maybe I'm just using it
wrong
no in
no in
function passing
function passing
argument makes pointer from integer
argument makes pointer from integer
without a cast
what is
underscore H underscore relu oh you need
underscore H underscore relu oh you need
the output I forgot I made it not in
the output I forgot I made it not in
place
ND array
ND array
output
size back to two got three
do I have to adjust this Proto yeah I
do I have to adjust this Proto yeah I
have to adjust
have to adjust
this
output
input implicit Declaration of sigmoid
we'll look at that in a
second undefined s symbol Sig
okay float
sigmoid float X
let me
let me
um hold
on if I just do
this return type defaults to int
Lo implicit decim definition of oh you
Lo implicit decim definition of oh you
just forgot to rename
just forgot to rename
it yeah we can leave it exactly as is I
it yeah we can leave it exactly as is I
just forgot to rename
just forgot to rename
it and then buffer
it and then buffer
sigmoid is underscore sigmoid andore
sigmoid compile no
warnings now we have to edit
warnings now we have to edit
[Music]
[Music]
puff I can just pass it the same uh the
puff I can just pass it the same uh the
same exact buffer
and it
works
works
cool so we got this updated for the new
cool so we got this updated for the new
API stuff I'm going to use a restro real
API stuff I'm going to use a restro real
quick we're going to write the tests for
quick we're going to write the tests for
um the new three functions and then I
um the new three functions and then I
mean if we get that done today I'll be
mean if we get that done today I'll be
happy
happy
because that will let us be able to
because that will let us be able to
write the full Network so we'll be right
back
for
e e
all right last few functions for the
all right last few functions for the
day it's actually only 6:15 I do have an
day it's actually only 6:15 I do have an
extra um good hour and half at least so
extra um good hour and half at least so
you should definitely be able to get
you should definitely be able to get
this done
[Music]
testet
one B size
F
F
size
size
X size equal 32 y size
64 x
64 x
NP okay we have the outputs we do
NP okay we have the outputs we do
cat by output batch size X size
perfect and then output torch we assert
perfect and then output torch we assert
near
point one and then argmax multi-
point one and then argmax multi-
discrete is going to be a little
harder
test bat
size uh log it siid
is
is
equal
equal
five uh
72 okay
okay make some of this some of logic
okay make some of this some of logic
[Music]
sizes what is going to be lared
sizes that's
good logic sizes
good logic sizes
the. array of logic
the. array of logic
[Music]
[Music]
sizes
sizes
sum n
actions length of logit
sizes okay and then what we do is
sizes okay and then what we do is
output output
output output
puffer batch size num actions and when
puffer batch size num actions and when
we argmax into it with that size logic
we argmax into it with that size logic
sizes um
sizes um
actions input
actions input
torch uh this argmax here does not
torch uh this argmax here does not
actually
work so then we have
um yeah there's not like a good thing
um yeah there's not like a good thing
for this
right I think we have to do
action
action
slices for.
splits for. stack of argmax and then we
output putut torch
torch
out
bre and then we add these to the tests
bre and then we add these to the tests
test buer one
test buer one
hot Captain one and we will just to make
hot Captain one and we will just to make
these tests a little faster comment this
these tests a little faster comment this
out while we're testing
python only applicable to index
AB uh okay fair fair play um
make
make
dummy make
dummy make
dummy int
data 10 Yep this is
fine me in
fine me in
data logic
data logic
sizes oops this is not the function that
sizes oops this is not the function that
I needed right
make
dummy in
dummy in
data num
data num
classes
classes
oops be like this num
classes
classes
classes
zero
classes yeah class
perfect only applicable to index tenser
huh okay so it looks like it's seg fting
huh okay so it looks like it's seg fting
here right
right yeah okay so our actual
right yeah okay so our actual
implementation like
cool
cool
shape
shape
inut
shape input
shape input
the wol in
the wol in
32 let's see what we're doing here
upet
pix float
pix float
[Music]
[Music]
star well this is not float this needs
star well this is not float this needs
to
to
be inar input right these are
be inar input right these are
ins and then one
ins and then one
hot that's the
problem and then I assume that I did the
problem and then I assume that I did the
same thing in here some
somehow yeah this is instar
somehow yeah this is instar
input inar output right and then we have
input inar output right and then we have
INT in address int out address
perfect okay what happened
perfect okay what happened
here Buffet
here Buffet
s yeah okay so we forgot this needs to
s yeah okay so we forgot this needs to
be in Star
be in Star
input and yeah that's
it
it
[Music]
passing output all right so this output
passing output all right so this output
needs to be size of int and then output
needs to be size of int and then output
here needs to be in Star we're going use
here needs to be in Star we're going use
in instead of Longs here
okay that
compiles
compiles
that's we still
SE yeah so we're still like fating
here see oops that doesn't
work test
[Music]
okay let's just go grab the uh the
okay let's just go grab the uh the
API and figure out where we're seg
API and figure out where we're seg
puling right
batch size 16 input
batch size 16 input
size um glasses going to be
size um glasses going to be
four we'll do
four we'll do
make one hot layer it's going to be make
make one hot layer it's going to be make
one
one
hot we'll do three one
hot we'll do three one
hot
hot
zero then we'll do one hot layer
zero then we'll do one hot layer
input then it will'll
do in Star input is going to be C
Al classes
W and uh what do we do
we'll just do
like
upet
upet
[Music]
play O test
T
T
Test dot see and I should not need any
Test dot see and I should not need any
of this
stuff okay H.H
stuff okay H.H
wrong goes
here and now I get real stuff so we have
to include standard I all this crap
we need string for mem copy I always
we need string for mem copy I always
forget about that okay so T's puffer
forget about that okay so T's puffer
net this actually runs
that's puffer net still seg
that's puffer net still seg
faults why does it seg
fault I do not know let's
see well wait a second does it even
see well wait a second does it even
Segal in the same spot let's just make
Segal in the same spot let's just make
sure of that
sure of that
it does still say b um on the one hun
it does still say b um on the one hun
okay so yeah I had this break point
okay so yeah I had this break point
there
there
anyways no this is a cat break point
anyways no this is a cat break point
what okay yeah yeah so T faults here um
what okay yeah yeah so T faults here um
takes
takes
input right then takes output
well this is
wrong this is
input input size num classes
right okay we don't get the segf anymore
right okay we don't get the segf anymore
right we just get an
right we just get an
error for
I do this wrong
okay this needs to be longed or
whatever somewhat
obnoxious
long
in insertion
in insertion
error point
max
out D type
float in 32
look at
look at
that we got
that we got
it okay we have our whoops we have our
it okay we have our whoops we have our
one hot
one hot
function that's a one hot function
it's a one hot to
function uh does this cat dim one just
work I think it
work I think it
does I I'm sure we'll find some bugs
does I I'm sure we'll find some bugs
later but
ah nope it doesn't
ah nope it doesn't
okay I was going to say that would have
okay I was going to say that would have
been too good to be uh
possible torch shape
put uh okay so it did something weird
put uh okay so it did something weird
did something real
weird neither of these make any bloody
weird neither of these make any bloody
sense
sense
right oh no wait wait this one is just
working
yeah this is just m equal
one p.
one p.
shape
shape
P output
puffer okay we still have assertion
puffer okay we still have assertion
error output
offer for
offer for
completely different
right
input put up
input put up
zero output for Z so we said that this
zero output for Z so we said that this
is five
is five
right Z one two three four
right Z one two three four
five wait this is five PR so the best
five wait this is five PR so the best
one is one so they're both right and
one is one so they're both right and
then the next
one is
seven and it says
seven and it says
six so torch is correct
six so torch is correct
and then two Z torch is
and then two Z torch is
correct so let's go let's go to
our
source let's go to our source
all action
types so this should not even be
types so this should not even be
possible because it's picking it's not
possible because it's picking it's not
just picking the wrong entries it's
just picking the wrong entries it's
picking like completely invalid
ones e
out
address loget sizes of a
I less than num action
I less than num action
types
interesting output of out Adder is equal
interesting output of out Adder is equal
to
I then in
I then in
Adder gets plus equal num action
types I don't see anything wrong with
types I don't see anything wrong with
this I'm obviously missing something I'm
this I'm obviously missing something I'm
also starting to get quite
also starting to get quite
hungry order some food
soon e
batch size num
actions
yeah and then Max logit is going to be
yeah and then Max logit is going to be
the input of the in
the input of the in
address
address
fine actually types the logic size
fine actually types the logic size
yes and the
yes and the
output to the input in address plus
output to the input in address plus
I bigger than the max
I bigger than the max
logit set it to the Max logit and then
logit set it to the Max logit and then
you set the
you set the
out
out
address to
I this looks good to me let me see if I
I this looks good to me let me see if I
mess something up with the data
coet in
coet in
32 well hold on maybe I screwed this up
right we should be able to see right
right we should be able to see right
here
loget sizes
aha good
you it's always that man always always
you it's always that man always always
always
that I should add some asserts or
something maybe we'll make like a safe
something maybe we'll make like a safe
API or something for the
testing because it's always
puffer
net it does concern me a little bit that
net it does concern me a little bit that
it takes that long to
run there might have to be some
run there might have to be some
optimization done we we'll
optimization done we we'll
see but uh it does
see but uh it does
run or maybe not cuz I'm importing P
run or maybe not cuz I'm importing P
torch and P torch takes a like a good
torch and P torch takes a like a good
couple seconds to import okay so we
couple seconds to import okay so we
literally have all of this done in uh NC
literally have all of this done in uh NC
let's add this before I lose
it
it
h m new puffet
layers Dev
more
puffer we like puffer
net
net
so I'm happy with that progress what I'm
so I'm happy with that progress what I'm
going to do now is I'm going to order my
going to do now is I'm going to order my
dinner on the side and then while I'm
dinner on the side and then while I'm
waiting my for my food as long as it
waiting my for my food as long as it
takes to get here um I
takes to get here um I
am yeah as long as it takes for my food
am yeah as long as it takes for my food
to get here I will try to get the full
to get here I will try to get the full
Network working and we'll see how that
Network working and we'll see how that
goes but I'm very very happy with this
goes but I'm very very happy with this
progress
progress
like this did not exist right this is a
like this did not exist right this is a
400 line file that just
400 line file that just
does neural nets for
you also let me check a DM
nope nothing
looking lots of progress just got here
looking lots of progress just got here
yeah let me order my food we're still
yeah let me order my food we're still
going to work on this for a little bit
going to work on this for a little bit
uh I just need to order something before
uh I just need to order something before
I pass
out technically if I were really
out technically if I were really
grinding this I would just eat food on
grinding this I would just eat food on
stream and keep working but I think
stream and keep working but I think
what's probably going to happen is I'm
what's probably going to happen is I'm
going to just order something eat and go
going to just order something eat and go
to bed early cuz
to bed early cuz
tomorrow I have another environment
tomorrow I have another environment
another big environment that I've been
another big environment that I've been
working on off stream that's still
working on off stream that's still
secret and I'm going to try to Port the
secret and I'm going to try to Port the
whole thing to see tomorrow it's like
whole thing to see tomorrow it's like
about the same size as the Moa
yeah me figure out what the hell to
yeah me figure out what the hell to
order let's do
this it's a good
protein yeah it doesn't matter
so I'll tell you the progress real
so I'll tell you the progress real
quick I'm pretty happy with
quick I'm pretty happy with
this so look at all the layers that we
this so look at all the layers that we
have implemented reu sigmoid linear com
have implemented reu sigmoid linear com
2D lstm one hot concatenation and argmax
2D lstm one hot concatenation and argmax
multi- discreet
multi- discreet
sampling um we also have a user API
sampling um we also have a user API
around all of these that just manages
around all of these that just manages
like all of the variabl for you here so
like all of the variabl for you here so
this is like closer to what P torch
this is like closer to what P torch
would be it's actually pretty much
would be it's actually pretty much
almost one to one with P torch it's a
almost one to one with P torch it's a
little bit lower level CU we don't have
little bit lower level CU we don't have
a tensor class um or a tensor struct so
a tensor class um or a tensor struct so
it's a little bit lower level because
it's a little bit lower level because
you have to manage stuff like um batch
you have to manage stuff like um batch
sizes and like com um com
sizes and like com um com
Dimensions but it's pretty
Dimensions but it's pretty
close it's only 400 lines of C we have a
close it's only 400 lines of C we have a
very nice test for
this so here's your 160 line test and
this so here's your 160 line test and
this actually ensures that our version
this actually ensures that our version
is exactly the same as P torch so not
is exactly the same as P torch so not
only is it correct but it matches P
only is it correct but it matches P
torch exactly meaning that we can load
torch exactly meaning that we can load
uh from pytorch into
uh from pytorch into
puffet this is what I've been
doing I think that's pretty
doing I think that's pretty
cool e
test cases took by surprise glad they're
test cases took by surprise glad they're
there
there
yeah these are
yeah these are
good they're a little bit annoying to
good they're a little bit annoying to
write because like in order to do
write because like in order to do
this I'll just show you what I had to do
this I'll just show you what I had to do
there's also a puffer net.
there's also a puffer net.
pyx which has this binding this is an
pyx which has this binding this is an
inter mediate layer between C and
inter mediate layer between C and
python um so this has to exist but given
python um so this has to exist but given
that this does exist it's not bad
okay um now what we're going to do is
okay um now what we're going to do is
what we were doing
what we were doing
before we were trying to do this
before we were trying to do this
Moet so there's this piece of code that
Moet so there's this piece of code that
I
have let me go find
it speaking of which how are we doing on
stars 13 stars off of 1K for
no wait it's
no wait it's
right head is stopping working because
right head is stopping working because
no
no
food need food in order
think
torch okay so this is the network that
torch okay so this is the network that
we're trying to implement
we're going to at least see if we get a
we're going to at least see if we get a
first pass on the logic today so the
first pass on the logic today so the
first thing is that this
first thing is that this
is
is
net one
net one
hot it's going to be inet one hot not
hot it's going to be inet one hot not
like
like
this it's
this it's
Dimensions
Dimensions
right 16et
H one
hot batch size input size gnome
hot batch size input size gnome
classes this is batch size 11 *
11 num classes is going to be 16
and then we have to
do net map stack
time 16
right
right
three this is the map stack
okay let's see from here so this
okay let's see from here so this
goes on
goes on
forward what you do
forward what you do
is you're going to one hot
jeez this is so obnoxious the way that
jeez this is so obnoxious the way that
this is I really am going to have to
this is I really am going to have to
mess with um the observation format or
mess with um the observation format or
something to make this easier they're
something to make this easier they're
just like so many tensor slice and copy
just like so many tensor slice and copy
and operations and such they're very
and operations and such they're very
difficult to do
difficult to do
well to be honest like I almost want to
well to be honest like I almost want to
spend some time making that net better
spend some time making that net better
because that's actually kind of slow now
because that's actually kind of slow now
that I'm looking at it
yeah well we're very close here
though let me check one
thing let's
thing let's
grab okay so we still have a good 20
grab okay so we still have a good 20
minutes let me see if I can figure out
minutes let me see if I can figure out
some optimizations to this
some optimizations to this
network I'm going to draw this as well
network I'm going to draw this as well
so we'll it'll be like kind of
so we'll it'll be like kind of
interactive we'll show you some uh some
interactive we'll show you some uh some
cool stuff
line
line
okay so the way that it works right now
okay so the way that it works right now
right
is if this is the observations
this is
this is
extra and then here what we have is
like
11 and by
11 and by
or
or
map is put it's encoded flat
map is put it's encoded flat
here and then what you need to do is you
here and then what you need to do is you
get so this turns into 11 by 11x
get so this turns into 11 by 11x
4 so what you end up getting is you get
4 so what you end up getting is you get
this map feature
this map feature
here and then you get this three map
here and then you get this three map
features like
this so this is
this so this is
one
hot
hot
hot and then this
hot and then this
is
Norm and then you do
Norm and then you do
[Music]
[Music]
cat one hot one hot means that you take
cat one hot one hot means that you take
let's say that you have a vector or
let's say that you have a vector or
let's say that you have a value that is
let's say that you have a value that is
five right and you have 10 total options
five right and you have 10 total options
then what you do is you make a vector
then what you do is you make a vector
length 10 and you set the fifth one to
length 10 and you set the fifth one to
be equal or you set I guess that's the
be equal or you set I guess that's the
sixth one technically uh to be equal to
sixth one technically uh to be equal to
one so it's essentially you treat the
one so it's essentially you treat the
data as an index which tells you which
data as an index which tells you which
element to set to
one
one
yeah but I'm doing like tons of
yeah but I'm doing like tons of
here so then what you do is like the
here so then what you do is like the
flat Fe
features this gets
normed and
normed and
then like
PR
cat these two get catted
cat these two get catted
together and then from there it's easy
but that's too much
stuff it gets Norm so that the sum is
stuff it gets Norm so that the sum is
one it just gets divided by a fixed
one it just gets divided by a fixed
value cat is
value cat is
concatenate so like you stack all the
concatenate so like you stack all the
stuff
stuff
together so basically what Happening
together so basically what Happening
Here is I just have too many freaking
Here is I just have too many freaking
operations on little slices of data that
operations on little slices of data that
are going to drive me nuts the way this
are going to drive me nuts the way this
is
written and not only that but this is
written and not only that but this is
not efficient the way it's written
either it's gets it does not get
either it's gets it does not get
normalized so the magnitude is Vector
normalized so the magnitude is Vector
one that's not the only type of
one that's not the only type of
normalization right in this case I'm
normalization right in this case I'm
just dividing by
just dividing by
255 um because what I'm doing actually
255 um because what I'm doing actually
here is I'm storing all the data in one
here is I'm storing all the data in one
bite which means you don't get a lot of
bite which means you don't get a lot of
precision so if I have a variable that's
precision so if I have a variable that's
from 0 to one what I do is I multiply It
from 0 to one what I do is I multiply It
Up by 255 and then that gets cast to a
Up by 255 and then that gets cast to a
bite and then I divide back by 255 and
bite and then I divide back by 255 and
cast as a float so I get to store it in
cast as a float so I get to store it in
one bite but uh I still get a little bit
one bite but uh I still get a little bit
of precision associated with it so
of precision associated with it so
there's a little bit of a trick going on
there but I can see looking at this that
there but I can see looking at this that
there are like all these operations that
there are like all these operations that
are slowing this down and this needs to
are slowing this down and this needs to
be
faster e
really the main problem here is the fact
really the main problem here is the fact
that you need to one hot this
right but there's not really a good way
right but there's not really a good way
around having to one hot it either
yeah the thing that's just really
yeah the thing that's just really
obnoxious is like the right patterns
obnoxious is like the right patterns
here they don't match
here they don't match
up like there isn't an easy way to just
up like there isn't an easy way to just
do a one hot plus I can cat plus like
do a one hot plus I can cat plus like
all these things in one step it's
all these things in one step it's
difficult
m
it's tough cuz we don't have like the
it's tough cuz we don't have like the
notion of applying an operation along an
notion of applying an operation along an
axis like the main thing is I I'm using
axis like the main thing is I I'm using
array Ops
array Ops
here and I'm using array operations in
here and I'm using array operations in
like I'm using array operations in kind
like I'm using array operations in kind
of a tricky way
I'm sure this is not efficient anyways
I'm sure this is not efficient anyways
right like we should be getting a
right like we should be getting a
million steps per second and we're only
million steps per second and we're only
getting 500K
but this is difficult because
like the thing is like if you just look
like the thing is like if you just look
at it visually you say oh yeah just
at it visually you say oh yeah just
stack it right but the thing is it's not
stack it right but the thing is it's not
that easy because the the way that these
that easy because the the way that these
things are laid out in memory certain
things are laid out in memory certain
operations are easy and certain
operations are easy and certain
operations are hard and this operation
operations are hard and this operation
is hard to do
nicely yeah not to mention all the casts
nicely yeah not to mention all the casts
and stuff that are getting done
what is the basis case like like if we
what is the basis case like like if we
have one observation we make looking at
have one observation we make looking at
um it doesn't really help if you have
um it doesn't really help if you have
one observation
one observation
even
even
like the thing is that there just there
like the thing is that there just there
are a lot of operations going on here
are a lot of operations going on here
right and like it's inefficient in this
right and like it's inefficient in this
implementation so we need to make this
implementation so we need to make this
more efficient and if I can find a way
more efficient and if I can find a way
to do that the hope is that it'll make
to do that the hope is that it'll make
the C easier as well
the C easier as well
um because like what's happening now is
um because like what's happening now is
we're splitting out the data into three
we're splitting out the data into three
separate chunks and those chunks do not
separate chunks and those chunks do not
occupy contiguous memory they're
occupy contiguous memory they're
contiguous along certain views but
contiguous along certain views but
they're not actually contiguous in
they're not actually contiguous in
memory and there's not really a way to
memory and there's not really a way to
make them contiguous in memory because
make them contiguous in memory because
of the way that batching works that's
of the way that batching works that's
like a hard uh issue though it's like
like a hard uh issue though it's like
there's not really a good way around
there's not really a good way around
that one so we have
that one so we have
like essentially a split along axis
like essentially a split along axis
operation if you
operation if you
will it's actually a little worse than
will it's actually a little worse than
that it's like there's a bunch of
that it's like there's a bunch of
reshapes that have to happen before you
reshapes that have to happen before you
can even do that and then you have to
can even do that and then you have to
apply a one hot and then you have to
apply a one hot and then you have to
apply a stack along an axis and then
apply a stack along an axis and then
there's a concat and then you can get
there's a concat and then you can get
normal stuff happening
normal stuff happening
again and there's got to be a way to
again and there's got to be a way to
simplify this so basically the operation
simplify this so basically the operation
that we're trying to do here that we
that we're trying to do here that we
care
care
about is we have one filter that needs
about is we have one filter that needs
to get one hotted we have some extra
to get one hotted we have some extra
filters that don't need to get one
filters that don't need to get one
hotted and then we need to be able to
hotted and then we need to be able to
convo for the Stacked versions of those
convo for the Stacked versions of those
once we stack them all
once we stack them all
together
together
um it's difficult because
like I mean there are technically other
like I mean there are technically other
encoders I can use for this instead of
encoders I can use for this instead of
one hot
one filter to hot
one filter to hot
one extra not hot
one extra not hot
one there's quite a bit of stuff so
one there's quite a bit of stuff so
there's there's one filter here that
there's there's one filter here that
needs to get one hotted there's several
needs to get one hotted there's several
additional filters that need to get just
additional filters that need to get just
stacked on top of this one
stacked on top of this one
hot um
hot um
and then I guess we also have some flat
and then I guess we also have some flat
data at the
end this is going to take some
thought stacking filters then flatten
thought stacking filters then flatten
yeah you can do all of that but it's
yeah you can do all of that but it's
going to be like one it's going to be me
going to be like one it's going to be me
writing a lot of C to make the same
writing a lot of C to make the same
thing work in C and two like the way
thing work in C and two like the way
that this is written right now like
that this is written right now like
there's just a lot of copying data
there's just a lot of copying data
around here like every time that you
around here like every time that you
take a slice every time you have to take
take a slice every time you have to take
data along a slice that okay you're fine
data along a slice that okay you're fine
doing that but as soon as you do
doing that but as soon as you do
anything with data that is not
anything with data that is not
contiguous you end up having to copy it
contiguous you end up having to copy it
so like I think we're copying the data
so like I think we're copying the data
several times here which is really
bad in this little
Network reference the
Network reference the
data well the problem like yeah you can
data well the problem like yeah you can
reference but the thing is it's not in
reference but the thing is it's not in
contiguous
contiguous
memory like generally it's like okay
memory like generally it's like okay
fine your data is not in contiguous
fine your data is not in contiguous
memory and there's no way around that
memory and there's no way around that
fine then what you want to do usually is
fine then what you want to do usually is
you want to get it in contiguous memory
you want to get it in contiguous memory
and do all your operations there without
and do all your operations there without
having to do any more copies
why can't we get it to contiguous
why can't we get it to contiguous
memory well if you look at it
like the way that I wrote it up here so
like the way that I wrote it up here so
each of these little slices here is one
each of these little slices here is one
of the filters right we have like 11 by
of the filters right we have like 11 by
11 map filters so we have like flattened
11 map filters so we have like flattened
filters here I guess there'd only be
filters here I guess there'd only be
four of
four of
them but yeah 11 by 11 11 by 11 11 by 11
them but yeah 11 by 11 11 by 11 11 by 11
11 by 11
um so
technically that the way it works hold
on I guess technically we can just split
on I guess technically we can just split
it right I guess technically it looks
it right I guess technically it looks
like this where this is like
like this where this is like
2D
2D
continuous and this is 2D
discreet and then this is
extra but like just because I can split
extra but like just because I can split
it like this doesn't mean it's
contiguous right you like the split
contiguous right you like the split
operation
operation
itself like the memory doesn't know that
itself like the memory doesn't know that
oh yeah this is a nice block right
oh yeah this is a nice block right
you're still like this is a row this is
you're still like this is a row this is
a row this is a row it's not
contiguous yeah each slice is a fil the
contiguous yeah each slice is a fil the
slices are contiguous but the thing is
slices are contiguous but the thing is
you
you
don't buy like just because the slices
don't buy like just because the slices
like they look like they're like
like they look like they're like
contiguous like that it looks like they
contiguous like that it looks like they
are that doesn't mean they actually are
are that doesn't mean they actually are
like what contiguous memory is like here
like what contiguous memory is like here
this block here this is a contiguous
this block here this is a contiguous
block of memory right like this is a
block of memory right like this is a
contiguous block of memory right this is
contiguous block of memory right this is
not a contiguous block of memory
you know what I'm kind of leaning
you know what I'm kind of leaning
towards
so I mean this is going to be a whole
so I mean this is going to be a whole
bunch of additional custom operations
bunch of additional custom operations
still but
still but
like what we could do is we could take
like what we could do is we could take
this block here this one hot block and
this block here this one hot block and
we could just like allocate
we could just like allocate
extra
extra
essentially so like this is what your
essentially so like this is what your
one hot looks like
this is what your one Hawk tensor looks
this is what your one Hawk tensor looks
like once it's expanded we could just
like once it's expanded we could just
like allocate extra
here and then like this goes here and
here and then like this goes here and
then this goes
here numpy flatten allows us to make it
contiguous yeah but you have to think
contiguous yeah but you have to think
about how that happens right that's a
about how that happens right that's a
copy
copy
so every time you look at an operation
so every time you look at an operation
like that and say oh yeah that lets us
like that and say oh yeah that lets us
do it like I have to not only does that
do it like I have to not only does that
incur a copy which slows down our
incur a copy which slows down our
training code here that's slow but also
training code here that's slow but also
I have to go Implement that and
see which is fine like I can Implement
see which is fine like I can Implement
some C stuff but ideally I'm not
some C stuff but ideally I'm not
implementing like a bajillion different
implementing like a bajillion different
things I think I can actually cheat this
things I think I can actually cheat this
because I'm thinking right
because I'm thinking right
here if I just make this F1 Hot
here if I just make this F1 Hot
here if I just make this Dimension
here if I just make this Dimension
19 so I just cheat some extra layers in
19 so I just cheat some extra layers in
then what I can do is I can take these
then what I can do is I can take these
extra map features and instead of doing
extra map features and instead of doing
this concatenate I can just like instead
this concatenate I can just like instead
of doing this
of doing this
concatenate I can just like put them in
concatenate I can just like put them in
there
there
maybe does that work
I think that
works yeah I can just put the extra ones
works yeah I can just put the extra ones
at the end
at the end
there which would be
faster slightly
faster slightly
easier I actually don't know that if
easier I actually don't know that if
that is is even easier
man I probably need to implement like a
man I probably need to implement like a
slice operation and a couple other
slice operation and a couple other
things
right e
this one hot is just so
this one hot is just so
obnoxious like if I'm thinking about it
obnoxious like if I'm thinking about it
here right without the one hot this is
easy without the one hot this is super
easy without the one hot this is super
easy
or alternatively without the extra data
or alternatively without the extra data
it's also super easy
food's almost
food's almost
here yeah I think my brain is going to
here yeah I think my brain is going to
have a a tough time until I can think
have a a tough time until I can think
about this
about this
better I'm going to definitely be
better I'm going to definitely be
thinking about this though over the
thinking about this though over the
weekend I have some other stuff to do
weekend I have some other stuff to do
but I'm going to be thinking about this
but I'm going to be thinking about this
for
sure yeah I need to get some food um
I'm
looking you know maybe this type of
looking you know maybe this type of
encoder is just not a good idea
encoder is just not a good idea
right you know I thought that this was a
right you know I thought that this was a
good idea but maybe it's just not a good
good idea but maybe it's just not a good
idea to have to have mixed one hot and
idea to have to have mixed one hot and
continuous data
yep that is what a one hot encoder
yep that is what a one hot encoder
does it is
does it is
true well I'll tell you what I'm going
true well I'll tell you what I'm going
to be back on Monday I'm going to have
to be back on Monday I'm going to have
I'm going to work on a lot of cool stuff
I'm going to work on a lot of cool stuff
over the weekend I'm going to get like a
over the weekend I'm going to get like a
I'm going to get stuff into a very nice
I'm going to get stuff into a very nice
spot
spot
um I if you'd like to take a look at the
um I if you'd like to take a look at the
some of the stuff that's in puffer at
some of the stuff that's in puffer at
the moment it's all open source so we've
the moment it's all open source so we've
got uh and really this is this is 12
got uh and really this is this is 12
Stars away from a th so if you want to
Stars away from a th so if you want to
support the project if you haven't
support the project if you haven't
started already please go ahead and help
started already please go ahead and help
us with that um it's been great to see
us with that um it's been great to see
the growth on this it's really awesome
the growth on this it's really awesome
and we're very close to that 1,000 M uh
and we're very close to that 1,000 M uh
that
that
Milestone um this is all open source and
Milestone um this is all open source and
the other thing is there is a Discord
the other thing is there is a Discord
and there's a lot of stuff going on in
and there's a lot of stuff going on in
there with contributors and whatnot um
there with contributors and whatnot um
like a lot of the stuff I do you can
like a lot of the stuff I do you can
ignore all the C that I do if that's not
ignore all the C that I do if that's not
your jam
your jam
right like we have much easier ways to
right like we have much easier ways to
implement ultra high perf RL
implement ultra high perf RL
environments and to learn a lot of stuff
environments and to learn a lot of stuff
around here so if you're interested in
around here so if you're interested in
that flash
puffer
puffer
yeah check that out there in the Discord
yeah check that out there in the Discord
um feature hashed hashing
um feature hashed hashing
[Music]
embeddings other encoding types
possibly I'd have to look at
possibly I'd have to look at
specifically this and I'll think about
specifically this and I'll think about
some stuff but anyways I'm going to go
some stuff but anyways I'm going to go
get food thanks folks I will be back um
get food thanks folks I will be back um
I'll be back on Monday with some cool
I'll be back on Monday with some cool
stuff and yeah I think next week we're
stuff and yeah I think next week we're
going to have like this nice full
going to have like this nice full
Standalone puffer net Library we're
Standalone puffer net Library we're
going to have demos running on the web
going to have demos running on the web
we're going to have the mobile running
we're going to have the mobile running
on the web we're going to get training
on the web we're going to get training
working and we're going to have like
working and we're going to have like
model
model
just being imported to like the web
just being imported to like the web
version very frequently uh and we're
version very frequently uh and we're
going to start having more environments
going to start having more environments
as well so thank you everyone and I will
as well so thank you everyone and I will
see you around bye

Kind: captions
Language: en
how's it going I got to get a quicker
how's it going I got to get a quicker
start on these streams I'd like to be on
start on these streams I'd like to be on
like a good hour or two earlier but we
like a good hour or two earlier but we
move slow once in a while we move
slow but here we are set and we have a
slow but here we are set and we have a
pretty concrete set of stuff to get done
today oops
cool so uh where we left this off
cool so uh where we left this off
yesterday why why am I sitting in green
yesterday why why am I sitting in green
Haze like do I have to make this any
Haze like do I have to make this any
brighter really all right fine I'll
brighter really all right fine I'll
stare into this all day sure
stare into this all day sure
um so where we left this off yesterday
um so where we left this off yesterday
we had some pretty good
progress where the heck is this
puffer Leb environments ocean MOA and
puffer Leb environments ocean MOA and
then MOA Doh here no
then MOA Doh here no
M.C okay so
M.C okay so
here we were implementing a few
here we were implementing a few
different layer types uh in C here so we
different layer types uh in C here so we
have this lstm we got the full
have this lstm we got the full
implementation done but it needs to be
implementation done but it needs to be
uh error checked and the like we also
uh error checked and the like we also
have the com done yesterday and pretty
have the com done yesterday and pretty
much all I have to do is uh finish this
much all I have to do is uh finish this
today make sure that this is correct I
today make sure that this is correct I
have to write some sort of better test
have to write some sort of better test
on this uh and
then probably from there we're going to
then probably from there we're going to
figure out a way to clean this up a
figure out a way to clean this up a
little bit so we can have like a
little bit so we can have like a
portable little
portable little
Standalone and then we'll go from there
Standalone and then we'll go from there
but that should be enough to get our RL
but that should be enough to get our RL
models onto the
web for sure
let me remember where we were how we
let me remember where we were how we
were doing this hold
on
it's right so we have this
it's right so we have this
here where we can look at the individual
here where we can look at the individual
weights in the lstm here right
uh this is garbage
uh this is garbage
right oh no that's old okay here it
right oh no that's old okay here it
is yeah
is yeah
so we have our break point here and then
so we have our break point here and then
here we're going to need to put a GDB
here we're going to need to put a GDB
breakpoint of some type I
breakpoint of some type I
assume and we're going to have to look
assume and we're going to have to look
at the individual outputs of
at the individual outputs of
stuff right
stuff right
yeah I think that's where we left
yeah I think that's where we left
off so in order to do that let me see
off so in order to do that let me see
where we want
where we want
to start probably like here
103 and then hold on
103 and then hold on
export how you doing doing well thank
export how you doing doing well thank
you
you
oh thank you for making me notice I have
oh thank you for making me notice I have
to rearrange this little little
to rearrange this little little
bit uh we
bit uh we
are doing some cool stuff at least this
are doing some cool stuff at least this
will be cool when it works cuz we'll be
will be cool when it works cuz we'll be
able to run really nice networks in the
browser okay so here we we are in uh the
browser okay so here we we are in uh the
start of the lstm layer right and
start of the lstm layer right and
then I run this flat that
thing and we have this
thing and we have this
buffer so let's see if the linear layer
buffer so let's see if the linear layer
is correct do you stream daily usually
is correct do you stream daily usually
like five days a week Monday through
like five days a week Monday through
Friday and then I do solo Dev on
Saturday usually somewhere around 100
Saturday usually somewhere around 100
p.m. Pacific to like 8 or something like
p.m. Pacific to like 8 or something like
that I've been trying to get on earlier
that I've been trying to get on earlier
um I don't know just me being lazy
um I don't know just me being lazy
taking too long to like get my exercise
taking too long to like get my exercise
done and get food and all that stuff in
done and get food and all that stuff in
the mornings
okay this gets saved
into
into
buffer
right
so oh there you
so oh there you
go you can see right there that we match
go you can see right there that we match
here
here
and like if I do buffer of
10 this matches and now we should check
10 this matches and now we should check
to make sure that this is correct across
to make sure that this is correct across
everything so
everything so
like uh I don't know
1024 which
1024 which
is to
is to
zero
zero
yeah isn't it difficult to to reply to
yeah isn't it difficult to to reply to
chat and focus
chat and focus
on the game what game game here is
on the game what game game here is
writing
code are you a language model is this an
code are you a language model is this an
automated bot say something if you're
automated bot say something if you're
actually a person here
H twitch
H twitch
Bots that's so
obnoxious well our linear layer is
correct hi sir welcome hold on let me
correct hi sir welcome hold on let me
ban this
bot there we
go literally an advertising
go literally an advertising
bot welcome back
okay so this is now
okay so this is now
at
at
buffer
buffer
right we should be able to see
like oh that's going to be hard to
like oh that's going to be hard to
figure out if this is correct isn't it
yeah this is all
yeah this is all
one okay we'll have to do something
one okay we'll have to do something
about
about
that yeah all of these gates are all
one I think we need to just like divide
one I think we need to just like divide
by 10,000 or something in all of our
by 10,000 or something in all of our
input
data
yeah that's obnoxious but at least we
yeah that's obnoxious but at least we
know that our input layers are correct
know that our input layers are correct
right
yeah so just all of these places where
yeah so just all of these places where
we are doing uh a range let's just do
we are doing uh a range let's just do
over
over
10,000 over
10,000
oops and this will uh this will get us
oops and this will uh this will get us
into a data regime where essentially
into a data regime where essentially
these sigmoids and these canes these
these sigmoids and these canes these
functions here will not always give the
functions here will not always give the
same result we should actually be able
same result we should actually be able
to get something done there I would
hope that might actually still not be
hope that might actually still not be
enough but we'll
see because all the weights are positive
see because all the weights are positive
right wait a second all the weights are
right wait a second all the weights are
positive
uh well we'll see what this does on its
uh well we'll see what this does on its
own
welcome YouTube
welcome YouTube
folks we're currently fixing the lstm
folks we're currently fixing the lstm
layer
layer
here uh and we are testing to make sure
here uh and we are testing to make sure
that this performs exactly the same as P
torch so what we're doing is we're
torch so what we're doing is we're
getting a little bit of synthetic
getting a little bit of synthetic
data and then we're going to test to
data and then we're going to test to
make sure that at every portion of this
make sure that at every portion of this
function we match the uh the P torch
function we match the uh the P torch
reference
reference
okay recompile
okay recompile
this where did my commands
go
cool and now 103 we have buff for
zero and here we should have
zero and here we should have
[Music]
[Music]
buffer
buffer
oops zero and these match as you can see
oops zero and these match as you can see
and we can do like buffer of like
and we can do like buffer of like
1024 which I believe corresponds to
1024 which I believe corresponds to
buffer two and these match exactly
buffer two and these match exactly
perfect so our linear layers are correct
perfect so our linear layers are correct
uh as we suspected 20
uh as we suspected 20
so now we go down to the bottom of the
so now we go down to the bottom of the
gates
right and perfect so now we actually
right and perfect so now we actually
have applied the gates
here what are we searching for today yes
here what are we searching for today yes
so uh the goal here is to
so uh the goal here is to
get these models which is hold on let me
get these models which is hold on let me
show you
so I have this uh this MOA that I've
so I have this uh this MOA that I've
been coding for RL work you can actually
been coding for RL work you can actually
play it online here this runs in a
play it online here this runs in a
browser you can like run around it's a
browser you can like run around it's a
basic little MOA here's a speed buff
basic little MOA here's a speed buff
right it's got like an assassinate
right it's got like an assassinate
ability on
ability on
stuff so on and so forth um yeah so and
stuff so on and so forth um yeah so and
what we're trying to do with this thing
if we go to the GitHub
here we have these models that we're
here we have these models that we're
using for the RL agents and they're all
using for the RL agents and they're all
pretty similar they basically they all
pretty similar they basically they all
are going to use
are going to use
convolutions uh they're going to
convolutions uh they're going to
use linear layers a few activations and
use linear layers a few activations and
an lstm
an lstm
so here's the network for the Moa so
so here's the network for the Moa so
basically if I can just Implement all
basically if I can just Implement all
these layers for uh the Inc I'll be able
these layers for uh the Inc I'll be able
to compile them and run them on the web
to compile them and run them on the web
and Noah how's it going we're uh we're
and Noah how's it going we're uh we're
porting models to see so that we can run
porting models to see so that we can run
them
them
online speaking of
online speaking of
which if your breakout environment is uh
which if your breakout environment is uh
is done we should get that integrated
is done we should get that integrated
because we're starting to have some cool
because we're starting to have some cool
demos around here here's the mobo being
demos around here here's the mobo being
run browser right lots of cool stuff
run browser right lots of cool stuff
going
on that's what we're doing for the time
on that's what we're doing for the time
being
being
here and it looks like it's going fairly
here and it looks like it's going fairly
well
513 yeah that's
513 yeah that's
correct no time to work on it start next
correct no time to work on it start next
month sounds
good yeah Nathan is also currently
good yeah Nathan is also currently
writing his thesis and he says he's
writing his thesis and he says he's
going to be working on some cool
going to be working on some cool
environments next week so cool
environments next week so cool
stuff but for the time
stuff but for the time
being I will handle all these nets and
being I will handle all these nets and
will actually be able to run stuff on
will actually be able to run stuff on
the web it would be very cool
the web it would be very cool
uh let me see how I want to check this
uh let me see how I want to check this
so hang on I
times hidden
times hidden
size wait
buffer right so this buffer is of size
1024 let me just make sure I understand
1024 let me just make sure I understand
this
yeah yeah okay so I here is 500 what is
yeah yeah okay so I here is 500 what is
this 128
elements and
elements and
then yeah this is correct and now we
then yeah this is correct and now we
need to
need to
check I mean the other one should be
check I mean the other one should be
right shouldn't
right shouldn't
they like if I do buffer of 120 of what
they like if I do buffer of 120 of what
is
is
0128 this should
0128 this should
be well not buffer it should be I here
be well not buffer it should be I here
I'm getting confused with
I'm getting confused with
indexing okay F of Z 0 should be
indexing okay F of Z 0 should be
buffer
128 is that not correct
sigmoid of
f ifg
o did I mess this up somehow let me
o did I mess this up somehow let me
see ifg o is split the
see ifg o is split the
buffer and then
I did I get the dimensions wrong
somehow 16 by
128 I might be interpreting the
128 I might be interpreting the
dimensions wrong
because we just put a broke we put a
because we just put a broke we put a
break point down to
break point down to
here
right wait does this make
right wait does this make
sense no this logic is wrong right two
sense no this logic is wrong right two
times hidden size
wait batch
wait batch
offset
is four times the batch times the hidden
is four times the batch times the hidden
size and then you do the buffer address
size and then you do the buffer address
B offset plus
B offset plus
I equal to
I equal to
sigmoid that looks good to me
okay maybe we figure something out
okay maybe we figure something out
here buffer of
one this
matches this also matches
matches this also matches
right about
127 also matches
what's I of one
what's I of one
Z
5087 is that
5087 is that
correct I guess it would be
so F of Z
Z I fail to see how this happens
128 is equal to
0.5 somehow these gates are not lined up
0.5 somehow these gates are not lined up
the way I think that they are I guess
so what I think should be happening here
so what I think should be happening here
right is that there are four different
right is that there are four different
Gates you can see them here I F uh go
Gates you can see them here I F uh go
four different activations I guess and
four different activations I guess and
these are each 128 Dimensions so I want
these are each 128 Dimensions so I want
to check that the values that are
to check that the values that are
computed in C for these are equal to the
computed in C for these are equal to the
values in pi torch and it looks like the
values in pi torch and it looks like the
first set matches and the second set
first set matches and the second set
doesn't which is very bizarre
because literally I just go through and
because literally I just go through and
set the
set the
first however many this is right
tch. sigmoid of f
right you split it into size of hidden
right you split it into size of hidden
chunks
yeah and we know that the sigmoid
yeah and we know that the sigmoid
function matches because it matched for
function matches because it matched for
I so why does it magically not match for
I so why does it magically not match for
this what am I not seeing here
this what am I not seeing here
sigmoid buffer buff
sigmoid buffer buff
address offset is equal to four time the
address offset is equal to four time the
batch times the hidden size this is zero
batch times the hidden size this is zero
for the first Loop
for the first Loop
right and then hidden size is 128 so
right and then hidden size is 128 so
this is the first 256
this is the first 256
elements and then you just go through 0
elements and then you just go through 0
to
to
256 you set the buffer equal
256 you set the buffer equal
to sigmoid here
let's rerun
this so buffer
zero8
right 0
0 oh
0 oh
well hold
well hold
on Match is
on Match is
there but
there but
[Music]
[Music]
127 you
get let's just take a look at what our
get let's just take a look at what our
data is
data is
here maybe the test case is weird
because there's nothing that should go
because there's nothing that should go
like should be cyclical like that oh
like should be cyclical like that oh
wait am I just not hold on num
buffer input is numb input buffer num
buffer input is numb input buffer num
buffer output num
buffer output num
output and we have hidden
output and we have hidden
size the weights input
this should be four shouldn't
this should be four shouldn't
it four times hidden
it four times hidden
size yeah so your test the test case is
size yeah so your test the test case is
just
wrong so we have buffer of zero
uh that's a little
uh that's a little
suspicious oh no wait because it's
suspicious oh no wait because it's
already yeah yeah yeah this is fine
already yeah yeah yeah this is fine
so okay so I still
so okay so I still
matches let's check 127 which is buffer
matches let's check 127 which is buffer
127 this matches which it did before and
127 this matches which it did before and
now this looks better this looks way
now this looks better this looks way
better uh because if I
do this doesn't work work here right
do this doesn't work work here right
because it's
because it's
F
F
Z
Z
93 that's a little bit off
9372 I don't know if that's within I
9372 I don't know if that's within I
don't know if that's within numerical
don't know if that's within numerical
Precision I would doubt
it yeah no in the third digit I I don't
it yeah no in the third digit I I don't
believe
believe
that let let's check the next one what
that let let's check the next one what
copile are you using super Maven it's
copile are you using super Maven it's
great I highly recommend
it it gives me very fast on line
it it gives me very fast on line
completions which is all I
want it'll do multi-line as well but
want it'll do multi-line as well but
typically I just want really fast one
typically I just want really fast one
line completion save typing not
thinking okay so something is screwy
thinking okay so something is screwy
here because
do I believe that it's that far
off no I don't believe it's that far off
off no I don't believe it's that far off
because if you look at the 127th element
because if you look at the 127th element
9359 9359 they match
perfectly plus this is um 0o to one data
perfectly plus this is um 0o to one data
is where the high float Precision lives
so what happened
here are you essentially flattening
here are you essentially flattening
arrays kind of yeah I have on the right
arrays kind of yeah I have on the right
side I have a pie torch implementation
side I have a pie torch implementation
which is like just going through the
which is like just going through the
different operations in the lstm and on
different operations in the lstm and on
the left I have GDB over the C
the left I have GDB over the C
implementation that operates on flat
implementation that operates on flat
buffers and I'm trying to make my C
buffers and I'm trying to make my C
impementation match the pytorch
impementation match the pytorch
implementation exactly because if it
implementation exactly because if it
does then I can load uh weights from
does then I can load uh weights from
pre-trained pytorch networks into it and
pre-trained pytorch networks into it and
I can run them on the web because I can
I can run them on the web because I can
compile the web
compile the web
assembly and then I'll end up with like
assembly and then I'll end up with like
this 300 line file that lets me just run
this 300 line file that lets me just run
whatever I want on the web
but you know you have to get them to
but you know you have to get them to
match
exactly is super Maven free there's a
exactly is super Maven free there's a
free version but I highly recommend the
free version but I highly recommend the
paid
one e
this is very weird because it looks
this is very weird because it looks
like the sigmoid should be
good are my weights somehow being set
good are my weights somehow being set
differently they shouldn't be
we should probably make sure that um the
we should probably make sure that um the
linear layers match before we commit to
linear layers match before we commit to
all this
right
right
so
so
here buffer zero buffer 12.7 buffer 128
here buffer zero buffer 12.7 buffer 128
right I can do
right I can do
buffer 0
buffer 0
0 that
0 that
matches
matches
6817 yep that
6817 yep that
matches and then
0128 okay this does not quite
0128 okay this does not quite
match right here so it might not it's
match right here so it might not it's
probably not the error in the gates it
probably not the error in the gates it
looks like there's something wrong
looks like there's something wrong
with our linear which is very weird
with our linear which is very weird
because we have that tested
because we have that tested
independently
independently
so I think that what we're going to have
so I think that what we're going to have
to do is we're going to have to make
to do is we're going to have to make
first of all we got to make sure our
first of all we got to make sure our
test date is actually what we think it
test date is actually what we think it
is was actually the same
is was actually the same
um and if it is then we'll have to look
um and if it is then we'll have to look
at the linear layer because maybe maybe
at the linear layer because maybe maybe
I missed something earlier I didn't
I missed something earlier I didn't
think that I did but we'll
think that I did but we'll
see welcome to all the YouTube folks oh
see welcome to all the YouTube folks oh
yeah by the way very quick plug all this
yeah by the way very quick plug all this
stuff is free and open source in puffer
stuff is free and open source in puffer
lib all the RL stuff we're 16 Stars off
lib all the RL stuff we're 16 Stars off
of 1K so if you want to help me out for
of 1K so if you want to help me out for
free star the repo to feed the
free star the repo to feed the
puffer thank you back to
Dev maybe too basic too much data do
Dev maybe too basic too much data do
difficult to print start of each your
difficult to print start of each your
segments aren't in CL well that's what
segments aren't in CL well that's what
I'm doing right I'm print I am doing
I'm doing right I'm print I am doing
that that's what I'm I'm printing out
that that's what I'm I'm printing out
these elements here I'm just doing it
these elements here I'm just doing it
interactively as
interactively as
all um you know because it's obnoxious
all um you know because it's obnoxious
to write test scripts that are like
to write test scripts that are like
across Python and C at the same time I'd
across Python and C at the same time I'd
have to write
bindings well they definitely mismatch
bindings well they definitely mismatch
here though so let's take a quick look
here though so let's take a quick look
at
at
the we'll look at the code side by side
okay so here's the code in
okay so here's the code in
pytorch and here is the code in
C and we're going to want to look at the
C and we're going to want to look at the
data going into these to start
data going into these to start
with so this is where I make the test
data and then let's see what I do over
data and then let's see what I do over
here so
here so
input num input
input num input
is batch size times input size these
is batch size times input size these
shapes look
shapes look
good and then the state
data batch size times hidden
size I'm output batch size yep that
size I'm output batch size yep that
looks
looks
good and then buffers four * batch times
good and then buffers four * batch times
hidden
hidden
just hold on are the weights
just hold on are the weights
wrong wait
four times
four times
hidden no that's correct right four
hidden no that's correct right four
times hidden times input four times
times hidden times input four times
hidden times hidden
hidden times hidden
yeah
yeah
right oh look right here it was just
right oh look right here it was just
ever so slightly off because we forgot
ever so slightly off because we forgot
to add the test data
to add the test data
to be the correct shape for the bias hey
to be the correct shape for the bias hey
man what are you up to I currently
man what are you up to I currently
making this C implementation of comet
making this C implementation of comet
plus lstm match the P torch version so
plus lstm match the P torch version so
that we can compile it to wasam and run
that we can compile it to wasam and run
it on the web so that we can actually
it on the web so that we can actually
demo our cool RL agents online
I bet it's going to match
now grab some sample
points o for 0 0 matches
points o for 0 0 matches
perfectly we didn't do one
perfectly we didn't do one
1.7 matches perfectly right down to the
1.7 matches perfectly right down to the
last significant
digit perfect now it
matches okay so now we are at we just
matches okay so now we are at we just
went past the activation function
went past the activation function
so where's the pie torch math on
so where's the pie torch math on
this if I just look up the
this if I just look up the
docks I'll show you what part we've been
docks I'll show you what part we've been
doing so we just confirmed that all
doing so we just confirmed that all
these map moles are correct in here all
these map moles are correct in here all
these arcs and now we're going to do
these arcs and now we're going to do
these individual activations we're going
these individual activations we're going
to make sure that the code is correct
to make sure that the code is correct
for
this nice to catch you live welcome
this nice to catch you live welcome
we're doing some crazy stuff today
okay so the first element matches
okay so the first element matches
here let's try
127 matches and now here I have it
127 matches and now here I have it
organized a little differently so it
organized a little differently so it
should be
should be
one
one
zero and then this is going to be
buffer it's flat
buffer it's flat
actually 512
actually 512
matches I've had good experience using
matches I've had good experience using
Onyx I've like I tried Onyx and it
Onyx I've like I tried Onyx and it
didn't work it was a pain so if you have
didn't work it was a pain so if you have
an easy way to get this working with
an easy way to get this working with
Onyx and CI all years but I have not
Onyx and CI all years but I have not
found an easy way of doing
found an easy way of doing
it there was like a massive chain of
it there was like a massive chain of
dependencies in build and it was
dependencies in build and it was
such a pain that I was like well I can
such a pain that I was like well I can
just write 300 lines of C
like And subscribe because it's hard
like And subscribe because it's hard
work yeah thank you and honestly like
work yeah thank you and honestly like
folks just St the repository we're so so
folks just St the repository we're so so
close to hitting a thousand
close to hitting a thousand
now
984 new to ml stuff and only started my
984 new to ml stuff and only started my
first research project surrounding the
first research project surrounding the
topic a month and a half ago think can
topic a month and a half ago think can
join a
join a
competition surrounding degenerative
competition surrounding degenerative
lumbar spine
lumbar spine
disease more experience in the field of
disease more experience in the field of
on High level what would you be your
on High level what would you be your
steps to
steps to
tackle to just
tackle to just
testing CNN V implementations and hyp
testing CNN V implementations and hyp
and doing pram
and doing pram
sweeps
sweeps
um well it depends how much compute you
um well it depends how much compute you
have access to
have access to
right a lot of stuff can
right a lot of stuff can
be a lot of stuff actually is going to
be a lot of stuff actually is going to
depend a lot more on the data than on
depend a lot more on the data than on
the models so you definitely are going
the models so you definitely are going
to want to spend more you're going to
to want to spend more you're going to
spend a lot of time massaging the data
spend a lot of time massaging the data
it depends how much of it is is as well
it depends how much of it is is as well
usually with stuff like that you don't
usually with stuff like that you don't
have that many like you don't have that
have that many like you don't have that
many images or that many samples of
many images or that many samples of
stuff so uh yeah that's usually you end
stuff so uh yeah that's usually you end
up spending a lot of time on the
data like architecture will matter
data like architecture will matter
matter a little bit parameter sweeps
matter a little bit parameter sweeps
will matter a little bit but probably
will matter a little bit but probably
just getting better data is
just getting better data is
when or like figure out like ways to
when or like figure out like ways to
augment the data or something like
that okay so
that okay so
here buffer
128 I did it on Jaz on
128 I did it on Jaz on
phones yeah if you want to do it with
phones yeah if you want to do it with
JavaScript then sure
JavaScript then sure
I was looking for a Capi to uh to Onyx
I was looking for a Capi to uh to Onyx
right cuz like if I do it in JavaScript
right cuz like if I do it in JavaScript
then I have to figure out how to get the
then I have to figure out how to get the
stupid like actions from JavaScript back
stupid like actions from JavaScript back
into the C environment and stuff it's
into the C environment and stuff it's
just such a
just such a
pain all the like multi language
stuff this is going to literally end up
stuff this is going to literally end up
being like a C file that just works
mhm yeah like people will see this and
mhm yeah like people will see this and
they'll think I'm just Ming like why the
they'll think I'm just Ming like why the
hell are you doing this in C it's like
hell are you doing this in C it's like
no I'm not I'm doing this in C because
no I'm not I'm doing this in C because
it's literally
it's literally
easier it's literally
easier and like doing this is kind of
easier and like doing this is kind of
cool um like make it like trying to get
cool um like make it like trying to get
this working in the JavaScript
this working in the JavaScript
ecosystem is going to make me
ecosystem is going to make me
demonetized
demonetized
[Laughter]
right let's check the tan H gate
is the whole tan H gate going to be like
this ah so the whole tan H is like
this ah so the whole tan H is like
this
really yeah because the numbers are too
really yeah because the numbers are too
big kage goes to one very
quickly I think we have to uh scale the
quickly I think we have to uh scale the
data down a little bit
data down a little bit
more in order to make sure that we can
more in order to make sure that we can
test this
test this
correctly thanks for the answer comp
correctly thanks for the answer comp
does mention using other publicly
does mention using other publicly
available data sets is allowed haven't
available data sets is allowed haven't
thought of much regarding
thought of much regarding
augmentation a new model or an existing
augmentation a new model or an existing
classifier for an unrelated but similar
classifier for an unrelated but similar
type of class probably fine tune
type of class probably fine tune
something
something
it's kind of difficult when you don't
it's kind of difficult when you don't
have compute for stuff right it's just
have compute for stuff right it's just
like it's so much harder to do anything
like it's so much harder to do anything
in these spaces when you like you have
in these spaces when you like you have
big models that actually require compute
big models that actually require compute
to
train we're going to add a zero here
and this what this is going to do is
and this what this is going to do is
this is going to get us into the regime
this is going to get us into the regime
where uh t h will not just always be one
where uh t h will not just always be one
so I'll actually be able to test to make
so I'll actually be able to test to make
sure that uh we match
correctly he's not joking writing it in
correctly he's not joking writing it in
C is literally
C is literally
easier I'm not doing this just because
easier I'm not doing this just because
I'm a masochist I'm not denying that I'm
I'm a masochist I'm not denying that I'm
a masochist but like I'm not doing it
a masochist but like I'm not doing it
just for the sake of masochism here
just for the sake of masochism here
right I have I have limitations there uh
right I have I have limitations there uh
it's because it is actually easier
honestly this is pretty
comfortable let me make sure we didn't
comfortable let me make sure we didn't
mess anything
up
oops
okay that's good and now we need
okay that's good and now we need
v00 which is going to be
buffer uh 256
buffer uh 256
right and does that look
right and does that look
good I think so the Precision does a
good I think so the Precision does a
little
iffy yeah no that's definitely
iffy yeah no that's definitely
correct so perfect so now we know that
correct so perfect so now we know that
these layers work let's just for the
these layers work let's just for the
just to be thorough uh let's do
just to be thorough uh let's do
like
384 uh oh wait did I do this
384 uh oh wait did I do this
wrong no no no no no fig G what's the
wrong no no no no no fig G what's the
other gate called is it
other gate called is it
o I think it's
o I think it's
O there you go okay so all the gates are
O there you go okay so all the gates are
good we now know that the lstm
good we now know that the lstm
implementation is correct all the way
implementation is correct all the way
through to here oops through like to
through to here oops through like to
here now we just need the last two lines
here now we just need the last two lines
of
of
it currently learning
DSA
DSA
[Music]
domain
domain
[Music]
[Music]
domain I literally don't know what this
domain I literally don't know what this
is I literally don't know what this is
people be the you'll be very surprised
people be the you'll be very surprised
about like the number of standard things
about like the number of standard things
that I just don't know what they are or
that I just don't know what they are or
haven't used
oh
okay well that one is definitely
useful I'm not a fan of teaching
useful I'm not a fan of teaching
beginners JavaScript Frameworks but yes
beginners JavaScript Frameworks but yes
core data structures and algorithms you
core data structures and algorithms you
definitely need to know I don't know if
definitely need to know I don't know if
that's a specific book or just like the
that's a specific book or just like the
abbreviation in general but yeah your
abbreviation in general but yeah your
first course in data structures is very
first course in data structures is very
important
it's actually very funny I think that if
it's actually very funny I think that if
I wanted to apply for like a traditional
I wanted to apply for like a traditional
software engineering job I probably
software engineering job I probably
would have been more qualified by
would have been more qualified by
interview standards after my freshman
interview standards after my freshman
year of undergrad because like they just
year of undergrad because like they just
ask you all the random basic data
ask you all the random basic data
structures
structures
crap and you don't remember the Stu like
crap and you don't remember the Stu like
the portions of that that you don't use
the portions of that that you don't use
for 10 years
let's
see I mean Stanford we just have course
see I mean Stanford we just have course
numbers on stuff
right please
guide trying to train a custom
aec two agent
environment oh a okay yeah two agent
environment oh a okay yeah two agent
environment by a see you just mean
environment by a see you just mean
turn-based
turn-based
observation space being the same and the
observation space being the same and the
actions being
actions being
different would you be willing to point
different would you be willing to point
me in the right
me in the right
direction um ah geez
direction um ah geez
so
so
yes
um I can show you how to hack
um I can show you how to hack
it so here most things don't handle a I
it so here most things don't handle a I
can make that work with
can make that work with
puffer um action spaces being different
puffer um action spaces being different
basically nothing supports
basically nothing supports
correctly
correctly
so you're going to have to like pad your
so you're going to have to like pad your
action spaces or
action spaces or
whatever in like an environment
whatever in like an environment
wrapper um with
wrapper um with
puffer there is a mask output an
puffer there is a mask output an
optional mask output that you can return
optional mask output that you can return
and what you will do is you'll basically
and what you will do is you'll basically
just set the mask to like mask out the
just set the mask to like mask out the
agent whose turn it isn't does that make
agent whose turn it isn't does that make
sense so you can just mask out whatever
sense so you can just mask out whatever
agent is not doesn't have their turn
agent is not doesn't have their turn
currently and then puffer will just work
currently and then puffer will just work
you will still have to write a rapper
you will still have to write a rapper
though to like match the action spaces
though to like match the action spaces
that is one of the very few features
that is one of the very few features
that I haven't done in puffer and like
that I haven't done in puffer and like
it's a real pain to do that like it's
it's a real pain to do that like it's
very very difficult to do that
very very difficult to do that
efficiently without messing up the whole
efficiently without messing up the whole
rest of the
rest of the
stack welcome as well
can you explain what puffer
can you explain what puffer
is
is
MHM
so I mean broadly speaking
so I mean broadly speaking
puffer is my attempt to fix all the
puffer is my attempt to fix all the
stuff that's currently wrong with
stuff that's currently wrong with
reinforcement learning so it contains a
reinforcement learning so it contains a
bunch of different
bunch of different
stuff but the high level of it is from
stuff but the high level of it is from
the uh the iceberg video which I'd
the uh the iceberg video which I'd
recommend if you haven't watched that
recommend if you haven't watched that
full thing
full thing
um it's generally low-level tools and
um it's generally low-level tools and
infrastructure to make it easy to work
infrastructure to make it easy to work
with lots of different types of
with lots of different types of
simulations and to do very fast
simulations and to do very fast
simulation as well as fast parallel
simulation as well as fast parallel
simulation
simulation
on top of that we have like sane
on top of that we have like sane
training libraries sane training
training libraries sane training
Integrations uh nice hyper parameter
Integrations uh nice hyper parameter
sweeps and other utilities that just
sweeps and other utilities that just
make it really easy to automate a lot of
make it really easy to automate a lot of
experimental research
experimental research
work so that is what puffer does
work so that is what puffer does
um Iceberg vid open will watch yeah the
um Iceberg vid open will watch yeah the
iceberg vid will really do a better job
iceberg vid will really do a better job
than I can do just off the cuff here um
than I can do just off the cuff here um
I mean that video I made it for this
I mean that video I made it for this
reason it's like 26 minutes for a
reason it's like 26 minutes for a
complete overview of the whole stack of
complete overview of the whole stack of
reinforcement learning my thoughts at
reinforcement learning my thoughts at
every single layer of the experimental
every single layer of the experimental
and infrastructure stack and what I am
and infrastructure stack and what I am
currently doing about it in
currently doing about it in
puffer what you're watching right here
puffer what you're watching right here
is a very specific small portion where
is a very specific small portion where
I'm looking at fast environments and uh
I'm looking at fast environments and uh
I'm just porting a couple like a couple
I'm just porting a couple like a couple
inference things to see so that we can
inference things to see so that we can
run demos on the web um and so that we
run demos on the web um and so that we
can have like nice contain
can have like nice contain
stuff but yeah nice haircut I did not
stuff but yeah nice haircut I did not
get a haircut nice try
though I was going to go get it cut it's
though I was going to go get it cut it's
too
too
long it gets in the way
long it gets in the way
running it's too darn hot outside
well we have the lstm matching up to the
gates so what do we think the odds are
gates so what do we think the odds are
that if I just put a breako at the end
that if I just put a breako at the end
of the
of the
function that this will
work let's try
this did you try just copy pasting code
this did you try just copy pasting code
to an l and ask it to convert to C no um
to an l and ask it to convert to C no um
that route leads to much pain and
that route leads to much pain and
suffering because I would rather just
suffering because I would rather just
write the code than and like spend my
write the code than and like spend my
time understanding the things that I've
time understanding the things that I've
done wrong and fixing those rather than
done wrong and fixing those rather than
not writing the code and spending the
not writing the code and spending the
same amount of time fixing dumb bugs
same amount of time fixing dumb bugs
that an llm has written where I have
that an llm has written where I have
like no understanding of what the hell
like no understanding of what the hell
it's trying to
it's trying to
do I generally suggest using language
do I generally suggest using language
models to save typing not thinking
okay so we have is there an output here
okay so we have is there an output here
bias
buffer what is this thing writing
buffer what is this thing writing
into wait what the heck did I make this
into wait what the heck did I make this
thing right
thing right
into oh State C State H that's
fine pain and suffering gp2 report
fine pain and suffering gp2 report
yeah VI LM is refreshing God or the
yeah VI LM is refreshing God or the
answer it's not it's really not and it's
answer it's not it's really not and it's
mostly dumb Junior developers uh who
mostly dumb Junior developers uh who
think that they can like get out of
think that they can like get out of
learning how to code
learning how to code
it's a really really dumb thing to be
it's a really really dumb thing to be
doing like here's here's the like here's
doing like here's here's the like here's
the really obvious way of putting it
the really obvious way of putting it
right like if you think that you're
right like if you think that you're
going to have value just by typing
going to have value just by typing
prompts into an llm like everybody can
prompts into an llm like everybody can
freaking do that okay so yeah you're
freaking do that okay so yeah you're
potentially right now in the next couple
potentially right now in the next couple
of years maybe you can build some cool
of years maybe you can build some cool
applications and make some money but
applications and make some money but
like thereafter you will have zero
like thereafter you will have zero
skills and zero value
skills and zero value
whatsoever like you're guaranteeing that
whatsoever like you're guaranteeing that
you will replace your so not because the
you will replace your so not because the
AI is good but because you have
AI is good but because you have
literally zero skills that's like this
literally zero skills that's like this
is why I suggest not doing
this yeah
it still will make it still will write
it still will make it still will write
tons of bugs converting languages I
tons of bugs converting languages I
tried that before um with some C code
tried that before um with some C code
and it was literally it was worse than
and it was literally it was worse than
me just writing it myself because like
me just writing it myself because like
here this is how you use language models
here this is how you use language models
to write to convert code faster I use
to write to convert code faster I use
super Maven it gives me on Line Auto
super Maven it gives me on Line Auto
completes so basically I'm tabbing on
completes so basically I'm tabbing on
line completions making sure that each
line completions making sure that each
line is exactly as I want it so it's
line is exactly as I want it so it's
like I can type 200 wpm I'm still doing
like I can type 200 wpm I'm still doing
all the thinking but it's like I no
all the thinking but it's like I no
longer am limited by me only being able
longer am limited by me only being able
to type 80 wpm or whatever and I get
to type 80 wpm or whatever and I get
like a 30 40% productivity boost out of
like a 30 40% productivity boost out of
it that is what I
it that is what I
recommend that is how you actually use
recommend that is how you actually use
AI to increase productivity without like
AI to increase productivity without like
reduce like without rotting your brain
basically you written inside see wait
basically you written inside see wait
did I miss a
message did I miss a me wait I think I
message did I miss a me wait I think I
missed a couple messages here would it
missed a couple messages here would it
even be smart to do
that is it Poss okay I miss some stuff
that is it Poss okay I miss some stuff
is it possible to build the environment
is it possible to build the environment
entirely in puffer or should I use
entirely in puffer or should I use
petting zoo and wrap it with puffer um
petting zoo and wrap it with puffer um
you can do either uh pu puffer supports
you can do either uh pu puffer supports
petting zoo and petting zoo parallel API
petting zoo and petting zoo parallel API
mind you and um um gymnasium natively so
mind you and um um gymnasium natively so
we have support for that there's also an
we have support for that there's also an
advanced thing you can do with puffer if
advanced thing you can do with puffer if
you really want extra speed so like the
you really want extra speed so like the
new environments I'm working on use the
new environments I'm working on use the
advanced API because we want a million
advanced API because we want a million
plus STS per second per
core my environment is very simple it
core my environment is very simple it
depends how fast you want to train on it
depends how fast you want to train on it
right like even for very simple
right like even for very simple
environments I can get simple
environments I can get simple
environment is training at over a
environment is training at over a
million steps per second so when you can
million steps per second so when you can
do that you can basically automate
do that you can basically automate
everything what is the mini grid M I'm
everything what is the mini grid M I'm
trying puffer lip for the first
trying puffer lip for the first
time um if you look up minig Grid it's
time um if you look up minig Grid it's
like a commonly used very simple
like a commonly used very simple
learning Benchmark we have Integrations
learning Benchmark we have Integrations
for that we have Atari we've got proc
for that we have Atari we've got proc
genen um I mean they're like a dozen
genen um I mean they're like a dozen
plus standard environments with puffer
plus standard environments with puffer
Li bindings for
it we basically like we have all the
it we basically like we have all the
standard stuff in puffer our goal is not
standard stuff in puffer our goal is not
to make your life more complicated by
to make your life more complicated by
introducing a bunch of new stuff you
introducing a bunch of new stuff you
don't need right we have all the
don't need right we have all the
standard tools exactly the way that
standard tools exactly the way that
you'd want them and they're faster than
you'd want them and they're faster than
the Alternatives that's what puffer lip
the Alternatives that's what puffer lip
gives you now if once you've done that
gives you now if once you've done that
right if you want to go a little bit
right if you want to go a little bit
deeper if you want to use our custom
deeper if you want to use our custom
environments if you want to write Ultra
environments if you want to write Ultra
ultra high performance simulations in
ultra high performance simulations in
order to make your research or your work
order to make your research or your work
even if you're an industry go a hundred
even if you're an industry go a hundred
times faster we have stuff for that as
times faster we have stuff for that as
well but it's not required you can get
well but it's not required you can get
benefit out of puffer lib immediately
benefit out of puffer lib immediately
without having to learn basically any
without having to learn basically any
new stuff if you've already done a
new stuff if you've already done a
little
RL and in case there are any industry
RL and in case there are any industry
folks here we do have support packages
co-pilot is fine just don't use it to
co-pilot is fine just don't use it to
write huge chunks of code for
you let's see
is this
is this
right
153 that looks good to
153 that looks good to
me um let's do
me um let's do
like
like
129 which should be I think like one
129 which should be I think like one
one well that doesn't work
oh one one yeah okay so the actually
oh one one yeah okay so the actually
this is complete this is completely
this is complete this is completely
correct which is kind of
correct which is kind of
cool let's do like what's this
cool let's do like what's this
257 no not yeah that's perfect
Joseph had trouble with Pip install d e
Joseph had trouble with Pip install d e
dot on
dev I probably broke the mooba build on
dev I probably broke the mooba build on
dev is what probably happened is that
dev is what probably happened is that
what is that what was it is that what it
was yeah okay I'll fix that my
bad let me fix this thing here it's just
bad let me fix this thing here it's just
I I put it in the same file I should
I I put it in the same file I should
have made a different
file I am allowed to break things on the
file I am allowed to break things on the
dev
Branch you can you can yell at me if I
Branch you can you can yell at me if I
break things on like on the stable
break things on like on the stable
branches on the dev Branch this is how
branches on the dev Branch this is how
it is supposed to work if I break a
it is supposed to work if I break a
thing by doing Dev fast you just come
thing by doing Dev fast you just come
here and tell
me I will fix that as soon as I as soon
me I will fix that as soon as I as soon
as I finish checking this one little
as I finish checking this one little
thing
here I want to contribute and want to
here I want to contribute and want to
break some stuff great let me uh here
break some stuff great let me uh here
let me just open real quick for folks
let me just open real quick for folks
watching
watching
if you're like either maybe new to
if you're like either maybe new to
reinforcement learning new to ml as a
reinforcement learning new to ml as a
whole whatever as long as you have some
whole whatever as long as you have some
development experience um building some
development experience um building some
cool RL environments is a really good
cool RL environments is a really good
way to get
way to get
involved now you can of course make
involved now you can of course make
contributions to the infrastructure and
contributions to the infrastructure and
stuff that's a lot harder but um if
stuff that's a lot harder but um if
you're just looking for like a fun way
you're just looking for like a fun way
to get into some RL let me see if I can
to get into some RL let me see if I can
find some of these environments in
find some of these environments in
here some of you might have uh might be
here some of you might have uh might be
familiar with this somebody's been
familiar with this somebody's been
building um like a Ultra ultra high
building um like a Ultra ultra high
performance uh clone of this old MMO
performance uh clone of this old MMO
called
called
dopus the combat system from it for an
dopus the combat system from it for an
environment we also have a few Atari
environment we also have a few Atari
environments that people have been
environments that people have been
making so like I think Noah might even
making so like I think Noah might even
still be around
still be around
here he's got pong no he's got breakout
here he's got pong no he's got breakout
and
and
then let's see yeah so so here is
then let's see yeah so so here is
stupidly high performance version of
stupidly high performance version of
pong we're going to try to replace some
pong we're going to try to replace some
of the Atari
of the Atari
environments here's like stupidly high
environments here's like stupidly high
performance version of
performance version of
breakout goal is going to be to replace
breakout goal is going to be to replace
tons and tons of environments with ultra
tons and tons of environments with ultra
ultra high performance
versions train and evalu on minig grid
versions train and evalu on minig grid
looks cool seeing the agent complete the
looks cool seeing the agent complete the
tasks yeah it should it's uh that's a
tasks yeah it should it's uh that's a
pretty simple task set also mini grid
pretty simple task set also mini grid
that is uh it would probably only take
that is uh it would probably only take
me a couple days to restructure the grid
me a couple days to restructure the grid
environment that I have to do all of
environment that I have to do all of
mini Rd at a million plus STS per second
mini Rd at a million plus STS per second
probably could get more than
that sioning space from
that sioning space from
o yo
o yo
bet that's a test environment that one
bet that's a test environment that one
doesn't have to be any faster that one's
doesn't have to be any faster that one's
literally like a 10sec test environment
literally like a 10sec test environment
anyways
like if you want to be building stuff
like if you want to be building stuff
like build some cool game environments
like build some cool game environments
right or or other types of environments
right or or other types of environments
right just like build some cool high
right just like build some cool high
perf
perf
simulators baby steps syon is really
simulators baby steps syon is really
easy to get used to so you don't have to
easy to get used to so you don't have to
be writing C to contribute to puffer at
be writing C to contribute to puffer at
all um probably you'll want to write in
all um probably you'll want to write in
like scyon or something because python
like scyon or something because python
itself is slow but if you haven't used
itself is slow but if you haven't used
python before it's literally you just
python before it's literally you just
write python add some types and boom now
write python add some types and boom now
it runs 100 times faster it's that
easy and the C is nowhere near as bad as
easy and the C is nowhere near as bad as
it looks if you're not used to
it looks if you're not used to
that but that's not required
28 lstm
28 lstm
Works would you be open to an aec
Works would you be open to an aec
implementation PR uh of course but I
implementation PR uh of course but I
don't know if you know how I don't know
don't know if you know how I don't know
if you know what you're getting yourself
if you know what you're getting yourself
into there is the thing um the reason
into there is the thing um the reason
that aec is hard is because well think
that aec is hard is because well think
about it right like you're getting
about it right like you're getting
observations from different agents at
observations from different agents at
different time steps so like if you're
different time steps so like if you're
going to use an lstm policy or even just
going to use an lstm policy or even just
for generalized Advantage estimation and
for generalized Advantage estimation and
such you need to keep track of which
such you need to keep track of which
agent comes from which environment aec
agent comes from which environment aec
is this it's basically turn-based um
is this it's basically turn-based um
it's like petting Zoo's name for
it's like petting Zoo's name for
turn-based environments so I've been
turn-based environments so I've been
thinking about that quite a bit Cole and
thinking about that quite a bit Cole and
the solution that I have in puffer lib
the solution that I have in puffer lib
is quite good I think it's going to be a
is quite good I think it's going to be a
lot faster than a lot faster and a lot
lot faster than a lot faster and a lot
less error prone then unless you have a
less error prone then unless you have a
really good idea in mind for it let me
really good idea in mind for it let me
explain how puffer lib does this real
quick I heard turnbas yeah so Nathan
quick I heard turnbas yeah so Nathan
this is relevant to for you as well for
this is relevant to for you as well for
your um your like dopus
your um your like dopus
environment God can I find okay here
environment God can I find okay here
so this is why turnbas is hard right so
so this is why turnbas is hard right so
normally when you get an environment
normally when you get an environment
right you have like agent One agent
right you have like agent One agent
two dot dot dot right and then this is
two dot dot dot right and then this is
going to give you
OBS and then these are going to go into
OBS and then these are going to go into
your model right which is like I don't
your model right which is like I don't
know some Com or whatever um and this
know some Com or whatever um and this
this one goes in this one goes in but
this one goes in this one goes in but
then also you have an lstm state right
and you need to grab like the state
and you need to grab like the state
variables right S1 S2 and these need to
variables right S1 S2 and these need to
go into here as
go into here as
well um even if you don't have an lstm
well um even if you don't have an lstm
you still need to keep track of which
you still need to keep track of which
OBS comes from which agent because then
OBS comes from which agent because then
what's going to happen is you're going
what's going to happen is you're going
to save this into a buffer right so you
to save this into a buffer right so you
have like A1 and you have like 01
have like A1 and you have like 01
o02 03
o02 03
and then you're going to do generalized
and then you're going to do generalized
Advantage estimation over
this which is very important but like if
this which is very important but like if
you're going to take away one of these
you're going to take away one of these
at a time then what happens well now you
at a time then what happens well now you
mess up all your indexing and you mess
mess up all your indexing and you mess
up your ability to like pack batches of
up your ability to like pack batches of
data so what puffer does for this is we
data so what puffer does for this is we
have a mask variable this is already
have a mask variable this is already
integrated with um our default training
integrated with um our default training
implementation what we do is we give you
implementation what we do is we give you
the option to return like a
the option to return like a
mask and then what happens when you do
mask and then what happens when you do
that is uh this observation just never
that is uh this observation just never
gets into the buffer so we actually have
gets into the buffer so we actually have
buffers that support
buffers that support
this but you still need to have like
this but you still need to have like
this mask essentially which is a little
this mask essentially which is a little
bit
bit
inefficient but um there's not really a
inefficient but um there's not really a
clear way to do this
clear way to do this
otherwise at least without massively
otherwise at least without massively
degrading the performance of vector
degrading the performance of vector
ation so I hope that gives you a rough
ation so I hope that gives you a rough
answer call like like you can already do
answer call like like you can already do
it in puffer and it's probably going to
it in puffer and it's probably going to
be way faster than anything else out
be way faster than anything else out
there just if you use this mask variable
there just if you use this mask variable
and the algorithm will be
correct I mean if you just want to look
correct I mean if you just want to look
at like our
vectorization just to show you what a
vectorization just to show you what a
massive difference that we have in
massive difference that we have in
performance and this is dated it's even
performance and this is dated it's even
faster
now you know we take a car Atari up from
now you know we take a car Atari up from
4.8k to 25k proen from 40K to 150 the
4.8k to 25k proen from 40K to 150 the
really fast environments go from 100K to
really fast environments go from 100K to
Millions right even for environments
Millions right even for environments
where like they're pretty slow and
where like they're pretty slow and
there's it's really easy to make them
there's it's really easy to make them
fast uh it's really hard to make them
fast uh it's really hard to make them
any faster like we go from 5 to 7.2
any faster like we go from 5 to 7.2
right we can run environments like
right we can run environments like
neural MMO that just gymnasium will
neural MMO that just gymnasium will
straight up fail on for
straight up fail on for
multi-agent um we've got like net hack
multi-agent um we've got like net hack
over 10x faster Mini grid 4X faster so
over 10x faster Mini grid 4X faster so
the perf is
there yeah Splinter check um the link
there yeah Splinter check um the link
the snake
link and for
reference on my way to Iceberg see you
thanks and for reference up until a few
thanks and for reference up until a few
days
days
ago this like entire MOA
ago this like entire MOA
EnV was uh implemented in pure
EnV was uh implemented in pure
syon so like this whole game was
syon so like this whole game was
implemented in
implemented in
syon only reason I'm doing C now is so I
syon only reason I'm doing C now is so I
can put it on the
can put it on the
web zon's plenty
web zon's plenty
fast do you do a masking for open Spiel
fast do you do a masking for open Spiel
Ms yeah so I think I only ever
Ms yeah so I think I only ever
integrated uh Connect 4 with that cuz I
integrated uh Connect 4 with that cuz I
had somebody that was trying to do
had somebody that was trying to do
Connect 4 but yeah you would mask for
Connect 4 but yeah you would mask for
that that's how we that's how we were
that that's how we that's how we were
handling it for um for open
Spiel I actually don't know how fast the
Spiel I actually don't know how fast the
open Spiel ends are they might already
open Spiel ends are they might already
be faster they might not
I'll see what I can come up with doesn't
I'll see what I can come up with doesn't
seem like anything implements turn based
seem like anything implements turn based
because I've thought about it a lot Cole
because I've thought about it a lot Cole
and the infrastructure for it is just
and the infrastructure for it is just
like it doesn't make sense with
like it doesn't make sense with
vectorization
vectorization
because you would have to change the
because you would have to change the
whole
whole
API you'd essentially have to change the
API you'd essentially have to change the
whole API and like the way that we get
whole API and like the way that we get
our vectorization fast is by passing
our vectorization fast is by passing
around like static chunks of
around like static chunks of
memory um and it's very difficult to do
memory um and it's very difficult to do
that when you have
that when you have
variable like variable agent turns and
variable like variable agent turns and
stuff but I don't think that there's a
stuff but I don't think that there's a
really good way of doing that any faster
really good way of doing that any faster
than we have it right
now
now
yeah I mean there are a couple
yeah I mean there are a couple
relatively easy optimizations that I can
relatively easy optimizations that I can
potentially think of but uh for the time
potentially think of but uh for the time
being you're we're probably like I would
being you're we're probably like I would
just use the puffer version for now and
just use the puffer version for now and
if you have a relatively simple
if you have a relatively simple
environment like puffer will probably
environment like puffer will probably
just Auto solve it in less than a
minute this is not a problem of um
minute this is not a problem of um
Nathan this is not a problem of
Nathan this is not a problem of
like there's no algorithmic problem here
like there's no algorithmic problem here
it's just literally like you have to be
it's just literally like you have to be
careful with the way that you're storing
careful with the way that you're storing
agent observations and the like if
agent observations and the like if
they're going to come from variable
sources so somehow while answering all
sources so somehow while answering all
these questions um I think we actually
these questions um I think we actually
got somewhere here
got somewhere here
because this is correct so we now have
because this is correct so we now have
an lstm implemented in C so that's
an lstm implemented in C so that's
cool
cool
right yeah this is now correct
so let's let's look at how cool this is
so let's let's look at how cool this is
real quick let's just take a moment to
real quick let's just take a moment to
appreciate how cool this is um from the
appreciate how cool this is um from the
top I guess from right here
top I guess from right here
21 down to
134 so like literally 100 lines of code
134 so like literally 100 lines of code
for an lstm convolution reu sigmoid T
for an lstm convolution reu sigmoid T
linear layers in C so literally it's 100
linear layers in C so literally it's 100
lines of code to just do all of this
lines of code to just do all of this
stuff so now it's compatible with web
stuff so now it's compatible with web
and we can run it
and we can run it
anywhere right we didn't need some crazy
anywhere right we didn't need some crazy
heavy framework we didn't need to deal
heavy framework we didn't need to deal
with like figuring out how to force onx
with like figuring out how to force onx
to work in C we didn't need to do any of
to work in C we didn't need to do any of
that it's 100 lines of C code
and we can probably make this shorter
and we can probably make this shorter
too
if anybody knows how to combine these
if anybody knows how to combine these
two functions into one function without
two functions into one function without
me having to put an if right here let me
me having to put an if right here let me
know are you still in the Academia
know are you still in the Academia
space are you commercial
space are you commercial
now um I'm not in Academia puffer is
now um I'm not in Academia puffer is
technically a startup we just launched
technically a startup we just launched
just a couple days ago officially um so
just a couple days ago officially um so
this is a company and we do offer
this is a company and we do offer
support packages so you know if you're
support packages so you know if you're
an Academia if you know fol in Academia
an Academia if you know fol in Academia
who could benefit from having RL not be
who could benefit from having RL not be
just a complete pain to work with and do
just a complete pain to work with and do
anything let me know but all of our
anything let me know but all of our
stuff is free and open source we're
stuff is free and open source we're
pretty much just selling extended
pretty much just selling extended
support and priority features and a
support and priority features and a
couple extra services around
that and I will say that the progress in
that and I will say that the progress in
the last few months has been very very
the last few months has been very very
rapid compared to Academia here it's
rapid compared to Academia here it's
been very very rapid progress
so the one thing I'd really like to have
so the one thing I'd really like to have
here is I'd like to have a test in C
here is I'd like to have a test in C
somehow I mean not in C I'd like to have
somehow I mean not in C I'd like to have
like an automated test for this I'm
like an automated test for this I'm
trying to think how we can do that
trying to think how we can do that
though
can you get detailed profiling like in
can you get detailed profiling like in
scyon yeah I'm sure I
can I only asked because I watched your
can I only asked because I watched your
thesis defense wondered what your next
thesis defense wondered what your next
thing was cool puffers fulltime nicely
thing was cool puffers fulltime nicely
thank you yeah no puffer is I think that
thank you yeah no puffer is I think that
this is going to change the whole field
this is going to change the whole field
very very quickly I mean when you can
very very quickly I mean when you can
just run like tens of billions of steps
just run like tens of billions of steps
worth of experiments per GPU per day
worth of experiments per GPU per day
field is a whole different place right
field is a whole different place right
it's like I said in the iceberg video If
it's like I said in the iceberg video If
you haven't seen that one I highly
you haven't seen that one I highly
recommend that seems like YouTube has
recommend that seems like YouTube has
not picked up on this video yet but uh
not picked up on this video yet but uh
at least I personally I thought I did I
at least I personally I thought I did I
thought the delivery was way better than
thought the delivery was way better than
my thesis we'll see if people agree with
my thesis we'll see if people agree with
that and if it just takes a little while
that and if it just takes a little while
to get into the algorithm but yeah yeah
to get into the algorithm but yeah yeah
okay be quiet you but yeah this I posted
okay be quiet you but yeah this I posted
this a few days ago now
has all my thoughts on RL in the
field all in one
place let me figure out how we're going
place let me figure out how we're going
to write this test because kind of what
to write this test because kind of what
I want to get done today um what I want
I want to get done today um what I want
to get done
to get done
today I have the working lstm I have
today I have the working lstm I have
working linear layer I have working comp
working linear layer I have working comp
layer which is technically enough to
layer which is technically enough to
build whatever I want um but these
build whatever I want um but these
functions are kind of Jank I want to at
functions are kind of Jank I want to at
least add like a a little bit of
least add like a a little bit of
structure to this just a tiny
bit and I don't want to break them in
bit and I don't want to break them in
the process so I'd like to figure out
the process so I'd like to figure out
how to have an automated
how to have an automated
test
um it's just a little bit obnoxious
um it's just a little bit obnoxious
because I'm technically relying on P
because I'm technically relying on P
torch and uh C code I guess technically
torch and uh C code I guess technically
I can just write the outputs to a right
I can just write the outputs to a right
and just compare the two
and just compare the two
files clicked on your thesis video cuz I
files clicked on your thesis video cuz I
saw a game in the thumbnail yeah fair
saw a game in the thumbnail yeah fair
enough we talk about lots of like RL and
enough we talk about lots of like RL and
game stuff in uh the puffer video it's a
game stuff in uh the puffer video it's a
very good overview of like the field hey
very good overview of like the field hey
Tenny
Tenny
welcome we're working on some stuff here
welcome we're working on some stuff here
I think what we're going to do is we're
I think what we're going to do is we're
going to take the next little bit to
going to take the next little bit to
build out some tests for this
what's bet what
what's bet what
is problem with views is the iceberg is
is problem with views is the iceberg is
not Normie friendly no the iceberg video
not Normie friendly no the iceberg video
is actually way more accessible than my
is actually way more accessible than my
thesis like the stuff in the iceberg
thesis like the stuff in the iceberg
video is actually like I threaded it
video is actually like I threaded it
through with like higher level stuff
through with like higher level stuff
that should be more
that should be more
accessible writing to two files and
accessible writing to two files and
comparing yeah it is kind of Jang but
comparing yeah it is kind of Jang but
what else would you have me do right
what else would you have me do right
like I have to have like otherwise I
like I have to have like otherwise I
have to bind this
I would I could write like a scon
I would I could write like a scon
binding for this and then call it from
binding for this and then call it from
python I guess
python I guess
right maybe that's
better I mean how bad would that
better I mean how bad would that
be let's say that I just take all these
be let's say that I just take all these
I put these into like puffer net. C or
I put these into like puffer net. C or
whatever I make like Puffer net. I make
whatever I make like Puffer net. I make
a scon
a scon
binding I import that into a python test
binding I import that into a python test
file that could work
file that could work
right maybe we will just do
right maybe we will just do
that that would be cleaner and I
that that would be cleaner and I
wouldn't have to do like the right
wouldn't have to do like the right
function and
see
see
yeah you've convinced
me what the heck is
me what the heck is
this oh yeah we don't need
this upper.
this upper.
C we don't need the
MOBA load weights can go at the bottom
MOBA load weights can go at the bottom
right so we'll just clean this up oops
right so we'll just clean this up oops
not
not
below the main file but we're not going
below the main file but we're not going
to even need a main
to even need a main
function and this is actually just going
function and this is actually just going
to be a h not a
c what are you working
c what are you working
on since we have some more people I'll
on since we have some more people I'll
go over quickly
go over quickly
so right now my main thing with puffer
so right now my main thing with puffer
lib for the next few weeks is ultra high
lib for the next few weeks is ultra high
performance simulation just making lots
performance simulation just making lots
of really good environments so that we
of really good environments so that we
can get experiments going in RL um part
can get experiments going in RL um part
of that is making it accessible so that
of that is making it accessible so that
people can actually see these
people can actually see these
environments and play around with them
environments and play around with them
and see what's going on so I have these
and see what's going on so I have these
running in the web like this is a MOBA
running in the web like this is a MOBA
that I wrote we're going to get more
that I wrote we're going to get more
environments into web soon this is
environments into web soon this is
written 100% in C compiles to web
written 100% in C compiles to web
assembly runs it a million steps per
assembly runs it a million steps per
second so it's very very efficient to
second so it's very very efficient to
play around with this thing and all
play around with this thing and all
different characters and whatever it's a
different characters and whatever it's a
very efficient environment for research
very efficient environment for research
it's a very efficient environment for um
it's a very efficient environment for um
testing out your RL methods it's great
testing out your RL methods it's great
but in order to actually have these guys
but in order to actually have these guys
do something and not just have me
do something and not just have me
controlling them right I want to have my
controlling them right I want to have my
RL bot actually control them so that you
RL bot actually control them so that you
can watch what the RL agents do and you
can watch what the RL agents do and you
can play around against the RL agents
can play around against the RL agents
and stuff like that and generally that's
and stuff like that and generally that's
just a really useful route to go and
just a really useful route to go and
it's not that hard all I have to do is
it's not that hard all I have to do is
make a few of the P torch layers work in
make a few of the P torch layers work in
C and then I can compile them to web
C and then I can compile them to web
assembly and then we can run them in
assembly and then we can run them in
browser so that's what I'm doing now
browser so that's what I'm doing now
that might sound kind of crazy but it's
that might sound kind of crazy but it's
only like 100 lines of C for linear lstm
only like 100 lines of C for linear lstm
convolution it's already done now all I
convolution it's already done now all I
have to do is make sure I don't break
have to do is make sure I don't break
this stuff because it's very easy to
this stuff because it's very easy to
break it write a couple quick
break it write a couple quick
tests I've already man manually tested
tests I've already man manually tested
it but I need to have like an automatic
it but I need to have like an automatic
test so that when I go to refactor this
test so that when I go to refactor this
a little bit in an hour or so as soon as
a little bit in an hour or so as soon as
I finish that I don't break it by
I finish that I don't break it by
mistake because like right now I've done
mistake because like right now I've done
all of this stuff with just like raw
all of this stuff with just like raw
pointers and it works but you have to be
pointers and it works but you have to be
very very careful about like you know
very very careful about like you know
making sure that you compute the offset
making sure that you compute the offset
in memory to your bias term correctly
in memory to your bias term correctly
and things like that and some of this I
and things like that and some of this I
can just make a lot easier so I want to
can just make a lot easier so I want to
do that refactor but not until I have a
do that refactor but not until I have a
quality test so yeah
quality test so yeah
you
could equally fast if factor is
const
um I don't know if that quite works
um I don't know if that quite works
because we need to use both of these
because we need to use both of these
functions
Stein but actually just reading your
Stein but actually just reading your
thing I got an idea as to how we can do
thing I got an idea as to how we can do
this with one function uh one function
this with one function uh one function
up here so you've jogged my memory so
up here so you've jogged my memory so
thanks for that do you think RL is
thanks for that do you think RL is
superior to evolutionary
superior to evolutionary
strategies
um if we're speaking generally then yes
um if we're speaking generally then yes
because the problem with es is that it
because the problem with es is that it
bets against Hardware like the classic
bets against Hardware like the classic
implementation of es um doesn't really
implementation of es um doesn't really
benefit from GPU it it really is like a
benefit from GPU it it really is like a
CPU type implement mentation it's a
CPU type implement mentation it's a
really bad idea to bet against advances
really bad idea to bet against advances
in
in
Hardware um it's also like you're not
Hardware um it's also like you're not
actually getting a good gradient signal
actually getting a good gradient signal
you need a ton of samples to approximate
you need a ton of samples to approximate
gradients
gradients
uh so it's very difficult to scale that
uh so it's very difficult to scale that
stuff and we just generally we haven't
stuff and we just generally we haven't
seen anything crazy come out of es
seen anything crazy come out of es
yet yeah I haven't really seen any super
yet yeah I haven't really seen any super
crazy results come out of es there was
crazy results come out of es there was
some cool stuff from like Ken and Jeff's
some cool stuff from like Ken and Jeff's
Uber group several years back but uh I
Uber group several years back but uh I
haven't seen anything since
then let's get puffer net. C written
then let's get puffer net. C written
real quick holy viewers welcome
real quick holy viewers welcome
everybody I promise we're going to
everybody I promise we're going to
actually like Buckle in and like write
actually like Buckle in and like write
these tests in a second so we can get
these tests in a second so we can get
some more stuff happening but I will
some more stuff happening but I will
just one last time since we're so close
just one last time since we're so close
to hitting this milestone
to hitting this milestone
like 15 stars to go until a th on puffer
like 15 stars to go until a th on puffer
so you want to make that happen help me
so you want to make that happen help me
out
guys okay so we don't really need any of
guys okay so we don't really need any of
this this stuff in here right all this
this this stuff in here right all this
stuff is just
Jank at least we don't need this stuff
we'll consider whether we need the rest
we'll consider whether we need the rest
of this test to be here or we're going
of this test to be here or we're going
to put this portion of the test in
to put this portion of the test in
Python uh get out what's this we don't
Python uh get out what's this we don't
use
use
this so lstm con sigmoid re linear okay
this so lstm con sigmoid re linear okay
so this is
good buffet. c
good buffet. c
buffet. h
now we need to make a a puffet scon file
now we need to make a a puffet scon file
right in order to make a python
binding hello this is Amos
binding hello this is Amos
welcome we're writing some C
Nets uh I'm going to want just the
Nets uh I'm going to want just the
prototypes of all these
prototypes of all these
functions right
which is if I wrote If I actually wrote
which is if I wrote If I actually wrote
a proper. h file you know
but we don't really do that
but we don't really do that
much maybe I should consider doing it I
much maybe I should consider doing it I
don't
don't
know the only thing that's making me
know the only thing that's making me
tempted to write proper. H files is that
tempted to write proper. H files is that
um you know H and C instead of just all
um you know H and C instead of just all
H is that you end up needing the
H is that you end up needing the
prototypes for scon anyways though I
prototypes for scon anyways though I
think they we still need it you'd like
think they we still need it you'd like
need like another set of
need like another set of
them only 14 to go to 1K thank you for
them only 14 to go to 1K thank you for
your support it helps a
your support it helps a
ton it really helps a
ton it really helps a
ton Factor should be an argument to
ton Factor should be an argument to
function I'mma head out till next week
function I'mma head out till next week
see you
see you
around thanks for dropping
by I already grabbed this
by I already grabbed this
one so we just need the LS M
one so we just need the LS M
right yeah look at that mess of a
right yeah look at that mess of a
signature okay so these are our
signature okay so these are our
functions and I need to go just grab a
functions and I need to go just grab a
little bit of
um what is it
simoa yeah so I just want to grab this
simoa yeah so I just want to grab this
just boiler
plate so we have all these flags on oop
plate so we have all these flags on oop
profile should be
false and we don't we do we need any of
false and we don't we do we need any of
this stuff I think we do need the numpy
this stuff I think we do need the numpy
apis we're not going to need all the
apis we're not going to need all the
other
stuff uh I think I need all of the
stuff uh I think I need all of the
function prototypes right so we'll
function prototypes right so we'll
do I can literally just copy these in
do I can literally just copy these in
can I like this
this
work and then if I can get a binding for
work and then if I can get a binding for
this going hold on I'm trying to
this going hold on I'm trying to
remember how I did this in the scon
remember how I did this in the scon
version here
version here
so I defined all these types right and
so I defined all these types right and
then how did I bind
then how did I bind
them
them
knit yeah I need this I need this logic
knit yeah I need this I need this logic
here to remind me how to do the casts
here to remind me how to do the casts
from uh from scyon
from uh from scyon
side I think that what you do
is we're going to end up with name
is we're going to end up with name
complex right
well I think this does
it yeah you just need like these wrapper
it yeah you just need like these wrapper
type things
type things
right and then
right and then
right
right
here you need to
here you need to
cast I think I think you need explicit
cast I think I think you need explicit
cast on stuff and they're formatted a
cast on stuff and they're formatted a
little weird so it's like bloat
little weird so it's like bloat
star input data looat star weight
star input data looat star weight
data uh looat
data uh looat
star this cast in tax is uh weird in
star this cast in tax is uh weird in
syon but the alternative Buy that I
syon but the alternative Buy that I
found for C like I think syon is
found for C like I think syon is
generally the easiest for numerical
generally the easiest for numerical
Computing at least I haven't found
Computing at least I haven't found
anything that I like more than cython so
anything that I like more than cython so
far uh we'll clean up the Syntax for
far uh we'll clean up the Syntax for
this in a bit but yeah I think now this
this in a bit but yeah I think now this
should auto complete right yeah this
should auto complete right yeah this
will just auto
complete let me make sure that this
complete let me make sure that this
didn't mess anything
didn't mess anything
up looks fine
okay so now we have a 50 line scon
okay so now we have a 50 line scon
binding for puffer net
binding for puffer net
and now what we do is we make a python
and now what we do is we make a python
file called test puffet
file called test puffet
right oops
and we don't need
this I want to figure out
this I want to figure out
there's there's a scyth online to like
there's there's a scyth online to like
one line pix import or
one line pix import or
whatever I guess for now we'll just do
whatever I guess for now we'll just do
from
from
puffer lib environment oceans
MOA puffer
net puffer
net and
net and
then
then
yeah death test
yeah death test
puffet linear player
we'll just make some like batch size is
we'll just make some like batch size is
16 hidden size input size
16 hidden size input size
right the test linear
right the test linear
layer uh and then we'll just
do data
a
range
range
space something like
space something like
this I know if it needs to be
reshaped pull this up on the side
ceret do c
ceret do c
oops H I
oops H I
guess so we have linear
guess so we have linear
layer and now we need to
layer and now we need to
do
do
p make dummy
p make dummy
data Waits
and this needs to take args
right inputs num Pi is going to
right inputs num Pi is going to
be input
be input
size uh weight NP is going to be input
size uh weight NP is going to be input
size times hidden size hidden size
size times hidden size hidden size
output
output
NP
NP
puts
puts
equals
equals
zeros size times hidden size
rightee
rightee
to okay so now we have this data right
to okay so now we have this data right
and we do Huffer
and we do Huffer
net. Huffer net linear layer
and now we have to do the torch
data
data
TCH it's going to
TCH it's going to
be this and then we do want separate
be this and then we do want separate
zero function like
zero function like
this and then we just
do uh
do uh
torch linear equal
torch linear equal
torch. nn.
linear we don't need this output because
linear we don't need this output because
torch is not in
place we do like this right and then
place we do like this right and then
what we have to do is we need to have
what we have to do is we need to have
like an assert all near like
like an assert all near like
so
so
assert
assert
near a b
oh I think you can just do
oh I think you can just do
this
right yeah but let's do it let's do it
right yeah but let's do it let's do it
this way so that we can do have the
this way so that we can do have the
shapes match uh
numpy we'll just do both numpy
right
right
yeah assert near a b so assert a do
yeah assert near a b so assert a do
shape is B do shape and then assert NP
shape is B do shape and then assert NP
all less than 1 minus
all less than 1 minus
6 okay and now we'll do assert
6 okay and now we'll do assert
near
near
numpy
numpy
perfect so this is the basic form of our
perfect so this is the basic form of our
tests right is that we
tests right is that we
have some dummy
data and then we have the same dummy
data and then we have the same dummy
data and we want to make sure that our
data and we want to make sure that our
uh our two things match
has offer net
linear puffer net. pyx
right this compile
uh
yeah I see your error bet let me fix
yeah I see your error bet let me fix
that real
quick what happened here expected zero
quick what happened here expected zero
got
11 what the heck
do we use this file we do right this is
do we use this file we do right this is
our main
binding well this definitely
binding well this definitely
takes
margs MOBA
star expected zero args
yeah that's really weird this was
yeah that's really weird this was
working
before oh uh I think I
before oh uh I think I
know yeah I think I know so
let's just change I think that we just
let's just change I think that we just
forgot to change
this
no okay we're going to comment this for
no okay we're going to comment this for
now but I will fix this today
now but I will fix this today
bet you can yell at me if I
bet you can yell at me if I
don't I think that we just were defining
don't I think that we just were defining
the same thing multiple I think that
the same thing multiple I think that
it's CU I have multiple different scon
it's CU I have multiple different scon
things I need to fully Port from the old
things I need to fully Port from the old
version to the new version is
version to the new version is
all uh so let's see what do we have
all uh so let's see what do we have
here Huffer net.
here Huffer net.
H apparently we use a couple
depths is it do we need standard
depths is it do we need standard
IO I think we need standard bull
why can't I
type we need math as
well MOA star in it MOA and puffer tank
well MOA star in it MOA and puffer tank
has empty
parenthesis I don't know scyon
oh I think you're
right hold
on
on
ah yeah this is you're right
here thank
you I forgot cuz I was just adding like
you I forgot cuz I was just adding like
a prototype or something so I forgot
a prototype or something so I forgot
that I actually had to like yeah it's
that I actually had to like yeah it's
one really obnoxious thing about scyon
one really obnoxious thing about scyon
is that you have to give it the whole
is that you have to give it the whole
signature for everything even though
signature for everything even though
it's already defined in C I don't know
it's already defined in C I don't know
why but it's really
why but it's really
obnoxious so like the fact that syon
obnoxious so like the fact that syon
essentially makes you do header files
essentially makes you do header files
anyways makes it really really redundant
anyways makes it really really redundant
to have to split your code into headers
to have to split your code into headers
and the source c as
well thanks for the fix
comparison
of we don't need this
right um agents we don't need any of
right um agents we don't need any of
this crap in puffer
net we have one warning here
net we have one warning here
different
signedness
Waits good by me what are the craziest
Waits good by me what are the craziest
RL simulations you've
RL simulations you've
seen well it depends what you mean like
seen well it depends what you mean like
they didn't rewrite DOTA for RL or
they didn't rewrite DOTA for RL or
anything for uh open A5 right like it's
anything for uh open A5 right like it's
the craziest use of RL I've ever seen
the craziest use of RL I've ever seen
and in fact in my video I say that I
and in fact in my video I say that I
consider DOTA to be the top result ever
consider DOTA to be the top result ever
in all of RL um but as for like people
in all of RL um but as for like people
who've coded up some crazy
who've coded up some crazy
simulations I think I'm at least in the
simulations I think I'm at least in the
top five there with the stuff that I've
top five there with the stuff that I've
done um the other one I know is craft ax
done um the other one I know is craft ax
is a crazy project
is a crazy project
that's a crazy project um madron is a
that's a crazy project um madron is a
really cool thing it's like a an engine
really cool thing it's like a an engine
for GPU simulation I don't know if I
for GPU simulation I don't know if I
like it generally but it definitely has
like it generally but it definitely has
some really cool
some really cool
uses
uses
yeah and stuff like that
test
puffet simulation of plasma infusion
puffet simulation of plasma infusion
rectors ah yeah that was in my video as
rectors ah yeah that was in my video as
well that one's pretty darn
well that one's pretty darn
cool see that's the type of thing that I
cool see that's the type of thing that I
would love to help out with with puffer
would love to help out with with puffer
right I just like to provide people
right I just like to provide people
infrastructure in order to solve all the
infrastructure in order to solve all the
cool industry problems with RL
hey we do have support contract now
hey we do have support contract now
support packages really more than
contracts that is newly
launched seven arguments were
launched seven arguments were
given okay
what do we need here we need input
what do we need here we need input
weights bias
output batch size input
output batch size input
size hidden
size hidden
size this I
believe must be Matrix got 1 D tensor
believe must be Matrix got 1 D tensor
okay
dot invalid input for size
128 question mark
128 question mark
oh input
oh input
NP bat size
right got one DET
right got one DET
tensor input torch
okay that looks
good Matt 2 must be Matrix got one deter
good Matt 2 must be Matrix got one deter
oh you didn't reshape the
oh you didn't reshape the
weights yeah I forgot about this um I'm
weights yeah I forgot about this um I'm
actually wondering
actually wondering
like can't I just reshape
these can I just do like
these can I just do like
this and then I can make the I can just
this and then I can make the I can just
make this in the shape that I want it
make this in the shape that I want it
it's still contiguous data
it's still contiguous data
right
right
5p and then I don't have to do this view
here probably don't need this float
here probably don't need this float
either we want it already to be in float
either we want it already to be in float
right cannot interpret 128 as data type
right
okay still cannot be multiplied well
okay still cannot be multiplied well
they're the right shapes now at
they're the right shapes now at
least
uh the weights get transp or something
uh the weights get transp or something
don't
they hold on do the weights have to get
transposed ye
all right let's see what's
wrong this
wrong this
looks oh totally
looks oh totally
wrong
whoops yeah there we go
output NP
output NP
output this is
output this is
oops
puffer cool so a certain here output
puffer cool so a certain here output
Puffer
Puffer
and we also need to
and we also need to
know uh because I see some of these
know uh because I see some of these
don't look quite quite
don't look quite quite
correct let's just do this break point
here these are
good um but these are totally
good um but these are totally
different so we'll have to figure out
different so we'll have to figure out
what's going on
what's going on
here because we tested that these are
here because we tested that these are
correct so now we know it's that the
correct so now we know it's that the
test is wrong right we know it's the
test is wrong right we know it's the
test is wrong not the code is
wrong let's see
uh up
uh up
N.H linear layer input
N.H linear layer input
weights bias
weights bias
output bat size input dim output
dimm right
okay well we don't know about the
okay well we don't know about the
weights yet it could be that the weights
weights yet it could be that the weights
need to be transposed right
let's see what the weight dimensions
are oh well it's 128 128
are oh well it's 128 128
obviously still doing doing the DOTA RL
obviously still doing doing the DOTA RL
and C yep in fact we're doing something
and C yep in fact we're doing something
that is going to benefit both that
that is going to benefit both that
project and a ton of others at the
project and a ton of others at the
moment um I'm writing a very small uh in
moment um I'm writing a very small uh in
inference library in C for just all
inference library in C for just all
sorts of different types of neuron Nets
sorts of different types of neuron Nets
that we're going to use uh so we have
that we're going to use uh so we have
comms linear layers lstms and a few
comms linear layers lstms and a few
activations so far uh I'm writing the
activations so far uh I'm writing the
test for those right now and the hope is
test for those right now and the hope is
that what we're going to be able to do
that what we're going to be able to do
is we're going to be able to upgrade our
is we're going to be able to upgrade our
agents on the
agents on the
web so like these guys here we're going
web so like these guys here we're going
to be able to give all of our different
to be able to give all of our different
AIS some like really nice policies and
AIS some like really nice policies and
they're going to run on the web and it's
they're going to run on the web and it's
going to be very easy to play around
going to be very easy to play around
with them it's going to be very easy for
with them it's going to be very easy for
people to like see whether they're good
people to like see whether they're good
like give feedback and stuff um so we're
like give feedback and stuff um so we're
going to just finish all this up right
going to just finish all this up right
now cuz it turned out to not be anywhere
now cuz it turned out to not be anywhere
near as hard as you would have
near as hard as you would have
thought it's basically like a 100 lines
thought it's basically like a 100 lines
of code in C for lstm convolution and
of code in C for lstm convolution and
linear
layer right in the test
layer right in the test
though let's modify this so that we can
though let's modify this so that we can
at least see if we have the shapes right
another cool example are bots in rocket
another cool example are bots in rocket
League yeah I've seen that that's also
League yeah I've seen that that's also
pretty cool
64 by
128 it's
128 it's
backwards this needs to be
transposed I don't know why but
transposed I don't know why but
apparently they do uh transpose
weights cannot call
ATT
ATT
okay output
okay output
puffer output
forch still completely
different still completely different and
different still completely different and
we know that the implementation is
we know that the implementation is
corrected as
well
well
yeah I'm trying to think what else it
yeah I'm trying to think what else it
could
be well hold on why don't we do
this I to see what this looks
this I to see what this looks
like possible that I only have it
like possible that I only have it
correct for square
correct for square
layers I would doubt that but it's
layers I would doubt that but it's
possible
okay
okay
uh tch. matat
mole weights torch input torch
shape 16 by
128 plus
bias
bias
torch what is it torch bias torch
torch what is it torch bias torch
T
TCH three yeah so this is consistent
TCH three yeah so this is consistent
here right with the linear layer their
here right with the linear layer their
linear layer is
consistent with
consistent with
this so this is the
right input weights bias output
okay where else could I have messed this
up is it possible that like by reshaping
up is it possible that like by reshaping
this data it's like not contiguous or
something is there no like do contiguous
reshaping torch is
reshaping torch is
weird it shouldn't be
yeah no so this is still way
off trying to think what it would
be it could be the binding is off hold
on uh puffet
on uh puffet
pix so here we do puffer linear right
pix so here we do puffer linear right
input weight bi output batch size input
input weight bi output batch size input
output
output
input weights bias output bch
input weights bias output bch
size put
size put
output all look good to me
tensor flow over torch is a very weird
tensor flow over torch is a very weird
take generally people like pie torch way
take generally people like pie torch way
more than tensor flow
well to be fair torch torch becomes very
well to be fair torch torch becomes very
bad very quickly once you go into the
bad very quickly once you go into the
internals but at a high level it's very
nice that's it tensor flow is equally
nice that's it tensor flow is equally
horrible with the internals if not worse
horrible with the internals if not worse
so
I'm trying to think what this would
be batch size times input
size input
weights hold on
weights hold on
here no because I
have I did make sure to zero the output
right yeah the output is
zeroed do I need to transpose the
zeroed do I need to transpose the
weights that go into
weights that go into
um do I need to transpose the weights
um do I need to transpose the weights
that go into puffer as
that go into puffer as
well would that do it
that could do it
right using tens ah and I did that way
right using tens ah and I did that way
back in the day and it was not
fun maybe the map Mo I had the thing is
fun maybe the map Mo I had the thing is
I've tested the M
independently so it's possible but I
independently so it's possible but I
would consider it very
unlikely I think it's more likely that
unlikely I think it's more likely that
I'm putting the data in
wrong let's just do hidden size input
wrong let's just do hidden size input
size like this right what if I do this
how big should I expect the outputs from
how big should I expect the outputs from
this thing to
be it's also very concerning here that
be it's also very concerning here that
um a lot of the entries in the puffer
um a lot of the entries in the puffer
output are
output are
zero
right M Mo yeah I did that
right M Mo yeah I did that
already it matches the torch
already it matches the torch
implementation matches
implementation matches
it is definitely an issue with the way
it is definitely an issue with the way
the data is getting loaded but the
the data is getting loaded but the
question is
question is
what the question is like what
what the question is like what
issue I think this is probably closer
because this should be closer though
because this should be closer though
because now I'm not having to transpose
because now I'm not having to transpose
anymore and this should be the order in
anymore and this should be the order in
which the data is written out to disk
which the data is written out to disk
which is how I tested the linear layer
dummy
dummy
inputs input
numpy wait
numai Puffer
let's just do a quick little test to
let's just do a quick little test to
make sure that I'm not totally wrong
make sure that I'm not totally wrong
about the puffer layer being
correct uh one
correct uh one
one 2
two or
be three
four
four
bias I'll
bias I'll
put upper is going to be four and then
put upper is going to be four and then
hidden size is
two upper net hold on let me do one
two upper net hold on let me do one
thing real quick be right back
okay uh
okay uh
is the repo open for contributions yes
is the repo open for contributions yes
it is all uh this is all open source it
it is all uh this is all open source it
is ater
is ater
AI puffer lib right here start the repo
AI puffer lib right here start the repo
on your way in we're almost at a
on your way in we're almost at a
thousand helps us out a lot nice 14 to
thousand helps us out a lot nice 14 to
go
so it's four two and
so it's four two and
two let's see if I'm wrong about this
two let's see if I'm wrong about this
being correct
here ye well that's not
good yeah that makes no sense
it could be an issue with the binding
though could be the pointer is not
though could be the pointer is not
getting passed
getting passed
correctly could it be SC yes it could
be that's what I'm trying to figure
out any issue when data is getting
out any issue when data is getting
converted from numpy to torch well here
converted from numpy to torch well here
right now we're doing numpy only and
right now we're doing numpy only and
it's the data is clearly wrong yeah you
it's the data is clearly wrong yeah you
tested and see and it see yeah exactly
tested and see and it see yeah exactly
so there's something weird about how the
so there's something weird about how the
data is getting passed I
data is getting passed I
think
think
um because if we look
right this data is
reasonable
hidden put output yeah so something is
hidden put output yeah so something is
definitely weird with how the data is
definitely weird with how the data is
getting passed I'm trying to think what
getting passed I'm trying to think what
that would
be the types are all hold on is it could
be the types are all hold on is it could
it is it
this huh
this huh
gotcha
gotcha does anybody want to guess why
gotcha does anybody want to guess why
this happened before I uh I
explain that's evil that is evil
holy was it 16 bit close 16 64
holy was it 16 bit close 16 64
bit wrong bit
Precision God
damn absolutely
evil I damn
evil I damn
yeah I was like what the heck am I dumb
yeah I was like what the heck am I dumb
did I test it wrong no you just put the
did I test it wrong no you just put the
wrong data into
it output
it output
puffer ah now all our data is
populated look at
that I think one e minus 6 is a little
that I think one e minus 6 is a little
bit ambitious
oneus
oneus
four yeah there you
four yeah there you
go so we match to one e minus 4 on the
go so we match to one e minus 4 on the
outputs of a linear
layer that's perfect I'm going to take
layer that's perfect I'm going to take
this out of here just so we don't have
this out of here just so we don't have
it but I'll save this just in case we
it but I'll save this just in case we
need it and down
there so all we do here
there so all we do here
is
is
we we write
the convolution lstm and the activation
the convolution lstm and the activation
tests which should be quite
easy and then we uh we will clean up the
easy and then we uh we will clean up the
puffer net it's 3:25 p.m. so I think we
puffer net it's 3:25 p.m. so I think we
should be able to get all that done
should be able to get all that done
today and probably even get these onto
today and probably even get these onto
the web that might be a little ambitious
the web that might be a little ambitious
but at the least we'll try to start
but at the least we'll try to start
building some real networks today with
this TBH first time I'm enjoying my 400
this TBH first time I'm enjoying my 400
a.m. noodles and coffee
a.m. noodles and coffee
breakfast
breakfast
gez that's
rough I spent many years in college like
rough I spent many years in college like
you know dinner would be like the fourth
you know dinner would be like the fourth
Monster Energy of the day and ramen or
Monster Energy of the day and ramen or
whatever next to the lava lamp and like
whatever next to the lava lamp and like
the super try hard Arch desktop in
college I was like Giga cringe
can
can
you explain why it's not able to assert
you explain why it's not able to assert
1 E minus 6
1 E minus 6
prision
prision
um frankly I don't know
um frankly I don't know
there's probably just a difference in
there's probably just a difference in
the compilation settings like I don't
the compilation settings like I don't
know maybe torch is compiled with like
know maybe torch is compiled with like
fast math or something on we'll have to
fast math or something on we'll have to
mess around with the compilation
mess around with the compilation
settings and see if we can figure out
settings and see if we can figure out
what torch uses because it should really
what torch uses because it should really
be the same like it should literally be
be the same like it should literally be
the same operations but um you know
the same operations but um you know
there are different compilation settings
there are different compilation settings
that could screw with stuff they could
that could screw with stuff they could
be doing some weird things I don't
be doing some weird things I don't
know it's to within one minus 4 in the
know it's to within one minus 4 in the
outputs which is pretty
outputs which is pretty
decent we should look at that though
decent we should look at that though
because yeah technically even if this is
because yeah technically even if this is
like even if ours is correct and theirs
like even if ours is correct and theirs
is correct we do want to match them
is correct we do want to match them
pretty
pretty
closely I also think that we probably
closely I also think that we probably
don't want to have constants hardcoded
don't want to have constants hardcoded
up
up
[Music]
here out of my element here just enough
here out of my element here just enough
to really show
to really show
ah you'd be be surprised how quickly you
ah you'd be be surprised how quickly you
can pick this up um I haven't programmed
can pick this up um I haven't programmed
in C for 10 years I'd only really
in C for 10 years I'd only really
briefly used it in undergrad a little
briefly used it in undergrad a little
bit and I've been doing this for the
bit and I've been doing this for the
last week and a half no not even like
last week and a half no not even like
the last week pretty much
the last week pretty much
so yeah it's not that
hard I mean of course like you got to
hard I mean of course like you got to
keep in mind I've done this type of work
keep in mind I've done this type of work
for the last 10 ear as well so I kind of
for the last 10 ear as well so I kind of
know I know all of the possible errors
know I know all of the possible errors
already so that
helps but hey if you're trying to do
helps but hey if you're trying to do
like some lower level stuff and get into
like some lower level stuff and get into
RL make some cool environments
RL make some cool environments
right we can always use uh we could
right we can always use uh we could
always use some contributions
I've got if I've got to learn something
I've got if I've got to learn something
new either way why scon over
new either way why scon over
Mojo Mojo is a random new language
Mojo Mojo is a random new language
designed by a company that I don't know
designed by a company that I don't know
what's happening to right scon is an
what's happening to right scon is an
extension language that's just an
extension language that's just an
intermediate layer between Python and C
intermediate layer between Python and C
that com that transpiles directly to C
that com that transpiles directly to C
and is also a Gateway for you you know
and is also a Gateway for you you know
going from python to scon 2C directly
going from python to scon 2C directly
it's like a bridge layer anyways so
it's like a bridge layer anyways so
that's
that's
why also some of the stuff that Mojo
why also some of the stuff that Mojo
gives you is just like it has like weird
gives you is just like it has like weird
rust inspiration that's completely
irrelevant I do like they have uh
irrelevant I do like they have uh
they've got like some simd support and
they've got like some simd support and
stuff that's kind of nice but I'm not
stuff that's kind of nice but I'm not
I'm not using some company's random
I'm not using some company's random
language that's like for all I know
language that's like for all I know
company will be bankrupt next year right
okay
uhet so you can see here
uhet so you can see here
like I could have written all of this
like I could have written all of this
code in scon like I could have written
code in scon like I could have written
all the C code in scon here and it would
all the C code in scon here and it would
look almost the same it would just be
look almost the same it would just be
like slightly more python syntax and it
like slightly more python syntax and it
would be just as fast I pushed it one
would be just as fast I pushed it one
layer deeper into C so that I can use it
layer deeper into C so that I can use it
independently and see and compile it for
independently and see and compile it for
web but you see how it's like you're not
web but you see how it's like you're not
even really learning something new with
even really learning something new with
scon it's just like an intermediate
scon it's just like an intermediate
between between two things that you
between between two things that you
should know anyways
okay we have B size input size hidden
size in wi
channels out
channels out
channels Fel
channels Fel
size
ride and let me find where I how I did
ride and let me find where I how I did
this test in see
I believe I have this somewhere uh
I believe I have this somewhere uh
here
here
yeah so now what we're going to do
is python probably uses double loading
is python probably uses double loading
point in its math Cort using 32 no pytor
point in its math Cort using 32 no pytor
should not be using precision and it's
should not be using precision and it's
math P torch is using float 32 I think
math P torch is using float 32 I think
it's compilation
it's compilation
settings I think it's like the thing is
settings I think it's like the thing is
their settings like you can compile with
their settings like you can compile with
like Dash like Dash fast math or
like Dash like Dash fast math or
whatever um yeah I don't know like
whatever um yeah I don't know like
they're probably just some different
they're probably just some different
compilation settings or something there
compilation settings or something there
could be really any number of things it
could be really any number of things it
could be like the order in which you're
could be like the order in which you're
adding the numbers it could literally be
adding the numbers it could literally be
that right like Loop order will matter I
that right like Loop order will matter I
I can also basically guarantee you that
I can also basically guarantee you that
like here the order that you add the
like here the order that you add the
numbers matters um and uh P torch is
numbers matters um and uh P torch is
almost certainly doing like a tiled mat
almost certainly doing like a tiled mat
mole instead of a standard mat mole
mole instead of a standard mat mole
right so that's going to be different
right so that's going to be different
that's going to change the order there
that's going to change the order there
are lots of optimizations here like the
are lots of optimizations here like the
puffer one right now is just a very
puffer one right now is just a very
boring simple C implementation with zero
boring simple C implementation with zero
optimization so far we might end up
optimization so far we might end up
optimizing it a little bit we're not
optimizing it a little bit we're not
going to try to ever make it as fast as
going to try to ever make it as fast as
p torch it's just for like testing an
p torch it's just for like testing an
inference in the web um but yeah that's
inference in the web um but yeah that's
like that gives you a little bit of an
like that gives you a little bit of an
idea not a bad guess though
Waits
oops okay and then we do
oops okay and then we do
input input
input input
torch and now what we do is we see
torch and now what we do is we see
whether this thing actually did
whether this thing actually did
something reasonable because I suspect
something reasonable because I suspect
it
it
didn't usually llm slop that's why I
didn't usually llm slop that's why I
don't auto complete sections that large
usually we forgot to run
it the cool thing about this is we can
it the cool thing about this is we can
also do like a perf test with
also do like a perf test with
this so we can see like how low ours is
this so we can see like how low ours is
compared to torch and we could actually
compared to torch and we could actually
like build this out if we wanted to
okay
so okay we got our weights the same
this actually looks
good maybe we got the output shape
good maybe we got the output shape
wrong
wrong
output for
shape right so the output is totally the
shape right so the output is totally the
wrong
wrong
shape so uh we have to do
there's a
formula yeah this formula right here
so we'll
do uh out
height in height minus
kernel that should be good
watch
uper okay so let's see what's
uper okay so let's see what's
wrong uh well first of all these values
wrong uh well first of all these values
are
massive I think we're going to want to
massive I think we're going to want to
adjust our data function
two
P let me see if we can just get
P let me see if we can just get
ourselves some better condition data
yeah you can't do like
that yeah so this does this does
float let's do like
this okay so that's actually works
now we just had to get our data to be
now we just had to get our data to be
better conditioned so floating Point
better conditioned so floating Point
Precision right is most accurate um with
Precision right is most accurate um with
like small values around zero so when we
like small values around zero so when we
have massive numbers because like the
have massive numbers because like the
coms keep accumulating more data right
coms keep accumulating more data right
so we were getting numbers in the
so we were getting numbers in the
thousands like you're not going to be
thousands like you're not going to be
able to have 1 E minus 4 when they're
able to have 1 E minus 4 when they're
like thousands you get like four
like thousands you get like four
significant figures not
significant figures not
0.0011 worth of accuracy you get four
0.0011 worth of accuracy you get four
significant figures
maybe python standard
float but this shouldn't be python
float but this shouldn't be python
standard float
standard float
because this is p torch and the P torch
because this is p torch and the P torch
is calling into
is calling into
C++ right which is then calling into qnn
C++ right which is then calling into qnn
or you know whatever the CPU
or you know whatever the CPU
implementation is so there's kind of a
implementation is so there's kind of a
big stack
there hence why I said it's like
there hence why I said it's like
potentially more complicated right
tab tab tab
tab tab tab
tab so the reason I'm tabbing all this
tab so the reason I'm tabbing all this
is because I actually have the same test
is because I actually have the same test
down here already so just should need to
down here already so just should need to
refactor a little as
well we'll see if it if it instantly
well we'll see if it if it instantly
works but I doubt
works but I doubt
it maybe super maven's goated
yep there you go
issue how often do you stream usually
issue how often do you stream usually
Monday through
Monday through
Friday sometimes I'm doing other stuff
Friday sometimes I'm doing other stuff
like yesterday I had a co-working thing
like yesterday I had a co-working thing
so uh I was only on for a short stream
so uh I was only on for a short stream
in the evening but I'm usually just like
in the evening but I'm usually just like
streaming my work you know when I'm
streaming my work you know when I'm
working except Saturday I take off to
working except Saturday I take off to
just do solo Dev all day um like
just do solo Dev all day um like
Saturday for instance last Saturday I
Saturday for instance last Saturday I
ported the entire MOA to see in like
ported the entire MOA to see in like
just8 hours of just frantic coding um at
just8 hours of just frantic coding um at
least the initial pass of it so like
least the initial pass of it so like
stuff like that occasionally I'll just
stuff like that occasionally I'll just
do off
do off
stream but I stream most of my work
I also ped I don't think that's correct
I also ped I don't think that's correct
it's I don't think it's 32 decimal
it's I don't think it's 32 decimal
digits of precision it's Python's 15
digits of precision it's Python's 15
decimal digits maybe is like the best it
decimal digits maybe is like the best it
could represent but you don't get all
could represent but you don't get all
the values there and then for C it's 32
the values there and then for C it's 32
bits which should be the same possibly
bits which should be the same possibly
there's some difference but I would
there's some difference but I would
doubt
it uper
N.H okay
lstm input
[Music]
[Music]
weights what happened
here weights
here weights
input how did they even mess it up this
input how did they even mess it up this
bad like I literally have the correct
bad like I literally have the correct
code down here don't
I yeah you need State what the hell is
I yeah you need State what the hell is
it
doing oops in here
right input
right input
State
State
h
h
p and then we have weights input
p and then we have weights input
wait State bias input bias
wait State bias input bias
State uh we also
State uh we also
need buffer
numpy need a
buffer which is this
buffer which is this
size and then you need uh bad size input
size and then you need uh bad size input
size hidden size okay so and then the
size hidden size okay so and then the
signature here is
signature here is
input uh
input uh
State
State
H State C
numpy then we have weight
State weight input weight State bias
State weight input weight State bias
input by state
input by state
buffer
buffer unfortunately uh funny story I
buffer unfortunately uh funny story I
was I tried to get the ppie package
was I tried to get the ppie package
named puffer and I couldn't because
named puffer and I couldn't because
there's a python buffer that somebody
there's a python buffer that somebody
named
puffer if anybody wants to get me that
puffer if anybody wants to get me that
package name but I think that's actually
package name but I think that's actually
something that gets used
I still mess this
up I think I counted wrong
up I think I counted wrong
right or maybe The Binding is wrong
what's the origin of the name almost get
what's the origin of the name almost get
killed by a
killed by a
puffer no man puffers are friendly it's
puffer no man puffers are friendly it's
literally as simple as just like hey uh
literally as simple as just like hey uh
I'm writing like infrastructure in
I'm writing like infrastructure in
middleware I have no visual depiction of
middleware I have no visual depiction of
my work for you whatsoever so screw it
my work for you whatsoever so screw it
we're going to have a fun mascot here
we're going to have a fun mascot here
have a puffer fish it's very memeable
like look at this guy he's very memeable
like look at this guy he's very memeable
right up
there I don't know more companies should
there I don't know more companies should
have mascots they're
funny
yeah he's
yeah he's
nice I mean puffer fish are not going to
nice I mean puffer fish are not going to
kill you either unless you try to eat
kill you either unless you try to eat
them like they're not like they're not
them like they're not like they're not
going to poison you if you it like by
going to poison you if you it like by
biting you it's just if you try to eat
them though so though the bigger ones
them though so though the bigger ones
will take your finger off if you wave it
will take your finger off if you wave it
too close to
them but if you piss me off I'll do that
them but if you piss me off I'll do that
too
take you out will take your finger
off well was so will
Li
buffer you don't need this output puffer
buffer you don't need this output puffer
variable
variable
that's what it
was
yeah now we do actually have to make a
yeah now we do actually have to make a
little change here though
because puffer will mess with the data
so we have to do state H torch State
so we have to do state H torch State
C
C
bias and
bias and
then what we do
then what we do
here this output torch
here this output torch
um State H torch state see
um State H torch state see
torch okay and
then GL drop
then GL drop
by be back in Future thanks for dropping
by be back in Future thanks for dropping
by cheers
come
come
on not enough values to unpack
Vape
error let's see what's
wrong Ah that's weird
wrong Ah that's weird
right that's real
weird so close to having this done the
weird so close to having this done the
activation functions are going to be
activation functions are going to be
super easy to test and then we'll
super easy to test and then we'll
basically be able to just refactor
basically be able to just refactor
however we want very nicely we can perf
however we want very nicely we can perf
optimize whatever we can build some
optimize whatever we can build some
networks we can put it on the web we can
networks we can put it on the web we can
literally do everything once we have
literally do everything once we have
this
test and I like the way that I did this
test and I like the way that I did this
as well where like I manually tested in
as well where like I manually tested in
order to make sure that it was correct
order to make sure that it was correct
right like I just did a bunch of
right like I just did a bunch of
interactive testing and then I wrote the
interactive testing and then I wrote the
formal test in order to allow me to
formal test in order to allow me to
refactor the known good code and the
refactor the known good code and the
reason I did that is because just like a
reason I did that is because just like a
test like this wouldn't even help me um
test like this wouldn't even help me um
before I had it correct because I need
before I had it correct because I need
to check like at every stage of the
to check like at every stage of the
operations right just having like binary
operations right just having like binary
yes no isn't correct isn't helpful from
this at least not
earlier so why do the H State like this
I think it's because you need to have
I think it's because you need to have
this like extra obnoxious layer variable
this like extra obnoxious layer variable
right well first of all this needs
State
State
view one bad size Hidden size.
view one bad size Hidden size.
View this maybe
is it
obnoxious for unbathed
input how did I test this before
one batch
one batch
size minus
one state one batch size minus one
okay SE
okay SE
Arrow
Arrow
H
H those look the same to me
those look the same to
me
me
TCH ah you got to strip the
um yeah got do
this well
this well
then oh well then
oh
hum that feels
good puffer net. C
definitely cleaner than comparing to
definitely cleaner than comparing to
files yeah that was kind of a dumb idea
files yeah that was kind of a dumb idea
but to be fair like it does mean that I
but to be fair like it does mean that I
have to have this annoying scyon binding
have to have this annoying scyon binding
which isn't bad I
which isn't bad I
guess I don't know I'm really surprised
guess I don't know I'm really surprised
that nobody's done this like why the
that nobody's done this like why the
hell doesn't this already
hell doesn't this already
exist like it's not that crazy of a
exist like it's not that crazy of a
project right to just like write a
project right to just like write a
little neuronet library and see and then
little neuronet library and see and then
like add some python
like add some python
bindings not that
hard and
testu what we
testu what we
think uh this is an in place
oops we think
assertion
assertion
error
error
really oh
really I'll put
really I'll put
puffer ah because
puffer ah because
it's for
there we
go now we
go now we
do uh test copper net sigmoid I think
do uh test copper net sigmoid I think
this is the last
this is the last
one probably literally will auto
one probably literally will auto
complete for us because it's like this
complete for us because it's like this
code is very
Samy and that is crazy that it's still
what takes one
what takes one
argument
argument
oh uh
oh uh
okay yeah I forgot that I did this as a
uh
huh
well input no
I did this for a single element so I
I did this for a single element so I
want to just have uh a nice test like
want to just have uh a nice test like
this
really oh
-
-
four by
four by
this okay there we
this okay there we
go here are all of our
go here are all of our
tests
tests
uh so now we can get rid of the rest of
uh so now we can get rid of the rest of
this stuff
this stuff
right now we can get rid of the rest of
right now we can get rid of the rest of
this still need an Epsilon tolerance
this still need an Epsilon tolerance
yeah
you fixed now my comments have
latency
latency
H it's
good I tend to
good I tend to
um I tend to like program very
um I tend to like program very
reactively so like I won't bother to
reactively so like I won't bother to
like think in order to prevent a bunch
like think in order to prevent a bunch
of bugs what I'll do is I'll just get my
of bugs what I'll do is I'll just get my
Dev Loop to be really really fast and
Dev Loop to be really really fast and
then it'll be like see a bug think about
then it'll be like see a bug think about
bug fix bug see a bug think about bug
bug fix bug see a bug think about bug
fix bug instead of like trying to fix
fix bug instead of like trying to fix
five bugs at the same time or trying to
five bugs at the same time or trying to
anticipate
anticipate
stuff I don't know maybe that just makes
stuff I don't know maybe that just makes
me really brain dead but it's very
me really brain dead but it's very
effective
and now you guys can have this in Dev as
and now you guys can have this in Dev as
well I'm going to use the restroom real
well I'm going to use the restroom real
quick and uh then I'm going to be back
quick and uh then I'm going to be back
in a couple minutes and what we will get
in a couple minutes and what we will get
to do is we'll actually get to take
to do is we'll actually get to take
these things we're going to refactor the
these things we're going to refactor the
Capi just a little bit and then we're
Capi just a little bit and then we're
going to start putting together some
going to start putting together some
actual real like good neuronet
actual real like good neuronet
architectures and uh trying to load
architectures and uh trying to load
pre-trained models into them like we're
pre-trained models into them like we're
going to have like com uh MLP lstm type
going to have like com uh MLP lstm type
architectures and then that'll let us
architectures and then that'll let us
like have that run on web so I'll be
like have that run on web so I'll be
right back and then we'll get doing
that
e e
okay
presenting puffer net.
presenting puffer net.
C this is so cool that this was like
C this is so cool that this was like
this quick to build
I think what we're going to do now is
I think what we're going to do now is
we'll just go
into I'm me grab one other thing real
into I'm me grab one other thing real
quick and then I have an idea well I
quick and then I have an idea well I
know what we're going to do
so I don't want to introduce too much
so I don't want to introduce too much
overhead into this stuff right like I
overhead into this stuff right like I
don't know if I want to have like a
don't know if I want to have like a
general tensor class or anything like
that I don't think I want to get that
that I don't think I want to get that
much I don't want to get into it that
much I don't want to get into it that
much
much
but you know potentially just having
H I'm trying to think if I want strs for
H I'm trying to think if I want strs for
the layers
actually let me think about that
well we can definitely remove this
well we can definitely remove this
linear layer accumulate if I'm a little
clever it's stuff like this H out this W
clever it's stuff like this H out this W
out right like technically I could do
out right like technically I could do
like struct com
like struct com
2D and you would initialize it with like
2D and you would initialize it with like
batch size in width and height you'd
batch size in width and height you'd
initialize it with all this stuff right
initialize it with all this stuff right
and then the com channel would be the
and then the com channel would be the
com layer would be easier
maybe do I like that
well yeah I think I do because otherwise
well yeah I think I do because otherwise
when I'm building
when I'm building
networks I need to
networks I need to
have the pointers to
have the pointers to
everything which brand is this committed
everything which brand is this committed
I'll show you right I'll link it to you
I'll show you right I'll link it to you
remember to Star the
remember to Star the
puffer helps out a
puffer helps out a
ton I'll link you the
ton I'll link you the
file so the test is just in the the base
file so the test is just in the the base
right here and then it's in puffer lib
right here and then it's in puffer lib
environments
environments
it's going to get moved into like you
it's going to get moved into like you
know a more General thing um but for now
know a more General thing um but for now
it's in it's in
it's in it's in
here MOA where is it puffer net
dot huh where is
dot huh where is
this it should be in
here puffer
here puffer
net. I I committed it
right okay there it
is I don't really understand why you
is I don't really understand why you
need these relatively small operations
need these relatively small operations
to implement an RL mod
to implement an RL mod
on the de where do these math layers or
on the de where do these math layers or
steps
steps
reside in a full so because I don't need
reside in a full so because I don't need
to train on the web right I just need to
to train on the web right I just need to
like load I have all of puffer lib for
like load I have all of puffer lib for
training right all I need is I need to
training right all I need is I need to
be able to load the weights of a p torch
be able to load the weights of a p torch
model into a c model that behaves
model into a c model that behaves
exactly the same way and then I can run
exactly the same way and then I can run
that on the web that's all I need and uh
that on the web that's all I need and uh
you can see like let me give you an
you can see like let me give you an
example so this snake game
example so this snake game
here this is RL agents running in your
here this is RL agents running in your
browser um but this is just like if you
browser um but this is just like if you
saw I already had like an MLP
saw I already had like an MLP
implemented I already had the linear
implemented I already had the linear
layer implemented so I can only make
layer implemented so I can only make
these like an MLP which is not a really
these like an MLP which is not a really
great architecture so by adding the lstm
great architecture so by adding the lstm
and the com layers I can Implement way
and the com layers I can Implement way
stronger models which are going to be
stronger models which are going to be
needed for honestly even the snakes
needed for honestly even the snakes
would be better with that but uh Ely for
would be better with that but uh Ely for
the
the
Moa
yeah yeah there's no reason to train on
yeah yeah there's no reason to train on
the web right that's just
dumb I mean you could kind of do an
dumb I mean you could kind of do an
interactive thing if you really wanted
interactive thing if you really wanted
to but
like way more effort than it's
worth this is not that bad right like
worth this is not that bad right like
look at this this is frankly and we're
look at this this is frankly and we're
going to get rid of this main as well so
going to get rid of this main as well so
130 lines of code we're going to
130 lines of code we're going to
actually there a few other things we can
actually there a few other things we can
clean up this will end up being a total
clean up this will end up being a total
of like 150
Max I think that that's a
win I think that's a huge win
okay so let's
do type
do type
death
struct do I want to type death struck
struct do I want to type death struck
hold
on typ
obstruct I think you
obstruct I think you
do struct
linear then you do type
linear then you do type
death is it no it's type
death is it no it's type
def linear and then you need to
def linear and then you need to
do there's like a weird um scon thing I
do there's like a weird um scon thing I
think we have to do it this
way
linear and then when you do your linear
linear and then when you do your linear
layer right now you have weights bias
layer right now you have weights bias
input dim output
input dim output
dim
um you still need to know your batch
um you still need to know your batch
size
do I want to have a tensor
class or tensor struct I
class or tensor struct I
mean I'm trying to think how silly I
mean I'm trying to think how silly I
want this to
be okay this is important
be okay this is important
so I have to patch B pass batch size
explicitly if
um if I just pass a tenser
then the tensor will have all the
then the tensor will have all the
dimensions I need
right it's so funny how you see like
right it's so funny how you see like
basically as soon as you go to introduce
basically as soon as you go to introduce
any amount of abstraction you just
any amount of abstraction you just
realize that there's a cost immediately
right well this is RA this at least this
right well this is RA this at least this
is very free so let's do this first and
is very free so let's do this first and
let's see if I like
let's see if I like
it this is this is like pretty easy for
it this is this is like pretty easy for
me
me
to uh to stomach here CU now all I need
to uh to stomach here CU now all I need
to do
to do
is linear layer of uh struct where is it
linear uh
layer near layer load
layer near layer load
input and then you don't need any of
this all you need is the B
and then this is a
and then this is a
linear star
linear star
layer
layer
linear input dim like
this or you can just do int input dim is
this or you can just do int input dim is
in layer input dim
in layer input dim
then in output
G
Waits is this better though
doing this way you should always be able
doing this way you should always be able
to create a tensor wrapping in
to create a tensor wrapping in
future without having to do all of your
future without having to do all of your
flattening work at the
moment well yeah no I'm fine like I
moment well yeah no I'm fine like I
don't have to redo any of the crazy work
don't have to redo any of the crazy work
it's just a question of what I want the
it's just a question of what I want the
code to look like so
code to look like so
like every time you roduce a piece of
like every time you roduce a piece of
abstraction it's never free there's a
abstraction it's never free there's a
cost right so like I can add this linear
cost right so like I can add this linear
layer operation or this linear layer
layer operation or this linear layer
struct here and if I do that then I get
struct here and if I do that then I get
to have the weights and the input dims
to have the weights and the input dims
taken care of so I don't have to keep
taken care of so I don't have to keep
around wherever I'm calling this I don't
around wherever I'm calling this I don't
have to have a ton of different
have to have a ton of different
variables to represent you know to make
variables to represent you know to make
sure I know where the weights and stuff
sure I know where the weights and stuff
are for this um but the cost is now I
are for this um but the cost is now I
have to you know get these variables
have to you know get these variables
from the struct and now now I have you
from the struct and now now I have you
know these pointer opts here cluttering
know these pointer opts here cluttering
the code where it's not quite as easy as
before and I mean you can go really
before and I mean you can go really
crazy with this right like I could
crazy with this right like I could
decide that the weights are a tensor the
decide that the weights are a tensor the
bias is a tensor like it's done in in a
bias is a tensor like it's done in in a
p torch and then the input is a tensor
p torch and then the input is a tensor
so now everything's a freaking tensor
so now everything's a freaking tensor
and now like this thing is suddenly
and now like this thing is suddenly
going to blow up and be 30 lines of code
going to blow up and be 30 lines of code
for a linear layer
so let me think about that
[Music]
well here's another
well here's another
question do I actually need the batch
question do I actually need the batch
size to
size to
be no I do want the the bat size to be
be no I do want the the bat size to be
part of it otherwise I end up with a
part of it otherwise I end up with a
whole bunch of additional
functions welcome
functions welcome
making a few decisions about how I want
making a few decisions about how I want
this to
this to
look so essentially let me let me just
look so essentially let me let me just
like walk through my uh my reasoning
like walk through my uh my reasoning
process right now so I have this very
process right now so I have this very
very nice and simple uh pure C library
very nice and simple uh pure C library
right it's got conf flayers it has lstms
right it's got conf flayers it has lstms
it's got all this stuff but if you look
it's got all this stuff but if you look
at the function
at the function
signatures you have to pass everything
signatures you have to pass everything
to these
to these
functions so like when I go to implement
functions so like when I go to implement
an actual neuronet right
an actual neuronet right
think about how I would have to do that
think about how I would have to do that
right now I'd have to make like a giant
right now I'd have to make like a giant
struct that's going to contain like you
struct that's going to contain like you
know linear layer one in like linear
know linear layer one in like linear
layer one weight linear Layer Two bias
layer one weight linear Layer Two bias
no C layer one uh weight conve layer one
no C layer one uh weight conve layer one
bias
bias
whereas if I introduce some layer types
whereas if I introduce some layer types
at the very
at the very
least
least
then all I have to do is allocate these
then all I have to do is allocate these
in the um
in the um
I all I have to do is allocate like a
I all I have to do is allocate like a
much smaller number of
much smaller number of
layers is it hard to Crate and see nope
layers is it hard to Crate and see nope
not at all this was actually very
not at all this was actually very
comfortable this was a total of like two
comfortable this was a total of like two
days of
work and I have not written C in 10
years you've been lied to C is very
years you've been lied to C is very
comfortable and very
easy frankly stuff like this figuring
easy frankly stuff like this figuring
stuff like this out annoys me a lot more
stuff like this out annoys me a lot more
than just writing basic
than just writing basic
functions um the design portion is the
functions um the design portion is the
obnoxious bit cuz you're always wrong no
obnoxious bit cuz you're always wrong no
matter what you do you're always wrong
oh wait I think I've got a genius
idea hold
on y guys I think I figured it
out you always hated a year later is it
out you always hated a year later is it
scyon no this is C we also have scyon
scyon no this is C we also have scyon
around and for contributors to puffer Li
around and for contributors to puffer Li
your perfectly welcome to write stuff in
your perfectly welcome to write stuff in
scon it'll be just as fast the reason
scon it'll be just as fast the reason
I'm doing this in purec is because this
I'm doing this in purec is because this
is going to run on the
is going to run on the
web that's why I'm writing this right
web that's why I'm writing this right
now is um I'm going to put this on the
now is um I'm going to put this on the
web and you're going to be able to play
web and you're going to be able to play
games with and against reinforcement
games with and against reinforcement
learned agents that are just running in
learned agents that are just running in
pure C which is pretty cool so here's
pure C which is pretty cool so here's
what I want to do I think that we're
what I want to do I think that we're
going to be a little smarter about this
going to be a little smarter about this
so
we keep the struct okay and we'll we'll
we keep the struct okay and we'll we'll
rename this stuff in a bit but like what
rename this stuff in a bit but like what
about
about
void
void
uh let's say like linear layer from
uh let's say like linear layer from
struct and then we
struct and then we
[Music]
[Music]
do into batch
do into batch
size and then what we do
size and then what we do
we autoc complete
that what do we think about something
that what do we think about something
like
that so we keep our very nice C
that so we keep our very nice C
functions right but then in order to
functions right but then in order to
maintain all the data that we need for
maintain all the data that we need for
the layers we have a struct and then we
the layers we have a struct and then we
have something that calls the method on
have something that calls the method on
this with the
struct what do we think about this
and then if I inlined this it would be
and then if I inlined this it would be
the exact same code so there wouldn't
the exact same code so there wouldn't
even be any
overhead I think it's
nice I still don't like the batch size
it will Ava be
it will Ava be
available on your YouTube well I'm
available on your YouTube well I'm
streaming like the streams are available
streaming like the streams are available
on YouTube the vods are all on my
on YouTube the vods are all on my
YouTube they're like I don't know
YouTube they're like I don't know
probably a 100 plus hours of vods on my
probably a 100 plus hours of vods on my
YouTube at this point occasionally they
YouTube at this point occasionally they
get broken up by Internet outages but if
get broken up by Internet outages but if
you just like click through them you'll
you just like click through them you'll
see all of them there um the code is
see all of them there um the code is
free the free it's free and open open
free the free it's free and open open
source like here you can play around
source like here you can play around
with it right here and I'm updating it
with it right here and I'm updating it
Live Well frequently not directly
live but yeah this is all stuff that
live but yeah this is all stuff that
we've built today and
yesterday what do we think about
this the batch size is a little awkward
this the batch size is a little awkward
isn't it
so technically I could remove the batch
so technically I could remove the batch
size portion from this and I could do
size portion from this and I could do
the batch size as an external Loop but I
the batch size as an external Loop but I
don't know if I want to do that I think
don't know if I want to do that I think
that their
optimizations
optimizations
yeah I don't think I want to do
that let me just really
that let me just really
quick because I forget let me just
jippy there any common
optimizations for cons that's uh
optimizations for cons that's uh
involve pushing
involve pushing
specifically the
specifically the
batch
batch
Loop batch
Loop batch
size from the
outermost inner
yeah that's what I
thought so I think we want to keep the
thought so I think we want to keep the
batch size Loop here because there are
batch size Loop here because there are
optimizations we might want to do that
optimizations we might want to do that
will involve pushing this Loop into the
middle how optimized does this have to
middle how optimized does this have to
be for now it doesn't have to be very
be for now it doesn't have to be very
optimized at all but like I don't want
optimized at all but like I don't want
to do stuff specifically that's going to
to do stuff specifically that's going to
our ability to make improvements to
our ability to make improvements to
it
right so like if I were to take this
right so like if I were to take this
batch Loop out of this function then I
batch Loop out of this function then I
wouldn't be able to push it like right
wouldn't be able to push it like right
now I can just move this down lower
now I can just move this down lower
right and the code will still
right and the code will still
work and that can improve cash locality
work and that can improve cash locality
and
and
such depending on how we optimize
uh this batch size parameter is going to
uh this batch size parameter is going to
bother
me I guess the only reason that this bad
me I guess the only reason that this bad
size parameter is here right is because
size parameter is here right is because
we don't have an input
tensor I'm having the output tensor be
separate in
fact in fact
fact in fact
um I could make the output part of the
um I could make the output part of the
linear layer
right that wouldn't be
right that wouldn't be
bad can you explain functions for one
bad can you explain functions for one
minute yeah so I'm implementing
minute yeah so I'm implementing
here this is a linear layer this is like
here this is a linear layer this is like
your like nn. linear and P torch I've
your like nn. linear and P torch I've
got re and sigmoids I've got a
got re and sigmoids I've got a
convolution layer I've got long
convolution layer I've got long
short-term memory I've got common neural
short-term memory I've got common neural
net layers here except that they're
net layers here except that they're
implemented in pure
implemented in pure
c um I have a test for these that
c um I have a test for these that
ensures that these functions
ensures that these functions
exactly match the pytorch
exactly match the pytorch
implementations so if you run the in
implementations so if you run the in
pytorch if you write like nn. linear L
pytorch if you write like nn. linear L
nn.com whatever they work exactly the
nn.com whatever they work exactly the
same way as my functions do which means
same way as my functions do which means
that I can load the weights from a
that I can load the weights from a
pytorch model into this and I can
pytorch model into this and I can
replicate the functionality exactly um
replicate the functionality exactly um
now all I'm
now all I'm
doing is I'm trying to clean this up a
doing is I'm trying to clean this up a
little bit because uh we're going to
little bit because uh we're going to
have to use this to build some actual
have to use this to build some actual
neural Nets and like right now you see
neural Nets and like right now you see
how many args these fun fun take right
how many args these fun fun take right
like I have tons of different pointers
like I have tons of different pointers
to different weights and things that
to different weights and things that
I'll have to keep
around but you can see how simple this
around but you can see how simple this
is like okay like don't even look at the
is like okay like don't even look at the
stuff at the bottom that's
stuff at the bottom that's
outdated that's a load function so 130
outdated that's a load function so 130
lines of
lines of
code for basically all the stuff that
code for basically all the stuff that
you will need for lots of different
you will need for lots of different
types of neuron
types of neuron
Nets 30 lines of C it'll probably be 150
Nets 30 lines of C it'll probably be 150
lines once I add some strs but still
uh
I guess the one other thing that would
I guess the one other thing that would
be really nice is
um
um
well no it really doesn't help us to
well no it really doesn't help us to
have like a tensor class at all does it
have like a tensor class at all does it
tensor class literally just gives us bat
size can anybody else see like an easy
size can anybody else see like an easy
way to like have batch size be somewhere
way to like have batch size be somewhere
like linear layer shouldn't take B size
like linear layer shouldn't take B size
right input shouldn't take batch
size you'd have to make a tensor class
size you'd have to make a tensor class
is what I think or tensor struct I mean
and like is there really a point of
and like is there really a point of
doing
that I think that's too much
abstraction I don't mind this linear
abstraction I don't mind this linear
layer because it just lets us group some
layer because it just lets us group some
data together
data together
together and like realistically right
together and like realistically right
when we implement this the the names are
when we implement this the the names are
going to be like
going to be like
this it's going to be like underscore
this it's going to be like underscore
linear and then this will just be like
linear and then this will just be like
linear
right something like
right something like
this layer
so that's not
so that's not
bad I think we don't overthink
bad I think we don't overthink
it I think that we uh we do it this way
it I think that we uh we do it this way
and I think this is pretty
good uh we'll be able to delete this
good uh we'll be able to delete this
linear layer accumulate in a moment
linear layer accumulate in a moment
you'll
see is nice as is think you may be
see is nice as is think you may be
worrying too
worrying too
much yeah I think this is good I I was
much yeah I think this is good I I was
just not sure if like I wanted to add a
just not sure if like I wanted to add a
tensor
tensor
struct I think it's good I think I'm
struct I think it's good I think I'm
happy with
happy with
this
so I'm off UK have good coding thank
so I'm off UK have good coding thank
you I mean the one thing is like if we
you I mean the one thing is like if we
had a tensor size right like stuff like
had a tensor size right like stuff like
this
this
we would be able to um have the size
we would be able to um have the size
peram come from
there that's kind of awkward isn't
it the alternative thing that we could
it the alternative thing that we could
do
do
here okay here's another thing we could
here okay here's another thing we could
do
do
right do we really need this thing to
right do we really need this thing to
work for different batch
sizes we don't need this to work for
sizes we don't need this to work for
different batch sizes
right what if we just made the batch
right what if we just made the batch
size part of the layer right when you
size part of the layer right when you
create the
create the
layer um the layer has a specific batch
layer um the layer has a specific batch
size and then everything should be good
everything should be good right
I'm trying to think if that's smarter
I'm trying to think if that's smarter
that's dumb
sometimes I like thinking about these
sometimes I like thinking about these
like design things but sometimes I hate
like design things but sometimes I hate
it cuz like no matter what you do you're
it cuz like no matter what you do you're
almost always going to be dumb
right what would it look like if we made
right what would it look like if we made
batch size a part of
batch size a part of
this well the linear layer wouldn't have
this well the linear layer wouldn't have
a bat size foram which would be cool it
a bat size foram which would be cool it
wouldn't need an output foram because
wouldn't need an output foram because
we'd be able to just have it be part
we'd be able to just have it be part
part of
part of
linear
linear
right we could have like a nice
right we could have like a nice
allocator for
allocator for
linear um we could have like an a make
linear um we could have like an a make
linear or whatever that is going to
linear or whatever that is going to
allocate us our output data
but things start to get very complicated
but things start to get very complicated
very quickly like I can look I can see
very quickly like I can look I can see
down that
down that
path but the thing is if we don't do
path but the thing is if we don't do
this then it's going to be very
this then it's going to be very
complicated for us to actually Implement
complicated for us to actually Implement
any cool neuron Nets because we're going
any cool neuron Nets because we're going
to have to keep around tons of
to have to keep around tons of
different weight pointers and
things but maybe that's okay maybe I'm
things but maybe that's okay maybe I'm
stuck on the pie torch design right I
stuck on the pie torch design right I
don't
know it does actually seem kind of
know it does actually seem kind of
obnoxious to have
um batch size be limited like the layer
um batch size be limited like the layer
to have to know the batch size
h
I'm trying to think how I can avoid
I'm trying to think how I can avoid
staring at this forever because this is
staring at this forever because this is
going to get very boring very quickly if
going to get very boring very quickly if
I just have to stare at this forever
I just have to stare at this forever
right
like it's tough
like it's tough
because I don't want to have like a
because I don't want to have like a
bunch of dynamic memory floating
bunch of dynamic memory floating
around I like having the output buffers
around I like having the output buffers
where it's
where it's
static technically I probably won't need
static technically I probably won't need
to have um batch size be
to have um batch size be
variable I might but probably
variable I might but probably
not it is just very gross to have the
not it is just very gross to have the
batch size be part of the layer
though okay let me think about let's
though okay let me think about let's
okay so here's what let me give you my
okay so here's what let me give you my
thoughts
thoughts
right I can leave it as this with no
right I can leave it as this with no
structs nothing and then what'll happen
structs nothing and then what'll happen
is when I have to implement like you
is when I have to implement like you
know CNN lstm MLP for the MOBA game or
know CNN lstm MLP for the MOBA game or
whatever it's going to be like 100 lines
whatever it's going to be like 100 lines
of allocations because I'm going to have
of allocations because I'm going to have
to take all the different weight
to take all the different weight
variables and stuff and I'm going to
variables and stuff and I'm going to
have to keep them around and I'm going
have to keep them around and I'm going
to have to manually make sure I'm
to have to manually make sure I'm
calling you know each layer with the
calling you know each layer with the
appropriate
appropriate
weights
right and then there's also if I'm going
right and then there's also if I'm going
to read stuff from a file right if I'm
to read stuff from a file right if I'm
going to like read from a file it's
going to like read from a file it's
going to be very difficult as well for
going to be very difficult as well for
me
me
to it's going to be very difficult for
to it's going to be very difficult for
me to like write a
function it's tough to visualize what
function it's tough to visualize what
the code is going to look like
the code is going to look like
right okay so the main thing let me
right okay so the main thing let me
think about it this way the main thing I
think about it this way the main thing I
need to do is I need to read a model in
need to do is I need to read a model in
from a file
from a file
right
right
so we have a function that does that
so we have a function that does that
it's right
here this gives you your weights
here this gives you your weights
technically I could just return uh I can
technically I could just return uh I can
just return right here I can return
this and then your architecture
it's going to have to tell you the
it's going to have to tell you the
number of btes or something
yeah you're definitely going to need
yeah you're definitely going to need
something to tell you the number of
something to tell you the number of
bites regardless that you need to be
bites regardless that you need to be
reading
so I'm going to just start coding on
so I'm going to just start coding on
something here and we're going to see if
something here and we're going to see if
it's stupid right and you guys can tell
it's stupid right and you guys can tell
me if I'm over complicating it but I'm
me if I'm over complicating it but I'm
going to just like the dumbest simplest
going to just like the dumbest simplest
thing I can think to do at the moment
thing I can think to do at the moment
with my very limited capabil ities
here just add
here just add
output and add batch size all
output and add batch size all
right we keep linear as
is underscore linear at least and then
is underscore linear at least and then
linear here takes a layer and it takes
linear here takes a layer and it takes
an input it doesn't need to take
an input it doesn't need to take
anything
else then this becomes layer output and
else then this becomes layer output and
this becomes layer batch size so you
this becomes layer batch size so you
have this very nice nice function
have this very nice nice function
signature that is what this buys you
signature that is what this buys you
okay this linear layer accumulation is
okay this linear layer accumulation is
going to go away in a second and then
going to go away in a second and then
we're going to do do I make one for reu
we're going to do do I make one for reu
I think I do make one for reu so we do
I think I do make one for reu so we do
struct type def struct re struct
struct type def struct re struct
re in
re in
data uh what is it float star data or
data uh what is it float star data or
float star
no
output in batch
output in batch
size in input
dim okay and then this is now underscore
relu this becomes data
input load star output
input load star output
in
size
right I less than side and then this
right I less than side and then this
becomes
becomes
output of I equal to F Max input of I
output of I equal to F Max input of I
okay and now we do void reu which takes
okay and now we do void reu which takes
a reu layer in an
a reu layer in an
input and now it looks like this very
input and now it looks like this very
clean thing right you take the input you
clean thing right you take the input you
take layer output you have batch size
take layer output you have batch size
and then you have input size and the
and then you have input size and the
only thing that we need is this needs to
only thing that we need is this needs to
be underscore reu not reu layer dummy
and uh layer B size times layer input
dim sigmoid is just an activation this
dim sigmoid is just an activation this
does not need a layer this is just
does not need a layer this is just
defined for a single
defined for a single
float this is not a layer yet since we
float this is not a layer yet since we
don't actually use a a sigmoid layer
don't actually use a a sigmoid layer
anywhere
and then this is going to
and then this is going to
beore com
2D let's make
our we'll decide how we want to
our we'll decide how we want to
structure these in a moment
structure these in a moment
type def stru com
type def stru com
2D it's going to have Lo output batch
2D it's going to have Lo output batch
size in kernel yeah there you
go then we
go then we
do void uh com 2D which is now just
do void uh com 2D which is now just
takes this and it's just going to call
function and then we have type Def
function and then we have type Def
struct and it's literally so brain dead
struct and it's literally so brain dead
that this can just be autoc
that this can just be autoc
completed right it just takes all of our
completed right it just takes all of our
data this is now underscore
data this is now underscore
lstm and then we do void
lstm and then we do void
lstm like
lstm like
this
this
okay and I think I want to group all
okay and I think I want to group all
this a little
differently cuz I think I want
differently cuz I think I want
the I think I want like this at the
top re
linear bmid
um
um
2D because this is really the the
2D because this is really the the
portion of the code that's
portion of the code that's
actually you know
matters and then I put the API at the
bottom okay so as I promised
bottom okay so as I promised
right literally this is 100 lines of
right literally this is 100 lines of
code not even 100 lines of code and then
code not even 100 lines of code and then
for The
for The
Binding
so internal uh layers
we'll like do that and then down here
we'll like do that and then down here
we
do user
do user
API
um provided to help
um provided to help
organize
layers I don't know something like that
layers I don't know something like that
right
and then do I want all the strs or all
and then do I want all the strs or all
of
of
the
impulse I think I like it like
impulse I think I like it like
this which like struct implementation
this which like struct implementation
struct implementation I think this is
struct implementation I think this is
good this is very easy to edit like
this so we added by doing this right
this so we added by doing this right
we add 100 no we add 80 lines of
code to have this
wrapper actually less because this thing
wrapper actually less because this thing
is going to go away in a second I'll put
is going to go away in a second I'll put
it up here for now but this is going to
it up here for now but this is going to
go away in a second so we add like
go away in a second so we add like
probably what's that uh 70 lines for
probably what's that uh 70 lines for
this user
this user
API and I think it's worth that
yeah and then we have load weights and
yeah and then we have load weights and
we have this main
we have this main
function like this which we can now get
function like this which we can now get
rid of this main this no longer is
rid of this main this no longer is
needed
oh and we can also do uh linear
oh and we can also do uh linear
accumulate
accumulate
right we can also add a linear
right we can also add a linear
accumulate
here void linear
here void linear
accumulate
wait is this actually valid hold on
I was thinking here that uh we could
I was thinking here that uh we could
just zero the
just zero the
memory but that's not actually efficient
memory but that's not actually efficient
is
it yeah that's not actually efficient
it yeah that's not actually efficient
damn it
well that sucks we'll just do linear
well that sucks we'll just do linear
accumulate like
this and then we'll uh we'll put this
this and then we'll uh we'll put this
down to
here until I figure out a better
here until I figure out a better
way to handle
it so maybe we'll find a better way of
it so maybe we'll find a better way of
doing that but for now yeah not bad
doing that but for now yeah not bad
so 200 Total
so 200 Total
Lines uh and then what we're going to do
Lines uh and then what we're going to do
is we
is we
will we'll have this like load weights
will we'll have this like load weights
thing we'll have a few other things and
thing we'll have a few other things and
that'll be
that'll be
good let me use a restroom real quick
good let me use a restroom real quick
and we'll then we'll test this we'll
and we'll then we'll test this we'll
make sure I didn't break stuff and we'll
make sure I didn't break stuff and we'll
implement the actual uh the actual CNN
implement the actual uh the actual CNN
lstm layers like CNN lstm uh networks
lstm layers like CNN lstm uh networks
right
right
back
e e
okay it occurred to me that we also have
okay it occurred to me that we also have
to make allocators and destru for these
right let me just look something
up I want to see if there's a style
up I want to see if there's a style
thing on
this
for for
not actually sure that this answer is
correct because now that I'm thinking
correct because now that I'm thinking
about
this we'll go with this for now I
this we'll go with this for now I
actually don't know if this is correct
actually don't know if this is correct
but
have you tried perplexity it can give
have you tried perplexity it can give
you
you
sources there not really any sources on
sources there not really any sources on
that though
right it's like the actual thing that
right it's like the actual thing that
llms are intended for which is a general
llms are intended for which is a general
amalgamation of
amalgamation of
Knowledge from a bajillion different
things so this is what uh this is what I
things so this is what uh this is what I
was thinking for the make right
calic
calic
it and then output is going to
be this
so this gives you your
sizes and then you do void free linear
sizes and then you do void free linear
and then this is linear
and then this is linear
star
star what we think about
star what we think about
that allocate you your memory
do make reu and then this is like
do make reu and then this is like
actually brain dead
actually brain dead
code right here this is very
easy um what is it
easy um what is it
comp 2D make comp
comp 2D make comp
2D just going to give you all this
garbage to
day yeah and the reason we can actually
day yeah and the reason we can actually
tab this is hopefully just like this is
tab this is hopefully just like this is
actually brain dead if you're looking at
actually brain dead if you're looking at
it right the only thing I'm not sure
it right the only thing I'm not sure
about here is if we want all these
about here is if we want all these
different calics instead of just like
different calics instead of just like
one big block of
memory but we that's an optimization we
memory but we that's an optimization we
could look at
later I mean that actually gives you a
later I mean that actually gives you a
pretty substantial
pretty substantial
API ask what is puffer
API ask what is puffer
lib I mean is it going to do anything
lib I mean is it going to do anything
other than just going to the site and
other than just going to the site and
then giving me this for
this is actually pretty good I will
say that's actually pretty
good I might consider using that
right so here are all the layers right
actually give you sources yeah that's
actually give you sources yeah that's
important that's fair I mean I could see
important that's fair I mean I could see
that replacing like traditional search
that replacing like traditional search
engines just because the traditional
engines just because the traditional
search engines have become so garbage
search engines have become so garbage
with all the
ads I'd always always always rather pay
ads I'd always always always rather pay
a subscription fee and just not have
a subscription fee and just not have
ads everywhere always
okay so MOBA doc
okay so MOBA doc
here uh this has a bunch of stuff we no
here uh this has a bunch of stuff we no
longer
longer
need this is now in
need this is now in
puffer
right yeah but we need some of this hold
on yeah we don't need
on yeah we don't need
this we don't need any of this
we don't need this so this was the Moa
we don't need this so this was the Moa
demo that we had from before
demo that we had from before
right let's make sure that this thing
right let's make sure that this thing
still
works okay now we
works okay now we
include puffer
include puffer
net. and we go fix some puffet errors
type death struct linear
that syntax has always been weird to
me I don't even know if this is fully
me I don't even know if this is fully
required to be fair I think I was just
required to be fair I think I was just
doing this because the scon layers are
doing this because the scon layers are
like weird about
like weird about
bindings might be able to clean that up
no member named
awaits well that's
awaits well that's
dumb
output start bias
output start bias
output weights by that's so weird that
output weights by that's so weird that
it didn't add that
in yeah so that actually builds
now and uh now what we get to do is we
now and uh now what we get to do is we
get to init some puffer net stuff
get to init some puffer net stuff
right uh so let us
just that. h
go down to our user
API uh we need a few different Windows
API uh we need a few different Windows
here don't
here don't
we anything how I'm going to do
this I think we'll just grab the
browser torch
we're going to try to implement this
we're going to try to implement this
network
network
now is not a trivial Network to be
now is not a trivial Network to be
fair so we're going to have to do this
fair so we're going to have to do this
piece by piece
let's do
let's do
type
struck open
struck open
that openet
that openet
Moet we're going to
do com
do com
2D star com
2D star com
one um
one um
2D two we'll do
2D two we'll do
reu
one linear St
one linear St
flat linear star
flat linear star
[Music]
FR and
FR and
then what is it linear
linear star
linear star
actor L linear star value
function all
right interesting
see what it gives us
here layer
here layer
init we don't care about the init
init we don't care about the init
functions here we just have to get the
functions here we just have to get the
dimensions right
um one is going to
um one is going to
be in
it see
so this is going to be numb
agents uh in width is going to be
agents uh in width is going to be
11 and height is 11 in
11 and height is 11 in
channels it's going to be 19 out
channels it's going to be 19 out
channels is 32 kernel size and stride
channels is 32 kernel size and stride
this is now
this is now
correct right and while we're here let's
correct right and while we're here let's
do comp 2 which is num
do comp 2 which is num
agents uh 32
no wait in width in height
no wait in width in height
still uh we have to compute this
still uh we have to compute this
ourselves don't
we I believe this was
we I believe this was
3x3 yeah I'm pretty sure this is
3x3 channels
3x3 channels
32 32
32 32
one and then
flat it's going to be batch size num
flat it's going to be batch size num
agents
agents
oh I don't know why it does
oh I don't know why it does
this agents and
this agents and
then
then
32 and then we have the
32 and then we have the
projection which is 64 it looks like
32 oh hidden size
s then
s then
actor is going to be hidden size which
actor is going to be hidden size which
is
28 we need numb agents
28 and then uh I believe this is
28 and then uh I believe this is
six no sum of self. action
six no sum of self. action
Dimension we'll need to find that
so 14 17 19 21 23 it looks like we'll be
so 14 17 19 21 23 it looks like we'll be
able to verify all this stuff so it's
able to verify all this stuff so it's
not going to be that
bad
bad
agents value function is
agents value function is
one so there are a few obnoxious things
one so there are a few obnoxious things
here right like uh needing to know the
here right like uh needing to know the
con input size and stuff like
con input size and stuff like
that versus Computing
that versus Computing
it it's not that bad
it it's not that bad
though yeah that's what you would need
though yeah that's what you would need
like a tensor class
for so if we wanted that we would need
for so if we wanted that we would need
like a tensor
struct it's not that bad as
struct it's not that bad as
this do we have multiple reers
there's an additional couple of re here
there's an additional couple of re here
at the bottom it looks
at the bottom it looks
like and there's one
like and there's one
hot quite a bit of encoding
hot quite a bit of encoding
actually we still have to get
actually we still have to get
right I mean it's a substantial
project but at least this gives us our
project but at least this gives us our
Network
now we'll have to load the weights in
now we'll have to load the weights in
which will be a
pain one thing we could do is we could
pain one thing we could do is we could
make like um
we could make it have like a file
we could make it have like a file
pointer of some
type so like when you load in a file
type so like when you load in a file
right you give the file to the init
function something like
that kind of complicated honestly
well we need the Ford
function uh sure we can have the
function uh sure we can have the
free and then
forward value
forward value
function this is not
yeah so this is not
yeah so this is not
remotely uh what we need
here
layer oh yeah this is fine because we
layer oh yeah this is fine because we
get the output of the previous layers
get the output of the previous layers
like this
like this
right so this is fine actually and then
right so this is fine actually and then
the only things we needed are uh
the only things we needed are uh
there're like a few different operations
there're like a few different operations
Maybe
that we didn't think
about in the
Moet let's see what it
Moet let's see what it
is I mean the big ones here are um
one hotting the data like
this there's a little bit of
this there's a little bit of
pre-processing which is no big deal
these concatenates
like this is fine this portion here is
fine but these concatenates are
fine but these concatenates are
obnoxious
I mean not really I can Implement a
I mean not really I can Implement a
concatenate
concatenate
function let me just think about this
function let me just think about this
network architecture if there's a better
network architecture if there's a better
way of doing this stuff
um
I mean I guess you just have to I just
I mean I guess you just have to I just
have to implement one hot and concat
right flatten I actually don't need to
right flatten I actually don't need to
do anything I don't
do anything I don't
think yeah flatten is it's like the data
think yeah flatten is it's like the data
is already flat so I don't need to do
is already flat so I don't need to do
that but I do need to implement
that but I do need to implement
one hot and conat I
believe I mean that's not
terrible and then what'll this look
like it actually won't look that much
like it actually won't look that much
more complicated than the python if I do
more complicated than the python if I do
that right
yeah what about this do
permute I'll just not implement it in
permute I'll just not implement it in
the way that you need the permute right
yeah do Prem is
silly time is it
silly time is it
5:18 I think I can probably implement
5:18 I think I can probably implement
these
these
two and have like something of a network
two and have like something of a network
working in the next couple hours if I
working in the next couple hours if I
buckle down and do it
it's a little
it's a little
tricky let me make sure I'm not missing
tricky let me make sure I'm not missing
anything start
split what about the action selection
split what about the action selection
mechanism it's just a Max isn't
it yeah they'll have to be something for
it yeah they'll have to be something for
multi- discreet selection though
though I mean it is it's literally
though I mean it is it's literally
puffer Doh is what it is it's just I
puffer Doh is what it is it's just I
need like more stuff in there it's not a
need like more stuff in there it's not a
huge deal I just have to implement a few
huge deal I just have to implement a few
more things than I thought I
more things than I thought I
would and there's not really any way
would and there's not really any way
around it right like you kind of just
around it right like you kind of just
need all these
Ops this will be a really sweet demo
Ops this will be a really sweet demo
though if you think about it right like
though if you think about it right like
being able to run a net of this
being able to run a net of this
complexity in your
complexity in your
browser that's pretty
sweet so let's uh let's start on that
1: a.m. stepping out see you around
1: a.m. stepping out see you around
thanks for dropping
by I want to make sure I understand how
by I want to make sure I understand how
how the one hot works
how the one hot works
in
Python great to have the background
Python great to have the background
while working thank you
put like
put like
um the breako right here
all right we had that issue
right we should probably fix that
what the
heck oh yeah we're going to have some
heck oh yeah we're going to have some
issues
here I'm trying to think what the
here I'm trying to think what the
easiest thing for me to do to fix some
easiest thing for me to do to fix some
stuff here
stuff here
is I think for now I'll just write a
is I think for now I'll just write a
quick quick
test
batch do
batch do
like 5 three three
like this
e
533 dude why do I not know the API for
533 dude why do I not know the API for
this
this
uh low high size okay what did he
uh low high size okay what did he
do
f. one hot
a
10 okay so it puts it at the very
10 okay so it puts it at the very
end whereas you want it on the second
end whereas you want it on the second
axis
axis
right always always on the second
right always always on the second
axis so that's
axis so that's
fine yeah we can we can work with that
input output batch
size uh input
size uh input
size size in input
size size in input
size in number classes
size in number classes
right batch size input size
yes oh man the memory is going to be
yes oh man the memory is going to be
tricky
tricky
here but I think I can do it
going be batch
going be batch
times now this is bad
right bad
times input s
batch times input
batch times input
size Plus
what was the first one num
what was the first one num
classes
no the memory addresses for these are so
tricky let's skip batch elements and
tricky let's skip batch elements and
then you have
plus I
plus I
time what is it input size times num
time what is it input size times num
classes I
believe wait batch times input size
believe wait batch times input size
times numb
times numb
classes
classes
plus I * num classes
plus
input what's the input
input what's the input
address there's also the input address
address there's also the input address
to handle
right which has to be
right which has to be
not * num classes batch time input size
not * num classes batch time input size
plus is it just
I I think it is just
I I think it is just
I plus I like this and then I * gome
I plus I like this and then I * gome
[Music]
[Music]
classes this is plus
classes this is plus
input yeah in Adder so this was correct
okay and then you set the output address
okay and then you set the output address
to
one that should be one
hot
hot
void concat
that them
one one
two what
size
one I can just do X and Y right
in y
size is this
correct let's see what it says
here e
well this code doesn't make any sense
right it's batch time X size plus
right it's batch time X size plus
I right
yeah this wrote to nutty
yeah this wrote to nutty
code
code
um the X address is just going to be
um the X address is just going to be
batch time X size plus
batch time X size plus
I and then out
I and then out
address not batch time X size plus
I
I
right it's batch
right it's batch
times X size plus y size plus
I and then
I and then
here y address is going to be batch time
here y address is going to be batch time
y size plus X size plus
y size plus X size plus
I and then the out
I and then the out
address is going to be B
address is going to be B
* B * X size
* B * X size
plus y
plus y
size oh wait wait wait hold on
size oh wait wait wait hold on
no no no no no no batch time y size plus
no no no no no no batch time y size plus
I is good batch time X size plus y
size now this is where you get plus X
size now this is where you get plus X
size plus I so it was almost correct
I think that's
right so the way that you look at this
right so the way that you look at this
right you go through the batch and you
right you go through the batch and you
have these two separate tensors so you
have these two separate tensors so you
go through the first row you grab all
go through the first row you grab all
the X Elements which are B * x i plus I
the X Elements which are B * x i plus I
and then you put them
and then you put them
into this is the row offset of your
into this is the row offset of your
output tensor
uh plus I so you put them into the first
uh plus I so you put them into the first
Slots of that tensor and then here for
Slots of that tensor and then here for
the next one the address index into Y is
the next one the address index into Y is
going to be the same but then in the
going to be the same but then in the
output you also have to add the X offset
output you also have to add the X offset
because it slides over to the
because it slides over to the
right that should be
right and then we also need um
didn't we need like a Max or
something I believe there was a Max
something I believe there was a Max
operation that we used for snake
there's a Max operation right yeah right
there's a Max operation right yeah right
here
and this will be Lo
and this will be Lo
star
input bat
size what is it in load star
in
in
Star
output looat no int bat
output looat no int bat
size
int input
size for match size
index yeah this actually is this auto
index yeah this actually is this auto
complete was good because I have
complete was good because I have
basically the same logic down here that
basically the same logic down here that
I had already
I had already
written um you get the first logic right
written um you get the first logic right
Max index is
Max index is
zero if it's
zero if it's
bigger yeah this just duplicated my
bigger yeah this just duplicated my
exact same logic here
and then output of B is equal to
Maxx
Maxx
yes but now the thing is if you do it
yes but now the thing is if you do it
this way hold
this way hold
on this is not going to work this way
right because you need to have this is
right because you need to have this is
going to be for multi- discreet as well
yeah this is going to be from multi topr
yeah this is going to be from multi topr
this is
this is
bad um
this is actually trickier to implement
this is actually trickier to implement
than I thought let me think
so the problem here that you can have a
so the problem here that you can have a
variable number of action uh of actions
variable number of action uh of actions
types that you
want I mean I know how to do it I'm just
want I mean I know how to do it I'm just
trying to think if there's a simpler way
we'll do it like
we'll do it like
this into batch size
uh is this how you do it for a
uh is this how you do it for a
list something like
list something like
this
in
inputs so four batch like this and then
inputs so four batch like this and then
what we do is
or yeah like this
this is one of these cases I think where
this is one of these cases I think where
we want to have a
we want to have a
uh an index that just keeps accumulating
right we'll see
logic sizes
yeah so loged
address there's no way to get the logit
address there's no way to get the logit
address without just doing index because
address without just doing index because
you have a variable number of size so
you have a variable number of size so
logit
address
address
put in address
and then the output address that we can
and then the output address that we can
do the output
do the output
address batch size times num
address batch size times num
actions
plus
I now plus
yeah this it just wrote garbage code
yeah this it just wrote garbage code
this doesn't make sense here because you
this doesn't make sense here because you
have to go
over so this needs to be I less num
over so this needs to be I less num
actions
i++ num actions plus I this is the
i++ num actions plus I this is the
output
output
address and now what we do is float Max
address and now what we do is float Max
logit is going to be the input of the in
logit is going to be the input of the in
address
here this should be a I
guess and
I okay we'll let this tab complete and
I okay we'll let this tab complete and
then we'll fix
so I actually like this implementation
so I actually like this implementation
because it doesn't end up with anything
because it doesn't end up with anything
super
super
janky um you go over the batch you go
janky um you go over the batch you go
over the number of different types of
over the number of different types of
actions
actions
here your out address is going to be
here your out address is going to be
equal to the batch size times the number
equal to the batch size times the number
of
actions no not bat size times number of
actions no not bat size times number of
actions B times number of actions
actions B times number of actions
plus a
plus a
yes and then your logic
yes and then your logic
here is going to
be input of in
address okay
I can just do in Adder
Plus+ no
in add plus I this is
good Max logic it's overwritten
good Max logic it's overwritten
here and then the output of output
here and then the output of output
address gets set to
address gets set to
I and then you get add the logic size
a so
in Num action
types then this is num action
types something like this we'll have to
types something like this we'll have to
validate all of this
stuff but that's not bad for a a quick
stuff but that's not bad for a a quick
draft of three functions right one hot
draft of three functions right one hot
cat and dim one and argmax on multi-
discreete uh we'll have to make layers
discreete uh we'll have to make layers
for these as well
for these as well
right we don't want to allocate yeah the
memory these will tab complete though
memory these will tab complete though
these are super brain
these are super brain
dead not MLP hi mate can I know what
dead not MLP hi mate can I know what
you're doing yeah so I've got this P
you're doing yeah so I've got this P
torch net here it's fairly sophisticated
torch net here it's fairly sophisticated
it has linear layers it has concats it
it has linear layers it has concats it
has one hot it has CNN's it has an lstm
has one hot it has CNN's it has an lstm
in it has a bunch of stuff and I'm
in it has a bunch of stuff and I'm
currently porting all of this stuff to
currently porting all of this stuff to
work directly in C in like a little 350
work directly in C in like a little 350
line file whatever this ends up
line file whatever this ends up
being so so that I can compile this to
being so so that I can compile this to
web assembly and run it
online that is what we are currently
doing now I might have underestimated
doing now I might have underestimated
the complexity of this project just a
the complexity of this project just a
little bit but uh at this point we're
little bit but uh at this point we're
mostly done
mostly done
so it's not that bad
I mean really the only thing I
I mean really the only thing I
underestimated was I forgot that I would
underestimated was I forgot that I would
have to add like these last three
have to add like these last three
operations in
operations in
here but we'll test these no
worries let's just do type
depu one hot one
hot yeah that's this is this is dumb
hot yeah that's this is this is dumb
easy we can just tab complete this it'll
easy we can just tab complete this it'll
probably be
right I don't know why this
is new and
is new and
CS
CS
senior advise something can be
senior advise something can be
helpful I it depends on where you're
helpful I it depends on where you're
coming
coming
from and what you're trying to do
I can't just give like anything General
I can't just give like anything General
that'll just help everyone in all
that'll just help everyone in all
situations right
yeah I'm we'll see if these Auto
yeah I'm we'll see if these Auto
completes are
completes are
correct but okay 418 lines now we ended
correct but okay 418 lines now we ended
up with a
lot like if you're brand new brand
lot like if you're brand new brand
new um you're going to need to like
new um you're going to need to like
there are some Basics like basic data
there are some Basics like basic data
structures and algorithms you will need
structures and algorithms you will need
to know they're not going toach how to
to know they're not going toach how to
build stuff but it will prevent you from
build stuff but it will prevent you from
doing a lot of dumb
doing a lot of dumb
things
things
um I mean experience just building stuff
um I mean experience just building stuff
is very important um I would advise you
is very important um I would advise you
to
to
not try to build like try to build stuff
not try to build like try to build stuff
not around gigantic Frameworks and tools
not around gigantic Frameworks and tools
that are like doing a lot of stuff like
that are like doing a lot of stuff like
try to like actually learn to build
try to like actually learn to build
stuff try not to just learn a specific
stuff try not to just learn a specific
framework I would say
okay we're going to have to
but yeah if you give me some context I
but yeah if you give me some context I
can maybe give you something more
useful ceret
here I think we just make the test for
here I think we just make the test for
this
this
already DS and what is a DS is that a
already DS and what is a DS is that a
bachelor's or um
where should we
where should we
connect you're free to chat here I just
connect you're free to chat here I just
what is a
DS oh working on data structures in C
DS oh working on data structures in C
okay sure yeah that's fine that's that's
okay sure yeah that's fine that's that's
what I learned that's how I learned as
what I learned that's how I learned as
well
well
um from there let's
see I mean from there you can pretty
see I mean from there you can pretty
much already just start building stuff
much already just start building stuff
um you know try building some like
um you know try building some like
simple projects like building most of
simple projects like building most of
this stuff yourself without using super
this stuff yourself without using super
heavy Frameworks for things it's a good
heavy Frameworks for things it's a good
way to
way to
learn I will recommend to you I mean
learn I will recommend to you I mean
like building simple games and things
like building simple games and things
are a great is a great way to learn I'll
are a great is a great way to learn I'll
recommend do you something I've been
recommend do you something I've been
enjoying a lot
lately this is a really nice library for
lately this is a really nice library for
graphics it's very
graphics it's very
lowlevel um but it just makes it very
lowlevel um but it just makes it very
easy to like it's fun to work on stuff
easy to like it's fun to work on stuff
that you can actually see um but this
that you can actually see um but this
will let you do you know a lot of like
will let you do you know a lot of like
heavy St and logic stuff right like I
heavy St and logic stuff right like I
have I've got like little demos that
have I've got like little demos that
I've built with this where I have like
I've built with this where I have like
pathfinding for instance where to like
pathfinding for instance where to like
you know you can just can I run it
you know you can just can I run it
actually real
actually real
quick I don't know if I have it compiled
quick I don't know if I have it compiled
anywhere
here uh let me see
here let me see if this
works
WS I think this maybe works yeah cool so
WS I think this maybe works yeah cool so
here's like a little thing that I built
here's like a little thing that I built
like this is a type of thing that you
like this is a type of thing that you
could totally build um as somebody
could totally build um as somebody
relative new to CS to get some
relative new to CS to get some
experience with stuff like I built this
experience with stuff like I built this
cool Pathfinder
cool Pathfinder
where you know wherever I'm pressed
where you know wherever I'm pressed
wherever I have the mouse here it's
wherever I have the mouse here it's
doing pathf finding to my current
location and you know it's a nice little
location and you know it's a nice little
visual demo so you can very easily tell
visual demo so you can very easily tell
if it's correct or not because you can
if it's correct or not because you can
see exactly how everything is
see exactly how everything is
pointing it involves a little bit of you
pointing it involves a little bit of you
know a little bit of algorithm stuff
know a little bit of algorithm stuff
little bit of UI
a little bit of design in there
a little bit of design in there
right things like this are fun and these
right things like this are fun and these
are a good way to learn no this took me
are a good way to learn no this took me
like a
day but yeah that's like the level of
day but yeah that's like the level of
stuff I would recommend
6:30 good luck man good luck
we want to add some test
we want to add some test
here so let's
do grette one
do grette one
hot batch size num
hot batch size num
classes we need input
classes we need input
size uh we also if I recall we changed a
size uh we also if I recall we changed a
lot lot of stuff didn't we Social
lot lot of stuff didn't we Social
account yeah I've got a Twitter
account yeah I've got a Twitter
Twitter's the main
thing why do I have a million
thing why do I have a million
notifications blowing
up for
the hell is
this now ignore
this now ignore
Twitter gotta get stuff done
what the heck is
what the heck is
this mixing C and python okay hold on
this mixing C and python okay hold on
here I need to I forgot I needed to fix
here I need to I forgot I needed to fix
a few things here um
a few things here um
because I need to
test actually shoot I need to expose a
test actually shoot I need to expose a
lot of stuff don't
I well technically I could still test it
I well technically I could still test it
this way for now yeah I think I'm
this way for now yeah I think I'm
actually fine here we'll do it like this
actually fine here we'll do it like this
so test puffer at one
hot input size BS
uh what is this
uh what is this
128 num classes
equal this then we'll do input it's
equal this then we'll do input it's
going to
going to
be make dummy
be make dummy
data for one
hun
hun
okay now we need to write The Binding
okay we need to add these B mins
here
here
okay go grab the Prototype from
here where it
go for
uh I forgot the hold
uh I forgot the hold
on losing a little steam here but we'll
on losing a little steam here but we'll
finish this today at least I hope we'll
finish this today at least I hope we'll
be able to test like these functions
be able to test like these functions
today
okay so we have these guys like
okay so we have these guys like
this uh we also need to
this uh we also need to
[Music]
[Music]
expose no wait
that underscore linear like
that underscore linear like
this yeah we want the
underscores linear like this
so we're just exposing the functional
so we're just exposing the functional
API for testing for now I might regret
API for testing for now I might regret
that we'll
that we'll
see
but
okay now we need to put these things up
okay now we need to put these things up
here
okay so now we
okay so now we
have all of our various
have all of our various
different function prototypes or
different function prototypes or
[Music]
whatever one
whatever one
hot now this should get it right we'll
hot now this should get it right we'll
see if it does we can let this auto
see if it does we can let this auto
complete don't need this
sure cool
sure cool
um we actually have to get this thing to
um we actually have to get this thing to
compile now
canot
canot
[Music]
convert cannot convert float star to
convert cannot convert float star to
python object
what
oh okay we actually didn't make very
oh okay we actually didn't make very
many errors
what is
what is
this puff argmax oh puff
this puff argmax oh puff
argmax into logic
sizes oh it just totally got the API
sizes oh it just totally got the API
wrong didn't it
wait
no wait multi discreete oh okay it's
no wait multi discreete oh okay it's
down here int logit
sizes yeah you can't do this this has to
sizes yeah you can't do this this has to
be like list logic sizes or something
be like list logic sizes or something
right
oh no you know what we can
oh no you know what we can
do c np. ND array loget sizes that'll do
do c np. ND array loget sizes that'll do
it and we'll do instar loget sizes like
it and we'll do instar loget sizes like
this okay so now we have all of the data
this okay so now we have all of the data
types exposed
types exposed
from C to
from C to
python apparently this
python apparently this
disagrees not be cast to pointers
beta okay I guess there are some errors
beta okay I guess there are some errors
in Puffer net.
this is supposed to be
a
flexible not at end of
struct fa you're allowed to do this I
struct fa you're allowed to do this I
remember
now invalid use
of do this for
invalid use of flexible array member
size of the entire structure is
size of the entire structure is
[Music]
unknown okay I didn't think I was doing
unknown okay I didn't think I was doing
that though right
M I know what we're going to do this is
M I know what we're going to do this is
obnoxious we're just going to
obnoxious we're just going to
[Music]
[Music]
do we're just going to do this
assignment to
expression do I just mem copy
it yeah that seems to work
work. what's wrong
work. what's wrong
here argument is of
type argument is of type
int po
int po
maybe I'm just using it
wrong
no in
no in
function passing
function passing
argument makes pointer from integer
argument makes pointer from integer
without a cast
what is
underscore H underscore relu oh you need
underscore H underscore relu oh you need
the output I forgot I made it not in
the output I forgot I made it not in
place
ND array
ND array
output
size back to two got three
do I have to adjust this Proto yeah I
do I have to adjust this Proto yeah I
have to adjust
have to adjust
this
output
input implicit Declaration of sigmoid
we'll look at that in a
second undefined s symbol Sig
okay float
sigmoid float X
let me
let me
um hold
on if I just do
this return type defaults to int
Lo implicit decim definition of oh you
Lo implicit decim definition of oh you
just forgot to rename
just forgot to rename
it yeah we can leave it exactly as is I
it yeah we can leave it exactly as is I
just forgot to rename
just forgot to rename
it and then buffer
it and then buffer
sigmoid is underscore sigmoid andore
sigmoid compile no
warnings now we have to edit
warnings now we have to edit
[Music]
[Music]
puff I can just pass it the same uh the
puff I can just pass it the same uh the
same exact buffer
and it
works
works
cool so we got this updated for the new
cool so we got this updated for the new
API stuff I'm going to use a restro real
API stuff I'm going to use a restro real
quick we're going to write the tests for
quick we're going to write the tests for
um the new three functions and then I
um the new three functions and then I
mean if we get that done today I'll be
mean if we get that done today I'll be
happy
happy
because that will let us be able to
because that will let us be able to
write the full Network so we'll be right
back
for
e e
all right last few functions for the
all right last few functions for the
day it's actually only 6:15 I do have an
day it's actually only 6:15 I do have an
extra um good hour and half at least so
extra um good hour and half at least so
you should definitely be able to get
you should definitely be able to get
this done
[Music]
testet
one B size
F
F
size
size
X size equal 32 y size
64 x
64 x
NP okay we have the outputs we do
NP okay we have the outputs we do
cat by output batch size X size
perfect and then output torch we assert
perfect and then output torch we assert
near
point one and then argmax multi-
point one and then argmax multi-
discrete is going to be a little
harder
test bat
size uh log it siid
is
is
equal
equal
five uh
72 okay
okay make some of this some of logic
okay make some of this some of logic
[Music]
sizes what is going to be lared
sizes that's
good logic sizes
good logic sizes
the. array of logic
the. array of logic
[Music]
[Music]
sizes
sizes
sum n
actions length of logit
sizes okay and then what we do is
sizes okay and then what we do is
output output
output output
puffer batch size num actions and when
puffer batch size num actions and when
we argmax into it with that size logic
we argmax into it with that size logic
sizes um
sizes um
actions input
actions input
torch uh this argmax here does not
torch uh this argmax here does not
actually
work so then we have
um yeah there's not like a good thing
um yeah there's not like a good thing
for this
right I think we have to do
action
action
slices for.
splits for. stack of argmax and then we
output putut torch
torch
out
bre and then we add these to the tests
bre and then we add these to the tests
test buer one
test buer one
hot Captain one and we will just to make
hot Captain one and we will just to make
these tests a little faster comment this
these tests a little faster comment this
out while we're testing
python only applicable to index
AB uh okay fair fair play um
make
make
dummy make
dummy make
dummy int
data 10 Yep this is
fine me in
fine me in
data logic
data logic
sizes oops this is not the function that
sizes oops this is not the function that
I needed right
make
dummy in
dummy in
data num
data num
classes
classes
oops be like this num
classes
classes
classes
zero
classes yeah class
perfect only applicable to index tenser
huh okay so it looks like it's seg fting
huh okay so it looks like it's seg fting
here right
right yeah okay so our actual
right yeah okay so our actual
implementation like
cool
cool
shape
shape
inut
shape input
shape input
the wol in
the wol in
32 let's see what we're doing here
upet
pix float
pix float
[Music]
[Music]
star well this is not float this needs
star well this is not float this needs
to
to
be inar input right these are
be inar input right these are
ins and then one
ins and then one
hot that's the
problem and then I assume that I did the
problem and then I assume that I did the
same thing in here some
somehow yeah this is instar
somehow yeah this is instar
input inar output right and then we have
input inar output right and then we have
INT in address int out address
perfect okay what happened
perfect okay what happened
here Buffet
here Buffet
s yeah okay so we forgot this needs to
s yeah okay so we forgot this needs to
be in Star
be in Star
input and yeah that's
it
it
[Music]
passing output all right so this output
passing output all right so this output
needs to be size of int and then output
needs to be size of int and then output
here needs to be in Star we're going use
here needs to be in Star we're going use
in instead of Longs here
okay that
compiles
compiles
that's we still
SE yeah so we're still like fating
here see oops that doesn't
work test
[Music]
okay let's just go grab the uh the
okay let's just go grab the uh the
API and figure out where we're seg
API and figure out where we're seg
puling right
batch size 16 input
batch size 16 input
size um glasses going to be
size um glasses going to be
four we'll do
four we'll do
make one hot layer it's going to be make
make one hot layer it's going to be make
one
one
hot we'll do three one
hot we'll do three one
hot
hot
zero then we'll do one hot layer
zero then we'll do one hot layer
input then it will'll
do in Star input is going to be C
Al classes
W and uh what do we do
we'll just do
like
upet
upet
[Music]
play O test
T
T
Test dot see and I should not need any
Test dot see and I should not need any
of this
stuff okay H.H
stuff okay H.H
wrong goes
here and now I get real stuff so we have
to include standard I all this crap
we need string for mem copy I always
we need string for mem copy I always
forget about that okay so T's puffer
forget about that okay so T's puffer
net this actually runs
that's puffer net still seg
that's puffer net still seg
faults why does it seg
fault I do not know let's
see well wait a second does it even
see well wait a second does it even
Segal in the same spot let's just make
Segal in the same spot let's just make
sure of that
sure of that
it does still say b um on the one hun
it does still say b um on the one hun
okay so yeah I had this break point
okay so yeah I had this break point
there
there
anyways no this is a cat break point
anyways no this is a cat break point
what okay yeah yeah so T faults here um
what okay yeah yeah so T faults here um
takes
takes
input right then takes output
well this is
wrong this is
input input size num classes
right okay we don't get the segf anymore
right okay we don't get the segf anymore
right we just get an
right we just get an
error for
I do this wrong
okay this needs to be longed or
whatever somewhat
obnoxious
long
in insertion
in insertion
error point
max
out D type
float in 32
look at
look at
that we got
that we got
it okay we have our whoops we have our
it okay we have our whoops we have our
one hot
one hot
function that's a one hot function
it's a one hot to
function uh does this cat dim one just
work I think it
work I think it
does I I'm sure we'll find some bugs
does I I'm sure we'll find some bugs
later but
ah nope it doesn't
ah nope it doesn't
okay I was going to say that would have
okay I was going to say that would have
been too good to be uh
possible torch shape
put uh okay so it did something weird
put uh okay so it did something weird
did something real
weird neither of these make any bloody
weird neither of these make any bloody
sense
sense
right oh no wait wait this one is just
working
yeah this is just m equal
one p.
one p.
shape
shape
P output
puffer okay we still have assertion
puffer okay we still have assertion
error output
offer for
offer for
completely different
right
input put up
input put up
zero output for Z so we said that this
zero output for Z so we said that this
is five
is five
right Z one two three four
right Z one two three four
five wait this is five PR so the best
five wait this is five PR so the best
one is one so they're both right and
one is one so they're both right and
then the next
one is
seven and it says
seven and it says
six so torch is correct
six so torch is correct
and then two Z torch is
and then two Z torch is
correct so let's go let's go to
our
source let's go to our source
all action
types so this should not even be
types so this should not even be
possible because it's picking it's not
possible because it's picking it's not
just picking the wrong entries it's
just picking the wrong entries it's
picking like completely invalid
ones e
out
address loget sizes of a
I less than num action
I less than num action
types
interesting output of out Adder is equal
interesting output of out Adder is equal
to
I then in
I then in
Adder gets plus equal num action
types I don't see anything wrong with
types I don't see anything wrong with
this I'm obviously missing something I'm
this I'm obviously missing something I'm
also starting to get quite
also starting to get quite
hungry order some food
soon e
batch size num
actions
yeah and then Max logit is going to be
yeah and then Max logit is going to be
the input of the in
the input of the in
address
address
fine actually types the logic size
fine actually types the logic size
yes and the
yes and the
output to the input in address plus
output to the input in address plus
I bigger than the max
I bigger than the max
logit set it to the Max logit and then
logit set it to the Max logit and then
you set the
you set the
out
out
address to
I this looks good to me let me see if I
I this looks good to me let me see if I
mess something up with the data
coet in
coet in
32 well hold on maybe I screwed this up
right we should be able to see right
right we should be able to see right
here
loget sizes
aha good
you it's always that man always always
you it's always that man always always
always
that I should add some asserts or
something maybe we'll make like a safe
something maybe we'll make like a safe
API or something for the
testing because it's always
puffer
net it does concern me a little bit that
net it does concern me a little bit that
it takes that long to
run there might have to be some
run there might have to be some
optimization done we we'll
optimization done we we'll
see but uh it does
see but uh it does
run or maybe not cuz I'm importing P
run or maybe not cuz I'm importing P
torch and P torch takes a like a good
torch and P torch takes a like a good
couple seconds to import okay so we
couple seconds to import okay so we
literally have all of this done in uh NC
literally have all of this done in uh NC
let's add this before I lose
it
it
h m new puffet
layers Dev
more
puffer we like puffer
net
net
so I'm happy with that progress what I'm
so I'm happy with that progress what I'm
going to do now is I'm going to order my
going to do now is I'm going to order my
dinner on the side and then while I'm
dinner on the side and then while I'm
waiting my for my food as long as it
waiting my for my food as long as it
takes to get here um I
takes to get here um I
am yeah as long as it takes for my food
am yeah as long as it takes for my food
to get here I will try to get the full
to get here I will try to get the full
Network working and we'll see how that
Network working and we'll see how that
goes but I'm very very happy with this
goes but I'm very very happy with this
progress
progress
like this did not exist right this is a
like this did not exist right this is a
400 line file that just
400 line file that just
does neural nets for
you also let me check a DM
nope nothing
looking lots of progress just got here
looking lots of progress just got here
yeah let me order my food we're still
yeah let me order my food we're still
going to work on this for a little bit
going to work on this for a little bit
uh I just need to order something before
uh I just need to order something before
I pass
out technically if I were really
out technically if I were really
grinding this I would just eat food on
grinding this I would just eat food on
stream and keep working but I think
stream and keep working but I think
what's probably going to happen is I'm
what's probably going to happen is I'm
going to just order something eat and go
going to just order something eat and go
to bed early cuz
to bed early cuz
tomorrow I have another environment
tomorrow I have another environment
another big environment that I've been
another big environment that I've been
working on off stream that's still
working on off stream that's still
secret and I'm going to try to Port the
secret and I'm going to try to Port the
whole thing to see tomorrow it's like
whole thing to see tomorrow it's like
about the same size as the Moa
yeah me figure out what the hell to
yeah me figure out what the hell to
order let's do
this it's a good
protein yeah it doesn't matter
so I'll tell you the progress real
so I'll tell you the progress real
quick I'm pretty happy with
quick I'm pretty happy with
this so look at all the layers that we
this so look at all the layers that we
have implemented reu sigmoid linear com
have implemented reu sigmoid linear com
2D lstm one hot concatenation and argmax
2D lstm one hot concatenation and argmax
multi- discreet
multi- discreet
sampling um we also have a user API
sampling um we also have a user API
around all of these that just manages
around all of these that just manages
like all of the variabl for you here so
like all of the variabl for you here so
this is like closer to what P torch
this is like closer to what P torch
would be it's actually pretty much
would be it's actually pretty much
almost one to one with P torch it's a
almost one to one with P torch it's a
little bit lower level CU we don't have
little bit lower level CU we don't have
a tensor class um or a tensor struct so
a tensor class um or a tensor struct so
it's a little bit lower level because
it's a little bit lower level because
you have to manage stuff like um batch
you have to manage stuff like um batch
sizes and like com um com
sizes and like com um com
Dimensions but it's pretty
Dimensions but it's pretty
close it's only 400 lines of C we have a
close it's only 400 lines of C we have a
very nice test for
this so here's your 160 line test and
this so here's your 160 line test and
this actually ensures that our version
this actually ensures that our version
is exactly the same as P torch so not
is exactly the same as P torch so not
only is it correct but it matches P
only is it correct but it matches P
torch exactly meaning that we can load
torch exactly meaning that we can load
uh from pytorch into
uh from pytorch into
puffet this is what I've been
doing I think that's pretty
doing I think that's pretty
cool e
test cases took by surprise glad they're
test cases took by surprise glad they're
there
there
yeah these are
yeah these are
good they're a little bit annoying to
good they're a little bit annoying to
write because like in order to do
write because like in order to do
this I'll just show you what I had to do
this I'll just show you what I had to do
there's also a puffer net.
there's also a puffer net.
pyx which has this binding this is an
pyx which has this binding this is an
inter mediate layer between C and
inter mediate layer between C and
python um so this has to exist but given
python um so this has to exist but given
that this does exist it's not bad
okay um now what we're going to do is
okay um now what we're going to do is
what we were doing
what we were doing
before we were trying to do this
before we were trying to do this
Moet so there's this piece of code that
Moet so there's this piece of code that
I
have let me go find
it speaking of which how are we doing on
stars 13 stars off of 1K for
no wait it's
no wait it's
right head is stopping working because
right head is stopping working because
no
no
food need food in order
think
torch okay so this is the network that
torch okay so this is the network that
we're trying to implement
we're going to at least see if we get a
we're going to at least see if we get a
first pass on the logic today so the
first pass on the logic today so the
first thing is that this
first thing is that this
is
is
net one
net one
hot it's going to be inet one hot not
hot it's going to be inet one hot not
like
like
this it's
this it's
Dimensions
Dimensions
right 16et
H one
hot batch size input size gnome
hot batch size input size gnome
classes this is batch size 11 *
11 num classes is going to be 16
and then we have to
do net map stack
time 16
right
right
three this is the map stack
okay let's see from here so this
okay let's see from here so this
goes on
goes on
forward what you do
forward what you do
is you're going to one hot
jeez this is so obnoxious the way that
jeez this is so obnoxious the way that
this is I really am going to have to
this is I really am going to have to
mess with um the observation format or
mess with um the observation format or
something to make this easier they're
something to make this easier they're
just like so many tensor slice and copy
just like so many tensor slice and copy
and operations and such they're very
and operations and such they're very
difficult to do
difficult to do
well to be honest like I almost want to
well to be honest like I almost want to
spend some time making that net better
spend some time making that net better
because that's actually kind of slow now
because that's actually kind of slow now
that I'm looking at it
yeah well we're very close here
though let me check one
thing let's
thing let's
grab okay so we still have a good 20
grab okay so we still have a good 20
minutes let me see if I can figure out
minutes let me see if I can figure out
some optimizations to this
some optimizations to this
network I'm going to draw this as well
network I'm going to draw this as well
so we'll it'll be like kind of
so we'll it'll be like kind of
interactive we'll show you some uh some
interactive we'll show you some uh some
cool stuff
line
line
okay so the way that it works right now
okay so the way that it works right now
right
is if this is the observations
this is
this is
extra and then here what we have is
like
11 and by
11 and by
or
or
map is put it's encoded flat
map is put it's encoded flat
here and then what you need to do is you
here and then what you need to do is you
get so this turns into 11 by 11x
get so this turns into 11 by 11x
4 so what you end up getting is you get
4 so what you end up getting is you get
this map feature
this map feature
here and then you get this three map
here and then you get this three map
features like
this so this is
this so this is
one
hot
hot
hot and then this
hot and then this
is
Norm and then you do
Norm and then you do
[Music]
[Music]
cat one hot one hot means that you take
cat one hot one hot means that you take
let's say that you have a vector or
let's say that you have a vector or
let's say that you have a value that is
let's say that you have a value that is
five right and you have 10 total options
five right and you have 10 total options
then what you do is you make a vector
then what you do is you make a vector
length 10 and you set the fifth one to
length 10 and you set the fifth one to
be equal or you set I guess that's the
be equal or you set I guess that's the
sixth one technically uh to be equal to
sixth one technically uh to be equal to
one so it's essentially you treat the
one so it's essentially you treat the
data as an index which tells you which
data as an index which tells you which
element to set to
one
one
yeah but I'm doing like tons of
yeah but I'm doing like tons of
here so then what you do is like the
here so then what you do is like the
flat Fe
features this gets
normed and
normed and
then like
PR
cat these two get catted
cat these two get catted
together and then from there it's easy
but that's too much
stuff it gets Norm so that the sum is
stuff it gets Norm so that the sum is
one it just gets divided by a fixed
one it just gets divided by a fixed
value cat is
value cat is
concatenate so like you stack all the
concatenate so like you stack all the
stuff
stuff
together so basically what Happening
together so basically what Happening
Here is I just have too many freaking
Here is I just have too many freaking
operations on little slices of data that
operations on little slices of data that
are going to drive me nuts the way this
are going to drive me nuts the way this
is
written and not only that but this is
written and not only that but this is
not efficient the way it's written
either it's gets it does not get
either it's gets it does not get
normalized so the magnitude is Vector
normalized so the magnitude is Vector
one that's not the only type of
one that's not the only type of
normalization right in this case I'm
normalization right in this case I'm
just dividing by
just dividing by
255 um because what I'm doing actually
255 um because what I'm doing actually
here is I'm storing all the data in one
here is I'm storing all the data in one
bite which means you don't get a lot of
bite which means you don't get a lot of
precision so if I have a variable that's
precision so if I have a variable that's
from 0 to one what I do is I multiply It
from 0 to one what I do is I multiply It
Up by 255 and then that gets cast to a
Up by 255 and then that gets cast to a
bite and then I divide back by 255 and
bite and then I divide back by 255 and
cast as a float so I get to store it in
cast as a float so I get to store it in
one bite but uh I still get a little bit
one bite but uh I still get a little bit
of precision associated with it so
of precision associated with it so
there's a little bit of a trick going on
there but I can see looking at this that
there but I can see looking at this that
there are like all these operations that
there are like all these operations that
are slowing this down and this needs to
are slowing this down and this needs to
be
faster e
really the main problem here is the fact
really the main problem here is the fact
that you need to one hot this
right but there's not really a good way
right but there's not really a good way
around having to one hot it either
yeah the thing that's just really
yeah the thing that's just really
obnoxious is like the right patterns
obnoxious is like the right patterns
here they don't match
here they don't match
up like there isn't an easy way to just
up like there isn't an easy way to just
do a one hot plus I can cat plus like
do a one hot plus I can cat plus like
all these things in one step it's
all these things in one step it's
difficult
m
it's tough cuz we don't have like the
it's tough cuz we don't have like the
notion of applying an operation along an
notion of applying an operation along an
axis like the main thing is I I'm using
axis like the main thing is I I'm using
array Ops
array Ops
here and I'm using array operations in
here and I'm using array operations in
like I'm using array operations in kind
like I'm using array operations in kind
of a tricky way
I'm sure this is not efficient anyways
I'm sure this is not efficient anyways
right like we should be getting a
right like we should be getting a
million steps per second and we're only
million steps per second and we're only
getting 500K
but this is difficult because
like the thing is like if you just look
like the thing is like if you just look
at it visually you say oh yeah just
at it visually you say oh yeah just
stack it right but the thing is it's not
stack it right but the thing is it's not
that easy because the the way that these
that easy because the the way that these
things are laid out in memory certain
things are laid out in memory certain
operations are easy and certain
operations are easy and certain
operations are hard and this operation
operations are hard and this operation
is hard to do
nicely yeah not to mention all the casts
nicely yeah not to mention all the casts
and stuff that are getting done
what is the basis case like like if we
what is the basis case like like if we
have one observation we make looking at
have one observation we make looking at
um it doesn't really help if you have
um it doesn't really help if you have
one observation
one observation
even
even
like the thing is that there just there
like the thing is that there just there
are a lot of operations going on here
are a lot of operations going on here
right and like it's inefficient in this
right and like it's inefficient in this
implementation so we need to make this
implementation so we need to make this
more efficient and if I can find a way
more efficient and if I can find a way
to do that the hope is that it'll make
to do that the hope is that it'll make
the C easier as well
the C easier as well
um because like what's happening now is
um because like what's happening now is
we're splitting out the data into three
we're splitting out the data into three
separate chunks and those chunks do not
separate chunks and those chunks do not
occupy contiguous memory they're
occupy contiguous memory they're
contiguous along certain views but
contiguous along certain views but
they're not actually contiguous in
they're not actually contiguous in
memory and there's not really a way to
memory and there's not really a way to
make them contiguous in memory because
make them contiguous in memory because
of the way that batching works that's
of the way that batching works that's
like a hard uh issue though it's like
like a hard uh issue though it's like
there's not really a good way around
there's not really a good way around
that one so we have
that one so we have
like essentially a split along axis
like essentially a split along axis
operation if you
operation if you
will it's actually a little worse than
will it's actually a little worse than
that it's like there's a bunch of
that it's like there's a bunch of
reshapes that have to happen before you
reshapes that have to happen before you
can even do that and then you have to
can even do that and then you have to
apply a one hot and then you have to
apply a one hot and then you have to
apply a stack along an axis and then
apply a stack along an axis and then
there's a concat and then you can get
there's a concat and then you can get
normal stuff happening
normal stuff happening
again and there's got to be a way to
again and there's got to be a way to
simplify this so basically the operation
simplify this so basically the operation
that we're trying to do here that we
that we're trying to do here that we
care
care
about is we have one filter that needs
about is we have one filter that needs
to get one hotted we have some extra
to get one hotted we have some extra
filters that don't need to get one
filters that don't need to get one
hotted and then we need to be able to
hotted and then we need to be able to
convo for the Stacked versions of those
convo for the Stacked versions of those
once we stack them all
once we stack them all
together
together
um it's difficult because
like I mean there are technically other
like I mean there are technically other
encoders I can use for this instead of
encoders I can use for this instead of
one hot
one filter to hot
one filter to hot
one extra not hot
one extra not hot
one there's quite a bit of stuff so
one there's quite a bit of stuff so
there's there's one filter here that
there's there's one filter here that
needs to get one hotted there's several
needs to get one hotted there's several
additional filters that need to get just
additional filters that need to get just
stacked on top of this one
stacked on top of this one
hot um
hot um
and then I guess we also have some flat
and then I guess we also have some flat
data at the
end this is going to take some
thought stacking filters then flatten
thought stacking filters then flatten
yeah you can do all of that but it's
yeah you can do all of that but it's
going to be like one it's going to be me
going to be like one it's going to be me
writing a lot of C to make the same
writing a lot of C to make the same
thing work in C and two like the way
thing work in C and two like the way
that this is written right now like
that this is written right now like
there's just a lot of copying data
there's just a lot of copying data
around here like every time that you
around here like every time that you
take a slice every time you have to take
take a slice every time you have to take
data along a slice that okay you're fine
data along a slice that okay you're fine
doing that but as soon as you do
doing that but as soon as you do
anything with data that is not
anything with data that is not
contiguous you end up having to copy it
contiguous you end up having to copy it
so like I think we're copying the data
so like I think we're copying the data
several times here which is really
bad in this little
Network reference the
Network reference the
data well the problem like yeah you can
data well the problem like yeah you can
reference but the thing is it's not in
reference but the thing is it's not in
contiguous
contiguous
memory like generally it's like okay
memory like generally it's like okay
fine your data is not in contiguous
fine your data is not in contiguous
memory and there's no way around that
memory and there's no way around that
fine then what you want to do usually is
fine then what you want to do usually is
you want to get it in contiguous memory
you want to get it in contiguous memory
and do all your operations there without
and do all your operations there without
having to do any more copies
why can't we get it to contiguous
why can't we get it to contiguous
memory well if you look at it
like the way that I wrote it up here so
like the way that I wrote it up here so
each of these little slices here is one
each of these little slices here is one
of the filters right we have like 11 by
of the filters right we have like 11 by
11 map filters so we have like flattened
11 map filters so we have like flattened
filters here I guess there'd only be
filters here I guess there'd only be
four of
four of
them but yeah 11 by 11 11 by 11 11 by 11
them but yeah 11 by 11 11 by 11 11 by 11
11 by 11
um so
technically that the way it works hold
on I guess technically we can just split
on I guess technically we can just split
it right I guess technically it looks
it right I guess technically it looks
like this where this is like
like this where this is like
2D
2D
continuous and this is 2D
discreet and then this is
extra but like just because I can split
extra but like just because I can split
it like this doesn't mean it's
contiguous right you like the split
contiguous right you like the split
operation
operation
itself like the memory doesn't know that
itself like the memory doesn't know that
oh yeah this is a nice block right
oh yeah this is a nice block right
you're still like this is a row this is
you're still like this is a row this is
a row this is a row it's not
contiguous yeah each slice is a fil the
contiguous yeah each slice is a fil the
slices are contiguous but the thing is
slices are contiguous but the thing is
you
you
don't buy like just because the slices
don't buy like just because the slices
like they look like they're like
like they look like they're like
contiguous like that it looks like they
contiguous like that it looks like they
are that doesn't mean they actually are
are that doesn't mean they actually are
like what contiguous memory is like here
like what contiguous memory is like here
this block here this is a contiguous
this block here this is a contiguous
block of memory right like this is a
block of memory right like this is a
contiguous block of memory right this is
contiguous block of memory right this is
not a contiguous block of memory
you know what I'm kind of leaning
you know what I'm kind of leaning
towards
so I mean this is going to be a whole
so I mean this is going to be a whole
bunch of additional custom operations
bunch of additional custom operations
still but
still but
like what we could do is we could take
like what we could do is we could take
this block here this one hot block and
this block here this one hot block and
we could just like allocate
we could just like allocate
extra
extra
essentially so like this is what your
essentially so like this is what your
one hot looks like
this is what your one Hawk tensor looks
this is what your one Hawk tensor looks
like once it's expanded we could just
like once it's expanded we could just
like allocate extra
here and then like this goes here and
here and then like this goes here and
then this goes
here numpy flatten allows us to make it
contiguous yeah but you have to think
contiguous yeah but you have to think
about how that happens right that's a
about how that happens right that's a
copy
copy
so every time you look at an operation
so every time you look at an operation
like that and say oh yeah that lets us
like that and say oh yeah that lets us
do it like I have to not only does that
do it like I have to not only does that
incur a copy which slows down our
incur a copy which slows down our
training code here that's slow but also
training code here that's slow but also
I have to go Implement that and
see which is fine like I can Implement
see which is fine like I can Implement
some C stuff but ideally I'm not
some C stuff but ideally I'm not
implementing like a bajillion different
implementing like a bajillion different
things I think I can actually cheat this
things I think I can actually cheat this
because I'm thinking right
because I'm thinking right
here if I just make this F1 Hot
here if I just make this F1 Hot
here if I just make this Dimension
here if I just make this Dimension
19 so I just cheat some extra layers in
19 so I just cheat some extra layers in
then what I can do is I can take these
then what I can do is I can take these
extra map features and instead of doing
extra map features and instead of doing
this concatenate I can just like instead
this concatenate I can just like instead
of doing this
of doing this
concatenate I can just like put them in
concatenate I can just like put them in
there
there
maybe does that work
I think that
works yeah I can just put the extra ones
works yeah I can just put the extra ones
at the end
at the end
there which would be
faster slightly
faster slightly
easier I actually don't know that if
easier I actually don't know that if
that is is even easier
man I probably need to implement like a
man I probably need to implement like a
slice operation and a couple other
slice operation and a couple other
things
right e
this one hot is just so
this one hot is just so
obnoxious like if I'm thinking about it
obnoxious like if I'm thinking about it
here right without the one hot this is
easy without the one hot this is super
easy without the one hot this is super
easy
or alternatively without the extra data
or alternatively without the extra data
it's also super easy
food's almost
food's almost
here yeah I think my brain is going to
here yeah I think my brain is going to
have a a tough time until I can think
have a a tough time until I can think
about this
about this
better I'm going to definitely be
better I'm going to definitely be
thinking about this though over the
thinking about this though over the
weekend I have some other stuff to do
weekend I have some other stuff to do
but I'm going to be thinking about this
but I'm going to be thinking about this
for
sure yeah I need to get some food um
I'm
looking you know maybe this type of
looking you know maybe this type of
encoder is just not a good idea
encoder is just not a good idea
right you know I thought that this was a
right you know I thought that this was a
good idea but maybe it's just not a good
good idea but maybe it's just not a good
idea to have to have mixed one hot and
idea to have to have mixed one hot and
continuous data
yep that is what a one hot encoder
yep that is what a one hot encoder
does it is
does it is
true well I'll tell you what I'm going
true well I'll tell you what I'm going
to be back on Monday I'm going to have
to be back on Monday I'm going to have
I'm going to work on a lot of cool stuff
I'm going to work on a lot of cool stuff
over the weekend I'm going to get like a
over the weekend I'm going to get like a
I'm going to get stuff into a very nice
I'm going to get stuff into a very nice
spot
spot
um I if you'd like to take a look at the
um I if you'd like to take a look at the
some of the stuff that's in puffer at
some of the stuff that's in puffer at
the moment it's all open source so we've
the moment it's all open source so we've
got uh and really this is this is 12
got uh and really this is this is 12
Stars away from a th so if you want to
Stars away from a th so if you want to
support the project if you haven't
support the project if you haven't
started already please go ahead and help
started already please go ahead and help
us with that um it's been great to see
us with that um it's been great to see
the growth on this it's really awesome
the growth on this it's really awesome
and we're very close to that 1,000 M uh
and we're very close to that 1,000 M uh
that
that
Milestone um this is all open source and
Milestone um this is all open source and
the other thing is there is a Discord
the other thing is there is a Discord
and there's a lot of stuff going on in
and there's a lot of stuff going on in
there with contributors and whatnot um
there with contributors and whatnot um
like a lot of the stuff I do you can
like a lot of the stuff I do you can
ignore all the C that I do if that's not
ignore all the C that I do if that's not
your jam
your jam
right like we have much easier ways to
right like we have much easier ways to
implement ultra high perf RL
implement ultra high perf RL
environments and to learn a lot of stuff
environments and to learn a lot of stuff
around here so if you're interested in
around here so if you're interested in
that flash
puffer
puffer
yeah check that out there in the Discord
yeah check that out there in the Discord
um feature hashed hashing
um feature hashed hashing
[Music]
embeddings other encoding types
possibly I'd have to look at
possibly I'd have to look at
specifically this and I'll think about
specifically this and I'll think about
some stuff but anyways I'm going to go
some stuff but anyways I'm going to go
get food thanks folks I will be back um
get food thanks folks I will be back um
I'll be back on Monday with some cool
I'll be back on Monday with some cool
stuff and yeah I think next week we're
stuff and yeah I think next week we're
going to have like this nice full
going to have like this nice full
Standalone puffer net Library we're
Standalone puffer net Library we're
going to have demos running on the web
going to have demos running on the web
we're going to have the mobile running
we're going to have the mobile running
on the web we're going to get training
on the web we're going to get training
working and we're going to have like
working and we're going to have like
model
model
just being imported to like the web
just being imported to like the web
version very frequently uh and we're
version very frequently uh and we're
going to start having more environments
going to start having more environments
as well so thank you everyone and I will
as well so thank you everyone and I will
see you around bye
