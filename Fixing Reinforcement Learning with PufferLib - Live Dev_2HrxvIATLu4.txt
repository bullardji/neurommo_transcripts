Kind: captions
Language: en
we're back
we're back
live I got a meeting time wrong it was
live I got a meeting time wrong it was
uh
uh
Pacific so I got another three
hours a couple things I want to do here
hours a couple things I want to do here
um so this is
um so this is
interesting score gets
to just above zero
let me see why this
let me see why this
is it should get to
is it should get to
one did all these experiments right and
one did all these experiments right and
it should get to
one break out no so this should
be let's see if I click this one
score there score
score there score
here what this is is this is a synthetic
here what this is is this is a synthetic
test of
test of
carbs the hyper pram out oiling so let
carbs the hyper pram out oiling so let
me see this gets
me see this gets
991 gamma
991 gamma
it's very close on gamma 942 so it gets
it's very close on gamma 942 so it gets
pretty darn close on
Lambda learning rate
Lambda learning rate
O2 it's a little bit
O2 it's a little bit
off BPT Horizon does it get
off BPT Horizon does it get
this no it completely fails
this no it completely fails
this so something is still scy
this so something is still scy
here this is not optimizing in the way
here this is not optimizing in the way
that we would
expect and you can see here that the
expect and you can see here that the
total time
total time
steps uh has not been sampled
steps uh has not been sampled
up so there's this score
up so there's this score
mod what about batch size batch size is
mod what about batch size batch size is
only
only
32k no mini
32k no mini
batches is only two upd epox is four
batches is only two upd epox is four
okay so something is very weird here
okay so something is very weird here
though
though
because this should be very
because this should be very
easy this should be very easy for it to
easy this should be very easy for it to
learn and the fact that it isn't
learn and the fact that it isn't
learning
this implies something about the
sampling I'm trying to think if there's
sampling I'm trying to think if there's
any explanation for this other than
any explanation for this other than
carbs being
wrong
right mini batches is
toy like what is the possible reason
hold on this is a uniform right I have
hold on this is a uniform right I have
batches this is defined as like a
batches this is defined as like a
uniform so this should 100% be able to
uniform so this should 100% be able to
be to be
be to be
solved and it's not
working let me see why this is the
working let me see why this is the
case
so I'm actually going to
so I'm actually going to
make a new
make a new
dashboard which is going to
dashboard which is going to
be
be
uh
sweep
progress okay and this one's going to
progress okay and this one's going to
have different widgets in it this is all
have different widgets in it this is all
going to be about learning progress over
going to be about learning progress over
time
so we're going to add some
so we're going to add some
scatters this will be
scatters this will be
score and then this will
score and then this will
be
be
start
time cyst creation
time cyst creation
time and then the Y AIS is going to be
time and then the Y AIS is going to be
score last
add okay and now we're going to do this
add okay and now we're going to do this
for basically for all of these hyper
for basically for all of these hyper
parameters and then this is going to
parameters and then this is going to
tell us which of these are improving
tell us which of these are improving
over
over
time um so yeah we're going to do
okay uh nope creation
yeah okay I think I I think that we're
yeah okay I think I I think that we're
actually going to be able
actually going to be able
to on we're going to be able to we're
to on we're going to be able to we're
going to be able to actually understand
going to be able to actually understand
what's going on now because the
what's going on now because the
synthetic test this is a very good idea
synthetic test this is a very good idea
I should have done this a long time ago
I should have done this a long time ago
right so we got back
right so we got back
size no not Spore this is back
size no not Spore this is back
size TR bad size class okay
okay so we got batch
okay so we got batch
size and then we got no mini batches
we only have to do this once and then
we only have to do this once and then
we'll have this dashboard for
usage okay so here's
usage okay so here's
this I don't know why there's this huge
this I don't know why there's this huge
gap in
gap in
in the creation times but
whatever we do
gamma Lambda
Okay add
this why is this the same
plot uh
plot uh
cuz they're just very similar okay and
cuz they're just very similar okay and
then update
Epoch so what this shows
Epoch so what this shows
you this doesn't show you performance
you this doesn't show you performance
right this just shows you the hyper
right this just shows you the hyper
prams this shows you how your hyper Prem
prams this shows you how your hyper Prem
sweep algorithm is changing over
time BPT
and I think this is it okay so now we
and I think this is it okay so now we
have all of these
parameters I don't know what's up with
parameters I don't know what's up with
this um this might be from like a
this um this might be from like a
partial sweep or something something
partial sweep or something something
weird also this is
yeah that's kind of
weird also this only gives you 200
runs okay I think that the thing is this
runs okay I think that the thing is this
is not giving us the right 200 runs that
is not giving us the right 200 runs that
we
we
want so let's do
want so let's do
none and then
H well why did that just change a whole
H well why did that just change a whole
bunch hold
bunch hold
on
on
14 or 223
okay so yeah what's happening is it's
okay so yeah what's happening is it's
showing us the most recent runs and
showing us the most recent runs and
that's actually that's a really bad
that's actually that's a really bad
thing to have in their
UI um so 422
UI um so 422
items so we actually want the
items so we actually want the
first 200 of
first 200 of
these I see
I'm actually just going to
I'm actually just going to
do this doesn't take very
do this doesn't take very
long and I'm going to change the max
long and I'm going to change the max
runs because this is very
awkward there should be
awkward there should be
200 cuz that's such a bad UI thing the
200 cuz that's such a bad UI thing the
way that they do
way that they do
that
that
um so we're going to do this
um so we're going to do this
want to see what this
want to see what this
does this will give us a very different
does this will give us a very different
picture I
think Neptune unsupported
think Neptune unsupported
type hang
type hang
on oh that's fine these are just
parameters cool so now this is running
and this will run very
quickly
um now we know that it didn't full solve
um now we know that it didn't full solve
we did not fully solve this even by the
we did not fully solve this even by the
end we might get some progress over time
end we might get some progress over time
curves but we know this is not going to
curves but we know this is not going to
full solve
full solve
and then the question is going to be why
and then the question is going to be why
so in the meantime while this
so in the meantime while this
runs I want to look at the way that
runs I want to look at the way that
carbs
carbs
samples its
samples its
parameters I suspect it's not doing what
parameters I suspect it's not doing what
we
want so we get suggestion
output get random
suggestion this is generate
candidate okay so do
candidate okay so do
fit and then you fit the suggestion
fit and then you fit the suggestion
s you fit the
failures fit fito
failures fit fito
set and then it
set and then it
generates candidates numb samples to
generate samples in
generate samples in
basic so you get sample around origins
basic so you get sample around origins
in basic
okay so this surrogate model gets
okay so this surrogate model gets
fit but then you sample
fit but then you sample
around the
origins and they round
origins and they round
this where's the surrogate
this where's the surrogate
model where does this get used
this is what I don't understand I don't
this is what I don't understand I don't
understand how they're
understand how they're
generating their suggestions so is
generating their suggestions so is
expected biasing
technique so what do you actually return
technique so what do you actually return
from
this oh man you returned okay there's a
this oh man you returned okay there's a
lot of stuff so samples in
lot of stuff so samples in
basic of best
basic of best
index
index
ooh oh [ __ ] is that what they're
doing okay I think I see why this is
wrong yeah okay I see why this is wrong
so it looks to and I got to check the
so it looks to and I got to check the
carbs paper but do you see this so they
carbs paper but do you see this so they
generate a whole bunch of random
generate a whole bunch of random
samples based on the space definition
samples based on the space definition
that you
that you
provide so it's only going to
provide so it's only going to
sample according to the initial
sample according to the initial
distribution that you
distribution that you
provide and
then they use
hold
on what do they call the surrogate
on what do they call the surrogate
model circuit
output position function
value I think that what this does is
value I think that what this does is
it's using the acquisition functions to
it's using the acquisition functions to
rank the suggestions
and then you it's only giving you the
and then you it's only giving you the
best ranked random suggestion it is not
best ranked random suggestion it is not
actually giving you a new
suggestion this would make sense because
suggestion this would make sense because
this is why carbs is supposed to be able
this is why carbs is supposed to be able
to generate uh like long like longer and
to generate uh like long like longer and
longer runs over time but under this
longer runs over time but under this
structure it will not do that
this seems like a fundamental problem
this seems like a fundamental problem
with
carbs I wonder if this is in their
paper how's this
going cool so this will progress for a
going cool so this will progress for a
bit
um the paper is very hard to
read this is a maj Maj limitation with
read this is a maj Maj limitation with
carbs if I'm
correct where's the
paper
Okay
so
algorithm generate candidat in local
algorithm generate candidat in local
search BAS
we Define the search
space it's supposed to be Gan
space it's supposed to be Gan
around the parito
front once we have the candidate
front once we have the candidate
suggestions
we estimate okay so they are
ranking but they say they
ranking but they say they
generate defines local spur space around
generate defines local spur space around
points on the observed cost performance
points on the observed cost performance
Paro
front so this would be very smart
but I don't think this is what's
happening does this match the
code let me
see so they're going to fit the success
see so they're going to fit the success
observations they fit the
failures they fit
failures they fit
the parito set
the parito set
okay now when they
sample they get this samples in
basic oh but look the origins in basic
basic oh but look the origins in basic
are the prito
groups sample around Origins and basic
groups sample around Origins and basic
okay
origin
index real
samples search distribution in basic.
Sample basic
Sample basic
search radius in
search radius in
basic in
basic immediately overwritten so I think
basic immediately overwritten so I think
I'm going to have to put some break
I'm going to have to put some break
points in here to figure this out
points in here to figure this out
because this is very very odd um the
because this is very very odd um the
thing that they say they're doing on
thing that they say they're doing on
paper makes sense to me but based on the
paper makes sense to me but based on the
experiments I'm not seeing the algorithm
experiments I'm not seeing the algorithm
do the thing it's supposed to be doing
do the thing it's supposed to be doing
on
on
paper what it's supposed to be doing is
paper what it's supposed to be doing is
it's supposed to be Computing a Paro
it's supposed to be Computing a Paro
front of cost and performance so it's
front of cost and performance so it's
trying to find runs for which there is
trying to find runs for which there is
no run that is both faster and
no run that is both faster and
better and then based on the Paro
better and then based on the Paro
front it's supposed to sample new
front it's supposed to sample new
points so that means that if you start
points so that means that if you start
off with a slow run I mean a fast run
off with a slow run I mean a fast run
you know you can sample a faster run and
you know you can sample a faster run and
a faster run and a faster run as long as
a faster run and a faster run as long as
they're on the parito
they're on the parito
front but this doesn't seem to be
front but this doesn't seem to be
happening even with the most basic of
happening even with the most basic of
synthetic
synthetic
tests carb seems to do a very good job
tests carb seems to do a very good job
just as a hyperparameter tuning
just as a hyperparameter tuning
algorithm without the cost
algorithm without the cost
awareness the cost that that's the
awareness the cost that that's the
important piece and it doesn't seem to
work okay so look at this so we get up
work okay so look at this so we get up
to
B size being decreased is interesting
B size being decreased is interesting
let me
let me
see maybe it's just that it doesn't
see maybe it's just that it doesn't
matter
[Music]
okay so right here this is what we have
okay so right here this is what we have
we got our test
we got our test
function and we get a score
mod is batch size divided square
mod is batch size divided square
root am I stupid or isn't lower isn't
root am I stupid or isn't lower isn't
bigger bat size better
here something is
here something is
wrong bigger bat size should be better
here mini batch should be better
here mini batch should be better
everything here should be better
oh but it's a
multiple I see it's a multip
okay well that's an interesting
interaction because the score is
interaction because the score is
negative you see right the score is
negative you see right the score is
negative here it's actually it's
negative here it's actually it's
learning the bat size is bad thing I
learning the bat size is bad thing I
wonder if it recovers from this because
wonder if it recovers from this because
now it's getting
now it's getting
positive still not getting positive
positive still not getting positive
scores
scores
interesting it should be getting
interesting it should be getting
positive
scores they're all still negative
yes you can actually see that it's it's
yes you can actually see that it's it's
totally messed up the mod
totally messed up the mod
parameters but let's ignore that for a
parameters but let's ignore that for a
second let's see if it's getting the
second let's see if it's getting the
correct values over here so learning
rate 002
so learning rate doesn't seem to get all
so learning rate doesn't seem to get all
the way to where it needs to
the way to where it needs to
be gamma of .99 is basically this is
be gamma of .99 is basically this is
spoton right this is very quickly
spoton right this is very quickly
correct and then Lambda .95 is also you
correct and then Lambda .95 is also you
know it's there's a little bit of noise
know it's there's a little bit of noise
here but this is correct it's
0.95 update
0.95 update
Epoch uh okay that that parameter is not
Epoch uh okay that that parameter is not
going to be good and then BPT
going to be good and then BPT
Horizon BP BT Horizon is also
wrong and actually there's no reason for
wrong and actually there's no reason for
BPT Horizon to be wrong right so
BPT Horizon to be wrong right so
ABS this minus
16 yeah it should be 16 here
16 yeah it should be 16 here
strictly so I suspect that my PO 2
strictly so I suspect that my PO 2
spaces are not correct
they're probably two separate issues
here yeah and now you can see it's
here yeah and now you can see it's
starting to get positive
values okay so this War mod here
is I don't think it's
is I don't think it's
ever yeah this is just a poorly defined
ever yeah this is just a poorly defined
score mod I'm going to add I'm going to
score mod I'm going to add I'm going to
add 20
add 20
here and that's going to fix part of
here and that's going to fix part of
it so that's going to fix the score mod
it so that's going to fix the score mod
um essentially making the score worse if
um essentially making the score worse if
it's negative because what's happened
it's negative because what's happened
here is that because the score is
here is that because the score is
negative and then this is a multiplier
negative and then this is a multiplier
is trying to reduce this multiplier as
is trying to reduce this multiplier as
much as
possible so that's just me screwing this
possible so that's just me screwing this
up like that's just a bad function on my
part so let's see what it does from here
I'm going to check a couple things in
I'm going to check a couple things in
the
the
meantime couple of academic
collabs give an update later today
collabs give an update later today
cool nothing from
cool nothing from
this nothing from
this nothing from
them for
okay I I don't know what they're on
okay I I don't know what they're on
about but
whatever
whatever
okay 11
items score is going up
I believe let's see there one two three
I believe let's see there one two three
four five six seven eight so yeah the
four five six seven eight so yeah the
first like eight trials or whatever are
first like eight trials or whatever are
random and then very quickly it should
random and then very quickly it should
start learning more stuff
start learning more stuff
here
um yeah gamma's already starting to fit
um yeah gamma's already starting to fit
lambda's already starting to
fit learning rate is not really fitting
fit learning rate is not really fitting
yet
yet
let me check some stuff
here so learning rate is
05 okay so the center param this is it's
05 okay so the center param this is it's
this is just where it's centered it
this is just where it's centered it
should very easily get to o1 though
should very easily get to o1 though
that's within one standard
that's within one standard
deviation so maybe it just takes a few
deviation so maybe it just takes a few
more trials
more trials
um but that should be fairly easy to
learn so here we go
learn so here we go
score continues to
score continues to
improve total time steps still being
decreased I believe believe I have this
decreased I believe believe I have this
as
as
a do I have this as a log
a do I have this as a log
two mini batches is correct now look at
two mini batches is correct now look at
this so mini batches is now
correct batch size does not seem to be
correct batch size does not seem to be
correct gamma's getting
correct gamma's getting
correct learning rate is not oh no it is
correct learning rate is not oh no it is
dropping it's just taking a second
dropping it's just taking a second
okay
okay
Lambda okay 0.95 this is what we want
Lambda okay 0.95 this is what we want
update epoch is good so BPT Horizon is
update epoch is good so BPT Horizon is
clearly
clearly
wrong and total time steps is clearly
wrong let's see let's look at this so c
wrong let's see let's look at this so c
2 so num M's is a p
2 so num M's is a p
two let's
add M I don't think I have this one do
add M I don't think I have this one do
I yeah I don't have this
yet xaxis is going to be
yet xaxis is going to be
creation
creation
time then y AIS is going to
time then y AIS is going to
be uh
num
okay and I don't actually know I have
okay and I don't actually know I have
five this in this for function let me
five this in this for function let me
see
so we have num
so we have num
M's uh not in the score function so this
M's uh not in the score function so this
is allowed to drift wherever it wants
is allowed to drift wherever it wants
because we're not currently using it in
because we're not currently using it in
the score function so we ignore this one
the score function so we ignore this one
for
for
now but now if we look at BPT Horizon is
now but now if we look at BPT Horizon is
uniform power
two now mini batches is a uniform power
two now mini batches is a uniform power
to
ah and it's only at four it's not at
ah and it's only at four it's not at
eight yet
eight yet
okay and total time steps is log
okay and total time steps is log
normal you know log normal should work
normal you know log normal should work
because I use log normal
because I use log normal
for everything else so I'm a little
for everything else so I'm a little
confused as to why total time steps
confused as to why total time steps
doesn't work
unless I messed up the function hold
on okay so I can see uniform p 2 being
on okay so I can see uniform p 2 being
broken like that's we'll look at that
broken like that's we'll look at that
but the log shouldn't be
but the log shouldn't be
broken how am I using this in the
broken how am I using this in the
function
log two of total time
steps you increase this you increase
steps you increase this you increase
your score
mod right
you increase this you increase your
you increase this you increase your
score
score
mod uh score
mod uh score
cost or
cost or
yeah so that is
bizarre especially like we see so many
bizarre especially like we see so many
of these are
correct okay look at this so score has
correct okay look at this so score has
gone up to
gone up to
70 total time steps is toal ho
70 total time steps is toal ho
crap mini batches has gotten up to four
crap mini batches has gotten up to four
and then got
stuck batch
size has gotten to
size has gotten to
60 5K and then
stuck learning rate is still progressing
stuck learning rate is still progressing
it looks like I don't know why it's
it looks like I don't know why it's
taking it this long to
taking it this long to
sample uh lower learning rates it this
sample uh lower learning rates it this
should be very easy to learn but it is
should be very easy to learn but it is
learning uh and then gamma is 99 so it's
learning uh and then gamma is 99 so it's
getting up to
getting up to
.99 this is very slow though it's very
slow keep in mind this is a synthetic
slow keep in mind this is a synthetic
test with perfect feedback there is no
test with perfect feedback there is no
noise in the evaluations like you should
noise in the evaluations like you should
basically be able to do this in I would
basically be able to do this in I would
guess 10 or 20 samples
okay so Lambda actually works very
nicely the kind of does some like these
nicely the kind of does some like these
are random and then it homes in and you
are random and then it homes in and you
get
0.95 is random BT Horizon is
wrong use the restroom real quick while
wrong use the restroom real quick while
this finishes some runs and uh then
this finishes some runs and uh then
we'll stop this I will make sure I'm
we'll stop this I will make sure I'm
completely right about the evaluation
completely right about the evaluation
function and then we'll see what carbs
function and then we'll see what carbs
is doing because this is very
weird
e e
okay we got 48 items we'll get 50 points
okay we got 48 items we'll get 50 points
from
them
see yeah so score does keep
see yeah so score does keep
improving these points down here are
improving these points down here are
very weird to
me and this is something that carbs
me and this is something that carbs
consistently
consistently
does is it just
misses oh okay maybe we actually do let
misses oh okay maybe we actually do let
this run a little longer because look at
this run a little longer because look at
total time steps it's coming
back but like why did it go down in the
back but like why did it go down in the
first
first
place right
so we'll let this run a little longer
not this one where's
not this one where's
carbs so many
papers here it is so
I would love to get somebody to just
I would love to get somebody to just
simplify this whole
simplify this whole
carbs um this whole carbs repository
carbs um this whole carbs repository
like really clean this
up it's just way too complicated right
up it's just way too complicated right
now that actually would be a really nice
now that actually would be a really nice
like mostly science side little bit
like mostly science side little bit
engineering side
engineering side
contribution because it requires you to
contribution because it requires you to
understand the algorithm
rounds see they say that this actually
rounds see they say that this actually
does
does
work and that this will continue to find
work and that this will continue to find
longer and longer
longer and longer
cost
hours but we're not seeing this working
hours but we're not seeing this working
in
practice this is
bizarre so gamma's get got to 99 here I
bizarre so gamma's get got to 99 here I
don't know why it took that long though
don't know why it took that long though
to sample up to
to sample up to
here and like Lambda is the right spot
here and like Lambda is the right spot
but it's not a
but it's not a
tight it hasn't really gotten that
tight it hasn't really gotten that
parameter tight
yet I also don't know why numm would
yet I also don't know why numm would
drift down like
drift down like
this because it's not included in the
this because it's not included in the
the function having drift like this in
the function having drift like this in
your having this type of drift is very
bad doesn't seem like this is going way
bad doesn't seem like this is going way
back
back
up okay I think I'm going to in a
up okay I think I'm going to in a
separate window I'm going to start
separate window I'm going to start
trying to figure out what the heck is up
trying to figure out what the heck is up
with carbs
um yeah
this is a big repo that I I think you
this is a big repo that I I think you
could probably clean this up to be like
could probably clean this up to be like
a 500
a 500
line Repository
okay so where's our
suggestion
generate
candidates sample around Origins and
candidates sample around Origins and
basic
yeah let do the window
oh am I on the other machine
demo or
aate okay so we have
aate okay so we have
here origin samples
let's figure out the order these are
let's figure out the order these are
passed
in we'll
in we'll
do flat spaces
Okay cool
Okay cool
so we've got
origin
samples so I can see right
here
here
1.06 and then this log space is at 32
so these have been transformed
already real
already real
samples
samples
tensor plus search distribution in
tensor plus search distribution in
basic
basic
he search just distribution in
he search just distribution in
basic normal with a scale of
0.3 so they're transforming my
parameters and then they're using a
fixed search distribution and basic
so what do we do so it's self.
so what do we do so it's self.
search radius in
search radius in
basic immediately overwritten by set
basic immediately overwritten by set
search
center set search
center I really
search center so you set the search
center param dict
type search center
type search center
basic so search center in basic is very
different search distribution in
basic search
radius so this is immediately
radius so this is immediately
overwritten by set search
center which is not true because this
center which is not true because this
doesn't set
doesn't set
that it only sets this it doesn't set
that it only sets this it doesn't set
the search
the search
radius so search radius in basic is not
radius so search radius in basic is not
overr
I do think that this is worth investing
I do think that this is worth investing
substantial time into
substantial time into
because this seems like a very good
because this seems like a very good
algorithm that's being held back
so where is search center and basic we
do let's do up
here so you have params
here so you have params
here
here
and the search center for these
is not what it's looking like here
set foram space real to per
set foram space real to per
basic foram space real
toam space real to basic space
toam space real to basic space
real okay so dim. basic from Pam
uh
terminal
terminal
uhoh internet might be
dropping I think we're
dropping I think we're
good I think just a small
good I think just a small
Spike I have had some janky driver
Spike I have had some janky driver
issues I'm hoping that they're fixed but
issues I'm hoping that they're fixed but
we will
see
see
basic we got input in
basic we got input in
param and we get these are the surch
param and we get these are the surch
centers these are the raw surf
centers these are the raw surf
centers okay
centers okay
and then we
do basic from
do basic from
pan and self.
real input
real input
inam K dim
inam K dim
in self. real number Space by
in self. real number Space by
name number Space by name
underscore
internet dim. basic from
internet dim. basic from
Chan okay so it's
so the spaces have a function called
so the spaces have a function called
basic drug
basic drug
foram
okay value over scale
so this tells
you this is the transform right
it's incredibly
it's incredibly
confusing I think basic from
confusing I think basic from
Pam it takes the ra
Pam it takes the ra
value and it transforms it to be in a
value and it transforms it to be in a
better space for
sampling but the way it's doing that at
sampling but the way it's doing that at
the moment is not good
yeah cuz I think what they're doing at
yeah cuz I think what they're doing at
the
the
moment so here they're just dividing the
moment so here they're just dividing the
parameter by whatever skill you give
it they're just dividing the parameter
it they're just dividing the parameter
by whatever scale that you give
it and then when you sample this
parameter this is why they have a three
parameter this is why they have a three
there because their default sample range
there because their default sample range
is
is
is.3 so what happens is they divide by
is.3 so what happens is they divide by
the scale that you give it and then they
the scale that you give it and then they
sample a normal with a standard
sample a normal with a standard
deviation of.
deviation of.
3 and then they transform back so like
3 and then they transform back so like
one standard deviation right let's say
one standard deviation right let's say
that you have 1 to 10 and you give it a
that you have 1 to 10 and you give it a
scale of
scale of
three okay so then you give it a five a
three okay so then you give it a five a
five is a or let's make it easier a six
five is a or let's make it easier a six
so they do 6 / 3 is two and then you
so they do 6 / 3 is two and then you
sample with a.3 Norm so let's say one
sample with a.3 Norm so let's say one
standard deviation you sample a 2.3 and
standard deviation you sample a 2.3 and
then you multiply back and then that
then you multiply back and then that
gives you a a 6.9
which is a terrible way of
sampling yeah that makes absolutely no
sense and this would explain why they're
uh why their algorithm doesn't
uh why their algorithm doesn't
sample or doesn't explore various spaces
sample or doesn't explore various spaces
in a way that looks reasonable to
in a way that looks reasonable to
me so this is basically this is a really
me so this is basically this is a really
really good algorithm that's being held
really good algorithm that's being held
back by space
back by space
Transformations um so I've just run 119
Transformations um so I've just run 119
experiments it's kind of starting to
experiments it's kind of starting to
learn to restore total time
learn to restore total time
steps it's got gamma it's
steps it's got gamma it's
got doesn't even have learning rate
really oh it's supposed to be o1 it's a
really oh it's supposed to be o1 it's a
little bit
little bit
off
um it's like kind of getting
um it's like kind of getting
there I think the algorithm is really
there I think the algorithm is really
really good and
really good and
like there's not much I can even change
like there's not much I can even change
with it it's like a really smart
with it it's like a really smart
algorithm it's just this space
algorithm it's just this space
transformation
transformation
stuff
stuff
um so I think I found that out
is there a chance that I'm wrong
here I think I have
here I think I have
it and I think this is what their paper
it and I think this is what their paper
says as well let me see if it matches
says as well let me see if it matches
the paper then I think I then I think
the paper then I think I then I think
we're good and then we'll know what we
we're good and then we'll know what we
need to change this this will take like
need to change this this will take like
a couple days of work probably to fix
a couple days of work probably to fix
this but then it will be will be
set assume that this we just
set assume that this we just
[Music]
find input parameters and out outputs
find input parameters and out outputs
are scaled to be of order one but they
are scaled to be of order one but they
don't actually do
this local search space around points
we Define the search
we Define the search
space as a set of Galan distributions of
space as a set of Galan distributions of
radius search around these
radius search around these
parameters defining the unnormalized
parameters defining the unnormalized
probability
density so I don't even think that this
density so I don't even think that this
makes sense
makes sense
if yeah this doesn't even make sense if
if yeah this doesn't even make sense if
you transform
you transform
correctly because each of these
correctly because each of these
parameters should have its own uh its
parameters should have its own uh its
own search
radius cuz like you know which
radius cuz like you know which
parameters have scale over many range
parameters have scale over many range
like many orders of magnitude and which
like many orders of magnitude and which
ones don't
once we've evaluated the candidate
suggestions three gum
suggestions three gum
processes to
processes to
predict the performance of a
predict the performance of a
candidate to predict the
candidate to predict the
cost and to predict the Optimal
cost and to predict the Optimal
Performance coresponding to that
Performance coresponding to that
cost and formed only by the pr fund all
cost and formed only by the pr fund all
the
the
shape
shape
okay I think I'm really starting to
okay I think I'm really starting to
understand this
understand this
algorithm this is a very heavy
algorithm this is a very heavy
out I'm starting to get
it doing only observations that
it doing only observations that
belong in the Paro
front is uses the
front is uses the
Baseline the expected
Improvement I don't know about
this I'm G to have to get way deep into
this I'm G to have to get way deep into
the code to figure out what they're
the code to figure out what they're
doing box
doing box
transform quantile transform
so they do have some transforms in here
so they do have some transforms in here
but I think that the thing is that
but I think that the thing is that
they're applying the transform to bad
data well the good thing is that I have
data well the good thing is that I have
this Baseline
this Baseline
now right so I have this
now right so I have this
Baseline this is how well it
Baseline this is how well it
does um let me compute the Optimal
does um let me compute the Optimal
Performance real quick
what's optimal on
this for
why can't I set
why can't I set
this I'll just do it here and then we're
this I'll just do it here and then we're
going to do something else
yeah so this should be the
yeah so this should be the
optimal parameter settings
Point yeah so like you can see here that
Point yeah so like you can see here that
there are parameters that get
there are parameters that get
254 way way way way way higher so uh
254 way way way way way higher so uh
this means carbs is not actually working
this means carbs is not actually working
perfectly and
optimal carbs is not working perfectly
optimal carbs is not working perfectly
and we will definitely look at that so
and we will definitely look at that so
this is why everything's been janked
this is why everything's been janked
basically if we can fix
basically if we can fix
this then we should have really solid
this then we should have really solid
sweeps and we should be in a really
sweeps and we should be in a really
solid position going
solid position going
forward
forward
um okay that's good for this segment of
um okay that's good for this segment of
work uh I think the next thing we're
work uh I think the next thing we're
going to do whoops let me
see the next thing we're going to do
oh interesting apparently newer
oh interesting apparently newer
compilers are faster
cool General let me find this real quick
cool General let me find this real quick
for
us okay I'm going to be reviewing this
us okay I'm going to be reviewing this
paper
now mini paper bir to Tim okay Co they
now mini paper bir to Tim okay Co they
should be
good elliptical episodic bonuses
good elliptical episodic bonuses
fineos to explore complex
fineos to explore complex
environments yeah we're going to do this
environments yeah we're going to do this
review
review
now let me get into paper review mode
now let me get into paper review mode
let actually make a new scene for this
let actually make a new scene for this
um you
add
I should actually flip this one as
well there we
go oh I have this because of the mic I
go oh I have this because of the mic I
guess
all right we'll flip this
back e
ch
e
e e
test
test audio works here does audio not
test audio works here does audio not
work on the other scene
okay I think I have audio here now let
okay I think I have audio here now let
me go double check from the
stream let me make sure this works
does this
does this
work test does this work yes okay it
work test does this work yes okay it
does
good okay now we have our paper review
good okay now we have our paper review
SC paper and code review
SC paper and code review
good okay
so recent
so recent
years RL methods have been proposed to
years RL methods have been proposed to
explore complex environment forr
explore complex environment forr
episodes in work we show that the
episodes in work we show that the
effectiveness of these methods were
effectiveness of these methods were
critically relies on account-based
critically relies on account-based
episodic term in their exploration bonus
episodic term in their exploration bonus
okay that entire line of work on
okay that entire line of work on
count-based uh bonus is bad idea does
count-based uh bonus is bad idea does
like that's a ridiculous thing to be
like that's a ridiculous thing to be
doing so they extend it here extend
doing so they extend it here extend
count-based episodic bonus to continuous
count-based episodic bonus to continuous
State spaces and encourages an agent to
State spaces and encourages an agent to
explore states that are diverse under a
explore states that are diverse under a
learned embedding within each
learned embedding within each
episode this embedding is is learned
episode this embedding is is learned
using an inverse Dynamics model in order
using an inverse Dynamics model in order
to capture controllable aspects of the
to capture controllable aspects of the
environment method sets a new state the
environment method sets a new state the
art across 16 challenging task for mini
art across 16 challenging task for mini
hack Suite without requiring task
hack Suite without requiring task
specific inductive
specific inductive
biases e 3B also matches existing
biases e 3B also matches existing
methods on sparse reward pixel based
methods on sparse reward pixel based
visdom out performance existing method
visdom out performance existing method
reward for exploration on
reward for exploration on
habitat demonstrating it can scale to
habitat demonstrating it can scale to
high dimensional pixel based
high dimensional pixel based
observations and a realistic environment
observations and a realistic environment
okay
um intro
here got R&D ICM pseudo
counts designed for Singleton RL
counts designed for Singleton RL
tasks the agent is spawned in the same
tasks the agent is spawned in the same
environment every
episode okay that's not entirely
true but yes these methods are pretty
limited number of methods have been
limited number of methods have been
proposed which have shown promising
proposed which have shown promising
performance in
PCG okay this is funny because
PCG okay this is funny because
procedurally generated environments are
procedurally generated environments are
often easier um than fixed environments
often easier um than fixed environments
it helps it's called domain uh domain
it helps it's called domain uh domain
randomization it's a natural curriculum
randomization it's a natural curriculum
so this is kind of f
me surprisingly count base often
me surprisingly count base often
includes Zer ristic is in fact
includes Zer ristic is in fact
essential methods fail if it's omitted
essential methods fail if it's omitted
okay existing methods fail more complex
okay existing methods fail more complex
tasks
sure we're not reading
sure we're not reading
this uh exploration
bonuses that's just needless
bonuses that's just needless
formalism environment rewards are sparse
formalism environment rewards are sparse
learning a policy using simple Epson
learning a policy using simple Epson
greedy exploration may require
greedy exploration may require
intractably many
intractably many
samples
samples
yes oh I remember liking this paper
yes oh I remember liking this paper
forgot the details yeah we're looking at
forgot the details yeah we're looking at
this now
this now
uh for some stuff
uh for some stuff
Ryan welcome to the code review setup or
Ryan welcome to the code review setup or
the paper and code review set
the paper and code review set
up oh also we found some screwy things
up oh also we found some screwy things
with carbs so I think we're going to be
with carbs so I think we're going to be
able to make hyper pram search for RL
able to make hyper pram search for RL
way better over the next
week spending a couple hours on this
week spending a couple hours on this
though consider methods that augment the
though consider methods that augment the
external reward function r with an
external reward function r with an
intrinsic reward bonus
B number of intrinsic bonuses that
B number of intrinsic bonuses that
encourage exploration in Singleton
encourage exploration in Singleton
proposed including pseudo camps ICM R&D
proposed including pseudo camps ICM R&D
okay if you make that easy you're a hero
okay if you make that easy you're a hero
and never do anything besides manual
and never do anything besides manual
okay Ryan like you're throwing away 99%
okay Ryan like you're throwing away 99%
of your compute this has kind of been
of your compute this has kind of been
the conclusion lately um I've been
the conclusion lately um I've been
realizing over the last few days so
realizing over the last few days so
people throw away uh a 100x to 1,000x
people throw away uh a 100x to 1,000x
compute off of using slow environments
compute off of using slow environments
but then they actually throw away
but then they actually throw away
another 100x compute on bad hyper pram
another 100x compute on bad hyper pram
search so literally all of RL is running
search so literally all of RL is running
at like 110,000 of the speed that it
at like 110,000 of the speed that it
should be and we wonder why nothing
should be and we wonder why nothing
works it's that
works it's that
bad I mean it's like the the more that I
bad I mean it's like the the more that I
dig the more stuff I find and it's like
dig the more stuff I find and it's like
it's not even like RL is just a hard
it's not even like RL is just a hard
hard thing it's literally just that
hard thing it's literally just that
we've screwed up the engine engering at
we've screwed up the engine engering at
every possible
level these methods Define an intrinsic
level these methods Define an intrinsic
reward bonus that is high if the current
reward bonus that is high if the current
state is different from the previous
state is different from the previous
States visit but visited by the agent
States visit but visited by the agent
and low if it is similar According to
and low if it is similar According to
some measure
okay so they all have some distance
okay so they all have some distance
measure Over
States more recently several measure
States more recently several measure
methods have been proposed for an
methods have been proposed for an
evaluate on procedurally generated the
evaluate on procedurally generated the
mdps I'll use different exploration
bonuses summarize in table
bonuses summarize in table
one bonus based on distance between the
embeddings second Bar D
embeddings second Bar D
bonuses okay so basically we want we
bonuses okay so basically we want we
want to try one of these that is simple
want to try one of these that is simple
and doesn't make a mess out of all your
and doesn't make a mess out of all your
learning code and we want to see if it
learning code and we want to see if it
does anything importance and limitations
does anything importance and limitations
of count-based exploration
bonuses three methods with and without
bonuses three methods with and without
the respective count-based episodic
the respective count-based episodic
terms on one of the Min grid
terms on one of the Min grid
environments Us in Prior work
minig grid n10 S10
minig grid n10 S10
v0 what is
this does anybody know what this
this does anybody know what this
is n10 S10 v0
yeah but what is this
environment what is
environment what is
it I can't see the environment to see if
it I can't see the environment to see if
this is actually
this is actually
interesting
interesting
um is this built
um is this built
in can I like go render it for
okay what what is this
okay what what is this
environment I wish they I can't find it
environment I wish they I can't find it
but the thing that I'm concerned here
but the thing that I'm concerned here
with is this axis is
with is this axis is
17 17 is nothing I train this is 10
17 17 is nothing I train this is 10
seconds of learning if your library
seconds of learning if your library
doesn't
doesn't
suck
suck
so like if you look at it that way this
so like if you look at it that way this
is a 10-second experiment like oh look
is a 10-second experiment like oh look
no episodic counts you don't make
no episodic counts you don't make
progress I most of these problems you
progress I most of these problems you
can literally brute force with po um
can literally brute force with po um
fair enough though yeah you add episodic
fair enough though yeah you add episodic
counts and it learns way faster because
counts and it learns way faster because
obviously it does and cuz that's like a
obviously it does and cuz that's like a
thing you can do with grid environments
fine because like the problem is
fine because like the problem is
fundamentally intractable right without
fundamentally intractable right without
a ton of samples without this like
a ton of samples without this like
exploration
exploration
thing um it looks like a ridiculously
thing um it looks like a ridiculously
deep uh exponential SEF space
see
it's if each state is
it's if each state is
unique and that will always be one and
unique and that will always be one and
the okay
the okay
yes so you need some sort of encoding
yes so you need some sort of encoding
over the observation not just the state
relevant features from each state and
relevant features from each state and
feed them to count
feed them to count
based well this still doesn't make sense
based well this still doesn't make sense
really unless you have a good
discretization got drop C around
Ryan figure two shows results on two
Ryan figure two shows results on two
tasks from the mini hack Suite 3 novel D
tasks from the mini hack Suite 3 novel D
variants
variants
TR to
outperform standard
formulation it's a bonus deisal feature
formulation it's a bonus deisal feature
encoding and episode bonus
encoding and episode bonus
okay it's X and
Y failed to enabl Sol multi room one
Y failed to enabl Sol multi room one
freeze okay cool
freeze okay cool
in this section we describe exploration
in this section we describe exploration
VI elliptical episode
bonuses we'd like an episode bonus that
bonuses we'd like an episode bonus that
can be used in continuous date
can be used in continuous date
representations we'd like a
representations we'd like a
representation learning method that only
representation learning method that only
captures information about the
captures information about the
environment is relevant for the task at
environment is relevant for the task at
hand first requirement is meant by using
hand first requirement is meant by using
an elliptical bonus whatever that means
an elliptical bonus whatever that means
continuous analog to counts spased
continuous analog to counts spased
bonus we'll see
bonus we'll see
how second
how second
requirements met by using a
requirements met by using a
representation learn with an inverse
representation learn with an inverse
Dynamics
Dynamics
model elliptical bonus given a feature
model elliptical bonus given a feature
encoding the elliptical episode bonus is
encoding the elliptical episode bonus is
described as
described as
follows what the hell
follows what the hell
um how do you get one7 steps in 10
um how do you get one7 steps in 10
seconds that would take me like an hour
seconds that would take me like an hour
RMS are fast so
RMS are fast so
this is why puffer is awesome right all
this is why puffer is awesome right all
of these environments run at a million
of these environments run at a million
steps per second on a single CPU core
steps per second on a single CPU core
and most of them train between 300,000
and most of them train between 300,000
and like 1.2 million steps per second on
and like 1.2 million steps per second on
one
GPU and these range from very simple to
GPU and these range from very simple to
some of the most complicated RL
some of the most complicated RL
environments out there like we can train
environments out there like we can train
neural mm3 at about 500,000 steps per
neural mm3 at about 500,000 steps per
second um this is a massively
second um this is a massively
multi-agent open world environment with
multi-agent open world environment with
economy and trade and all sorts of stuff
economy and trade and all sorts of stuff
what's puffer puffer is the library that
what's puffer puffer is the library that
I am developing to fix the gigantic mess
I am developing to fix the gigantic mess
that reinforcement learning is in at the
that reinforcement learning is in at the
moment you can check it out at puffer
moment you can check it out at puffer
doai GitHub is right here it's all free
doai GitHub is right here it's all free
and open source start to help us out a
and open source start to help us out a
bunch and uh we've got a nice Discord
bunch and uh we've got a nice Discord
community of people building high
community of people building high
performance rlms and we're starting to
performance rlms and we're starting to
now use those High per rlms to run
now use those High per rlms to run
thousands and thousands of experiments
thousands and thousands of experiments
to fix all the other problems around RL
to fix all the other problems around RL
because we can do that now since they're
fast so yeah this is pretty much what I
fast so yeah this is pretty much what I
do it's like I just stream all of my
do it's like I just stream all of my
work on on puffer lib which includes
work on on puffer lib which includes
developing and merging environments it
developing and merging environments it
includes doing science side work on top
includes doing science side work on top
of our environments it includes doing
of our environments it includes doing
you know some support stuff for clients
you know some support stuff for clients
adding specific features to puffer lib
adding specific features to puffer lib
that people need uh for both like
that people need uh for both like
companies and academic Labs uh it's just
companies and academic Labs uh it's just
generally this is my effort to try to
generally this is my effort to try to
fix the mess that reinforcement learning
fix the mess that reinforcement learning
is in where everything is kind of cursed
is in where everything is kind of cursed
and hard to make to
and hard to make to
work we got classic ones too simple
work we got classic ones too simple
pong these are neural Nets these are
pong these are neural Nets these are
trained agents running in your browser
trained agents running in your browser
as
well multi-agent snake lots of stuff
what is this elliptical episode
bonus
so feature encoding I assume is just
so feature encoding I assume is just
going to be like the hidden
State and then
what is this
what is this
Matrix so this is a vect
Matrix so this is a vect
weight is this an outer
product this is how easy is it to import
product this is how easy is it to import
my own environment like a simple
my own environment like a simple
imported uh inverted pendulum we have
imported uh inverted pendulum we have
wrappers for gymnasium environment ments
wrappers for gymnasium environment ments
and for petting zoo environments you
and for petting zoo environments you
will immediately get a performance speed
will immediately get a performance speed
up out of our CPU vectorization on those
up out of our CPU vectorization on those
because our vectorization is much faster
because our vectorization is much faster
than what everything else that is out
than what everything else that is out
there um for the maximum maximum
there um for the maximum maximum
performance you're going to want to look
performance you're going to want to look
at our native API and our native M's but
at our native API and our native M's but
if you just want like out of the box get
if you just want like out of the box get
some good performance speedups get like
some good performance speedups get like
nice hyper parameter sweep to get RL
nice hyper parameter sweep to get RL
working generally then it's very very
working generally then it's very very
easy and we have lots and lots of
easy and we have lots and lots of
examples um basically anything in the
examples um basically anything in the
puffer lib environments folder like any
puffer lib environments folder like any
of like the main environments that are
of like the main environments that are
actually used actively you can see how
actually used actively you can see how
we bind it's like a oneline
wrapper pretty much puffer will give you
wrapper pretty much puffer will give you
the best performance for the level of
the best performance for the level of
engineering effort that you want to put
engineering effort that you want to put
in if you just want to wrap an existing
in if you just want to wrap an existing
environment that's fine if you want to
environment that's fine if you want to
do a little bit more work you know you
do a little bit more work you know you
can get faster and it goes all the way
can get faster and it goes all the way
up to million steps per second
training okay so this formulation
training okay so this formulation
bothers me a
bothers me a
lot
because well hold on I guess nice look
because well hold on I guess nice look
of the rapper try yeah I mean this is
of the rapper try yeah I mean this is
why I stream as well if you run into any
why I stream as well if you run into any
trouble I'm right here right put paste
trouble I'm right here right put paste
errors I help
fix okay maybe this isn't that bad
fix okay maybe this isn't that bad
because you can Cal this
right so this is a
sum wait I equal
sum wait I equal
1 to T minus1
given a feature encoding at each time
step is this over the entire
episode so regularization term to make
episode so regularization term to make
sure that it's not
sure that it's not
singular but that's not a good way of
singular but that's not a good way of
making a matrix not
making a matrix not
singular and it's an outer
product okay so this is a kind of
crazy function to
include it's a kind of a crazy function
include it's a kind of a crazy function
I guess technically
technically you can like pass this as an
technically you can like pass this as an
extra State variable I
guess you can technically pass this as
guess you can technically pass this as
an extra State
variable yeah
you have to reset this thing though
you have to reset this thing though
don't
you can I Decay it over
time I wonder if I can modify this to
time I wonder if I can modify this to
Decay over
time and wait do you differentiate
time and wait do you differentiate
through this thing
intrinsic
rewards I think that if this is just the
rewards I think that if this is just the
reward you don't differentiate through
reward you don't differentiate through
this right
natural generalization of a count based
natural generalization of a count based
episod I have no idea how problem is
episod I have no idea how problem is
tabular this is a one hot en coding of
tabular this is a one hot en coding of
state and this will be a diagonal matrix
state and this will be a diagonal matrix
as entries contain the count
as entries contain the count
corresponding to each
corresponding to each
state encountered in the
episode
what C T minus one
oh that's kind of
wonky inverse will also be a diagonal
wonky inverse will also be a diagonal
matrix his entries are inverse State
matrix his entries are inverse State
visitation
visitation
counts which off the entry corresponding
counts which off the entry corresponding
yielding a bonus of okay yeah so these
yielding a bonus of okay yeah so these
are fan some fancy math people did some
are fan some fancy math people did some
fancy math I I kind of see how this
fancy math I I kind of see how this
works
works
for more General geometric interpr
interpretation if they're roughly
interpretation if they're roughly
centered at
centered at
zero unnormalized covariance Matrix what
zero unnormalized covariance Matrix what
the heck to that now consider the igen
the heck to that now consider the igen
decomposition
okay set of coordinates we can write the
okay set of coordinates we can write the
elliptical bonus
okay I have no idea honestly like this
okay I have no idea honestly like this
is I don't know what the hell any of
is I don't know what the hell any of
this is but okay um efficient
this is but okay um efficient
computation The Matrix needs to be
computation The Matrix needs to be
inverted at each
inverted at each
step operation that's
step operation that's
cubic we use the Sherman Morrison Matrix
cubic we use the Sherman Morrison Matrix
identity to perform fast rank one
identity to perform fast rank one
updates in quadratic time
see T minus
one
jeez okay
learned feature
learned feature
encoder any feature learning method
encoder any feature learning method
could in principle be
used here we use the inverse Dynamics
used here we use the inverse Dynamics
model approach in
model approach in
52 a model G along
52 a model G along
with Fe to map each
with Fe to map each
pair of consecutive
pair of consecutive
embeddings to a distribution over
embeddings to a distribution over
actions at linking
actions at linking
them separate from the policy
Network model is changed
Network model is changed
jointly the following per sample loss
jointly the following per sample loss
so you
so you
take this
buffer jeez
okay sample
action step through environment
action step through environment
compute
compute
bonus update covariance
Matrix from policy grading update is
Matrix from policy grading update is
rewards
rewards
update to minimize the
loss
okay torch Beast andace yeah terrible
okay torch Beast andace yeah terrible
library and then they just do
and then they do well
and then they do well
cool mini hack is not a very competitive
cool mini hack is not a very competitive
Benchmark cuz not enough people use
Benchmark cuz not enough people use
it
andala 3
B they underperform this
blue
blue
one or green
one or green
[Music]
one get this
okay this is
okay this is
cool that's a good result
again these are not very competitive
again these are not very competitive
benchmarks cuz they're like five people
benchmarks cuz they're like five people
doing this
work different okay
different algorithmic
components where is a randomly
components where is a randomly
initialized
initialized
Network this is bad
okay policy en code indicates
okay policy en code indicates
when these weights are tied to those of
when these weights are tied to those of
the policy Network
the policy Network
with the last layer
with the last layer
producing action probabilities
removed so instead of doing the act the
removed so instead of doing the act the
inverse Dynamics model this is actually
inverse Dynamics model this is actually
way simpler and that looks pretty
way simpler and that looks pretty
decent elliptical bonuses comped using
decent elliptical bonuses comped using
observations across
observations across
all time
all time
steps and not just the current episode
elliptical bonus is computed using
elliptical bonus is computed using
observations yeah so that Matrix just
observations yeah so that Matrix just
gets too much junk in it I
gets too much junk in it I
guess can you just I think I want to do
guess can you just I think I want to do
an exponential decaying
thing wait this highlights the both the
thing wait this highlights the both the
index and the episodic
index and the episodic
bonus well this is pretty good the
bonus well this is pretty good the
policy and code version is pretty good
policy and code version is pretty good
and it's simpler right
mini hack
ablations yeah this is pretty good right
ablations yeah this is pretty good right
here we're not having to train a whole
here we're not having to train a whole
inverse Dynamics
inverse Dynamics
model I actually like this one more
model I actually like this one more
here what did they get
here what did they get
Point say
6 and then
yeah so this is still better than the
yeah so this is still better than the
other
other
methods
methods
um this should still be better than the
um this should still be better than the
other
other
methods using without the inverse
methods using without the inverse
Dynamics model and it's much
Dynamics model and it's much
simpler so that's kind of what I want to
simpler so that's kind of what I want to
try Red Hook what's this that's
funny we got any appendix
funny we got any appendix
and useless
checklist they had this already I
think all these Nerfs checklist and
think all these Nerfs checklist and
statements are just so
statements are just so
dumb um follow
dumb um follow
this five layer comom
this five layer comom
okay it's a big policy for
RL
RL
Impala H for
Impala H for
parameters we did not
nail rolling
nail rolling
[Music]
[Music]
normalization
normalization
[Music]
deviation so they
tuned they just tuned their new hyper
tuned they just tuned their new hyper
paramet
yeah so you can see that they didn't
yeah so you can see that they didn't
these are just some parameter somebody
these are just some parameter somebody
came up
came up
with um
with um
okay so they could do way better just by
okay so they could do way better just by
tuning this stuff but the rl's too
slow
okay oh the they do
tune They Don't Really
tune They Don't Really
tune I guess they did a little bit of
tune I guess they did a little bit of
sweep but not
sweep but not
really they did like a dumb grid search
really they did like a dumb grid search
that's
fine okay neither Baseline okay
fine okay neither Baseline okay
okay well I'm not going to be too hard
okay well I'm not going to be too hard
on them like the results aren't going to
on them like the results aren't going to
be good cuz they're slow so it's it's
fine GP 100 what the
fine GP 100 what the
heck 10 and 30
heck 10 and 30
hours
yuck e3b was 1.5 to two times
yuck e3b was 1.5 to two times
slower additional forward pass through
slower additional forward pass through
the embedding Network used to compute
the embedding Network used to compute
the elliptical
bonus was performed on
bonus was performed on
CPU
why
okay do they release code
okay so they do actually tune a little
okay so they do actually tune a little
bit not great tuning but they tune a
bit not great tuning but they tune a
little
little
bit habitat details
bit habitat details
yeah code base
yeah code base
used official
official okay well where's your code
official okay well where's your code
base
yeah so I'm pretty sure we solve most of
yeah so I'm pretty sure we solve most of
these problems in puffer just like with
these problems in puffer just like with
tuned hyper parameters and more samples
tuned hyper parameters and more samples
and training
and training
fast
fast
um but fine we'll look at this
So Co variance regularizer
robust do they release
code they do
good good
job was published in 2020 oh 2022 okay
job was published in 2020 oh 2022 okay
so 3 years cool
so 3 years cool
um is there there anything more recent
um is there there anything more recent
than this or is this the like the best
thing let
thing let
me I don't know maybe let me just real
quick e
good job you reported older
good job you reported older
papers
stupid jity not
smart okay let's see code
smart okay let's see code
I'm I'm expecting this to be
I'm I'm expecting this to be
horrifying if this is built on forch
horrifying if this is built on forch
beast and
stuff okay wait we got it in Sample
stuff okay wait we got it in Sample
Factory
mini hack SL sample
Factory
okay this is 10 times faster than
okay this is 10 times faster than
before 10K FPS is 10 times faster than
before 10K FPS is 10 times faster than
before that is horrifying holy
hell good job
Alexi
um ah they do have the sweep
here is this just vendor yeah this is
here is this just vendor yeah this is
vendor sample Factory
so where is
this where the heck is this
I love it when the code base is
I love it when the code base is
structured such that you can't even find
structured such that you can't even find
the code in the code
base e3bp anybody
no no E3
b.p dude
b.p dude
how where is the
code do I have to look at the other one
code do I have to look at the other one
because of how ridiculous this
because of how ridiculous this
is um
they still have a
they still have a
bajillion D this
bajillion D this
is this should be a paper that is like
is this should be a paper that is like
300 lines of code on top of a standard
300 lines of code on top of a standard
implementation I do not know what the
hell maybe
hell maybe
this okay hold on
Source
FES
okay is
okay is
this okay here's your inverse Dynamics
this okay here's your inverse Dynamics
cool and
cool and
then e3bp
elliptical encoder
I honestly have no idea how I've stayed
I honestly have no idea how I've stayed
in RL this long cuz like I remember
in RL this long cuz like I remember
having to deal with stuff like this and
having to deal with stuff like this and
it's just a miserable time it's just an
it's just a miserable time it's just an
absolutely miserable time having to deal
absolutely miserable time having to deal
with li like
this um
this um
they have a separate Optimizer for the
encoder is it2
share memory what is
that okay so here's the
that okay so here's the
actual learn
actual learn
function so
that's
obscene
obscene
uh oh maybe okay this is just setting
uh oh maybe okay this is just setting
the mode okay right yeah this
the mode okay right yeah this
is please tell me this should just be
is please tell me this should just be
setting the
setting the
mode and
mode and
then elliptical encoder
State embed all
reward is bat a
reward R trce
return Baseline loss
turns yeah man I know it's this code is
turns yeah man I know it's this code is
like I literally don't
understand like literally you work on
understand like literally you work on
this code bra base for a week you'll
this code bra base for a week you'll
have crippling depression there's no way
have crippling depression there's no way
around
it like I remember when working in RL
it like I remember when working in RL
sucked this much in the first few years
sucked this much in the first few years
of my P HD and it was a miserable time
of my P HD and it was a miserable time
like I honestly don't know how I stayed
like I honestly don't know how I stayed
in this field for this long to like
in this field for this long to like
actually get to the point where stuff
actually get to the point where stuff
doesn't suck because like it's actually
doesn't suck because like it's actually
just miserable working on code like
this there's the thing with puffer it's
this there's the thing with puffer it's
like stuff's actually easy and make
like stuff's actually easy and make
sense now
it's kind of funny like I always like I
it's kind of funny like I always like I
start thinking like ah the stuff I'm
start thinking like ah the stuff I'm
doing with puffer is kind of simple
doing with puffer is kind of simple
actually and then like I go look at what
actually and then like I go look at what
everyone else is doing and I was like oh
everyone else is doing and I was like oh
my gosh okay yeah no we're doing good
my gosh okay yeah no we're doing good
work
here I have some weird puffer issues to
here I have some weird puffer issues to
ask about have you tested it with slow
ask about have you tested it with slow
multi-agent
multi-agent
M yeah it should
M yeah it should
work um that should work if you link me
work um that should work if you link me
a thing I will take a look at it
gladly slow multi-agent Ms with like
gladly slow multi-agent Ms with like
petting through wrapper or whatever you
petting through wrapper or whatever you
should just like double buffer sample on
should just like double buffer sample on
all the
all the
course and you should get close to num
course and you should get close to num
core speed up
sure what M specifically are you messing
with equal speed with here that sucks um
with equal speed with here that sucks um
now puffer should be way
now puffer should be way
faster Ridley laser tag n
um gley has its own internal
um gley has its own internal
vectorization though Ryan
right doesn't gly have its own internal
vectorization I don't know I'm using
vectorization I don't know I'm using
poppers okay I can look at it I know
poppers okay I can look at it I know
Gridley has really obnoxiously slow
Gridley has really obnoxiously slow
resets so he actually have to be pretty
resets so he actually have to be pretty
careful with your
careful with your
async
um but yeah if you have if you have cuz
um but yeah if you have if you have cuz
I know the our gridly binding is out a
I know the our gridly binding is out a
date so if you just want a like PR
date so if you just want a like PR
version of Gridley that actually works
version of Gridley that actually works
then I will be more than happy to uh you
then I will be more than happy to uh you
know run the perf test on whatever M
know run the perf test on whatever M
you're playing with
puffer should be
fast look into more
fast look into more
yeah you don't have to narrow down the
yeah you don't have to narrow down the
issue all you got to do is PR or like a
issue all you got to do is PR or like a
branch or whatever a
branch or whatever a
version like that I can just run right
version like that I can just run right
and see it
so either like link me your if you have
so either like link me your if you have
a fork of puffer or whatever you know
a fork of puffer or whatever you know
ideally if you're using gridly and you
ideally if you're using gridly and you
actually have it working with puffer it
actually have it working with puffer it
would be nice to have that PR cuz I
would be nice to have that PR cuz I
haven't had the time to mess with
haven't had the time to mess with
Gridley and Gridley is pretty
cool like we have a binding for Gridley
cool like we have a binding for Gridley
it just doesn't I don't think it works
it just doesn't I don't think it works
cuz Gridley is kind of weird they don't
cuz Gridley is kind of weird they don't
Define the observation spes until you
Define the observation spes until you
reset the n and that kind of screws some
reset the n and that kind of screws some
stuff
up technically not able to
share
really
oh yeah okay well if we want to do
oh yeah okay well if we want to do
something privately we can that's uh
I don't know why people do that on
I don't know why people do that on
academic research that should just that
academic research that should just that
should just be published by now but is
should just be published by now but is
it wait isn't that is it not a built-in
it wait isn't that is it not a built-in
gridly m is that not like a built-in
gridly m is that not like a built-in
gridly m
okay so we is the custom
M well I don't usually look at closed
M well I don't usually look at closed
Source
Source
Ms um but for you yeah I'll take a quick
Ms um but for you yeah I'll take a quick
look at
look at
in and see if I can figure out what's
in and see if I can figure out what's
wrong
really is pretty
cool sucks for RL that
cool sucks for RL that
um that
um that
mistel got uh got
mistel got uh got
Chris it' be awesome to have him doing
Chris it' be awesome to have him doing
RL stuff
nowadays I wonder what Chris would think
nowadays I wonder what Chris would think
of all the C stuff that I've been
of all the C stuff that I've been
writing I think he'd be down with it
writing I think he'd be down with it
it's like really just freaking simple
it's like really just freaking simple
ass C I think he'd be down with
it isn't he not a big RL
it isn't he not a big RL
fan I don't know about that I think he's
fan I don't know about that I think he's
just been doing language models at
just been doing language models at
minstral with a bunch of guys that are
minstral with a bunch of guys that are
like writing code 247 and having a good
like writing code 247 and having a good
time getting a nice
time getting a nice
paycheck I don't know if he like doesn't
paycheck I don't know if he like doesn't
like RL anymore I haven't heard that
nice it works well yeah RL is freaking
nice it works well yeah RL is freaking
cursed and broken because it hasn't had
cursed and broken because it hasn't had
billions of dollars of engineering
billions of dollars of engineering
investment but uh you know next best
investment but uh you know next best
thing is going to be one you know one
thing is going to be one you know one
puffer Libs worth of engineering
puffer Libs worth of engineering
investment it RL is going to work 2025
investment it RL is going to work 2025
here it's going to be 10 times easier to
here it's going to be 10 times easier to
get stuff up and running literally I'm
get stuff up and running literally I'm
telling you the end of the end of 25
telling you the end of the end of 25
we're going to have RL 10 times easier
we're going to have RL 10 times easier
to get working on new problems than it
to get working on new problems than it
is now so if it would take you you know
is now so if it would take you you know
10 hours to get something working on a
10 hours to get something working on a
new M it's going to take you one hour if
new M it's going to take you one hour if
it would take you 10 days it will take
it would take you 10 days it will take
you one day
curriculum learning will be easier as
curriculum learning will be easier as
well you should do um if you well I know
well you should do um if you well I know
you have enough work to do already but
you have enough work to do already but
um syllabus
um syllabus
with puffer native ends would be a cool
with puffer native ends would be a cool
thing it's a little tricky
thing it's a little tricky
because pipes are slow like on the scale
because pipes are slow like on the scale
of how fast our um our M's are pipes are
of how fast our um our M's are pipes are
just too slow so so you'd probably have
just too slow so so you'd probably have
to do like a shared memory
to do like a shared memory
thing yeah exactly like you can't you
thing yeah exactly like you can't you
can't just have like the pipe thing that
can't just have like the pipe thing that
you have is perfectly good for most RL
you have is perfectly good for most RL
environments but at our scale like when
environments but at our scale like when
we're doing a million steps per second
we're doing a million steps per second
you can if you you can still communicate
you can if you you can still communicate
stuff across processes and whatnot but
stuff across processes and whatnot but
it's got to be in shared
it's got to be in shared
memory it'd be pretty easy to bind for
memory it'd be pretty easy to bind for
um our like single process native M
um our like single process native M
though cuz a lot of our M's are so fast
though cuz a lot of our M's are so fast
we literally just run them on the main
we literally just run them on the main
process and still train it a million
process and still train it a million
steps per
second time for fast
second time for fast
prototyping yeah
prototyping yeah
wow the goal is to do both right with
wow the goal is to do both right with
puffer like if you look at our M
puffer like if you look at our M
wrappers and stuff stuff's actually very
wrappers and stuff stuff's actually very
very simple and it's fast so we like to
very simple and it's fast so we like to
have our cake and eat it
too we an elliptical
[Music]
encoder what the
encoder what the
hell net hack State embedding net
models
dot where the hell are
dot where the hell are
models issues the curriculum learning
models issues the curriculum learning
algorithms of totally random interfaces
algorithms of totally random interfaces
they're hard to hard to optimize out of
they're hard to hard to optimize out of
time need arbitrary data transfer to two
time need arbitrary data transfer to two
and from
and from
M's yeah but we can do
M's yeah but we can do
that like that's not that hard to
that like that's not that hard to
add you have to have the data be you
add you have to have the data be you
have to put the data into an
have to put the data into an
array um but if you do that then it's
array um but if you do that then it's
not that
bad cuz like what we do is we just
bad cuz like what we do is we just
instead of having a pipe right you just
instead of having a pipe right you just
have a shared memory buffer that you
have a shared memory buffer that you
write to so you're basically you're
write to so you're basically you're
writing to a number High Ray and shared
writing to a number High Ray and shared
memory the only thing that's obnoxious
memory the only thing that's obnoxious
is like we'd have to add an extra thing
is like we'd have to add an extra thing
into the all the environments uh just to
into the all the environments uh just to
support the curriculum learning stuff um
support the curriculum learning stuff um
so there'd have to be pretty damn
so there'd have to be pretty damn
compelling evidence that like you know
compelling evidence that like you know
this is the thing that's going to make
this is the thing that's going to make
RL sane and
RL sane and
stable I like curriculum learning so I
stable I like curriculum learning so I
think it's definitely possible but we
think it's definitely possible but we
need
evidence really need to reoptimize it
evidence really need to reoptimize it
every time you add yeah but the thing is
every time you add yeah but the thing is
Ryan like you're in this mindset where
Ryan like you're in this mindset where
there are a million algorithms
there are a million algorithms
constantly and like we need to support
constantly and like we need to support
all of them we genuinely don't care we
all of them we genuinely don't care we
just need like one good algorithm that
just need like one good algorithm that
works and we just support the current
works and we just support the current
best thing and that's
it
it
right like puffer doesn't have a million
right like puffer doesn't have a million
different algorithms and which not to
different algorithms and which not to
designed for a million different
designed for a million different
algorithms that have like arbitrary
algorithms that have like arbitrary
screwy things that they do we have like
screwy things that they do we have like
a simple V interface that
works we have no idea it
works we have no idea it
works yeah I mean my approach to
works yeah I mean my approach to
figuring out what's Works has just been
figuring out what's Works has just been
make the experiments run like 10,000 x
make the experiments run like 10,000 x
faster and then you kind of don't have
faster and then you kind of don't have
to be very smart if you do that you just
to be very smart if you do that you just
run everything
where their
where their
models I literally can't find their
models I literally can't find their
models how's this import even
work models
work models
dot
dot
huh source. models as models
oh it's a
oh it's a
file I thought it' be a
file I thought it' be a
folder me dumb
folder me dumb
okay net hack I remember this crop
okay net hack I remember this crop
banana
agains this is the elliptical
thingy why is there a full model on the
thingy why is there a full model on the
elliptical
thing I do not understand
this state embeddings
so neither of these look like an
so neither of these look like an
elliptical well neither of these look
elliptical well neither of these look
like the
like the
elliptical right neither of these look
elliptical right neither of these look
like the elliptical at
all so they have elliptical encoder
all so they have elliptical encoder
optim elliptical
encoder where's this thing
and then they Define
and then they Define
this so this is this thing I guess it's
this so this is this thing I guess it's
going to be in the loss function or
something
elliptical encoder
this so hard to figure this [ __ ]
this so hard to figure this [ __ ]
out
um I guess it's going to be in here is
um I guess it's going to be in here is
it compute policy gradient
it compute policy gradient
loss where's the
loss where's the
reward intrinsic rewards Plus
bonus
bonus
reward romly yeah
it's this is I've been reviewing like
it's this is I've been reviewing like
academic code bases all week and this is
academic code bases all week and this is
the worst by
the worst by
far this is just the
far this is just the
worst and that includes me having to
worst and that includes me having to
deal with rlb code
well the thing is rlb is they just have
well the thing is rlb is they just have
zero use like they have zero checks on
zero use like they have zero checks on
their API so like if you just if you use
their API so like if you just if you use
their API wrong at all you just get like
their API wrong at all you just get like
garbage internal messages 10 layers deep
garbage internal messages 10 layers deep
and then it's slow but the thing is once
and then it's slow but the thing is once
you actually get the code written
you actually get the code written
correctly like it will run and not be
correctly like it will run and not be
that much code it's completely opaque
that much code it's completely opaque
and you can't deal do anything with it
and you can't deal do anything with it
but like it runs this is just like
but like it runs this is just like
demonic I have no idea what this
demonic I have no idea what this
is which is annoying because it looks
is which is annoying because it looks
like a pretty decent paper but then it's
like a pretty decent paper but then it's
just like you look at the code and it's
just like you look at the code and it's
holy
hell okay I guess so this is inverse
hell okay I guess so this is inverse
Dynamics
Dynamics
floss right and then they have
floss right and then they have
elliptical encoder
where does the intrinsic reward get
where does the intrinsic reward get
computed bonus reward I don't know where
computed bonus reward I don't know where
this gets
this gets
rewarded at least it's just a bunch of
rewarded at least it's just a bunch of
yeah I
yeah I
guess but this is like maniacal I can't
guess but this is like maniacal I can't
find where they have the elliptical code
is it in
here this is net
here this is net
right so I don't see elliptical in here
right so I don't see elliptical in here
where's the Matrix stuff
right there's supposed to
right there's supposed to
be code on like low rank Matrix stuff
all the curriculum on that's good that
all the curriculum on that's good that
is what you should
is what you should
do I like I literally can't
do I like I literally can't
find is this
find is this
it
no like where's the low rank Matrix
no like where's the low rank Matrix
stuff
they have a whole habit of
yeah but I need to find where they
yeah but I need to find where they
compute it oh yeah Ryan I wanted to ask
compute it oh yeah Ryan I wanted to ask
you as well
you as well
so they have here let me find this I I
so they have here let me find this I I
thought I did something kind of clever
thought I did something kind of clever
here um I thought I found something kind
here um I thought I found something kind
of
of
clever with their
clever with their
math so here's the
math so here's the
paper um I think I found a nice
paper um I think I found a nice
Improvement to it so there's there's a
Improvement to it so there's there's a
major implementation Quirk here where
major implementation Quirk here where
it's just going to be very very
it's just going to be very very
difficult to implement this
difficult to implement this
incorrectly um this is defined over
incorrectly um this is defined over
episodes meaning that you need episode
episodes meaning that you need episode
bounds for
bounds for
this you need like per Agent episode
this you need like per Agent episode
bounds uh to compute this thing
bounds uh to compute this thing
correctly
correctly
so what I was thinking of doing is
so what I was thinking of doing is
instead in this is a a strict sum uh
instead in this is a a strict sum uh
right and they actually they have an
right and they actually they have an
oblation that says if you sum over
oblation that says if you sum over
everything like if you sum over all the
everything like if you sum over all the
episodes it's really bad nonepisodic
episodes it's really bad nonepisodic
right here so what if you made this
right here so what if you made this
exponentially
exponentially
decaying right what if I did like 0.9
decaying right what if I did like 0.9
times this thing like uh I just do
times this thing like uh I just do
like every every time you get a new one
like every every time you get a new one
of these you do
of these you do
* the old one plus 0.1 time the new one
* the old one plus 0.1 time the new one
or something like that they do like an
or something like that they do like an
exponentially decaying
thing and then you don't have to reset
it does that work
sounds interesting well the thing is
sounds interesting well the thing is
this you can't do
this you can't do
this you just can't do this when you
this you just can't do this when you
have variable episode length
literally where is their
literally where is their
freaking I'm log it where
freaking I'm log it where
is their
is their
fancy I literally can't find the piece
fancy I literally can't find the piece
of code that is the entire paper I can't
of code that is the entire paper I can't
find it
out e
literally where's the piece of
code okay what's the torch inverse
can I like search for
inverse KL
inverse e
is this
is this
it inverse
it inverse
covariance so this is it for
Habitat so we
Habitat so we
have one over
Ridge
Ridge
on inverse covariance
okay here's the outer product buffers
I'm trying to think how I'm going to add
I'm trying to think how I'm going to add
this to
puffery to think I'm going to add this
puffery to think I'm going to add this
to
to
puffer so
is it just like an extra
is it just like an extra
State let me
think look at the paper again
so you can almost just add this
so you can almost just add this
to to the network but not quite
to to the network but not quite
I think it's an extra state that we have
I think it's an extra state that we have
to
to
add just like the lstm
state wait
state wait
c t minus1
given a featureing coding
wait why does it only go to T minus
wait why does it only go to T minus
one hang
on okay so this is the previous date
on okay so this is the previous date
basically
wait does this have to get
wait does this have to get
differentiated through
yeah they use an inverse Dynamics model
yeah they use an inverse Dynamics model
for
fee but what was the alternative
here oh okay so this is a simple way of
here oh okay so this is a simple way of
producing
producing
it yeah you just chuse the hidden layer
it yeah you just chuse the hidden layer
okay so then if you do
okay so then if you do
that then this is gets just this is a
that then this is gets just this is a
DOT
detach I think this is not that
detach I think this is not that
bad this is not that bad so all I have
bad this is not that bad so all I have
to do is
to do is
add I have to add one state variable
the state variable is an inverted
Matrix and then what's this
update okay so there is a way to do
this we'll start with the standard thing
here and this thing is
here and this thing is
apparently apparently
useful just joined what paper is this
useful just joined what paper is this
this is
this is
e3b elliptical exploration via
e3b elliptical exploration via
elliptical episode
elliptical episode
bonuses they got this fancy function
bonuses they got this fancy function
here that they just add as a
reward and and this apparently
helps we're going to need to test this
helps we're going to need to test this
on a bunch of stuff
say it helps
say it helps
generally I mean they test on a bunch of
generally I mean they test on a bunch of
M's not as many M's as I would like but
M's not as many M's as I would like but
a bunch of
M's the thing is you like exploration is
M's the thing is you like exploration is
always key right it's just that by
always key right it's just that by
default we're doing it
default we're doing it
via um we're basically doing it via
via um we're basically doing it via
Brute Force initially
Brute Force initially
this is a generalization of counts
this is a generalization of counts
spaced exploration to continuous
spaced exploration to continuous
spaces
spaces
archived I mean it looks decent to me in
archived I mean it looks decent to me in
the sense that
the sense that
like this is not that hard to compute
like this is not that hard to compute
you add like you only have to add like
you add like you only have to add like
two small things to your
algorithm continuous no it's not
algorithm continuous no it's not
continuous action space specific it'll
continuous action space specific it'll
work for
anything it'll work for
whatever well it won't right you never
whatever well it won't right you never
know with these papers half the time
know with these papers half the time
they only work on the experiments that
they only work on the experiments that
they were done for here
they were done for here
but I don't know this
but I don't know this
probably this probably does
probably this probably does
something
something
um we'll see how annoying this thing is
um we'll see how annoying this thing is
to compute
I think it shouldn't be that
bad I'm going to go grab a quick I got a
bad I'm going to go grab a quick I got a
meeting in 30 minutes they have
meeting in 30 minutes they have
reference code yeah it's it's terrible
reference code yeah it's it's terrible
reference code but they have it it's a
reference code but they have it it's a
God awful reference code but they have
God awful reference code but they have
it it's on H Facebook research
e3b so I'm probably going to start
e3b so I'm probably going to start
implementing this later
implementing this later
tonight I got a 300 p.m. meeting so
tonight I got a 300 p.m. meeting so
probably and I got to make a couple
probably and I got to make a couple
quick calls so probably after that so
quick calls so probably after that so
yeah let me do that now what I'm going
yeah let me do that now what I'm going
to go do I'm going to grab a quick snack
to go do I'm going to grab a quick snack
and make a couple calls I got to make
and make a couple calls I got to make
and then we'll come back later and I'll
and then we'll come back later and I'll
start on this also we made uh Captain I
start on this also we made uh Captain I
made a huge amount of progress on carbs
made a huge amount of progress on carbs
I think I figured out why it's not
I think I figured out why it's not
working as well as it should be um
working as well as it should be um
that's going to take me a couple days of
that's going to take me a couple days of
work but we're going to have way better
work but we're going to have way better
hyper parameter
hyper parameter
sweeps I figured that out today as
well what's the problem pretty much the
well what's the problem pretty much the
thing that I said where they're like
thing that I said where they're like
they're transforming parameters into
they're transforming parameters into
like uh they're applying bad
like uh they're applying bad
transformations to the parameters and
transformations to the parameters and
applying bad sampling
applying bad sampling
basically so they have a really good
basically so they have a really good
algorithm that they're just doing their
algorithm that they're just doing their
data transforms and sampling wrong
I mean it makes sense that they are
I mean it makes sense that they are
their code is like horribly over
their code is like horribly over
complicated there as well in fact you
complicated there as well in fact you
know I think that there are two projects
know I think that there are two projects
that I want just for puffer one is I
that I want just for puffer one is I
want a much cleaned up and simpler
want a much cleaned up and simpler
version of carbs um that matches or
version of carbs um that matches or
exceeds the original and then I want the
exceeds the original and then I want the
same for box 2D so those are two major
same for box 2D so those are two major
projects for people to look at I'm
projects for people to look at I'm
probably going to do the carbs one
probably going to do the carbs one
myself um because it's kind of technical
myself um because it's kind of technical
unless anybody's really really wants to
unless anybody's really really wants to
look at
look at
it seeing the code you're talking about
it seeing the code you're talking about
didn't Brocket didn't try to see if it
didn't Brocket didn't try to see if it
was correct
was correct
yeah I don't know why your message just
yeah I don't know why your message just
didn't show up on the stream though I
didn't show up on the stream though I
see it in the in the chat it's
see it in the in the chat it's
weird
weird
um yeah it's a weird plugin thing okay
um yeah it's a weird plugin thing okay
I'm G to go I only got a half hour to
I'm G to go I only got a half hour to
like do some stuff so I'm going to go do
like do some stuff so I'm going to go do
some stuff and uh I will be back later
some stuff and uh I will be back later
in the afternoon thanks for tuning in
in the afternoon thanks for tuning in
folks um if you're interested in getting
folks um if you're interested in getting
involved or learning more about
involved or learning more about
puffer puffer doai GitHub star it helps
puffer puffer doai GitHub star it helps
us out a ton Discord puffer do discord.
us out a ton Discord puffer do discord.
GPU get involved here and you can also
GPU get involved here and you can also
follow me on X where I post all sorts of
follow me on X where I post all sorts of
RL
RL
stuff thanks and

Kind: captions
Language: en
we're back
we're back
live I got a meeting time wrong it was
live I got a meeting time wrong it was
uh
uh
Pacific so I got another three
hours a couple things I want to do here
hours a couple things I want to do here
um so this is
um so this is
interesting score gets
to just above zero
let me see why this
let me see why this
is it should get to
is it should get to
one did all these experiments right and
one did all these experiments right and
it should get to
one break out no so this should
be let's see if I click this one
score there score
score there score
here what this is is this is a synthetic
here what this is is this is a synthetic
test of
test of
carbs the hyper pram out oiling so let
carbs the hyper pram out oiling so let
me see this gets
me see this gets
991 gamma
991 gamma
it's very close on gamma 942 so it gets
it's very close on gamma 942 so it gets
pretty darn close on
Lambda learning rate
Lambda learning rate
O2 it's a little bit
O2 it's a little bit
off BPT Horizon does it get
off BPT Horizon does it get
this no it completely fails
this no it completely fails
this so something is still scy
this so something is still scy
here this is not optimizing in the way
here this is not optimizing in the way
that we would
expect and you can see here that the
expect and you can see here that the
total time
total time
steps uh has not been sampled
steps uh has not been sampled
up so there's this score
up so there's this score
mod what about batch size batch size is
mod what about batch size batch size is
only
only
32k no mini
32k no mini
batches is only two upd epox is four
batches is only two upd epox is four
okay so something is very weird here
okay so something is very weird here
though
though
because this should be very
because this should be very
easy this should be very easy for it to
easy this should be very easy for it to
learn and the fact that it isn't
learn and the fact that it isn't
learning
this implies something about the
sampling I'm trying to think if there's
sampling I'm trying to think if there's
any explanation for this other than
any explanation for this other than
carbs being
wrong
right mini batches is
toy like what is the possible reason
hold on this is a uniform right I have
hold on this is a uniform right I have
batches this is defined as like a
batches this is defined as like a
uniform so this should 100% be able to
uniform so this should 100% be able to
be to be
be to be
solved and it's not
working let me see why this is the
working let me see why this is the
case
so I'm actually going to
so I'm actually going to
make a new
make a new
dashboard which is going to
dashboard which is going to
be
be
uh
sweep
progress okay and this one's going to
progress okay and this one's going to
have different widgets in it this is all
have different widgets in it this is all
going to be about learning progress over
going to be about learning progress over
time
so we're going to add some
so we're going to add some
scatters this will be
scatters this will be
score and then this will
score and then this will
be
be
start
time cyst creation
time cyst creation
time and then the Y AIS is going to be
time and then the Y AIS is going to be
score last
add okay and now we're going to do this
add okay and now we're going to do this
for basically for all of these hyper
for basically for all of these hyper
parameters and then this is going to
parameters and then this is going to
tell us which of these are improving
tell us which of these are improving
over
over
time um so yeah we're going to do
okay uh nope creation
yeah okay I think I I think that we're
yeah okay I think I I think that we're
actually going to be able
actually going to be able
to on we're going to be able to we're
to on we're going to be able to we're
going to be able to actually understand
going to be able to actually understand
what's going on now because the
what's going on now because the
synthetic test this is a very good idea
synthetic test this is a very good idea
I should have done this a long time ago
I should have done this a long time ago
right so we got back
right so we got back
size no not Spore this is back
size no not Spore this is back
size TR bad size class okay
okay so we got batch
okay so we got batch
size and then we got no mini batches
we only have to do this once and then
we only have to do this once and then
we'll have this dashboard for
usage okay so here's
usage okay so here's
this I don't know why there's this huge
this I don't know why there's this huge
gap in
gap in
in the creation times but
whatever we do
gamma Lambda
Okay add
this why is this the same
plot uh
plot uh
cuz they're just very similar okay and
cuz they're just very similar okay and
then update
Epoch so what this shows
Epoch so what this shows
you this doesn't show you performance
you this doesn't show you performance
right this just shows you the hyper
right this just shows you the hyper
prams this shows you how your hyper Prem
prams this shows you how your hyper Prem
sweep algorithm is changing over
time BPT
and I think this is it okay so now we
and I think this is it okay so now we
have all of these
parameters I don't know what's up with
parameters I don't know what's up with
this um this might be from like a
this um this might be from like a
partial sweep or something something
partial sweep or something something
weird also this is
yeah that's kind of
weird also this only gives you 200
runs okay I think that the thing is this
runs okay I think that the thing is this
is not giving us the right 200 runs that
is not giving us the right 200 runs that
we
we
want so let's do
want so let's do
none and then
H well why did that just change a whole
H well why did that just change a whole
bunch hold
bunch hold
on
on
14 or 223
okay so yeah what's happening is it's
okay so yeah what's happening is it's
showing us the most recent runs and
showing us the most recent runs and
that's actually that's a really bad
that's actually that's a really bad
thing to have in their
UI um so 422
UI um so 422
items so we actually want the
items so we actually want the
first 200 of
first 200 of
these I see
I'm actually just going to
I'm actually just going to
do this doesn't take very
do this doesn't take very
long and I'm going to change the max
long and I'm going to change the max
runs because this is very
awkward there should be
awkward there should be
200 cuz that's such a bad UI thing the
200 cuz that's such a bad UI thing the
way that they do
way that they do
that
that
um so we're going to do this
um so we're going to do this
want to see what this
want to see what this
does this will give us a very different
does this will give us a very different
picture I
think Neptune unsupported
think Neptune unsupported
type hang
type hang
on oh that's fine these are just
parameters cool so now this is running
and this will run very
quickly
um now we know that it didn't full solve
um now we know that it didn't full solve
we did not fully solve this even by the
we did not fully solve this even by the
end we might get some progress over time
end we might get some progress over time
curves but we know this is not going to
curves but we know this is not going to
full solve
full solve
and then the question is going to be why
and then the question is going to be why
so in the meantime while this
so in the meantime while this
runs I want to look at the way that
runs I want to look at the way that
carbs
carbs
samples its
samples its
parameters I suspect it's not doing what
parameters I suspect it's not doing what
we
want so we get suggestion
output get random
suggestion this is generate
candidate okay so do
candidate okay so do
fit and then you fit the suggestion
fit and then you fit the suggestion
s you fit the
failures fit fito
failures fit fito
set and then it
set and then it
generates candidates numb samples to
generate samples in
generate samples in
basic so you get sample around origins
basic so you get sample around origins
in basic
okay so this surrogate model gets
okay so this surrogate model gets
fit but then you sample
fit but then you sample
around the
origins and they round
origins and they round
this where's the surrogate
this where's the surrogate
model where does this get used
this is what I don't understand I don't
this is what I don't understand I don't
understand how they're
understand how they're
generating their suggestions so is
generating their suggestions so is
expected biasing
technique so what do you actually return
technique so what do you actually return
from
this oh man you returned okay there's a
this oh man you returned okay there's a
lot of stuff so samples in
lot of stuff so samples in
basic of best
basic of best
index
index
ooh oh [ __ ] is that what they're
doing okay I think I see why this is
wrong yeah okay I see why this is wrong
so it looks to and I got to check the
so it looks to and I got to check the
carbs paper but do you see this so they
carbs paper but do you see this so they
generate a whole bunch of random
generate a whole bunch of random
samples based on the space definition
samples based on the space definition
that you
that you
provide so it's only going to
provide so it's only going to
sample according to the initial
sample according to the initial
distribution that you
distribution that you
provide and
then they use
hold
on what do they call the surrogate
on what do they call the surrogate
model circuit
output position function
value I think that what this does is
value I think that what this does is
it's using the acquisition functions to
it's using the acquisition functions to
rank the suggestions
and then you it's only giving you the
and then you it's only giving you the
best ranked random suggestion it is not
best ranked random suggestion it is not
actually giving you a new
suggestion this would make sense because
suggestion this would make sense because
this is why carbs is supposed to be able
this is why carbs is supposed to be able
to generate uh like long like longer and
to generate uh like long like longer and
longer runs over time but under this
longer runs over time but under this
structure it will not do that
this seems like a fundamental problem
this seems like a fundamental problem
with
carbs I wonder if this is in their
paper how's this
going cool so this will progress for a
going cool so this will progress for a
bit
um the paper is very hard to
read this is a maj Maj limitation with
read this is a maj Maj limitation with
carbs if I'm
correct where's the
paper
Okay
so
algorithm generate candidat in local
algorithm generate candidat in local
search BAS
we Define the search
space it's supposed to be Gan
space it's supposed to be Gan
around the parito
front once we have the candidate
front once we have the candidate
suggestions
we estimate okay so they are
ranking but they say they
ranking but they say they
generate defines local spur space around
generate defines local spur space around
points on the observed cost performance
points on the observed cost performance
Paro
front so this would be very smart
but I don't think this is what's
happening does this match the
code let me
see so they're going to fit the success
see so they're going to fit the success
observations they fit the
failures they fit
failures they fit
the parito set
the parito set
okay now when they
sample they get this samples in
basic oh but look the origins in basic
basic oh but look the origins in basic
are the prito
groups sample around Origins and basic
groups sample around Origins and basic
okay
origin
index real
samples search distribution in basic.
Sample basic
Sample basic
search radius in
search radius in
basic in
basic immediately overwritten so I think
basic immediately overwritten so I think
I'm going to have to put some break
I'm going to have to put some break
points in here to figure this out
points in here to figure this out
because this is very very odd um the
because this is very very odd um the
thing that they say they're doing on
thing that they say they're doing on
paper makes sense to me but based on the
paper makes sense to me but based on the
experiments I'm not seeing the algorithm
experiments I'm not seeing the algorithm
do the thing it's supposed to be doing
do the thing it's supposed to be doing
on
on
paper what it's supposed to be doing is
paper what it's supposed to be doing is
it's supposed to be Computing a Paro
it's supposed to be Computing a Paro
front of cost and performance so it's
front of cost and performance so it's
trying to find runs for which there is
trying to find runs for which there is
no run that is both faster and
no run that is both faster and
better and then based on the Paro
better and then based on the Paro
front it's supposed to sample new
front it's supposed to sample new
points so that means that if you start
points so that means that if you start
off with a slow run I mean a fast run
off with a slow run I mean a fast run
you know you can sample a faster run and
you know you can sample a faster run and
a faster run and a faster run as long as
a faster run and a faster run as long as
they're on the parito
they're on the parito
front but this doesn't seem to be
front but this doesn't seem to be
happening even with the most basic of
happening even with the most basic of
synthetic
synthetic
tests carb seems to do a very good job
tests carb seems to do a very good job
just as a hyperparameter tuning
just as a hyperparameter tuning
algorithm without the cost
algorithm without the cost
awareness the cost that that's the
awareness the cost that that's the
important piece and it doesn't seem to
work okay so look at this so we get up
work okay so look at this so we get up
to
B size being decreased is interesting
B size being decreased is interesting
let me
let me
see maybe it's just that it doesn't
see maybe it's just that it doesn't
matter
[Music]
okay so right here this is what we have
okay so right here this is what we have
we got our test
we got our test
function and we get a score
mod is batch size divided square
mod is batch size divided square
root am I stupid or isn't lower isn't
root am I stupid or isn't lower isn't
bigger bat size better
here something is
here something is
wrong bigger bat size should be better
here mini batch should be better
here mini batch should be better
everything here should be better
oh but it's a
multiple I see it's a multip
okay well that's an interesting
interaction because the score is
interaction because the score is
negative you see right the score is
negative you see right the score is
negative here it's actually it's
negative here it's actually it's
learning the bat size is bad thing I
learning the bat size is bad thing I
wonder if it recovers from this because
wonder if it recovers from this because
now it's getting
now it's getting
positive still not getting positive
positive still not getting positive
scores
scores
interesting it should be getting
interesting it should be getting
positive
scores they're all still negative
yes you can actually see that it's it's
yes you can actually see that it's it's
totally messed up the mod
totally messed up the mod
parameters but let's ignore that for a
parameters but let's ignore that for a
second let's see if it's getting the
second let's see if it's getting the
correct values over here so learning
rate 002
so learning rate doesn't seem to get all
so learning rate doesn't seem to get all
the way to where it needs to
the way to where it needs to
be gamma of .99 is basically this is
be gamma of .99 is basically this is
spoton right this is very quickly
spoton right this is very quickly
correct and then Lambda .95 is also you
correct and then Lambda .95 is also you
know it's there's a little bit of noise
know it's there's a little bit of noise
here but this is correct it's
0.95 update
0.95 update
Epoch uh okay that that parameter is not
Epoch uh okay that that parameter is not
going to be good and then BPT
going to be good and then BPT
Horizon BP BT Horizon is also
wrong and actually there's no reason for
wrong and actually there's no reason for
BPT Horizon to be wrong right so
BPT Horizon to be wrong right so
ABS this minus
16 yeah it should be 16 here
16 yeah it should be 16 here
strictly so I suspect that my PO 2
strictly so I suspect that my PO 2
spaces are not correct
they're probably two separate issues
here yeah and now you can see it's
here yeah and now you can see it's
starting to get positive
values okay so this War mod here
is I don't think it's
is I don't think it's
ever yeah this is just a poorly defined
ever yeah this is just a poorly defined
score mod I'm going to add I'm going to
score mod I'm going to add I'm going to
add 20
add 20
here and that's going to fix part of
here and that's going to fix part of
it so that's going to fix the score mod
it so that's going to fix the score mod
um essentially making the score worse if
um essentially making the score worse if
it's negative because what's happened
it's negative because what's happened
here is that because the score is
here is that because the score is
negative and then this is a multiplier
negative and then this is a multiplier
is trying to reduce this multiplier as
is trying to reduce this multiplier as
much as
possible so that's just me screwing this
possible so that's just me screwing this
up like that's just a bad function on my
part so let's see what it does from here
I'm going to check a couple things in
I'm going to check a couple things in
the
the
meantime couple of academic
collabs give an update later today
collabs give an update later today
cool nothing from
cool nothing from
this nothing from
this nothing from
them for
okay I I don't know what they're on
okay I I don't know what they're on
about but
whatever
whatever
okay 11
items score is going up
I believe let's see there one two three
I believe let's see there one two three
four five six seven eight so yeah the
four five six seven eight so yeah the
first like eight trials or whatever are
first like eight trials or whatever are
random and then very quickly it should
random and then very quickly it should
start learning more stuff
start learning more stuff
here
um yeah gamma's already starting to fit
um yeah gamma's already starting to fit
lambda's already starting to
fit learning rate is not really fitting
fit learning rate is not really fitting
yet
yet
let me check some stuff
here so learning rate is
05 okay so the center param this is it's
05 okay so the center param this is it's
this is just where it's centered it
this is just where it's centered it
should very easily get to o1 though
should very easily get to o1 though
that's within one standard
that's within one standard
deviation so maybe it just takes a few
deviation so maybe it just takes a few
more trials
more trials
um but that should be fairly easy to
learn so here we go
learn so here we go
score continues to
score continues to
improve total time steps still being
decreased I believe believe I have this
decreased I believe believe I have this
as
as
a do I have this as a log
a do I have this as a log
two mini batches is correct now look at
two mini batches is correct now look at
this so mini batches is now
correct batch size does not seem to be
correct batch size does not seem to be
correct gamma's getting
correct gamma's getting
correct learning rate is not oh no it is
correct learning rate is not oh no it is
dropping it's just taking a second
dropping it's just taking a second
okay
okay
Lambda okay 0.95 this is what we want
Lambda okay 0.95 this is what we want
update epoch is good so BPT Horizon is
update epoch is good so BPT Horizon is
clearly
clearly
wrong and total time steps is clearly
wrong let's see let's look at this so c
wrong let's see let's look at this so c
2 so num M's is a p
2 so num M's is a p
two let's
add M I don't think I have this one do
add M I don't think I have this one do
I yeah I don't have this
yet xaxis is going to be
yet xaxis is going to be
creation
creation
time then y AIS is going to
time then y AIS is going to
be uh
num
okay and I don't actually know I have
okay and I don't actually know I have
five this in this for function let me
five this in this for function let me
see
so we have num
so we have num
M's uh not in the score function so this
M's uh not in the score function so this
is allowed to drift wherever it wants
is allowed to drift wherever it wants
because we're not currently using it in
because we're not currently using it in
the score function so we ignore this one
the score function so we ignore this one
for
for
now but now if we look at BPT Horizon is
now but now if we look at BPT Horizon is
uniform power
two now mini batches is a uniform power
two now mini batches is a uniform power
to
ah and it's only at four it's not at
ah and it's only at four it's not at
eight yet
eight yet
okay and total time steps is log
okay and total time steps is log
normal you know log normal should work
normal you know log normal should work
because I use log normal
because I use log normal
for everything else so I'm a little
for everything else so I'm a little
confused as to why total time steps
confused as to why total time steps
doesn't work
unless I messed up the function hold
on okay so I can see uniform p 2 being
on okay so I can see uniform p 2 being
broken like that's we'll look at that
broken like that's we'll look at that
but the log shouldn't be
but the log shouldn't be
broken how am I using this in the
broken how am I using this in the
function
log two of total time
steps you increase this you increase
steps you increase this you increase
your score
mod right
you increase this you increase your
you increase this you increase your
score
score
mod uh score
mod uh score
cost or
cost or
yeah so that is
bizarre especially like we see so many
bizarre especially like we see so many
of these are
correct okay look at this so score has
correct okay look at this so score has
gone up to
gone up to
70 total time steps is toal ho
70 total time steps is toal ho
crap mini batches has gotten up to four
crap mini batches has gotten up to four
and then got
stuck batch
size has gotten to
size has gotten to
60 5K and then
stuck learning rate is still progressing
stuck learning rate is still progressing
it looks like I don't know why it's
it looks like I don't know why it's
taking it this long to
taking it this long to
sample uh lower learning rates it this
sample uh lower learning rates it this
should be very easy to learn but it is
should be very easy to learn but it is
learning uh and then gamma is 99 so it's
learning uh and then gamma is 99 so it's
getting up to
getting up to
.99 this is very slow though it's very
slow keep in mind this is a synthetic
slow keep in mind this is a synthetic
test with perfect feedback there is no
test with perfect feedback there is no
noise in the evaluations like you should
noise in the evaluations like you should
basically be able to do this in I would
basically be able to do this in I would
guess 10 or 20 samples
okay so Lambda actually works very
nicely the kind of does some like these
nicely the kind of does some like these
are random and then it homes in and you
are random and then it homes in and you
get
0.95 is random BT Horizon is
wrong use the restroom real quick while
wrong use the restroom real quick while
this finishes some runs and uh then
this finishes some runs and uh then
we'll stop this I will make sure I'm
we'll stop this I will make sure I'm
completely right about the evaluation
completely right about the evaluation
function and then we'll see what carbs
function and then we'll see what carbs
is doing because this is very
weird
e e
okay we got 48 items we'll get 50 points
okay we got 48 items we'll get 50 points
from
them
see yeah so score does keep
see yeah so score does keep
improving these points down here are
improving these points down here are
very weird to
me and this is something that carbs
me and this is something that carbs
consistently
consistently
does is it just
misses oh okay maybe we actually do let
misses oh okay maybe we actually do let
this run a little longer because look at
this run a little longer because look at
total time steps it's coming
back but like why did it go down in the
back but like why did it go down in the
first
first
place right
so we'll let this run a little longer
not this one where's
not this one where's
carbs so many
papers here it is so
I would love to get somebody to just
I would love to get somebody to just
simplify this whole
simplify this whole
carbs um this whole carbs repository
carbs um this whole carbs repository
like really clean this
up it's just way too complicated right
up it's just way too complicated right
now that actually would be a really nice
now that actually would be a really nice
like mostly science side little bit
like mostly science side little bit
engineering side
engineering side
contribution because it requires you to
contribution because it requires you to
understand the algorithm
rounds see they say that this actually
rounds see they say that this actually
does
does
work and that this will continue to find
work and that this will continue to find
longer and longer
longer and longer
cost
hours but we're not seeing this working
hours but we're not seeing this working
in
practice this is
bizarre so gamma's get got to 99 here I
bizarre so gamma's get got to 99 here I
don't know why it took that long though
don't know why it took that long though
to sample up to
to sample up to
here and like Lambda is the right spot
here and like Lambda is the right spot
but it's not a
but it's not a
tight it hasn't really gotten that
tight it hasn't really gotten that
parameter tight
yet I also don't know why numm would
yet I also don't know why numm would
drift down like
drift down like
this because it's not included in the
this because it's not included in the
the function having drift like this in
the function having drift like this in
your having this type of drift is very
bad doesn't seem like this is going way
bad doesn't seem like this is going way
back
back
up okay I think I'm going to in a
up okay I think I'm going to in a
separate window I'm going to start
separate window I'm going to start
trying to figure out what the heck is up
trying to figure out what the heck is up
with carbs
um yeah
this is a big repo that I I think you
this is a big repo that I I think you
could probably clean this up to be like
could probably clean this up to be like
a 500
a 500
line Repository
okay so where's our
suggestion
generate
candidates sample around Origins and
candidates sample around Origins and
basic
yeah let do the window
oh am I on the other machine
demo or
aate okay so we have
aate okay so we have
here origin samples
let's figure out the order these are
let's figure out the order these are
passed
in we'll
in we'll
do flat spaces
Okay cool
Okay cool
so we've got
origin
samples so I can see right
here
here
1.06 and then this log space is at 32
so these have been transformed
already real
already real
samples
samples
tensor plus search distribution in
tensor plus search distribution in
basic
basic
he search just distribution in
he search just distribution in
basic normal with a scale of
0.3 so they're transforming my
parameters and then they're using a
fixed search distribution and basic
so what do we do so it's self.
so what do we do so it's self.
search radius in
search radius in
basic immediately overwritten by set
basic immediately overwritten by set
search
center set search
center I really
search center so you set the search
center param dict
type search center
type search center
basic so search center in basic is very
different search distribution in
basic search
radius so this is immediately
radius so this is immediately
overwritten by set search
center which is not true because this
center which is not true because this
doesn't set
doesn't set
that it only sets this it doesn't set
that it only sets this it doesn't set
the search
the search
radius so search radius in basic is not
radius so search radius in basic is not
overr
I do think that this is worth investing
I do think that this is worth investing
substantial time into
substantial time into
because this seems like a very good
because this seems like a very good
algorithm that's being held back
so where is search center and basic we
do let's do up
here so you have params
here so you have params
here
here
and the search center for these
is not what it's looking like here
set foram space real to per
set foram space real to per
basic foram space real
toam space real to basic space
toam space real to basic space
real okay so dim. basic from Pam
uh
terminal
terminal
uhoh internet might be
dropping I think we're
dropping I think we're
good I think just a small
good I think just a small
Spike I have had some janky driver
Spike I have had some janky driver
issues I'm hoping that they're fixed but
issues I'm hoping that they're fixed but
we will
see
see
basic we got input in
basic we got input in
param and we get these are the surch
param and we get these are the surch
centers these are the raw surf
centers these are the raw surf
centers okay
centers okay
and then we
do basic from
do basic from
pan and self.
real input
real input
inam K dim
inam K dim
in self. real number Space by
in self. real number Space by
name number Space by name
underscore
internet dim. basic from
internet dim. basic from
Chan okay so it's
so the spaces have a function called
so the spaces have a function called
basic drug
basic drug
foram
okay value over scale
so this tells
you this is the transform right
it's incredibly
it's incredibly
confusing I think basic from
confusing I think basic from
Pam it takes the ra
Pam it takes the ra
value and it transforms it to be in a
value and it transforms it to be in a
better space for
sampling but the way it's doing that at
sampling but the way it's doing that at
the moment is not good
yeah cuz I think what they're doing at
yeah cuz I think what they're doing at
the
the
moment so here they're just dividing the
moment so here they're just dividing the
parameter by whatever skill you give
it they're just dividing the parameter
it they're just dividing the parameter
by whatever scale that you give
it and then when you sample this
parameter this is why they have a three
parameter this is why they have a three
there because their default sample range
there because their default sample range
is
is
is.3 so what happens is they divide by
is.3 so what happens is they divide by
the scale that you give it and then they
the scale that you give it and then they
sample a normal with a standard
sample a normal with a standard
deviation of.
deviation of.
3 and then they transform back so like
3 and then they transform back so like
one standard deviation right let's say
one standard deviation right let's say
that you have 1 to 10 and you give it a
that you have 1 to 10 and you give it a
scale of
scale of
three okay so then you give it a five a
three okay so then you give it a five a
five is a or let's make it easier a six
five is a or let's make it easier a six
so they do 6 / 3 is two and then you
so they do 6 / 3 is two and then you
sample with a.3 Norm so let's say one
sample with a.3 Norm so let's say one
standard deviation you sample a 2.3 and
standard deviation you sample a 2.3 and
then you multiply back and then that
then you multiply back and then that
gives you a a 6.9
which is a terrible way of
sampling yeah that makes absolutely no
sense and this would explain why they're
uh why their algorithm doesn't
uh why their algorithm doesn't
sample or doesn't explore various spaces
sample or doesn't explore various spaces
in a way that looks reasonable to
in a way that looks reasonable to
me so this is basically this is a really
me so this is basically this is a really
really good algorithm that's being held
really good algorithm that's being held
back by space
back by space
Transformations um so I've just run 119
Transformations um so I've just run 119
experiments it's kind of starting to
experiments it's kind of starting to
learn to restore total time
learn to restore total time
steps it's got gamma it's
steps it's got gamma it's
got doesn't even have learning rate
really oh it's supposed to be o1 it's a
really oh it's supposed to be o1 it's a
little bit
little bit
off
um it's like kind of getting
um it's like kind of getting
there I think the algorithm is really
there I think the algorithm is really
really good and
really good and
like there's not much I can even change
like there's not much I can even change
with it it's like a really smart
with it it's like a really smart
algorithm it's just this space
algorithm it's just this space
transformation
transformation
stuff
stuff
um so I think I found that out
is there a chance that I'm wrong
here I think I have
here I think I have
it and I think this is what their paper
it and I think this is what their paper
says as well let me see if it matches
says as well let me see if it matches
the paper then I think I then I think
the paper then I think I then I think
we're good and then we'll know what we
we're good and then we'll know what we
need to change this this will take like
need to change this this will take like
a couple days of work probably to fix
a couple days of work probably to fix
this but then it will be will be
set assume that this we just
set assume that this we just
[Music]
find input parameters and out outputs
find input parameters and out outputs
are scaled to be of order one but they
are scaled to be of order one but they
don't actually do
this local search space around points
we Define the search
we Define the search
space as a set of Galan distributions of
space as a set of Galan distributions of
radius search around these
radius search around these
parameters defining the unnormalized
parameters defining the unnormalized
probability
density so I don't even think that this
density so I don't even think that this
makes sense
makes sense
if yeah this doesn't even make sense if
if yeah this doesn't even make sense if
you transform
you transform
correctly because each of these
correctly because each of these
parameters should have its own uh its
parameters should have its own uh its
own search
radius cuz like you know which
radius cuz like you know which
parameters have scale over many range
parameters have scale over many range
like many orders of magnitude and which
like many orders of magnitude and which
ones don't
once we've evaluated the candidate
suggestions three gum
suggestions three gum
processes to
processes to
predict the performance of a
predict the performance of a
candidate to predict the
candidate to predict the
cost and to predict the Optimal
cost and to predict the Optimal
Performance coresponding to that
Performance coresponding to that
cost and formed only by the pr fund all
cost and formed only by the pr fund all
the
the
shape
shape
okay I think I'm really starting to
okay I think I'm really starting to
understand this
understand this
algorithm this is a very heavy
algorithm this is a very heavy
out I'm starting to get
it doing only observations that
it doing only observations that
belong in the Paro
front is uses the
front is uses the
Baseline the expected
Improvement I don't know about
this I'm G to have to get way deep into
this I'm G to have to get way deep into
the code to figure out what they're
the code to figure out what they're
doing box
doing box
transform quantile transform
so they do have some transforms in here
so they do have some transforms in here
but I think that the thing is that
but I think that the thing is that
they're applying the transform to bad
data well the good thing is that I have
data well the good thing is that I have
this Baseline
this Baseline
now right so I have this
now right so I have this
Baseline this is how well it
Baseline this is how well it
does um let me compute the Optimal
does um let me compute the Optimal
Performance real quick
what's optimal on
this for
why can't I set
why can't I set
this I'll just do it here and then we're
this I'll just do it here and then we're
going to do something else
yeah so this should be the
yeah so this should be the
optimal parameter settings
Point yeah so like you can see here that
Point yeah so like you can see here that
there are parameters that get
there are parameters that get
254 way way way way way higher so uh
254 way way way way way higher so uh
this means carbs is not actually working
this means carbs is not actually working
perfectly and
optimal carbs is not working perfectly
optimal carbs is not working perfectly
and we will definitely look at that so
and we will definitely look at that so
this is why everything's been janked
this is why everything's been janked
basically if we can fix
basically if we can fix
this then we should have really solid
this then we should have really solid
sweeps and we should be in a really
sweeps and we should be in a really
solid position going
solid position going
forward
forward
um okay that's good for this segment of
um okay that's good for this segment of
work uh I think the next thing we're
work uh I think the next thing we're
going to do whoops let me
see the next thing we're going to do
oh interesting apparently newer
oh interesting apparently newer
compilers are faster
cool General let me find this real quick
cool General let me find this real quick
for
us okay I'm going to be reviewing this
us okay I'm going to be reviewing this
paper
now mini paper bir to Tim okay Co they
now mini paper bir to Tim okay Co they
should be
good elliptical episodic bonuses
good elliptical episodic bonuses
fineos to explore complex
fineos to explore complex
environments yeah we're going to do this
environments yeah we're going to do this
review
review
now let me get into paper review mode
now let me get into paper review mode
let actually make a new scene for this
let actually make a new scene for this
um you
add
I should actually flip this one as
well there we
go oh I have this because of the mic I
go oh I have this because of the mic I
guess
all right we'll flip this
back e
ch
e
e e
test
test audio works here does audio not
test audio works here does audio not
work on the other scene
okay I think I have audio here now let
okay I think I have audio here now let
me go double check from the
stream let me make sure this works
does this
does this
work test does this work yes okay it
work test does this work yes okay it
does
good okay now we have our paper review
good okay now we have our paper review
SC paper and code review
SC paper and code review
good okay
so recent
so recent
years RL methods have been proposed to
years RL methods have been proposed to
explore complex environment forr
explore complex environment forr
episodes in work we show that the
episodes in work we show that the
effectiveness of these methods were
effectiveness of these methods were
critically relies on account-based
critically relies on account-based
episodic term in their exploration bonus
episodic term in their exploration bonus
okay that entire line of work on
okay that entire line of work on
count-based uh bonus is bad idea does
count-based uh bonus is bad idea does
like that's a ridiculous thing to be
like that's a ridiculous thing to be
doing so they extend it here extend
doing so they extend it here extend
count-based episodic bonus to continuous
count-based episodic bonus to continuous
State spaces and encourages an agent to
State spaces and encourages an agent to
explore states that are diverse under a
explore states that are diverse under a
learned embedding within each
learned embedding within each
episode this embedding is is learned
episode this embedding is is learned
using an inverse Dynamics model in order
using an inverse Dynamics model in order
to capture controllable aspects of the
to capture controllable aspects of the
environment method sets a new state the
environment method sets a new state the
art across 16 challenging task for mini
art across 16 challenging task for mini
hack Suite without requiring task
hack Suite without requiring task
specific inductive
specific inductive
biases e 3B also matches existing
biases e 3B also matches existing
methods on sparse reward pixel based
methods on sparse reward pixel based
visdom out performance existing method
visdom out performance existing method
reward for exploration on
reward for exploration on
habitat demonstrating it can scale to
habitat demonstrating it can scale to
high dimensional pixel based
high dimensional pixel based
observations and a realistic environment
observations and a realistic environment
okay
um intro
here got R&D ICM pseudo
counts designed for Singleton RL
counts designed for Singleton RL
tasks the agent is spawned in the same
tasks the agent is spawned in the same
environment every
episode okay that's not entirely
true but yes these methods are pretty
limited number of methods have been
limited number of methods have been
proposed which have shown promising
proposed which have shown promising
performance in
PCG okay this is funny because
PCG okay this is funny because
procedurally generated environments are
procedurally generated environments are
often easier um than fixed environments
often easier um than fixed environments
it helps it's called domain uh domain
it helps it's called domain uh domain
randomization it's a natural curriculum
randomization it's a natural curriculum
so this is kind of f
me surprisingly count base often
me surprisingly count base often
includes Zer ristic is in fact
includes Zer ristic is in fact
essential methods fail if it's omitted
essential methods fail if it's omitted
okay existing methods fail more complex
okay existing methods fail more complex
tasks
sure we're not reading
sure we're not reading
this uh exploration
bonuses that's just needless
bonuses that's just needless
formalism environment rewards are sparse
formalism environment rewards are sparse
learning a policy using simple Epson
learning a policy using simple Epson
greedy exploration may require
greedy exploration may require
intractably many
intractably many
samples
samples
yes oh I remember liking this paper
yes oh I remember liking this paper
forgot the details yeah we're looking at
forgot the details yeah we're looking at
this now
this now
uh for some stuff
uh for some stuff
Ryan welcome to the code review setup or
Ryan welcome to the code review setup or
the paper and code review set
the paper and code review set
up oh also we found some screwy things
up oh also we found some screwy things
with carbs so I think we're going to be
with carbs so I think we're going to be
able to make hyper pram search for RL
able to make hyper pram search for RL
way better over the next
week spending a couple hours on this
week spending a couple hours on this
though consider methods that augment the
though consider methods that augment the
external reward function r with an
external reward function r with an
intrinsic reward bonus
B number of intrinsic bonuses that
B number of intrinsic bonuses that
encourage exploration in Singleton
encourage exploration in Singleton
proposed including pseudo camps ICM R&D
proposed including pseudo camps ICM R&D
okay if you make that easy you're a hero
okay if you make that easy you're a hero
and never do anything besides manual
and never do anything besides manual
okay Ryan like you're throwing away 99%
okay Ryan like you're throwing away 99%
of your compute this has kind of been
of your compute this has kind of been
the conclusion lately um I've been
the conclusion lately um I've been
realizing over the last few days so
realizing over the last few days so
people throw away uh a 100x to 1,000x
people throw away uh a 100x to 1,000x
compute off of using slow environments
compute off of using slow environments
but then they actually throw away
but then they actually throw away
another 100x compute on bad hyper pram
another 100x compute on bad hyper pram
search so literally all of RL is running
search so literally all of RL is running
at like 110,000 of the speed that it
at like 110,000 of the speed that it
should be and we wonder why nothing
should be and we wonder why nothing
works it's that
works it's that
bad I mean it's like the the more that I
bad I mean it's like the the more that I
dig the more stuff I find and it's like
dig the more stuff I find and it's like
it's not even like RL is just a hard
it's not even like RL is just a hard
hard thing it's literally just that
hard thing it's literally just that
we've screwed up the engine engering at
we've screwed up the engine engering at
every possible
level these methods Define an intrinsic
level these methods Define an intrinsic
reward bonus that is high if the current
reward bonus that is high if the current
state is different from the previous
state is different from the previous
States visit but visited by the agent
States visit but visited by the agent
and low if it is similar According to
and low if it is similar According to
some measure
okay so they all have some distance
okay so they all have some distance
measure Over
States more recently several measure
States more recently several measure
methods have been proposed for an
methods have been proposed for an
evaluate on procedurally generated the
evaluate on procedurally generated the
mdps I'll use different exploration
bonuses summarize in table
bonuses summarize in table
one bonus based on distance between the
embeddings second Bar D
embeddings second Bar D
bonuses okay so basically we want we
bonuses okay so basically we want we
want to try one of these that is simple
want to try one of these that is simple
and doesn't make a mess out of all your
and doesn't make a mess out of all your
learning code and we want to see if it
learning code and we want to see if it
does anything importance and limitations
does anything importance and limitations
of count-based exploration
bonuses three methods with and without
bonuses three methods with and without
the respective count-based episodic
the respective count-based episodic
terms on one of the Min grid
terms on one of the Min grid
environments Us in Prior work
minig grid n10 S10
minig grid n10 S10
v0 what is
this does anybody know what this
this does anybody know what this
is n10 S10 v0
yeah but what is this
environment what is
environment what is
it I can't see the environment to see if
it I can't see the environment to see if
this is actually
this is actually
interesting
interesting
um is this built
um is this built
in can I like go render it for
okay what what is this
okay what what is this
environment I wish they I can't find it
environment I wish they I can't find it
but the thing that I'm concerned here
but the thing that I'm concerned here
with is this axis is
with is this axis is
17 17 is nothing I train this is 10
17 17 is nothing I train this is 10
seconds of learning if your library
seconds of learning if your library
doesn't
doesn't
suck
suck
so like if you look at it that way this
so like if you look at it that way this
is a 10-second experiment like oh look
is a 10-second experiment like oh look
no episodic counts you don't make
no episodic counts you don't make
progress I most of these problems you
progress I most of these problems you
can literally brute force with po um
can literally brute force with po um
fair enough though yeah you add episodic
fair enough though yeah you add episodic
counts and it learns way faster because
counts and it learns way faster because
obviously it does and cuz that's like a
obviously it does and cuz that's like a
thing you can do with grid environments
fine because like the problem is
fine because like the problem is
fundamentally intractable right without
fundamentally intractable right without
a ton of samples without this like
a ton of samples without this like
exploration
exploration
thing um it looks like a ridiculously
thing um it looks like a ridiculously
deep uh exponential SEF space
see
it's if each state is
it's if each state is
unique and that will always be one and
unique and that will always be one and
the okay
the okay
yes so you need some sort of encoding
yes so you need some sort of encoding
over the observation not just the state
relevant features from each state and
relevant features from each state and
feed them to count
feed them to count
based well this still doesn't make sense
based well this still doesn't make sense
really unless you have a good
discretization got drop C around
Ryan figure two shows results on two
Ryan figure two shows results on two
tasks from the mini hack Suite 3 novel D
tasks from the mini hack Suite 3 novel D
variants
variants
TR to
outperform standard
formulation it's a bonus deisal feature
formulation it's a bonus deisal feature
encoding and episode bonus
encoding and episode bonus
okay it's X and
Y failed to enabl Sol multi room one
Y failed to enabl Sol multi room one
freeze okay cool
freeze okay cool
in this section we describe exploration
in this section we describe exploration
VI elliptical episode
bonuses we'd like an episode bonus that
bonuses we'd like an episode bonus that
can be used in continuous date
can be used in continuous date
representations we'd like a
representations we'd like a
representation learning method that only
representation learning method that only
captures information about the
captures information about the
environment is relevant for the task at
environment is relevant for the task at
hand first requirement is meant by using
hand first requirement is meant by using
an elliptical bonus whatever that means
an elliptical bonus whatever that means
continuous analog to counts spased
continuous analog to counts spased
bonus we'll see
bonus we'll see
how second
how second
requirements met by using a
requirements met by using a
representation learn with an inverse
representation learn with an inverse
Dynamics
Dynamics
model elliptical bonus given a feature
model elliptical bonus given a feature
encoding the elliptical episode bonus is
encoding the elliptical episode bonus is
described as
described as
follows what the hell
follows what the hell
um how do you get one7 steps in 10
um how do you get one7 steps in 10
seconds that would take me like an hour
seconds that would take me like an hour
RMS are fast so
RMS are fast so
this is why puffer is awesome right all
this is why puffer is awesome right all
of these environments run at a million
of these environments run at a million
steps per second on a single CPU core
steps per second on a single CPU core
and most of them train between 300,000
and most of them train between 300,000
and like 1.2 million steps per second on
and like 1.2 million steps per second on
one
GPU and these range from very simple to
GPU and these range from very simple to
some of the most complicated RL
some of the most complicated RL
environments out there like we can train
environments out there like we can train
neural mm3 at about 500,000 steps per
neural mm3 at about 500,000 steps per
second um this is a massively
second um this is a massively
multi-agent open world environment with
multi-agent open world environment with
economy and trade and all sorts of stuff
economy and trade and all sorts of stuff
what's puffer puffer is the library that
what's puffer puffer is the library that
I am developing to fix the gigantic mess
I am developing to fix the gigantic mess
that reinforcement learning is in at the
that reinforcement learning is in at the
moment you can check it out at puffer
moment you can check it out at puffer
doai GitHub is right here it's all free
doai GitHub is right here it's all free
and open source start to help us out a
and open source start to help us out a
bunch and uh we've got a nice Discord
bunch and uh we've got a nice Discord
community of people building high
community of people building high
performance rlms and we're starting to
performance rlms and we're starting to
now use those High per rlms to run
now use those High per rlms to run
thousands and thousands of experiments
thousands and thousands of experiments
to fix all the other problems around RL
to fix all the other problems around RL
because we can do that now since they're
fast so yeah this is pretty much what I
fast so yeah this is pretty much what I
do it's like I just stream all of my
do it's like I just stream all of my
work on on puffer lib which includes
work on on puffer lib which includes
developing and merging environments it
developing and merging environments it
includes doing science side work on top
includes doing science side work on top
of our environments it includes doing
of our environments it includes doing
you know some support stuff for clients
you know some support stuff for clients
adding specific features to puffer lib
adding specific features to puffer lib
that people need uh for both like
that people need uh for both like
companies and academic Labs uh it's just
companies and academic Labs uh it's just
generally this is my effort to try to
generally this is my effort to try to
fix the mess that reinforcement learning
fix the mess that reinforcement learning
is in where everything is kind of cursed
is in where everything is kind of cursed
and hard to make to
and hard to make to
work we got classic ones too simple
work we got classic ones too simple
pong these are neural Nets these are
pong these are neural Nets these are
trained agents running in your browser
trained agents running in your browser
as
well multi-agent snake lots of stuff
what is this elliptical episode
bonus
so feature encoding I assume is just
so feature encoding I assume is just
going to be like the hidden
State and then
what is this
what is this
Matrix so this is a vect
Matrix so this is a vect
weight is this an outer
product this is how easy is it to import
product this is how easy is it to import
my own environment like a simple
my own environment like a simple
imported uh inverted pendulum we have
imported uh inverted pendulum we have
wrappers for gymnasium environment ments
wrappers for gymnasium environment ments
and for petting zoo environments you
and for petting zoo environments you
will immediately get a performance speed
will immediately get a performance speed
up out of our CPU vectorization on those
up out of our CPU vectorization on those
because our vectorization is much faster
because our vectorization is much faster
than what everything else that is out
than what everything else that is out
there um for the maximum maximum
there um for the maximum maximum
performance you're going to want to look
performance you're going to want to look
at our native API and our native M's but
at our native API and our native M's but
if you just want like out of the box get
if you just want like out of the box get
some good performance speedups get like
some good performance speedups get like
nice hyper parameter sweep to get RL
nice hyper parameter sweep to get RL
working generally then it's very very
working generally then it's very very
easy and we have lots and lots of
easy and we have lots and lots of
examples um basically anything in the
examples um basically anything in the
puffer lib environments folder like any
puffer lib environments folder like any
of like the main environments that are
of like the main environments that are
actually used actively you can see how
actually used actively you can see how
we bind it's like a oneline
wrapper pretty much puffer will give you
wrapper pretty much puffer will give you
the best performance for the level of
the best performance for the level of
engineering effort that you want to put
engineering effort that you want to put
in if you just want to wrap an existing
in if you just want to wrap an existing
environment that's fine if you want to
environment that's fine if you want to
do a little bit more work you know you
do a little bit more work you know you
can get faster and it goes all the way
can get faster and it goes all the way
up to million steps per second
training okay so this formulation
training okay so this formulation
bothers me a
bothers me a
lot
because well hold on I guess nice look
because well hold on I guess nice look
of the rapper try yeah I mean this is
of the rapper try yeah I mean this is
why I stream as well if you run into any
why I stream as well if you run into any
trouble I'm right here right put paste
trouble I'm right here right put paste
errors I help
fix okay maybe this isn't that bad
fix okay maybe this isn't that bad
because you can Cal this
right so this is a
sum wait I equal
sum wait I equal
1 to T minus1
given a feature encoding at each time
step is this over the entire
episode so regularization term to make
episode so regularization term to make
sure that it's not
sure that it's not
singular but that's not a good way of
singular but that's not a good way of
making a matrix not
making a matrix not
singular and it's an outer
product okay so this is a kind of
crazy function to
include it's a kind of a crazy function
include it's a kind of a crazy function
I guess technically
technically you can like pass this as an
technically you can like pass this as an
extra State variable I
guess you can technically pass this as
guess you can technically pass this as
an extra State
variable yeah
you have to reset this thing though
you have to reset this thing though
don't
you can I Decay it over
time I wonder if I can modify this to
time I wonder if I can modify this to
Decay over
time and wait do you differentiate
time and wait do you differentiate
through this thing
intrinsic
rewards I think that if this is just the
rewards I think that if this is just the
reward you don't differentiate through
reward you don't differentiate through
this right
natural generalization of a count based
natural generalization of a count based
episod I have no idea how problem is
episod I have no idea how problem is
tabular this is a one hot en coding of
tabular this is a one hot en coding of
state and this will be a diagonal matrix
state and this will be a diagonal matrix
as entries contain the count
as entries contain the count
corresponding to each
corresponding to each
state encountered in the
episode
what C T minus one
oh that's kind of
wonky inverse will also be a diagonal
wonky inverse will also be a diagonal
matrix his entries are inverse State
matrix his entries are inverse State
visitation
visitation
counts which off the entry corresponding
counts which off the entry corresponding
yielding a bonus of okay yeah so these
yielding a bonus of okay yeah so these
are fan some fancy math people did some
are fan some fancy math people did some
fancy math I I kind of see how this
fancy math I I kind of see how this
works
works
for more General geometric interpr
interpretation if they're roughly
interpretation if they're roughly
centered at
centered at
zero unnormalized covariance Matrix what
zero unnormalized covariance Matrix what
the heck to that now consider the igen
the heck to that now consider the igen
decomposition
okay set of coordinates we can write the
okay set of coordinates we can write the
elliptical bonus
okay I have no idea honestly like this
okay I have no idea honestly like this
is I don't know what the hell any of
is I don't know what the hell any of
this is but okay um efficient
this is but okay um efficient
computation The Matrix needs to be
computation The Matrix needs to be
inverted at each
inverted at each
step operation that's
step operation that's
cubic we use the Sherman Morrison Matrix
cubic we use the Sherman Morrison Matrix
identity to perform fast rank one
identity to perform fast rank one
updates in quadratic time
see T minus
one
jeez okay
learned feature
learned feature
encoder any feature learning method
encoder any feature learning method
could in principle be
used here we use the inverse Dynamics
used here we use the inverse Dynamics
model approach in
model approach in
52 a model G along
52 a model G along
with Fe to map each
with Fe to map each
pair of consecutive
pair of consecutive
embeddings to a distribution over
embeddings to a distribution over
actions at linking
actions at linking
them separate from the policy
Network model is changed
Network model is changed
jointly the following per sample loss
jointly the following per sample loss
so you
so you
take this
buffer jeez
okay sample
action step through environment
action step through environment
compute
compute
bonus update covariance
Matrix from policy grading update is
Matrix from policy grading update is
rewards
rewards
update to minimize the
loss
okay torch Beast andace yeah terrible
okay torch Beast andace yeah terrible
library and then they just do
and then they do well
and then they do well
cool mini hack is not a very competitive
cool mini hack is not a very competitive
Benchmark cuz not enough people use
Benchmark cuz not enough people use
it
andala 3
B they underperform this
blue
blue
one or green
one or green
[Music]
one get this
okay this is
okay this is
cool that's a good result
again these are not very competitive
again these are not very competitive
benchmarks cuz they're like five people
benchmarks cuz they're like five people
doing this
work different okay
different algorithmic
components where is a randomly
components where is a randomly
initialized
initialized
Network this is bad
okay policy en code indicates
okay policy en code indicates
when these weights are tied to those of
when these weights are tied to those of
the policy Network
the policy Network
with the last layer
with the last layer
producing action probabilities
removed so instead of doing the act the
removed so instead of doing the act the
inverse Dynamics model this is actually
inverse Dynamics model this is actually
way simpler and that looks pretty
way simpler and that looks pretty
decent elliptical bonuses comped using
decent elliptical bonuses comped using
observations across
observations across
all time
all time
steps and not just the current episode
elliptical bonus is computed using
elliptical bonus is computed using
observations yeah so that Matrix just
observations yeah so that Matrix just
gets too much junk in it I
gets too much junk in it I
guess can you just I think I want to do
guess can you just I think I want to do
an exponential decaying
thing wait this highlights the both the
thing wait this highlights the both the
index and the episodic
index and the episodic
bonus well this is pretty good the
bonus well this is pretty good the
policy and code version is pretty good
policy and code version is pretty good
and it's simpler right
mini hack
ablations yeah this is pretty good right
ablations yeah this is pretty good right
here we're not having to train a whole
here we're not having to train a whole
inverse Dynamics
inverse Dynamics
model I actually like this one more
model I actually like this one more
here what did they get
here what did they get
Point say
6 and then
yeah so this is still better than the
yeah so this is still better than the
other
other
methods
methods
um this should still be better than the
um this should still be better than the
other
other
methods using without the inverse
methods using without the inverse
Dynamics model and it's much
Dynamics model and it's much
simpler so that's kind of what I want to
simpler so that's kind of what I want to
try Red Hook what's this that's
funny we got any appendix
funny we got any appendix
and useless
checklist they had this already I
think all these Nerfs checklist and
think all these Nerfs checklist and
statements are just so
statements are just so
dumb um follow
dumb um follow
this five layer comom
this five layer comom
okay it's a big policy for
RL
RL
Impala H for
Impala H for
parameters we did not
nail rolling
nail rolling
[Music]
[Music]
normalization
normalization
[Music]
deviation so they
tuned they just tuned their new hyper
tuned they just tuned their new hyper
paramet
yeah so you can see that they didn't
yeah so you can see that they didn't
these are just some parameter somebody
these are just some parameter somebody
came up
came up
with um
with um
okay so they could do way better just by
okay so they could do way better just by
tuning this stuff but the rl's too
slow
okay oh the they do
tune They Don't Really
tune They Don't Really
tune I guess they did a little bit of
tune I guess they did a little bit of
sweep but not
sweep but not
really they did like a dumb grid search
really they did like a dumb grid search
that's
fine okay neither Baseline okay
fine okay neither Baseline okay
okay well I'm not going to be too hard
okay well I'm not going to be too hard
on them like the results aren't going to
on them like the results aren't going to
be good cuz they're slow so it's it's
fine GP 100 what the
fine GP 100 what the
heck 10 and 30
heck 10 and 30
hours
yuck e3b was 1.5 to two times
yuck e3b was 1.5 to two times
slower additional forward pass through
slower additional forward pass through
the embedding Network used to compute
the embedding Network used to compute
the elliptical
bonus was performed on
bonus was performed on
CPU
why
okay do they release code
okay so they do actually tune a little
okay so they do actually tune a little
bit not great tuning but they tune a
bit not great tuning but they tune a
little
little
bit habitat details
bit habitat details
yeah code base
yeah code base
used official
official okay well where's your code
official okay well where's your code
base
yeah so I'm pretty sure we solve most of
yeah so I'm pretty sure we solve most of
these problems in puffer just like with
these problems in puffer just like with
tuned hyper parameters and more samples
tuned hyper parameters and more samples
and training
and training
fast
fast
um but fine we'll look at this
So Co variance regularizer
robust do they release
code they do
good good
job was published in 2020 oh 2022 okay
job was published in 2020 oh 2022 okay
so 3 years cool
so 3 years cool
um is there there anything more recent
um is there there anything more recent
than this or is this the like the best
thing let
thing let
me I don't know maybe let me just real
quick e
good job you reported older
good job you reported older
papers
stupid jity not
smart okay let's see code
smart okay let's see code
I'm I'm expecting this to be
I'm I'm expecting this to be
horrifying if this is built on forch
horrifying if this is built on forch
beast and
stuff okay wait we got it in Sample
stuff okay wait we got it in Sample
Factory
mini hack SL sample
Factory
okay this is 10 times faster than
okay this is 10 times faster than
before 10K FPS is 10 times faster than
before 10K FPS is 10 times faster than
before that is horrifying holy
hell good job
Alexi
um ah they do have the sweep
here is this just vendor yeah this is
here is this just vendor yeah this is
vendor sample Factory
so where is
this where the heck is this
I love it when the code base is
I love it when the code base is
structured such that you can't even find
structured such that you can't even find
the code in the code
base e3bp anybody
no no E3
b.p dude
b.p dude
how where is the
code do I have to look at the other one
code do I have to look at the other one
because of how ridiculous this
because of how ridiculous this
is um
they still have a
they still have a
bajillion D this
bajillion D this
is this should be a paper that is like
is this should be a paper that is like
300 lines of code on top of a standard
300 lines of code on top of a standard
implementation I do not know what the
hell maybe
hell maybe
this okay hold on
Source
FES
okay is
okay is
this okay here's your inverse Dynamics
this okay here's your inverse Dynamics
cool and
cool and
then e3bp
elliptical encoder
I honestly have no idea how I've stayed
I honestly have no idea how I've stayed
in RL this long cuz like I remember
in RL this long cuz like I remember
having to deal with stuff like this and
having to deal with stuff like this and
it's just a miserable time it's just an
it's just a miserable time it's just an
absolutely miserable time having to deal
absolutely miserable time having to deal
with li like
this um
this um
they have a separate Optimizer for the
encoder is it2
share memory what is
that okay so here's the
that okay so here's the
actual learn
actual learn
function so
that's
obscene
obscene
uh oh maybe okay this is just setting
uh oh maybe okay this is just setting
the mode okay right yeah this
the mode okay right yeah this
is please tell me this should just be
is please tell me this should just be
setting the
setting the
mode and
mode and
then elliptical encoder
State embed all
reward is bat a
reward R trce
return Baseline loss
turns yeah man I know it's this code is
turns yeah man I know it's this code is
like I literally don't
understand like literally you work on
understand like literally you work on
this code bra base for a week you'll
this code bra base for a week you'll
have crippling depression there's no way
have crippling depression there's no way
around
it like I remember when working in RL
it like I remember when working in RL
sucked this much in the first few years
sucked this much in the first few years
of my P HD and it was a miserable time
of my P HD and it was a miserable time
like I honestly don't know how I stayed
like I honestly don't know how I stayed
in this field for this long to like
in this field for this long to like
actually get to the point where stuff
actually get to the point where stuff
doesn't suck because like it's actually
doesn't suck because like it's actually
just miserable working on code like
this there's the thing with puffer it's
this there's the thing with puffer it's
like stuff's actually easy and make
like stuff's actually easy and make
sense now
it's kind of funny like I always like I
it's kind of funny like I always like I
start thinking like ah the stuff I'm
start thinking like ah the stuff I'm
doing with puffer is kind of simple
doing with puffer is kind of simple
actually and then like I go look at what
actually and then like I go look at what
everyone else is doing and I was like oh
everyone else is doing and I was like oh
my gosh okay yeah no we're doing good
my gosh okay yeah no we're doing good
work
here I have some weird puffer issues to
here I have some weird puffer issues to
ask about have you tested it with slow
ask about have you tested it with slow
multi-agent
multi-agent
M yeah it should
M yeah it should
work um that should work if you link me
work um that should work if you link me
a thing I will take a look at it
gladly slow multi-agent Ms with like
gladly slow multi-agent Ms with like
petting through wrapper or whatever you
petting through wrapper or whatever you
should just like double buffer sample on
should just like double buffer sample on
all the
all the
course and you should get close to num
course and you should get close to num
core speed up
sure what M specifically are you messing
with equal speed with here that sucks um
with equal speed with here that sucks um
now puffer should be way
now puffer should be way
faster Ridley laser tag n
um gley has its own internal
um gley has its own internal
vectorization though Ryan
right doesn't gly have its own internal
vectorization I don't know I'm using
vectorization I don't know I'm using
poppers okay I can look at it I know
poppers okay I can look at it I know
Gridley has really obnoxiously slow
Gridley has really obnoxiously slow
resets so he actually have to be pretty
resets so he actually have to be pretty
careful with your
careful with your
async
um but yeah if you have if you have cuz
um but yeah if you have if you have cuz
I know the our gridly binding is out a
I know the our gridly binding is out a
date so if you just want a like PR
date so if you just want a like PR
version of Gridley that actually works
version of Gridley that actually works
then I will be more than happy to uh you
then I will be more than happy to uh you
know run the perf test on whatever M
know run the perf test on whatever M
you're playing with
puffer should be
fast look into more
fast look into more
yeah you don't have to narrow down the
yeah you don't have to narrow down the
issue all you got to do is PR or like a
issue all you got to do is PR or like a
branch or whatever a
branch or whatever a
version like that I can just run right
version like that I can just run right
and see it
so either like link me your if you have
so either like link me your if you have
a fork of puffer or whatever you know
a fork of puffer or whatever you know
ideally if you're using gridly and you
ideally if you're using gridly and you
actually have it working with puffer it
actually have it working with puffer it
would be nice to have that PR cuz I
would be nice to have that PR cuz I
haven't had the time to mess with
haven't had the time to mess with
Gridley and Gridley is pretty
cool like we have a binding for Gridley
cool like we have a binding for Gridley
it just doesn't I don't think it works
it just doesn't I don't think it works
cuz Gridley is kind of weird they don't
cuz Gridley is kind of weird they don't
Define the observation spes until you
Define the observation spes until you
reset the n and that kind of screws some
reset the n and that kind of screws some
stuff
up technically not able to
share
really
oh yeah okay well if we want to do
oh yeah okay well if we want to do
something privately we can that's uh
I don't know why people do that on
I don't know why people do that on
academic research that should just that
academic research that should just that
should just be published by now but is
should just be published by now but is
it wait isn't that is it not a built-in
it wait isn't that is it not a built-in
gridly m is that not like a built-in
gridly m is that not like a built-in
gridly m
okay so we is the custom
M well I don't usually look at closed
M well I don't usually look at closed
Source
Source
Ms um but for you yeah I'll take a quick
Ms um but for you yeah I'll take a quick
look at
look at
in and see if I can figure out what's
in and see if I can figure out what's
wrong
really is pretty
cool sucks for RL that
cool sucks for RL that
um that
um that
mistel got uh got
mistel got uh got
Chris it' be awesome to have him doing
Chris it' be awesome to have him doing
RL stuff
nowadays I wonder what Chris would think
nowadays I wonder what Chris would think
of all the C stuff that I've been
of all the C stuff that I've been
writing I think he'd be down with it
writing I think he'd be down with it
it's like really just freaking simple
it's like really just freaking simple
ass C I think he'd be down with
it isn't he not a big RL
it isn't he not a big RL
fan I don't know about that I think he's
fan I don't know about that I think he's
just been doing language models at
just been doing language models at
minstral with a bunch of guys that are
minstral with a bunch of guys that are
like writing code 247 and having a good
like writing code 247 and having a good
time getting a nice
time getting a nice
paycheck I don't know if he like doesn't
paycheck I don't know if he like doesn't
like RL anymore I haven't heard that
nice it works well yeah RL is freaking
nice it works well yeah RL is freaking
cursed and broken because it hasn't had
cursed and broken because it hasn't had
billions of dollars of engineering
billions of dollars of engineering
investment but uh you know next best
investment but uh you know next best
thing is going to be one you know one
thing is going to be one you know one
puffer Libs worth of engineering
puffer Libs worth of engineering
investment it RL is going to work 2025
investment it RL is going to work 2025
here it's going to be 10 times easier to
here it's going to be 10 times easier to
get stuff up and running literally I'm
get stuff up and running literally I'm
telling you the end of the end of 25
telling you the end of the end of 25
we're going to have RL 10 times easier
we're going to have RL 10 times easier
to get working on new problems than it
to get working on new problems than it
is now so if it would take you you know
is now so if it would take you you know
10 hours to get something working on a
10 hours to get something working on a
new M it's going to take you one hour if
new M it's going to take you one hour if
it would take you 10 days it will take
it would take you 10 days it will take
you one day
curriculum learning will be easier as
curriculum learning will be easier as
well you should do um if you well I know
well you should do um if you well I know
you have enough work to do already but
you have enough work to do already but
um syllabus
um syllabus
with puffer native ends would be a cool
with puffer native ends would be a cool
thing it's a little tricky
thing it's a little tricky
because pipes are slow like on the scale
because pipes are slow like on the scale
of how fast our um our M's are pipes are
of how fast our um our M's are pipes are
just too slow so so you'd probably have
just too slow so so you'd probably have
to do like a shared memory
to do like a shared memory
thing yeah exactly like you can't you
thing yeah exactly like you can't you
can't just have like the pipe thing that
can't just have like the pipe thing that
you have is perfectly good for most RL
you have is perfectly good for most RL
environments but at our scale like when
environments but at our scale like when
we're doing a million steps per second
we're doing a million steps per second
you can if you you can still communicate
you can if you you can still communicate
stuff across processes and whatnot but
stuff across processes and whatnot but
it's got to be in shared
it's got to be in shared
memory it'd be pretty easy to bind for
memory it'd be pretty easy to bind for
um our like single process native M
um our like single process native M
though cuz a lot of our M's are so fast
though cuz a lot of our M's are so fast
we literally just run them on the main
we literally just run them on the main
process and still train it a million
process and still train it a million
steps per
second time for fast
second time for fast
prototyping yeah
prototyping yeah
wow the goal is to do both right with
wow the goal is to do both right with
puffer like if you look at our M
puffer like if you look at our M
wrappers and stuff stuff's actually very
wrappers and stuff stuff's actually very
very simple and it's fast so we like to
very simple and it's fast so we like to
have our cake and eat it
too we an elliptical
[Music]
encoder what the
encoder what the
hell net hack State embedding net
models
dot where the hell are
dot where the hell are
models issues the curriculum learning
models issues the curriculum learning
algorithms of totally random interfaces
algorithms of totally random interfaces
they're hard to hard to optimize out of
they're hard to hard to optimize out of
time need arbitrary data transfer to two
time need arbitrary data transfer to two
and from
and from
M's yeah but we can do
M's yeah but we can do
that like that's not that hard to
that like that's not that hard to
add you have to have the data be you
add you have to have the data be you
have to put the data into an
have to put the data into an
array um but if you do that then it's
array um but if you do that then it's
not that
bad cuz like what we do is we just
bad cuz like what we do is we just
instead of having a pipe right you just
instead of having a pipe right you just
have a shared memory buffer that you
have a shared memory buffer that you
write to so you're basically you're
write to so you're basically you're
writing to a number High Ray and shared
writing to a number High Ray and shared
memory the only thing that's obnoxious
memory the only thing that's obnoxious
is like we'd have to add an extra thing
is like we'd have to add an extra thing
into the all the environments uh just to
into the all the environments uh just to
support the curriculum learning stuff um
support the curriculum learning stuff um
so there'd have to be pretty damn
so there'd have to be pretty damn
compelling evidence that like you know
compelling evidence that like you know
this is the thing that's going to make
this is the thing that's going to make
RL sane and
RL sane and
stable I like curriculum learning so I
stable I like curriculum learning so I
think it's definitely possible but we
think it's definitely possible but we
need
evidence really need to reoptimize it
evidence really need to reoptimize it
every time you add yeah but the thing is
every time you add yeah but the thing is
Ryan like you're in this mindset where
Ryan like you're in this mindset where
there are a million algorithms
there are a million algorithms
constantly and like we need to support
constantly and like we need to support
all of them we genuinely don't care we
all of them we genuinely don't care we
just need like one good algorithm that
just need like one good algorithm that
works and we just support the current
works and we just support the current
best thing and that's
it
it
right like puffer doesn't have a million
right like puffer doesn't have a million
different algorithms and which not to
different algorithms and which not to
designed for a million different
designed for a million different
algorithms that have like arbitrary
algorithms that have like arbitrary
screwy things that they do we have like
screwy things that they do we have like
a simple V interface that
works we have no idea it
works we have no idea it
works yeah I mean my approach to
works yeah I mean my approach to
figuring out what's Works has just been
figuring out what's Works has just been
make the experiments run like 10,000 x
make the experiments run like 10,000 x
faster and then you kind of don't have
faster and then you kind of don't have
to be very smart if you do that you just
to be very smart if you do that you just
run everything
where their
where their
models I literally can't find their
models I literally can't find their
models how's this import even
work models
work models
dot
dot
huh source. models as models
oh it's a
oh it's a
file I thought it' be a
file I thought it' be a
folder me dumb
folder me dumb
okay net hack I remember this crop
okay net hack I remember this crop
banana
agains this is the elliptical
thingy why is there a full model on the
thingy why is there a full model on the
elliptical
thing I do not understand
this state embeddings
so neither of these look like an
so neither of these look like an
elliptical well neither of these look
elliptical well neither of these look
like the
like the
elliptical right neither of these look
elliptical right neither of these look
like the elliptical at
all so they have elliptical encoder
all so they have elliptical encoder
optim elliptical
encoder where's this thing
and then they Define
and then they Define
this so this is this thing I guess it's
this so this is this thing I guess it's
going to be in the loss function or
something
elliptical encoder
this so hard to figure this [ __ ]
this so hard to figure this [ __ ]
out
um I guess it's going to be in here is
um I guess it's going to be in here is
it compute policy gradient
it compute policy gradient
loss where's the
loss where's the
reward intrinsic rewards Plus
bonus
bonus
reward romly yeah
it's this is I've been reviewing like
it's this is I've been reviewing like
academic code bases all week and this is
academic code bases all week and this is
the worst by
the worst by
far this is just the
far this is just the
worst and that includes me having to
worst and that includes me having to
deal with rlb code
well the thing is rlb is they just have
well the thing is rlb is they just have
zero use like they have zero checks on
zero use like they have zero checks on
their API so like if you just if you use
their API so like if you just if you use
their API wrong at all you just get like
their API wrong at all you just get like
garbage internal messages 10 layers deep
garbage internal messages 10 layers deep
and then it's slow but the thing is once
and then it's slow but the thing is once
you actually get the code written
you actually get the code written
correctly like it will run and not be
correctly like it will run and not be
that much code it's completely opaque
that much code it's completely opaque
and you can't deal do anything with it
and you can't deal do anything with it
but like it runs this is just like
but like it runs this is just like
demonic I have no idea what this
demonic I have no idea what this
is which is annoying because it looks
is which is annoying because it looks
like a pretty decent paper but then it's
like a pretty decent paper but then it's
just like you look at the code and it's
just like you look at the code and it's
holy
hell okay I guess so this is inverse
hell okay I guess so this is inverse
Dynamics
Dynamics
floss right and then they have
floss right and then they have
elliptical encoder
where does the intrinsic reward get
where does the intrinsic reward get
computed bonus reward I don't know where
computed bonus reward I don't know where
this gets
this gets
rewarded at least it's just a bunch of
rewarded at least it's just a bunch of
yeah I
yeah I
guess but this is like maniacal I can't
guess but this is like maniacal I can't
find where they have the elliptical code
is it in
here this is net
here this is net
right so I don't see elliptical in here
right so I don't see elliptical in here
where's the Matrix stuff
right there's supposed to
right there's supposed to
be code on like low rank Matrix stuff
all the curriculum on that's good that
all the curriculum on that's good that
is what you should
is what you should
do I like I literally can't
do I like I literally can't
find is this
find is this
it
no like where's the low rank Matrix
no like where's the low rank Matrix
stuff
they have a whole habit of
yeah but I need to find where they
yeah but I need to find where they
compute it oh yeah Ryan I wanted to ask
compute it oh yeah Ryan I wanted to ask
you as well
you as well
so they have here let me find this I I
so they have here let me find this I I
thought I did something kind of clever
thought I did something kind of clever
here um I thought I found something kind
here um I thought I found something kind
of
of
clever with their
clever with their
math so here's the
math so here's the
paper um I think I found a nice
paper um I think I found a nice
Improvement to it so there's there's a
Improvement to it so there's there's a
major implementation Quirk here where
major implementation Quirk here where
it's just going to be very very
it's just going to be very very
difficult to implement this
difficult to implement this
incorrectly um this is defined over
incorrectly um this is defined over
episodes meaning that you need episode
episodes meaning that you need episode
bounds for
bounds for
this you need like per Agent episode
this you need like per Agent episode
bounds uh to compute this thing
bounds uh to compute this thing
correctly
correctly
so what I was thinking of doing is
so what I was thinking of doing is
instead in this is a a strict sum uh
instead in this is a a strict sum uh
right and they actually they have an
right and they actually they have an
oblation that says if you sum over
oblation that says if you sum over
everything like if you sum over all the
everything like if you sum over all the
episodes it's really bad nonepisodic
episodes it's really bad nonepisodic
right here so what if you made this
right here so what if you made this
exponentially
exponentially
decaying right what if I did like 0.9
decaying right what if I did like 0.9
times this thing like uh I just do
times this thing like uh I just do
like every every time you get a new one
like every every time you get a new one
of these you do
of these you do
* the old one plus 0.1 time the new one
* the old one plus 0.1 time the new one
or something like that they do like an
or something like that they do like an
exponentially decaying
thing and then you don't have to reset
it does that work
sounds interesting well the thing is
sounds interesting well the thing is
this you can't do
this you can't do
this you just can't do this when you
this you just can't do this when you
have variable episode length
literally where is their
literally where is their
freaking I'm log it where
freaking I'm log it where
is their
is their
fancy I literally can't find the piece
fancy I literally can't find the piece
of code that is the entire paper I can't
of code that is the entire paper I can't
find it
out e
literally where's the piece of
code okay what's the torch inverse
can I like search for
inverse KL
inverse e
is this
is this
it inverse
it inverse
covariance so this is it for
Habitat so we
Habitat so we
have one over
Ridge
Ridge
on inverse covariance
okay here's the outer product buffers
I'm trying to think how I'm going to add
I'm trying to think how I'm going to add
this to
puffery to think I'm going to add this
puffery to think I'm going to add this
to
to
puffer so
is it just like an extra
is it just like an extra
State let me
think look at the paper again
so you can almost just add this
so you can almost just add this
to to the network but not quite
to to the network but not quite
I think it's an extra state that we have
I think it's an extra state that we have
to
to
add just like the lstm
state wait
state wait
c t minus1
given a featureing coding
wait why does it only go to T minus
wait why does it only go to T minus
one hang
on okay so this is the previous date
on okay so this is the previous date
basically
wait does this have to get
wait does this have to get
differentiated through
yeah they use an inverse Dynamics model
yeah they use an inverse Dynamics model
for
fee but what was the alternative
here oh okay so this is a simple way of
here oh okay so this is a simple way of
producing
producing
it yeah you just chuse the hidden layer
it yeah you just chuse the hidden layer
okay so then if you do
okay so then if you do
that then this is gets just this is a
that then this is gets just this is a
DOT
detach I think this is not that
detach I think this is not that
bad this is not that bad so all I have
bad this is not that bad so all I have
to do is
to do is
add I have to add one state variable
the state variable is an inverted
Matrix and then what's this
update okay so there is a way to do
this we'll start with the standard thing
here and this thing is
here and this thing is
apparently apparently
useful just joined what paper is this
useful just joined what paper is this
this is
this is
e3b elliptical exploration via
e3b elliptical exploration via
elliptical episode
elliptical episode
bonuses they got this fancy function
bonuses they got this fancy function
here that they just add as a
reward and and this apparently
helps we're going to need to test this
helps we're going to need to test this
on a bunch of stuff
say it helps
say it helps
generally I mean they test on a bunch of
generally I mean they test on a bunch of
M's not as many M's as I would like but
M's not as many M's as I would like but
a bunch of
M's the thing is you like exploration is
M's the thing is you like exploration is
always key right it's just that by
always key right it's just that by
default we're doing it
default we're doing it
via um we're basically doing it via
via um we're basically doing it via
Brute Force initially
Brute Force initially
this is a generalization of counts
this is a generalization of counts
spaced exploration to continuous
spaced exploration to continuous
spaces
spaces
archived I mean it looks decent to me in
archived I mean it looks decent to me in
the sense that
the sense that
like this is not that hard to compute
like this is not that hard to compute
you add like you only have to add like
you add like you only have to add like
two small things to your
algorithm continuous no it's not
algorithm continuous no it's not
continuous action space specific it'll
continuous action space specific it'll
work for
anything it'll work for
whatever well it won't right you never
whatever well it won't right you never
know with these papers half the time
know with these papers half the time
they only work on the experiments that
they only work on the experiments that
they were done for here
they were done for here
but I don't know this
but I don't know this
probably this probably does
probably this probably does
something
something
um we'll see how annoying this thing is
um we'll see how annoying this thing is
to compute
I think it shouldn't be that
bad I'm going to go grab a quick I got a
bad I'm going to go grab a quick I got a
meeting in 30 minutes they have
meeting in 30 minutes they have
reference code yeah it's it's terrible
reference code yeah it's it's terrible
reference code but they have it it's a
reference code but they have it it's a
God awful reference code but they have
God awful reference code but they have
it it's on H Facebook research
e3b so I'm probably going to start
e3b so I'm probably going to start
implementing this later
implementing this later
tonight I got a 300 p.m. meeting so
tonight I got a 300 p.m. meeting so
probably and I got to make a couple
probably and I got to make a couple
quick calls so probably after that so
quick calls so probably after that so
yeah let me do that now what I'm going
yeah let me do that now what I'm going
to go do I'm going to grab a quick snack
to go do I'm going to grab a quick snack
and make a couple calls I got to make
and make a couple calls I got to make
and then we'll come back later and I'll
and then we'll come back later and I'll
start on this also we made uh Captain I
start on this also we made uh Captain I
made a huge amount of progress on carbs
made a huge amount of progress on carbs
I think I figured out why it's not
I think I figured out why it's not
working as well as it should be um
working as well as it should be um
that's going to take me a couple days of
that's going to take me a couple days of
work but we're going to have way better
work but we're going to have way better
hyper parameter
hyper parameter
sweeps I figured that out today as
well what's the problem pretty much the
well what's the problem pretty much the
thing that I said where they're like
thing that I said where they're like
they're transforming parameters into
they're transforming parameters into
like uh they're applying bad
like uh they're applying bad
transformations to the parameters and
transformations to the parameters and
applying bad sampling
applying bad sampling
basically so they have a really good
basically so they have a really good
algorithm that they're just doing their
algorithm that they're just doing their
data transforms and sampling wrong
I mean it makes sense that they are
I mean it makes sense that they are
their code is like horribly over
their code is like horribly over
complicated there as well in fact you
complicated there as well in fact you
know I think that there are two projects
know I think that there are two projects
that I want just for puffer one is I
that I want just for puffer one is I
want a much cleaned up and simpler
want a much cleaned up and simpler
version of carbs um that matches or
version of carbs um that matches or
exceeds the original and then I want the
exceeds the original and then I want the
same for box 2D so those are two major
same for box 2D so those are two major
projects for people to look at I'm
projects for people to look at I'm
probably going to do the carbs one
probably going to do the carbs one
myself um because it's kind of technical
myself um because it's kind of technical
unless anybody's really really wants to
unless anybody's really really wants to
look at
look at
it seeing the code you're talking about
it seeing the code you're talking about
didn't Brocket didn't try to see if it
didn't Brocket didn't try to see if it
was correct
was correct
yeah I don't know why your message just
yeah I don't know why your message just
didn't show up on the stream though I
didn't show up on the stream though I
see it in the in the chat it's
see it in the in the chat it's
weird
weird
um yeah it's a weird plugin thing okay
um yeah it's a weird plugin thing okay
I'm G to go I only got a half hour to
I'm G to go I only got a half hour to
like do some stuff so I'm going to go do
like do some stuff so I'm going to go do
some stuff and uh I will be back later
some stuff and uh I will be back later
in the afternoon thanks for tuning in
in the afternoon thanks for tuning in
folks um if you're interested in getting
folks um if you're interested in getting
involved or learning more about
involved or learning more about
puffer puffer doai GitHub star it helps
puffer puffer doai GitHub star it helps
us out a ton Discord puffer do discord.
us out a ton Discord puffer do discord.
GPU get involved here and you can also
GPU get involved here and you can also
follow me on X where I post all sorts of
follow me on X where I post all sorts of
RL
RL
stuff thanks and
