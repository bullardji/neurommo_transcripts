Kind: captions
Language: en
Good
Good
morning. We're back
morning. We're back
live.
Hi. The goal is to get heck of a lot of
Hi. The goal is to get heck of a lot of
stuff done today.
Um, a lot of experiment analysis, a
Um, a lot of experiment analysis, a
little bit of work done towards the
little bit of work done towards the
release. We're just going to see if I
release. We're just going to see if I
get bored at any point. I'm just going
get bored at any point. I'm just going
to stop working on release stuff and
to stop working on release stuff and
start working on other environment
start working on other environment
things this Saturday
things this Saturday
and I want to do at least some bits of
and I want to do at least some bits of
uh cool stuff
uh cool stuff
today. But the experiment analysis will
today. But the experiment analysis will
be a little bit interesting to start. So
be a little bit interesting to start. So
let me switch this over
let me switch this over
here. Let me grab the uh the chat.
What I always do is I just
um pass
this under
camera. So, we have a couple of sweeps
camera. So, we have a couple of sweeps
from overnight here. We've got Pac-Man.
from overnight here. We've got Pac-Man.
We've also got snake. These both seem to
We've also got snake. These both seem to
have performed quite adequately.
One day somebody will make a console
One day somebody will make a console
logging platform that actually
logging platform that actually
works. Um, but today is not that day.
So, here's real
time. There is one standout result
time. There is one standout result
here. I'm actually kind of
curious like does this have uh some
curious like does this have uh some
weird hyperparame is it just a lucky
on. I'm not seeing any um any standout
on. I'm not seeing any um any standout
hypers.
Oh well, it is interesting that it has a
Oh well, it is interesting that it has a
reasonable value function clip
reasonable value function clip
coefficient. It's kind of good news for
coefficient. It's kind of good news for
us.
This is Gab's new uh Pac-Man
This is Gab's new uh Pac-Man
environment. So, as a a little thank you
environment. So, as a a little thank you
for him having submitted this thing and
for him having submitted this thing and
cleaned it up in a quite a nice time
cleaned it up in a quite a nice time
frame.
frame.
Um, I uh decided to have one of the
Um, I uh decided to have one of the
sweeps from last night just be on that
sweeps from last night just be on that
end. He said he was having a little
end. He said he was having a little
trouble getting policies working as well
trouble getting policies working as well
as he wanted them
to. I figured I would just go ahead and
to. I figured I would just go ahead and
automate a bit of that for him.
So we get num ms is
eight. And I really should have a way of
eight. And I really should have a way of
automatically copying
automatically copying
these parameters over,
but only takes like a minute.
So, what I've been doing lately on
So, what I've been doing lately on
um on these sweeps here, right, is I've
um on these sweeps here, right, is I've
been first of all making sure that the
been first of all making sure that the
best runs that we get actually repro.
best runs that we get actually repro.
That's
That's
important. Uh but then I've been kind of
important. Uh but then I've been kind of
just filling all of these hyper prams
just filling all of these hyper prams
into a big spreadsheet.
into a big spreadsheet.
which you know obviously I could
which you know obviously I could
automate this in smarter ways there's
automate this in smarter ways there's
all sorts of things I can do with the
all sorts of things I can do with the
analysis
analysis
uh but just as an initial thing having a
uh but just as an initial thing having a
sheet that has all the best runs in it
sheet that has all the best runs in it
uh and the point of that is just to see
uh and the point of that is just to see
the hyperparam optimals are like
the hyperparam optimals are like
dramatically different or if I see any
dramatically different or if I see any
trends and if I see any trends maybe
trends and if I see any trends maybe
it's worth doing something more
it's worth doing something more
sophisticated
I think for now we will do
this. What do we think? H no CUDA
this. What do we think? H no CUDA
GPUs. Wish that that would not happen.
some reason the CUDA GPUs just
some reason the CUDA GPUs just
disconnect every so
disconnect every so
often
often
randomly. No good reason for
it. We
are Oh.
Huh?
Let me ask Gabe the max
score. Show him this result.
We got 167
We got 167
here. I think that the 180 or whatever
here. I think that the 180 or whatever
was just
was just
lucky. This can happen. Is that an OBS
lucky. This can happen. Is that an OBS
notification? We're still good,
notification? We're still good,
right? Good.
Um, we do want to make sure we get
this. Where did we go?
Pac-Man.
Okay. So, like all these guys are
Okay. So, like all these guys are
chilling at like 160s or whatever. And
chilling at like 160s or whatever. And
then
then
um you got this guy
um you got this guy
here that does
here that does
this. Let's actually let's set this to
this. Let's actually let's set this to
160 just so we can
like really see it. Okay. Okay, so we
like really see it. Okay. Okay, so we
have all these runs and then this repro
here, excuse me. Okay, so this repro
here, excuse me. Okay, so this repro
here, it does as well as the best run
here, it does as well as the best run
here except for this. So there is a
here except for this. So there is a
little bit of seed noise where like
little bit of seed noise where like
somehow there's a lucky game or
somehow there's a lucky game or
whatever. Uh but the repro run is still
whatever. Uh but the repro run is still
about as good as it gets. It's not like
about as good as it gets. It's not like
this was like looked lucky and then it
this was like looked lucky and then it
crashed a bunch. This is still very
crashed a bunch. This is still very
good.
How to
die? Oh, this is random.
All right, let's see what we're doing
All right, let's see what we're doing
here. Shouldn't have eaten that dot, I
here. Shouldn't have eaten that dot, I
don't
think. Hello,
think. Hello,
Landon. Puffer Lib is uh our toolkit of
Landon. Puffer Lib is uh our toolkit of
reinforcement learning environments,
reinforcement learning environments,
algorithms,
algorithms,
implementations, uh all of our research.
implementations, uh all of our research.
It's really just a comprehensive effort
It's really just a comprehensive effort
to make reinforcement learning fast and
to make reinforcement learning fast and
simple. You can find a bunch of our
simple. You can find a bunch of our
demos at puffer.ai. We have a lot of the
demos at puffer.ai. We have a lot of the
games like this that you can just play
games like this that you can just play
and uh you can see some of our trained
and uh you can see some of our trained
agents playing them in your browser. So,
agents playing them in your browser. So,
at the moment, I'm working on our next
at the moment, I'm working on our next
release. Uh it's a really pretty big
release. Uh it's a really pretty big
release and it makes everything at least
release and it makes everything at least
a few times better than it ever was
a few times better than it ever was
before.
before.
This looks like a a reasonable enough
This looks like a a reasonable enough
policy,
though. It hasn't learned to uh like not
though. It hasn't learned to uh like not
eat the dots for a while. Like that's
eat the dots for a while. Like that's
kind of hard for it. It kind of just
kind of hard for it. It kind of just
knows to
uh Did it just know there that whatever
uh Did it just know there that whatever
the pink one's name is was going to run
the pink one's name is was going to run
away?
I mean, this is better than me. At least
I mean, this is better than me. At least
this is better at the game than I am.
So, it must have got frame perfected
So, it must have got frame perfected
right
right
there. Like the ghost must have
there. Like the ghost must have
just come out of V.
Why doesn't it turn
around? Huh?
I wonder if it can see when the ghosts
are. Does it know when the ghosts are
vulnerable? How feasible do you think it
vulnerable? How feasible do you think it
would be to make some kind of model
would be to make some kind of model
scratch? I don't work on LM. I
scratch? I don't work on LM. I
technically have a little bit. I worked
technically have a little bit. I worked
on language modeling before LLMs
on language modeling before LLMs
existed. Um, it depends on your level of
existed. Um, it depends on your level of
experience, you know, if you have a good
experience, you know, if you have a good
programming
programming
background, some knowledge in computer.
background, some knowledge in computer.
I mean, if you're like, you'd have to
I mean, if you're like, you'd have to
basically be already be a decent
basically be already be a decent
programmer. Like, the thing that's going
programmer. Like, the thing that's going
to be difficult if you're trying to make
to be difficult if you're trying to make
a model from scratch is LMS just take a
a model from scratch is LMS just take a
ton of compute to train. is really
ton of compute to train. is really
obnoxious. If you want to look at
obnoxious. If you want to look at
something that's like really well done
something that's like really well done
in this area though, I would suggest you
in this area though, I would suggest you
look at like
look at like
Carpathy's GPT2 implementation where he
Carpathy's GPT2 implementation where he
basically did that, right? Uh he went
basically did that, right? Uh he went
and
and
like just implemented GPT2 from scratch
like just implemented GPT2 from scratch
and like C and CUDA and uh it was a
and like C and CUDA and uh it was a
really cool project.
really cool project.
Now, Car Pathy is pretty awesome, so
Now, Car Pathy is pretty awesome, so
that's a high bar, but
yeah. I mean, that project is pretty
yeah. I mean, that project is pretty
well exactly
that. The compute stuff is just
that. The compute stuff is just
annoying. like I think his original
annoying. like I think his original
version used um like 8H 800s or
version used um like 8H 800s or
something or 88 800s I don't know um for
something or 88 800s I don't know um for
GPT2 so way smaller model and then
GPT2 so way smaller model and then
eventually like people got it down to
eventually like people got it down to
train like really really really fast but
train like really really really fast but
you're never going to get it training
you're never going to get it training
really fast on your first go like it's
really fast on your first go like it's
going to always start off being more
going to always start off being more
expensive as
Okay. Okay. So they can actually
see. Yeah, this is done correctly. Good
see. Yeah, this is done correctly. Good
job, Gabe. This is reasonable.
Wait for it to lose.
something that can kind of respond to
something that can kind of respond to
what I type. It doesn't have to be. But
what I type. It doesn't have to be. But
I The thing is
like Have
you I'm trying to figure out how I put
this like the bar of oh, it doesn't have
this like the bar of oh, it doesn't have
to be a genius or anything.
Um, like I worked in I worked at least
Um, like I worked in I worked at least
for like a year or two in language
for like a year or two in language
modeling when we were happy if we could
modeling when we were happy if we could
get it to not be a genius to to be even
get it to not be a genius to to be even
like remotely
coherent.
coherent.
Um, so
Um, so
like you're actually going to have to
like you're actually going to have to
train something substantially large like
train something substantially large like
GP2 GPT2 is like
GP2 GPT2 is like
kind of coherentish at
best. It's not that most other fields of
best. It's not that most other fields of
computer science are cooked
either. It's that the salaries in um AI
either. It's that the salaries in um AI
specifically have gone to seven figures
specifically have gone to seven figures
while most of the other ones have kind
while most of the other ones have kind
of stayed roughly where they are.
But it's not like there's a super low
But it's not like there's a super low
barrier to entry either. It's not like
barrier to entry either. It's not like
you just do one like I mean have you
you just do one like I mean have you
read research papers right? Have you
read research papers right? Have you
done like deep learning basics? I mean
done like deep learning basics? I mean
there are like some
there are like some
pretty they're like very accessible
pretty they're like very accessible
these days to be fair but they still
these days to be fair but they still
exist.
exist.
um like generally people doing uh trying
um like generally people doing uh trying
to get into deep learning I have the
to get into deep learning I have the
guide on my website that's specifically
guide on my website that's specifically
for RL but like you want to at least
for RL but like you want to at least
have done something like Stanford CS231N
have done something like Stanford CS231N
it's not a hard class at least it's not
it's not a hard class at least it's not
meant to be but you do need to know some
meant to be but you do need to know some
fundamentals
fundamentals
um you probably want some experience
um you probably want some experience
training the models of different types
training the models of different types
implementing a few things from scratch
implementing a few things from scratch
so good on you that you did it that way
so good on you that you did it that way
you're trying to do that um not just
you're trying to do that um not just
like using stuff off the
shelf. Generally in AI like you're kind
shelf. Generally in AI like you're kind
of expected to be reading at least some
of expected to be reading at least some
number of research
number of research
papers in the area that you're
papers in the area that you're
interested
in. Hi
in. Hi
Spencer. Yeah, I trained uh I trained up
Spencer. Yeah, I trained uh I trained up
a decent model for Gabe here. Not
a decent model for Gabe here. Not
perfect yet. Oops. Where'd my files
go? We obviously have to make the power
go? We obviously have to make the power
pellet stars as
well. I mean, obviously
We can leave the little ones as is. I
We can leave the little ones as is. I
think the big ones got to be
stars. I can do terraform today,
man. I can do some terraform. I'm just
man. I can do some terraform. I'm just
checking some of the experiments
first cuz like we've run a whole bunch
first cuz like we've run a whole bunch
of stuff here. I'm kind of trying to get
of stuff here. I'm kind of trying to get
all our hypers together. Let me show you
all our hypers together. Let me show you
what I've been working on
here. Also, I don't know if that AWS
here. Also, I don't know if that AWS
request has even gone through
request has even gone through
yet. So, I'm kind of just sticking hyper
yet. So, I'm kind of just sticking hyper
prams for all the best runs in here.
Um, and I want to see if there's like if
Um, and I want to see if there's like if
there are any obvious
trends cuz so far all the runs they
trends cuz so far all the runs they
reproduce very
well, but like I don't know if there any
well, but like I don't know if there any
they're going to be any trends. I also
they're going to be any trends. I also
there is technically a way that we could
there is technically a way that we could
run a sweep um over like trying to
run a sweep um over like trying to
explicitly discover one set of hyper
explicitly discover one set of hyper
prams for everything. That would be
prams for everything. That would be
pretty cool.
But
like there's still a couple hypers that
like there's still a couple hypers that
make it a little
Landon, I would suggest just like pretty
Landon, I would suggest just like pretty
much just hard
much just hard
muting like all of the doomsayers on
muting like all of the doomsayers on
social media and stuff. um they're not
social media and stuff. um they're not
going to do you any favors and like
going to do you any favors and like
frankly a lot of the CEOs at these
frankly a lot of the CEOs at these
companies they're just lying to like
companies they're just lying to like
stir up hype and raise funds. Like the
stir up hype and raise funds. Like the
honestly the best thing you can do for
honestly the best thing you can do for
yourself professionally and also just
yourself professionally and also just
for your general enjoyment of stuff is
for your general enjoyment of stuff is
to just like ignore that crap. learn
to just like ignore that crap. learn
about AI for sure, but ignore like the
about AI for sure, but ignore like the
hype crap and just like focus on
hype crap and just like focus on
developing, you know, developing your
developing, you know, developing your
skills at something that you enjoy and
skills at something that you enjoy and
something that you can be proud of.
something that you can be proud of.
That's pretty much
it. You will be infinitely happier and
it. You will be infinitely happier and
also likely much more successful.
Like nobody's even honestly like
Like nobody's even honestly like
nobody's even thought about this for
nobody's even thought about this for
like two freaking seconds, right? For it
like two freaking seconds, right? For it
to even make sense. Okay, so is AI going
to even make sense. Okay, so is AI going
to automate all software? Okay, let's
to automate all software? Okay, let's
think about what that means. So well, if
think about what that means. So well, if
you write like if you write good domain
you write like if you write good domain
specific software in pretty much any
specific software in pretty much any
industry, uh you can solve like very
industry, uh you can solve like very
longstanding problems. I mean, literally
longstanding problems. I mean, literally
anybody who's capable, right, a capable
anybody who's capable, right, a capable
programmer who like actually knows some
programmer who like actually knows some
tech can really really transform a ton
tech can really really transform a ton
of industries just via software. So like
of industries just via software. So like
that's not just going to be software
that's not just going to be software
being replaced. That's kind of like most
being replaced. That's kind of like most
of the entire economy being
of the entire economy being
replaced. Okay. So
like you can't just like the magnitude
like you can't just like the magnitude
of the change is either going to be it
of the change is either going to be it
takes a while or
takes a while or
like well everything is completely
like well everything is completely
changed. It's not going to just be like
changed. It's not going to just be like
oh do this AI do like
oh do this AI do like
it's you kind of got to think about like
it's you kind of got to think about like
if you take the things that they say to
if you take the things that they say to
their logical conclusion what does that
their logical conclusion what does that
happen? Oh okay that makes no sense.
I'm not explaining that correctly
I'm not explaining that correctly
because it's like 8 a.m. on a Saturday.
But if I remove expert trajectories with
But if I remove expert trajectories with
collisions will improve score. Uh that's
collisions will improve score. Uh that's
a reasonable thing to do.
Spencer, I actually you're probably at
Spencer, I actually you're probably at
the point where you can just start
the point where you can just start
asking questions to the NYU folks just
asking questions to the NYU folks just
so that you get whatever it is that
so that you get whatever it is that
that's going to be useful for them
that's going to be useful for them
because like these aren't even details
because like these aren't even details
that are super important for whatever
that are super important for whatever
we're going to do with the sim at this
we're going to do with the sim at this
point, right?
Yeah. So, honestly to you, I would just
Yeah. So, honestly to you, I would just
suggest like, you
suggest like, you
know, build stuff that you find
know, build stuff that you find
interesting and that you enjoy. Um, if
interesting and that you enjoy. Um, if
AI is interesting to you and you want to
AI is interesting to you and you want to
learn about, go that way. There's so
learn about, go that way. There's so
much stuff that can be done.
much stuff that can be done.
And like at least at the time being as
And like at least at the time being as
somebody who's been programming for a
somebody who's been programming for a
long time and somebody who builds a lot
long time and somebody who builds a lot
of you know a lot of software in this
of you know a lot of software in this
area like the current language models
area like the current language models
are terrible programmers.
Um now I mean that said like could argue
Um now I mean that said like could argue
that like I would apply the same thing
that like I would apply the same thing
to like 90% of fang engineers and
to like 90% of fang engineers and
they're like making good money. So if
they're like making good money. So if
you're just trying to get a job then
you're just trying to get a job then
like okay maybe Maybe there's something
like okay maybe Maybe there's something
there. But like, have you noticed it's
there. But like, have you noticed it's
not like Fang has stopped hiring
not like Fang has stopped hiring
software engineers. Not like all the big
software engineers. Not like all the big
companies are like no longer hiring
companies are like no longer hiring
engineers. What does that tell
you? Hey,
you? Hey,
Quicksautique. We're taking a look at
Quicksautique. We're taking a look at
some um experiments from last
night and seeing if we see any cool
night and seeing if we see any cool
trends.
These are the 10 best snake
runs. Cycle learning rate is like in the
runs. Cycle learning rate is like in the
range we
expect. Gamas are very very high which
expect. Gamas are very very high which
is kind of
is kind of
surprising. You wouldn't expect gamma to
surprising. You wouldn't expect gamma to
be that high and then there's really low
be that high and then there's really low
lambda.
resampling my speed compute knobs. Yeah,
resampling my speed compute knobs. Yeah,
but the thing is like so Spencer with
but the thing is like so Spencer with
the speed on that like what we're going
the speed on that like what we're going
to do is we're like we match their
to do is we're like we match their
result and we say hey you guys mind if
result and we say hey you guys mind if
we mess with the obs a bit if we uh if
we mess with the obs a bit if we uh if
we keep PF the
we keep PF the
same they're going to say go for it.
same they're going to say go for it.
You're going to cut out 90% of the crap
You're going to cut out 90% of the crap
that's in the obs and then it's going to
that's in the obs and then it's going to
go 2 million SPS, right?
Why do think hard way if easy way just
Why do think hard way if easy way just
as
good? Okay, so snake actually benefits
good? Okay, so snake actually benefits
from some entropy it seems.
from some entropy it seems.
Cool. I guess it is one of the ends
Cool. I guess it is one of the ends
where you would kind of expect that.
I
I
mean, the bar for CS jobs has frankly
mean, the bar for CS jobs has frankly
just been way too low in the past.
Like, and let let me put it in a way
Like, and let let me put it in a way
that I think you'll find more
that I think you'll find more
encouraging. Um, working with bad
encouraging. Um, working with bad
programmers is a absolutely miserable
programmers is a absolutely miserable
experience. All right? Like I've had to
experience. All right? Like I've had to
work on teams where like, you know, you
work on teams where like, you know, you
have 10 engineers and they all suck. It
have 10 engineers and they all suck. It
is the most horrendous, depressing thing
is the most horrendous, depressing thing
imaginable, right? Like you can get paid
imaginable, right? Like you can get paid
well to like go do 30 hours of work a
well to like go do 30 hours of work a
week, but it's like holy hell. It is the
week, but it's like holy hell. It is the
most soul sucking depressing [ __ ]
most soul sucking depressing [ __ ]
imaginable. Like oh my god. because it's
imaginable. Like oh my god. because it's
like you're working on a job on a
like you're working on a job on a
computer all day where you're like
computer all day where you're like
fiddling with complicated things, right?
fiddling with complicated things, right?
And like hooking things together and
And like hooking things together and
basically it's the equivalent of like if
basically it's the equivalent of like if
you're building a house and people are
you're building a house and people are
just like nailing [ __ ] everywhere and
just like nailing [ __ ] everywhere and
you're trying to like make the thing
you're trying to like make the thing
like not fall apart. It is horrible.
like not fall apart. It is horrible.
Now, CS with a good team, with people
Now, CS with a good team, with people
who are building cool stuff is one of
who are building cool stuff is one of
the most enjoyable and awesome things
the most enjoyable and awesome things
out there cuz there's literally no other
out there cuz there's literally no other
field where you can build stuff that is
field where you can build stuff that is
this transformative just from your
this transformative just from your
laptop without having to have huge
laptop without having to have huge
amounts of equipment, without having to
amounts of equipment, without having to
have a capital investment. Like, you can
have a capital investment. Like, you can
do all sorts of cool stuff and in a ton
do all sorts of cool stuff and in a ton
of different areas, right? You can like
of different areas, right? You can like
go build stuff to transform basically
go build stuff to transform basically
any industry you can imagine just with
any industry you can imagine just with
that one skill set. Um, so like really,
that one skill set. Um, so like really,
yeah, the bar is higher. Just get good.
yeah, the bar is higher. Just get good.
Like if you care about this stuff, just
Like if you care about this stuff, just
get good. Put in the effort, right?
get good. Put in the effort, right?
You'll have more. Like, first of all,
You'll have more. Like, first of all,
you'll do better professionally
you'll do better professionally
regardless, and you'll enjoy it a heck
regardless, and you'll enjoy it a heck
of a lot more, too.
You're not going to be able to obsolete
You're not going to be able to obsolete
people in the next few years like this
people in the next few years like this
without a like a dramatic restructuring
without a like a dramatic restructuring
of stuff. So here's the thing like look
of stuff. So here's the thing like look
can you technically in the next few
can you technically in the next few
years will you technically be able to
years will you technically be able to
like ask a language model details about
like ask a language model details about
laws right and get a better response
laws right and get a better response
than you would get from a lawyer? Yeah,
than you would get from a lawyer? Yeah,
probably.
probably.
Um, are courts going to be letting you
Um, are courts going to be letting you
just have GPT defend you in court? No.
just have GPT defend you in court? No.
Uh, is GPT a person that's going to
Uh, is GPT a person that's going to
actually be able like to like an
actually be able like to like an
attorney to deliver a defense? No. Like,
attorney to deliver a defense? No. Like,
is it going to be able to actually
is it going to be able to actually
interact with professional systems like
interact with professional systems like
with like the in the existing way where
with like the in the existing way where
there has to be a person? No. And like
there has to be a person? No. And like
like even if the technological changes
like even if the technological changes
there like the infrastructure and the
there like the infrastructure and the
setup is not going to be so quick for a
setup is not going to be so quick for a
lot of stuff. Um, which is frustrating
lot of stuff. Um, which is frustrating
actually. It's frustrating when you
actually. It's frustrating when you
build tech when you build something that
build tech when you build something that
is better and it doesn't work better.
is better and it doesn't work better.
Now, to be fair, is it going to be
Now, to be fair, is it going to be
better than a good lawyer? No. No, it's
better than a good lawyer? No. No, it's
not. Um, so that's kind of a important
not. Um, so that's kind of a important
distinction.
distinction.
Um, yeah, I I think it's like I wouldn't
Um, yeah, I I think it's like I wouldn't
worry too much about like planning for
worry too much about like planning for
what is AI going to replace and this and
what is AI going to replace and this and
that. Just like trying to like give a
that. Just like trying to like give a
damn and get good at stuff is going to
damn and get good at stuff is going to
put you ahead of people who don't try
put you ahead of people who don't try
and don't, right? That's
it.
it.
Like that's kind of like regardless of
Like that's kind of like regardless of
what happens. Like no, you're going to
what happens. Like no, you're going to
do better off than the guy who doesn't
do better off than the guy who doesn't
give a damn and doesn't try.
And that's just how it always is.
Right now, the the key thing, right, and
Right now, the the key thing, right, and
this is the thing that's very difficult
this is the thing that's very difficult
unless you're one of those rare people
unless you're one of those rare people
who can basically like choose to do a
who can basically like choose to do a
thing and then just do it and like focus
thing and then just do it and like focus
on it regardless of whether you're
on it regardless of whether you're
interested. I can't do that at all. Uh
interested. I can't do that at all. Uh
the key thing is actually picking
the key thing is actually picking
something where you're able to get a
something where you're able to get a
good chunk of your like focus and
good chunk of your like focus and
attention out of it for prolonged
attention out of it for prolonged
periods of time, right? Which is usually
periods of time, right? Which is usually
you have to find something that is
you have to find something that is
consistently interesting to
you. Yeah. But if you defend yourself in
you. Yeah. But if you defend yourself in
court and just are reading off a GPT or
court and just are reading off a GPT or
whatever, you have to like there's a
whatever, you have to like there's a
jury sitting there, right, that's
jury sitting there, right, that's
watching you do
that. Like it doesn't work like whoever
that. Like it doesn't work like whoever
says the more like there there's an
says the more like there there's an
interaction there,
right? How can a lawyer be? Because it's
right? How can a lawyer be? Because it's
not just knowing the law. That's not
not just knowing the law. That's not
what it is, right? That's like an
encyclopedia. There's argument, there is
encyclopedia. There's argument, there is
interpretation, there's combination of
interpretation, there's combination of
that. Like there's a lot of things
that. Like there's a lot of things
there. It's not just like I mean that's
there. It's not just like I mean that's
not how that's like saying like, hey,
not how that's like saying like, hey,
how can uh how could a programmer
how can uh how could a programmer
possibly be better than GPT that has
possibly be better than GPT that has
access to every API ever? Well, I have
access to every API ever? Well, I have
access to every API ever just with a
access to every API ever just with a
Google search,
Google search,
right? That's not what it's about.
Oh, that's a crazy clip coefficient.
Oh, that's a crazy clip coefficient.
That's kind of
That's kind of
interesting. 75 clip with snake. Yeah.
interesting. 75 clip with snake. Yeah.
Okay, buddy.
All
All
right, let's go see our 75 clip snake
run.
run.
Jesus. It's a good thing that I
Jesus. It's a good thing that I
increased the uh the range of that param
increased the uh the range of that param
cuz apparently it
works. Holy
I don't know.
I don't know.
I would just generally suggest ignoring
I would just generally suggest ignoring
the like there's basically nothing good
the like there's basically nothing good
that comes out of listening to the like
that comes out of listening to the like
oh AI replacing you all whatever is on
oh AI replacing you all whatever is on
on the internet especially like Daario
on the internet especially like Daario
and Altman. I do not trust them for
and Altman. I do not trust them for
[ __ ] I
don't. It's actually, you know,
don't. It's actually, you know,
like, and it sucks as well because when
like, and it sucks as well because when
I was at OpenAI in 2019, Ultman actually
I was at OpenAI in 2019, Ultman actually
had a really, really good vision
had a really, really good vision
for where he wanted to take Open AI. He
for where he wanted to take Open AI. He
basically said like, "We want to be able
basically said like, "We want to be able
to take a ton of different concentrated
to take a ton of different concentrated
bets in different areas, right? Like a
bets in different areas, right? Like a
ton of different concentrated bets just
ton of different concentrated bets just
in all sorts of different areas of AI
in all sorts of different areas of AI
and see where they go." And that would
and see where they go." And that would
be fantastic. But then what happened is
be fantastic. But then what happened is
that GPT happened and then they canned
that GPT happened and then they canned
all the other teams and they put all the
all the other teams and they put all the
resources into LLMs and they didn't even
resources into LLMs and they didn't even
keep like you know any amount of stuff
keep like you know any amount of stuff
on different areas of AI and now it's
on different areas of AI and now it's
all marketing and it's just like it's a
all marketing and it's just like it's a
mess. It's a whole real
mess. So
mess. So
like didn't follow through on on that at
like didn't follow through on on that at
all.
money can. Yeah, it
money can. Yeah, it
is. But the thing is like I don't
is. But the thing is like I don't
begrudge people the money, right? I
begrudge people the money, right? I
never begrudge people the money. Um it's
never begrudge people the money. Um it's
just like don't entirely lose focus,
just like don't entirely lose focus,
right? Okay, LM are great, right? LM are
right? Okay, LM are great, right? LM are
doing a ton of stuff, but
doing a ton of stuff, but
like it's not that, oh, I see people
like it's not that, oh, I see people
making money in LM and that's bad or
making money in LM and that's bad or
like LM are blowing up. Like that's all
like LM are blowing up. Like that's all
good. The point where it drives me nuts
good. The point where it drives me nuts
is that
is that
like so you know how many people I know
like so you know how many people I know
in reinforcement learning, like really
in reinforcement learning, like really
good smart people who are still in
good smart people who are still in
reinforcement
reinforcement
learning, like pure RL with no LLM
learning, like pure RL with no LLM
stuff, zero.
stuff, zero.
All my buddies, all my buddies who are
All my buddies, all my buddies who are
brilliant in pure RL have gone to work
brilliant in pure RL have gone to work
at least in some capacity on
at least in some capacity on
LLMs. That's sad. And the reason that's
LLMs. That's sad. And the reason that's
sad is because what happens if the LLM
sad is because what happens if the LLM
people are wrong, right? What if they
people are wrong, right? What if they
don't solve everything? Then we're
don't solve everything? Then we're
[ __ ] because all that knowledge has
[ __ ] because all that knowledge has
just gone out the window. You know, it's
just gone out the window. You know, it's
not like you can't just read papers and
not like you can't just read papers and
get back the domain knowledge that the
get back the domain knowledge that the
experts actually have. It takes years to
experts actually have. It takes years to
rediscover these types of things, right?
rediscover these types of things, right?
So, that's actually damaged science a
So, that's actually damaged science a
ton. really more than anything else you
ton. really more than anything else you
see in the news lately is draining all
see in the news lately is draining all
of the resources from every other field
of the resources from every other field
to go into this one very specific sub
to go into this one very specific sub
field and have everybody building bigger
field and have everybody building bigger
and bigger models and like filtering
and bigger models and like filtering
data and whatever the hell else they're
data and whatever the hell else they're
doing with like a thousand people
doing with like a thousand people
instead of with
instead of with
500. So that's that is where I get
500. So that's that is where I get
annoyed with uh what's happening with
annoyed with uh what's happening with
LMS at the moment. Now, to be fair, I
LMS at the moment. Now, to be fair, I
think RL's going to be just fine. Um,
think RL's going to be just fine. Um,
because I, for whatever reason, have
because I, for whatever reason, have
decided to spend the rest of my 20s like
decided to spend the rest of my 20s like
trying to actually make it work and I'm
trying to actually make it work and I'm
having some good success here. So, I'm
having some good success here. So, I'm
going to make sure that RL is good, but
going to make sure that RL is good, but
what about all the other sub fields,
what about all the other sub fields,
right? There were people doing cool AIE
right? There were people doing cool AIE
stuff. There were people doing like
stuff. There were people doing like
hybrid systems. There were so many other
hybrid systems. There were so many other
cool things that people are doing that
cool things that people are doing that
they just stopped
on. Yeah. closed source max profit
on. Yeah. closed source max profit
is you want you'd ideally you want these
is you want you'd ideally you want these
research labs to at least have some open
research labs to at least have some open
source and like some mix of incentives
right like to their credit right the
right like to their credit right the
thing that they said is right like
thing that they said is right like
they're not going to get to where they
they're not going to get to where they
want to be without raising a ton of
want to be without raising a ton of
money
money
but like that doesn't mean you have to
but like that doesn't mean you have to
go 100% down that route
to the detriment of the rest of the
to the detriment of the rest of the
field at
field at
least. Like what happened to the Dota
least. Like what happened to the Dota
team, right? Like the Dota guys, I think
team, right? Like the Dota guys, I think
they just went on to codegen and stuff
they just went on to codegen and stuff
like man that you know how much damage
like man that you know how much damage
that did to RL alone losing like the
that did to RL alone losing like the
Dota team. That would have like we would
Dota team. That would have like we would
have a different field right now if they
have a different field right now if they
kept on that stuff. Um there were so
kept on that stuff. Um there were so
many so many good things and I know
many so many good things and I know
because I was around those people and
because I was around those people and
they were brilliant.
And now here I am. You know, it took me
And now here I am. You know, it took me
I had to do a PhD. So it took me five
I had to do a PhD. So it took me five
years to like actually get through the
years to like actually get through the
rigma role of that. Uh I made some
rigma role of that. Uh I made some
discoveries over the process but heavily
discoveries over the process but heavily
heavily constrained by academia and the
heavily constrained by academia and the
way that academia expects you to do your
way that academia expects you to do your
work. And now one year, it's literally
work. And now one year, it's literally
been one year since I've graduated. RS
been one year since I've graduated. RS
is a different field. And you know
is a different field. And you know
that's a little bit aggressive to say
that's a little bit aggressive to say
when I'm kind of promoting my own stuff
when I'm kind of promoting my own stuff
here, but literally just like take a
here, but literally just like take a
look at our tools today. use our tools
look at our tools today. use our tools
for RL now compared to anything else
for RL now compared to anything else
that existed one year ago. It is a
that existed one year ago. It is a
different field from one year of
different field from one year of
work. Like this stuff can be done and
work. Like this stuff can be done and
it's like it could have been done but it
it's like it could have been done but it
could have been done a long time ago,
could have been done a long time ago,
right? This could have been done a long
right? This could have been done a long
time
ago. It's all right. I'll do it now.
the right M. This is
right. Google's I've heard cool things.
right. Google's I've heard cool things.
Haven't read it yet.
I mean, the thing is like at this point
I mean, the thing is like at this point
there's like very little that I could
there's like very little that I could
read outside of what I'm doing at the
read outside of what I'm doing at the
moment unless it directly says that the
moment unless it directly says that the
thing I'm doing won't work. There's like
thing I'm doing won't work. There's like
very little that would like convince me
very little that would like convince me
to like look at other stuff at the
to like look at other stuff at the
moment because I see like where this is
moment because I see like where this is
going right
going right
now. Drainage of young people. Well,
now. Drainage of young people. Well,
they're being drained into into all AI.
they're being drained into into all AI.
Yeah.
Yeah.
I don't know, man. There's a bunch of
I don't know, man. There's a bunch of
just jank
just jank
stuff. The whole like, oh, let's just
stuff. The whole like, oh, let's just
use GPA to code for us thing is
horrid. The fact that they're actually
horrid. The fact that they're actually
CEOs dumb enough to think that like, oh
CEOs dumb enough to think that like, oh
yeah, the most important thing is all
yeah, the most important thing is all
our programmers are using AI constantly.
our programmers are using AI constantly.
Like, holy hell.
Like most of the time, at least like 80%
Like most of the time, at least like 80%
of the time, I'd say I uh I kind of use
of the time, I'd say I uh I kind of use
like I'll use Grock or whatever as like
like I'll use Grock or whatever as like
fancy API docs for like looking up niche
fancy API docs for like looking up niche
stuff. I'm never using it to like just
stuff. I'm never using it to like just
oh yeah, just write all the code.
oh yeah, just write all the code.
I literally I had the other
day I went off on one of our
day I went off on one of our
contributors for costing me six hours by
contributors for costing me six hours by
uh to be fair I shouldn't have merged
uh to be fair I shouldn't have merged
it. Like I didn't I missed it though. He
it. Like I didn't I missed it though. He
like used GPT or Gemini or whatever uh
like used GPT or Gemini or whatever uh
to submit a patch to critical
to submit a patch to critical
infrastructure he didn't understand and
infrastructure he didn't understand and
literally cost me six hours with one of
literally cost me six hours with one of
the worst bugs I've had to deal with in
the worst bugs I've had to deal with in
months.
months.
um
um
just don't you
know and it almost doesn't matter like
know and it almost doesn't matter like
how good the AI gets is the thing like
how good the AI gets is the thing like
there's never a time when that's going
there's never a time when that's going
to
to
be like there's kind of never a time in
be like there's kind of never a time in
my s in like my eyes where it makes
my s in like my eyes where it makes
sense to have like the human like like
sense to have like the human like like
person writing prompts in equals
person writing prompts in equals
programmer because then it's like you
programmer because then it's like you
either just use the lang language model
either just use the lang language model
as the programmer completely which ain't
as the programmer completely which ain't
happening anytime soon. Uh or you don't
happening anytime soon. Uh or you don't
do that and you actually maintain
do that and you actually maintain
control over what you're writing and
control over what you're writing and
like you understand how the thing that
like you understand how the thing that
you're working on actually should
work more efficient algorithm. Yeah. So
work more efficient algorithm. Yeah. So
that was
that was
interesting. But this is far from what
interesting. But this is far from what
we were promised, right? This is far
we were promised, right? This is far
from like the recursively self-improving
from like the recursively self-improving
systems that just get better and better
systems that just get better and better
and better.
Um, which is odd because like I can do
Um, which is odd because like I can do
that, right? Like I can recursively
that, right? Like I can recursively
self-improve. I've done it with Puffer,
self-improve. I've done it with Puffer,
right? I've literally if you look at
right? I've literally if you look at
where it was in like if you look at
where it was in like if you look at
where RL was a year ago and you look at
where RL was a year ago and you look at
it now and basically the prompt behind
it now and basically the prompt behind
puffer was like hey fix everything wrong
puffer was like hey fix everything wrong
with reinforcement learning informed by
with reinforcement learning informed by
you know your own understanding of the
you know your own understanding of the
current literature the current research
current literature the current research
and the current state of the field. If
and the current state of the field. If
you want to like think of the prompt
you want to like think of the prompt
that would be it.
So, you know,
So, you know,
if if uh you're going to say that like,
if if uh you're going to say that like,
okay, these language models have PhD
okay, these language models have PhD
level intelligence. Well, I'm a PhD.
level intelligence. Well, I'm a PhD.
That's my qualification for doing this.
That's my qualification for doing this.
Um I don't see language models doing
Um I don't see language models doing
anything remotely like this, right?
anything remotely like this, right?
They're not even like, you can't even
They're not even like, you can't even
give them like, hey, you know, go pick a
give them like, hey, you know, go pick a
problem, like pick a thing that needs
problem, like pick a thing that needs
like some better tools and make those
like some better tools and make those
tools. You can't even get them to do
tools. You can't even get them to do
like a midsize project that I could have
like a midsize project that I could have
any more junior dev do who's had like a
any more junior dev do who's had like a
couple years of dev
couple years of dev
experience. So, I don't
experience. So, I don't
know. That's not to say these things
know. That's not to say these things
aren't impressive. They wildly are very
aren't impressive. They wildly are very
impressive. And I should be clear with
impressive. And I should be clear with
that when I uh when I'm bashing these
that when I uh when I'm bashing these
things. The thing that I'm critical of
things. The thing that I'm critical of
is the drainage of all talent to work on
is the drainage of all talent to work on
these. And also how much the CEOs in
these. And also how much the CEOs in
these areas just they lie about freaking
these areas just they lie about freaking
everything, you know?
That's the
issue. AI discovered something new.
issue. AI discovered something new.
Well, that's not definitely not true,
Well, that's not definitely not true,
right? That's definitely not the case.
right? That's definitely not the case.
We've had AIS discover things all the
We've had AIS discover things all the
time that are new.
time that are new.
Um, I mean the thing is like most new
Um, I mean the thing is like most new
things
things
are I mean they're just logical
are I mean they're just logical
inferences off of previous things many
inferences off of previous things many
of the times unless every so often
of the times unless every so often
there's like a completely out there
there's like a completely out there
thing.
thing.
Um, but that stuff's definitely happened
before. I don't think it's I wouldn't
before. I don't think it's I wouldn't
look at it as like a step
change as much as just like an
change as much as just like an
impressive result.
the like, oh, it's a step change thing
the like, oh, it's a step change thing
is usually, at least when there's money
is usually, at least when there's money
behind it, there's usually like, hey,
behind it, there's usually like, hey,
um, somebody's trying to sell you
um, somebody's trying to sell you
something. Now, I say that while kind of
something. Now, I say that while kind of
claiming the same thing about Puffer,
claiming the same thing about Puffer,
like I will say that Puffer 3 is a step
like I will say that Puffer 3 is a step
change over, uh, previous like RL stuff.
change over, uh, previous like RL stuff.
Um, but that's really because like from
Um, but that's really because like from
a perspective of somebody who's been
a perspective of somebody who's been
doing RL research for a long time, like
doing RL research for a long time, like
it just feels more stable is the thing.
it just feels more stable is the thing.
It feels like a qualitative
change. Whereas I don't think like
change. Whereas I don't think like
something discovering one thing is a
something discovering one thing is a
step like that's not like a qu like a
step like that's not like a qu like a
step change. It would have to be
step change. It would have to be
something really crazy, right?
Like, yeah, if it goes and resolves P
Like, yeah, if it goes and resolves P
equals NP or something, then yeah.
equals NP or something, then yeah.
Okay. Okay.
Okay. Okay.
Right. But like, it made its own
Right. But like, it made its own
training 1% more efficient. It's really
training 1% more efficient. It's really
cool. It's a like it's a nice
cool. It's a like it's a nice
advancement. It's not like a step
advancement. It's not like a step
change, I wouldn't say.
But the thing is you're you're limiting
But the thing is you're you're limiting
to just LMS. Like RL's been doing this
to just LMS. Like RL's been doing this
for a while, right? There was like the
for a while, right? There was like the
uh the was it move 37 or whatever in Go.
uh the was it move 37 or whatever in Go.
Um they like there's new strategies that
Um they like there's new strategies that
the thing has discovered and like Dota
the thing has discovered and like Dota
like and those are like really small
like and those are like really small
models as well. Um heck the Dota ones
models as well. Um heck the Dota ones
didn't even have search in them and they
didn't even have search in them and they
changed like they discovered stuff that
changed like they discovered stuff that
like pro players hadn't seen before as
like pro players hadn't seen before as
well. Um there's similar stuff in Alpha
well. Um there's similar stuff in Alpha
Star. AI has been like it's kind of
Star. AI has been like it's kind of
always been able to discover new
always been able to discover new
stuff. Now like language models
specifically, language models
specifically, language models
specifically, it's very hard to prove is
specifically, it's very hard to prove is
the problem because like you don't
the problem because like you don't
actually know what's in the training
actually know what's in the training
data.
data.
There's definitely been
There's definitely been
quirky like clever stuff where I
quirky like clever stuff where I
couldn't find a reference for it. I
couldn't find a reference for it. I
think one of the the funniest things I
think one of the the funniest things I
saw was
um there was a thing that I came out of
um there was a thing that I came out of
GPT. I think it was like three or 3.5. I
GPT. I think it was like three or 3.5. I
couldn't find a source for it anywhere,
couldn't find a source for it anywhere,
but that doesn't mean it wasn't in the
but that doesn't mean it wasn't in the
training data.
training data.
There was like some quip from it that's
There was like some quip from it that's
like, "What's a bastard sword?" Well,
like, "What's a bastard sword?" Well,
it's not my father's sword and I didn't
it's not my father's sword and I didn't
make it. And he didn't make it
make it. And he didn't make it
himself, which I like that was the first
himself, which I like that was the first
thing I looked at and went like, I
thing I looked at and went like, I
actually come up with
that. I don't know. But you can't prove
that. I don't know. But you can't prove
that type of stuff unfortunately. Now,
that type of stuff unfortunately. Now,
like scientific breakthroughs,
um, yeah, comedian chief, that's funny.
um, yeah, comedian chief, that's funny.
Now, like scientific breakthroughs, the
Now, like scientific breakthroughs, the
thing is
thing is
like that's not really that's like they
like that's not really that's like they
made an optimization to a kernel. Like
made an optimization to a kernel. Like
there's one optimization to a kernel.
there's one optimization to a kernel.
Um, the reason that that sounds
Um, the reason that that sounds
impressive is because kernels are like
impressive is because kernels are like
this, oh, like this fantastic weird
this, oh, like this fantastic weird
thing that only the elite elite
thing that only the elite elite
programmers know. Kernels are freaking
programmers know. Kernels are freaking
simple. Here, let me show you a
kernel.
Here, this is all a kernel
Here, this is all a kernel
is.
Uh, all right. It's just a piece of C
Uh, all right. It's just a piece of C
code that runs on your GPU. That's all
code that runs on your GPU. That's all
it
it
is. And it's like run in parallel on
is. And it's like run in parallel on
blocks of like on usually embarrassingly
blocks of like on usually embarrassingly
parallel blocks of
parallel blocks of
data. That's all it is. But all the
data. That's all it is. But all the
thing did is like all right you got like
thing did is like all right you got like
a matrix mold kernel that has some ops
a matrix mold kernel that has some ops
it makes like some small change that
it makes like some small change that
makes this it a little bit faster while
makes this it a little bit faster while
have doing like the same
have doing like the same
thing. Now be fair I think that in their
thing. Now be fair I think that in their
case it was it made a much larger change
case it was it made a much larger change
but it was because it was only for a
but it was because it was only for a
very specific matrix multiply format.
very specific matrix multiply format.
Um,
Um,
yeah, I wouldn't be surprised like
yeah, I wouldn't be surprised like
literally nobody's tried to like
literally nobody's tried to like
optimize that at all
before. Did this thing just only get 97?
before. Did this thing just only get 97?
Did I just read that
right? That's not good.
Maybe we shouldn't go for the lucky yolo
Maybe we shouldn't go for the lucky yolo
run
here. Yeah, that doesn't seem super
here. Yeah, that doesn't seem super
stable,
huh?
huh?
Wait, something's weird.
I was definitely weird with that.
Something feels different there. Did I
Something feels different there. Did I
miss a parameter?
miss a parameter?
Perhaps I might have missed a a
Perhaps I might have missed a a
parameter there. Hang on.
So yeah, this one is definitely unstable
So yeah, this one is definitely unstable
at least as written.
32k mini
32k mini
batch. I missed something like with veck
batch. I missed something like with veck
or
or
something. There's ve Oh, 16
something. There's ve Oh, 16
m. I don't know how I messed that
m. I don't know how I messed that
up. Try again.
Oh yeah, that's way faster. 3 million
Oh yeah, that's way faster. 3 million
step per second
step per second
snake. That's with a That's with a small
snake. That's with a That's with a small
combin too, isn't it? It is with a comet
combin too, isn't it? It is with a comet
combet at 3
combet at 3
million. That's
million. That's
good. That's not even on a 5090.
Ah, there we
Ah, there we
go. Okay, that was on me. I just had it
go. Okay, that was on me. I just had it
reproed
wrong. Oh, we have lots of M that we're
wrong. Oh, we have lots of M that we're
trying to solve. Um, so Gabe made
trying to solve. Um, so Gabe made
Pac-Man.
Pac-Man.
We also have the snake end
We also have the snake end
which we
are. Let's see how good these snakes
look. Multi-agent snake with a ton of
look. Multi-agent snake with a ton of
snakes.
Pretty cool if you just kind of watch
Pretty cool if you just kind of watch
this thing,
right? Thing took like two minutes to
right? Thing took like two minutes to
train and we actually have
train and we actually have
like neuronets playing snake pretty darn
like neuronets playing snake pretty darn
capably.
mechanically they're
superhuman. Oh, I
bought. Yeah, that's way better than
bought. Yeah, that's way better than
what we have on the website for
sure.
sure.
Cool. I'm happy with this result. This
Cool. I'm happy with this result. This
is very clean.
Where did this go?
Let's just do a little bit of quick
math. Second
There's that many
160 days, right?
160 days, right?
Yeah.
Yeah.
Hours, 10 steps per second. Yeah, that's
Hours, 10 steps per second. Yeah, that's
right. And that
right. And that
passes my quick maths test as well.
Yeah. 140 mil
Yeah. 140 mil
steps, 36,000 steps per
steps, 36,000 steps per
hour, 24 days. Yeah, that's correct.
That's a nice gift.
Okay, snake prams are
good. Let's add um add these to the
spreadsheet. Pac-Man and Snake.
These clipping coefficients are very
These clipping coefficients are very
odd, I will
odd, I will
say. Very, very
odd. Being zero is especially sus.
Got seven of these M's
Got seven of these M's
though. And I can probably get connect
though. And I can probably get connect
four if I can make it not Seg fault.
Fix render in
Python.
Yes. Not going to get called.
Welcome, man. How's it
going? Thoughts on
hiking? I don't really ever hike. I'll
hiking? I don't really ever hike. I'll
run.
run.
I did a heck of a lot of running last
I did a heck of a lot of running last
summer at the Stamford
Dish. I don't
Dish. I don't
know. If I want to relax, I'm going to
know. If I want to relax, I'm going to
walk. If I want to exercise, I'm going
walk. If I want to exercise, I'm going
to run. Hiking is kind of a weird in
to run. Hiking is kind of a weird in
between.
I wonder if this is a numb workers.
supported. Yeah, I know. Wolfra does the
supported. Yeah, I know. Wolfra does the
the funny
things. Nah, I prefer to
things. Nah, I prefer to
do I don't do my exercise while I'm
do I don't do my exercise while I'm
coding. It's crazy. That guy is just
coding. It's crazy. That guy is just
nuts. He's very productive, but he's
nuts. He's very productive, but he's
nuts. I don't know how the hell he does
nuts. I don't know how the hell he does
any of
that.
Unsupported. Something's weird here.
Why the hell is this?
Why the hell is this?
Four
in the Zaro
here. Cellular. That's cool stuff. I
here. Cellular. That's cool stuff. I
mean, we could pro like honestly there's
mean, we could pro like honestly there's
a lot of a lifestyle work we could do
a lot of a lifestyle work we could do
and probably just crush with
and probably just crush with
uh the way we do stuff in
puffer. Okay.
puffer. Okay.
So somehow numb
workers up for connect four. So somehow
workers up for connect four. So somehow
numb workers is getting passed as
numb workers is getting passed as
four. Really shouldn't be here. Upper
four. Really shouldn't be here. Upper
connect
connect
four because this auto
This not have numb
This not have numb
workers. Oh, it's got to be
Vec. Okay, so this has numb workers set
Vec. Okay, so this has numb workers set
to four for some reason.
Something seems weird with that.
Am I like I'm trying to figure out if
Am I like I'm trying to figure out if
I'm doing something monumentally
stupid? Not just do I not have it
stupid? Not just do I not have it
written like what?
written like what?
Oh, I do base
env. So, how the heck does it default to
uh the four? That's
weird. That's so weird.
Oh, cuz you're stupid. That's why.
This still This still does not run
This still This still does not run
though.
Still does not run.
Is there anything jank in this config
Is there anything jank in this config
that would
that would
cause I wonder if it's this
No, it's not the learning, right?
What the heck would cause this in
um like the end of itself.
If I set up a preset number of
agents, but my M does not actually
agents, but my M does not actually
create that total number of
create that total number of
agents across all
copies. That have a bad downstream.
copies. That have a bad downstream.
Well, yes.
Um well, if
Um well, if
you if you create more agents than you
you if you create more agents than you
request and you're writing to the
request and you're writing to the
buffer, then you're
overflowing. If you have 1022, then the
overflowing. If you have 1022, then the
odds are just going to be zeros, right?
odds are just going to be zeros, right?
like you're going to have it's either
like you're going to have it's either
going to be zero data or whatever
going to be zero data or whatever
happened to be in that buffer last
thing is still
jank. Other M's we can do. We should
jank. Other M's we can do. We should
launch some more sweeps right now.
launch some more sweeps right now.
Get like puffer grid.
We're going to let this
We're going to let this
run. This covers grid and let's do
run. This covers grid and let's do
um that I can't
really ask
I do have an invite I want to work on
I do have an invite I want to work on
actually today potentially. There's also
actually today potentially. There's also
terraform to
terraform to
do. We could just sweep Terraform
do. We could just sweep Terraform
technically, but like it's
technically, but like it's
not I don't know if it's like close
not I don't know if it's like close
enough to done deep BB like be worth
enough to done deep BB like be worth
doing anything with that on yet. I
doing anything with that on yet. I
definitely like having the grid sweep
definitely like having the grid sweep
up. Um what other M have we not done? I
up. Um what other M have we not done? I
guess we haven't done the RAWware and
guess we haven't done the RAWware and
triple like those are easy though. It's
triple like those are easy though. It's
just I there's one annoying thing I have
just I there's one annoying thing I have
to deal with for that.
Oh yeah, tower climb. Let me do that for
Oh yeah, tower climb. Let me do that for
you real quick. Good
call. Not on the website, so I keep
call. Not on the website, so I keep
forgetting website.
max. And well, we'll see what this does.
Um, why does this not have a num maps
param? No maps is
param? No maps is
50. Hey, does it take forever to make
50. Hey, does it take forever to make
maps or something?
like map gems really slow.
Oh, that's
annoying. Yeah, dude. That map gen is
annoying. Yeah, dude. That map gen is
super
slow. Is it crashed?
That's seg faulted, isn't it?
Looks like faulted.
Well, this runs
Yeah. Okay. It is just
slow. Are we supposed to use harder maps
slow. Are we supposed to use harder maps
or something though? Because
like I mean I just ran defaults and
like I mean I just ran defaults and
um get 80% in like seconds.
um get 80% in like seconds.
Doesn't look stable though. I guess I'll
Doesn't look stable though. I guess I'll
run this for
now. Go get you. Um
Get this.
Good. This is actually No, this is
Good. This is actually No, this is
four. Oh, I I messed that up in the
four. Oh, I I messed that up in the
repro then, didn't
repro then, didn't
I? I will fix that real quick.
I forgot his name.
Didn't I just edit tower climb?
That heat.
math domain error. Lovely.
Did I just get a good
error? Uh cuz min and max are backwards,
error? Uh cuz min and max are backwards,
man.
man.
That's why
and then this will be the tower climb
and then this will be the tower climb
sweep. We're getting very close to
sweep. We're getting very close to
having hyper prams for everything.
It should be
sweep. How do we still have this
error reward full Bro,
Still thought I fixed
Still thought I fixed
everything. 0 to one with mean of.5.
Oh, you dummy.
Still,
man, how am I screwing this up so badly
man, how am I screwing this up so badly
today? What the
heck? Like
Ah, I
Ah, I
see. Why had I not I have negative
see. Why had I not I have negative
number? What?
confused. I not swept negative rewards
confused. I not swept negative rewards
before.
Well, I mean for now what we can do
is hang on. I got uh somebody at the at
is hang on. I got uh somebody at the at
the
Four. All right.
We'll just change this to uniform for
We'll just change this to uniform for
now. I think that that should
work. And
now error train.
What? What are we doing here? Oh, we're
What? What are we doing here? Oh, we're
doing stupid things.
Seems like it's
starting. If it actually starts uh
starting. If it actually starts uh
starts
starts
running. So then we are
set. Hoping this is just taking a
while. Oh yeah, it works.
while. Oh yeah, it works.
This takes a while to generate maps.
This takes a while to generate maps.
That's
That's
fine.
Cool. We've got grid and tower climb
Cool. We've got grid and tower climb
running sweeps at the moment.
Okay, so let's think of uh what
Okay, so let's think of uh what
environments have we not done yet? We
environments have we not done yet? We
got tower climb. Obviously, there is
got tower climb. Obviously, there is
Impulse Wars to deal
Impulse Wars to deal
with. Neuralarm MMO, those are the hard
with. Neuralarm MMO, those are the hard
ones.
ones.
We got Moa, go snake. We got all these
We got Moa, go snake. We got all these
done. E4 even. This has the Segv
done. E4 even. This has the Segv
vault. Not bad. Look at that. These two
vault. Not bad. Look at that. These two
we haven't done yet. They're easy.
we haven't done yet. They're easy.
They're just one small quirk I have to
They're just one small quirk I have to
fix.
fix.
Um and then yeah, we get to start
Um and then yeah, we get to start
thinking probably about neural MMO and
thinking probably about neural MMO and
uh and such.
It would seem odd that neural MMO is
It would seem odd that neural MMO is
this much harder
this much harder
though, wouldn't
it? Oh, it is kind of a hard end.
I guess we could do like a
I guess we could do like a
short a short local sweep
short a short local sweep
uh on Terraform.
Make sure this actually runs.
All
right. Stuff like target we don't need
right. Stuff like target we don't need
to hyper prem sweep it just it trains
instantly. We can start looking at um
instantly. We can start looking at um
the trends here
though. The atom optimizer params are or
though. The atom optimizer params are or
the uh the optim params are very weird.
We look at VF
clip. It only did for enduro. It did the
clip. It only did for enduro. It did the
really low VF clip
here. The rest of them are actually
here. The rest of them are actually
reasonable.
They're pretty different hypers
They're pretty different hypers
actually.
I mean, at least like triple triad has
I mean, at least like triple triad has
the low gamma you'd
the low gamma you'd
expect and connect four which did run
expect and connect four which did run
gives
gives
us really high. Okay, that's weird.
us really high. Okay, that's weird.
So, I mean, we definitely have way more
So, I mean, we definitely have way more
stable hyper pram ranges than
stable hyper pram ranges than
before to the point like if you don't
before to the point like if you don't
tune your hypers, you can still like get
tune your hypers, you can still like get
a lot of stuff to work. But I think it
a lot of stuff to work. But I think it
still makes sense to have pretty tuned
still makes sense to have pretty tuned
hypers for a lot of
stuff. So I think that's probably the
stuff. So I think that's probably the
best way to think about it is like it's
best way to think about it is like it's
not necessarily that we made hypers way
not necessarily that we made hypers way
more robust alone. It's that we kind of
more robust alone. It's that we kind of
just made everything better. So like the
just made everything better. So like the
level of performance we were getting
level of performance we were getting
before with optimized hypers we can now
before with optimized hypers we can now
get with unoptimized hypers. But we can
get with unoptimized hypers. But we can
do way better
do way better
still with optimized hypers which is
still with optimized hypers which is
fine. That's totally
fine. That's totally
fine. I'm fine shipping like custom
fine. I'm fine shipping like custom
hypers for each if that's not an issue.
hypers for each if that's not an issue.
if it gives us better
if it gives us better
perf. I don't think we should feel bad
perf. I don't think we should feel bad
about
that. Let's go look at what other M's I
that. Let's go look at what other M's I
have missed that I just like have
have missed that I just like have
forgotten about in here.
Oh, we kind of got Oh, those are the
Oh, we kind of got Oh, those are the
two. What about the
two. What about the
3L? Blast star. I didn't tune that
yet. We're doing pretty well.
I'm going to just launch a quick sweep
I'm going to just launch a quick sweep
on Terraform.
I'm just going to let this run locally
I'm just going to let this run locally
for uh over
for uh over
breakfast. And yeah, I'm going to go get
breakfast. And yeah, I'm going to go get
breakfast in a minute here. Uh and I'll
breakfast in a minute here. Uh and I'll
be back in a bit. And
be back in a bit. And
then I think it'll probably make the
then I think it'll probably make the
most sense to just like either do stuff
most sense to just like either do stuff
on some of the harder M's like look at
on some of the harder M's like look at
Impulse Wars, look at Nurm Mo, maybe
Impulse Wars, look at Nurm Mo, maybe
look at uh some Dev on Terraform or
look at uh some Dev on Terraform or
start uh some new new research pretty
start uh some new new research pretty
well. So I'll go think about what I want
well. So I'll go think about what I want
to do next on this. I guess technically
to do next on this. I guess technically
we could also just like if I don't feel
we could also just like if I don't feel
like starting on something, we could
like starting on something, we could
also just like get all the new policies
also just like get all the new policies
exported that we have the demos done.
exported that we have the demos done.
and that's also fine. Anyways, uh I will
and that's also fine. Anyways, uh I will
be back after breakfast. So, uh and then
be back after breakfast. So, uh and then
I will be live for the whole rest of the
I will be live for the whole rest of the
day. Goal is going to be to stream like
day. Goal is going to be to stream like
an extra seven, eight hours today. So,
an extra seven, eight hours today. So,
um at least. Thanks for tuning in for
um at least. Thanks for tuning in for
the morning session and I will

Kind: captions
Language: en
Good
Good
morning. We're back
morning. We're back
live.
Hi. The goal is to get heck of a lot of
Hi. The goal is to get heck of a lot of
stuff done today.
Um, a lot of experiment analysis, a
Um, a lot of experiment analysis, a
little bit of work done towards the
little bit of work done towards the
release. We're just going to see if I
release. We're just going to see if I
get bored at any point. I'm just going
get bored at any point. I'm just going
to stop working on release stuff and
to stop working on release stuff and
start working on other environment
start working on other environment
things this Saturday
things this Saturday
and I want to do at least some bits of
and I want to do at least some bits of
uh cool stuff
uh cool stuff
today. But the experiment analysis will
today. But the experiment analysis will
be a little bit interesting to start. So
be a little bit interesting to start. So
let me switch this over
let me switch this over
here. Let me grab the uh the chat.
What I always do is I just
um pass
this under
camera. So, we have a couple of sweeps
camera. So, we have a couple of sweeps
from overnight here. We've got Pac-Man.
from overnight here. We've got Pac-Man.
We've also got snake. These both seem to
We've also got snake. These both seem to
have performed quite adequately.
One day somebody will make a console
One day somebody will make a console
logging platform that actually
logging platform that actually
works. Um, but today is not that day.
So, here's real
time. There is one standout result
time. There is one standout result
here. I'm actually kind of
curious like does this have uh some
curious like does this have uh some
weird hyperparame is it just a lucky
on. I'm not seeing any um any standout
on. I'm not seeing any um any standout
hypers.
Oh well, it is interesting that it has a
Oh well, it is interesting that it has a
reasonable value function clip
reasonable value function clip
coefficient. It's kind of good news for
coefficient. It's kind of good news for
us.
This is Gab's new uh Pac-Man
This is Gab's new uh Pac-Man
environment. So, as a a little thank you
environment. So, as a a little thank you
for him having submitted this thing and
for him having submitted this thing and
cleaned it up in a quite a nice time
cleaned it up in a quite a nice time
frame.
frame.
Um, I uh decided to have one of the
Um, I uh decided to have one of the
sweeps from last night just be on that
sweeps from last night just be on that
end. He said he was having a little
end. He said he was having a little
trouble getting policies working as well
trouble getting policies working as well
as he wanted them
to. I figured I would just go ahead and
to. I figured I would just go ahead and
automate a bit of that for him.
So we get num ms is
eight. And I really should have a way of
eight. And I really should have a way of
automatically copying
automatically copying
these parameters over,
but only takes like a minute.
So, what I've been doing lately on
So, what I've been doing lately on
um on these sweeps here, right, is I've
um on these sweeps here, right, is I've
been first of all making sure that the
been first of all making sure that the
best runs that we get actually repro.
best runs that we get actually repro.
That's
That's
important. Uh but then I've been kind of
important. Uh but then I've been kind of
just filling all of these hyper prams
just filling all of these hyper prams
into a big spreadsheet.
into a big spreadsheet.
which you know obviously I could
which you know obviously I could
automate this in smarter ways there's
automate this in smarter ways there's
all sorts of things I can do with the
all sorts of things I can do with the
analysis
analysis
uh but just as an initial thing having a
uh but just as an initial thing having a
sheet that has all the best runs in it
sheet that has all the best runs in it
uh and the point of that is just to see
uh and the point of that is just to see
the hyperparam optimals are like
the hyperparam optimals are like
dramatically different or if I see any
dramatically different or if I see any
trends and if I see any trends maybe
trends and if I see any trends maybe
it's worth doing something more
it's worth doing something more
sophisticated
I think for now we will do
this. What do we think? H no CUDA
this. What do we think? H no CUDA
GPUs. Wish that that would not happen.
some reason the CUDA GPUs just
some reason the CUDA GPUs just
disconnect every so
disconnect every so
often
often
randomly. No good reason for
it. We
are Oh.
Huh?
Let me ask Gabe the max
score. Show him this result.
We got 167
We got 167
here. I think that the 180 or whatever
here. I think that the 180 or whatever
was just
was just
lucky. This can happen. Is that an OBS
lucky. This can happen. Is that an OBS
notification? We're still good,
notification? We're still good,
right? Good.
Um, we do want to make sure we get
this. Where did we go?
Pac-Man.
Okay. So, like all these guys are
Okay. So, like all these guys are
chilling at like 160s or whatever. And
chilling at like 160s or whatever. And
then
then
um you got this guy
um you got this guy
here that does
here that does
this. Let's actually let's set this to
this. Let's actually let's set this to
160 just so we can
like really see it. Okay. Okay, so we
like really see it. Okay. Okay, so we
have all these runs and then this repro
here, excuse me. Okay, so this repro
here, excuse me. Okay, so this repro
here, it does as well as the best run
here, it does as well as the best run
here except for this. So there is a
here except for this. So there is a
little bit of seed noise where like
little bit of seed noise where like
somehow there's a lucky game or
somehow there's a lucky game or
whatever. Uh but the repro run is still
whatever. Uh but the repro run is still
about as good as it gets. It's not like
about as good as it gets. It's not like
this was like looked lucky and then it
this was like looked lucky and then it
crashed a bunch. This is still very
crashed a bunch. This is still very
good.
How to
die? Oh, this is random.
All right, let's see what we're doing
All right, let's see what we're doing
here. Shouldn't have eaten that dot, I
here. Shouldn't have eaten that dot, I
don't
think. Hello,
think. Hello,
Landon. Puffer Lib is uh our toolkit of
Landon. Puffer Lib is uh our toolkit of
reinforcement learning environments,
reinforcement learning environments,
algorithms,
algorithms,
implementations, uh all of our research.
implementations, uh all of our research.
It's really just a comprehensive effort
It's really just a comprehensive effort
to make reinforcement learning fast and
to make reinforcement learning fast and
simple. You can find a bunch of our
simple. You can find a bunch of our
demos at puffer.ai. We have a lot of the
demos at puffer.ai. We have a lot of the
games like this that you can just play
games like this that you can just play
and uh you can see some of our trained
and uh you can see some of our trained
agents playing them in your browser. So,
agents playing them in your browser. So,
at the moment, I'm working on our next
at the moment, I'm working on our next
release. Uh it's a really pretty big
release. Uh it's a really pretty big
release and it makes everything at least
release and it makes everything at least
a few times better than it ever was
a few times better than it ever was
before.
before.
This looks like a a reasonable enough
This looks like a a reasonable enough
policy,
though. It hasn't learned to uh like not
though. It hasn't learned to uh like not
eat the dots for a while. Like that's
eat the dots for a while. Like that's
kind of hard for it. It kind of just
kind of hard for it. It kind of just
knows to
uh Did it just know there that whatever
uh Did it just know there that whatever
the pink one's name is was going to run
the pink one's name is was going to run
away?
I mean, this is better than me. At least
I mean, this is better than me. At least
this is better at the game than I am.
So, it must have got frame perfected
So, it must have got frame perfected
right
right
there. Like the ghost must have
there. Like the ghost must have
just come out of V.
Why doesn't it turn
around? Huh?
I wonder if it can see when the ghosts
are. Does it know when the ghosts are
vulnerable? How feasible do you think it
vulnerable? How feasible do you think it
would be to make some kind of model
would be to make some kind of model
scratch? I don't work on LM. I
scratch? I don't work on LM. I
technically have a little bit. I worked
technically have a little bit. I worked
on language modeling before LLMs
on language modeling before LLMs
existed. Um, it depends on your level of
existed. Um, it depends on your level of
experience, you know, if you have a good
experience, you know, if you have a good
programming
programming
background, some knowledge in computer.
background, some knowledge in computer.
I mean, if you're like, you'd have to
I mean, if you're like, you'd have to
basically be already be a decent
basically be already be a decent
programmer. Like, the thing that's going
programmer. Like, the thing that's going
to be difficult if you're trying to make
to be difficult if you're trying to make
a model from scratch is LMS just take a
a model from scratch is LMS just take a
ton of compute to train. is really
ton of compute to train. is really
obnoxious. If you want to look at
obnoxious. If you want to look at
something that's like really well done
something that's like really well done
in this area though, I would suggest you
in this area though, I would suggest you
look at like
look at like
Carpathy's GPT2 implementation where he
Carpathy's GPT2 implementation where he
basically did that, right? Uh he went
basically did that, right? Uh he went
and
and
like just implemented GPT2 from scratch
like just implemented GPT2 from scratch
and like C and CUDA and uh it was a
and like C and CUDA and uh it was a
really cool project.
really cool project.
Now, Car Pathy is pretty awesome, so
Now, Car Pathy is pretty awesome, so
that's a high bar, but
yeah. I mean, that project is pretty
yeah. I mean, that project is pretty
well exactly
that. The compute stuff is just
that. The compute stuff is just
annoying. like I think his original
annoying. like I think his original
version used um like 8H 800s or
version used um like 8H 800s or
something or 88 800s I don't know um for
something or 88 800s I don't know um for
GPT2 so way smaller model and then
GPT2 so way smaller model and then
eventually like people got it down to
eventually like people got it down to
train like really really really fast but
train like really really really fast but
you're never going to get it training
you're never going to get it training
really fast on your first go like it's
really fast on your first go like it's
going to always start off being more
going to always start off being more
expensive as
Okay. Okay. So they can actually
see. Yeah, this is done correctly. Good
see. Yeah, this is done correctly. Good
job, Gabe. This is reasonable.
Wait for it to lose.
something that can kind of respond to
something that can kind of respond to
what I type. It doesn't have to be. But
what I type. It doesn't have to be. But
I The thing is
like Have
you I'm trying to figure out how I put
this like the bar of oh, it doesn't have
this like the bar of oh, it doesn't have
to be a genius or anything.
Um, like I worked in I worked at least
Um, like I worked in I worked at least
for like a year or two in language
for like a year or two in language
modeling when we were happy if we could
modeling when we were happy if we could
get it to not be a genius to to be even
get it to not be a genius to to be even
like remotely
coherent.
coherent.
Um, so
Um, so
like you're actually going to have to
like you're actually going to have to
train something substantially large like
train something substantially large like
GP2 GPT2 is like
GP2 GPT2 is like
kind of coherentish at
best. It's not that most other fields of
best. It's not that most other fields of
computer science are cooked
either. It's that the salaries in um AI
either. It's that the salaries in um AI
specifically have gone to seven figures
specifically have gone to seven figures
while most of the other ones have kind
while most of the other ones have kind
of stayed roughly where they are.
But it's not like there's a super low
But it's not like there's a super low
barrier to entry either. It's not like
barrier to entry either. It's not like
you just do one like I mean have you
you just do one like I mean have you
read research papers right? Have you
read research papers right? Have you
done like deep learning basics? I mean
done like deep learning basics? I mean
there are like some
there are like some
pretty they're like very accessible
pretty they're like very accessible
these days to be fair but they still
these days to be fair but they still
exist.
exist.
um like generally people doing uh trying
um like generally people doing uh trying
to get into deep learning I have the
to get into deep learning I have the
guide on my website that's specifically
guide on my website that's specifically
for RL but like you want to at least
for RL but like you want to at least
have done something like Stanford CS231N
have done something like Stanford CS231N
it's not a hard class at least it's not
it's not a hard class at least it's not
meant to be but you do need to know some
meant to be but you do need to know some
fundamentals
fundamentals
um you probably want some experience
um you probably want some experience
training the models of different types
training the models of different types
implementing a few things from scratch
implementing a few things from scratch
so good on you that you did it that way
so good on you that you did it that way
you're trying to do that um not just
you're trying to do that um not just
like using stuff off the
shelf. Generally in AI like you're kind
shelf. Generally in AI like you're kind
of expected to be reading at least some
of expected to be reading at least some
number of research
number of research
papers in the area that you're
papers in the area that you're
interested
in. Hi
in. Hi
Spencer. Yeah, I trained uh I trained up
Spencer. Yeah, I trained uh I trained up
a decent model for Gabe here. Not
a decent model for Gabe here. Not
perfect yet. Oops. Where'd my files
go? We obviously have to make the power
go? We obviously have to make the power
pellet stars as
well. I mean, obviously
We can leave the little ones as is. I
We can leave the little ones as is. I
think the big ones got to be
stars. I can do terraform today,
man. I can do some terraform. I'm just
man. I can do some terraform. I'm just
checking some of the experiments
first cuz like we've run a whole bunch
first cuz like we've run a whole bunch
of stuff here. I'm kind of trying to get
of stuff here. I'm kind of trying to get
all our hypers together. Let me show you
all our hypers together. Let me show you
what I've been working on
here. Also, I don't know if that AWS
here. Also, I don't know if that AWS
request has even gone through
request has even gone through
yet. So, I'm kind of just sticking hyper
yet. So, I'm kind of just sticking hyper
prams for all the best runs in here.
Um, and I want to see if there's like if
Um, and I want to see if there's like if
there are any obvious
trends cuz so far all the runs they
trends cuz so far all the runs they
reproduce very
well, but like I don't know if there any
well, but like I don't know if there any
they're going to be any trends. I also
they're going to be any trends. I also
there is technically a way that we could
there is technically a way that we could
run a sweep um over like trying to
run a sweep um over like trying to
explicitly discover one set of hyper
explicitly discover one set of hyper
prams for everything. That would be
prams for everything. That would be
pretty cool.
But
like there's still a couple hypers that
like there's still a couple hypers that
make it a little
Landon, I would suggest just like pretty
Landon, I would suggest just like pretty
much just hard
much just hard
muting like all of the doomsayers on
muting like all of the doomsayers on
social media and stuff. um they're not
social media and stuff. um they're not
going to do you any favors and like
going to do you any favors and like
frankly a lot of the CEOs at these
frankly a lot of the CEOs at these
companies they're just lying to like
companies they're just lying to like
stir up hype and raise funds. Like the
stir up hype and raise funds. Like the
honestly the best thing you can do for
honestly the best thing you can do for
yourself professionally and also just
yourself professionally and also just
for your general enjoyment of stuff is
for your general enjoyment of stuff is
to just like ignore that crap. learn
to just like ignore that crap. learn
about AI for sure, but ignore like the
about AI for sure, but ignore like the
hype crap and just like focus on
hype crap and just like focus on
developing, you know, developing your
developing, you know, developing your
skills at something that you enjoy and
skills at something that you enjoy and
something that you can be proud of.
something that you can be proud of.
That's pretty much
it. You will be infinitely happier and
it. You will be infinitely happier and
also likely much more successful.
Like nobody's even honestly like
Like nobody's even honestly like
nobody's even thought about this for
nobody's even thought about this for
like two freaking seconds, right? For it
like two freaking seconds, right? For it
to even make sense. Okay, so is AI going
to even make sense. Okay, so is AI going
to automate all software? Okay, let's
to automate all software? Okay, let's
think about what that means. So well, if
think about what that means. So well, if
you write like if you write good domain
you write like if you write good domain
specific software in pretty much any
specific software in pretty much any
industry, uh you can solve like very
industry, uh you can solve like very
longstanding problems. I mean, literally
longstanding problems. I mean, literally
anybody who's capable, right, a capable
anybody who's capable, right, a capable
programmer who like actually knows some
programmer who like actually knows some
tech can really really transform a ton
tech can really really transform a ton
of industries just via software. So like
of industries just via software. So like
that's not just going to be software
that's not just going to be software
being replaced. That's kind of like most
being replaced. That's kind of like most
of the entire economy being
of the entire economy being
replaced. Okay. So
like you can't just like the magnitude
like you can't just like the magnitude
of the change is either going to be it
of the change is either going to be it
takes a while or
takes a while or
like well everything is completely
like well everything is completely
changed. It's not going to just be like
changed. It's not going to just be like
oh do this AI do like
oh do this AI do like
it's you kind of got to think about like
it's you kind of got to think about like
if you take the things that they say to
if you take the things that they say to
their logical conclusion what does that
their logical conclusion what does that
happen? Oh okay that makes no sense.
I'm not explaining that correctly
I'm not explaining that correctly
because it's like 8 a.m. on a Saturday.
But if I remove expert trajectories with
But if I remove expert trajectories with
collisions will improve score. Uh that's
collisions will improve score. Uh that's
a reasonable thing to do.
Spencer, I actually you're probably at
Spencer, I actually you're probably at
the point where you can just start
the point where you can just start
asking questions to the NYU folks just
asking questions to the NYU folks just
so that you get whatever it is that
so that you get whatever it is that
that's going to be useful for them
that's going to be useful for them
because like these aren't even details
because like these aren't even details
that are super important for whatever
that are super important for whatever
we're going to do with the sim at this
we're going to do with the sim at this
point, right?
Yeah. So, honestly to you, I would just
Yeah. So, honestly to you, I would just
suggest like, you
suggest like, you
know, build stuff that you find
know, build stuff that you find
interesting and that you enjoy. Um, if
interesting and that you enjoy. Um, if
AI is interesting to you and you want to
AI is interesting to you and you want to
learn about, go that way. There's so
learn about, go that way. There's so
much stuff that can be done.
much stuff that can be done.
And like at least at the time being as
And like at least at the time being as
somebody who's been programming for a
somebody who's been programming for a
long time and somebody who builds a lot
long time and somebody who builds a lot
of you know a lot of software in this
of you know a lot of software in this
area like the current language models
area like the current language models
are terrible programmers.
Um now I mean that said like could argue
Um now I mean that said like could argue
that like I would apply the same thing
that like I would apply the same thing
to like 90% of fang engineers and
to like 90% of fang engineers and
they're like making good money. So if
they're like making good money. So if
you're just trying to get a job then
you're just trying to get a job then
like okay maybe Maybe there's something
like okay maybe Maybe there's something
there. But like, have you noticed it's
there. But like, have you noticed it's
not like Fang has stopped hiring
not like Fang has stopped hiring
software engineers. Not like all the big
software engineers. Not like all the big
companies are like no longer hiring
companies are like no longer hiring
engineers. What does that tell
you? Hey,
you? Hey,
Quicksautique. We're taking a look at
Quicksautique. We're taking a look at
some um experiments from last
night and seeing if we see any cool
night and seeing if we see any cool
trends.
These are the 10 best snake
runs. Cycle learning rate is like in the
runs. Cycle learning rate is like in the
range we
expect. Gamas are very very high which
expect. Gamas are very very high which
is kind of
is kind of
surprising. You wouldn't expect gamma to
surprising. You wouldn't expect gamma to
be that high and then there's really low
be that high and then there's really low
lambda.
resampling my speed compute knobs. Yeah,
resampling my speed compute knobs. Yeah,
but the thing is like so Spencer with
but the thing is like so Spencer with
the speed on that like what we're going
the speed on that like what we're going
to do is we're like we match their
to do is we're like we match their
result and we say hey you guys mind if
result and we say hey you guys mind if
we mess with the obs a bit if we uh if
we mess with the obs a bit if we uh if
we keep PF the
we keep PF the
same they're going to say go for it.
same they're going to say go for it.
You're going to cut out 90% of the crap
You're going to cut out 90% of the crap
that's in the obs and then it's going to
that's in the obs and then it's going to
go 2 million SPS, right?
Why do think hard way if easy way just
Why do think hard way if easy way just
as
good? Okay, so snake actually benefits
good? Okay, so snake actually benefits
from some entropy it seems.
from some entropy it seems.
Cool. I guess it is one of the ends
Cool. I guess it is one of the ends
where you would kind of expect that.
I
I
mean, the bar for CS jobs has frankly
mean, the bar for CS jobs has frankly
just been way too low in the past.
Like, and let let me put it in a way
Like, and let let me put it in a way
that I think you'll find more
that I think you'll find more
encouraging. Um, working with bad
encouraging. Um, working with bad
programmers is a absolutely miserable
programmers is a absolutely miserable
experience. All right? Like I've had to
experience. All right? Like I've had to
work on teams where like, you know, you
work on teams where like, you know, you
have 10 engineers and they all suck. It
have 10 engineers and they all suck. It
is the most horrendous, depressing thing
is the most horrendous, depressing thing
imaginable, right? Like you can get paid
imaginable, right? Like you can get paid
well to like go do 30 hours of work a
well to like go do 30 hours of work a
week, but it's like holy hell. It is the
week, but it's like holy hell. It is the
most soul sucking depressing [ __ ]
most soul sucking depressing [ __ ]
imaginable. Like oh my god. because it's
imaginable. Like oh my god. because it's
like you're working on a job on a
like you're working on a job on a
computer all day where you're like
computer all day where you're like
fiddling with complicated things, right?
fiddling with complicated things, right?
And like hooking things together and
And like hooking things together and
basically it's the equivalent of like if
basically it's the equivalent of like if
you're building a house and people are
you're building a house and people are
just like nailing [ __ ] everywhere and
just like nailing [ __ ] everywhere and
you're trying to like make the thing
you're trying to like make the thing
like not fall apart. It is horrible.
like not fall apart. It is horrible.
Now, CS with a good team, with people
Now, CS with a good team, with people
who are building cool stuff is one of
who are building cool stuff is one of
the most enjoyable and awesome things
the most enjoyable and awesome things
out there cuz there's literally no other
out there cuz there's literally no other
field where you can build stuff that is
field where you can build stuff that is
this transformative just from your
this transformative just from your
laptop without having to have huge
laptop without having to have huge
amounts of equipment, without having to
amounts of equipment, without having to
have a capital investment. Like, you can
have a capital investment. Like, you can
do all sorts of cool stuff and in a ton
do all sorts of cool stuff and in a ton
of different areas, right? You can like
of different areas, right? You can like
go build stuff to transform basically
go build stuff to transform basically
any industry you can imagine just with
any industry you can imagine just with
that one skill set. Um, so like really,
that one skill set. Um, so like really,
yeah, the bar is higher. Just get good.
yeah, the bar is higher. Just get good.
Like if you care about this stuff, just
Like if you care about this stuff, just
get good. Put in the effort, right?
get good. Put in the effort, right?
You'll have more. Like, first of all,
You'll have more. Like, first of all,
you'll do better professionally
you'll do better professionally
regardless, and you'll enjoy it a heck
regardless, and you'll enjoy it a heck
of a lot more, too.
You're not going to be able to obsolete
You're not going to be able to obsolete
people in the next few years like this
people in the next few years like this
without a like a dramatic restructuring
without a like a dramatic restructuring
of stuff. So here's the thing like look
of stuff. So here's the thing like look
can you technically in the next few
can you technically in the next few
years will you technically be able to
years will you technically be able to
like ask a language model details about
like ask a language model details about
laws right and get a better response
laws right and get a better response
than you would get from a lawyer? Yeah,
than you would get from a lawyer? Yeah,
probably.
probably.
Um, are courts going to be letting you
Um, are courts going to be letting you
just have GPT defend you in court? No.
just have GPT defend you in court? No.
Uh, is GPT a person that's going to
Uh, is GPT a person that's going to
actually be able like to like an
actually be able like to like an
attorney to deliver a defense? No. Like,
attorney to deliver a defense? No. Like,
is it going to be able to actually
is it going to be able to actually
interact with professional systems like
interact with professional systems like
with like the in the existing way where
with like the in the existing way where
there has to be a person? No. And like
there has to be a person? No. And like
like even if the technological changes
like even if the technological changes
there like the infrastructure and the
there like the infrastructure and the
setup is not going to be so quick for a
setup is not going to be so quick for a
lot of stuff. Um, which is frustrating
lot of stuff. Um, which is frustrating
actually. It's frustrating when you
actually. It's frustrating when you
build tech when you build something that
build tech when you build something that
is better and it doesn't work better.
is better and it doesn't work better.
Now, to be fair, is it going to be
Now, to be fair, is it going to be
better than a good lawyer? No. No, it's
better than a good lawyer? No. No, it's
not. Um, so that's kind of a important
not. Um, so that's kind of a important
distinction.
distinction.
Um, yeah, I I think it's like I wouldn't
Um, yeah, I I think it's like I wouldn't
worry too much about like planning for
worry too much about like planning for
what is AI going to replace and this and
what is AI going to replace and this and
that. Just like trying to like give a
that. Just like trying to like give a
damn and get good at stuff is going to
damn and get good at stuff is going to
put you ahead of people who don't try
put you ahead of people who don't try
and don't, right? That's
it.
it.
Like that's kind of like regardless of
Like that's kind of like regardless of
what happens. Like no, you're going to
what happens. Like no, you're going to
do better off than the guy who doesn't
do better off than the guy who doesn't
give a damn and doesn't try.
And that's just how it always is.
Right now, the the key thing, right, and
Right now, the the key thing, right, and
this is the thing that's very difficult
this is the thing that's very difficult
unless you're one of those rare people
unless you're one of those rare people
who can basically like choose to do a
who can basically like choose to do a
thing and then just do it and like focus
thing and then just do it and like focus
on it regardless of whether you're
on it regardless of whether you're
interested. I can't do that at all. Uh
interested. I can't do that at all. Uh
the key thing is actually picking
the key thing is actually picking
something where you're able to get a
something where you're able to get a
good chunk of your like focus and
good chunk of your like focus and
attention out of it for prolonged
attention out of it for prolonged
periods of time, right? Which is usually
periods of time, right? Which is usually
you have to find something that is
you have to find something that is
consistently interesting to
you. Yeah. But if you defend yourself in
you. Yeah. But if you defend yourself in
court and just are reading off a GPT or
court and just are reading off a GPT or
whatever, you have to like there's a
whatever, you have to like there's a
jury sitting there, right, that's
jury sitting there, right, that's
watching you do
that. Like it doesn't work like whoever
that. Like it doesn't work like whoever
says the more like there there's an
says the more like there there's an
interaction there,
right? How can a lawyer be? Because it's
right? How can a lawyer be? Because it's
not just knowing the law. That's not
not just knowing the law. That's not
what it is, right? That's like an
encyclopedia. There's argument, there is
encyclopedia. There's argument, there is
interpretation, there's combination of
interpretation, there's combination of
that. Like there's a lot of things
that. Like there's a lot of things
there. It's not just like I mean that's
there. It's not just like I mean that's
not how that's like saying like, hey,
not how that's like saying like, hey,
how can uh how could a programmer
how can uh how could a programmer
possibly be better than GPT that has
possibly be better than GPT that has
access to every API ever? Well, I have
access to every API ever? Well, I have
access to every API ever just with a
access to every API ever just with a
Google search,
Google search,
right? That's not what it's about.
Oh, that's a crazy clip coefficient.
Oh, that's a crazy clip coefficient.
That's kind of
That's kind of
interesting. 75 clip with snake. Yeah.
interesting. 75 clip with snake. Yeah.
Okay, buddy.
All
All
right, let's go see our 75 clip snake
run.
run.
Jesus. It's a good thing that I
Jesus. It's a good thing that I
increased the uh the range of that param
increased the uh the range of that param
cuz apparently it
works. Holy
I don't know.
I don't know.
I would just generally suggest ignoring
I would just generally suggest ignoring
the like there's basically nothing good
the like there's basically nothing good
that comes out of listening to the like
that comes out of listening to the like
oh AI replacing you all whatever is on
oh AI replacing you all whatever is on
on the internet especially like Daario
on the internet especially like Daario
and Altman. I do not trust them for
and Altman. I do not trust them for
[ __ ] I
don't. It's actually, you know,
don't. It's actually, you know,
like, and it sucks as well because when
like, and it sucks as well because when
I was at OpenAI in 2019, Ultman actually
I was at OpenAI in 2019, Ultman actually
had a really, really good vision
had a really, really good vision
for where he wanted to take Open AI. He
for where he wanted to take Open AI. He
basically said like, "We want to be able
basically said like, "We want to be able
to take a ton of different concentrated
to take a ton of different concentrated
bets in different areas, right? Like a
bets in different areas, right? Like a
ton of different concentrated bets just
ton of different concentrated bets just
in all sorts of different areas of AI
in all sorts of different areas of AI
and see where they go." And that would
and see where they go." And that would
be fantastic. But then what happened is
be fantastic. But then what happened is
that GPT happened and then they canned
that GPT happened and then they canned
all the other teams and they put all the
all the other teams and they put all the
resources into LLMs and they didn't even
resources into LLMs and they didn't even
keep like you know any amount of stuff
keep like you know any amount of stuff
on different areas of AI and now it's
on different areas of AI and now it's
all marketing and it's just like it's a
all marketing and it's just like it's a
mess. It's a whole real
mess. So
mess. So
like didn't follow through on on that at
like didn't follow through on on that at
all.
money can. Yeah, it
money can. Yeah, it
is. But the thing is like I don't
is. But the thing is like I don't
begrudge people the money, right? I
begrudge people the money, right? I
never begrudge people the money. Um it's
never begrudge people the money. Um it's
just like don't entirely lose focus,
just like don't entirely lose focus,
right? Okay, LM are great, right? LM are
right? Okay, LM are great, right? LM are
doing a ton of stuff, but
doing a ton of stuff, but
like it's not that, oh, I see people
like it's not that, oh, I see people
making money in LM and that's bad or
making money in LM and that's bad or
like LM are blowing up. Like that's all
like LM are blowing up. Like that's all
good. The point where it drives me nuts
good. The point where it drives me nuts
is that
is that
like so you know how many people I know
like so you know how many people I know
in reinforcement learning, like really
in reinforcement learning, like really
good smart people who are still in
good smart people who are still in
reinforcement
reinforcement
learning, like pure RL with no LLM
learning, like pure RL with no LLM
stuff, zero.
stuff, zero.
All my buddies, all my buddies who are
All my buddies, all my buddies who are
brilliant in pure RL have gone to work
brilliant in pure RL have gone to work
at least in some capacity on
at least in some capacity on
LLMs. That's sad. And the reason that's
LLMs. That's sad. And the reason that's
sad is because what happens if the LLM
sad is because what happens if the LLM
people are wrong, right? What if they
people are wrong, right? What if they
don't solve everything? Then we're
don't solve everything? Then we're
[ __ ] because all that knowledge has
[ __ ] because all that knowledge has
just gone out the window. You know, it's
just gone out the window. You know, it's
not like you can't just read papers and
not like you can't just read papers and
get back the domain knowledge that the
get back the domain knowledge that the
experts actually have. It takes years to
experts actually have. It takes years to
rediscover these types of things, right?
rediscover these types of things, right?
So, that's actually damaged science a
So, that's actually damaged science a
ton. really more than anything else you
ton. really more than anything else you
see in the news lately is draining all
see in the news lately is draining all
of the resources from every other field
of the resources from every other field
to go into this one very specific sub
to go into this one very specific sub
field and have everybody building bigger
field and have everybody building bigger
and bigger models and like filtering
and bigger models and like filtering
data and whatever the hell else they're
data and whatever the hell else they're
doing with like a thousand people
doing with like a thousand people
instead of with
instead of with
500. So that's that is where I get
500. So that's that is where I get
annoyed with uh what's happening with
annoyed with uh what's happening with
LMS at the moment. Now, to be fair, I
LMS at the moment. Now, to be fair, I
think RL's going to be just fine. Um,
think RL's going to be just fine. Um,
because I, for whatever reason, have
because I, for whatever reason, have
decided to spend the rest of my 20s like
decided to spend the rest of my 20s like
trying to actually make it work and I'm
trying to actually make it work and I'm
having some good success here. So, I'm
having some good success here. So, I'm
going to make sure that RL is good, but
going to make sure that RL is good, but
what about all the other sub fields,
what about all the other sub fields,
right? There were people doing cool AIE
right? There were people doing cool AIE
stuff. There were people doing like
stuff. There were people doing like
hybrid systems. There were so many other
hybrid systems. There were so many other
cool things that people are doing that
cool things that people are doing that
they just stopped
on. Yeah. closed source max profit
on. Yeah. closed source max profit
is you want you'd ideally you want these
is you want you'd ideally you want these
research labs to at least have some open
research labs to at least have some open
source and like some mix of incentives
right like to their credit right the
right like to their credit right the
thing that they said is right like
thing that they said is right like
they're not going to get to where they
they're not going to get to where they
want to be without raising a ton of
want to be without raising a ton of
money
money
but like that doesn't mean you have to
but like that doesn't mean you have to
go 100% down that route
to the detriment of the rest of the
to the detriment of the rest of the
field at
field at
least. Like what happened to the Dota
least. Like what happened to the Dota
team, right? Like the Dota guys, I think
team, right? Like the Dota guys, I think
they just went on to codegen and stuff
they just went on to codegen and stuff
like man that you know how much damage
like man that you know how much damage
that did to RL alone losing like the
that did to RL alone losing like the
Dota team. That would have like we would
Dota team. That would have like we would
have a different field right now if they
have a different field right now if they
kept on that stuff. Um there were so
kept on that stuff. Um there were so
many so many good things and I know
many so many good things and I know
because I was around those people and
because I was around those people and
they were brilliant.
And now here I am. You know, it took me
And now here I am. You know, it took me
I had to do a PhD. So it took me five
I had to do a PhD. So it took me five
years to like actually get through the
years to like actually get through the
rigma role of that. Uh I made some
rigma role of that. Uh I made some
discoveries over the process but heavily
discoveries over the process but heavily
heavily constrained by academia and the
heavily constrained by academia and the
way that academia expects you to do your
way that academia expects you to do your
work. And now one year, it's literally
work. And now one year, it's literally
been one year since I've graduated. RS
been one year since I've graduated. RS
is a different field. And you know
is a different field. And you know
that's a little bit aggressive to say
that's a little bit aggressive to say
when I'm kind of promoting my own stuff
when I'm kind of promoting my own stuff
here, but literally just like take a
here, but literally just like take a
look at our tools today. use our tools
look at our tools today. use our tools
for RL now compared to anything else
for RL now compared to anything else
that existed one year ago. It is a
that existed one year ago. It is a
different field from one year of
different field from one year of
work. Like this stuff can be done and
work. Like this stuff can be done and
it's like it could have been done but it
it's like it could have been done but it
could have been done a long time ago,
could have been done a long time ago,
right? This could have been done a long
right? This could have been done a long
time
ago. It's all right. I'll do it now.
the right M. This is
right. Google's I've heard cool things.
right. Google's I've heard cool things.
Haven't read it yet.
I mean, the thing is like at this point
I mean, the thing is like at this point
there's like very little that I could
there's like very little that I could
read outside of what I'm doing at the
read outside of what I'm doing at the
moment unless it directly says that the
moment unless it directly says that the
thing I'm doing won't work. There's like
thing I'm doing won't work. There's like
very little that would like convince me
very little that would like convince me
to like look at other stuff at the
to like look at other stuff at the
moment because I see like where this is
moment because I see like where this is
going right
going right
now. Drainage of young people. Well,
now. Drainage of young people. Well,
they're being drained into into all AI.
they're being drained into into all AI.
Yeah.
Yeah.
I don't know, man. There's a bunch of
I don't know, man. There's a bunch of
just jank
just jank
stuff. The whole like, oh, let's just
stuff. The whole like, oh, let's just
use GPA to code for us thing is
horrid. The fact that they're actually
horrid. The fact that they're actually
CEOs dumb enough to think that like, oh
CEOs dumb enough to think that like, oh
yeah, the most important thing is all
yeah, the most important thing is all
our programmers are using AI constantly.
our programmers are using AI constantly.
Like, holy hell.
Like most of the time, at least like 80%
Like most of the time, at least like 80%
of the time, I'd say I uh I kind of use
of the time, I'd say I uh I kind of use
like I'll use Grock or whatever as like
like I'll use Grock or whatever as like
fancy API docs for like looking up niche
fancy API docs for like looking up niche
stuff. I'm never using it to like just
stuff. I'm never using it to like just
oh yeah, just write all the code.
oh yeah, just write all the code.
I literally I had the other
day I went off on one of our
day I went off on one of our
contributors for costing me six hours by
contributors for costing me six hours by
uh to be fair I shouldn't have merged
uh to be fair I shouldn't have merged
it. Like I didn't I missed it though. He
it. Like I didn't I missed it though. He
like used GPT or Gemini or whatever uh
like used GPT or Gemini or whatever uh
to submit a patch to critical
to submit a patch to critical
infrastructure he didn't understand and
infrastructure he didn't understand and
literally cost me six hours with one of
literally cost me six hours with one of
the worst bugs I've had to deal with in
the worst bugs I've had to deal with in
months.
months.
um
um
just don't you
know and it almost doesn't matter like
know and it almost doesn't matter like
how good the AI gets is the thing like
how good the AI gets is the thing like
there's never a time when that's going
there's never a time when that's going
to
to
be like there's kind of never a time in
be like there's kind of never a time in
my s in like my eyes where it makes
my s in like my eyes where it makes
sense to have like the human like like
sense to have like the human like like
person writing prompts in equals
person writing prompts in equals
programmer because then it's like you
programmer because then it's like you
either just use the lang language model
either just use the lang language model
as the programmer completely which ain't
as the programmer completely which ain't
happening anytime soon. Uh or you don't
happening anytime soon. Uh or you don't
do that and you actually maintain
do that and you actually maintain
control over what you're writing and
control over what you're writing and
like you understand how the thing that
like you understand how the thing that
you're working on actually should
work more efficient algorithm. Yeah. So
work more efficient algorithm. Yeah. So
that was
that was
interesting. But this is far from what
interesting. But this is far from what
we were promised, right? This is far
we were promised, right? This is far
from like the recursively self-improving
from like the recursively self-improving
systems that just get better and better
systems that just get better and better
and better.
Um, which is odd because like I can do
Um, which is odd because like I can do
that, right? Like I can recursively
that, right? Like I can recursively
self-improve. I've done it with Puffer,
self-improve. I've done it with Puffer,
right? I've literally if you look at
right? I've literally if you look at
where it was in like if you look at
where it was in like if you look at
where RL was a year ago and you look at
where RL was a year ago and you look at
it now and basically the prompt behind
it now and basically the prompt behind
puffer was like hey fix everything wrong
puffer was like hey fix everything wrong
with reinforcement learning informed by
with reinforcement learning informed by
you know your own understanding of the
you know your own understanding of the
current literature the current research
current literature the current research
and the current state of the field. If
and the current state of the field. If
you want to like think of the prompt
you want to like think of the prompt
that would be it.
So, you know,
So, you know,
if if uh you're going to say that like,
if if uh you're going to say that like,
okay, these language models have PhD
okay, these language models have PhD
level intelligence. Well, I'm a PhD.
level intelligence. Well, I'm a PhD.
That's my qualification for doing this.
That's my qualification for doing this.
Um I don't see language models doing
Um I don't see language models doing
anything remotely like this, right?
anything remotely like this, right?
They're not even like, you can't even
They're not even like, you can't even
give them like, hey, you know, go pick a
give them like, hey, you know, go pick a
problem, like pick a thing that needs
problem, like pick a thing that needs
like some better tools and make those
like some better tools and make those
tools. You can't even get them to do
tools. You can't even get them to do
like a midsize project that I could have
like a midsize project that I could have
any more junior dev do who's had like a
any more junior dev do who's had like a
couple years of dev
couple years of dev
experience. So, I don't
experience. So, I don't
know. That's not to say these things
know. That's not to say these things
aren't impressive. They wildly are very
aren't impressive. They wildly are very
impressive. And I should be clear with
impressive. And I should be clear with
that when I uh when I'm bashing these
that when I uh when I'm bashing these
things. The thing that I'm critical of
things. The thing that I'm critical of
is the drainage of all talent to work on
is the drainage of all talent to work on
these. And also how much the CEOs in
these. And also how much the CEOs in
these areas just they lie about freaking
these areas just they lie about freaking
everything, you know?
That's the
issue. AI discovered something new.
issue. AI discovered something new.
Well, that's not definitely not true,
Well, that's not definitely not true,
right? That's definitely not the case.
right? That's definitely not the case.
We've had AIS discover things all the
We've had AIS discover things all the
time that are new.
time that are new.
Um, I mean the thing is like most new
Um, I mean the thing is like most new
things
things
are I mean they're just logical
are I mean they're just logical
inferences off of previous things many
inferences off of previous things many
of the times unless every so often
of the times unless every so often
there's like a completely out there
there's like a completely out there
thing.
thing.
Um, but that stuff's definitely happened
before. I don't think it's I wouldn't
before. I don't think it's I wouldn't
look at it as like a step
change as much as just like an
change as much as just like an
impressive result.
the like, oh, it's a step change thing
the like, oh, it's a step change thing
is usually, at least when there's money
is usually, at least when there's money
behind it, there's usually like, hey,
behind it, there's usually like, hey,
um, somebody's trying to sell you
um, somebody's trying to sell you
something. Now, I say that while kind of
something. Now, I say that while kind of
claiming the same thing about Puffer,
claiming the same thing about Puffer,
like I will say that Puffer 3 is a step
like I will say that Puffer 3 is a step
change over, uh, previous like RL stuff.
change over, uh, previous like RL stuff.
Um, but that's really because like from
Um, but that's really because like from
a perspective of somebody who's been
a perspective of somebody who's been
doing RL research for a long time, like
doing RL research for a long time, like
it just feels more stable is the thing.
it just feels more stable is the thing.
It feels like a qualitative
change. Whereas I don't think like
change. Whereas I don't think like
something discovering one thing is a
something discovering one thing is a
step like that's not like a qu like a
step like that's not like a qu like a
step change. It would have to be
step change. It would have to be
something really crazy, right?
Like, yeah, if it goes and resolves P
Like, yeah, if it goes and resolves P
equals NP or something, then yeah.
equals NP or something, then yeah.
Okay. Okay.
Okay. Okay.
Right. But like, it made its own
Right. But like, it made its own
training 1% more efficient. It's really
training 1% more efficient. It's really
cool. It's a like it's a nice
cool. It's a like it's a nice
advancement. It's not like a step
advancement. It's not like a step
change, I wouldn't say.
But the thing is you're you're limiting
But the thing is you're you're limiting
to just LMS. Like RL's been doing this
to just LMS. Like RL's been doing this
for a while, right? There was like the
for a while, right? There was like the
uh the was it move 37 or whatever in Go.
uh the was it move 37 or whatever in Go.
Um they like there's new strategies that
Um they like there's new strategies that
the thing has discovered and like Dota
the thing has discovered and like Dota
like and those are like really small
like and those are like really small
models as well. Um heck the Dota ones
models as well. Um heck the Dota ones
didn't even have search in them and they
didn't even have search in them and they
changed like they discovered stuff that
changed like they discovered stuff that
like pro players hadn't seen before as
like pro players hadn't seen before as
well. Um there's similar stuff in Alpha
well. Um there's similar stuff in Alpha
Star. AI has been like it's kind of
Star. AI has been like it's kind of
always been able to discover new
always been able to discover new
stuff. Now like language models
specifically, language models
specifically, language models
specifically, it's very hard to prove is
specifically, it's very hard to prove is
the problem because like you don't
the problem because like you don't
actually know what's in the training
actually know what's in the training
data.
data.
There's definitely been
There's definitely been
quirky like clever stuff where I
quirky like clever stuff where I
couldn't find a reference for it. I
couldn't find a reference for it. I
think one of the the funniest things I
think one of the the funniest things I
saw was
um there was a thing that I came out of
um there was a thing that I came out of
GPT. I think it was like three or 3.5. I
GPT. I think it was like three or 3.5. I
couldn't find a source for it anywhere,
couldn't find a source for it anywhere,
but that doesn't mean it wasn't in the
but that doesn't mean it wasn't in the
training data.
training data.
There was like some quip from it that's
There was like some quip from it that's
like, "What's a bastard sword?" Well,
like, "What's a bastard sword?" Well,
it's not my father's sword and I didn't
it's not my father's sword and I didn't
make it. And he didn't make it
make it. And he didn't make it
himself, which I like that was the first
himself, which I like that was the first
thing I looked at and went like, I
thing I looked at and went like, I
actually come up with
that. I don't know. But you can't prove
that. I don't know. But you can't prove
that type of stuff unfortunately. Now,
that type of stuff unfortunately. Now,
like scientific breakthroughs,
um, yeah, comedian chief, that's funny.
um, yeah, comedian chief, that's funny.
Now, like scientific breakthroughs, the
Now, like scientific breakthroughs, the
thing is
thing is
like that's not really that's like they
like that's not really that's like they
made an optimization to a kernel. Like
made an optimization to a kernel. Like
there's one optimization to a kernel.
there's one optimization to a kernel.
Um, the reason that that sounds
Um, the reason that that sounds
impressive is because kernels are like
impressive is because kernels are like
this, oh, like this fantastic weird
this, oh, like this fantastic weird
thing that only the elite elite
thing that only the elite elite
programmers know. Kernels are freaking
programmers know. Kernels are freaking
simple. Here, let me show you a
kernel.
Here, this is all a kernel
Here, this is all a kernel
is.
Uh, all right. It's just a piece of C
Uh, all right. It's just a piece of C
code that runs on your GPU. That's all
code that runs on your GPU. That's all
it
it
is. And it's like run in parallel on
is. And it's like run in parallel on
blocks of like on usually embarrassingly
blocks of like on usually embarrassingly
parallel blocks of
parallel blocks of
data. That's all it is. But all the
data. That's all it is. But all the
thing did is like all right you got like
thing did is like all right you got like
a matrix mold kernel that has some ops
a matrix mold kernel that has some ops
it makes like some small change that
it makes like some small change that
makes this it a little bit faster while
makes this it a little bit faster while
have doing like the same
have doing like the same
thing. Now be fair I think that in their
thing. Now be fair I think that in their
case it was it made a much larger change
case it was it made a much larger change
but it was because it was only for a
but it was because it was only for a
very specific matrix multiply format.
very specific matrix multiply format.
Um,
Um,
yeah, I wouldn't be surprised like
yeah, I wouldn't be surprised like
literally nobody's tried to like
literally nobody's tried to like
optimize that at all
before. Did this thing just only get 97?
before. Did this thing just only get 97?
Did I just read that
right? That's not good.
Maybe we shouldn't go for the lucky yolo
Maybe we shouldn't go for the lucky yolo
run
here. Yeah, that doesn't seem super
here. Yeah, that doesn't seem super
stable,
huh?
huh?
Wait, something's weird.
I was definitely weird with that.
Something feels different there. Did I
Something feels different there. Did I
miss a parameter?
miss a parameter?
Perhaps I might have missed a a
Perhaps I might have missed a a
parameter there. Hang on.
So yeah, this one is definitely unstable
So yeah, this one is definitely unstable
at least as written.
32k mini
32k mini
batch. I missed something like with veck
batch. I missed something like with veck
or
or
something. There's ve Oh, 16
something. There's ve Oh, 16
m. I don't know how I messed that
m. I don't know how I messed that
up. Try again.
Oh yeah, that's way faster. 3 million
Oh yeah, that's way faster. 3 million
step per second
step per second
snake. That's with a That's with a small
snake. That's with a That's with a small
combin too, isn't it? It is with a comet
combin too, isn't it? It is with a comet
combet at 3
combet at 3
million. That's
million. That's
good. That's not even on a 5090.
Ah, there we
Ah, there we
go. Okay, that was on me. I just had it
go. Okay, that was on me. I just had it
reproed
wrong. Oh, we have lots of M that we're
wrong. Oh, we have lots of M that we're
trying to solve. Um, so Gabe made
trying to solve. Um, so Gabe made
Pac-Man.
Pac-Man.
We also have the snake end
We also have the snake end
which we
are. Let's see how good these snakes
look. Multi-agent snake with a ton of
look. Multi-agent snake with a ton of
snakes.
Pretty cool if you just kind of watch
Pretty cool if you just kind of watch
this thing,
right? Thing took like two minutes to
right? Thing took like two minutes to
train and we actually have
train and we actually have
like neuronets playing snake pretty darn
like neuronets playing snake pretty darn
capably.
mechanically they're
superhuman. Oh, I
bought. Yeah, that's way better than
bought. Yeah, that's way better than
what we have on the website for
sure.
sure.
Cool. I'm happy with this result. This
Cool. I'm happy with this result. This
is very clean.
Where did this go?
Let's just do a little bit of quick
math. Second
There's that many
160 days, right?
160 days, right?
Yeah.
Yeah.
Hours, 10 steps per second. Yeah, that's
Hours, 10 steps per second. Yeah, that's
right. And that
right. And that
passes my quick maths test as well.
Yeah. 140 mil
Yeah. 140 mil
steps, 36,000 steps per
steps, 36,000 steps per
hour, 24 days. Yeah, that's correct.
That's a nice gift.
Okay, snake prams are
good. Let's add um add these to the
spreadsheet. Pac-Man and Snake.
These clipping coefficients are very
These clipping coefficients are very
odd, I will
odd, I will
say. Very, very
odd. Being zero is especially sus.
Got seven of these M's
Got seven of these M's
though. And I can probably get connect
though. And I can probably get connect
four if I can make it not Seg fault.
Fix render in
Python.
Yes. Not going to get called.
Welcome, man. How's it
going? Thoughts on
hiking? I don't really ever hike. I'll
hiking? I don't really ever hike. I'll
run.
run.
I did a heck of a lot of running last
I did a heck of a lot of running last
summer at the Stamford
Dish. I don't
Dish. I don't
know. If I want to relax, I'm going to
know. If I want to relax, I'm going to
walk. If I want to exercise, I'm going
walk. If I want to exercise, I'm going
to run. Hiking is kind of a weird in
to run. Hiking is kind of a weird in
between.
I wonder if this is a numb workers.
supported. Yeah, I know. Wolfra does the
supported. Yeah, I know. Wolfra does the
the funny
things. Nah, I prefer to
things. Nah, I prefer to
do I don't do my exercise while I'm
do I don't do my exercise while I'm
coding. It's crazy. That guy is just
coding. It's crazy. That guy is just
nuts. He's very productive, but he's
nuts. He's very productive, but he's
nuts. I don't know how the hell he does
nuts. I don't know how the hell he does
any of
that.
Unsupported. Something's weird here.
Why the hell is this?
Why the hell is this?
Four
in the Zaro
here. Cellular. That's cool stuff. I
here. Cellular. That's cool stuff. I
mean, we could pro like honestly there's
mean, we could pro like honestly there's
a lot of a lifestyle work we could do
a lot of a lifestyle work we could do
and probably just crush with
and probably just crush with
uh the way we do stuff in
puffer. Okay.
puffer. Okay.
So somehow numb
workers up for connect four. So somehow
workers up for connect four. So somehow
numb workers is getting passed as
numb workers is getting passed as
four. Really shouldn't be here. Upper
four. Really shouldn't be here. Upper
connect
connect
four because this auto
This not have numb
This not have numb
workers. Oh, it's got to be
Vec. Okay, so this has numb workers set
Vec. Okay, so this has numb workers set
to four for some reason.
Something seems weird with that.
Am I like I'm trying to figure out if
Am I like I'm trying to figure out if
I'm doing something monumentally
stupid? Not just do I not have it
stupid? Not just do I not have it
written like what?
written like what?
Oh, I do base
env. So, how the heck does it default to
uh the four? That's
weird. That's so weird.
Oh, cuz you're stupid. That's why.
This still This still does not run
This still This still does not run
though.
Still does not run.
Is there anything jank in this config
Is there anything jank in this config
that would
that would
cause I wonder if it's this
No, it's not the learning, right?
What the heck would cause this in
um like the end of itself.
If I set up a preset number of
agents, but my M does not actually
agents, but my M does not actually
create that total number of
create that total number of
agents across all
copies. That have a bad downstream.
copies. That have a bad downstream.
Well, yes.
Um well, if
Um well, if
you if you create more agents than you
you if you create more agents than you
request and you're writing to the
request and you're writing to the
buffer, then you're
overflowing. If you have 1022, then the
overflowing. If you have 1022, then the
odds are just going to be zeros, right?
odds are just going to be zeros, right?
like you're going to have it's either
like you're going to have it's either
going to be zero data or whatever
going to be zero data or whatever
happened to be in that buffer last
thing is still
jank. Other M's we can do. We should
jank. Other M's we can do. We should
launch some more sweeps right now.
launch some more sweeps right now.
Get like puffer grid.
We're going to let this
We're going to let this
run. This covers grid and let's do
run. This covers grid and let's do
um that I can't
really ask
I do have an invite I want to work on
I do have an invite I want to work on
actually today potentially. There's also
actually today potentially. There's also
terraform to
terraform to
do. We could just sweep Terraform
do. We could just sweep Terraform
technically, but like it's
technically, but like it's
not I don't know if it's like close
not I don't know if it's like close
enough to done deep BB like be worth
enough to done deep BB like be worth
doing anything with that on yet. I
doing anything with that on yet. I
definitely like having the grid sweep
definitely like having the grid sweep
up. Um what other M have we not done? I
up. Um what other M have we not done? I
guess we haven't done the RAWware and
guess we haven't done the RAWware and
triple like those are easy though. It's
triple like those are easy though. It's
just I there's one annoying thing I have
just I there's one annoying thing I have
to deal with for that.
Oh yeah, tower climb. Let me do that for
Oh yeah, tower climb. Let me do that for
you real quick. Good
call. Not on the website, so I keep
call. Not on the website, so I keep
forgetting website.
max. And well, we'll see what this does.
Um, why does this not have a num maps
param? No maps is
param? No maps is
50. Hey, does it take forever to make
50. Hey, does it take forever to make
maps or something?
like map gems really slow.
Oh, that's
annoying. Yeah, dude. That map gen is
annoying. Yeah, dude. That map gen is
super
slow. Is it crashed?
That's seg faulted, isn't it?
Looks like faulted.
Well, this runs
Yeah. Okay. It is just
slow. Are we supposed to use harder maps
slow. Are we supposed to use harder maps
or something though? Because
like I mean I just ran defaults and
like I mean I just ran defaults and
um get 80% in like seconds.
um get 80% in like seconds.
Doesn't look stable though. I guess I'll
Doesn't look stable though. I guess I'll
run this for
now. Go get you. Um
Get this.
Good. This is actually No, this is
Good. This is actually No, this is
four. Oh, I I messed that up in the
four. Oh, I I messed that up in the
repro then, didn't
repro then, didn't
I? I will fix that real quick.
I forgot his name.
Didn't I just edit tower climb?
That heat.
math domain error. Lovely.
Did I just get a good
error? Uh cuz min and max are backwards,
error? Uh cuz min and max are backwards,
man.
man.
That's why
and then this will be the tower climb
and then this will be the tower climb
sweep. We're getting very close to
sweep. We're getting very close to
having hyper prams for everything.
It should be
sweep. How do we still have this
error reward full Bro,
Still thought I fixed
Still thought I fixed
everything. 0 to one with mean of.5.
Oh, you dummy.
Still,
man, how am I screwing this up so badly
man, how am I screwing this up so badly
today? What the
heck? Like
Ah, I
Ah, I
see. Why had I not I have negative
see. Why had I not I have negative
number? What?
confused. I not swept negative rewards
confused. I not swept negative rewards
before.
Well, I mean for now what we can do
is hang on. I got uh somebody at the at
is hang on. I got uh somebody at the at
the
Four. All right.
We'll just change this to uniform for
We'll just change this to uniform for
now. I think that that should
work. And
now error train.
What? What are we doing here? Oh, we're
What? What are we doing here? Oh, we're
doing stupid things.
Seems like it's
starting. If it actually starts uh
starting. If it actually starts uh
starts
starts
running. So then we are
set. Hoping this is just taking a
while. Oh yeah, it works.
while. Oh yeah, it works.
This takes a while to generate maps.
This takes a while to generate maps.
That's
That's
fine.
Cool. We've got grid and tower climb
Cool. We've got grid and tower climb
running sweeps at the moment.
Okay, so let's think of uh what
Okay, so let's think of uh what
environments have we not done yet? We
environments have we not done yet? We
got tower climb. Obviously, there is
got tower climb. Obviously, there is
Impulse Wars to deal
Impulse Wars to deal
with. Neuralarm MMO, those are the hard
with. Neuralarm MMO, those are the hard
ones.
ones.
We got Moa, go snake. We got all these
We got Moa, go snake. We got all these
done. E4 even. This has the Segv
done. E4 even. This has the Segv
vault. Not bad. Look at that. These two
vault. Not bad. Look at that. These two
we haven't done yet. They're easy.
we haven't done yet. They're easy.
They're just one small quirk I have to
They're just one small quirk I have to
fix.
fix.
Um and then yeah, we get to start
Um and then yeah, we get to start
thinking probably about neural MMO and
thinking probably about neural MMO and
uh and such.
It would seem odd that neural MMO is
It would seem odd that neural MMO is
this much harder
this much harder
though, wouldn't
it? Oh, it is kind of a hard end.
I guess we could do like a
I guess we could do like a
short a short local sweep
short a short local sweep
uh on Terraform.
Make sure this actually runs.
All
right. Stuff like target we don't need
right. Stuff like target we don't need
to hyper prem sweep it just it trains
instantly. We can start looking at um
instantly. We can start looking at um
the trends here
though. The atom optimizer params are or
though. The atom optimizer params are or
the uh the optim params are very weird.
We look at VF
clip. It only did for enduro. It did the
clip. It only did for enduro. It did the
really low VF clip
here. The rest of them are actually
here. The rest of them are actually
reasonable.
They're pretty different hypers
They're pretty different hypers
actually.
I mean, at least like triple triad has
I mean, at least like triple triad has
the low gamma you'd
the low gamma you'd
expect and connect four which did run
expect and connect four which did run
gives
gives
us really high. Okay, that's weird.
us really high. Okay, that's weird.
So, I mean, we definitely have way more
So, I mean, we definitely have way more
stable hyper pram ranges than
stable hyper pram ranges than
before to the point like if you don't
before to the point like if you don't
tune your hypers, you can still like get
tune your hypers, you can still like get
a lot of stuff to work. But I think it
a lot of stuff to work. But I think it
still makes sense to have pretty tuned
still makes sense to have pretty tuned
hypers for a lot of
stuff. So I think that's probably the
stuff. So I think that's probably the
best way to think about it is like it's
best way to think about it is like it's
not necessarily that we made hypers way
not necessarily that we made hypers way
more robust alone. It's that we kind of
more robust alone. It's that we kind of
just made everything better. So like the
just made everything better. So like the
level of performance we were getting
level of performance we were getting
before with optimized hypers we can now
before with optimized hypers we can now
get with unoptimized hypers. But we can
get with unoptimized hypers. But we can
do way better
do way better
still with optimized hypers which is
still with optimized hypers which is
fine. That's totally
fine. That's totally
fine. I'm fine shipping like custom
fine. I'm fine shipping like custom
hypers for each if that's not an issue.
hypers for each if that's not an issue.
if it gives us better
if it gives us better
perf. I don't think we should feel bad
perf. I don't think we should feel bad
about
that. Let's go look at what other M's I
that. Let's go look at what other M's I
have missed that I just like have
have missed that I just like have
forgotten about in here.
Oh, we kind of got Oh, those are the
Oh, we kind of got Oh, those are the
two. What about the
two. What about the
3L? Blast star. I didn't tune that
yet. We're doing pretty well.
I'm going to just launch a quick sweep
I'm going to just launch a quick sweep
on Terraform.
I'm just going to let this run locally
I'm just going to let this run locally
for uh over
for uh over
breakfast. And yeah, I'm going to go get
breakfast. And yeah, I'm going to go get
breakfast in a minute here. Uh and I'll
breakfast in a minute here. Uh and I'll
be back in a bit. And
be back in a bit. And
then I think it'll probably make the
then I think it'll probably make the
most sense to just like either do stuff
most sense to just like either do stuff
on some of the harder M's like look at
on some of the harder M's like look at
Impulse Wars, look at Nurm Mo, maybe
Impulse Wars, look at Nurm Mo, maybe
look at uh some Dev on Terraform or
look at uh some Dev on Terraform or
start uh some new new research pretty
start uh some new new research pretty
well. So I'll go think about what I want
well. So I'll go think about what I want
to do next on this. I guess technically
to do next on this. I guess technically
we could also just like if I don't feel
we could also just like if I don't feel
like starting on something, we could
like starting on something, we could
also just like get all the new policies
also just like get all the new policies
exported that we have the demos done.
exported that we have the demos done.
and that's also fine. Anyways, uh I will
and that's also fine. Anyways, uh I will
be back after breakfast. So, uh and then
be back after breakfast. So, uh and then
I will be live for the whole rest of the
I will be live for the whole rest of the
day. Goal is going to be to stream like
day. Goal is going to be to stream like
an extra seven, eight hours today. So,
an extra seven, eight hours today. So,
um at least. Thanks for tuning in for
um at least. Thanks for tuning in for
the morning session and I will
